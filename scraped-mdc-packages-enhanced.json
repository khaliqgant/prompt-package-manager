[
  {
    "name": "cursor-actix-web",
    "description": "Comprehensive best practices for developing robust, efficient, and maintainable applications using the actix-web framework in Rust. This rule covers coding standards, project structure, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "actix-web",
      "rust",
      "systems",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/actix-web.mdc",
    "content": "# Actix-web Best Practices: A Comprehensive Guide\n\nThis guide provides a comprehensive overview of best practices for developing applications using the actix-web framework in Rust. It covers various aspects of development, including code organization, performance optimization, security, testing, and common pitfalls.\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability and scalability. Here's how to structure your actix-web project effectively:\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a modular and layered architecture. A common and recommended directory structure is as follows:\n\n\nproject_root/\n├── src/\n│   ├── main.rs           # Entry point of the application\n│   ├── lib.rs            # Library file if extracting common functionality\n│   ├── modules/\n│   │   ├── mod.rs        # Module declaration\n│   │   ├── auth/         # Authentication module\n│   │   │   ├── mod.rs    # Auth module declaration\n│   │   │   ├── models.rs # Auth models\n│   │   │   ├── routes.rs # Auth routes\n│   │   │   ├── handlers.rs # Auth handlers\n│   │   ├── users/        # User management module\n│   │   │   ├── mod.rs    # User module declaration\n│   │   │   ├── models.rs # User models\n│   │   │   ├── routes.rs # User routes\n│   │   │   ├── handlers.rs # User handlers\n│   ├── models/           # Data models\n│   │   ├── mod.rs\n│   │   ├── user.rs      # User model\n│   │   ├── post.rs      # Post model\n│   ├── routes/           # Route configurations\n│   │   ├── mod.rs\n│   │   ├── auth_routes.rs # Authentication routes\n│   │   ├── user_routes.rs # User routes\n│   ├── handlers/         # Request handlers (controllers)\n│   │   ├── mod.rs\n│   │   ├── auth_handlers.rs # Authentication handlers\n│   │   ├── user_handlers.rs # User handlers\n│   ├── middleware/       # Custom middleware components\n│   │   ├── mod.rs\n│   │   ├── logger.rs   # Logging middleware\n│   │   ├── auth.rs     # Authentication middleware\n│   ├── utils/            # Utility functions and modules\n│   │   ├── mod.rs\n│   │   ├── db.rs        # Database connection utility\n│   ├── errors/           # Custom error definitions\n│   │   ├── mod.rs\n│   │   ├── app_error.rs # Application-specific error types\n├── tests/            # Integration and unit tests\n│   ├── mod.rs\n│   ├── api_tests.rs  # Integration tests for API endpoints\n├── .env                # Environment variables\n├── Cargo.toml          # Project dependencies and metadata\n├── Cargo.lock          # Dependency lockfile\n\n\n### 1.2. File Naming Conventions\n\n*   **Modules:** Use lowercase, descriptive names (e.g., `auth`, `users`, `posts`).\n*   **Files:** Use lowercase with underscores (e.g., `user_routes.rs`, `auth_handlers.rs`).\n*   **Models:** Use singular nouns (e.g., `user.rs`, `post.rs`).\n*   **Handlers:** Use descriptive names indicating the action performed (e.g., `create_user`, `get_user`).\n*   **Routes:** Use names indicating the resource they handle (e.g., `user_routes`, `auth_routes`).\n\n### 1.3. Module Organization\n\n*   **Explicit Module Declarations:** Always declare submodules in `mod.rs` files. This ensures proper module resolution and prevents naming conflicts.\n*   **Clear Boundaries:** Each module should have a well-defined responsibility. Avoid mixing unrelated functionalities within the same module.\n*   **Public vs. Private:** Use `pub` keyword judiciously to control visibility. Keep implementation details private to modules to prevent accidental external dependencies.\n\n### 1.4. Component Architecture\n\n*   **Layered Architecture:** Separate concerns into distinct layers (e.g., data access, business logic, presentation). This improves testability and maintainability.\n*   **Dependency Injection:**  Use dependency injection to provide dependencies to handlers. This makes it easier to test and configure your application.\n*   **Services:** Encapsulate business logic into services. Handlers should primarily focus on request/response handling and delegate business logic to services.\n\n### 1.5. Code Splitting Strategies\n\n*   **Feature-Based Splitting:** Group code based on features (e.g., authentication, user management). This makes it easier to understand and maintain related code.\n*   **Module-Based Splitting:** Split code into modules based on functionality. This improves code organization and reusability.\n*   **Lazy Loading (Future Enhancement):**  For very large applications, consider lazy loading modules or features to reduce initial startup time.  This can be accomplished by dynamically enabling parts of your application based on configuration or runtime conditions.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Actix-web\n\n*   **Extractor Pattern:** Use extractors to handle different types of incoming data (e.g., `Path`, `Query`, `Json`, `Form`). Extractors simplify handler logic and provide type safety.\n*   **Middleware Pattern:** Implement custom middleware for tasks like logging, authentication, and request modification. Middleware allows you to intercept and process requests before they reach the handlers.\n*   **State Management Pattern:** Use `web::Data` to share application state across handlers. This provides a thread-safe way to access shared resources like database connections and configuration settings.\n*   **Error Handling Pattern:** Define custom error types and implement the `ResponseError` trait for centralized error handling and consistent error responses.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Database Integration:** Use an asynchronous database driver like `tokio-postgres` or `sqlx` for efficient database interactions.\n*   **Authentication:** Implement authentication using JWT (JSON Web Tokens) or other secure authentication mechanisms.\n*   **Authorization:** Implement role-based access control (RBAC) or attribute-based access control (ABAC) to restrict access to resources based on user roles or attributes.\n*   **Logging:** Use a logging framework like `tracing` or `log` for structured logging and monitoring.\n*   **Configuration Management:** Use a configuration library like `config` or `dotenv` to manage application settings from environment variables and configuration files.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n*   **Long Handler Functions:** Keep handler functions short and focused. Delegate complex logic to services or helper functions.\n*   **Tight Coupling:** Avoid tight coupling between modules. Use interfaces and dependency injection to decouple components.\n*   **Ignoring Errors:** Always handle errors gracefully and provide informative error messages to the client.\n*   **Blocking Operations in Handlers:** Avoid performing blocking operations (e.g., synchronous I/O) in handler functions. Use asynchronous operations to prevent blocking the event loop.\n*   **Overusing Global State:** Minimize the use of global state. Prefer passing state as dependencies to handler functions.\n\n### 2.4. State Management Best Practices\n\n*   **Immutable State:** Prefer immutable state whenever possible. This reduces the risk of race conditions and makes it easier to reason about the application.\n*   **Thread-Safe Data Structures:** Use thread-safe data structures like `Arc<Mutex<T>>` or `RwLock<T>` to share mutable state across threads.\n*   **Avoid Direct Mutability:** Avoid directly mutating shared state. Instead, use atomic operations or message passing to coordinate state updates.\n*   **Dependency Injection:** Use dependency injection to provide state to handler functions. This makes it easier to test and configure the application.\n\n### 2.5. Error Handling Patterns\n\n*   **Custom Error Types:** Define custom error types to represent different error scenarios in your application.\n*   **`ResponseError` Trait:** Implement the `ResponseError` trait for custom error types to generate appropriate HTTP responses.\n*   **Centralized Error Handling:** Use a centralized error handling mechanism (e.g., middleware) to catch and process errors consistently.\n*   **Informative Error Messages:** Provide informative error messages to the client to help them understand and resolve the issue.\n*   **Logging Errors:** Log errors with sufficient detail to help diagnose and debug issues.\n*  **`Result` Type:** Leverage the `Result` type effectively, propagating errors up the call stack using the `?` operator, and handle them at the appropriate level.\n\n## 3. Performance Considerations\n\nOptimizing performance is crucial for building scalable and responsive actix-web applications.\n\n### 3.1. Optimization Techniques\n\n*   **Asynchronous Operations:** Use asynchronous operations for I/O-bound tasks (e.g., database access, network requests) to prevent blocking the event loop.\n*   **Connection Pooling:** Use connection pooling for database connections to reduce the overhead of establishing new connections.\n*   **Caching:** Implement caching for frequently accessed data to reduce database load and improve response times.\n*   **Compression:** Enable compression (e.g., gzip) for responses to reduce the amount of data transmitted over the network.\n*   **Keep-Alive Connections:** Use keep-alive connections to reuse existing TCP connections and reduce connection establishment overhead.\n\n### 3.2. Memory Management\n\n*   **Avoid Unnecessary Cloning:** Minimize cloning of data to reduce memory allocations and copying.\n*   **Use References:** Use references instead of copying data whenever possible.\n*   **Smart Pointers:** Use smart pointers (e.g., `Box`, `Arc`, `Rc`) to manage memory efficiently.\n*   **String Handling:** Be mindful of string handling. Use `String` when ownership is needed, and `&str` when a read-only view is sufficient.\n\n### 3.3. Rendering Optimization\n\n*   **Template Caching:** Cache templates to reduce the overhead of parsing and compiling templates on each request.\n*   **Minimize DOM Updates:** Minimize DOM updates in the client-side JavaScript code to improve rendering performance.\n*   **Efficient Serialization:** Ensure your data serialization is efficient, using appropriate data structures and serialization libraries (e.g., `serde_json`).\n\n### 3.4. Bundle Size Optimization\n\n*   **Dependency Pruning:** Remove unused dependencies from your `Cargo.toml` file to reduce the bundle size.\n*   **Feature Flags:** Use feature flags to enable or disable optional features at compile time.\n*   **Code Minification:** Use code minification to reduce the size of your JavaScript and CSS files.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Lazy Initialization:** Use lazy initialization for expensive resources to defer their creation until they are actually needed.\n*   **On-Demand Loading:** Load resources on demand (e.g., images, data) to reduce the initial load time.\n\n## 4. Security Best Practices\n\nSecurity is paramount for building robust and reliable actix-web applications.\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:** Use parameterized queries or ORMs to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input and escape output to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection to prevent unauthorized requests from other websites.\n*   **Authentication and Authorization:** Use strong authentication and authorization mechanisms to protect sensitive resources.\n*   **Denial-of-Service (DoS):** Implement rate limiting and other defense mechanisms to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n*   **Validate All Input:** Validate all user input to ensure that it conforms to the expected format and range.\n*   **Use Type Safety:** Use type safety to prevent invalid data from being processed.\n*   **Regular Expressions:** Use regular expressions to validate complex input patterns.\n*   **Whitelist vs. Blacklist:** Prefer whitelisting valid input over blacklisting invalid input.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **JWT (JSON Web Tokens):** Use JWT for stateless authentication and authorization.\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n*   **RBAC (Role-Based Access Control):** Use RBAC to restrict access to resources based on user roles.\n*   **ABAC (Attribute-Based Access Control):** Use ABAC to restrict access to resources based on user attributes.\n*   **Password Hashing:** Always hash passwords using a strong hashing algorithm (e.g., bcrypt, Argon2) and store them securely.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data to prevent unauthorized access.\n*   **Data Anonymization:** Anonymize data to protect user privacy.\n*   **Access Control:** Implement strict access control policies to restrict access to sensitive data.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n*   **TLS Certificates:** Use valid TLS certificates from a trusted certificate authority.\n*   **API Keys:** Use API keys to authenticate API clients.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse and DoS attacks.\n\n## 5. Testing Approaches\n\nThorough testing is essential for ensuring the quality and reliability of actix-web applications.\n\n### 5.1. Unit Testing Strategies\n\n*   **Test Individual Modules:** Unit test individual modules and functions in isolation.\n*   **Mock Dependencies:** Use mocking to isolate units from external dependencies (e.g., database, API).\n*   **Test Edge Cases:** Test edge cases and boundary conditions to ensure that the code handles them correctly.\n*   **Table-Driven Tests:** Use table-driven tests to test multiple scenarios with different inputs and expected outputs.\n\n### 5.2. Integration Testing\n\n*   **Test API Endpoints:** Integration test API endpoints to ensure that they function correctly together.\n*   **Test Database Interactions:** Test database interactions to ensure that data is read and written correctly.\n*   **Test Middleware:** Test middleware to ensure that they correctly process requests and responses.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate User Interactions:** End-to-end tests simulate user interactions to test the entire application flow.\n*   **Use a Testing Framework:** Use a testing framework (e.g., Selenium, Cypress) to automate end-to-end tests.\n\n### 5.4. Test Organization\n\n*   **Test Directory:** Keep tests in a separate `tests` directory.\n*   **Test Modules:** Organize tests into modules that mirror the application structure.\n*   **Test Naming:** Use descriptive names for test functions to indicate what they are testing.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock External Dependencies:** Mock external dependencies (e.g., database, API) to isolate units from external factors.\n*   **Use Mocking Libraries:** Use mocking libraries (e.g., `mockall`) to create mock objects and define their behavior.\n*   **Stub Data:** Use stub data to simulate different scenarios and test edge cases.\n\n## 6. Common Pitfalls and Gotchas\n\nBe aware of common pitfalls and gotchas when developing actix-web applications.\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   **Blocking Operations:** Performing blocking operations in handler functions can block the event loop and degrade performance.\n*   **Incorrect Error Handling:** Ignoring errors or not handling them correctly can lead to unexpected behavior and security vulnerabilities.\n*   **Not Validating Input:** Not validating user input can lead to security vulnerabilities and data corruption.\n*   **Overusing Global State:** Overusing global state can make the application difficult to reason about and test.\n*   **Not Using Asynchronous Operations:** Not using asynchronous operations for I/O-bound tasks can degrade performance.\n\n### 6.2. Edge Cases to be Aware Of\n\n*   **Handling Large Requests:** Be mindful of handling large requests and implement appropriate size limits to prevent DoS attacks.\n*   **Handling Concurrent Requests:** Ensure that the application can handle concurrent requests efficiently and without race conditions.\n*   **Handling Network Errors:** Handle network errors gracefully and provide informative error messages to the client.\n*   **Handling Database Connection Errors:** Handle database connection errors gracefully and implement retry mechanisms.\n\n### 6.3. Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes in actix-web and its dependencies.\n*   **Deprecated Features:** Avoid using deprecated features and migrate to the recommended alternatives.\n*   **Compatibility:** Ensure that the application is compatible with the target Rust version and operating system.\n\n### 6.4. Compatibility Concerns\n\n*   **Rust Version:** Ensure compatibility with the supported Rust versions.\n*   **Operating System:** Test on different operating systems (Linux, macOS, Windows).\n*   **Browser Compatibility (if applicable):** If the application includes a front-end, test with various browsers.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Use logging to track the application's execution flow and identify potential issues.\n*   **Debugging Tools:** Use debugging tools (e.g., `gdb`, `lldb`) to inspect the application's state and step through the code.\n*   **Unit Tests:** Write unit tests to isolate and debug individual modules and functions.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\nUsing the right tools and environment can significantly improve the development experience and productivity.\n\n### 7.1. Recommended Development Tools\n\n*   **Rust IDE:** Use a Rust IDE (e.g., Visual Studio Code with the Rust extension, IntelliJ Rust) for code completion, syntax highlighting, and debugging.\n*   **Cargo:** Use Cargo, the Rust package manager, for managing dependencies and building the application.\n*   **Rustup:** Use Rustup for managing Rust toolchains and versions.\n*   **Clippy:** Use Clippy, a Rust linter, for identifying potential code quality issues.\n*   **Formatter:** Use rustfmt to automatically format the code according to the Rust style guide.\n\n### 7.2. Build Configuration\n\n*   **Release Mode:** Build the application in release mode for optimized performance.\n*   **Link-Time Optimization (LTO):** Enable link-time optimization to improve performance.\n*   **Codegen Units:** Experiment with different codegen unit settings to optimize compilation time and code size.\n\n### 7.3. Linting and Formatting\n\n*   **Clippy:** Use Clippy to identify potential code quality issues and enforce coding standards.\n*   **Rustfmt:** Use rustfmt to automatically format the code according to the Rust style guide.\n*   **Pre-commit Hooks:** Use pre-commit hooks to automatically run Clippy and rustfmt before committing changes.\n\n### 7.4. Deployment Best Practices\n\n*   **Containerization:** Use containerization (e.g., Docker) to package the application and its dependencies into a portable container.\n*   **Orchestration:** Use container orchestration (e.g., Kubernetes) to manage and scale the application.\n*   **Reverse Proxy:** Use a reverse proxy (e.g., Nginx, Apache) to handle incoming requests and route them to the application.\n*   **Load Balancing:** Use load balancing to distribute traffic across multiple instances of the application.\n*   **Monitoring:** Implement monitoring to track the application's health and performance.\n\n### 7.5. CI/CD Integration\n\n*   **Continuous Integration (CI):** Use a CI system (e.g., GitHub Actions, GitLab CI, Jenkins) to automatically build, test, and lint the code on every commit.\n*   **Continuous Delivery (CD):** Use a CD system to automatically deploy the application to production after it passes all tests.\n*   **Automated Testing:** Automate unit, integration, and end-to-end tests in the CI/CD pipeline.\n\nBy following these best practices, you can build robust, efficient, and maintainable actix-web applications that meet the highest standards of quality and security. Remember to stay up-to-date with the latest recommendations and adapt them to your specific project needs.",
    "metadata": {
      "globs": "*.rs",
      "format": "mdc",
      "originalFile": "actix-web.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "actix",
      "web",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "robust",
      "efficient",
      "maintainable",
      "applications",
      "using",
      "actix-web",
      "rust",
      "systems",
      "performance",
      "cursor-rule",
      "mdc",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "actix-web",
        "rust",
        "systems",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-aiohttp",
    "description": "Comprehensive guide for aiohttp development covering code organization, performance, security, testing, and deployment best practices. Provides actionable guidance for developers to build robust and maintainable aiohttp applications.",
    "author": "sanjeed5",
    "tags": [
      "aiohttp",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aiohttp.mdc",
    "content": "# Aiohttp Best Practices\n\nThis document provides a comprehensive guide to aiohttp development, covering code organization, performance, security, testing, and deployment.\n\nLibrary Information:\n- Name: aiohttp\n- Tags: web, python, http-client, async\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices:\n\n*   **Project Root:**\n    *   `src/`: Contains the main application code.\n        *   `main.py`: Entry point of the application.\n        *   `app.py`: Application factory and setup.\n        *   `routes.py`: Defines application routes.\n        *   `handlers/`: Contains request handlers.\n            *   `user_handlers.py`: User-related handlers.\n            *   `product_handlers.py`: Product-related handlers.\n        *   `middlewares/`: Custom middleware components.\n            *   `logging_middleware.py`: Logging middleware.\n            *   `auth_middleware.py`: Authentication middleware.\n        *   `utils/`: Utility modules.\n            *   `db.py`: Database connection and utilities.\n            *   `config.py`: Configuration management.\n    *   `tests/`: Contains unit and integration tests.\n        *   `conftest.py`: Pytest configuration file.\n        *   `unit/`: Unit tests.\n        *   `integration/`: Integration tests.\n    *   `static/`: Static files (CSS, JavaScript, images).\n    *   `templates/`: Jinja2 or other template files.\n    *   `docs/`: Project documentation.\n    *   `requirements.txt`: Python dependencies.\n    *   `Dockerfile`: Docker configuration file.\n    *   `docker-compose.yml`: Docker Compose configuration.\n    *   `.env`: Environment variables.\n    *   `README.md`: Project description and instructions.\n    *   `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n    *   `.cursor/rules/`: Project specific Cursor AI rules.\n\n### 1.2. File Naming Conventions:\n\n*   Python files: `snake_case.py` (e.g., `user_handlers.py`, `database_utils.py`).\n*   Class names: `CamelCase` (e.g., `UserHandler`, `DatabaseConnection`).\n*   Function names: `snake_case` (e.g., `get_user`, `create_product`).\n*   Variables: `snake_case` (e.g., `user_id`, `product_name`).\n*   Constants: `UPPER_SNAKE_CASE` (e.g., `DEFAULT_PORT`, `MAX_CONNECTIONS`).\n\n### 1.3. Module Organization:\n\n*   Group related functionality into modules.\n*   Use clear and descriptive module names.\n*   Avoid circular dependencies.\n*   Keep modules focused and concise.\n*   Use packages to organize modules into a hierarchical structure.\n\n### 1.4. Component Architecture:\n\n*   **Layered Architecture:** Separate the application into distinct layers (e.g., presentation, business logic, data access).\n*   **Microservices Architecture:** Decompose the application into small, independent services.\n*   **Hexagonal Architecture (Ports and Adapters):** Decouple the application core from external dependencies.\n*   **MVC (Model-View-Controller):** Organize the application into models (data), views (presentation), and controllers (logic).\n\n### 1.5. Code Splitting Strategies:\n\n*   **Route-based splitting:** Load modules based on the requested route.\n*   **Feature-based splitting:** Divide the application into feature modules.\n*   **Component-based splitting:** Split the application into reusable components.\n*   **On-demand loading:** Load modules only when they are needed.\n*   **Asynchronous loading:** Use `asyncio.gather` or similar techniques to load modules concurrently.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns:\n\n*   **Singleton:** For managing shared resources like database connections or configuration objects.\n*   **Factory:** For creating instances of classes with complex initialization logic.\n*   **Strategy:** For implementing different algorithms or behaviors.\n*   **Observer:** For implementing event-driven systems.\n*   **Middleware:** For handling cross-cutting concerns like logging, authentication, and error handling.\n\n### 2.2. Recommended Approaches for Common Tasks:\n\n*   **Request Handling:** Use request handlers to process incoming requests.\n*   **Routing:** Use `aiohttp.web.RouteTableDef` for defining routes.\n*   **Middleware:** Implement middleware for request pre-processing and response post-processing.\n*   **Data Serialization:** Use `aiohttp.web.json_response` for serializing data to JSON.\n*   **Error Handling:** Implement custom error handlers to handle exceptions gracefully.\n*   **Session Management:** Use `aiohttp-session` for managing user sessions.\n*   **WebSockets:** Utilize `aiohttp.web.WebSocketResponse` for handling WebSocket connections.\n\n### 2.3. Anti-patterns and Code Smells:\n\n*   **Creating a new `ClientSession` for each request:** This is a performance bottleneck. Reuse a single `ClientSession`.\n*   **Blocking operations in asynchronous code:** Avoid using blocking operations (e.g., `time.sleep`) in asynchronous code.\n*   **Ignoring exceptions:** Always handle exceptions properly to prevent unexpected behavior.\n*   **Overusing global variables:** Avoid using global variables as much as possible to maintain code clarity and testability.\n*   **Tight coupling:** Decouple components to improve maintainability and reusability.\n*   **Hardcoding configuration:** Use environment variables or configuration files to manage configuration settings.\n\n### 2.4. State Management:\n\n*   **Application State:** Store application-level state in the `aiohttp.web.Application` instance.\n*   **Request State:** Store request-specific state in the `aiohttp.web.Request` instance.\n*   **Session State:** Use `aiohttp-session` to manage user session data.\n*   **Database:** Use a database like PostgreSQL, MySQL, or MongoDB to store persistent state.\n*   **Redis/Memcached:** Use in-memory data stores for caching frequently accessed data.\n\n### 2.5. Error Handling:\n\n*   **Use `try-except` blocks:** Wrap code that may raise exceptions in `try-except` blocks.\n*   **Handle specific exceptions:** Catch specific exception types instead of using a generic `except Exception`.\n*   **Log exceptions:** Log exceptions with detailed information for debugging.\n*   **Return informative error responses:** Return appropriate HTTP status codes and error messages to the client.\n*   **Implement custom error handlers:** Create custom error handlers to handle specific exception types.\n*   **Use `aiohttp.web.HTTPException`:** Raise `aiohttp.web.HTTPException` to return HTTP error responses.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques:\n\n*   **Reuse `ClientSession`:** Always reuse a single `ClientSession` instance for making multiple requests.\n*   **Connection Pooling:** aiohttp automatically uses connection pooling, so reuse your session.\n*   **Keep-Alive Connections:** Keep-alive connections are enabled by default, reducing connection overhead.\n*   **Gzip Compression:** Enable Gzip compression for responses to reduce bandwidth usage.\n*   **Caching:** Implement caching for frequently accessed data to reduce database load.\n*   **Optimize Database Queries:** Optimize database queries to improve response times.\n*   **Use Indexes:** Use indexes in your database tables to speed up queries.\n*   **Limit Payload Size:** Keep request and response payloads as small as possible.\n*   **Background Tasks:** Use `asyncio.create_task` to offload long-running tasks to the background.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks.\n\n### 3.2. Memory Management:\n\n*   **Avoid Memory Leaks:** Ensure that all resources are properly released to prevent memory leaks.\n*   **Use Generators:** Use generators to process large datasets in chunks.\n*   **Limit Object Creation:** Minimize the creation of objects to reduce memory overhead.\n*   **Use Data Structures Efficiently:** Choose appropriate data structures to optimize memory usage.\n*   **Garbage Collection:** Understand how Python's garbage collection works and optimize your code accordingly.\n\n### 3.3. Rendering Optimization:\n\n*   **Template Caching:** Cache templates to reduce rendering time.\n*   **Minimize Template Logic:** Keep template logic simple and move complex logic to request handlers.\n*   **Use Asynchronous Templates:** Use asynchronous template engines like `aiohttp-jinja2`.\n*   **Optimize Static Files:** Optimize static files (CSS, JavaScript, images) to reduce page load times.\n\n### 3.4. Bundle Size Optimization:\n\n*   **Minimize Dependencies:** Reduce the number of dependencies in your project.\n*   **Tree Shaking:** Use tree shaking to remove unused code from your bundles.\n*   **Code Minification:** Minify your code to reduce bundle sizes.\n*   **Code Compression:** Compress your code to further reduce bundle sizes.\n\n### 3.5. Lazy Loading:\n\n*   **Lazy Load Modules:** Load modules only when they are needed.\n*   **Lazy Load Images:** Load images only when they are visible in the viewport.\n*   **Use Asynchronous Loading:** Use `asyncio.gather` or similar techniques to load resources concurrently.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities:\n\n*   **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM.\n*   **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input in templates.\n*   **Cross-Site Request Forgery (CSRF):** Prevent CSRF by using CSRF tokens.\n*   **Authentication and Authorization Issues:** Implement secure authentication and authorization mechanisms.\n*   **Denial-of-Service (DoS) Attacks:** Implement rate limiting and other measures to prevent DoS attacks.\n*   **Insecure Dependencies:** Keep your dependencies up to date to prevent vulnerabilities.\n\n### 4.2. Input Validation:\n\n*   **Validate all user input:** Validate all user input to prevent malicious data from entering your application.\n*   **Use a validation library:** Use a validation library like `marshmallow` or `voluptuous` to simplify input validation.\n*   **Sanitize user input:** Sanitize user input to remove potentially harmful characters.\n*   **Limit input length:** Limit the length of input fields to prevent buffer overflows.\n*   **Use regular expressions:** Use regular expressions to validate input patterns.\n\n### 4.3. Authentication and Authorization:\n\n*   **Use a strong authentication scheme:** Use a strong authentication scheme like OAuth 2.0 or JWT.\n*   **Store passwords securely:** Store passwords securely using a hashing algorithm like bcrypt.\n*   **Implement role-based access control (RBAC):** Use RBAC to control access to resources based on user roles.\n*   **Use secure cookies:** Use secure cookies to protect session data.\n*   **Implement multi-factor authentication (MFA):** Use MFA to add an extra layer of security.\n\n### 4.4. Data Protection:\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **Store data securely:** Store data in a secure location with appropriate access controls.\n*   **Regularly back up data:** Regularly back up data to prevent data loss.\n*   **Comply with data privacy regulations:** Comply with data privacy regulations like GDPR and CCPA.\n\n### 4.5. Secure API Communication:\n\n*   **Use HTTPS:** Always use HTTPS for API communication.\n*   **Implement API authentication:** Use API keys or tokens to authenticate API requests.\n*   **Rate limit API requests:** Implement rate limiting to prevent abuse.\n*   **Validate API requests:** Validate API requests to prevent malicious data from entering your application.\n*   **Log API requests:** Log API requests for auditing and debugging.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing:\n\n*   **Test individual components:** Unit tests should test individual components in isolation.\n*   **Use a testing framework:** Use a testing framework like `pytest` or `unittest`.\n*   **Write clear and concise tests:** Write clear and concise tests that are easy to understand.\n*   **Test edge cases:** Test edge cases and boundary conditions.\n*   **Use mocks and stubs:** Use mocks and stubs to isolate components under test.\n\n### 5.2. Integration Testing:\n\n*   **Test interactions between components:** Integration tests should test interactions between different components.\n*   **Test with real dependencies:** Integration tests should use real dependencies whenever possible.\n*   **Test the entire application flow:** Integration tests should test the entire application flow.\n*   **Use a testing database:** Use a testing database to isolate integration tests from the production database.\n\n### 5.3. End-to-End Testing:\n\n*   **Test the entire system:** End-to-end tests should test the entire system from end to end.\n*   **Use a testing environment:** Use a testing environment that mimics the production environment.\n*   **Automate end-to-end tests:** Automate end-to-end tests to ensure that the system is working correctly.\n*   **Use a browser automation tool:** Use a browser automation tool like Selenium or Puppeteer.\n\n### 5.4. Test Organization:\n\n*   **Organize tests by module:** Organize tests by module to improve test discovery and maintainability.\n*   **Use descriptive test names:** Use descriptive test names that clearly indicate what the test is verifying.\n*   **Use test fixtures:** Use test fixtures to set up and tear down test environments.\n*   **Use test markers:** Use test markers to categorize tests and run specific test suites.\n\n### 5.5. Mocking and Stubbing:\n\n*   **Use mocks to simulate dependencies:** Use mocks to simulate the behavior of dependencies.\n*   **Use stubs to provide predefined responses:** Use stubs to provide predefined responses to API calls.\n*   **Use mocking libraries:** Use mocking libraries like `unittest.mock` or `pytest-mock`.\n*   **Avoid over-mocking:** Avoid over-mocking, as it can make tests less reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes:\n\n*   **Not handling exceptions properly:** Always handle exceptions to prevent unexpected behavior.\n*   **Using blocking operations in asynchronous code:** Avoid using blocking operations in asynchronous code.\n*   **Not closing `ClientSession`:** Always close the `ClientSession` to release resources.\n*   **Not validating user input:** Always validate user input to prevent security vulnerabilities.\n*   **Not using HTTPS:** Always use HTTPS for secure communication.\n\n### 6.2. Edge Cases:\n\n*   **Handling timeouts:** Implement proper timeout handling to prevent requests from hanging indefinitely.\n*   **Handling connection errors:** Handle connection errors gracefully to prevent application crashes.\n*   **Handling large payloads:** Handle large payloads efficiently to prevent memory issues.\n*   **Handling concurrent requests:** Handle concurrent requests properly to prevent race conditions.\n*   **Handling Unicode encoding:** Be aware of Unicode encoding issues when processing text data.\n\n### 6.3. Version-Specific Issues:\n\n*   **aiohttp version compatibility:** Be aware of compatibility issues between different aiohttp versions.\n*   **asyncio version compatibility:** Be aware of compatibility issues between aiohttp and different asyncio versions.\n*   **Python version compatibility:** Be aware of compatibility issues between aiohttp and different Python versions.\n\n### 6.4. Compatibility Concerns:\n\n*   **Compatibility with other libraries:** Be aware of compatibility issues between aiohttp and other libraries.\n*   **Compatibility with different operating systems:** Be aware of compatibility issues between aiohttp and different operating systems.\n*   **Compatibility with different web servers:** Be aware of compatibility issues between aiohttp and different web servers.\n\n### 6.5. Debugging Strategies:\n\n*   **Use logging:** Use logging to track application behavior and identify issues.\n*   **Use a debugger:** Use a debugger to step through code and examine variables.\n*   **Use a profiler:** Use a profiler to identify performance bottlenecks.\n*   **Use error reporting tools:** Use error reporting tools to track and fix errors in production.\n*   **Use a network analyzer:** Use a network analyzer like Wireshark to capture and analyze network traffic.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools:\n\n*   **IDE:** Use an IDE like VS Code, PyCharm, or Sublime Text.\n*   **Virtual Environment:** Use a virtual environment to isolate project dependencies.\n*   **Package Manager:** Use a package manager like pip or poetry to manage dependencies.\n*   **Testing Framework:** Use a testing framework like pytest or unittest.\n*   **Linting Tool:** Use a linting tool like pylint or flake8 to enforce code style.\n*   **Formatting Tool:** Use a formatting tool like black or autopep8 to format code automatically.\n\n### 7.2. Build Configuration:\n\n*   **Use a build system:** Use a build system like Make or tox to automate build tasks.\n*   **Define dependencies in `requirements.txt` or `pyproject.toml`:** Specify all project dependencies in a `requirements.txt` or `pyproject.toml` file.\n*   **Use a Dockerfile:** Use a Dockerfile to create a containerized build environment.\n*   **Use Docker Compose:** Use Docker Compose to manage multi-container applications.\n\n### 7.3. Linting and Formatting:\n\n*   **Use a consistent code style:** Use a consistent code style throughout the project.\n*   **Configure linting tools:** Configure linting tools to enforce code style rules.\n*   **Configure formatting tools:** Configure formatting tools to format code automatically.\n*   **Use pre-commit hooks:** Use pre-commit hooks to run linters and formatters before committing code.\n\n### 7.4. Deployment:\n\n*   **Use a web server:** Use a web server like Nginx or Apache to serve the application.\n*   **Use a process manager:** Use a process manager like Supervisor or systemd to manage the application process.\n*   **Use a reverse proxy:** Use a reverse proxy to improve security and performance.\n*   **Use a load balancer:** Use a load balancer to distribute traffic across multiple servers.\n*   **Use a monitoring system:** Use a monitoring system to track application health and performance.\n*   **Standalone Server:** aiohttp.web.run_app(), simple but doesn't utilize all CPU cores.\n*   **Nginx + Supervisord:** Nginx prevents attacks, allows utilizing all CPU cores, and serves static files faster.\n*   **Nginx + Gunicorn:** Gunicorn launches the app as worker processes, simplifying deployment compared to bare Nginx.\n\n### 7.5. CI/CD Integration:\n\n*   **Use a CI/CD pipeline:** Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Use a CI/CD tool:** Use a CI/CD tool like Jenkins, GitLab CI, or GitHub Actions.\n*   **Run tests in the CI/CD pipeline:** Run tests in the CI/CD pipeline to ensure that code changes don't break the application.\n*   **Automate deployment:** Automate deployment to reduce manual effort and improve consistency.\n\n## Additional Best Practices:\n\n*   **Session Management:** Always create a `ClientSession` for making requests and reuse it across multiple requests to benefit from connection pooling. Avoid creating a new session for each request, as this can lead to performance issues.\n*   **Error Handling:** Implement robust error handling in your request handlers. Use try-except blocks to manage exceptions, particularly for network-related errors. For example, handle `ConnectionResetError` to manage client disconnections gracefully.\n*   **Middleware Usage:** Utilize middleware for cross-cutting concerns such as logging, error handling, and modifying requests/responses. Define middleware functions that accept a request and a handler, allowing you to process requests before they reach your main handler.\n*   **Graceful Shutdown:** Implement graceful shutdown procedures for your server to ensure that ongoing requests are completed before the application exits. This can be achieved by registering shutdown signals and cleaning up resources.\n*   **Security Practices:** When deploying, consider using a reverse proxy like Nginx for added security and performance. Configure SSL/TLS correctly to secure your application.\n*   **Character Set Detection:**  If a response does not include the charset needed to decode the body, use `ClientSession` accepts a `fallback_charset_resolver` parameter which can be used to introduce charset guessing functionality.\n*   **Persistent Session:** Use `Cleanup Context` when creating a persistent session.\n\nBy adhering to these practices, developers can enhance the reliability, performance, and security of their `aiohttp` applications.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "aiohttp.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "aiohttp",
      "comprehensive",
      "guide",
      "development",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "testing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aiohttp",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-amazon-ec2",
    "description": "This rule file provides best practices, coding standards, and security guidelines for developing, deploying, and maintaining applications using the amazon-ec2 library within the AWS ecosystem. It focuses on infrastructure as code (IaC), resource management, performance, and security considerations for robust and scalable EC2-based solutions.",
    "author": "sanjeed5",
    "tags": [
      "amazon-ec2",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/amazon-ec2.mdc",
    "content": "- ## General Principles\n  - **Infrastructure as Code (IaC):** Treat your infrastructure as code. Define and provision AWS resources (EC2 instances, security groups, networks) using code (e.g., AWS CloudFormation, AWS CDK, Terraform). This ensures consistency, repeatability, and version control.\n  - **Security First:** Integrate security best practices into every stage of development, from IaC template creation to instance configuration. Implement the principle of least privilege, regularly patch instances, and utilize security assessment tools.\n  - **Modularity and Reusability:** Design your infrastructure and application code in modular components that can be reused across multiple projects or environments.\n  - **Automation:** Automate as much of the infrastructure provisioning, deployment, and management processes as possible. Use CI/CD pipelines for automated testing and deployment.\n  - **Monitoring and Logging:** Implement comprehensive monitoring and logging to track the health, performance, and security of your EC2 instances and applications.\n\n- ## 1. Code Organization and Structure\n\n  - **Directory Structure Best Practices:**\n    - Adopt a logical directory structure that reflects the architecture of your application and infrastructure.\n    - Example:\n      \n      project-root/\n      ├── modules/                  # Reusable infrastructure modules (e.g., VPC, security groups)\n      │   ├── vpc/                # VPC module\n      │   │   ├── main.tf          # Terraform configuration for the VPC\n      │   │   ├── variables.tf     # Input variables for the VPC module\n      │   │   ├── outputs.tf       # Output values for the VPC module\n      │   ├── security_group/    # Security Group module\n      │   │   ├── ...\n      ├── environments/            # Environment-specific configurations\n      │   ├── dev/               # Development environment\n      │   │   ├── main.tf          # Terraform configuration for the Dev environment\n      │   │   ├── variables.tf     # Environment specific variables\n      │   ├── prod/              # Production environment\n      │   │   ├── ...\n      ├── scripts/                 # Utility scripts (e.g., deployment scripts, automation scripts)\n      │   ├── deploy.sh          # Deployment script\n      │   ├── update_ami.py      # Python script to update AMI\n      ├── application/            # Application code\n      │   ├── src/                # Source code\n      │   ├── tests/              # Unit and integration tests\n      ├── README.md\n      └── ...\n      \n  - **File Naming Conventions:**\n    - Use consistent and descriptive file names.\n    - Examples:\n      - `main.tf`: Main Terraform configuration file\n      - `variables.tf`: Terraform variables file\n      - `outputs.tf`: Terraform output values file\n      - `deploy.sh`: Deployment script\n      - `instance.py`: Python module for instance management\n  - **Module Organization:**\n    - Encapsulate reusable infrastructure components into modules (e.g., VPC, security groups, load balancers).\n    - Each module should have:\n      - A clear purpose.\n      - Well-defined input variables and output values.\n      - Comprehensive documentation.\n    - Keep modules small and focused.\n  - **Component Architecture:**\n    - Design your application as a collection of loosely coupled components.\n    - Each component should have:\n      - A well-defined interface.\n      - Clear responsibilities.\n      - Independent deployment lifecycle.\n  - **Code Splitting:**\n    - Break down large application codebases into smaller, manageable modules.\n    - Use lazy loading to load modules on demand, reducing initial load time.\n    - Example (Python):\n      python\n      # main.py\n      import importlib\n\n      def load_module(module_name):\n          module = importlib.import_module(module_name)\n          return module\n\n      # Load the module when needed\n      my_module = load_module('my_module')\n      my_module.my_function()\n      \n\n- ## 2. Common Patterns and Anti-patterns\n\n  - **Design Patterns:**\n    - **Singleton:** Use when exactly one instance of a class is needed (e.g., a configuration manager).\n    - **Factory:** Use to create objects without specifying their concrete classes (e.g., creating different types of EC2 instances).\n    - **Strategy:** Use to define a family of algorithms, encapsulate each one, and make them interchangeable (e.g., different instance termination strategies).\n  - **Common Tasks:**\n    - **Creating an EC2 Instance (AWS CLI):**\n      bash\n      aws ec2 run-instances --image-id ami-xxxxxxxxxxxxxxxxx --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-xxxxxxxxxxxxxxxxx\n      \n    - **Creating an EC2 Instance (AWS CDK):\n      typescript\n      import * as ec2 from 'aws-cdk-lib/aws-ec2';\n\n      const vpc = new ec2.Vpc(this, 'TheVPC', { maxAzs: 3 });\n\n      const instance = new ec2.Instance(this, 'EC2Instance', {\n        vpc: vpc,\n        instanceType: ec2.InstanceType.of(ec2.InstanceClass.T2, ec2.InstanceSize.MICRO),\n        machineImage: new ec2.AmazonLinux2023Image({generation: ec2.AmazonLinuxGeneration.AMAZON_LINUX_2}),\n      });\n      \n    - **Attaching an EBS Volume:**\n      - Ensure the EBS volume is in the same Availability Zone as the EC2 instance.\n      - Use the `aws ec2 attach-volume` command or the equivalent SDK call.\n  - **Anti-patterns:**\n    - **Hardcoding AWS Credentials:** Never hardcode AWS credentials in your code. Use IAM roles for EC2 instances and IAM users with restricted permissions for local development.\n    - **Creating Publicly Accessible S3 Buckets:** Avoid creating S3 buckets that are publicly accessible without proper security controls.\n    - **Ignoring Error Handling:** Always handle exceptions and errors gracefully. Provide meaningful error messages and logging.\n    - **Over-Permissive Security Groups:** Implement the principle of least privilege. Grant only the minimum necessary permissions to your security groups.\n  - **State Management:**\n    - Use state files (e.g., Terraform state) to track the current state of your infrastructure.\n    - Store state files securely (e.g., in an S3 bucket with encryption and versioning).\n    - Use locking mechanisms to prevent concurrent modifications to the state file.\n  - **Error Handling:**\n    - Implement robust error handling to catch exceptions and prevent application crashes.\n    - Use try-except blocks to handle potential errors.\n    - Log error messages with sufficient detail for debugging.\n\n- ## 3. Performance Considerations\n\n  - **Optimization Techniques:**\n    - **Instance Type Selection:** Choose the appropriate EC2 instance type based on your application's requirements (CPU, memory, network).\n    - **EBS Optimization:** Use Provisioned IOPS (PIOPS) EBS volumes for high-performance applications.\n    - **Caching:** Implement caching mechanisms to reduce database load and improve response times (e.g., using Amazon ElastiCache).\n    - **Load Balancing:** Distribute traffic across multiple EC2 instances using an Elastic Load Balancer (ELB).\n    - **Auto Scaling:** Use Auto Scaling groups to automatically scale your EC2 instances based on demand.\n  - **Memory Management:**\n    - Monitor memory usage on your EC2 instances.\n    - Optimize application code to reduce memory consumption.\n    - Use memory profiling tools to identify memory leaks.\n  - **Bundle Size Optimization:**\n    - Minimize the size of your application's deployment package.\n    - Remove unnecessary dependencies.\n    - Use code minification and compression.\n    - Example (Python):\n      bash\n      # Create a virtual environment\n      python3 -m venv .venv\n      source .venv/bin/activate\n\n      # Install only necessary dependencies\n      pip install --no-cache-dir -r requirements.txt\n\n      # Create deployment package\n      zip -r deployment_package.zip *\n      \n  - **Lazy Loading:**\n    - Load application modules on demand to reduce initial load time.\n    - Use code splitting to break down large modules into smaller chunks.\n    - Example (JavaScript):\n      javascript\n      // main.js\n      async function loadModule() {\n        const module = await import('./my_module.js');\n        module.myFunction();\n      }\n\n      loadModule();\n      \n\n- ## 4. Security Best Practices\n\n  - **Common Vulnerabilities:**\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries and input validation.\n    - **Cross-Site Scripting (XSS):** Prevent XSS by sanitizing user input and encoding output.\n    - **Remote Code Execution (RCE):** Prevent RCE by validating user input and using secure coding practices.\n    - **Unsecured API endpoints:** Secure API endpoints using authentication and authorization mechanisms.\n  - **Input Validation:**\n    - Validate all user input to prevent malicious code from being injected into your application.\n    - Use regular expressions and data type validation.\n  - **Authentication and Authorization:**\n    - Use strong authentication mechanisms (e.g., multi-factor authentication).\n    - Implement role-based access control (RBAC) to restrict access to sensitive resources.\n    - Use AWS IAM roles for EC2 instances to grant access to AWS resources.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all API communication.\n    - Store sensitive data in secure storage (e.g., AWS Secrets Manager).\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Validate API requests and responses.\n    - Implement rate limiting to prevent abuse.\n    - Use AWS API Gateway to manage and secure your APIs.\n\n- ## 5. Testing Approaches\n\n  - **Unit Testing:**\n    - Write unit tests for individual components to verify their functionality.\n    - Use mocking and stubbing to isolate components from external dependencies.\n    - Example (Python):\n      python\n      import unittest\n      from unittest.mock import Mock\n\n      class MyComponent:\n          def __init__(self, external_dependency):\n              self.dependency = external_dependency\n\n          def my_function(self, input_data):\n              result = self.dependency.process_data(input_data)\n              return result\n\n      class TestMyComponent(unittest.TestCase):\n          def test_my_function(self):\n              # Create a mock for the external dependency\n              mock_dependency = Mock()\n              mock_dependency.process_data.return_value = \"Mocked Result\"\n\n              # Create an instance of MyComponent with the mock dependency\n              component = MyComponent(mock_dependency)\n\n              # Call the function to be tested\n              result = component.my_function(\"Test Input\")\n\n              # Assert the expected behavior\n              self.assertEqual(result, \"Mocked Result\")\n              mock_dependency.process_data.assert_called_once_with(\"Test Input\")\n\n      if __name__ == '__main__':\n          unittest.main()\n      \n  - **Integration Testing:**\n    - Write integration tests to verify the interaction between components.\n    - Test the integration of your application with AWS services.\n  - **End-to-End Testing:**\n    - Write end-to-end tests to verify the entire application flow.\n    - Simulate real user scenarios.\n  - **Test Organization:**\n    - Organize your tests into a logical directory structure.\n    - Use meaningful test names.\n    - Keep tests independent of each other.\n  - **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components from external dependencies.\n    - Example (AWS CDK):\n      typescript\n      // Mocking AWS SDK calls in Jest\n      jest.mock('aws-sdk', () => {\n        const mEC2 = {\n          describeInstances: jest.fn().mockReturnValue({\n            promise: jest.fn().mockResolvedValue({ Reservations: [] }),\n          }),\n        };\n        return {\n          EC2: jest.fn().mockImplementation(() => mEC2),\n        };\n      });\n      \n\n- ## 6. Common Pitfalls and Gotchas\n\n  - **Frequent Mistakes:**\n    - **Incorrect Security Group Configuration:** Incorrectly configured security groups can expose your EC2 instances to security risks.\n    - **Insufficient Resource Limits:** Exceeding AWS resource limits can cause application failures.\n    - **Not Using Auto Scaling:** Not using Auto Scaling can lead to performance bottlenecks and outages during periods of high demand.\n    - **Forgetting to Terminate Unused Instances:** Forgetting to terminate unused EC2 instances can lead to unnecessary costs.\n  - **Edge Cases:**\n    - **Spot Instance Interruptions:** Spot instances can be interrupted with short notice. Design your application to handle spot instance interruptions gracefully.\n    - **Network Connectivity Issues:** Network connectivity issues can prevent your application from accessing AWS services or other resources.\n  - **Version-Specific Issues:**\n    - Be aware of version-specific issues with the amazon-ec2 library or AWS services.\n    - Consult the documentation for the specific versions you are using.\n  - **Compatibility Concerns:**\n    - Ensure compatibility between your application and the underlying operating system and libraries.\n    - Test your application on different operating systems and browsers.\n  - **Debugging Strategies:**\n    - Use logging and monitoring to track the behavior of your application.\n    - Use debugging tools to identify and fix errors.\n    - Consult the AWS documentation and community forums for help.\n\n- ## 7. Tooling and Environment\n\n  - **Recommended Tools:**\n    - **AWS CLI:** Command-line interface for interacting with AWS services.\n    - **AWS Management Console:** Web-based interface for managing AWS resources.\n    - **AWS CloudFormation:** Infrastructure as code service for provisioning and managing AWS resources.\n    - **AWS CDK:** Cloud Development Kit for defining cloud infrastructure in code.\n    - **Terraform:** Infrastructure as code tool for provisioning and managing cloud resources.\n    - **Packer:** Tool for creating machine images.\n    - **Ansible:** Configuration management tool.\n  - **Build Configuration:**\n    - Use a build tool (e.g., Make, Gradle, Maven) to automate the build process.\n    - Define dependencies and build steps in a build file.\n    - Example (Python):\n      makefile\n      # Makefile\n      venv: \n      \tpython3 -m venv .venv\n      \t. .venv/bin/activate\n      \tpip install -r requirements.txt\n\n      deploy:\n      \tzip -r deployment_package.zip *\n      \taws s3 cp deployment_package.zip s3://my-bucket/deployment_package.zip\n      \taws lambda update-function-code --function-name my-function --s3-bucket my-bucket --s3-key deployment_package.zip\n      \n  - **Linting and Formatting:**\n    - Use a linter (e.g., pylint, eslint) to enforce code style and identify potential errors.\n    - Use a formatter (e.g., black, prettier) to automatically format your code.\n  - **Deployment Best Practices:**\n    - Use a deployment pipeline to automate the deployment process.\n    - Deploy to a staging environment before deploying to production.\n    - Use blue/green deployments to minimize downtime.\n  - **CI/CD Integration:**\n    - Integrate your application with a CI/CD system (e.g., Jenkins, CircleCI, GitLab CI).\n    - Automate testing, building, and deployment.\n\n- ## Additional Considerations\n\n  - **Cost Optimization:** Regularly review your AWS resource usage and identify opportunities for cost savings. Consider using Reserved Instances or Spot Instances to reduce costs.\n  - **Disaster Recovery:** Implement a disaster recovery plan to ensure business continuity in the event of an outage. Use AWS Backup or other backup solutions to protect your data.\n  - **Compliance:** Ensure that your application complies with relevant regulations and standards (e.g., PCI DSS, HIPAA).\n\n- ## References\n\n  - [AWS EC2 Best Practices](mdc:https:/docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-best-practices.html)\n  - [AWS CDK Best Practices](mdc:https:/docs.aws.amazon.com/cdk/v2/guide/best-practices.html)\n  - [Terraform AWS Provider Best Practices](mdc:https:/docs.aws.amazon.com/prescriptive-guidance/latest/terraform-aws-provider-best-practices/structure.html)",
    "metadata": {
      "globs": "*.tf,*.json,*.yml,*.yaml,*.py,*.js,*.ts,*.sh,*.java,*.go,*.rb,*.m",
      "format": "mdc",
      "originalFile": "amazon-ec2.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "amazon",
      "ec2",
      "this",
      "rule",
      "file",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "security",
      "guidelines",
      "amazon-ec2",
      "aws",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "amazon-ec2",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-amazon-s3",
    "description": "This rule file provides comprehensive best practices, coding standards, and security guidelines for developing applications using Amazon S3. It aims to ensure secure, performant, and maintainable S3 integrations.",
    "author": "sanjeed5",
    "tags": [
      "amazon-s3",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/amazon-s3.mdc",
    "content": "- Always disable public access to S3 buckets unless explicitly needed. Use AWS Identity and Access Management (IAM) policies and bucket policies for access control instead of Access Control Lists (ACLs), which are now generally deprecated.\n- Implement encryption for data at rest using Server-Side Encryption (SSE), preferably with AWS Key Management Service (KMS) for enhanced security.\n- Use S3 Transfer Acceleration for faster uploads over long distances and enable versioning to protect against accidental deletions. Monitor performance using Amazon CloudWatch and enable logging for auditing. Additionally, consider using S3 Storage Lens for insights into storage usage and activity trends.\n- Leverage S3's lifecycle policies to transition objects to cheaper storage classes based on access patterns, and regularly review your storage usage to optimize costs. Utilize S3 Intelligent-Tiering for automatic cost savings based on changing access patterns.\n\n## Amazon S3 Best Practices and Coding Standards\n\nThis document provides comprehensive best practices, coding standards, and security guidelines for developing applications using Amazon S3.  Following these guidelines will help ensure that your S3 integrations are secure, performant, maintainable, and cost-effective.\n\n### 1. Code Organization and Structure\n\n#### 1.1. Directory Structure Best Practices\n\nOrganize your code related to Amazon S3 into logical directories based on functionality.\n\n\nproject/\n├── src/\n│   ├── s3/\n│   │   ├── utils.js          # Utility functions for S3 operations\n│   │   ├── uploader.js        # Handles uploading files to S3\n│   │   ├── downloader.js      # Handles downloading files from S3\n│   │   ├── config.js          # Configuration for S3 (bucket name, region, etc.)\n│   │   ├── errors.js          # Custom error handling for S3 operations\n│   │   └── index.js           # Entry point for S3 module\n│   ├── ...\n│   └── tests/\n│       ├── s3/\n│       │   ├── uploader.test.js # Unit tests for uploader.js\n│       │   └── ...\n│       └── ...\n├── ...\n\n\n#### 1.2. File Naming Conventions\n\nUse descriptive and consistent file names.\n\n*   `uploader.js`: Module for uploading files to S3.\n*   `downloader.js`: Module for downloading files from S3.\n*   `s3_service.py`: (Python Example) Defines S3 related services.\n*   `S3Manager.java`: (Java Example) Manages S3 client and configurations.\n\n#### 1.3. Module Organization\n\n*   **Single Responsibility Principle:** Each module should have a clear and specific purpose (e.g., uploading, downloading, managing bucket lifecycle).\n*   **Abstraction:** Hide complex S3 operations behind simpler interfaces.\n*   **Configuration:** Store S3 configuration details (bucket name, region, credentials) in a separate configuration file.\n\nExample (JavaScript):\njavascript\n// s3/uploader.js\nimport AWS from 'aws-sdk';\nimport config from './config';\n\nconst s3 = new AWS.S3(config.s3);\n\nexport const uploadFile = async (file, key) => {\n  const params = {\n    Bucket: config.s3.bucketName,\n    Key: key,\n    Body: file\n  };\n  try {\n    await s3.upload(params).promise();\n    console.log(`File uploaded successfully: ${key}`);\n  } catch (error) {\n    console.error('Error uploading file:', error);\n    throw error; // Re-throw for handling in the caller.\n  }\n};\n\n\n#### 1.4. Component Architecture\n\nFor larger applications, consider a component-based architecture. This can involve creating distinct components for different S3-related tasks. For example:\n\n*   **Upload Component:** Handles file uploads, progress tracking, and error handling.\n*   **Download Component:** Handles file downloads, progress tracking, and caching.\n*   **Management Component:** Manages bucket creation, deletion, and configuration.\n\n#### 1.5. Code Splitting\n\nIf you have a large application using S3, consider using code splitting to reduce the initial load time.  This involves breaking your code into smaller chunks that can be loaded on demand.  This is especially relevant for front-end applications using S3 for asset storage.\n\n*   **Dynamic Imports:** Use dynamic imports to load S3-related modules only when needed.\n*   **Webpack/Rollup:** Configure your bundler to create separate chunks for S3 code.\n\n### 2. Common Patterns and Anti-patterns\n\n#### 2.1. Design Patterns\n\n*   **Strategy Pattern:**  Use a strategy pattern to handle different storage classes or encryption methods.\n*   **Factory Pattern:**  Use a factory pattern to create S3 clients with different configurations.\n*   **Singleton Pattern:** Use a singleton pattern if you want to use one s3 instance for all the s3 interactions. \n\n#### 2.2. Recommended Approaches for Common Tasks\n\n*   **Uploading large files:** Use multipart upload for files larger than 5 MB.  This allows you to upload files in parallel and resume interrupted uploads.\n*   **Downloading large files:** Use byte-range fetches to download files in chunks. This is useful for resuming interrupted downloads and for accessing specific portions of a file.\n*   **Deleting multiple objects:** Use the `deleteObjects` API to delete multiple objects in a single request.  This is more efficient than deleting objects one by one.\n\n#### 2.3. Anti-patterns and Code Smells\n\n*   **Hardcoding credentials:** Never hardcode AWS credentials in your code.  Use IAM roles or environment variables.\n*   **Insufficient error handling:**  Always handle errors from S3 operations gracefully.  Provide informative error messages and retry failed operations.\n*   **Ignoring bucket access control:** Properly configure bucket policies and IAM roles to restrict access to your S3 buckets.\n*   **Overly permissive bucket policies:** Avoid granting overly broad permissions in your bucket policies. Follow the principle of least privilege.\n*   **Not using versioning:**  Failing to enable versioning can lead to data loss if objects are accidentally deleted or overwritten.\n*   **Assuming immediate consistency:** S3 provides eventual consistency for some operations.  Be aware of this and design your application accordingly.\n*   **Polling for object existence:** Instead of polling, use S3 events to trigger actions when objects are created or modified.\n*   **Inefficient data retrieval:**  Avoid retrieving entire objects when only a portion of the data is needed. Use byte-range fetches or S3 Select to retrieve only the necessary data.\n\n#### 2.4. State Management\n\n*   **Stateless operations:**  Design your S3 operations to be stateless whenever possible. This makes your application more scalable and resilient.\n*   **Caching:**  Use caching to reduce the number of requests to S3.  Consider using a CDN (Content Delivery Network) to cache frequently accessed objects.\n*   **Session management:** If you need to maintain state, store session data in a separate database or cache, not in S3.\n\n#### 2.5. Error Handling\n\n*   **Retry mechanism:** Implement retry logic with exponential backoff for transient errors.\n*   **Specific error handling:** Handle different S3 errors differently (e.g., retry 503 errors, log 403 errors).\n*   **Centralized error logging:** Log all S3 errors to a centralized logging system for monitoring and analysis.\n\nExample (Python):\npython\nimport boto3\nfrom botocore.exceptions import ClientError\nimport time\n\ns3 = boto3.client('s3')\n\ndef upload_file(file_name, bucket, object_name=None):\n    \"\"\"Upload a file to an S3 bucket\"\"\"\n    if object_name is None:\n        object_name = file_name\n\n    for attempt in range(3): # Retry up to 3 times\n        try:\n            response = s3.upload_file(file_name, bucket, object_name)\n            return True\n        except ClientError as e:\n            if e.response['Error']['Code'] == 'NoSuchBucket':\n                print(f\"The bucket {bucket} does not exist.\")\n                return False\n            elif e.response['Error']['Code'] == 'AccessDenied':\n                print(\"Access denied.  Check your credentials and permissions.\")\n                return False\n            else:\n                print(f\"An error occurred: {e}\")\n                if attempt < 2:  # Wait and retry\n                    time.sleep(2 ** attempt)\n                else:\n                    return False\n        except Exception as e:\n            print(f\"An unexpected error occurred: {e}\")\n            return False\n    return False # Reached max retries and failed\n\n\n### 3. Performance Considerations\n\n#### 3.1. Optimization Techniques\n\n*   **Use S3 Transfer Acceleration:** If you are uploading or downloading files from a geographically distant location, use S3 Transfer Acceleration to improve performance. S3 Transfer Acceleration utilizes Amazon CloudFront's globally distributed edge locations.\n*   **Use multipart upload:** For large files, use multipart upload to upload files in parallel. The documentation states the best practice is to use this for files larger than 5MB. \n*   **Enable gzip compression:**  Compress objects before uploading them to S3 to reduce storage costs and improve download times.  Set the `Content-Encoding` header to `gzip` when uploading compressed objects.\n*   **Use HTTP/2:** Enable HTTP/2 on your S3 bucket to improve performance.\n*   **Optimize object sizes:**  Store related data in a single object to reduce the number of requests to S3.\n\n#### 3.2. Memory Management\n\n*   **Stream data:**  Avoid loading entire files into memory. Use streams to process data in chunks.\n*   **Release resources:**  Release S3 client objects when they are no longer needed.\n\n#### 3.3. Bundle Size Optimization\n\n*   **Tree shaking:**  Use a bundler that supports tree shaking to remove unused code from your bundle.\n*   **Code splitting:**  Split your code into smaller chunks that can be loaded on demand.\n\n#### 3.4. Lazy Loading\n\n*   **Load images on demand:**  Load images from S3 only when they are visible on the screen.\n*   **Lazy load data:**  Load data from S3 only when it is needed.\n\n### 4. Security Best Practices\n\n#### 4.1. Common Vulnerabilities\n\n*   **Publicly accessible buckets:**  Ensure that your S3 buckets are not publicly accessible.\n*   **Insufficient access control:**  Properly configure bucket policies and IAM roles to restrict access to your S3 buckets.\n*   **Cross-site scripting (XSS):**  Sanitize user input to prevent XSS attacks if you are serving content directly from S3.\n*   **Data injection:** Validate all data before storing it in S3 to prevent data injection attacks.\n\n#### 4.2. Input Validation\n\n*   **Validate file types:**  Validate the file types of uploaded objects to prevent malicious files from being stored in S3.\n*   **Validate file sizes:**  Limit the file sizes of uploaded objects to prevent denial-of-service attacks.\n*   **Sanitize file names:**  Sanitize file names to prevent directory traversal attacks.\n\n#### 4.3. Authentication and Authorization\n\n*   **Use IAM roles:**  Use IAM roles to grant permissions to applications running on EC2 instances or other AWS services.\n*   **Use temporary credentials:**  Use temporary credentials for applications that need to access S3 from outside of AWS.  You can use AWS STS (Security Token Service) to generate temporary credentials.\n*   **Principle of least privilege:**  Grant only the minimum permissions required for each user or application.\n\n#### 4.4. Data Protection\n\n*   **Encrypt data at rest:**  Use server-side encryption (SSE) or client-side encryption to encrypt data at rest in S3.\n*   **Encrypt data in transit:**  Use HTTPS to encrypt data in transit between your application and S3.\n*   **Enable versioning:**  Enable versioning to protect against accidental data loss.\n*   **Enable MFA Delete:** Require multi-factor authentication to delete objects from S3.\n*   **Object locking:**  Use S3 Object Lock to prevent objects from being deleted or overwritten for a specified period of time.\n\n#### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Always use HTTPS to communicate with the S3 API.\n*   **Validate certificates:**  Validate the SSL/TLS certificates of the S3 endpoints.\n*   **Restrict access:** Restrict access to the S3 API using IAM policies and bucket policies.\n\n### 5. Testing Approaches\n\n#### 5.1. Unit Testing\n\n*   **Mock S3 client:**  Mock the S3 client to isolate your unit tests.\n*   **Test individual functions:**  Test individual functions that interact with S3.\n*   **Verify error handling:**  Verify that your code handles S3 errors correctly.\n\nExample (JavaScript with Jest):\njavascript\n// s3/uploader.test.js\nimport { uploadFile } from './uploader';\nimport AWS from 'aws-sdk';\n\njest.mock('aws-sdk', () => {\n  const mS3 = {\n    upload: jest.fn().mockReturnThis(),\n    promise: jest.fn(),\n  };\n  return {\n    S3: jest.fn(() => mS3),\n  };\n});\n\ndescribe('uploadFile', () => {\n  it('should upload file successfully', async () => {\n    const mockS3 = new AWS.S3();\n    mockS3.promise.mockResolvedValue({});\n    const file = 'test file content';\n    const key = 'test.txt';\n\n    await uploadFile(file, key);\n\n    expect(AWS.S3).toHaveBeenCalledTimes(1);\n    expect(mockS3.upload).toHaveBeenCalledWith({\n      Bucket: 'your-bucket-name',\n      Key: key,\n      Body: file\n    });\n  });\n\n  it('should handle upload error', async () => {\n    const mockS3 = new AWS.S3();\n    mockS3.promise.mockRejectedValue(new Error('Upload failed'));\n    const file = 'test file content';\n    const key = 'test.txt';\n\n    await expect(uploadFile(file, key)).rejects.toThrow('Upload failed');\n  });\n});\n\n\n#### 5.2. Integration Testing\n\n*   **Test with real S3 buckets:**  Create a dedicated S3 bucket for integration tests.\n*   **Test end-to-end flows:**  Test complete workflows that involve S3 operations.\n*   **Verify data integrity:**  Verify that data is correctly stored and retrieved from S3.\n\n#### 5.3. End-to-End Testing\n\n*   **Simulate user scenarios:**  Simulate real user scenarios to test your application's S3 integration.\n*   **Monitor performance:**  Monitor the performance of your S3 integration under load.\n\n#### 5.4. Test Organization\n\n*   **Separate test directories:**  Create separate test directories for unit tests, integration tests, and end-to-end tests.\n*   **Descriptive test names:**  Use descriptive test names that clearly indicate what is being tested.\n\n#### 5.5. Mocking and Stubbing\n\n*   **Mock S3 client:** Use a mocking library (e.g., Jest, Mockito) to mock the S3 client.\n*   **Stub S3 responses:** Stub S3 API responses to simulate different scenarios.\n*   **Use dependency injection:** Use dependency injection to inject mocked S3 clients into your components.\n\n### 6. Common Pitfalls and Gotchas\n\n#### 6.1. Frequent Mistakes\n\n*   **Forgetting to handle errors:** Failing to handle S3 errors can lead to unexpected behavior and data loss.\n*   **Using incorrect region:**  Using the wrong region can result in connection errors and data transfer costs.\n*   **Exposing sensitive data:**  Storing sensitive data in S3 without proper encryption can lead to security breaches.\n*   **Not cleaning up temporary files:**  Failing to delete temporary files after uploading them to S3 can lead to storage waste.\n*   **Overusing public read access:**  Granting public read access to S3 buckets can expose sensitive data to unauthorized users.\n\n#### 6.2. Edge Cases\n\n*   **Eventual consistency:**  S3 provides eventual consistency for some operations. Be aware of this and design your application accordingly.\n*   **Object size limits:**  Be aware of the object size limits for S3.\n*   **Request rate limits:**  Be aware of the request rate limits for S3.\n*   **Special characters in object keys:**  Handle special characters in object keys correctly.\n\n#### 6.3. Version-Specific Issues\n\n*   **SDK compatibility:**  Ensure that your AWS SDK is compatible with the S3 API version.\n*   **API changes:**  Be aware of any API changes that may affect your application.\n\n#### 6.4. Compatibility Concerns\n\n*   **Browser compatibility:**  Ensure that your application is compatible with different browsers if you are using S3 directly from the browser.\n*   **Serverless environments:**  Be aware of any limitations when using S3 in serverless environments (e.g., Lambda).\n\n#### 6.5. Debugging Strategies\n\n*   **Enable logging:**  Enable logging to track S3 API calls and errors.\n*   **Use S3 monitoring tools:** Use S3 monitoring tools to monitor the performance and health of your S3 buckets.\n*   **Check S3 access logs:** Analyze S3 access logs to identify potential security issues.\n*   **Use AWS CloudTrail:**  Use AWS CloudTrail to track API calls to S3.\n*   **Use AWS X-Ray:** Use AWS X-Ray to trace requests through your application and identify performance bottlenecks.\n\n### 7. Tooling and Environment\n\n#### 7.1. Recommended Development Tools\n\n*   **AWS CLI:**  The AWS Command Line Interface (CLI) is a powerful tool for managing S3 resources.\n*   **AWS SDK:**  The AWS SDK provides libraries for interacting with S3 from various programming languages.\n*   **S3 Browser:** S3 Browser is a Windows client for managing S3 buckets and objects.\n*   **Cyberduck:** Cyberduck is a cross-platform client for managing S3 buckets and objects.\n*   **Cloudberry Explorer:** Cloudberry Explorer is a Windows client for managing S3 buckets and objects.\n\n#### 7.2. Build Configuration\n\n*   **Use environment variables:**  Store S3 configuration details (bucket name, region, credentials) in environment variables.\n*   **Use a build tool:** Use a build tool (e.g., Maven, Gradle, Webpack) to manage your project dependencies and build your application.\n\n#### 7.3. Linting and Formatting\n\n*   **Use a linter:** Use a linter (e.g., ESLint, PyLint) to enforce code style and best practices.\n*   **Use a formatter:**  Use a code formatter (e.g., Prettier, Black) to automatically format your code.\n\n#### 7.4. Deployment\n\n*   **Use infrastructure as code:** Use infrastructure as code (e.g., CloudFormation, Terraform) to automate the deployment of your S3 resources.\n*   **Use a deployment pipeline:**  Use a deployment pipeline to automate the deployment of your application.\n*   **Use blue/green deployments:**  Use blue/green deployments to minimize downtime during deployments.\n\n#### 7.5. CI/CD Integration\n\n*   **Integrate with CI/CD tools:** Integrate your S3 deployment process with CI/CD tools (e.g., Jenkins, CircleCI, Travis CI).\n*   **Automate testing:** Automate your unit tests, integration tests, and end-to-end tests as part of your CI/CD pipeline.\n*   **Automate deployments:** Automate the deployment of your application to S3 as part of your CI/CD pipeline.\n\nBy following these best practices and coding standards, you can ensure that your Amazon S3 integrations are secure, performant, maintainable, and cost-effective.",
    "metadata": {
      "globs": "*S3*.js,*S3*.ts,*S3*.jsx,*S3*.tsx,*S3*.py,*S3*.java,*S3*.go,*S3*.csharp",
      "format": "mdc",
      "originalFile": "amazon-s3.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "amazon",
      "s3",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "security",
      "amazon-s3",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "amazon-s3",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-android-sdk",
    "description": "This rule file provides comprehensive best practices for Android SDK development, encompassing code organization, performance, security, testing, and common pitfalls. It aims to guide developers in creating robust, maintainable, and efficient Android applications and libraries.",
    "author": "sanjeed5",
    "tags": [
      "android-sdk",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/android-sdk.mdc",
    "content": "- MUST be under source control management (SCM). RECOMMENDED source control management is git\n- If you intend your source repo to be public ensure you have received the necessary management and legal approval\n- MUST use a .gitignore configuration tailored for Android projects (e.g., ignoring `local.properties`, `build/`, `.gradle/`)\n- Source code repositories SHOULD follow the naming convention `[platform]-[library name]`, e.g., `android-analytics`, `java-datastore`\n- MUST NOT restrict read access to source code repositories unnecessarily\n- RECOMMEND to not have source file header comment blocks as these easily get out of date\n\n## Code Organization and Structure\n\n- SHOULD follow the standard project layout for Android projects. Key directories:\n    - `src/main/java`: Java/Kotlin source code\n    - `src/main/res`: Resources (layouts, drawables, strings, etc.)\n    - `src/test/java`: Unit tests\n    - `src/androidTest/java`: Instrumentation tests\n- MUST prefix all exported resources (layout files, XML files, drawable IDs, color IDs, dimension IDs, string IDs, etc.) with a unique prefix for the library using `resourcePrefix` in the Gradle build file.  Example: `sug` for a Suggestion Module. This avoids naming conflicts when the library is used in other projects.\n- Use package names that are descriptive and follow the reverse domain name convention (e.g., `com.example.myapp.feature`).\n- Organize code into logical modules or features. Each module should have a clear responsibility and be loosely coupled with other modules.\n- Use Kotlin for new projects. If working with Java, target Java 8 or higher to utilize modern language features.\n- Consider using a multi-module project structure for larger projects to improve build times and code organization. Modules can represent different features, libraries, or build variants.\n- Employ a layered architecture (e.g., presentation, domain, data) to separate concerns and improve testability.\n\n### Directory Structure Best Practices:\n\n\nroot/\n├── app/\n│   ├── build.gradle\n│   └── src/\n│       ├── androidTest/\n│       │   └── java/\n│       ├── main/\n│       │   ├── AndroidManifest.xml\n│       │   ├── java/\n│       │   │   └── com/example/app/\n│       │   │       ├── MainActivity.kt\n│       │   │       ├── model/\n│       │   │       ├── view/\n│       │   │       └── viewmodel/\n│       │   └── res/\n│       │       ├── layout/\n│       │       ├── drawable/\n│       │       ├── values/\n│       │       └── mipmap-xxhdpi/\n│       └── test/\n│           └── java/\n├── library_module/\n│   ├── build.gradle\n│   └── src/\n│       ├── main/\n│       │   ├── java/\n│       │   └── res/\n│       └── test/\n├── build.gradle\n├── settings.gradle\n\n\n### File Naming Conventions:\n\n- **Kotlin/Java:** `PascalCase` for class names (e.g., `MainActivity`), `camelCase` for variables and method names (e.g., `userName`, `calculateTotal`).\n- **Layout XML:** `snake_case` (e.g., `activity_main.xml`). Use descriptive names reflecting the layout's purpose.\n- **Drawable XML:** `snake_case` (e.g., `ic_launcher.xml`). Prefix icons with `ic_`, backgrounds with `bg_`, and other drawables accordingly.\n- **Values XML:** `snake_case` (e.g., `strings.xml`, `colors.xml`, `dimens.xml`).\n- **Gradle:** `build.gradle` (module-level), `settings.gradle` (project-level).\n\n### Component Architecture Recommendations:\n\n- MVVM (Model-View-ViewModel) is the recommended architecture pattern. Use Android Architecture Components (LiveData, ViewModel, Room) to implement it effectively.\n- For complex UI logic, consider using a ViewBindingDelegate to simplify view access and reduce boilerplate.\n- Use dependency injection (Hilt or Dagger) to manage dependencies and improve testability.\n\n## Common Patterns and Anti-patterns\n\n- Use `LiveData` and `Flow` for reactive data streams.\n- Utilize coroutines for asynchronous operations to simplify threading and avoid callback hell.\n- Avoid performing long-running operations on the main thread (UI thread). Use `Dispatchers.IO` or `Dispatchers.Default` with coroutines or `AsyncTask` for background tasks.\n- Don't use `AsyncTask` if possible, prefer coroutines.\n- Prefer `ConstraintLayout` over other layout types for complex UIs as it is more flexible and performant.\n- Use `RecyclerView` for displaying large lists of data efficiently. Implement view holder pattern correctly for optimal performance.\n- Apply data binding to reduce boilerplate code in UI updates.\n- Use sealed classes for representing state to ensure exhaustive handling of all possible states.\n- Implement proper error handling with try-catch blocks and report errors gracefully to the user.\n- Log errors and exceptions using a logging framework (Timber) for debugging and analysis.\n\n### Anti-patterns and Code Smells to Avoid:\n\n- **God Classes:** Classes that are too large and have too many responsibilities. Break them down into smaller, more focused classes.\n- **Spaghetti Code:** Code that is difficult to read and understand due to complex control flow. Refactor it to improve readability and maintainability.\n- **Copy-Paste Programming:** Duplicating code across multiple locations. Extract the common code into reusable functions or classes.\n- **Hardcoding Values:** Avoid hardcoding values directly in the code. Use resources (strings, colors, dimensions) for better maintainability and localization.\n- **Leaking Context:** Holding onto `Activity` or `Context` instances for longer than necessary, leading to memory leaks.\n\n### State Management Best Practices:\n\n- Use `ViewModel` to store UI-related data that survives configuration changes.\n- Utilize `SavedStateHandle` in `ViewModel` to persist data across process death.\n- Consider using a state management library (e.g., Redux, MVI) for complex applications with complex state.\n- Implement appropriate caching strategies to reduce network requests and improve performance.\n\n### Error Handling Patterns:\n\n- Use try-catch blocks to handle potential exceptions and prevent app crashes.\n- Report errors gracefully to the user with informative error messages.\n- Log errors and exceptions using a logging framework (Timber) for debugging and analysis.\n- Implement retry mechanisms for transient errors (e.g., network connection issues).\n\n## Performance Considerations\n\n- Optimize image loading using libraries like Glide or Coil. Resize images to the required dimensions before loading them into `ImageViews`.\n- Use efficient data structures (e.g., `SparseArray` instead of `HashMap` for integer keys).\n- Avoid creating unnecessary objects, especially in loops or frequently called methods.\n- Use `StringBuilder` instead of string concatenation for building strings efficiently.\n- Minimize network requests and optimize data transfer using compression and pagination.\n- Analyze app performance using profiling tools (Android Profiler) to identify bottlenecks.\n- Utilize the LeakCanary library to detect memory leaks during development.\n- Use ProGuard or R8 to shrink, obfuscate, and optimize the code for release builds.\n\n### Memory Management Considerations:\n\n- Avoid creating memory leaks by properly managing object lifecycles and releasing resources when they are no longer needed.\n- Use `WeakReference` to hold references to objects that may be garbage collected to prevent memory leaks.\n- Monitor memory usage using the Android Profiler and identify potential memory leaks.\n\n### Rendering Optimization:\n\n- Minimize overdraw by reducing the number of layers that are drawn on top of each other.\n- Use hardware acceleration to improve rendering performance.\n- Optimize custom views by implementing `onDraw()` method efficiently and avoiding unnecessary allocations.\n\n### Bundle Size Optimization:\n\n- Remove unused resources using `shrinkResources` in the Gradle build file.\n- Use vector drawables instead of raster images for icons and other simple graphics.\n- Enable code shrinking and obfuscation using ProGuard or R8.\n- Compress images using tools like TinyPNG or ImageOptim.\n- Use app bundles to deliver optimized APKs for different device configurations.\n- Utilize dynamic feature modules to defer the download of non-essential features.\n\n### Lazy Loading Strategies:\n\n- Implement lazy loading for images and other resources that are not immediately visible on the screen.\n- Use pagination or infinite scrolling to load data in chunks as the user scrolls down the list.\n\n## Security Best Practices\n\n- MUST use Kotlin or Java. Kotlin is RECOMMENDED\n- SHOULD use static code analysis, such as detekt or SwiftLint to minimise errors and minimise debates and formatting fix-up commits in PRs. It is RECOMMENDED to integrate these tools with the CI workflow. SHOULD use quality tools available in common config: Android and iOS\n- Android: MUST use the Android Support Annotations for public APIs. Non-Android Java code MUST use the Jetbrains Annotations for public APIs\n- Secure API communication and proper permission handling are vital to protect user data.\n- MUST use a `consumerProguardFiles` file if obfuscation breaks the libraries function.\n- SHOULD NOT have unnecessary exported dependencies, in particular SHOULD NOT leak networking library to consumers. SHOULD NOT leak serialization library to consumers.  An exception to this rule are optional adapters for popular libraries.\n\n### Common Vulnerabilities and Prevention:\n\n- **SQL Injection:** Avoid using raw SQL queries. Use parameterized queries or an ORM like Room to prevent SQL injection attacks.\n- **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n- **Man-in-the-Middle (MITM) Attacks:** Use HTTPS for all network communication to encrypt data in transit and prevent MITM attacks.\n- **Insecure Data Storage:** Encrypt sensitive data before storing it on the device.\n- **Improper Platform Usage:** Ensure that permissions are properly requested and handled. Review and minimize the permissions your app requests.\n\n### Input Validation:\n\n- Validate all user input on both the client and server sides to prevent malicious data from being processed.\n- Use regular expressions or validation libraries to enforce input constraints.\n\n### Authentication and Authorization:\n\n- Use secure authentication protocols (e.g., OAuth 2.0, OpenID Connect) for user authentication.\n- Implement proper authorization mechanisms to control access to resources based on user roles.\n- Store user credentials securely using hashing and salting.\n\n### Data Protection:\n\n- Encrypt sensitive data at rest using AES or other strong encryption algorithms.\n- Securely transmit data over the network using HTTPS.\n- Implement data masking or anonymization techniques to protect user privacy.\n\n### Secure API Communication:\n\n- Use HTTPS for all API communication.\n- Verify the server's SSL certificate to prevent MITM attacks.\n- Implement API rate limiting to prevent denial-of-service attacks.\n\n## Testing Approaches\n\n- All library (sub-)projects MUST generate coverage test reports (e.g. jacoco, Xcode/slather).\n- Unit test coverage MUST be at least 80% and SHOULD be above 85%\n- Unit tests MUST NOT rely on reflection to expose otherwise private/internal classes or members.\n- Tests SHOULD use JUnit, and MAY use helper libraries such as Mockito or Robolectric\n\n### Unit Testing Strategies:\n\n- Write unit tests for all critical components, including `ViewModels`, repositories, and use cases.\n- Use mocking frameworks (Mockito) to isolate units under test and mock dependencies.\n- Follow the AAA (Arrange, Act, Assert) pattern for writing clear and concise unit tests.\n\n### Integration Testing Approaches:\n\n- Write integration tests to verify the interaction between different components, such as `ViewModels` and repositories.\n- Use dependency injection to provide mock dependencies for integration tests.\n\n### End-to-End Testing:\n\n- Use UI testing frameworks (Espresso, UI Automator) to write end-to-end tests that simulate user interactions.\n\n### Test Organization:\n\n- Organize tests into separate directories based on the type of tests (unit, integration, UI).\n- Use descriptive names for test classes and methods to clearly indicate what is being tested.\n\n### Mocking and Stubbing:\n\n- Use mocking frameworks (Mockito) to create mock objects for dependencies.\n- Use stubbing to define the behavior of mock objects for specific test cases.\n\n## Common Pitfalls and Gotchas\n\n- Frequent mistakes developers make when using android-sdk\n- Edge cases to be aware of when using android-sdk\n- Version-specific issues with android-sdk\n- Compatibility concerns between android-sdk and other technologies\n- Debugging strategies for android-sdk applications\n\n### Frequent Mistakes:\n\n- Not handling configuration changes properly, leading to data loss or unexpected behavior.\n- Performing long-running operations on the main thread, causing the UI to freeze.\n- Leaking `Context` objects, leading to memory leaks.\n- Not properly validating user input, leading to security vulnerabilities.\n- Not handling exceptions properly, leading to app crashes.\n- Overusing `AsyncTask` and not managing thread pools correctly.\n\n### Edge Cases:\n\n- Handling network connectivity issues gracefully.\n- Managing different screen sizes and densities.\n- Dealing with low-memory conditions.\n- Handling background tasks properly to avoid ANRs (Application Not Responding).\n- Handling different Android versions and API levels.\n\n### Version-Specific Issues:\n\n- Be aware of API level differences and use `@TargetApi` and `@RequiresApi` annotations to handle them correctly.\n- Test your app on different Android versions to ensure compatibility.\n\n### Compatibility Concerns:\n\n- Ensure compatibility with different device manufacturers and hardware configurations.\n- Test your app on different screen sizes and densities.\n\n### Debugging Strategies:\n\n- Use the Android Debug Bridge (ADB) to connect to devices and emulators for debugging.\n- Use the Android Profiler to analyze app performance and identify bottlenecks.\n- Use logging statements to track the flow of execution and identify errors.\n- Use the debugger to step through the code and inspect variables.\n\n## Tooling and Environment\n\n### Recommended Tools:\n\n- Android Studio: The official IDE for Android development.\n- Gradle: The build system for Android projects.\n- ADB (Android Debug Bridge): A command-line tool for communicating with Android devices and emulators.\n- Android Profiler: A tool for analyzing app performance.\n- LeakCanary: A library for detecting memory leaks.\n- Timber: A logging library for Android.\n\n### Build Configuration:\n\n- MUST use gradle with gradle wrapper to build Android library or Java library\n- MUST have consistent minSdk and supportLib versions with other SDKs\n- SHOULD use shared build configuration for consistent version with other SDKs/libraries\n- MAY use manual configuration with values (same as in shared build configuration), if so SHOULD use a recent minSdk version unless there is an engineering or product decision to support older versions\n- SHOULD use latest versions of Android X libraries (if required)\n\n- Configure build variants for different environments (debug, release, staging).\n- Use ProGuard or R8 to shrink, obfuscate, and optimize the code for release builds.\n- Configure signing configurations to sign the APK for distribution.\n\n### Linting and Formatting:\n\n- Enforce code style guidelines using lint and code formatters (e.g., ktlint for Kotlin).\n- Configure lint to run automatically during the build process.\n- Resolve lint warnings and errors to improve code quality.\n\n### Deployment:\n\n- Publish libraries to a Maven repository (Maven Central or a private repository).\n- Deploy apps to the Google Play Store.\n- Implement beta testing using Google Play Console.\n\n### CI/CD Integration:\n\n- Integrate the build process with a CI/CD system (e.g., Jenkins, CircleCI, GitHub Actions).\n- Automate testing, linting, and code formatting as part of the CI/CD pipeline.\n- Automate deployment to the Google Play Store.\n\n## Additional Considerations\n- Limit impact on consumers. SHOULD limit dependencies as much as possible primarily due to risk of version clashes\n- RECOMMENDED not to have any exported dependency on other SDK modules e.g. if your module needs authentication, do not depend on Authentication SDK. Instead, require your library consumer to pass an access token string to your API instead.\n- Expose minimal Surface area. Keep everything private unless it needs to be public. Every public class, method, property & resource MUST have a strong reason for being public. MAY keep internal source code in a /Private folder to allow tools to more easily ignore those files\n- MUST hide classes from generated API documentation that are required to be public solely for technical reasons and are not intended for SDK consumers\n- SHOULD declare classes as final to avoid unexpected high-jacking of SDK behavior by subclasses\n- For better testability of your library it is RECOMMENDED to use dependency injection\n- MUST follow Semantic Versioning\n- MUST tag source control management revision/commit that is published\n- RECOMMENDED For Android: Use gradle-versions-plugin for automated versioning by git tag",
    "metadata": {
      "globs": "*.java,*.kt,*.xml,*.gradle,*.properties",
      "format": "mdc",
      "originalFile": "android-sdk.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "android",
      "sdk",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "encompassing",
      "android-sdk",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "android-sdk",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-angular",
    "description": "This rule provides comprehensive guidelines for Angular development, covering coding standards, best practices, performance optimization, security considerations, and testing approaches to ensure maintainable, scalable, and high-performing applications.",
    "author": "sanjeed5",
    "tags": [
      "angular",
      "frontend",
      "typescript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "javascript",
      "types",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/angular.mdc",
    "content": "# Angular Best Practices and Coding Standards\n\nThis document outlines comprehensive best practices and coding standards for developing Angular applications. Adhering to these guidelines will promote maintainability, scalability, performance, and security.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n- **Feature-based Modules:** Organize your application into feature modules, where each module encapsulates a specific feature or functionality.\n- **Shared Module:** Create a `shared` module for commonly used components, directives, pipes, and services.\n- **Core Module:** Create a `core` module for application-wide services and singleton instances (e.g., authentication service, configuration service).\n- **Lazy-loaded Modules:** Group related features into lazy-loaded modules to improve initial load time.\n- **Directory structure example:**\n\n  \n  src/\n  ├── app/\n  │   ├── core/\n  │   │   ├── core.module.ts\n  │   │   └── auth.service.ts\n  │   ├── shared/\n  │   │   ├── shared.module.ts\n  │   │   └── components/\n  │   │       └── ...\n  │   ├── features/\n  │   │   ├── dashboard/\n  │   │   │   ├── dashboard.module.ts\n  │   │   │   ├── dashboard.component.ts\n  │   │   │   └── dashboard.component.html\n  │   │   ├── user-management/\n  │   │   │   ├── user-management.module.ts\n  │   │   │   └── ...\n  │   │   └── ...\n  │   ├── app.component.ts\n  │   └── app.module.ts\n  └── ...\n  \n\n### 1.2. File Naming Conventions\n\n- **Consistent Naming:** Use a consistent naming pattern for all files and symbols, following the `feature.type.ts` convention (e.g., `user.component.ts`, `user.service.ts`).\n- **Type Abbreviations:** Use abbreviations for file types (e.g., `component.ts` -> `.component.ts`, `service.ts` -> `.service.ts`, `module.ts` -> `.module.ts`).\n- **Descriptive Names:** Use descriptive names that clearly indicate the purpose of the file.\n\n### 1.3. Module Organization\n\n- **Single Responsibility:** Each module should have a single responsibility.\n- **Declarations:** Declare components, directives, and pipes within the appropriate module.\n- **Imports:** Import only the necessary modules in each module.\n- **Exports:** Export components, directives, and pipes that need to be used by other modules.\n- **forRoot() pattern:** Use the `forRoot()` pattern for modules that provide singleton services to ensure they are only instantiated once in the application.\n\n### 1.4. Component Architecture\n\n- **Smart vs. Dumb Components:** Distinguish between smart (container) components that handle data and logic, and dumb (presentational) components that focus on rendering UI.\n- **Component Reusability:** Design components for reusability.\n- **Input and Output Properties:** Use `@Input()` and `@Output()` properties to pass data and events between components.\n- **Change Detection:** Be mindful of change detection strategies (e.g., `OnPush`) to optimize rendering performance.\n\n### 1.5. Code Splitting Strategies\n\n- **Lazy Loading:** Implement lazy loading for modules to reduce the initial bundle size and improve load time.\n- **Route-based Code Splitting:** Split your application into modules based on routes.\n- **Feature-based Code Splitting:** Split your application into modules based on features.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Angular\n\n- **Dependency Injection (DI):** Use DI to manage dependencies between components and services.\n- **Observables:** Use RxJS Observables for handling asynchronous data streams.\n- **Services:** Use services for encapsulating reusable business logic.\n- **Pipes:** Use pipes for transforming data in templates.\n- **Directives:** Use directives for manipulating the DOM.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n- **Data Binding:** Use data binding (`{{ }}`, `[]`, `()`) to synchronize data between the component and the template.\n- **Event Handling:** Use event binding (`()`) to handle user interactions.\n- **Form Handling:** Use reactive forms or template-driven forms to manage user input.\n- **HTTP Requests:** Use the `HttpClient` to make HTTP requests to backend APIs.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n- **Deeply Nested Components:** Avoid deeply nested component hierarchies, which can make it difficult to manage state and events.\n- **Large Components:** Break large components into smaller, reusable components.\n- **Logic in Templates:** Avoid complex logic in templates; move it to the component class.\n- **Direct DOM Manipulation:** Avoid direct DOM manipulation; use Angular's data binding and directives instead.\n- **Unnecessary Subscriptions:** Unsubscribe from Observables to prevent memory leaks.  Use the `async` pipe in templates to automatically handle subscriptions and unsubscriptions.\n\n### 2.4. State Management Best Practices\n\n- **Choose a State Management Library:** Consider using a state management library like NgRx, Akita, or MobX for complex applications.\n- **Centralized State:** Store application state in a central store.\n- **Immutability:** Treat state as immutable to simplify change detection and debugging.\n- **Actions and Reducers:** Use actions to describe state changes and reducers to update the state.\n- **Selectors:** Use selectors to efficiently retrieve data from the store.\n\n### 2.5. Error Handling Patterns\n\n- **Centralized Error Handling:** Implement a centralized error handling mechanism using an `ErrorHandler`.\n- **Error Interceptors:** Use HTTP interceptors to handle errors from backend APIs.\n- **User-Friendly Error Messages:** Display user-friendly error messages to the user.\n- **Logging:** Log errors to a central logging service for debugging and monitoring.\n- **Retry mechanism:** Implement retry mechanism for failed requests using RxJS retry operators.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Change Detection Optimization:** Use `OnPush` change detection strategy for components that only depend on their input properties.\n- **TrackBy Function:** Use the `trackBy` function with `ngFor` to optimize rendering of lists.\n- **Virtualization:** Use virtual scrolling for large lists to improve performance.\n- **Ahead-of-Time (AOT) Compilation:** Use AOT compilation to compile templates during the build process, improving startup time.\n- **Minification and Uglification:** Minify and uglify your code to reduce bundle size.\n\n### 3.2. Memory Management\n\n- **Unsubscribe from Observables:** Unsubscribe from Observables when they are no longer needed to prevent memory leaks.\n- **Avoid Circular Dependencies:** Avoid circular dependencies, which can lead to memory leaks.\n- **Detach Event Listeners:** Detach event listeners when they are no longer needed.\n\n### 3.3. Rendering Optimization\n\n- **Minimize DOM Manipulation:** Minimize DOM manipulation, as it can be expensive.\n- **Use CSS Transforms:** Use CSS transforms instead of modifying layout properties.\n- **Debouncing and Throttling:** Use debouncing and throttling to reduce the frequency of event handlers.\n\n### 3.4. Bundle Size Optimization\n\n- **Lazy Loading:** Implement lazy loading for modules to reduce the initial bundle size.\n- **Tree Shaking:** Use tree shaking to remove unused code from your bundle.\n- **Code Splitting:** Split your application into smaller bundles to improve load time.\n- **Image Optimization:** Optimize images to reduce their file size.\n- **Vendor Libraries:** Use only necessary vendor libraries, and ensure they are up-to-date for optimized versions.\n\n### 3.5. Lazy Loading Strategies\n\n- **Route-based Lazy Loading:** Load modules when navigating to a specific route.\n- **Feature-based Lazy Loading:** Load modules based on feature requirements.\n- **Preloading:** Preload modules in the background to improve perceived performance.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n- **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and avoiding the use of `innerHTML`.\n- **Cross-Site Request Forgery (CSRF):** Prevent CSRF attacks by using anti-CSRF tokens.\n- **Injection Attacks:** Prevent injection attacks by validating user input and using parameterized queries.\n\n### 4.2. Input Validation\n\n- **Client-Side Validation:** Perform client-side validation to provide immediate feedback to the user.\n- **Server-Side Validation:** Perform server-side validation to ensure data integrity.\n- **Whitelist Validation:** Use whitelist validation to allow only specific characters or patterns.\n\n### 4.3. Authentication and Authorization Patterns\n\n- **Authentication:** Implement authentication to verify the user's identity.\n- **Authorization:** Implement authorization to control access to resources based on the user's roles and permissions.\n- **JSON Web Tokens (JWT):** Use JWTs for secure authentication and authorization.\n- **OAuth 2.0:** Use OAuth 2.0 for delegating authorization to third-party applications.\n\n### 4.4. Data Protection Strategies\n\n- **Encryption:** Encrypt sensitive data at rest and in transit.\n- **Hashing:** Hash passwords before storing them in the database.\n- **Data Masking:** Mask sensitive data to prevent unauthorized access.\n\n### 4.5. Secure API Communication\n\n- **HTTPS:** Use HTTPS for secure communication between the client and the server.\n- **API Keys:** Use API keys to authenticate API requests.\n- **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n- **Test Driven Development (TDD):** Write tests before writing code.\n- **Component Testing:** Test components in isolation using mock data.\n- **Service Testing:** Test services in isolation using dependency injection.\n- **Pipe Testing:** Test pipes to ensure they transform data correctly.\n\n### 5.2. Integration Testing\n\n- **Module Testing:** Test modules to ensure they integrate correctly.\n- **Component Interaction Testing:** Test the interaction between components.\n- **HTTP Testing:** Test HTTP requests and responses.\n\n### 5.3. End-to-End Testing\n\n- **User Interface (UI) Testing:** Test the UI to ensure it behaves as expected.\n- **Workflow Testing:** Test complete workflows to ensure they function correctly.\n- **Cross-Browser Testing:** Test your application in different browsers.\n\n### 5.4. Test Organization\n\n- **Test Directory Structure:** Mirror your source code directory structure in your test directory.\n- **Test File Naming:** Use consistent naming conventions for test files (e.g., `user.component.spec.ts`).\n- **Test Suites:** Group related tests into test suites.\n\n### 5.5. Mocking and Stubbing\n\n- **Mock Dependencies:** Mock dependencies to isolate units of code for testing.\n- **Stub HTTP Requests:** Stub HTTP requests to avoid making actual API calls during testing.\n- **Use Mocking Libraries:** Use mocking libraries like Jasmine or Jest to simplify mocking and stubbing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n- **Forgetting to Unsubscribe from Observables:** Always unsubscribe from Observables to prevent memory leaks.\n- **Using `any` Type:** Avoid using the `any` type, as it bypasses type checking.\n- **Not Handling Errors:** Handle errors gracefully to prevent unexpected behavior.\n- **Ignoring Performance:** Optimize your code for performance from the beginning.\n\n### 6.2. Edge Cases to Be Aware Of\n\n- **Empty Arrays:** Handle empty arrays correctly.\n- **Null Values:** Handle null values correctly.\n- **Unexpected Input:** Validate user input to prevent unexpected behavior.\n\n### 6.3. Version-Specific Issues\n\n- **Breaking Changes:** Be aware of breaking changes in new versions of Angular and third-party libraries.\n- **Deprecated APIs:** Avoid using deprecated APIs.\n- **Migration Guides:** Follow migration guides when upgrading to new versions of Angular.\n\n### 6.4. Compatibility Concerns\n\n- **Browser Compatibility:** Test your application in different browsers to ensure compatibility.\n- **Device Compatibility:** Test your application on different devices to ensure compatibility.\n\n### 6.5. Debugging Strategies\n\n- **Browser Developer Tools:** Use browser developer tools to debug your code.\n- **Logging:** Use logging to track the flow of execution and identify errors.\n- **Debugging Tools:** Use debugging tools like VS Code's debugger to step through your code.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **VS Code:** Use VS Code as your code editor.\n- **Angular CLI:** Use the Angular CLI for scaffolding, building, and deploying your application.\n- **Chrome Developer Tools:** Use Chrome Developer Tools for debugging and performance profiling.\n\n### 7.2. Build Configuration\n\n- **Angular CLI Configuration:** Configure your Angular CLI settings in the `angular.json` file.\n- **Environment Variables:** Use environment variables to configure your application for different environments.\n- **Build Optimization:** Configure your build process to optimize your code for production.\n\n### 7.3. Linting and Formatting\n\n- **ESLint:** Use ESLint to enforce coding standards.\n- **Prettier:** Use Prettier to format your code automatically.\n- **Husky:** Use Husky to run linters and formatters before committing code.\n\n### 7.4. Deployment Best Practices\n\n- **Continuous Integration/Continuous Deployment (CI/CD):** Use a CI/CD pipeline to automate the build, test, and deployment process.\n- **Deployment Environments:** Use different deployment environments for development, testing, and production.\n- **CDN:** Use a content delivery network (CDN) to serve static assets.\n\n### 7.5. CI/CD Integration\n\n- **Jenkins:** Use Jenkins for CI/CD.\n- **GitHub Actions:** Use GitHub Actions for CI/CD.\n- **Azure DevOps:** Use Azure DevOps for CI/CD.\n- **GitLab CI:** Use GitLab CI for CI/CD.\n\nBy following these best practices and coding standards, you can build robust, maintainable, and scalable Angular applications.",
    "metadata": {
      "globs": "*.ts,*.html,*.scss,*.css",
      "format": "mdc",
      "originalFile": "angular.mdc"
    },
    "subcategory": "angular",
    "keywords": [
      "cursor",
      "angular",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "coding",
      "standards",
      "frontend",
      "typescript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "javascript",
      "types",
      "type-safety",
      "frontend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "angular",
        "frontend",
        "typescript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-ansible",
    "description": "This rule file provides comprehensive best practices and coding standards for Ansible projects, covering code organization, common patterns, performance, security, testing, pitfalls, and tooling. It aims to improve maintainability, reusability, and efficiency in Ansible automation.",
    "author": "sanjeed5",
    "tags": [
      "ansible",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ansible.mdc",
    "content": "- Adopt and adhere to the following Ansible best practices to ensure maintainable, reusable, and efficient automation code. This guide provides standards for code organization, common patterns, performance optimization, security, testing, tooling, and common pitfalls to avoid.\n\n## 1. Code Organization and Structure\n\n- Structure your Ansible projects in a clear and consistent manner to enhance readability and maintainability.\n\n### 1.1 Directory Structure Best Practices\n\n- **Root Directory:**\n    - `ansible.cfg`: Ansible configuration file. This should live in the root directory of your project.\n    - `inventory/`: Contains your inventory files (hosts, groups, and variables).\n        - `hosts`: Main inventory file.\n        - `group_vars/`: Directory for group-specific variables.\n            - `all/`: Contains variables that apply to all hosts.\n                - `vars.yml`: Primary file for common variables.\n                - `vault.yml`: Encrypted variables.\n            - `<group_name>/`: Directory for variables specific to a group.\n                - `vars.yml`: Group-specific variables.\n                - `vault.yml`: Encrypted group variables.\n        - `host_vars/`: Directory for host-specific variables.\n            - `<host_name>/`: Directory for a specific host.\n                - `vars.yml`: Host-specific variables.\n                - `vault.yml`: Encrypted host variables.\n    - `playbooks/`: Directory for your Ansible playbooks.\n        - `site.yml`: Main playbook, orchestrating other playbooks.\n        - `<environment>.yml`: Playbooks tailored to different environments (e.g., staging.yml, production.yml).\n        - `<component>.yml`: Playbooks for specific components (e.g., webservers.yml, databases.yml).\n    - `roles/`: Directory for reusable Ansible roles.\n        - `<role_name>/`:\n            - `tasks/`: Contains tasks for the role.\n                - `main.yml`: Entry point for the role's tasks.\n            - `handlers/`: Contains handlers for the role.\n                - `main.yml`: Entry point for the role's handlers.\n            - `defaults/`: Contains default variable values for the role.\n                - `main.yml`: Default variable values.\n            - `vars/`: Contains role-specific variables.\n                - `main.yml`: Role-specific variables.\n            - `meta/`: Contains metadata about the role.\n                - `main.yml`: Role metadata (e.g., dependencies, author).\n            - `templates/`: Contains Jinja2 templates for the role.\n            - `files/`: Contains static files used by the role.\n    - `library/`: (Optional) Custom Ansible modules.\n    - `filter_plugins/`: (Optional) Custom Jinja2 filter plugins.\n    - `lookup_plugins/`: (Optional) Custom lookup plugins.\n    - `plugins/`: All of the above (library, filter, lookup, etc) should be placed in respective subfolders in this directory\n    - `requirements.yml`: Lists roles to be downloaded from Ansible Galaxy.\n    - `README.md`: Project documentation.\n\n### 1.2 File Naming Conventions\n\n- **Playbooks:**\n    - Use lowercase with hyphens for readability (e.g., `webservers.yml`, `database-setup.yml`).\n    - Name your main playbook `site.yml` for consistency.\n- **Roles:**\n    - Use lowercase with underscores (e.g., `common_setup`, `nginx_configuration`).\n    - Role names should be descriptive and concise.\n- **Variables Files:**\n    - Use `vars.yml` for general variables and `defaults.yml` for role defaults.\n    - Use `vault.yml` for encrypted variables.\n    - Group-specific variables: `<group_name>.yml`.\n    - Host-specific variables: `<host_name>.yml`.\n- **Tasks and Handlers:**\n    - `main.yml` as the entry point for tasks and handlers within roles.\n- **Templates:**\n    - Give descriptive names to templates, using the `.j2` extension (e.g., `nginx.conf.j2`, `application.properties.j2`).\n- **Inventory:**\n    - Name your inventory file `hosts` or follow a consistent naming convention, such as `<environment>_hosts` (e.g., `staging_hosts`, `production_hosts`).\n\n### 1.3 Module Organization\n\n- Keep custom modules in the `library/` directory at the project root.\n- Organize modules into subdirectories based on functionality (e.g., `library/custom_modules/database`, `library/custom_modules/monitoring`).\n- Document each custom module with clear usage examples and return values.\n- Utilize `module_utils` to create shared code used by multiple modules.\n- Follow a consistent naming convention for custom modules (e.g., `my_custom_module.py`).\n- All modules should contain argument spec and proper return values (changed, failed, original_message, message, etc).\n\n### 1.4 Component Architecture Recommendations\n\n- **Roles as Building Blocks:**\n    - Divide your infrastructure into logical components (e.g., web servers, databases, load balancers) and create roles for each.\n    - Keep roles single-purposed and focused on specific functionality to promote reusability.\n- **Playbooks for Orchestration:**\n    - Use playbooks to orchestrate roles and define the desired state of your infrastructure.\n    - The main `site.yml` playbook should act as the entry point, calling other component-specific playbooks.\n- **Variables for Configuration:**\n    - Externalize configuration data using variables in `group_vars/` and `host_vars/`.\n    - Use default variables within roles to provide sane defaults and allow for customization.\n- **Handlers for Event-Driven Configuration:**\n    - Use handlers to manage service restarts and other event-driven tasks.\n    - Ensure handlers are idempotent and only triggered when necessary.\n\n### 1.5 Code Splitting Strategies\n\n- **Role Decomposition:**\n    - Break down complex roles into smaller, more manageable roles to improve reusability and maintainability.\n- **Task Includes:**\n    - Use `include_tasks` to split long task lists into smaller, more focused files.\n- **Dynamic Includes:**\n    - Employ `include_vars`, `include_role`, and `include_tasks` with dynamic variables to load configuration data or tasks based on conditions.\n- **Blocks for Logical Grouping:**\n    - Use blocks to group related tasks, providing better error handling and readability.\n\n## 2. Common Patterns and Anti-patterns\n\n- Learn and apply common Ansible design patterns to solve infrastructure automation problems efficiently while avoiding pitfalls.\n\n### 2.1 Design Patterns\n\n- **Idempotency:**\n    - Design tasks to be idempotent, meaning they should produce the same result regardless of how many times they are executed.\n    - Use the `changed_when` and `failed_when` directives to customize task result conditions.\n- **Variable Prioritization:**\n    - Understand Ansible's variable precedence and use it effectively to override default values.\n    - Variable precedence order (highest to lowest): extra vars (-e), command line arguments (-e), role vars, include vars, block vars, task vars, role defaults, inventory vars, registered vars, facts.\n- **Handlers for Service Management:**\n    - Utilize handlers to restart services when configuration files change. Use `notify` directive in tasks to trigger handlers.\n- **Template Management:**\n    - Use the `template` module to manage configuration files. Keep templates simple and focused on configuration logic.\n- **Looping with `with_items`:**\n    - Use `with_items` or `loop` to iterate over lists of items, such as packages to install or users to create.\n- **Conditions with `when`:**\n    - Use the `when` directive to conditionally execute tasks based on variables or facts.\n- **Delegation with `delegate_to`:**\n    - Use the `delegate_to` directive to run tasks on a specific host, such as when managing a load balancer or database server.\n- **Error Handling with `block` and `rescue`:**\n    - Wrap tasks in `block` directives and use `rescue` to handle errors gracefully.\n- **Register variables for complex tasks:**\n    - Register variables to capture output from a task and use it in subsequent tasks.\n- **Meta Tasks for Role Management:**\n    - Use meta tasks (e.g., `meta: clear_host_errors`, `meta: end_play`) to manage role execution and handle errors.\n- **Facts for dynamic configuration:**\n    - Utilize facts to gather system information and dynamically configure tasks.\n- **Loops for repetitive tasks:**\n    - Use loops to perform repetitive tasks, such as creating multiple users or installing multiple packages. Always name the loop so the end user can identify the tasks better.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Package Management:**\n    - Use the appropriate package manager module (e.g., `apt`, `yum`, `dnf`, `homebrew`) for the target system.\n    - Always specify the `state` (e.g., `present`, `latest`, `absent`) when managing packages.\n- **File Management:**\n    - Use the `file` module to create, modify, or delete files and directories.\n    - Use the `copy` module to copy files from the control node to the target nodes.\n    - Use the `template` module to manage configuration files with Jinja2 templates.\n- **Service Management:**\n    - Use the `service` or `systemd` module to manage services.\n    - Always specify the `state` (e.g., `started`, `stopped`, `restarted`) when managing services.\n    - Use handlers to restart services when configuration files change.\n- **User Management:**\n    - Use the `user` module to create, modify, or delete users.\n    - Use the `group` module to manage groups.\n    - Use the `authorized_key` module to manage SSH keys.\n- **Cron Job Management:**\n    - Use the `cron` module to create, modify, or delete cron jobs.\n- **Firewall Management:**\n    - Use the `firewalld` or `ufw` module to manage firewalls.\n- **SELinux Management:**\n    - Use the `selinux` module to manage SELinux policies.\n- **Line-in-File management:**\n    - Use the `lineinfile` module to ensure a specific line exists in a file.\n    - Use the `blockinfile` module to ensure a block of lines exist in a file.\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Shell and Command Modules:**\n    - Avoid using the `shell` and `command` modules unless absolutely necessary.\n    - Prefer Ansible's built-in modules for specific tasks, as they provide idempotency and better error handling.\n- **Hardcoded Values:**\n    - Avoid hardcoding values in your playbooks or roles.\n    - Use variables in `group_vars/` and `host_vars/` to externalize configuration data.\n- **Inconsistent Naming Conventions:**\n    - Follow a consistent naming convention for variables, tasks, roles, and files.\n    - This improves readability and maintainability.\n- **Unnecessary Complexity:**\n    - Keep your playbooks and roles as simple as possible.\n    - Avoid over-engineering or introducing unnecessary complexity.\n- **Lack of Idempotency:**\n    - Ensure your tasks are idempotent to avoid unintended side effects.\n    - Use the `changed_when` and `failed_when` directives to customize task result conditions.\n- **Ignoring Errors:**\n    - Always handle errors gracefully by using `block` and `rescue` directives.\n    - Use the `fail` module to explicitly fail a playbook when a critical error occurs.\n- **Storing Secrets in Plain Text:**\n    - Never store sensitive data in plain text.\n    - Use Ansible Vault to encrypt variables and files.\n- **Lack of Documentation:**\n    - Always document your playbooks, roles, and custom modules.\n    - This improves collaboration and makes it easier to maintain your automation code.\n- **Copying the same block of code:**\n    - Refactor and call the common tasks using `include_tasks` to improve readability and maintainability\n- **Using loops when a module can handle multiple arguments:**\n    - Some modules can perform multiple tasks by passing a list of arguments (e.g. `yum` module), so avoid using loops as much as possible.\n- **Creating complex templates:**\n    - Templates should be simple and contain logic that is easy to read and maintain.\n    - Avoid implementing complex functionality that increases maintenance cost and reduces code readability.\n- **Writing unoptimized Jinja expressions:**\n    - Use Jinja filters for data manipulation, rather than implementing the logic using Ansible modules\n\n### 2.4 State Management\n\n- **Use Ansible to manage the desired state of your infrastructure.** Avoid manual changes outside of Ansible.\n- **Leverage facts to gather system information and dynamically configure tasks.**\n- **Use handlers to react to state changes and ensure services are restarted or reconfigured when necessary.**\n- **Use variables to store configuration data and customize the desired state for different environments.**\n\n### 2.5 Error Handling Patterns\n\n- **Use `block` and `rescue` to handle errors gracefully.**\n- **Use the `fail` module to explicitly fail a playbook when a critical error occurs.**\n- **Register variables to capture the output of tasks and use the output in error handling logic.**\n- **Use the `ignore_errors` directive to continue playbook execution even when a task fails (use with caution).**\n- **Use the `meta: clear_host_errors` task to clear errors on a host and continue playbook execution.**\n- **Implement rollback mechanisms to revert changes in case of failures.**\n\n## 3. Performance Considerations\n\n- Optimize your Ansible code to improve execution speed and resource utilization.\n\n### 3.1 Optimization Techniques\n\n- **Use SSH multiplexing:**\n    - Enable SSH multiplexing in your `ansible.cfg` file to reduce the overhead of establishing SSH connections.\n    - `pipelining = True`\n- **Use ControlPersist:**\n    - Enable ControlPersist in your SSH configuration to keep SSH connections alive for longer periods of time.\n- **Optimize Inventory:**\n    - Use a dynamic inventory to manage large numbers of hosts.\n    - Cache the inventory data to reduce the time it takes to load the inventory.\n- **Minimize Fact Gathering:**\n    - Disable fact gathering for tasks that don't require them.\n    - Use the `gather_facts: false` directive in your playbooks or tasks.\n- **Parallel Execution:**\n    - Increase the number of forks to execute tasks in parallel.\n    - Use the `-f` or `--forks` option when running Ansible playbooks.\n    - Be mindful of resource limitations and avoid overloading your control node or target hosts.\n- **Avoid Loops When Possible:**\n    - Prefer modules that can handle lists of items instead of using loops.\n    - For example, use the `yum` or `apt` module with a list of packages to install instead of using a loop with the `package` module.\n- **Optimize Jinja2 Templates:**\n    - Use Jinja2 filters to perform data manipulation instead of using Ansible modules.\n    - Cache the results of Jinja2 filters to avoid recomputing them repeatedly.\n- **Use Async Tasks:**\n    - Use async tasks with poll to execute tasks in the background and reduce the time it takes to run your playbooks.\n- **Use Connection Type `smart` or `persistent`:**\n    - These connection types are optimized for performance, especially for larger deployments.\n- **Use Caching:**\n    - Utilize Ansible's fact caching to avoid gathering the same facts repeatedly.\n- **Use strategy plugins:**\n    - Use plugins such as free, debug and host_pinned in your Ansible configuration file to maximize execution performance and concurrency.\n\n### 3.2 Memory Management\n\n- **Limit the number of forks:**\n    - Reduce the number of forks if your control node is running out of memory.\n- **Use smaller inventories:**\n    - Split large inventories into smaller inventories to reduce memory usage.\n- **Avoid loading large files into variables:**\n    - Use the `slurp` module to read large files into variables only when necessary.\n- **Compress large files before transferring them:**\n    - Use the `compress` module to compress large files before transferring them to target hosts.\n\n### 3.3 Rendering Optimization\n\n- **Cache Jinja2 templates:**\n    - Enable Jinja2 template caching to reduce the time it takes to render templates.\n- **Use filters and tests:**\n    - Instead of modules, use filters and tests to avoid calling Ansible tasks.\n- **Limit Variable Scope:**\n    - Declare variables in the narrowest scope possible to minimize memory usage and improve performance.\n\n## 4. Security Best Practices\n\n- Secure your Ansible environment and protect sensitive data.\n\n### 4.1 Common Vulnerabilities and Prevention\n\n- **Plaintext Secrets:**\n    - *Vulnerability:* Storing passwords, API keys, and other sensitive data in plaintext in playbooks or variable files.\n    - *Prevention:* Use Ansible Vault to encrypt sensitive data.\n        - Example:\n          \n          # Encrypt a variable file\n          ansible-vault encrypt group_vars/all/vault.yml\n\n          # Use the variable in a playbook\n          - name: Deploy application with secret key\n            template:\n              src: app.conf.j2\n              dest: /etc/app/app.conf\n          \n- **Unprotected SSH Keys:**\n    - *Vulnerability:* Leaving private SSH keys unprotected on the control node or target hosts.\n    - *Prevention:* Restrict access to the control node and use SSH key-based authentication with proper permissions.\n- **Command Injection:**\n    - *Vulnerability:* Using user-supplied data directly in shell commands without proper sanitization.\n    - *Prevention:* Avoid using the `shell` and `command` modules unless absolutely necessary.\n        - Use Ansible's built-in modules whenever possible.\n        - If you must use `shell` or `command`, sanitize user input properly.\n- **Privilege Escalation:**\n    - *Vulnerability:* Granting unnecessary privileges to Ansible users or tasks.\n    - *Prevention:* Use the `become` directive only when necessary.\n        - Grant the minimum required privileges to Ansible users.\n- **Unvalidated Input:**\n    - *Vulnerability:* Using unvalidated input from external sources (e.g., APIs, user input) without proper sanitization.\n    - *Prevention:* Validate all input from external sources before using it in your playbooks or tasks.\n        - Use the `assert` module to validate input.\n- **Insecure Communication:**\n    - *Vulnerability:* Using insecure communication protocols (e.g., HTTP) to transfer sensitive data.\n    - *Prevention:* Use HTTPS for all communication with APIs and other external services.\n- **Weak SSH Keys:**\n    - *Vulnerability:* Using weak or compromised SSH keys.\n    - *Prevention:* Generate strong SSH keys with a key length of at least 2048 bits.\n        - Rotate SSH keys regularly.\n- **Unauthorized Access:**\n    - *Vulnerability:* Allowing unauthorized access to the control node or target hosts.\n    - *Prevention:* Use strong passwords and multi-factor authentication.\n        - Restrict access to the control node and target hosts to authorized users only.\n\n### 4.2 Input Validation\n\n- **Validate all input from external sources before using it in your playbooks or tasks.**\n- **Use the `assert` module to validate input.**\n- **Use regular expressions to validate input strings.**\n- **Use the `int` and `float` filters to validate numeric input.**\n- **Use the `bool` filter to validate boolean input.**\n- **Use the `list` and `dict` filters to validate list and dictionary input.**\n\n### 4.3 Authentication and Authorization\n\n- **Use SSH key-based authentication instead of passwords.**\n- **Restrict access to the control node and target hosts to authorized users only.**\n- **Use the `become` directive to escalate privileges only when necessary.**\n- **Use the `sudo` module to execute tasks with elevated privileges.**\n- **Use the `acl` module to manage access control lists (ACLs) on files and directories.**\n- **Integrate with external authentication providers (e.g., LDAP, Active Directory) for centralized user management.**\n\n### 4.4 Data Protection\n\n- **Use Ansible Vault to encrypt sensitive data.**\n- **Use HTTPS for all communication with APIs and other external services.**\n- **Use the `slurp` module to read sensitive data from files into variables only when necessary.**\n- **Use the `compress` module to compress sensitive data before transferring it to target hosts.**\n- **Use the `hash` filter to hash sensitive data before storing it in files or databases.**\n- **Implement data masking and tokenization techniques to protect sensitive data at rest and in transit.**\n\n### 4.5 Secure API Communication\n\n- **Use HTTPS for all communication with APIs.**\n- **Use strong authentication mechanisms (e.g., API keys, OAuth 2.0) to protect your APIs.**\n- **Validate all input from APIs before using it in your playbooks or tasks.**\n- **Use the `uri` module to interact with APIs securely.**\n- **Implement rate limiting and throttling to protect your APIs from abuse.**\n- **Monitor your APIs for security vulnerabilities and performance issues.**\n\n## 5. Testing Approaches\n\n- Implement a comprehensive testing strategy to ensure your Ansible code is reliable and error-free.\n\n### 5.1 Unit Testing\n\n- **Unit test custom modules, filter plugins, and lookup plugins.**\n- **Use a testing framework such as `pytest` to write and run unit tests.**\n- **Mock external dependencies to isolate the code being tested.**\n- **Write tests for all possible scenarios, including edge cases and error conditions.**\n- **Use continuous integration to run unit tests automatically on every commit.**\n- **Test modules for different possible input arguments and check their results.**\n\n### 5.2 Integration Testing\n\n- **Integration test your playbooks and roles to ensure they work together correctly.**\n- **Use a testing framework such as `Molecule` to automate integration testing.**\n- **Create a test environment that closely resembles your production environment.**\n- **Test all critical functionality, including package installation, configuration management, and service management.**\n- **Use continuous integration to run integration tests automatically on every commit.**\n- **Use an ephemeral infrastructure using Vagrant or Docker to test the playbooks on a fresh machine.**\n- **Test for idempotency by running the same playbook multiple times.**\n\n### 5.3 End-to-End Testing\n\n- **End-to-end test your entire infrastructure to ensure all components work together correctly.**\n- **Use a testing framework such as `Testinfra` or `Inspec` to write and run end-to-end tests.**\n- **Create a test environment that is as close as possible to your production environment.**\n- **Test all critical business processes to ensure they work as expected.**\n- **Use continuous integration to run end-to-end tests automatically on every commit.**\n\n### 5.4 Test Organization\n\n- **Organize your tests into a directory structure that mirrors your Ansible code.**\n- **Create separate directories for unit tests, integration tests, and end-to-end tests.**\n- **Use descriptive names for your test files and test functions.**\n- **Document your tests with clear explanations of what they are testing.**\n- **Use a consistent naming convention for your tests to improve readability and maintainability.**\n\n### 5.5 Mocking and Stubbing Techniques\n\n- **Use mocking and stubbing to isolate your code during unit testing.**\n- **Mock external dependencies such as APIs, databases, and operating system commands.**\n- **Use a mocking framework such as `unittest.mock` (Python) to create mocks and stubs.**\n- **Write tests that verify that your code interacts with the mocked dependencies correctly.**\n- **Avoid mocking Ansible modules, instead create a module that is a wrapper around it.**\n\n## 6. Common Pitfalls and Gotchas\n\n- Be aware of common mistakes and edge cases when working with Ansible.\n\n### 6.1 Frequent Mistakes\n\n- **Incorrect YAML Syntax:**\n    - YAML is whitespace-sensitive. Incorrect indentation or missing colons can cause syntax errors.\n    - Use a YAML linter to validate your syntax.\n- **Variable Scope Issues:**\n    - Variables can be defined at different levels (e.g., playbook, role, inventory). Understanding variable precedence is crucial.\n    - Use the `vars_prompt` directive to prompt users for variables.\n- **Incorrect Module Usage:**\n    - Using the wrong module for a task can lead to unexpected results or errors.\n    - Refer to the Ansible documentation for module usage examples and best practices.\n- **Lack of Idempotency:**\n    - Tasks that are not idempotent can cause unintended side effects when run repeatedly.\n    - Use the `changed_when` and `failed_when` directives to customize task result conditions.\n- **Ignoring Errors:**\n    - Ignoring errors can lead to cascading failures or inconsistent state.\n    - Use the `block` and `rescue` directives to handle errors gracefully.\n- **Misunderstanding Facts:**\n    - Facts are variables that contain information about the target hosts. Misunderstanding or misusing facts can lead to incorrect behavior.\n    - Use the `ansible_facts` variable to access all available facts.\n- **Over-reliance on the `shell` module:**\n    - Avoid the shell module unless absolutely necessary as using it hinders the playbook's idempotency.\n- **Not testing playbooks:**\n    - Always test your playbooks before running them in production to avoid any unexpected issues.\n\n### 6.2 Edge Cases\n\n- **Handling Large Files:**\n    - Transferring large files can be slow and consume a lot of resources. Use the `synchronize` module or the `archive` and `unarchive` modules to optimize file transfers.\n- **Managing Complex Dependencies:**\n    - Managing complex dependencies between tasks and roles can be challenging. Use the `block` and `rescue` directives to handle errors gracefully.\n- **Working with Dynamic Inventories:**\n    - Dynamic inventories can be complex to set up and maintain. Use a dynamic inventory plugin or script to manage your inventory automatically.\n- **Handling Network Latency:**\n    - Network latency can affect the performance of your playbooks. Use the `async` directive to execute tasks asynchronously.\n- **Special characters in variables:**\n    - Avoid using special characters that can interfere with playbook's execution.\n\n### 6.3 Version-Specific Issues\n\n- **Module Compatibility:**\n    - Some modules may not be compatible with all versions of Ansible.\n    - Check the module documentation for compatibility information.\n- **Deprecated Features:**\n    - Some features may be deprecated in newer versions of Ansible.\n    - Be aware of deprecated features and migrate to the recommended alternatives.\n- **Behavioral Changes:**\n    - Some modules may have different behavior in different versions of Ansible.\n    - Test your playbooks with different versions of Ansible to ensure they behave as expected.\n\n### 6.4 Compatibility Concerns\n\n- **Operating System Compatibility:**\n    - Some playbooks and roles may only be compatible with specific operating systems.\n    - Check the playbook or role documentation for compatibility information.\n- **Python Version Compatibility:**\n    - Ansible requires Python to be installed on the target hosts. Ensure that the target hosts have a compatible version of Python installed.\n- **Module Dependencies:**\n    - Some modules may have external dependencies that need to be installed on the target hosts.\n    - Check the module documentation for dependency information.\n\n### 6.5 Debugging Strategies\n\n- **Use the `-v` or `--verbose` option to increase the verbosity of Ansible output.**\n- **Use the `-C` or `--check` option to perform a dry run of your playbook.**\n- **Use the `--diff` option to see the changes that will be made to the target hosts.**\n- **Use the `debug` module to print variables and facts.**\n- **Use the `assert` module to validate variables and facts.**\n- **Use the `pause` module to pause playbook execution and inspect the target hosts.**\n- **Use the `register` directive to capture the output of tasks and use the output in debugging logic.**\n- **Check the Ansible logs on the control node and the target hosts for error messages.**\n\n## 7. Tooling and Environment\n\n- Utilize recommended tools and environment configurations to streamline your Ansible development and deployment processes.\n\n### 7.1 Recommended Development Tools\n\n- **Text Editor or IDE:**\n    - Use a text editor or IDE with YAML and Jinja2 syntax highlighting and auto-completion.\n    - Popular options include VS Code, Sublime Text, Atom, and PyCharm.\n    - Install Ansible-specific plugins for improved code completion and linting.\n- **Ansible Lint:**\n    - Use `ansible-lint` to check your playbooks and roles for common errors and best practices violations.\n    - Configure `ansible-lint` to use a custom style guide or to enforce specific rules.\n- **Molecule:**\n    - Use `Molecule` to test your roles in a Docker or Vagrant environment.\n    - Molecule provides a framework for writing and running integration tests for your roles.\n- **Vagrant:**\n    - Use `Vagrant` to create virtual machines for testing your playbooks and roles.\n    - Vagrant allows you to easily create and destroy test environments.\n- **Docker:**\n    - Use `Docker` to containerize your Ansible control node and target hosts.\n    - Docker provides a lightweight and portable environment for running your Ansible code.\n- **Testinfra:**\n    - Use `Testinfra` to write and run end-to-end tests for your infrastructure.\n    - Testinfra allows you to verify the state of your target hosts after running your playbooks.\n\n### 7.2 Build Configuration\n\n- **Use a build tool such as `Make` or `Grunt` to automate your build process.**\n- **Create a `Makefile` or `Gruntfile.js` that defines the tasks for linting, testing, and deploying your Ansible code.**\n- **Use environment variables to configure your build process.**\n- **Use a version control system such as `Git` to track changes to your build configuration.**\n- **Keep your build configuration simple and easy to understand.**\n\n### 7.3 Linting and Formatting\n\n- **Use `ansible-lint` to check your playbooks and roles for common errors and best practices violations.**\n- **Configure `ansible-lint` to use a custom style guide or to enforce specific rules.**\n- **Use a YAML linter to validate your YAML syntax.**\n- **Use a Jinja2 linter to validate your Jinja2 syntax.**\n- **Automate linting and formatting as part of your build process.**\n- **Use auto-formatting tools such as `Prettier` to automatically format your YAML and Jinja2 code.**\n- **Follow a consistent naming convention for your variables, tasks, roles, and files.**\n\n### 7.4 Deployment Best Practices\n\n- **Use a deployment tool such as `Ansible Tower` or `AWX` to manage your deployments.**\n- **Use a continuous integration and continuous delivery (CI/CD) pipeline to automate your deployments.**\n- **Use a version control system such as `Git` to track changes to your playbooks and roles.**\n- **Use a rollback mechanism to revert changes in case of failures.**\n- **Use a monitoring tool such as `Nagios` or `Zabbix` to monitor your infrastructure.**\n- **Use a logging tool such as `ELK Stack` or `Splunk` to collect and analyze your logs.**\n- **Always test your playbooks in a staging environment before deploying them to production.**\n\n### 7.5 CI/CD Integration\n\n- **Integrate your Ansible code into your CI/CD pipeline to automate testing and deployment.**\n- **Use a CI/CD tool such as `Jenkins`, `GitLab CI`, or `Travis CI` to automate your pipeline.**\n- **Create a CI/CD pipeline that includes linting, testing, and deployment steps.**\n- **Use environment variables to configure your CI/CD pipeline.**\n- **Use a version control system such as `Git` to trigger your CI/CD pipeline on every commit.**\n- **Use automated testing to verify that your infrastructure changes work as expected.**\n- **Use automated deployment to deploy your infrastructure changes to your target environment.**\n- **Automate configuration management:**\n   - Ensure consistent configurations for servers and applications.\n- **Implement infrastructure as code:**\n   - Track and manage infrastructure in source control.\n- **Automate application deployments:**\n   - Deploy new versions of software reliably and efficiently.\n- **Orchestrate multi-tier deployments:**\n   - Coordinate deployments across various layers of infrastructure.",
    "metadata": {
      "globs": "*.yml,*.yaml,*.j2",
      "format": "mdc",
      "originalFile": "ansible.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "ansible",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "cursor-rule",
      "mdc",
      "infrastructure",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ansible",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-ant-design",
    "description": "This rule enforces best practices and coding standards for projects using the Ant Design (antd) UI library within React applications. It covers code organization, performance, security, testing, and common pitfalls to ensure maintainable and efficient applications.",
    "author": "sanjeed5",
    "tags": [
      "ant-design",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ant-design.mdc",
    "content": "# Ant Design (antd) Best Practices and Coding Standards\n\nThis document outlines the recommended best practices for developing React applications using the Ant Design (antd) UI library. Following these guidelines will lead to more maintainable, performant, and secure applications.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n-   **`src/components/`**: Contains reusable React components, including those utilizing antd components.\n-   **`src/pages/`**: Contains components representing different application routes or pages.\n-   **`src/layouts/`**: Contains layout components that provide a consistent structure across pages.\n-   **`src/services/`**: Contains modules for interacting with APIs and handling data fetching.\n-   **`src/utils/`**: Contains utility functions and helper modules.\n-   **`src/styles/`**: Contains global styles, theme customizations, and component-specific stylesheets.\n-   **`src/assets/`**: Contains static assets such as images, fonts, and icons.\n-   **`src/context/`**: (Optional) If using context API, store all context definition files here.\n\nExample:\n\n\nmy-app/\n├── src/\n│   ├── components/\n│   │   ├── Button.jsx\n│   │   ├── Input.jsx\n│   │   └── ...\n│   ├── pages/\n│   │   ├── HomePage.jsx\n│   │   ├── LoginPage.jsx\n│   │   └── ...\n│   ├── layouts/\n│   │   ├── MainLayout.jsx\n│   │   └── ...\n│   ├── services/\n│   │   ├── api.js\n│   │   └── ...\n│   ├── utils/\n│   │   ├── date-formatter.js\n│   │   └── ...\n│   ├── styles/\n│   │   ├── global.css\n│   │   ├── theme.js\n│   │   └── ...\n│   ├── App.jsx\n│   └── index.js\n└── ...\n\n\n### 1.2. File Naming Conventions\n\n-   **Components**: Use PascalCase for component file names (e.g., `MyComponent.jsx`, `UserProfile.tsx`).\n-   **Styles**: Use kebab-case for style file names (e.g., `my-component.css`, `user-profile.module.scss`).\n-   **Modules**: Use camelCase for module file names (e.g., `api.js`, `dateFormatter.ts`).\n\n### 1.3. Module Organization\n\n-   Group related components, styles, and assets within the same directory.\n-   Create separate modules for API interactions, data transformations, and utility functions.\n\n### 1.4. Component Architecture\n\n-   **Presentational Components**: Focus on rendering UI elements and receiving data via props.\n-   **Container Components**: Handle data fetching, state management, and logic, passing data to presentational components.\n-   Use functional components with hooks whenever possible for simplicity and reusability.\n\n### 1.5. Code Splitting\n\n-   Utilize React.lazy and Suspense to load components on demand, improving initial load time.\n-   Split routes into separate chunks to minimize the initial bundle size.\n-   Consider using dynamic imports for less frequently used components or modules.\n\nExample:\n\njsx\nimport React, { Suspense } from 'react';\n\nconst MyComponent = React.lazy(() => import('./MyComponent'));\n\nfunction MyPage() {\n  return (\n    <Suspense fallback={<div>Loading...</div>}>\n      <MyComponent />\n    </Suspense>\n  );\n}\n\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Higher-Order Components (HOCs)**: Use for cross-cutting concerns like authentication or data fetching.  Prefer hooks where possible.\n-   **Render Props**:  An alternative to HOCs for sharing code between components.  Prefer hooks where possible.\n-   **Compound Components**: Create reusable components with implicit state sharing (e.g., `Tabs` and `Tab` components).\n\n### 2.2. Recommended Approaches\n\n-   **Form Handling**: Use `antd`'s `Form` component for managing form state, validation, and submission.\n-   **Data Display**: Leverage `antd`'s `Table`, `List`, and `Card` components for structured data presentation.\n-   **Navigation**: Use `antd`'s `Menu` and `Breadcrumb` components for creating intuitive navigation.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Direct DOM Manipulation**: Avoid directly manipulating the DOM; let React manage updates.\n-   **Over-reliance on `any` type**: Using `any` in TypeScript defeats the purpose of static typing.  Provide explicit types.\n-   **Mutating Props**: Treat props as read-only and avoid modifying them directly.\n-   **Inline Styles**:  Keep styles in CSS files or use styled-components for better organization and maintainability. Prefer CSS Modules or Styled Components for component specific styles.\n\n### 2.4. State Management\n\n-   **Component State**: Use `useState` for simple, local component state.\n-   **Context API**: Use for sharing state across multiple components without prop drilling.\n-   **Redux/Zustand**: Consider for complex applications with global state and predictable state transitions.\n-   **MobX**: Consider for complex applications where you want to observe changes in your data and derive calculations from that data.\n\n### 2.5. Error Handling\n\n-   **Try-Catch Blocks**: Use for handling synchronous errors.\n-   **Error Boundaries**: Use to catch errors during rendering and prevent the entire application from crashing.\n-   **Global Error Handling**: Implement a global error handler to log errors and provide user feedback.\n\nExample (Error Boundary):\n\njsx\nclass ErrorBoundary extends React.Component {\n  constructor(props) {\n    super(props);\n    this.state = { hasError: false };\n  }\n\n  static getDerivedStateFromError(error) {\n    return { hasError: true };\n  }\n\n  componentDidCatch(error, errorInfo) {\n    console.error('Caught error: ', error, errorInfo);\n  }\n\n  render() {\n    if (this.state.hasError) {\n      return <h1>Something went wrong.</h1>;\n    }\n\n    return this.props.children;\n  }\n}\n\nexport default ErrorBoundary;\n\n// Usage:\n<ErrorBoundary>\n  <MyComponent />\n</ErrorBoundary>\n\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Memoization**: Use `React.memo` to prevent unnecessary re-renders of components with the same props.\n-   **Pure Components**: Extend `React.PureComponent` for class components to perform shallow prop comparisons.\n-   **Virtualization**: Use `antd`'s `Table` and `List` components with virtualization for large datasets.\n-   **Debouncing/Throttling**: Use for event handlers that trigger frequent updates (e.g., search input).\n\n### 3.2. Memory Management\n\n-   **Avoid Memory Leaks**: Properly clean up event listeners and timers in `useEffect` hooks.\n-   **Release Resources**: Release unused objects and data structures to free up memory.\n\n### 3.3. Rendering Optimization\n\n-   **ShouldComponentUpdate**: Implement `shouldComponentUpdate` (for class components) or use `React.memo` (for functional components) to prevent unnecessary re-renders.\n-   **Immutable Data**: Use immutable data structures to simplify change detection.\n\n### 3.4. Bundle Size Optimization\n\n-   **Modular Imports**: Import only the necessary components from `antd` to reduce bundle size (e.g., `import { Button } from 'antd';`).  Use `babel-plugin-import` for automatic modular imports.\n-   **Tree Shaking**: Ensure your build process supports tree shaking to remove unused code.\n-   **Code Splitting**: As mentioned earlier, split your code into smaller chunks to reduce the initial bundle size.\n\n### 3.5. Lazy Loading\n\n-   Use `React.lazy` and `Suspense` to load components on demand.\n-   Implement lazy loading for images and other assets using libraries like `react-lazyload`.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n-   **Cross-Site Scripting (XSS)**: Prevent XSS by sanitizing user input and encoding output.\n-   **Cross-Site Request Forgery (CSRF)**: Protect against CSRF attacks by implementing CSRF tokens.\n-   **SQL Injection**: Avoid directly embedding user input in SQL queries; use parameterized queries or ORMs.\n\n### 4.2. Input Validation\n\n-   **Server-Side Validation**: Always validate user input on the server-side.\n-   **Client-Side Validation**: Use `antd`'s `Form` component for client-side validation to provide immediate feedback to the user.\n-   **Sanitize Input**: Sanitize user input to remove potentially harmful characters or code.\n\n### 4.3. Authentication and Authorization\n\n-   **Secure Authentication**: Use secure authentication mechanisms like JWT (JSON Web Tokens) or OAuth.\n-   **Role-Based Access Control (RBAC)**: Implement RBAC to control access to different parts of the application based on user roles.\n\n### 4.4. Data Protection\n\n-   **Encryption**: Encrypt sensitive data both in transit and at rest.\n-   **Data Masking**: Mask sensitive data in the UI to prevent unauthorized access.\n\n### 4.5. Secure API Communication\n\n-   **HTTPS**: Use HTTPS to encrypt communication between the client and the server.\n-   **API Rate Limiting**: Implement rate limiting to prevent abuse and denial-of-service attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   Test individual components in isolation to ensure they function correctly.\n-   Use testing libraries like Jest and React Testing Library.\n-   Mock dependencies to isolate the component being tested.\n\n### 5.2. Integration Testing\n\n-   Test the interaction between multiple components or modules.\n-   Use testing libraries like React Testing Library and Cypress.\n\n### 5.3. End-to-End Testing\n\n-   Test the entire application from the user's perspective.\n-   Use testing frameworks like Cypress or Playwright.\n\n### 5.4. Test Organization\n\n-   Create a `tests/` directory at the root of your project.\n-   Place test files alongside the components or modules they test (e.g., `MyComponent.test.jsx`).\n-   Use descriptive test names to clearly indicate what is being tested.\n\n### 5.5. Mocking and Stubbing\n\n-   Use mocking libraries like Jest's `jest.mock()` to mock external dependencies.\n-   Use stubbing to replace functions or methods with predefined behavior.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Not using modular imports**:  Importing the entire `antd` library can significantly increase bundle size.\n-   **Ignoring TypeScript errors**: Failing to address TypeScript errors can lead to runtime issues.\n-   **Not handling asynchronous operations correctly**:  Failing to handle promises or async/await can lead to unhandled rejections and unexpected behavior.\n-   **Not localizing strings correctly**: Hardcoding strings instead of using `antd` i18n features. \n\n### 6.2. Edge Cases\n\n-   **Handling different screen sizes and devices**: Ensuring responsive design using `antd` grid system.\n-   **Accessibility**: Consider accessibility when using components, making sure to include `aria` attributes.\n-   **Browser compatibility**: Test the app on various browsers (Chrome, Firefox, Safari, Edge, etc).\n\n### 6.3. Version-Specific Issues\n\n-   **Breaking changes**: Be aware of breaking changes when upgrading `antd` versions.\n-   **Deprecated APIs**:  Avoid using deprecated APIs and migrate to the recommended alternatives.\n-   **CSS class conflicts:** Potential issues with CSS specificity or conflicts with global styles. Use CSS Modules or Styled Components for more robust style isolation.\n\n### 6.4. Compatibility Concerns\n\n-   **React version**:  Ensure compatibility between `antd` and your React version.\n-   **Other UI libraries**: Avoid conflicts with other UI libraries by using consistent styling and naming conventions.\n\n### 6.5. Debugging\n\n-   **Use browser developer tools**: Inspect the DOM, network requests, and console output.\n-   **Use React DevTools**: Inspect the component tree, props, and state.\n-   **Use logging and debugging statements**: Add `console.log` statements to trace the execution flow and inspect variable values.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n-   **IDE**: VS Code, WebStorm.\n-   **Build Tool**: Webpack, Parcel, Rollup, esbuild.\n-   **Testing Libraries**: Jest, React Testing Library, Cypress.\n-   **Linting**: ESLint, Prettier.\n\n### 7.2. Build Configuration\n\n-   **Optimize for production**: Use production-specific build configurations to minimize bundle size and improve performance.\n-   **Configure code splitting**: Set up code splitting to load components on demand.\n-   **Enable tree shaking**: Ensure your build process supports tree shaking to remove unused code.\n\n### 7.3. Linting and Formatting\n\n-   **ESLint**: Use ESLint with recommended React and `antd` plugins to enforce coding standards and detect potential errors.\n-   **Prettier**: Use Prettier to automatically format your code for consistency.\n-   **Stylelint:** Use Stylelint to enforce consistent style practices.\n\n### 7.4. Deployment\n\n-   **Choose a hosting platform**:  Netlify, Vercel, AWS, Google Cloud, Azure.\n-   **Configure environment variables**:  Set up environment variables for API keys, database credentials, and other sensitive information.\n-   **Use a CDN**: Use a Content Delivery Network (CDN) to cache static assets and improve loading times.\n\n### 7.5. CI/CD Integration\n\n-   **Set up a CI/CD pipeline**: Use tools like Jenkins, Travis CI, CircleCI, or GitHub Actions to automate testing, building, and deployment.\n-   **Automate testing**: Run unit, integration, and end-to-end tests in your CI/CD pipeline.\n-   **Automate deployment**: Automate the deployment process to reduce manual effort and errors.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "ant-design.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "ant",
      "design",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "using",
      "ant-design",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ant-design",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-anyio",
    "description": "This rule provides best practices and coding standards for developing with the AnyIO library, focusing on structured concurrency, task management, and proper use of synchronization primitives to create robust, cross-backend asynchronous applications.",
    "author": "sanjeed5",
    "tags": [
      "anyio",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/anyio.mdc",
    "content": "# AnyIO Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for developing with the AnyIO library, covering code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and recommended tooling.\n\n## Library Information:\n- Name: anyio\n- Tags: python, async, compatibility-layer\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:** Organize your project to separate concerns clearly.\n    - `src/`: Contains the main application code.\n    - `tests/`: Contains unit, integration, and end-to-end tests.\n    - `examples/`: Contains example code showcasing AnyIO features.\n    - `docs/`: Contains project documentation (using Sphinx, for example).\n    - `tasks.py`: Invoke tasks for building, testing, and deploying (using Invoke).\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - `my_component.py` for a component's source code.\n    - `my_component_test.py` for its tests.\n    - `conftest.py` in the `tests/` directory for test fixtures.\n- **Module Organization:**\n    - Group related functionality into modules.\n    - Use packages to further structure your code.\n    - Employ clear and concise module-level docstrings.\n- **Component Architecture:**\n    - Design components with clear responsibilities.\n    - Use interfaces or abstract base classes for decoupling.\n    - Consider using dependency injection to improve testability.\n- **Code Splitting:**\n    - Break down large functions into smaller, more manageable ones.\n    - Decompose complex modules into simpler sub-modules.\n    - Consider lazy-loading modules or components to improve startup time.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Task Groups (Nurseries):**  Use task groups (`anyio.create_task_group()`) for structured concurrency. This is the most crucial pattern in AnyIO.\n    - **Resource Acquisition Is Initialization (RAII):**  Use `async with` statements for managing resources (e.g., sockets, files) to ensure proper cleanup, even in case of exceptions or cancellations.\n    - **Observer Pattern:**  Use AnyIO's `Event` or `Condition` primitives to implement observer patterns for asynchronous communication.\n    - **Producer-Consumer Pattern:**  Use `anyio.Queue` for implementing producer-consumer patterns with asynchronous tasks.\n- **Recommended Approaches:**\n    - Use `anyio.sleep()` for non-blocking delays.\n    - Employ `anyio.to_thread.run_sync()` to run blocking code in a separate thread to avoid blocking the event loop.\n    - Utilize `anyio.Path` for asynchronous file I/O operations.\n- **Anti-patterns:**\n    - **Blocking the Event Loop:** Avoid performing long-running synchronous operations in the main event loop. Use `anyio.to_thread.run_sync()` to offload such tasks to worker threads.\n    - **Ignoring Exceptions:** Always handle exceptions gracefully within tasks and task groups. Unhandled exceptions can crash your application.\n    - **Unstructured Concurrency:** Avoid creating tasks without a task group. This can lead to resource leaks and difficult-to-debug issues.\n    - **Spin Locks:** Do not use busy-waiting or spin locks in asynchronous code. Use synchronization primitives like `Lock` or `Condition` instead.\n- **State Management:**\n    - Use immutable data structures whenever possible to avoid race conditions.\n    - Employ `Lock` or `Condition` objects to protect shared mutable state.\n    - Consider using atomic operations for simple state updates.\n- **Error Handling:**\n    - Wrap code in `try...except` blocks to catch exceptions.\n    - Use `try...finally` blocks to ensure cleanup, even in case of exceptions.\n    - Leverage task groups to handle exceptions across multiple tasks.\n    - Implement retry mechanisms for transient errors.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Asynchronous I/O:** Utilize AnyIO's asynchronous I/O functions (e.g., `anyio.Path`, `anyio.open_file`) for optimal performance when dealing with I/O-bound operations.\n    - **Connection Pooling:** Implement connection pooling for database connections or other network resources to reduce overhead.\n    - **Caching:** Cache frequently accessed data to minimize I/O operations.\n    - **Minimize Context Switching:** Reduce unnecessary context switching by batching operations and avoiding excessive `await` calls.\n- **Memory Management:**\n    - Avoid creating large, unnecessary data structures.\n    - Use generators or iterators to process large datasets in a memory-efficient manner.\n    - Properly close resources (e.g., sockets, files) to release memory.\n    - Use the `del` statement or `weakref` to break circular references and allow garbage collection.\n- **Rendering Optimization:** N/A (AnyIO is not directly involved in rendering).\n- **Bundle Size Optimization:** N/A (AnyIO itself is a dependency, not a frontend bundle).\n- **Lazy Loading:**\n    - Use lazy loading to defer the initialization of components until they are needed.\n    - Implement code splitting to load modules on demand.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Denial of Service (DoS):** Protect against DoS attacks by limiting the number of concurrent connections or requests.\n    - **Injection Attacks:** Sanitize user inputs to prevent injection attacks (e.g., SQL injection, command injection).\n    - **Cross-Site Scripting (XSS):** N/A (AnyIO is not directly involved in front-end development).\n- **Input Validation:**\n    - Validate all user inputs to ensure they conform to expected formats and ranges.\n    - Use input validation libraries to simplify the process.\n    - Escape or sanitize user inputs before using them in database queries or system commands.\n- **Authentication and Authorization:**\n    - Implement authentication to verify the identity of users.\n    - Implement authorization to control access to resources based on user roles.\n    - Use secure password hashing algorithms (e.g., bcrypt, Argon2).\n- **Data Protection:**\n    - Use encryption to protect sensitive data at rest and in transit.\n    - Store cryptographic keys securely.\n    - Comply with relevant data privacy regulations (e.g., GDPR, CCPA).\n- **Secure API Communication:**\n    - Use HTTPS for all API communication to encrypt data in transit.\n    - Implement proper authentication and authorization mechanisms for API endpoints.\n    - Protect against Cross-Site Request Forgery (CSRF) attacks if your API is used by web applications.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - Write unit tests for individual components to verify their functionality.\n    - Use mocking or stubbing to isolate components from their dependencies.\n    - Aim for high test coverage to ensure that all code paths are tested.\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between different components.\n    - Test the integration with external services (e.g., databases, APIs).\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the entire application flow.\n    - Simulate real user interactions to test the application from a user's perspective.\n- **Test Organization:**\n    - Organize tests into separate modules based on the components or features they test.\n    - Use a consistent naming convention for test files and functions.\n    - Employ test fixtures to set up and tear down test environments.\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to replace dependencies with mock objects.\n    - Stub external services or APIs to simulate different scenarios.\n    - Verify that mock objects are called with the expected arguments.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Not using `async with` for resources:** Forgetting to use `async with` for resources that require asynchronous cleanup can lead to resource leaks.\n    - **Mixing asyncio and Trio idioms:** Avoid mixing idioms from different asynchronous frameworks. Stick to AnyIO's API.\n    - **Incorrectly using `to_thread.run_sync`:**  Ensure that the code passed to `to_thread.run_sync` is actually blocking.\n- **Edge Cases:**\n    - **Cancellation:** Be aware of how cancellation works in AnyIO and handle it gracefully.\n    - **Timeouts:** Implement timeouts to prevent tasks from running indefinitely.\n    - **Signal Handling:** Properly handle signals (e.g., `SIGINT`, `SIGTERM`) to ensure graceful shutdown.\n- **Version-Specific Issues:**\n    - Consult the AnyIO changelog for known issues and breaking changes in different versions.\n- **Compatibility Concerns:**\n    - Ensure that AnyIO is compatible with the versions of asyncio or Trio you are using.\n    - Be aware of potential compatibility issues with other libraries that use asynchronous programming.\n- **Debugging Strategies:**\n    - Use logging to trace the execution flow of your code.\n    - Employ debuggers (e.g., `pdb`, `ipdb`) to step through your code and inspect variables.\n    - Use asynchronous debugging tools to debug asynchronous code.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **Python:** Use the latest stable version of Python (3.10+ recommended).\n    - **Poetry/Pip:** Use Poetry or Pip for dependency management.\n    - **Pytest:** Use Pytest for testing.\n    - **Black/Ruff:** Use Black and Ruff for code formatting and linting.\n    - **VS Code/PyCharm:** Use VS Code or PyCharm as your IDE.\n- **Build Configuration:**\n    - Use a `pyproject.toml` file to configure Poetry or Pip.\n    - Specify dependencies and build settings in the `pyproject.toml` file.\n    - Use a `setup.py` file for projects that need to be installed with `pip install -e .`\n- **Linting and Formatting:**\n    - Configure Black and Ruff to enforce consistent code formatting and style.\n    - Use a pre-commit hook to automatically format and lint code before committing.\n- **Deployment:**\n    - Package your application into a Docker container for easy deployment.\n    - Use a process manager (e.g., systemd, Supervisor) to manage your application.\n    - Deploy your application to a cloud platform (e.g., AWS, Azure, GCP).\n- **CI/CD Integration:**\n    - Use a CI/CD pipeline to automate the build, test, and deployment process.\n    - Integrate your CI/CD pipeline with your version control system (e.g., GitHub, GitLab, Bitbucket).\n    - Use automated testing to ensure that code changes do not introduce regressions.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "anyio.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "anyio",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "anyio",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-apollo-client",
    "description": "This rule provides comprehensive best practices for using Apollo Client in your projects, covering code organization, performance, security, testing, and common pitfalls. It aims to guide developers in building robust and maintainable GraphQL-powered applications.",
    "author": "sanjeed5",
    "tags": [
      "apollo-client",
      "graphql",
      "api",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/apollo-client.mdc",
    "content": "- **Code Organization and Structure:**\n  - **Directory Structure:**\n    - Organize GraphQL queries and mutations in a dedicated directory (e.g., `graphql` or `queries`).\n    - Group related queries and mutations into subdirectories based on features or modules.\n    - Consider a separate directory for GraphQL types/schemas if you're managing them locally.\n    - Example:\n      \n      src/\n        graphql/\n          user/\n            getUser.gql\n            createUser.gql\n          product/\n            getProduct.gql\n            updateProduct.gql\n      \n  - **File Naming Conventions:**\n    - Use descriptive names for GraphQL query and mutation files (e.g., `getUser.gql`, `updateProduct.gql`).\n    - Employ a consistent naming scheme (e.g., `[operationName].[operationType].gql`).\n  - **Module Organization:**\n    - Encapsulate Apollo Client logic (e.g., initialization, hooks) within reusable modules.\n    - Create custom hooks for common data fetching patterns (e.g., `useUser`, `useProduct`).\n  - **Component Architecture:**\n    - Favor a component-based architecture for UI development.\n    - Decouple data fetching logic from UI components using hooks or render props.\n    - Utilize higher-order components (HOCs) or render props for cross-cutting concerns (e.g., authentication, error handling).\n  - **Code Splitting:**\n    - Use dynamic imports to lazy-load components and queries, improving initial load time.\n    - Split large queries into smaller fragments to reduce bundle size.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Repository Pattern:** Abstract data access logic behind a repository interface.\n    - **Facade Pattern:** Provide a simplified interface to a complex subsystem (e.g., Apollo Client).\n    - **Hook Composition:** Combine multiple custom hooks to create more complex data fetching logic.\n  - **Recommended Approaches:**\n    - Use the `useQuery` and `useMutation` hooks for data fetching and manipulation.\n    - Leverage Apollo Client's cache for improved performance and offline capabilities.\n    - Implement optimistic updates to provide a better user experience.\n    - Use GraphQL fragments to reuse common data structures across multiple queries and mutations.\n  - **Anti-patterns:**\n    - Avoid directly manipulating the Apollo Client cache outside of mutations.\n    - Don't fetch the entire schema unnecessarily; only fetch what you need.\n    - Avoid deeply nested components with complex data fetching logic.\n  - **State Management:**\n    - Use Apollo Client's cache as the primary source of truth for application state.\n    - Integrate with external state management libraries (e.g., Redux, Zustand) when necessary for complex state requirements.\n    - Consider using Apollo Link State for managing local client-side state.\n  - **Error Handling:**\n    - Implement global error handling with Apollo Link.\n    - Display user-friendly error messages to the user.\n    - Retry failed queries or mutations automatically.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use the `fetchPolicy` option in `useQuery` to control cache behavior.\n    - Implement pagination for large datasets.\n    - Use batching and caching at the server-side to reduce network requests.\n  - **Memory Management:**\n    - Unsubscribe from subscriptions when components unmount to prevent memory leaks.\n    - Avoid storing large amounts of data in the Apollo Client cache.\n  - **Rendering Optimization:**\n    - Use React's `memo` or `useMemo` to prevent unnecessary re-renders.\n    - Implement virtualization for rendering large lists.\n  - **Bundle Size Optimization:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused dependencies.\n    - Minify and compress your code.\n  - **Lazy Loading:**\n    - Lazy-load components and queries using dynamic imports.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - **GraphQL Injection:** Prevent injection attacks by validating user input and using parameterized queries.\n    - **Denial of Service (DoS):** Limit query complexity and depth to prevent DoS attacks.\n    - **Information Disclosure:** Avoid exposing sensitive data in error messages.\n  - **Input Validation:**\n    - Validate all user input on both the client and server sides.\n    - Use GraphQL's built-in validation capabilities.\n  - **Authentication and Authorization:**\n    - Implement proper authentication and authorization mechanisms.\n    - Use JWT (JSON Web Tokens) or other secure authentication protocols.\n    - Follow the principle of least privilege when granting access to data.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all API communication.\n  - **Secure API Communication:**\n    - Use Apollo Link to add security headers to API requests.\n    - Implement CORS (Cross-Origin Resource Sharing) to prevent cross-site scripting (XSS) attacks.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Test individual components and hooks in isolation.\n    - Mock Apollo Client's API to control data fetching behavior.\n  - **Integration Testing:**\n    - Test the integration of components with Apollo Client.\n    - Use a test GraphQL server to simulate real API interactions.\n  - **End-to-end Testing:**\n    - Test the entire application flow from the user interface to the backend.\n    - Use tools like Cypress or Puppeteer for end-to-end testing.\n  - **Test Organization:**\n    - Organize tests in a directory structure that mirrors the source code.\n    - Use descriptive names for test files and test cases.\n  - **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., Jest, Sinon) to mock Apollo Client's API.\n    - Create stub GraphQL responses for testing different scenarios.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Incorrect cache configuration leading to stale data.\n    - Over-fetching data in GraphQL queries.\n    - Ignoring error handling in `useQuery` and `useMutation`.\n  - **Edge Cases:**\n    - Handling network errors and offline scenarios.\n    - Dealing with large datasets and complex queries.\n    - Managing cache invalidation and updates.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between Apollo Client versions.\n    - Consult the Apollo Client documentation for migration guides.\n  - **Compatibility Concerns:**\n    - Ensure compatibility with different browsers and devices.\n    - Test your application on different platforms.\n  - **Debugging Strategies:**\n    - Use Apollo Client DevTools to inspect queries, mutations, and cache state.\n    - Log API requests and responses for debugging purposes.\n\n- **Tooling and Environment:**\n  - **Recommended Tools:**\n    - Apollo Client DevTools for debugging and inspecting the cache.\n    - GraphQL Playground or GraphiQL for exploring and testing GraphQL APIs.\n    - Apollo VS Code extension for syntax highlighting and autocompletion.\n  - **Build Configuration:**\n    - Use a build tool like Webpack or Parcel to bundle your code.\n    - Configure Babel to transpile your code to compatible JavaScript versions.\n  - **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce code style and best practices.\n    - Configure linting rules specific to Apollo Client and GraphQL.\n  - **Deployment:**\n    - Use a deployment platform like Netlify, Vercel, or AWS Amplify.\n    - Configure environment variables for API endpoints and other sensitive data.\n  - **CI/CD Integration:**\n    - Use a CI/CD pipeline to automate testing and deployment.\n    - Integrate linters, formatters, and test runners into the pipeline.\n\n- **Specific Best Practices based on Exa Search Results:**\n  - Ensure all queries for a specific type return an ID for normalization and caching (RedwoodJS Community).\n  - Store queries in separate `.gql` files and use tools like `graphql-import` for better organization (Reddit).\n  - Use Apollo Client's `watchQuery` method for real-time data updates (Medium).\n  - Follow GraphQL query best practices for efficient API design (Apollo GraphQL).\n\n- **Additional considerations**\n  - When creating queries and mutations, follow best practices to get the most out of both GraphQL and Apollo tooling.\n\n- **Example Directory Structure**\n\nsrc/\n  components/\n    UserCard.tsx\n    ProductDetails.tsx\n  graphql/\n    queries/\n      getUser.gql\n      getProduct.gql\n    mutations/\n      createUser.gql\n      updateProduct.gql\n  hooks/\n    useUser.ts\n    useProduct.ts\n  utils/\n    apolloClient.ts // Initialize Apollo Client here\n\n\nThis is a comprehensive guide for using Apollo Client. Please adapt these guidelines to your specific project requirements and coding style.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.gql,*.graphql",
      "format": "mdc",
      "originalFile": "apollo-client.mdc"
    },
    "subcategory": "other",
    "keywords": [
      "cursor",
      "apollo",
      "client",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "your",
      "apollo-client",
      "graphql",
      "api",
      "backend",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "other"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "apollo-client",
        "graphql",
        "api",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-apollo-graphql",
    "description": "This rule provides comprehensive best practices and coding standards for developing with Apollo GraphQL. It covers schema design, security, performance, testing, and deployment.",
    "author": "sanjeed5",
    "tags": [
      "apollo-graphql",
      "graphql",
      "api",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/apollo-graphql.mdc",
    "content": "- Always use UV when installing dependencies\n- Always use python 3.12\n- Always use classes instead of function\n\n# Apollo GraphQL Best Practices\n\nThis document provides a comprehensive guide to best practices and coding standards for developing GraphQL APIs and applications using the Apollo ecosystem.\n\n## Library Information:\n- Name: apollo-graphql\n- Tags: web, api, graphql, javascript\n\n## 1. Schema Design\n\n- **Clarity and Consistency:**\n    - Use descriptive naming conventions for types, fields, and arguments (e.g., `getUserById` instead of `getUser`).\n    - Maintain consistency across the schema in terms of naming and structure.\n    - Define a clear schema that reflects your business domain and data model.\n\n- **Interfaces and Unions:**\n    - Implement interfaces and unions for shared features and common data structures.\n    - Use interfaces to define contracts for types that implement shared behaviors.\n    - Use unions when a field can return different object types that don't share a common interface.\n\n- **Nullability:**\n    - Every field is nullable by default unless explicitly marked as non-null using `!`.  Carefully consider nullability for each field.\n    - Use non-null types (`!`) only when you can guarantee that the field will always return a value.\n    - Handle potential errors gracefully and return `null` for nullable fields when appropriate.\n\n- **Demand-Driven Schema Design:**\n   - Design your schema to serve client use cases and product requirements.\n   - Intentionally design your schema to serve client use cases and product requirements.\n\n- **Avoid Autogenerated Schemas:**\n    - Avoid autogenerating schemas, especially the fields on the root operation types\n\n## 2. Security\n\n- **Disable Introspection in Production:**\n    - Disable introspection in production environments to prevent unauthorized access to your schema.\n    - Restrict access to staging environments where introspection is enabled.\n\n- **Input Validation:**\n    - Validate all user inputs to prevent injection attacks and data corruption.\n    - Use custom scalars or directives to enforce validation rules on input types.\n    - Sanitize and escape user inputs before using them in resolvers.\n\n- **Authentication and Authorization:**\n    - Implement robust authentication and authorization mechanisms to protect your API.\n    - Use industry-standard protocols like OAuth 2.0 or JWT for authentication.\n    - Implement fine-grained authorization checks at the field level.\n    - Enforcing authentication and authorization in the router protects your underlying APIs from malicious operations\n\n- **Rate Limiting and Depth Limiting:**\n    - Implement rate limiting to prevent abuse and denial-of-service attacks.\n    - Limit query depth to prevent complex queries from overwhelming your server.\n\n- **Whitelisting Queries:**\n    - Consider whitelisting queries to restrict the operations that can be executed against your API.\n\n- **Obfuscate Error Details:**\n    - Remove verbose error details from API responses in your production graph.\n    - Only selectively expose error details to clients in production.\n\n- **Data Validation and Sanitization:**\n    - As a schema design best practice, you should deliberately design your schema to serve client use cases and product requirements.\n\n## 3. Performance Optimization\n\n- **Batching and Caching:**\n    - Utilize batching techniques (e.g., DataLoader) to reduce the number of requests to backend data sources.\n    - Implement caching at different levels (e.g., server-side, client-side) to improve response times.\n\n- **Pagination:**\n    - Implement pagination strategies to manage large datasets effectively.\n    - Use cursor-based pagination for efficient retrieval of paginated data.\n\n- **N+1 Problem:**\n    - Use tools like DataLoader to address the N+1 query problem and ensure efficient data fetching.\n\n- **Server-Side Batching &amp; Caching:**\n    - GraphQL is designed in a way that allows you to write clean code on the server, where every field on every type has a focused single-purpose function for resolving that value.\n\n- **Automatic Persisted Queries (APQ):**\n    - Consider implementing automatic persisted queries (APQ) to optimize network usage and improve security\n\n## 4. Code Organization and Structure\n\n- **Directory Structure:**\n    \n    src/\n      schema/\n        types/\n          *.graphql\n        resolvers/\n          *.js\n      dataSources/\n        *.js\n      utils/\n        *.js\n      index.js // Entry point\n    \n\n- **File Naming Conventions:**\n    - Use PascalCase for type definitions (e.g., `UserType.graphql`).\n    - Use camelCase for resolver functions (e.g., `getUserById.js`).\n\n- **Module Organization:**\n    - Organize your code into reusable modules based on functionality (e.g., user management, product catalog).\n    - Create separate modules for schema definitions, resolvers, and data sources.\n\n- **Component Architecture:**\n    - Follow a component-based architecture for building GraphQL applications.\n    - Create reusable components for common UI elements and data fetching logic.\n\n- **Code Splitting:**\n    - Use code splitting to reduce the initial bundle size and improve page load times.\n    - Consider splitting your application into smaller chunks based on routes or features.\n\n## 5. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Data Source Pattern:** Decouple data fetching logic from resolvers using data sources.\n    - **Schema Stitching:** Combine multiple GraphQL APIs into a single, unified schema.\n\n- **Recommended Approaches:**\n    - Use a GraphQL client library (e.g., Apollo Client, Relay) for efficient data fetching and caching.\n    - Implement custom directives to add additional functionality to your schema.\n\n- **Anti-patterns:**\n    - **Over-fetching/Under-fetching:** Avoid returning more or less data than required by the client.\n    - **Chatty APIs:** Reduce the number of round trips between the client and the server.\n    - **God Objects:** Avoid creating large, monolithic types with too many fields.\n\n- **State Management:**\n    - Use a state management library (e.g., Redux, Zustand, Jotai) to manage client-side state.\n    - Consider using Apollo Client's local state management features for simple state requirements.\n\n- **Error Handling:**\n    - Use a consistent error handling mechanism across your application.\n    - Return informative error messages to the client.\n    - Log errors on the server for debugging purposes.\n\n## 6. Testing Approaches\n\n- **Unit Testing:**\n    - Unit test individual resolvers and data sources.\n    - Mock external dependencies to isolate the code under test.\n\n- **Integration Testing:**\n    - Integrate test your GraphQL API with your database and other backend services.\n    - Use a testing framework like Jest or Mocha for writing integration tests.\n\n- **End-to-End Testing:**\n    - Use end-to-end testing to verify the entire application flow.\n    - Use a testing tool like Cypress or Puppeteer for writing end-to-end tests.\n\n- **Test Organization:**\n    - Organize your tests into separate directories based on functionality.\n    - Use descriptive names for your test files and test cases.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing techniques to isolate the code under test and simulate external dependencies.\n\n## 7. Common Pitfalls and Gotchas\n\n- **N+1 Problem:** Be aware of the N+1 query problem and use DataLoader or other batching techniques to solve it.\n- **Schema Evolution:** Plan for schema evolution and use techniques like adding new fields and deprecating old ones to avoid breaking changes.\n- **Performance Bottlenecks:** Monitor your API for performance bottlenecks and use profiling tools to identify slow resolvers.\n- **Nullability:** Ensure that non-null fields never return `null` to avoid unexpected errors.\n\n## 8. Tooling and Environment\n\n- **Development Tools:**\n    - Use a GraphQL IDE like GraphiQL or Apollo Studio for exploring and testing your API.\n    - Use code generation tools to generate types and resolvers from your schema.\n\n- **Build Configuration:**\n    - Use a build tool like Webpack or Parcel to bundle your code for production.\n    - Configure your build tool to optimize your code and reduce bundle size.\n\n- **Linting and Formatting:**\n    - Use a linter like ESLint or Prettier to enforce code style and prevent errors.\n\n- **Deployment:**\n    - Deploy your GraphQL API to a production environment like AWS Lambda, Google Cloud Functions, or a Node.js server.\n    - Use a serverless platform for easy scaling and management.\n\n- **CI/CD Integration:**\n    - Integrate your GraphQL API with a CI/CD pipeline for automated testing and deployment.\n\n## 9. Additional Best Practices\n\n- **Versioning:** While GraphQL promotes continuous evolution, consider versioning your API if you need to make breaking changes.\n- **Documentation:** Provide comprehensive documentation for your GraphQL API using tools like GraphQL Docs.\n- **Monitoring:** Monitor your GraphQL API for performance and errors using tools like Apollo Studio or New Relic.\n- **Error Messages and Notifications:** You can also opt for union types to represent an error and to prompt suggestions to users, though this is a more expensive choice.\n\n## 10. Global Identification\n\n- Another way to organize components, besides Pagination, is by using a global identification. Originally proposed on Relay and similar to URIs, this method has become a more general good practice though it is not considered mandatory — especially if you are not planning on supporting Relay in your application\n\n## 11. Rate Limiting\n\n-  Like any other web API, setting limits is a good strategy to avoid, for example, an overload of requests per minute. There are a few ways this can be done in GraphQL\n\n## 12. Authentication and Authorization\n\n- Often interchanged in their meaning, authentication is the act of determining who a user is and whether they are logged in or not. Authorization, on the other hand, is the act of determining if a user is allowed to do an action or see something.\n\n## 13. Safelisting with Persisted queries\n\n-  Beyond operation limits, GraphOS enables first-party apps to register trusted operations in a persisted query list ( PQL) or safelist.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.graphql",
      "format": "mdc",
      "originalFile": "apollo-graphql.mdc"
    },
    "subcategory": "other",
    "keywords": [
      "cursor",
      "apollo",
      "graphql",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "apollo-graphql",
      "api",
      "backend",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "other"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "apollo-graphql",
        "graphql",
        "api",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-asp-net",
    "description": "This rule file provides best practices and coding standards for ASP.NET Core development, covering various aspects from code organization to security and performance optimization.",
    "author": "sanjeed5",
    "tags": [
      "asp-net",
      "aspnet",
      "csharp",
      "dotnet",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/asp-net.mdc",
    "content": "# ASP.NET Core Best Practices and Coding Standards\n\nThis document outlines recommended best practices and coding standards for developing ASP.NET Core applications. Following these guidelines will help ensure code clarity, maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\n### Directory Structure Best Practices:\n\nA well-defined directory structure is crucial for maintaining a scalable and organized ASP.NET Core project. Here's a suggested structure:\n\n\nProjectName/\n├── src/\n│   ├── ProjectName.Web/\n│   │   ├── Controllers/\n│   │   ├── Models/\n│   │   ├── Views/\n│   │   ├── Pages/ (for Razor Pages)\n│   │   ├── wwwroot/\n│   │   ├── appsettings.json\n│   │   ├── Program.cs\n│   │   ├── Startup.cs\n│   ├── ProjectName.Data/\n│   │   ├── Models/\n│   │   ├── Contexts/\n│   │   ├── Repositories/\n│   │   ├── Migrations/\n│   ├── ProjectName.Services/\n│   │   ├── Interfaces/\n│   │   ├── Implementations/\n│   ├── ProjectName.Models/ (if different from Data Models)\n├── tests/\n│   ├── ProjectName.UnitTests/\n│   ├── ProjectName.IntegrationTests/\n├── artifacts/\n├── .editorconfig\n├── .gitignore\n├── ProjectName.sln\n\n\n*   **src:** Contains the source code of the application.\n*   **ProjectName.Web:** The main web application project.  This can also be named `API` for web API projects.\n*   **Controllers:** Contains ASP.NET Core controllers.\n*   **Models:** Contains view models and other data transfer objects (DTOs) specific to the web layer.\n*   **Views:** Contains Razor views (.cshtml files).\n*   **Pages:** Contains Razor Pages (if using Razor Pages model).\n*   **wwwroot:** Contains static files like CSS, JavaScript, and images.\n*   **ProjectName.Data:** Contains data access logic, Entity Framework Core contexts, and models representing database entities.\n*   **Models (Data):** Defines entity models that correspond to database tables.\n*   **Contexts:**  Contains the DbContext class.\n*   **Repositories:** Contains repositories for data access.\n*   **Migrations:** Contains Entity Framework Core migrations.\n*   **ProjectName.Services:** Contains business logic and application services.\n*   **Interfaces:** Defines interfaces for services.\n*   **Implementations:** Contains concrete implementations of service interfaces.\n*   **ProjectName.Models:** (Optional) Contains domain models that are shared across multiple layers. This layer promotes separation of concerns if your data layer models should not be exposed at the API or Web layer.\n*   **tests:** Contains unit and integration tests.\n*   **ProjectName.UnitTests:** Contains unit tests.\n*   **ProjectName.IntegrationTests:** Contains integration tests.\n*   **artifacts:**  Contains build artifacts.\n*   **.editorconfig:** Defines code style rules.\n*   **.gitignore:** Specifies intentionally untracked files that Git should ignore.\n*   **ProjectName.sln:** The solution file.\n\n### File Naming Conventions:\n\n*   **Classes:** PascalCase (e.g., `UserController`, `ProductService`)\n*   **Interfaces:** IPascalCase (e.g., `IProductService`, `IUserRepository`)\n*   **Methods:** PascalCase (e.g., `GetProduct`, `CreateUser`)\n*   **Variables (local):** camelCase (e.g., `productName`, `userId`)\n*   **Parameters:** camelCase (e.g., `productId`, `userName`)\n*   **Constants:** PascalCase (e.g., `DefaultPageSize`, `MaxRetries`)\n*   **Enums:** PascalCase (e.g., `OrderStatus`, `UserRole`)\n*   **Namespaces:** PascalCase, mirroring the directory structure (e.g., `ProjectName.Web.Controllers`, `ProjectName.Services.Implementations`)\n*   **Files:** Match the class/interface name (e.g., `UserController.cs`, `IProductService.cs`)\n\n### Module Organization:\n\n*   **Feature-based Modules:** Group related functionality into modules based on features (e.g., `Authentication`, `Products`, `Orders`).  Each feature can have its own folder within the `src` directory, containing its own controllers, models, services, and data access components.  This enhances cohesion and reduces coupling.\n*   **Vertical Slices:** Organize modules around specific use cases or user stories.  Each slice contains all the code necessary to implement a particular feature, from the UI to the data access layer. This promotes faster development and easier maintenance.\n\n### Component Architecture:\n\n*   **Layered Architecture:** Divide the application into layers (e.g., Presentation, Application, Domain, Infrastructure) to separate concerns and promote testability. Each layer has a specific responsibility and interacts with other layers through well-defined interfaces.\n*   **Microservices:**  For larger applications, consider breaking down the application into smaller, independent microservices. Each microservice handles a specific business capability and can be deployed and scaled independently.\n\n### Code Splitting Strategies:\n\n*   **Feature-based Splitting:** Split code based on features, loading modules only when they are needed. This can improve initial load time and reduce memory consumption.\n*   **Route-based Splitting:** Load code only when a specific route is accessed. This is especially useful for large applications with many routes.\n*   **On-Demand Loading:** Load code dynamically when a user interacts with a specific component. This can improve perceived performance and reduce the initial download size.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns:\n\n*   **Dependency Injection (DI):** Use the built-in DI container to manage dependencies and promote loose coupling.\n*   **Repository Pattern:** Abstract data access logic behind repositories to improve testability and maintainability. Avoid exposing EF Core `IQueryable` outside of the repository.\n*   **Unit of Work Pattern:** Encapsulate multiple operations into a single transaction to ensure data consistency.\n*   **CQRS (Command Query Responsibility Segregation):** Separate read and write operations into separate models to optimize performance and scalability.\n*   **Mediator Pattern:** Decouple components by routing messages through a central mediator.  Libraries like MediatR are excellent for this.\n*   **Specification Pattern:**  Encapsulate complex query logic into reusable specification objects.\n*   **Strategy Pattern:** Define a family of algorithms, encapsulate each one, and make them interchangeable.\n\n### Recommended Approaches for Common Tasks:\n\n*   **Configuration:** Use the `IOptions<T>` pattern to access configuration settings in a strongly-typed manner.\n*   **Logging:** Use the `ILogger<T>` interface for logging. Configure logging providers in `appsettings.json` and leverage structured logging.\n*   **Exception Handling:** Implement global exception handling middleware to handle unhandled exceptions and return appropriate error responses.\n*   **Data Validation:** Use data annotations and the `ModelState` property for validating user input. Implement custom validation attributes for complex validation rules.\n*   **Asynchronous Programming:** Use `async` and `await` for I/O-bound operations to avoid blocking threads.\n*   **HTTP Requests:** Utilize `HttpClientFactory` for creating and managing `HttpClient` instances.\n*   **Background Tasks:** Use hosted services or background worker services for running long-running tasks asynchronously.\n\n### Anti-patterns and Code Smells:\n\n*   **Tight Coupling:** Avoid tight coupling between components. Use interfaces and dependency injection to promote loose coupling.\n*   **God Classes:** Avoid creating large classes with too many responsibilities. Break down large classes into smaller, more manageable classes.\n*   **Shotgun Surgery:** Avoid making changes to multiple classes when a single responsibility changes. This indicates poor separation of concerns.\n*   **Primitive Obsession:** Avoid using primitive types to represent domain concepts. Create value objects to encapsulate domain logic and validation rules.\n*   **Feature Envy:** Avoid classes that access the data of another class more than their own. Move the method to the class where the data resides.\n*   **Sync-over-Async:**  Avoid using `Task.Wait()` or `Task.Result` in asynchronous methods, as this can lead to thread pool starvation. Always use `await`.\n*   **Ignoring Exceptions:** Avoid catching exceptions and not logging or handling them appropriately.\n*   **Magic Strings/Numbers:** Avoid hardcoding values directly in the code.  Use constants or configuration settings instead.\n*   **Returning raw Entities:**  Do not expose EF Core entities directly to the client.  Create DTOs or View Models to represent the data that needs to be returned.\n\n### State Management Best Practices:\n\n*   **Stateless Controllers:** Design controllers to be stateless. Avoid storing state in controller fields.\n*   **Session State:** Use session state sparingly. Session state can impact scalability. Consider using a distributed cache for session state.\n*   **Cookies:** Use cookies for storing small amounts of non-sensitive data. Be mindful of cookie size limits and security concerns.\n*   **TempData:** Use TempData for passing data between redirects.  TempData is stored in session or cookies.\n*   **Caching:** Use caching (memory cache, distributed cache, response caching) to improve performance and reduce database load.  Cache aggressively, but invalidate appropriately.\n\n### Error Handling Patterns:\n\n*   **Global Exception Handling:** Implement global exception handling middleware to catch unhandled exceptions and return consistent error responses.\n*   **Exception Filters:** Use exception filters to handle exceptions at the controller level.\n*   **Try-Catch Blocks:** Use try-catch blocks for handling expected exceptions.\n*   **Problem Details:** Return problem details (RFC 7807) in error responses to provide more detailed information about the error.\n*   **Idempotency:** Design APIs to be idempotent where possible, so that retries are safe.\n\n## 3. Performance Considerations\n\n### Optimization Techniques:\n\n*   **Asynchronous Programming:** Use `async` and `await` for I/O-bound operations.\n*   **Caching:** Implement caching strategies to reduce database load and improve response times.\n*   **Response Compression:** Enable response compression to reduce the size of HTTP responses.\n*   **Minification and Bundling:** Minify and bundle CSS and JavaScript files to reduce the number of HTTP requests and improve load times.\n*   **Image Optimization:** Optimize images to reduce their file size without sacrificing quality.\n*   **Database Optimization:** Optimize database queries and indexing to improve data access performance.\n*   **Connection Pooling:** Use connection pooling to reuse database connections and reduce connection overhead.\n*   **HTTP/2:** Use HTTP/2 for improved performance and reduced latency.\n*   **Precompiled Views:**  Precompile Razor views to improve startup time. \n*   **Use Span<T> and Memory<T>:** Utilize these types for efficient memory manipulation, reducing allocations and copies.\n*   **Object Pooling:** Employ object pooling for frequently created and destroyed objects to reduce garbage collection overhead. `ArrayPool<T>` is especially effective for large arrays.\n*   **Optimize LINQ Usage:** Use LINQ effectively, avoiding unnecessary iterations and allocations. Utilize `AsNoTracking()` for read-only queries and be mindful of client-side evaluation.\n*   **Use System.Text.Json:** Prefer `System.Text.Json` over `Newtonsoft.Json` where possible, as it offers better performance and is designed for UTF-8 text.\n\n### Memory Management:\n\n*   **Minimize Object Allocations:** Reduce object allocations, especially in hot code paths. Consider using object pooling and value types.\n*   **Avoid Large Objects:** Avoid allocating large objects (>= 85,000 bytes) as they are stored on the large object heap and can cause performance issues.\n*   **Dispose of Resources:** Dispose of disposable resources (e.g., database connections, file streams) properly to prevent memory leaks.\n*   **Garbage Collection:** Understand how the garbage collector works and avoid patterns that trigger frequent garbage collections.\n\n### Rendering Optimization:\n\n*   **Partial Views:** Use partial views to reuse code and reduce code duplication.\n*   **View Components:** Use view components to encapsulate complex rendering logic.\n*   **Tag Helpers:** Use tag helpers to create reusable UI components.\n*   **Client-Side Rendering:** Consider using client-side rendering frameworks (e.g., React, Angular, Vue.js) for complex UI interactions.\n*   **Lazy Loading:** Implement lazy loading for images and other assets to improve initial load time.\n\n### Bundle Size Optimization:\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from JavaScript bundles.\n*   **Code Splitting:** Split code into smaller chunks that can be loaded on demand.\n*   **Compression:** Compress JavaScript and CSS files using gzip or Brotli.\n*   **Dead Code Elimination:** Remove unused code from the application.\n\n### Lazy Loading Strategies:\n\n*   **Lazy Loading of Images:** Load images only when they are visible in the viewport.\n*   **Lazy Loading of Modules:** Load modules only when they are needed.\n*   **Lazy Loading of Data:** Load data only when it is requested.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and Prevention:\n\n*   **SQL Injection:** Use parameterized queries or ORMs to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input and encode output to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Use anti-forgery tokens to prevent CSRF attacks.\n*   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms to protect sensitive data and functionality.\n*   **Clickjacking:** Protect against clickjacking attacks by using the X-Frame-Options header.\n*   **Denial of Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n*   **Open Redirects:**  Validate redirect URLs to prevent open redirect vulnerabilities.\n*   **Insecure Direct Object References (IDOR):** Implement proper authorization checks to prevent unauthorized access to resources.\n\n### Input Validation:\n\n*   **Server-Side Validation:** Always validate user input on the server-side.\n*   **Whitelisting:** Use whitelisting to allow only valid characters and data formats.\n*   **Data Annotations:** Use data annotations to validate model properties.\n*   **Custom Validation:** Implement custom validation attributes for complex validation rules.\n*   **Sanitization:** Sanitize user input to remove potentially harmful characters.\n\n### Authentication and Authorization:\n\n*   **Authentication Schemes:** Choose an appropriate authentication scheme (e.g., cookies, JWT, OAuth2) based on the application requirements.\n*   **Authorization Policies:** Use authorization policies to define access control rules.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to grant users access to specific resources based on their roles.\n*   **Claims-Based Authorization:** Use claims-based authorization to grant users access to specific resources based on their claims.\n*   **Secure Password Storage:** Use strong password hashing algorithms (e.g., bcrypt, Argon2) to store passwords securely.\n*   **Multi-Factor Authentication (MFA):** Implement MFA to enhance security.\n*   **Implement OWASP Recommendations:** Follow the OWASP (Open Web Application Security Project) guidelines for secure authentication and authorization.\n\n### Data Protection:\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Protection API:** Use the Data Protection API to protect sensitive data.\n*   **Key Management:** Implement proper key management practices to protect encryption keys.\n*   **HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n\n### Secure API Communication:\n\n*   **API Keys:** Use API keys to authenticate API clients.\n*   **OAuth 2.0:** Use OAuth 2.0 to authorize API clients.\n*   **JWT (JSON Web Tokens):** Use JWT for secure API authentication and authorization.\n*   **Rate Limiting:** Implement rate limiting to prevent API abuse.\n*   **Input Validation:** Implement proper input validation on the server-side to prevent injection attacks.\n*   **Output Encoding:** Encode API responses to prevent XSS attacks.\n*   **CORS (Cross-Origin Resource Sharing):** Configure CORS to allow only authorized domains to access the API.\n\n## 5. Testing Approaches\n\n### Unit Testing:\n\n*   **Test-Driven Development (TDD):** Write unit tests before writing the code.\n*   **Arrange, Act, Assert (AAA):** Follow the AAA pattern in unit tests.\n*   **Mocking:** Use mocking frameworks (e.g., Moq, NSubstitute) to isolate the code being tested.\n*   **Code Coverage:** Aim for high code coverage.\n*   **Focus on Business Logic:** Unit test the business logic of the application.\n\n### Integration Testing:\n\n*   **Test Data Access:** Test the interaction between the application and the database.\n*   **Test External Services:** Test the interaction between the application and external services.\n*   **Use a Test Database:** Use a separate test database for integration tests.\n*   **Seed the Database:** Seed the test database with test data before running integration tests.\n\n### End-to-End Testing:\n\n*   **Test the Entire Application Flow:** Test the entire application flow from the user interface to the database.\n*   **Use Automation Tools:** Use automation tools (e.g., Selenium, Cypress) to automate end-to-end tests.\n*   **Test in a Production-Like Environment:** Test in a production-like environment to ensure that the application works as expected in production.\n\n### Test Organization:\n\n*   **Separate Test Projects:** Create separate test projects for unit tests, integration tests, and end-to-end tests.\n*   **Organize Tests by Feature:** Organize tests by feature or module.\n*   **Use Naming Conventions:** Use consistent naming conventions for test classes and methods.\n\n### Mocking and Stubbing:\n\n*   **Use Mocking Frameworks:** Use mocking frameworks to create mock objects and stubs.\n*   **Mock Dependencies:** Mock external dependencies to isolate the code being tested.\n*   **Verify Interactions:** Verify that the code being tested interacts with its dependencies as expected.\n*   **Avoid Over-Mocking:** Avoid mocking too many dependencies. Focus on mocking external dependencies and complex objects.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes:\n\n*   **Incorrect Dependency Injection Configuration:** Incorrectly configuring dependency injection can lead to runtime errors.\n*   **Not Handling Exceptions Properly:** Not handling exceptions properly can lead to application crashes.\n*   **Blocking Calls:** Making blocking calls in asynchronous methods can lead to thread pool starvation.\n*   **Incorrect Data Validation:** Incorrect data validation can lead to security vulnerabilities and data corruption.\n*   **Over-Engineering:** Over-engineering the application can lead to unnecessary complexity.\n*   **Premature Optimization:** Optimizing the application too early can lead to wasted effort and code that is difficult to maintain.\n*   **Ignoring Security Best Practices:** Ignoring security best practices can lead to security vulnerabilities.\n*   **Not Writing Tests:** Not writing tests can lead to code that is difficult to maintain and prone to errors.\n*   **Leaking Database Connections:** Failing to properly dispose of database connections can exhaust connection resources and cause performance issues.\n*   **Using Sync over Async:** Blocking asynchronous operations can lead to thread pool starvation and performance degradation.\n*   **Not using HttpClientFactory correctly:** Improper disposal of `HttpClient` instances leads to socket exhaustion. Always use `HttpClientFactory`.\n\n### Edge Cases:\n\n*   **Handling Null Values:** Handle null values properly to prevent null reference exceptions.\n*   **Handling Empty Collections:** Handle empty collections properly to prevent unexpected behavior.\n*   **Handling Large Data Sets:** Handle large data sets efficiently to prevent performance issues.\n*   **Handling Time Zones:** Handle time zones correctly to prevent data inconsistencies.\n\n### Version-Specific Issues:\n\n*   **Breaking Changes:** Be aware of breaking changes between different versions of ASP.NET Core.\n*   **Deprecated Features:** Be aware of deprecated features and plan to migrate to newer features.\n*   **Performance Improvements:** Take advantage of performance improvements in newer versions of ASP.NET Core.\n*   **Security Patches:** Stay up-to-date with security patches to protect against vulnerabilities.\n\n### Compatibility Concerns:\n\n*   **.NET Framework vs .NET Core:** Be aware of the differences between .NET Framework and .NET Core and choose the appropriate framework for the application.\n*   **Operating System Compatibility:** Ensure that the application is compatible with the target operating system.\n*   **Browser Compatibility:** Ensure that the application is compatible with the target browsers.\n\n### Debugging Strategies:\n\n*   **Logging:** Use logging to track down errors and unexpected behavior.\n*   **Debugging Tools:** Use debugging tools (e.g., Visual Studio debugger) to step through the code and examine variables.\n*   **Profiling Tools:** Use profiling tools to identify performance bottlenecks.\n*   **Remote Debugging:** Use remote debugging to debug applications running on remote servers.\n*   **Diagnostic Tools:** Use diagnostic tools (e.g., Application Insights) to monitor the health and performance of the application.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools:\n\n*   **Visual Studio:** A comprehensive IDE for developing ASP.NET Core applications.\n*   **Visual Studio Code:** A lightweight and versatile code editor for developing ASP.NET Core applications.\n*   **.NET CLI:** A command-line tool for creating, building, and running ASP.NET Core applications.\n*   **NuGet Package Manager:** A package manager for managing dependencies in ASP.NET Core applications.\n*   **Postman:** A tool for testing APIs.\n*   **Fiddler:** A tool for debugging HTTP traffic.\n\n### Build Configuration:\n\n*   **Use a Build Server:** Use a build server (e.g., Azure DevOps, Jenkins) to automate the build process.\n*   **Configure Build Configurations:** Configure build configurations (e.g., Debug, Release) to optimize the application for different environments.\n*   **Use NuGet Package Restore:** Use NuGet package restore to automatically download dependencies during the build process.\n*   **Version Control:** Use version control (e.g., Git) to track changes to the code.\n\n### Linting and Formatting:\n\n*   **.editorconfig:** Use an .editorconfig file to define code style rules.\n*   **Code Analyzers:** Use code analyzers to enforce code style rules and detect potential errors.\n*   **StyleCop:** Use StyleCop to enforce coding style guidelines.\n*   **ReSharper:** Use ReSharper to improve code quality and productivity.\n*   **Format on Save:** Configure the IDE to format code on save.\n\n### Deployment Best Practices:\n\n*   **Choose a Hosting Environment:** Choose an appropriate hosting environment (e.g., Azure, AWS, on-premises server) based on the application requirements.\n*   **Configure Application Settings:** Configure application settings (e.g., connection strings, API keys) for the production environment.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **Enable Logging:** Enable logging to track errors and unexpected behavior in the production environment.\n*   **Monitor the Application:** Monitor the health and performance of the application in the production environment.\n*   **Use a Deployment Pipeline:** Automate the deployment process with a CI/CD pipeline.\n*   **Consider Containerization:** Deploy your application using containers (e.g., Docker) to ensure consistency across environments.\n*   **Implement Health Checks:** Use ASP.NET Core's built-in health checks endpoint to monitor the health of your application.\n\n### CI/CD Integration:\n\n*   **Use a CI/CD Pipeline:** Use a CI/CD pipeline (e.g., Azure DevOps, GitHub Actions, GitLab CI) to automate the build, test, and deployment process.\n*   **Automate Testing:** Automate unit tests, integration tests, and end-to-end tests in the CI/CD pipeline.\n*   **Automate Deployment:** Automate the deployment process in the CI/CD pipeline.\n*   **Implement Rollbacks:** Implement rollbacks to quickly revert to a previous version of the application if there are problems with the new deployment.",
    "metadata": {
      "globs": "*.cs",
      "format": "mdc",
      "originalFile": "asp-net.mdc"
    },
    "subcategory": "other",
    "keywords": [
      "cursor",
      "asp",
      "net",
      "this",
      "rule",
      "file",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "core",
      "development",
      "asp-net",
      "aspnet",
      "csharp",
      "dotnet",
      "backend",
      "cursor-rule",
      "mdc",
      "backend-frameworks",
      "other"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "asp-net",
        "aspnet",
        "csharp",
        "dotnet",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-astro",
    "description": "This rule provides comprehensive best practices and coding standards for developing Astro projects. It covers code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "astro",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/astro.mdc",
    "content": "# Astro Library Best Practices and Coding Standards\n\nThis document outlines the recommended best practices and coding standards for developing Astro projects to ensure maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\n### 1.1 Project Structure\n\n-   **`src/` Directory:**  This directory contains the core source code of your Astro project.\n    -   **`src/pages/`:**  This directory is crucial for routing. Every `.astro`, `.md`, or `.mdx` file in this directory automatically becomes a route. Use a clear and consistent naming convention for your pages (e.g., `about.astro`, `blog/index.astro`, `blog/[slug].astro`).\n    -   **`src/components/`:**  Store reusable UI components in this directory. Organize components into subdirectories based on their functionality or feature area (e.g., `src/components/Header/`, `src/components/Card/`).\n    -   **`src/layouts/`:** Layouts define the overall structure of your pages (e.g., header, footer, navigation).  Use layouts to maintain a consistent look and feel across your website.\n    -   **`src/content/`:**  (Recommended for content-driven sites) Use the Content Collections feature to manage structured content like blog posts, documentation, or product listings.  Define schemas for your content types to ensure data consistency.\n    -   **`src/styles/`:** Store global styles and CSS variables in this directory. Consider using CSS Modules or a CSS-in-JS solution for component-specific styling.\n    -   **`src/scripts/`:**  Place client-side JavaScript files in this directory. Use modules and avoid polluting the global scope.\n    -   **`src/assets/`:**  Store static assets like images, fonts, and other media files in this directory.\n-   **`public/` Directory:** This directory contains static assets that don't need processing, such as `robots.txt`, `favicon.ico`, and other files that should be served directly.  Avoid placing images that require optimization in this directory; use the `src/assets/` directory instead.\n-   **`astro.config.mjs`:** This file contains the Astro configuration options, including integrations, build settings, and more.  Keep this file well-organized and documented.\n-   **`.env`:** Store environment variables in this file.  Use a library like `dotenv` to load environment variables into your application.\n\n### 1.2 Component Design\n\n-   **Atomic Design Principles:** Consider using Atomic Design principles to structure your components into atoms, molecules, organisms, templates, and pages.  This promotes reusability and maintainability.\n-   **Single Responsibility Principle:** Each component should have a single, well-defined responsibility.  Avoid creating large, complex components that do too much.\n-   **Props and Slots:** Use props to pass data to components and slots to allow components to accept children.  Define prop types using TypeScript to ensure type safety.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 UI Framework Integration\n\n-   **Island Architecture:** Embrace Astro's island architecture to minimize JavaScript and improve performance.  Only hydrate interactive components.\n-   **Client Directives:** Use `client:load`, `client:idle`, `client:visible`, `client:media`, and `client:only` directives appropriately to control when components are hydrated.  Avoid over-hydrating components.\n-   **Framework Component Composition:**  Compose components from different frameworks (React, Vue, Svelte, etc.) within the same Astro page.  This allows you to leverage the strengths of different frameworks.\n-   **Passing Props and Children:**  Pass props and children to framework components from Astro components.  Use named slots to organize children.\n-   **Anti-pattern: Mixing Astro and Framework Components:** Do not import `.astro` components directly into UI framework components (e.g., `.jsx` or `.svelte`). Use slots to pass static content from Astro components to framework components.\n\n### 2.2 Data Fetching\n\n-   **`fetch` API:** Use the `fetch` API to fetch data from external sources or internal APIs.  Handle errors appropriately.\n-   **Content Collections API:** Use the Content Collections API to manage structured content like blog posts or documentation.  Define schemas for your content types.\n-   **CMS Integration:** Integrate with a headless CMS like Hygraph, Contentful, or Strapi to manage content.  Use the CMS's API to fetch data and display it on your website.\n-   **GraphQL:** When using a CMS that supports GraphQL (like Hygraph), use GraphQL queries to fetch only the data you need.  This can improve performance and reduce data transfer.\n\n### 2.3 Routing\n\n-   **File-Based Routing:**  Use Astro's file-based routing to create routes automatically.  Follow a consistent naming convention for your pages.\n-   **Dynamic Routes:** Use dynamic routes (e.g., `[slug].astro`) to handle variable segments in the URL.  Access the route parameters using `Astro.params`.\n-   **Nested Routes:** Use nested folders within `src/pages/` to create nested routes.\n-   **Anti-pattern: Overly Complex Routing:**  Avoid creating overly complex routing structures.  Keep your routes simple and intuitive.\n\n### 2.4 Styling\n\n-   **Scoped CSS:**  Use scoped CSS within Astro components to avoid style conflicts.  This ensures that component styles are isolated.\n-   **Global Styles:**  Use global styles for site-wide styling.  Store global styles in `src/styles/global.css`.\n-   **CSS Frameworks:** Use CSS frameworks like Tailwind CSS, Bootstrap, or Materialize to speed up development and maintain a consistent look and feel. Install the appropriate integration for your chosen CSS framework.\n-   **CSS Modules:** Consider using CSS Modules for component-specific styling.  CSS Modules generate unique class names to avoid naming collisions.\n\n## 3. Performance Considerations\n\n### 3.1 Minimizing JavaScript\n\n-   **Static-First Architecture:**  Embrace Astro's static-first architecture to minimize JavaScript and improve performance.  Render as much as possible as static HTML.\n-   **Island Architecture:**  Only hydrate interactive components.  Avoid over-hydrating components.\n-   **Code Splitting:**  Use code splitting to break up your JavaScript into smaller chunks.  This can improve initial load times.\n-   **Lazy Loading:**  Use lazy loading for images and other assets that are not immediately visible.  This can improve initial load times.\n\n### 3.2 Image Optimization\n\n-   **Astro's `<Image />` Component:**  Use Astro's built-in `<Image />` component to optimize images.  The `<Image />` component automatically optimizes images, resizes them, and generates responsive versions.\n-   **Image Formats:**  Use modern image formats like WebP to reduce file sizes. Use AVIF for even better compression, where supported.\n-   **Compression:**  Compress images to reduce file sizes.  Use tools like ImageOptim or TinyPNG.\n-   **Lazy Loading:**  Use lazy loading for images that are not immediately visible.\n-   **Responsive Images:**  Use responsive images to serve different image sizes based on the user's screen size.\n\n### 3.3 Font Optimization\n\n-   **Web Font Formats:** Use modern web font formats like WOFF2.  These formats offer better compression and performance.\n-   **Font Loading:**  Use font loading strategies to avoid blocking rendering.  Consider using `font-display: swap`.\n-   **Preloading:**  Preload important fonts to improve loading times.\n\n### 3.4 Caching\n\n-   **Browser Caching:**  Configure browser caching to cache static assets like images, fonts, and JavaScript files.  This can improve performance for returning users.\n-   **CDN:**  Use a Content Delivery Network (CDN) to serve static assets from geographically distributed servers.  This can improve performance for users around the world.\n\n## 4. Security Best Practices\n\n### 4.1 Input Validation\n\n-   **Validate User Input:**  Validate all user input to prevent injection attacks and other security vulnerabilities.  Use server-side validation in addition to client-side validation.\n-   **Sanitize User Input:**  Sanitize user input to remove potentially malicious code.  Use a library like DOMPurify to sanitize HTML.\n\n### 4.2 Cross-Site Scripting (XSS)\n\n-   **Escape Output:**  Escape all output to prevent XSS attacks.  Use Astro's built-in escaping mechanisms or a library like Handlebars.js.\n-   **Content Security Policy (CSP):**  Implement a Content Security Policy (CSP) to control the resources that the browser is allowed to load.  This can help prevent XSS attacks.\n\n### 4.3 Cross-Site Request Forgery (CSRF)\n\n-   **CSRF Tokens:**  Use CSRF tokens to protect against CSRF attacks.  Generate a unique CSRF token for each user session and include it in all forms.\n\n### 4.4 Authentication and Authorization\n\n-   **Secure Authentication:**  Use secure authentication mechanisms to protect user accounts.  Use a library like Passport.js or Auth0.\n-   **Authorization:**  Implement authorization to control access to resources.  Use roles and permissions to define what users are allowed to do.\n\n### 4.5 Dependency Management\n\n-   **Keep Dependencies Up-to-Date:**  Keep your dependencies up-to-date to patch security vulnerabilities.  Use a tool like `npm audit` or `yarn audit` to identify and fix vulnerabilities.\n-   **Lock Dependencies:**  Lock your dependencies to prevent unexpected changes.  Use `package-lock.json` or `yarn.lock`.\n\n### 4.6 Environment Variables\n\n-   **Store Secrets Securely:**  Store secrets like API keys and database passwords in environment variables.  Do not hardcode secrets in your code.\n-   **Avoid Committing `.env`:**  Never commit your `.env` file to version control.  Use a `.gitignore` file to exclude it.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n-   **Test Individual Components:**  Write unit tests to test individual components in isolation.  Use a testing framework like Jest or Mocha.\n-   **Mock Dependencies:**  Mock dependencies to isolate components during testing.\n\n### 5.2 Integration Testing\n\n-   **Test Component Interactions:**  Write integration tests to test how components interact with each other.  Use a testing framework like Cypress or Playwright.\n\n### 5.3 End-to-End Testing\n\n-   **Test User Flows:**  Write end-to-end tests to test complete user flows.  Use a testing framework like Cypress or Playwright.\n\n### 5.4 Accessibility Testing\n\n-   **Automated Accessibility Testing:**  Use automated accessibility testing tools to identify accessibility issues.  Use a tool like axe-core.\n-   **Manual Accessibility Testing:**  Perform manual accessibility testing to ensure that your website is accessible to users with disabilities.  Use a screen reader to test your website.\n\n## 6. Common Pitfalls and Gotchas\n\n-   **Over-Hydration:**  Avoid over-hydrating components.  Only hydrate interactive components.\n-   **Incorrect Client Directives:**  Use the correct client directives for your components.  Using the wrong client directive can lead to performance issues or unexpected behavior.\n-   **Global Scope Pollution:**  Avoid polluting the global scope with JavaScript variables.  Use modules to encapsulate your code.\n-   **Missing `alt` Attributes:**  Always include `alt` attributes for images.  The `alt` attribute is important for accessibility and SEO.\n-   **Hardcoded Secrets:**  Never hardcode secrets in your code.  Store secrets in environment variables.\n-   **Insecure Dependencies:**  Keep your dependencies up-to-date to patch security vulnerabilities.\n-   **Not handling errors:** Always handle errors gracefully, especially when fetching data or interacting with external APIs.\n\n## 7. Tooling and Environment\n\n### 7.1 Code Editor\n\n-   **Visual Studio Code:**  Use Visual Studio Code as your code editor.  VS Code has excellent support for Astro and other web development technologies.\n-   **Astro VS Code Extension:**  Install the Astro VS Code extension for syntax highlighting, code completion, and other features.\n-   **ESLint and Prettier:**  Install ESLint and Prettier for code linting and formatting.\n\n### 7.2 Package Manager\n\n-   **npm, Yarn, or pnpm:**  Use npm, Yarn, or pnpm as your package manager.  Choose the package manager that best suits your needs.\n\n### 7.3 Build Tool\n\n-   **Astro's Built-in Build Tool:**  Use Astro's built-in build tool to build your website.  The build tool automatically optimizes your code and assets.\n\n### 7.4 Version Control\n\n-   **Git:**  Use Git for version control.  Git allows you to track changes to your code and collaborate with other developers.\n-   **GitHub, GitLab, or Bitbucket:**  Use GitHub, GitLab, or Bitbucket to host your Git repository.  These platforms provide a centralized location for managing and collaborating on code.\n\n### 7.5 Deployment\n\n-   **Netlify, Vercel, or Cloudflare Pages:**  Use Netlify, Vercel, or Cloudflare Pages to deploy your website.  These platforms provide easy-to-use deployment workflows and CDN integration.\n\nBy following these best practices and coding standards, you can ensure that your Astro projects are maintainable, performant, and secure.",
    "metadata": {
      "globs": "*.astro",
      "format": "mdc",
      "originalFile": "astro.mdc"
    },
    "subcategory": "other",
    "keywords": [
      "cursor",
      "astro",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "other"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "astro",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-asyncio",
    "description": "This rule provides comprehensive guidelines and best practices for utilizing the asyncio library in Python, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "asyncio",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/asyncio.mdc",
    "content": "# asyncio Best Practices and Coding Standards\n\nThis document outlines comprehensive best practices for using the `asyncio` library in Python. It covers various aspects of asyncio development, including code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling.\n\n## Library Information:\n\n- Name: asyncio\n- Tags: python, async, standard-library\n\n## 1. Code Organization and Structure\n\nEffective code organization is crucial for maintainability and scalability when working with asyncio.\n\n### 1.1 Directory Structure Best Practices\n\nA well-defined directory structure helps in organizing different parts of your asyncio application.\n\n\nproject_root/\n├── src/\n│   ├── __init__.py\n│   ├── main.py          # Entry point of the application\n│   ├── modules/\n│   │   ├── __init__.py\n│   │   ├── networking.py  # Handles networking tasks\n│   │   ├── processing.py  # Data processing tasks\n│   │   └── utils.py       # Utility functions\n│   ├── config.py        # Configuration settings\n├── tests/\n│   ├── __init__.py\n│   ├── test_networking.py\n│   ├── test_processing.py\n│   └── conftest.py      # Fixtures and configuration for pytest\n├── requirements.txt     # Project dependencies\n├── pyproject.toml       # Project metadata and build system\n├── README.md            # Project documentation\n\n\n### 1.2 File Naming Conventions\n\nConsistent file naming conventions enhance readability and maintainability.\n\n- Use descriptive names that reflect the module's purpose.\n- Prefer lowercase with underscores (snake_case) for file names (e.g., `async_utils.py`, `data_handler.py`).\n- Test files should follow the `test_*.py` pattern for pytest compatibility.\n\n### 1.3 Module Organization\n\nDivide your code into logical modules based on functionality.\n\n- Group related functions and classes within the same module.\n- Use `__init__.py` files to make directories into Python packages.\n- Employ relative imports for internal modules (`from . import utils`).\n- Use absolute imports for external libraries (`import aiohttp`).\n\npython\n# src/modules/networking.py\nimport asyncio\nimport aiohttp\n\nasync def fetch_data(url: str) -> str:\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.text()\n\n\n### 1.4 Component Architecture Recommendations\n\nConsider using a layered architecture to separate concerns.\n\n- **Presentation Layer**: Handles user interface or API endpoints.\n- **Service Layer**: Contains business logic and orchestrates tasks.\n- **Data Access Layer**: Manages data persistence and retrieval.\n- **Infrastructure Layer**: Provides supporting services like logging and configuration.\n\n### 1.5 Code Splitting Strategies\n\nSplit large modules into smaller, more manageable files.\n\n- Use functions and classes to encapsulate specific tasks.\n- Consider splitting modules based on logical boundaries (e.g., one module for database interactions, another for API calls).\n- Refactor complex coroutines into smaller, reusable coroutines.\n\n## 2. Common Patterns and Anti-patterns\n\nUnderstanding common patterns and anti-patterns helps in writing efficient and maintainable asyncio code.\n\n### 2.1 Design Patterns Specific to asyncio\n\n- **Producer-Consumer**: Use `asyncio.Queue` to manage tasks between producers and consumers.\n- **Worker Pool**: Create a pool of worker coroutines to process tasks concurrently.\n- **Pub-Sub**: Implement a publish-subscribe pattern using queues or custom event handling.\n\n#### Producer-Consumer Example\n\npython\nimport asyncio\n\nasync def producer(queue: asyncio.Queue, data: list):\n    for item in data:\n        await queue.put(item)\n        print(f\"Produced: {item}\")\n    await queue.put(None)  # Signal end of production\n\nasync def consumer(queue: asyncio.Queue):\n    while True:\n        item = await queue.get()\n        if item is None:\n            break\n        print(f\"Consumed: {item}\")\n        queue.task_done()\n\nasync def main():\n    queue = asyncio.Queue()\n    data = [1, 2, 3, 4, 5]\n    producer_task = asyncio.create_task(producer(queue, data))\n    consumer_task = asyncio.create_task(consumer(queue))\n\n    await asyncio.gather(producer_task, consumer_task)\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Making HTTP Requests**: Use `aiohttp` for non-blocking HTTP requests.\n- **Reading/Writing Files**: Use `aiofiles` for asynchronous file I/O.\n- **Database Operations**: Utilize async database drivers like `aiopg` or `asyncpg`.\n- **Task Scheduling**: Use `asyncio.create_task` or `asyncio.gather` to manage concurrent tasks.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n- **Blocking Calls**: Avoid using blocking functions like `time.sleep` or `requests` in coroutines. Use `asyncio.sleep` and `aiohttp` instead.\n- **Long-Running Coroutines**: Break down long-running coroutines into smaller, awaitable chunks to avoid blocking the event loop.\n- **Ignoring Exceptions**: Always handle exceptions properly to prevent unexpected crashes.\n- **Over-using Locks**: Excessive use of locks can reduce concurrency. Consider using queues or other synchronization primitives.\n- **Unnecessary Context Switching**: Minimize context switches by optimizing code and reducing unnecessary `await` calls.\n\n### 2.4 State Management Best Practices\n\n- **Immutable Data**: Prefer immutable data structures to avoid race conditions.\n- **Thread-Safe Data Structures**: Use thread-safe data structures from the `queue` or `collections` modules when sharing data between coroutines.\n- **Avoid Global State**: Minimize the use of global state to reduce complexity and potential conflicts.\n\n### 2.5 Error Handling Patterns\n\n- **Try-Except Blocks**: Use `try-except` blocks to catch and handle exceptions within coroutines.\n- **`asyncio.gather(..., return_exceptions=True)`**: Use `return_exceptions=True` in `asyncio.gather` to prevent one exception from canceling other tasks.\n- **Logging Errors**: Log exceptions with detailed information for debugging purposes.\n- **Graceful Shutdown**: Implement a mechanism to gracefully shut down the application and release resources.\n\npython\nimport asyncio\nimport logging\n\nasync def my_coroutine(value):\n    try:\n        if value < 0:\n            raise ValueError(\"Value must be non-negative\")\n        await asyncio.sleep(1)\n        return value * 2\n    except ValueError as e:\n        logging.error(f\"Error processing {value}: {e}\")\n        return None\n\nasync def main():\n    results = await asyncio.gather(\n        my_coroutine(5), my_coroutine(-1), my_coroutine(10), return_exceptions=True\n    )\n    print(f\"Results: {results}\")\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.ERROR)\n    asyncio.run(main())\n\n\n## 3. Performance Considerations\n\nOptimizing performance is critical for asyncio applications.\n\n### 3.1 Optimization Techniques\n\n- **Minimize I/O Operations**: Reduce the number of I/O operations by batching requests or caching data.\n- **Use Efficient Data Structures**: Choose appropriate data structures for specific tasks (e.g., dictionaries for fast lookups).\n- **Avoid Unnecessary Copying**: Minimize copying data to reduce memory usage and improve performance.\n- **Profile Your Code**: Use profiling tools to identify performance bottlenecks.\n- **Use `uvloop`**: Consider using `uvloop`, a fast, drop-in replacement for the default asyncio event loop.\n\npython\ntry:\n    import uvloop\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    print(\"Using uvloop\")\nexcept ImportError:\n    print(\"uvloop not installed, using default asyncio loop\")\n\n\n### 3.2 Memory Management\n\n- **Resource Management**: Properly release resources (e.g., file handles, database connections) when they are no longer needed.\n- **Use Generators**: Use generators to process large datasets in chunks.\n- **Limit Object Creation**: Reduce the creation of unnecessary objects to minimize memory overhead.\n\n### 3.3 Lazy Loading Strategies\n\n- **Import on Demand**: Import modules only when they are needed to reduce startup time.\n- **Load Data Lazily**: Load data only when it is accessed to reduce initial memory usage.\n\n## 4. Security Best Practices\n\nSecuring asyncio applications is essential for protecting against vulnerabilities.\n\n### 4.1 Common Vulnerabilities and Prevention\n\n- **Injection Attacks**: Sanitize user inputs to prevent SQL injection, command injection, and other injection attacks.\n- **Cross-Site Scripting (XSS)**: Encode user-generated content to prevent XSS attacks.\n- **Denial of Service (DoS)**: Implement rate limiting and input validation to prevent DoS attacks.\n- **Man-in-the-Middle (MitM) Attacks**: Use TLS/SSL for secure communication to prevent MitM attacks.\n\n### 4.2 Input Validation\n\n- **Validate All Inputs**: Validate all user inputs and data received from external sources.\n- **Use Regular Expressions**: Use regular expressions to validate input formats.\n- **Limit Input Length**: Restrict the length of input fields to prevent buffer overflows.\n\n### 4.3 Authentication and Authorization\n\n- **Use Strong Authentication**: Implement strong authentication mechanisms (e.g., multi-factor authentication).\n- **Implement Authorization**: Implement authorization checks to ensure users only have access to authorized resources.\n- **Store Passwords Securely**: Hash passwords using strong hashing algorithms (e.g., bcrypt or Argon2).\n- **Use JWTs**: Employ JSON Web Tokens (JWTs) for stateless authentication.\n\n### 4.4 Data Protection Strategies\n\n- **Encrypt Sensitive Data**: Encrypt sensitive data at rest and in transit.\n- **Use Secure Protocols**: Use secure protocols (e.g., HTTPS, SSH) for communication.\n- **Regularly Audit Security**: Conduct regular security audits to identify and address vulnerabilities.\n\n### 4.5 Secure API Communication\n\n- **Use HTTPS**: Always use HTTPS for API communication.\n- **Validate API Responses**: Validate API responses to ensure data integrity.\n- **Implement Rate Limiting**: Implement rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\nTesting is crucial for ensuring the reliability of asyncio applications.\n\n### 5.1 Unit Testing Strategies\n\n- **Test Coroutines in Isolation**: Use `asyncio.run` or `pytest-asyncio` to test coroutines in isolation.\n- **Mock External Dependencies**: Use mocking libraries like `unittest.mock` to mock external dependencies.\n- **Assert Expected Outcomes**: Use assertions to verify expected outcomes and error conditions.\n\n### 5.2 Integration Testing\n\n- **Test Interactions Between Components**: Test interactions between different components of the application.\n- **Use Real Dependencies**: Use real dependencies (e.g., databases, APIs) in a controlled environment.\n\n### 5.3 End-to-End Testing\n\n- **Simulate Real User Scenarios**: Simulate real user scenarios to test the entire application flow.\n- **Use Test Automation Frameworks**: Use test automation frameworks like Selenium or Playwright.\n\n### 5.4 Test Organization\n\n- **Organize Tests by Module**: Organize tests into separate files that correspond to the application modules.\n- **Use Descriptive Test Names**: Use descriptive test names that clearly indicate what is being tested.\n\n### 5.5 Mocking and Stubbing Techniques\n\n- **Mock Asynchronous Functions**: Use `asyncio.iscoroutinefunction` to check if a function is a coroutine before mocking it.\n- **Patch External Dependencies**: Use `unittest.mock.patch` to replace external dependencies with mock objects.\n- **Use Asynchronous Mocks**: Use asynchronous mocks to simulate asynchronous behavior.\n\npython\nimport asyncio\nimport unittest.mock\nimport pytest\n\nasync def fetch_data(url: str) -> str:\n    # This is just a placeholder; in real code, it would use aiohttp\n    await asyncio.sleep(0.1)  # Simulate I/O delay\n    return f\"Data from {url}\"\n\n@pytest.mark.asyncio\nasync def test_fetch_data():\n    with unittest.mock.patch(\"__main__.fetch_data\") as mock_fetch_data:\n        mock_fetch_data.return_value = \"Mocked data\"\n        result = await fetch_data(\"http://example.com\")\n        assert result == \"Mocked data\"\n        mock_fetch_data.assert_called_once_with(\"http://example.com\")\n\n\n## 6. Common Pitfalls and Gotchas\n\nBeing aware of common pitfalls helps in avoiding mistakes when using asyncio.\n\n### 6.1 Frequent Mistakes\n\n- **Mixing Synchronous and Asynchronous Code**: Avoid mixing synchronous and asynchronous code in the same coroutine.\n- **Forgetting to Await**: Ensure that you `await` all awaitable objects.\n- **Blocking the Event Loop**: Avoid blocking the event loop with long-running synchronous operations.\n- **Ignoring Task Cancellation**: Handle task cancellation properly to prevent resource leaks.\n- **Not Handling Exceptions**: Always handle exceptions properly to prevent unexpected crashes.\n\n### 6.2 Edge Cases\n\n- **Task Timeouts**: Implement task timeouts to prevent tasks from running indefinitely.\n- **Resource Limits**: Set resource limits (e.g., maximum number of connections) to prevent resource exhaustion.\n- **Signal Handling**: Handle signals (e.g., SIGINT, SIGTERM) to gracefully shut down the application.\n\n### 6.3 Version-Specific Issues\n\n- **asyncio API Changes**: Be aware of API changes between different versions of asyncio.\n- **Python 3.7+**: Use Python 3.7 or later to take advantage of the latest asyncio features (e.g., `asyncio.run`).\n\n### 6.4 Compatibility Concerns\n\n- **Third-Party Libraries**: Ensure that third-party libraries are compatible with asyncio.\n- **Event Loop Implementations**: Be aware of compatibility issues between different event loop implementations (e.g., `uvloop`).\n\n### 6.5 Debugging Strategies\n\n- **Enable Debug Mode**: Enable asyncio debug mode to get more detailed information about tasks and coroutines.\n- **Use Logging**: Use logging to track the execution flow and identify potential issues.\n- **Use Debuggers**: Use debuggers like `pdb` or IDE-integrated debuggers to step through code and inspect variables.\n- **Inspect Task State**: Inspect the state of tasks using `asyncio.Task.all_tasks()` to identify stuck or failing tasks.\n\n## 7. Tooling and Environment\n\nUsing the right tools and environment can greatly improve the development experience.\n\n### 7.1 Recommended Development Tools\n\n- **IDE**: Use an IDE like VS Code, PyCharm, or Sublime Text with Python support.\n- **Linters**: Use linters like `flake8` or `pylint` to enforce coding standards.\n- **Formatters**: Use formatters like `black` or `autopep8` to automatically format code.\n- **Debuggers**: Use debuggers like `pdb` or IDE-integrated debuggers to step through code and inspect variables.\n\n### 7.2 Build Configuration\n\n- **Use `pyproject.toml`**: Configure the project using a `pyproject.toml` file to specify build dependencies and settings.\n- **Specify Dependencies**: Specify project dependencies in `requirements.txt` or `pyproject.toml`.\n- **Use Virtual Environments**: Use virtual environments to isolate project dependencies.\n\n### 7.3 Linting and Formatting\n\n- **Configure Linters**: Configure linters to enforce coding standards (e.g., PEP 8).\n- **Configure Formatters**: Configure formatters to automatically format code.\n- **Use Pre-commit Hooks**: Use pre-commit hooks to automatically run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n- **Use a Production-Ready Event Loop**: Use a production-ready event loop like `uvloop`.\n- **Use a Process Manager**: Use a process manager like systemd or Supervisor to manage the application process.\n- **Use a Load Balancer**: Use a load balancer to distribute traffic across multiple instances of the application.\n- **Monitor Application Health**: Monitor the application's health and performance using metrics and alerts.\n\n### 7.5 CI/CD Integration\n\n- **Automate Tests**: Automate unit, integration, and end-to-end tests in the CI/CD pipeline.\n- **Automate Linting and Formatting**: Automate linting and formatting in the CI/CD pipeline.\n- **Automate Deployment**: Automate deployment to production environments.\n\nBy adhering to these best practices, you can build robust, efficient, and maintainable asyncio applications in Python.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "asyncio.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "asyncio",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "best",
      "practices",
      "utilizing",
      "library",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "asyncio",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-auth0",
    "description": "This rule provides comprehensive guidance for Auth0 library usage, covering code organization, security, performance, testing, and common pitfalls. Adhering to these guidelines ensures secure, efficient, and maintainable Auth0 integrations.",
    "author": "sanjeed5",
    "tags": [
      "auth0",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/auth0.mdc",
    "content": "---\n\n# Auth0 Best Practices and Coding Standards\n\nThis document outlines best practices for working with Auth0 to ensure secure, efficient, and maintainable authentication and authorization in your applications.\n\n## Library Information:\n\n- Name: Auth0\n- Tags: authentication, security, identity, SaaS\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - Adopt a modular structure.  For example:\n        \n        src/\n          auth/\n            auth0.config.js  # Auth0 configuration\n            auth0.service.js # Authentication and authorization logic\n            components/\n              login.jsx        # Login component\n              profile.jsx      # User profile component\n            utils/\n              auth.helper.js # Helper functions for authentication\n          components/\n            ... other application components\n        \n- **File Naming Conventions:**\n    - Use descriptive names. Example: `auth0.config.js`, `AuthService.ts`, `LoginButton.jsx`.\n    - Follow a consistent naming convention (e.g., camelCase for JavaScript, PascalCase for React components).\n- **Module Organization:**\n    - Group related Auth0 logic into modules.  Avoid placing all Auth0-related code in a single, monolithic file.\n    - Use dependency injection to decouple Auth0 modules from other parts of your application.\n- **Component Architecture (if applicable, e.g., React, Angular, Vue):**\n    - Create dedicated components for authentication-related UI elements (login buttons, profile displays, etc.).\n    - Separate concerns: keep UI components focused on rendering and delegate authentication logic to a separate service or module.\n- **Code Splitting:**\n    - For large applications, consider lazy-loading Auth0-related code to improve initial load time.\n    - Implement code splitting at the route level, loading authentication modules only when necessary.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - **Adapter Pattern:**  Use an adapter to abstract the underlying Auth0 SDK and provide a consistent API for your application.\n    - **Singleton Pattern:**  Ensure that only one instance of the Auth0 client is created.\n    - **Observer Pattern:**  Use an observer pattern to notify components when the authentication state changes.\n- **Recommended Approaches for Common Tasks:**\n    - **Authentication:** Use the Auth0 SDK to handle authentication flows (login, logout, password reset).\n    - **Authorization:** Implement role-based access control (RBAC) using Auth0's authorization features.\n    - **User Profile Management:**  Leverage Auth0's user profile management features to store and retrieve user information.\n    - **Token Handling:**  Securely store and manage access tokens and refresh tokens. Consider using HttpOnly cookies or secure storage mechanisms.\n- **Anti-patterns and Code Smells:**\n    - **Hardcoding Credentials:** Never hardcode Auth0 credentials (Client ID, Client Secret) directly in your code. Use environment variables or secure configuration files.\n    - **Exposing Sensitive Data:** Avoid exposing sensitive user data (e.g., access tokens) in the client-side code or URLs.\n    - **Ignoring Error Handling:**  Implement robust error handling to catch and handle authentication errors gracefully.\n    - **Overly Complex Rules/Actions:** Keep Auth0 Rules and Actions simple and focused.  Delegate complex logic to external services.\n    - **Storing Secrets in Rules Code:** Don't store sensitive keys or credentials directly in the Rule code. Use the rule settings and the configuration object instead.\n- **State Management:**\n    - Utilize context API, Redux, Zustand, or similar state management libraries to manage the user's authentication state (e.g., isLoggedIn, user profile).\n    - Ensure the authentication state is persisted across page reloads (e.g., using localStorage or sessionStorage).\n- **Error Handling:**\n    - Use try-catch blocks to handle potential errors during authentication and authorization.\n    - Log errors to a central logging service for monitoring and debugging.\n    - Display user-friendly error messages to the user.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - **Caching:** Cache user profiles and access tokens to reduce the number of calls to Auth0.\n    - **Token Reuse:**  Reuse existing access tokens whenever possible.\n    - **Minimize Data Transfer:**  Only request the necessary user profile information from Auth0.\n- **Memory Management:**\n    - Release resources (e.g., timers, event listeners) when they are no longer needed.\n    - Avoid creating unnecessary objects during authentication and authorization.\n- **Rendering Optimization (if applicable):**\n    - Use techniques like memoization and virtualization to optimize the rendering of authentication-related UI components.\n- **Bundle Size Optimization:**\n    - Use tree shaking to remove unused Auth0 code from the final bundle.\n    - Consider using a smaller alternative to the full Auth0 SDK if possible.\n- **Lazy Loading:**\n    - Lazy load Auth0 modules and components to improve initial page load time.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities and Prevention:**\n    - **Cross-Site Scripting (XSS):** Sanitize user inputs to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using anti-CSRF tokens.\n    - **Token Theft:** Securely store and manage access tokens to prevent token theft.\n    - **Injection Attacks:** Prevent injection attacks by validating and sanitizing all user inputs.\n- **Input Validation:**\n    - Validate all user inputs to prevent malicious data from being processed.\n    - Use a validation library to simplify the input validation process.\n- **Authentication and Authorization:**\n    - Use the Auth0 SDK for authentication and authorization.\n    - Implement role-based access control (RBAC) using Auth0's authorization features.\n    - Enforce multi-factor authentication (MFA) to enhance security.\n    - Regularly review security settings, enable breach detection features, and utilize logging to monitor authentication events for any suspicious activities.\n- **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all communications.\n    - Protect API keys and other sensitive credentials.\n- **Secure API Communication:**\n    - Always use HTTPS for all communications to protect sensitive data during transmission.\n    - Store sensitive information, like API keys, in the Auth0 rule settings instead of hardcoding them directly in your code to prevent exposure.\n    - Avoid sending the entire context object to external services. Send only a subset of the less sensitive attributes from the context object when and where necessary. In a similar fashion, avoid passing any aspect of the auth0 object outside of a rule.\n\n## 5. Testing Approaches:\n\n- **Unit Testing:**\n    - Write unit tests for Auth0-related modules and components.\n    - Mock the Auth0 SDK to isolate the code being tested.\n    - Test different authentication scenarios (successful login, failed login, password reset).\n- **Integration Testing:**\n    - Integrate Auth0 with your application and test the entire authentication flow.\n    - Use a test Auth0 tenant for integration testing.\n    - Verify that authentication and authorization work as expected.\n- **End-to-End Testing:**\n    - Use end-to-end testing frameworks (e.g., Cypress, Selenium) to test the entire application from the user's perspective.\n    - Simulate user interactions and verify that authentication works correctly.\n- **Test Organization:**\n    - Organize tests into separate directories based on the modules or components being tested.\n    - Use descriptive test names to clearly indicate the purpose of each test.\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., Jest, Mocha) to mock the Auth0 SDK and other external dependencies.\n    - Use stubbing to replace external dependencies with predefined values.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n    - Forgetting to configure the callback URL in the Auth0 dashboard.\n    - Incorrectly configuring the allowed logout URLs.\n    - Failing to handle authentication errors gracefully.\n    - Storing sensitive data in client-side code.\n    - Not enabling multi-factor authentication (MFA).\n- **Edge Cases:**\n    - Handling expired access tokens.\n    - Dealing with network connectivity issues.\n    - Supporting different browsers and devices.\n    - Managing user sessions.\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in Auth0 SDK updates.\n    - Refer to the Auth0 documentation for migration guides.\n- **Compatibility Concerns:**\n    - Ensure that the Auth0 SDK is compatible with the other technologies used in your application.\n    - Test the integration with different browsers and devices.\n- **Debugging:**\n    - Use the Auth0 logs to troubleshoot authentication issues.\n    - Use browser developer tools to inspect network requests and responses.\n    - Set breakpoints in your code to debug authentication logic.\n\n## 7. Tooling and Environment:\n\n- **Recommended Tools:**\n    - Auth0 CLI:  For managing Auth0 tenants and applications.\n    - Auth0 Management API:  For programmatically managing Auth0 resources.\n    - Auth0 SDKs:  For integrating Auth0 into your applications.\n    - Postman or Insomnia: For testing API endpoints.\n- **Build Configuration:**\n    - Use a build tool (e.g., Webpack, Parcel, Rollup) to bundle your application.\n    - Configure the build tool to use tree shaking to remove unused Auth0 code.\n    - Minify the code to reduce the bundle size.\n- **Linting and Formatting:**\n    - Use a linter (e.g., ESLint, JSHint) to enforce code style and prevent errors.\n    - Use a code formatter (e.g., Prettier) to automatically format your code.\n- **Deployment:**\n    - Deploy your Auth0 configuration to production using the Auth0 CLI or Management API.\n    - Use environment variables to configure your application for different environments.\n    - Monitor the application for errors and performance issues.\n- **CI/CD Integration:**\n    - Integrate Auth0 deployment into your CI/CD pipeline.\n    - Use automated tests to verify the integration before deploying to production.\n\n## Additional Best Practices:\n\n*   **Use Identity Industry Standards:** Use OAuth 2.0 and OpenID Connect for interoperability and compliance.\n*   **Regularly Review Security Settings:** Enable breach detection and anomaly detection features. Configure rate limits to protect against brute force attacks.\n*   **Store Configuration Values in the Dashboard:** If your Actions, Rules, Hooks, custom database scripts, or Webtasks require configuration values (such as credentials or API keys), store them in the Auth0 Dashboard.  This makes migrating configuration between tenants easier.\n*   **Add Auth0 Public IP Addresses to Allow List:** If your Actions, Rules, Hooks, custom database scripts, or Webtasks call a service in your intranet or behind another firewall, be sure to add the Auth0 public IP addresses to the Allow List. This lets requests from those IP addresses through.\n*   **Run Tenant Configuration Checks:** The Auth0 Support Center provides a configuration checker tool. Run the configuration checker periodically during development and again before you launch. To run the configuration check, go to Auth0 Support Center > Tenants, select the gear icon, and choose Run Production Check.\n*   **Contextual bypass for Multi-Factor Authentication (MFA):** As a recommended best practice, use of allowRememberBrowser or context.authentication should be the only options considered for contextual bypass when using out-of-box MFA.\n*   **Passwordless Connections:** Enable passwordless login using email or SMS for improved user experience.\n*   **Custom Domains:** Use a custom domain (example: auth.yourcompany.com) for branding and consistent user experience.\n*   **Regularly Review User Accounts and Roles:** Remove inactive accounts and update permissions as needed.\n*   **Software Updates:** Keep your Auth0 SDKs and libraries up to date to ensure you benefit from the latest security patches and features.\n*   **Continuous Monitoring:** Continuously monitor authentication logs and respond to any anomalies or security incidents.\n*   **Always use HTTPS:** Always use HTTPS, not HTTP, when making calls to external services or when executing redirect as part of your rule implementation.\n*   **Check if an email is verified:** Check to see if a user's email address is verified in a rule\n*   **Check for exact string matches:** For rules that determine access control based on a particular string, such as an email domain, check for an exact string match instead of checking for a substring match.\n\nBy following these best practices, you can build secure, scalable, and maintainable applications with Auth0.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.html,*.css,*.scss,*.py,*.java,*.go",
      "format": "mdc",
      "originalFile": "auth0.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "auth0",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "library",
      "usage",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "auth0",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-autogen",
    "description": "Provides coding standards, best practices, and guidance specific to the AutoGen library, covering aspects from code structure to security and performance.",
    "author": "sanjeed5",
    "tags": [
      "autogen",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/autogen.mdc",
    "content": "- Best practice 1: Employ Modular Design. Utilize AutoGen's multi-agent framework to create modular agents with specific roles. This enhances code reusability and simplifies the orchestration of complex workflows. Example: Create separate agents for data fetching, code execution, and response formatting.\n- Best practice 2: Define Customizable Workflows. Leverage AutoGen's capabilities to define customizable workflows that integrate LLMs, human inputs, and tools. This allows for flexible agent interactions and enhances the performance of LLM applications. Implement a workflow manager to define and control agent interactions.\n- Best practice 3: Ensure Code Quality and Consistency. Implement automatic code formatting and linting features provided by AutoGen to ensure consistent coding styles and practices. This reduces human error in code generation and maintains high code quality. Integrate linters like `pylint` or `flake8` in your CI/CD pipeline.\n- Best practice 4: Integrate Human Feedback. Incorporate a Human Proxy Agent to facilitate human feedback in the workflow, ensuring that the AI systems remain aligned with user expectations and can adapt based on real-world input. Use AutoGen's `HumanProxyAgent` to gather and incorporate human feedback in the loop.\n- Best practice 5: Use UV for dependency management for faster and more reliable installations.\n- Best practice 6: Always use the latest stable version of Python (currently 3.12) for better performance and security.\n- Best practice 7: Prefer using classes over standalone functions to encapsulate state and behavior, particularly for agents and tools.\n- Best practice 8: Separate configuration from code using environment variables and configuration files to allow easy modification without altering the code base\n\n## Library Information:\n- Name: autogen\n- Tags: ai, ml, llm, python, agent-framework, multi-agent\n\n## Comprehensive Guide to AutoGen Best Practices\n\n### 1. Code Organization and Structure:\n   - **Directory Structure Best Practices:**\n     - `src/`: Contains the core AutoGen application code.\n     - `src/agents/`: Holds individual agent implementations (e.g., `code_writer_agent.py`, `data_analyst_agent.py`).\n     - `src/workflows/`: Defines workflows or agent interaction patterns (e.g., `code_generation_workflow.py`).\n     - `src/tools/`: Contains custom tools and utilities used by agents (e.g., `web_scraper.py`, `api_client.py`).\n     - `config/`: Stores configuration files (e.g., `agent_config.yaml`, `llm_config.json`).\n     - `tests/`: Contains unit and integration tests.\n     - `docs/`: Holds documentation.\n     - `examples/`: Example scripts and notebooks showcasing AutoGen's capabilities.\n   - **File Naming Conventions:**\n     - Use descriptive names with snake_case (e.g., `code_executor_agent.py`, `data_processing_tool.py`).\n     - Configuration files should use `.yaml` or `.json` extensions (e.g., `agent_config.yaml`).\n     - Test files should be named `test_<module_name>.py` (e.g., `test_code_executor.py`).\n   - **Module Organization Best Practices:**\n     - Group related functionalities into modules (e.g., `agents`, `workflows`, `tools`).\n     - Use `__init__.py` files to define packages and control imports.\n     - Implement clear and concise module-level documentation.\n   - **Component Architecture Recommendations:**\n     - Separate agents, tools, and workflows into distinct components.\n     - Use interfaces or abstract base classes to define contracts between components.\n     - Implement a central registry or dependency injection mechanism to manage component dependencies.\n   - **Code Splitting Strategies:**\n     - Split large agent implementations into smaller, more manageable classes or functions.\n     - Use lazy loading or dynamic imports to load components only when needed.\n     - Implement a plugin system to allow external components to be added to the application.\n\n### 2. Common Patterns and Anti-patterns:\n   - **Design Patterns:**\n     - **Factory Pattern:**  Create agents and tools dynamically based on configuration or user input.\n     - **Strategy Pattern:** Implement different agent behaviors or tool execution strategies based on the current context.\n     - **Observer Pattern:**  Allow agents to subscribe to events or notifications from other agents or tools.\n   - **Recommended Approaches for Common Tasks:**\n     - **Code Generation:** Use AutoGen's code generation capabilities to automate boilerplate code creation or data transformation tasks. Example: Automatically generate data validation functions based on schema definitions.\n     - **Data Analysis:** Implement agents that can analyze data, generate visualizations, and extract insights. Example: Create an agent that analyzes website traffic data and identifies potential areas for improvement.\n     - **Workflow Orchestration:** Define workflows that automate complex multi-step tasks involving multiple agents and tools. Example: Implement a workflow that automatically generates, tests, and deploys code changes.\n   - **Anti-patterns and Code Smells:**\n     - **God Agent:** Avoid creating a single agent that performs too many tasks. Decompose complex tasks into smaller, more manageable agents.\n     - **Tight Coupling:**  Minimize dependencies between agents and tools. Use interfaces or abstract base classes to decouple components.\n     - **Code Duplication:**  Extract common functionalities into reusable functions or classes.\n   - **State Management Best Practices:**\n     - Use a central state management system to store and manage the application's state.\n     - Implement versioning or snapshotting to track state changes over time.\n     - Use immutable data structures to prevent unintended state modifications.\n   - **Error Handling Patterns:**\n     - Implement robust error handling mechanisms to catch and handle exceptions.\n     - Use logging to record errors and debug issues.\n     - Implement retry logic to handle transient errors.\n\n### 3. Performance Considerations:\n   - **Optimization Techniques:**\n     - **Caching:**  Cache frequently accessed data to reduce latency and improve throughput.\n     - **Parallelization:**  Use asynchronous programming or multithreading to parallelize tasks and improve performance.\n     - **Code Optimization:**  Profile and optimize code to reduce execution time.\n   - **Memory Management:**\n     - Use generators or iterators to process large datasets in chunks.\n     - Release resources as soon as they are no longer needed.\n     - Avoid creating unnecessary copies of data.\n   - **Bundle Size Optimization (if applicable):** N/A for a Python Library, but if creating web apps with autogen, use tree-shaking to remove unused code and minimize bundle size.\n   - **Lazy Loading:** Load modules and components only when needed to reduce startup time and memory usage.\n\n### 4. Security Best Practices:\n   - **Common Vulnerabilities:**\n     - **Prompt Injection:**  Sanitize user inputs to prevent malicious code from being injected into agent prompts.\n     - **Unauthorized Access:** Implement access controls to restrict access to sensitive data and functionalities.\n     - **Data Leaks:** Protect sensitive data from being exposed in logs or error messages.\n   - **Input Validation:**\n     - Validate all user inputs to ensure that they conform to the expected format and range.\n     - Use allow lists to restrict the types of inputs that are allowed.\n     - Sanitize inputs to remove potentially harmful characters or code.\n   - **Authentication and Authorization:**\n     - Implement authentication mechanisms to verify the identity of users or agents.\n     - Use authorization policies to control access to resources and functionalities.\n     - Use role-based access control (RBAC) to simplify access management.\n   - **Data Protection:**\n     - Encrypt sensitive data at rest and in transit.\n     - Use secure storage mechanisms to protect data from unauthorized access.\n     - Implement data masking or anonymization techniques to protect sensitive data in logs or error messages.\n   - **Secure API Communication:**\n     - Use HTTPS to encrypt API communication.\n     - Authenticate and authorize API requests.\n     - Validate API responses to prevent data tampering.\n\n### 5. Testing Approaches:\n   - **Unit Testing:**\n     - Write unit tests for individual agents, tools, and workflows.\n     - Use mocking or stubbing to isolate components during testing.\n     - Test different scenarios and edge cases.\n   - **Integration Testing:**\n     - Write integration tests to verify the interaction between different components.\n     - Test the integration with external systems or APIs.\n     - Use test data that is representative of real-world data.\n   - **End-to-End Testing:**\n     - Write end-to-end tests to verify the overall functionality of the application.\n     - Simulate user interactions and verify that the application behaves as expected.\n     - Use automated testing frameworks to automate the testing process.\n   - **Test Organization:**\n     - Organize tests into separate directories or files based on the component being tested.\n     - Use descriptive names for test functions or classes.\n     - Follow a consistent testing convention.\n   - **Mocking and Stubbing:**\n     - Use mocking to replace external dependencies with mock objects.\n     - Use stubbing to replace complex functionalities with simple stubs.\n     - Use mocking frameworks to simplify the mocking process.\n\n### 6. Common Pitfalls and Gotchas:\n   - **Frequent Mistakes:**\n     - Not properly configuring LLM parameters (e.g., temperature, max tokens).\n     - Overly complex prompts that confuse the LLM.\n     - Ignoring error messages and logs.\n     - Not validating user inputs.\n   - **Edge Cases:**\n     - Handling unexpected LLM responses.\n     - Dealing with rate limits or API outages.\n     - Handling large datasets or complex workflows.\n   - **Version-Specific Issues:**\n     - Be aware of breaking changes in AutoGen updates.\n     - Check the release notes for known issues or workarounds.\n   - **Compatibility Concerns:**\n     - Ensure that AutoGen is compatible with other libraries or frameworks being used in the project.\n     - Check for conflicts between different versions of AutoGen.\n   - **Debugging Strategies:**\n     - Use logging to track the execution flow and identify errors.\n     - Use a debugger to step through the code and inspect variables.\n     - Use print statements to output intermediate results.\n\n### 7. Tooling and Environment:\n   - **Recommended Development Tools:**\n     - Python IDE (e.g., VS Code, PyCharm).\n     - Version control system (e.g., Git).\n     - Dependency management tool (e.g., pip, uv).\n   - **Build Configuration:**\n     - Use a build system to automate the build process.\n     - Configure the build system to run linters and tests.\n     - Use a virtual environment to isolate dependencies.\n   - **Linting and Formatting:**\n     - Use linters to enforce coding style guidelines.\n     - Use formatters to automatically format code.\n     - Integrate linters and formatters into the development workflow.\n   - **Deployment:**\n     - Use a deployment platform to deploy the application to a production environment.\n     - Configure the deployment platform to automatically scale the application.\n     - Use a monitoring system to track the application's performance.\n   - **CI/CD Integration:**\n     - Use a CI/CD pipeline to automate the build, test, and deployment process.\n     - Integrate the CI/CD pipeline with the version control system.\n     - Use automated testing to ensure code quality.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "autogen.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "autogen",
      "provides",
      "coding",
      "standards",
      "best",
      "practices",
      "guidance",
      "specific",
      "library",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "autogen",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-aws-amplify",
    "description": "This rule provides best practices and coding standards for aws-amplify projects, covering code organization, common patterns, performance, security, testing, pitfalls, and tooling. It aims to guide developers in building robust, scalable, and maintainable aws-amplify applications.",
    "author": "sanjeed5",
    "tags": [
      "aws-amplify",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-amplify.mdc",
    "content": "- # aws-amplify Best Practices\n\n  This document outlines best practices and coding standards for developing applications using the aws-amplify library. It aims to guide developers in creating robust, scalable, and maintainable applications.\n\n- ## 1. Code Organization and Structure\n\n  - ### Directory Structure\n\n    - **src/**: Contains all the application source code.\n      - **components/**: Reusable UI components.\n        - `ComponentName/`: Each component in its own directory.\n          - `ComponentName.tsx`: The component file.\n          - `ComponentName.module.css`: Component-specific styles (using CSS Modules).\n          - `ComponentName.test.tsx`: Unit tests for the component.\n          - `index.ts`: (Optional) Exports the component for easier imports.\n      - **pages/**: Defines the application's routes/pages (especially important for Next.js and similar frameworks).\n        - `index.tsx`: The home page.\n        - `[routeName].tsx`: Dynamic routes.\n      - **services/**: Contains business logic, data fetching, and interactions with aws-amplify services.\n        - `authService.ts`: Authentication-related functions.\n        - `dataService.ts`: Data fetching and manipulation (e.g., interacting with AppSync).\n        - `storageService.ts`: Storage-related functions (e.g., interacting with S3).\n      - **models/**: Defines data models used in the application.  This often corresponds to your Amplify DataStore or GraphQL schema definitions.\n        - `Todo.ts`: Example data model for a `Todo` item.\n      - **utils/**: Utility functions and helpers.\n        - `apiClient.ts`: A wrapper around the `Amplify` object for making API requests.\n        - `dateUtils.ts`: Date formatting functions.\n      - **config/**: Application configuration files.\n        - `aws-exports.js`: Automatically generated aws-amplify configuration.\n      - **hooks/**: Custom React hooks for reusable logic.\n        - `useAuth.ts`: A hook for managing authentication state.\n    - **amplify/**:  Generated directory by Amplify CLI, containing backend definitions.\n      - **backend/**: Code and configurations that define the AWS resources.\n        -  `api/`:  GraphQL API definitions (schema.graphql, resolvers, etc.).\n        -  `auth/`:  Authentication configuration (Cognito User Pool, Identity Pool).\n        -  `storage/`:  Storage configurations (S3 bucket).\n        -  `function/`:  Lambda functions.\n\n  - ### File Naming Conventions\n\n    - Components: `ComponentName.tsx`\n    - Styles: `ComponentName.module.css`\n    - Services: `serviceName.ts`\n    - Models: `ModelName.ts`\n    - Hooks: `useHookName.ts`\n    - Tests: `FileName.test.tsx` or `FileName.spec.tsx`\n\n  - ### Module Organization\n\n    - Group related functionalities into modules.\n    - Use clear and descriptive names for modules.\n    - Avoid circular dependencies between modules.\n    - Export only necessary functions and variables from each module.\n\n  - ### Component Architecture\n\n    - **Presentational Components:** Responsible for how things look.  Receive data and callbacks via props.\n    - **Container Components:** Concerned with how things work.  Fetch data, manage state, and pass data/callbacks to presentational components.\n    - Use composition over inheritance.\n    - Keep components small and focused on a single responsibility.\n    - Use React Hooks for managing state and side effects.\n\n  - ### Code Splitting\n\n    - Use dynamic imports (`React.lazy`) for components that are not immediately needed.\n    - Split routes into separate bundles.\n    - Leverage webpack, Parcel, or other bundlers to automatically split code.\n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### Design Patterns\n\n    - **Provider Pattern:** Use React Context to provide aws-amplify client and authentication state to the entire application.\n    - **Hook Composition:** Create custom hooks that encapsulate aws-amplify logic for reusability.\n    - **Repository Pattern:** Abstract data access logic behind a repository interface.\n\n  - ### Recommended Approaches\n\n    - **Authentication:** Use `Amplify.configure` to initialize Amplify with the configuration from `aws-exports.js`.\n      - Implement sign-in, sign-up, sign-out using `Auth` API.\n      - Utilize Higher Order Components or custom Hooks to protect routes based on authentication status.\n    - **Data Fetching:** Use `DataStore` or GraphQL APIs for data fetching.  Consider using pagination for large datasets.\n    - **Storage:** Use `Storage` API for uploading and retrieving files from S3.\n\n  - ### Anti-patterns and Code Smells\n\n    - **Tight Coupling:** Avoid directly using `Amplify` APIs in components. Abstract them into services or hooks.\n    - **Over-fetching:**  Fetch only the necessary data from APIs. Use GraphQL fragments to specify required fields.\n    - **Ignoring Errors:**  Always handle errors when interacting with aws-amplify services.\n    - **Storing Sensitive Data in Client:** Never store API keys or secrets in the client-side code. Use Lambda functions with environment variables.\n    - **Over-reliance on Amplify UI Components:** While useful for rapid prototyping, customize or replace Amplify UI components for complex designs and accessibility requirements.\n\n  - ### State Management\n\n    - **Component State:**  Use `useState` or `useReducer` for local component state.\n    - **Context API:**  Use React Context for application-wide state (e.g., authentication status, user data).\n    - **Redux/Zustand/Recoil:**  Consider using a state management library for complex applications with global state dependencies.\n    - **Amplify DataStore:** Excellent solution for offline-first applications needing real-time data synchronization with the cloud.  Use its built-in mechanisms for local persistence and conflict resolution.\n\n  - ### Error Handling\n\n    - Use `try...catch` blocks to handle errors when calling aws-amplify APIs.\n    - Display user-friendly error messages.\n    - Log errors for debugging purposes.\n    - Implement retry mechanisms for transient errors.\n\n- ## 3. Performance Considerations\n\n  - ### Optimization Techniques\n\n    - **Caching:** Cache API responses to reduce network requests. Use `Cache` API for storing data in the browser.\n    - **Lazy Loading:** Load components and data only when needed.\n    - **Debouncing and Throttling:**  Limit the rate at which functions are executed (e.g., event handlers).\n    - **Memoization:**  Cache the results of expensive function calls using `useMemo` or `React.memo`.\n    - **Image Optimization:** Optimize images before uploading them to S3. Use responsive images with different sizes for different devices.\n\n  - ### Memory Management\n\n    - Avoid memory leaks by cleaning up subscriptions and timers in `useEffect` hooks.\n    - Release unused resources.\n\n  - ### Rendering Optimization\n\n    - Use `React.memo` to prevent unnecessary re-renders of components.\n    - Implement shouldComponentUpdate (if using class components) for fine-grained control over rendering.\n    - Virtualize long lists to render only visible items.\n\n  - ### Bundle Size Optimization\n\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused code and dependencies.\n    - Minify and compress code.\n    - Analyze bundle size with tools like `webpack-bundle-analyzer` or `Source Map Explorer`.\n\n  - ### Lazy Loading\n\n    - Use `React.lazy` and `Suspense` for lazy-loading components.\n    - Implement lazy loading for images and other assets.\n\n- ## 4. Security Best Practices\n\n  - ### Common Vulnerabilities\n\n    - **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection mechanisms.\n    - **Injection Attacks:** Protect against SQL injection, NoSQL injection, and command injection attacks.\n    - **Authentication and Authorization Flaws:** Secure authentication and authorization mechanisms.\n\n  - ### Input Validation\n\n    - Validate all user input on both the client and server sides.\n    - Use strong validation rules to prevent invalid data from being stored in the database.\n\n  - ### Authentication and Authorization\n\n    - Use Amazon Cognito for authentication and authorization.\n    - Implement role-based access control (RBAC) to restrict access to resources.\n    - Secure API endpoints with authentication and authorization checks.\n    - Follow the principle of least privilege when granting permissions.\n\n  - ### Data Protection\n\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all communication.\n    - Implement data masking and redaction techniques to protect sensitive data from unauthorized access.\n    - Regularly back up data.\n\n  - ### Secure API Communication\n\n    - Use HTTPS for all API requests.\n    - Validate API responses.\n    - Implement rate limiting to prevent abuse.\n\n- ## 5. Testing Approaches\n\n  - ### Unit Testing\n\n    - Test individual components and functions in isolation.\n    - Use mocking and stubbing to isolate components from external dependencies.\n    - Write tests that cover all possible scenarios and edge cases.\n    - Use testing frameworks like Jest and React Testing Library.\n\n  - ### Integration Testing\n\n    - Test the interaction between different components and modules.\n    - Test the integration with aws-amplify services.\n    - Use integration testing frameworks like Cypress or Playwright.\n\n  - ### End-to-End Testing\n\n    - Test the entire application flow from start to finish.\n    - Simulate real user interactions.\n    - Use end-to-end testing frameworks like Cypress or Selenium.\n\n  - ### Test Organization\n\n    - Keep tests close to the code they are testing.\n    - Use descriptive names for tests.\n    - Organize tests into logical groups.\n\n  - ### Mocking and Stubbing\n\n    - Use mocking libraries like Jest to mock aws-amplify APIs and services.\n    - Use stubbing to replace complex dependencies with simple implementations for testing purposes.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### Frequent Mistakes\n\n    - Misconfiguring aws-amplify.\n    - Ignoring error messages.\n    - Not handling edge cases.\n    - Over-complicating code.\n    - Not testing thoroughly.\n\n  - ### Edge Cases\n\n    - Handling offline scenarios.\n    - Dealing with slow network connections.\n    - Handling unexpected API responses.\n\n  - ### Version-Specific Issues\n\n    - Be aware of breaking changes between aws-amplify versions.\n    - Consult the aws-amplify documentation and release notes for migration guides.\n\n  - ### Compatibility Concerns\n\n    - Ensure compatibility between aws-amplify and other libraries and frameworks used in the project.\n    - Check for known compatibility issues and workarounds.\n\n  - ### Debugging Strategies\n\n    - Use browser developer tools for debugging client-side code.\n    - Use CloudWatch logs for debugging server-side code (Lambda functions).\n    - Use the aws-amplify CLI to diagnose configuration issues.\n\n- ## 7. Tooling and Environment\n\n  - ### Recommended Tools\n\n    - Visual Studio Code (VS Code) or other preferred IDE\n    - aws-amplify CLI\n    - Node.js and npm or yarn\n    - Git for version control\n    - Jest and React Testing Library for unit testing\n    - Cypress or Playwright for end-to-end testing\n\n  - ### Build Configuration\n\n    - Use a build tool like webpack, Parcel, or esbuild.\n    - Configure the build tool to optimize code for production.\n    - Use environment variables for configuration settings.\n\n  - ### Linting and Formatting\n\n    - Use ESLint and Prettier to enforce code style and prevent errors.\n    - Configure ESLint and Prettier to automatically format code on save.\n\n  - ### Deployment\n\n    - Use aws-amplify Console for deploying the application.\n    - Configure CI/CD pipelines to automatically deploy changes to production.\n    - Use environment variables for configuration settings.\n\n  - ### CI/CD Integration\n\n    - Integrate with CI/CD tools like GitHub Actions, CircleCI, or Travis CI.\n    - Automate the build, test, and deployment processes.\n    - Use environment variables for configuration settings.\n\n- **Code-First Approach with TypeScript:** Embrace the code-first approach with AWS Amplify Gen 2, using TypeScript for both frontend and backend development to improve developer productivity and catch errors early.  Leverage AWS CDK for defining infrastructure as code.\n\n- **Single Responsibility Principle:** Adhere to the Single Responsibility Principle for AWS Lambda functions to improve code maintainability and testability.\n\n- **Avoid Function Chaining:** Reduce complexity and improve debugging by avoiding function chaining in Lambda functions.  If code reuse is needed, utilize separate TypeScript files for shared logic.\n\n- **Start with Templates:** Accelerate development by using pre-built templates instead of starting projects from scratch.\n\n- **Utilize Cloud Sandboxes:** Leverage per-developer cloud sandbox environments for isolated testing and iteration without interfering with other team members.\n\n- **Take advantage of Amplify's opinionated nature** When you read the docs, you will start to understand how opinionated Amplify is. Whether you choose Amplify or not should include this aspect of its design, and you shouldn't choose this tool if it doesn't align with the direction your team is taking with infrastructure. It is best used as 'Glue' for an All-AWS roadmap.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "aws-amplify.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "amplify",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "covering",
      "aws-amplify",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-amplify",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws-cli",
    "description": "This rule provides comprehensive guidance on best practices for developing and managing AWS resources using the AWS CLI, covering code organization, security, performance, and testing.",
    "author": "sanjeed5",
    "tags": [
      "aws-cli",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-cli.mdc",
    "content": "# AWS CLI Best Practices and Coding Standards\n\nThis document provides guidelines and recommendations for developing and managing AWS resources using the AWS CLI. Following these practices enhances code quality, security, and operational efficiency.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nA well-organized directory structure promotes maintainability and readability.\n\n\nproject-root/\n├── scripts/                  # Shell scripts for common AWS CLI operations\n│   ├── create-s3-bucket.sh\n│   ├── deploy-lambda.sh\n│   └── ...\n├── modules/                  # Reusable modules (e.g., Python scripts)\n│   ├── s3_utils.py           # S3 utility functions\n│   ├── iam_utils.py          # IAM utility functions\n│   └── ...\n├── config/                   # Configuration files\n│   ├── aws_config.yml        # AWS CLI configuration\n│   └── ...\n├── terraform/                # Infrastructure as Code (IaC) using Terraform (optional)\n│   ├── main.tf\n│   ├── variables.tf\n│   └── ...\n├── tests/                    # Test scripts\n│   ├── test_s3_utils.py\n│   └── ...\n├── README.md                 # Project documentation\n└── .gitignore                # Git ignore file\n\n\n### 1.2. File Naming Conventions\n\n*   **Scripts:** Use descriptive names (e.g., `create-ec2-instance.sh`).  Suffix with `.sh` for shell scripts.\n*   **Modules:** Use descriptive names (e.g., `s3_utils.py`).  Suffix with `.py` for Python modules.\n*   **Configuration:**  Use `.yml` or `.yaml` for YAML configuration files (e.g., `aws_config.yml`).\n*   **Terraform:** Follow Terraform conventions (`main.tf`, `variables.tf`).\n*   **Tests:** Prefix test files with `test_` (e.g., `test_s3_utils.py`).\n\n### 1.3. Module Organization\n\n*   **Purpose-Driven Modules:** Group related functionalities into modules (e.g., `s3_utils.py` for S3 operations).\n*   **Avoid Circular Dependencies:** Design modules to minimize inter-dependencies.\n*   **Clear Interfaces:** Define clear function signatures and API contracts for each module.\n*   **Documentation:** Include docstrings to explain the purpose and usage of each function within a module.\n\n### 1.4. Component Architecture\n\nFor larger projects, consider a component-based architecture. Each component encapsulates specific AWS-related functionalities. This approach promotes modularity, testability, and reusability.\n\nExample:\n\n\ncomponents/\n├── s3/\n│   ├── s3_component.py\n│   ├── ...\n├── iam/\n│   ├── iam_component.py\n│   ├── ...\n└── ...\n\n\n### 1.5. Code Splitting\n\n*   **Break Down Complex Scripts:** Split large, complex scripts into smaller, more manageable functions or modules.\n*   **Configuration-Driven Scripts:** Use configuration files to drive script behavior, making them more flexible and reusable.\n*   **Parameterization:** Parameterize scripts to accept input variables, reducing hardcoding and improving adaptability.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Facade:** Create a facade to simplify complex AWS CLI operations.\n*   **Adapter:** Use adapters to translate between different data formats (e.g., JSON and YAML).\n*   **Strategy:** Implement different strategies for error handling or retry mechanisms.\n*   **Command Pattern:** Encapsulate AWS CLI commands as objects, facilitating command queuing, logging, and undo operations.\n\n### 2.2. Recommended Approaches\n\n*   **Configuration Management:** Use environment variables, configuration files, or AWS Systems Manager Parameter Store to manage AWS credentials and configurations.\n*   **Idempotent Scripts:** Design scripts to be idempotent, meaning that running them multiple times has the same effect as running them once.\n*   **Logging:** Implement comprehensive logging to track script execution and identify issues.\n*   **Error Handling:** Use appropriate error handling mechanisms to gracefully handle exceptions.\n*   **Progress Indicators:** Add progress indicators to provide feedback during long-running operations.\n\n### 2.3. Anti-patterns\n\n*   **Hardcoding Credentials:** Avoid hardcoding AWS credentials directly in scripts.\n*   **Lack of Error Handling:** Failing to handle exceptions can lead to unexpected script termination.\n*   **Overly Complex Scripts:** Overly complex scripts are difficult to maintain and debug.\n*   **Ignoring Security Best Practices:** Neglecting security best practices can lead to vulnerabilities.\n*   **Not using IaC:** Managing infrastructure manually instead of using Infrastructure as Code (IaC) tools such as CloudFormation or Terraform.\n\n### 2.4. State Management\n\n*   **AWS Systems Manager Parameter Store:** Use Parameter Store to store and manage configuration data and secrets.\n*   **DynamoDB:** Use DynamoDB to store application state data.\n*   **S3:** Store state data in S3 buckets, ensuring proper access control.\n*   **CloudFormation Stack Outputs:** If using CloudFormation, use stack outputs to manage state information.\n*   **Terraform State:** If using Terraform, properly manage the Terraform state file (e.g., using S3 backend with DynamoDB lock). Never commit the state file to version control.\n\n### 2.5. Error Handling\n\n*   **Try-Except Blocks:** Use `try-except` blocks in Python to handle exceptions.\n*   **Error Codes:** Check for specific error codes returned by AWS CLI commands.\n*   **Retry Mechanisms:** Implement retry mechanisms with exponential backoff for transient errors.\n*   **Alerting:** Set up alerting to notify administrators of critical errors.\n*   **Consistent Error Messages:** Provide clear, informative error messages that help in debugging.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Parallel Execution:** Use parallel processing to execute multiple AWS CLI commands concurrently.\n*   **Caching:** Cache frequently accessed data to reduce API calls.\n*   **Pagination:** Use pagination to retrieve large datasets in smaller chunks.\n*   **Filtering:** Filter data on the server-side to reduce the amount of data transferred.\n*   **Asynchronous Operations:**  Utilize asynchronous operations when possible to avoid blocking the main thread of execution.\n\n### 3.2. Memory Management\n\n*   **Large Datasets:** Avoid loading large datasets into memory at once.  Use iterators or generators to process data in chunks.\n*   **Resource Cleanup:** Ensure that resources are properly released after use to prevent memory leaks.\n*   **Efficient Data Structures:** Use efficient data structures to minimize memory consumption.\n\n### 3.3. Rendering Optimization (If applicable)\n\nN/A - The AWS CLI is not a rendering library.\n\n### 3.4. Bundle Size Optimization (If applicable)\n\nN/A - Bundle size optimization is not directly relevant to the AWS CLI itself, but it might be relevant for tools built on top of it that are distributed as standalone applications.\n\n### 3.5. Lazy Loading\n\n*   **Import Modules on Demand:** Import modules only when they are needed to reduce startup time.\n*   **Load Configuration As Needed:** Load configuration data only when it is required.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Credential Exposure:** Exposing AWS credentials in code or configuration files.\n*   **Insufficient Access Control:** Granting excessive permissions to IAM roles or users.\n*   **SQL Injection (if applicable):**  If constructing SQL queries dynamically, protect against SQL injection.\n*   **Cross-Site Scripting (XSS) (if applicable):** If the CLI interacts with web interfaces, sanitize inputs to prevent XSS.\n*   **Command Injection:**  If constructing shell commands dynamically from user inputs, sanitize inputs to prevent command injection.\n\n### 4.2. Input Validation\n\n*   **Sanitize Inputs:** Sanitize all user inputs to prevent malicious code injection.\n*   **Validate Data Types:** Validate that input data conforms to expected data types.\n*   **Limit Input Lengths:** Limit the length of input strings to prevent buffer overflows.\n*   **Regular Expressions:** Use regular expressions to validate input patterns.\n*   **Whitelist Allowed Values:**  If applicable, use a whitelist of allowed values rather than a blacklist.\n\n### 4.3. Authentication and Authorization\n\n*   **IAM Roles:** Use IAM roles to grant permissions to AWS resources.\n*   **Least Privilege:** Follow the principle of least privilege when granting permissions.\n*   **Multi-Factor Authentication (MFA):** Enable MFA for all IAM users.\n*   **Credential Rotation:** Rotate AWS credentials regularly.\n*   **IAM Policies:** Implement granular IAM policies to control access to resources.\n\n### 4.4. Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Access Control Lists (ACLs):** Use ACLs to control access to S3 buckets and objects.\n*   **Data Masking:** Mask sensitive data to prevent unauthorized access.\n*   **Regular Backups:** Create regular backups of critical data.\n*   **Secure Logging:**  Ensure that logs do not contain sensitive information and are stored securely.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **TLS:** Enforce TLS 1.2 or higher for secure connections.\n*   **API Gateway:** Use API Gateway to secure and manage API endpoints.\n*   **Rate Limiting:** Implement rate limiting to prevent denial-of-service attacks.\n*   **WAF (Web Application Firewall):** Use WAF to protect against common web exploits.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Mock AWS CLI Calls:** Use mocking libraries to simulate AWS CLI calls and verify expected behavior.\n*   **Test Individual Functions:** Write unit tests for each function or module.\n*   **Boundary Conditions:** Test boundary conditions and edge cases.\n*   **Assertion Libraries:** Use assertion libraries to verify expected results.\n\n### 5.2. Integration Testing\n\n*   **Test End-to-End Workflows:** Test complete workflows that involve multiple AWS services.\n*   **Use Real AWS Resources:** Use real AWS resources in a test environment.\n*   **Automated Test Execution:** Automate integration tests as part of the CI/CD pipeline.\n*   **Verify Resource Creation and Deletion:** Ensure that resources are created and deleted correctly during testing.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate Real-World Scenarios:** Simulate real-world scenarios to test the application's overall behavior.\n*   **Automated Test Scripts:** Create automated test scripts to verify functionality.\n*   **Monitor System Behavior:** Monitor system behavior during end-to-end tests.\n\n### 5.4. Test Organization\n\n*   **Dedicated Test Directory:** Store test files in a dedicated directory (e.g., `tests/`).\n*   **Test Naming Conventions:** Follow consistent test naming conventions.\n*   **Test Suites:** Group related tests into test suites.\n*   **Test Reports:** Generate test reports to track test results.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock AWS CLI:** Use mocking libraries to simulate AWS CLI behavior.\n*   **Stub External Dependencies:** Stub external dependencies to isolate components during testing.\n*   **Control Test Data:** Use controlled test data to ensure predictable test results.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Incorrect IAM Permissions:** Granting insufficient or excessive IAM permissions.\n*   **Missing Configuration:** Failing to configure the AWS CLI properly.\n*   **Hardcoding Values:** Hardcoding values instead of using configuration files or environment variables.\n*   **Ignoring Error Messages:** Ignoring error messages can lead to unexpected behavior.\n*   **Not Using Pagination:** Retrieving incomplete datasets due to lack of pagination.\n\n### 6.2. Edge Cases\n\n*   **Rate Limiting:** Handling API rate limits gracefully.\n*   **Service Outages:** Handling service outages or transient errors.\n*   **Data Consistency:** Ensuring data consistency across multiple AWS services.\n*   **Concurrency Issues:** Managing concurrency issues when multiple scripts access the same resources.\n\n### 6.3. Version-Specific Issues\n\n*   **API Changes:** Handling API changes across different AWS CLI versions.\n*   **Deprecated Features:** Avoiding deprecated features.\n*   **Compatibility Issues:** Addressing compatibility issues between different AWS CLI versions and AWS services.\n\n### 6.4. Compatibility Concerns\n\n*   **Operating Systems:** Ensuring compatibility across different operating systems (e.g., Linux, Windows, macOS).\n*   **Programming Languages:** Addressing compatibility issues with different programming languages.\n*   **Third-Party Libraries:** Managing dependencies on third-party libraries.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Use comprehensive logging to track script execution.\n*   **Debugging Tools:** Use debugging tools to step through code and inspect variables.\n*   **Error Messages:** Analyze error messages carefully to identify the root cause of issues.\n*   **Verbose Mode:** Use verbose mode to print detailed information about AWS CLI commands.\n*   **AWS CloudTrail:** Use AWS CloudTrail to track API calls and identify potential issues.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **AWS CLI:** The core command-line interface for interacting with AWS services.\n*   **Text Editor/IDE:** A suitable text editor or IDE for writing scripts (e.g., VS Code, Sublime Text, PyCharm).\n*   **Version Control:** Git for version control.\n*   **Shell:** Bash, Zsh, or PowerShell for running scripts.\n*   **Python (if applicable):** Python for scripting and automation.\n*   **jq:** A command-line JSON processor.\n*   **yq:** A command-line YAML processor.\n\n### 7.2. Build Configuration\n\n*   **Makefile:** Use Makefiles to automate common build tasks.\n*   **Build Scripts:** Create build scripts to package and deploy applications.\n*   **Dependency Management:** Use appropriate dependency management tools (e.g., pip for Python).\n\n### 7.3. Linting and Formatting\n\n*   **Shellcheck:** Use Shellcheck to lint shell scripts.\n*   **Pylint:** Use Pylint to lint Python code.\n*   **Black:** Use Black to format Python code.\n*   **YAML Lint:** Use a YAML linter to validate YAML files.\n\n### 7.4. Deployment\n\n*   **AWS CloudFormation:** Deploy infrastructure as code using AWS CloudFormation.\n*   **AWS CodeDeploy:** Automate application deployments using AWS CodeDeploy.\n*   **AWS Lambda:** Deploy serverless functions using AWS Lambda.\n*   **Docker:** Containerize applications using Docker.\n\n### 7.5. CI/CD Integration\n\n*   **AWS CodePipeline:** Use AWS CodePipeline to automate the CI/CD process.\n*   **Jenkins:** Integrate with Jenkins for continuous integration.\n*   **GitHub Actions:** Use GitHub Actions for CI/CD.\n*   **Automated Testing:** Integrate automated testing into the CI/CD pipeline.\n\n## Infrastructure as Code (IaC)\n\n*   Treat your infrastructure as code using tools like AWS CloudFormation or Terraform. This allows for version control, consistent deployments, and easier management of infrastructure changes.\n\n## Continuous Integration/Continuous Deployment (CI/CD)\n\n*   Implement CI/CD pipelines using AWS CodePipeline, ensuring that all code changes are automatically tested and deployed. This includes defining clear stages for building, testing, and deploying applications, and incorporating security checks throughout the pipeline.\n\n## Security\n\n*   Employ least-privilege access controls using IAM, enforce multi-factor authentication (MFA), and regularly review permissions. Security should be integrated at every stage of the development and deployment process.\n\n## Automate tasks\n\n*   Automate repetitive tasks to increase efficiency and reduce errors.\n\n## Version control\n\n*   Ensure robust version control for all code and configuration files.\n\n## Prioritize testing\n\n*   Integrate comprehensive testing at every stage to ensure code quality.\n\n## Maintain and adapt\n\n*   Regularly update and adapt the pipeline to evolving requirements.\n\n## Monitor and analyze\n\n*   Continuously monitor and analyze pipeline performance and outcomes.\n\n## IAM Best Practices:\n\n*   Require human users to use federation with an identity provider to access AWS using temporary credentials\n*   Require workloads to use temporary credentials with IAM roles to access AWS\n*   Require multi-factor authentication (MFA)\n*   Update access keys when needed for use cases that require long-term credentials\n*   Follow best practices to protect your root user credentials\n*   Apply least-privilege permissions\n*   Get started with AWS managed policies and move toward least-privilege permissions\n*   Use IAM Access Analyzer to generate least-privilege policies based on access activity\n*   Regularly review and remove unused users, roles, permissions, policies, and credentials\n*   Use conditions in IAM policies to further restrict access\n*   Verify public and cross-account access to resources with IAM Access Analyzer\n*   Use IAM Access Analyzer to validate your IAM policies to ensure secure and functional permissions\n*   Establish permissions guardrails across multiple accounts\n*   Use permissions boundaries to delegate permissions management within an account\n\nBy adhering to these best practices, you can develop robust, secure, and efficient AWS CLI applications.",
    "metadata": {
      "globs": "*.sh,*.py,*.yml,*.yaml,*.tf,*.json,*.md",
      "format": "mdc",
      "originalFile": "aws-cli.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "cli",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "developing",
      "managing",
      "resources",
      "aws-cli",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-cli",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws-dynamodb",
    "description": "This rule provides best practices and coding standards for developing applications using AWS DynamoDB. It covers aspects like schema design, performance optimization, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "aws-dynamodb",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-dynamodb.mdc",
    "content": "- **Minimize the number of tables; prefer single-table design.** Having fewer tables keeps things more scalable, requires less permissions management, and reduces overhead for your DynamoDB application. Consider using a single table with appropriate use of primary and secondary indexes.\n- **Identify query patterns before schema design.** Understand the application's access patterns before designing the DynamoDB schema. Knowing how the data will be queried is crucial for optimizing performance and cost.\n- **Use sort order for related items and distribute queries to avoid hot spots.** Group related items together by utilizing sort keys and design data keys to distribute traffic evenly across partitions.\n- **Prefer queries over scans for efficiency.** DynamoDB queries are more efficient and less costly than scan operations. Always aim to use queries that filter based on partition and sort keys.\n- **Use caching to reduce read/write costs.** Implement caching strategies, such as AWS ElastiCache or DynamoDB Accelerator (DAX), to minimize DynamoDB read/write costs.  Use appropriate invalidation logic.\n- **Validate data integrity in the application layer.** Since DynamoDB doesn't enforce relationship data or integrity constraints, it's essential to perform strict data validations in the application or business layer.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure Best Practices:**\n    - `src/`: Contains the application's source code.\n    - `src/models/`: Defines data models representing DynamoDB entities.\n    - `src/services/`: Implements business logic and interacts with DynamoDB.\n    - `src/repositories/`: Handles DynamoDB data access operations.\n    - `src/utils/`: Contains utility functions (e.g., data validation, error handling).\n    - `tests/`: Includes unit, integration, and end-to-end tests.\n    - `config/`: Stores configuration files (e.g., DynamoDB table names, AWS region).\n- **File Naming Conventions:**\n    - Use descriptive names for files and directories.\n    - Model files: `user.model.js` or `user.model.ts`\n    - Service files: `user.service.js` or `user.service.ts`\n    - Repository files: `user.repository.js` or `user.repository.ts`\n    - Test files: `user.service.test.js` or `user.service.test.ts`\n- **Module Organization Best Practices:**\n    - Encapsulate DynamoDB interactions within dedicated modules (e.g., repositories).\n    - Use dependency injection to manage dependencies (e.g., DynamoDB client).\n    - Follow the single responsibility principle for modules.\n- **Component Architecture Recommendations:**\n    - Adopt a layered architecture (e.g., presentation, application, domain, infrastructure).\n    - Decouple components to improve maintainability and testability.\n    - Use interfaces to define contracts between components.\n- **Code Splitting Strategies:**\n    - Bundle only the necessary aws-sdk/client-dynamodb code by using tree shaking and only importing the necessary modules.\n    - Implement lazy loading for less frequently used features.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Repository Pattern:** Abstract DynamoDB data access logic.\n    - **Data Mapper Pattern:** Transform data between application and DynamoDB formats.\n    - **Single Table Design Pattern:** Minimize tables by using composite keys and attributes to represent different entity types and relationships.\n    - **Composite Keys Pattern:** Combine attributes to create partition and sort keys.\n- **Recommended Approaches for Common Tasks:**\n    - **Creating Items:** Use the `PutItem` operation.\n    - **Reading Items:** Use the `GetItem` operation for single items and `Query` for sets.\n    - **Updating Items:** Use the `UpdateItem` operation for granular updates.\n    - **Deleting Items:** Use the `DeleteItem` operation.\n    - **Querying Data:**  Utilize indexes (GSI/LSI) to optimize query performance.  Use projection expressions to return only required attributes.\n    - **Scanning Data (Avoid when possible):** If scanning is unavoidable, use `Limit` and `ExclusiveStartKey` for pagination and consider parallel scans for large datasets.\n- **Anti-patterns and Code Smells:**\n    - **Over-fetching Data:** Avoid retrieving unnecessary attributes.\n    - **Excessive Scanning:**  Design schemas and queries to minimize scans.\n    - **Hardcoding Table Names:**  Use configuration files or environment variables.\n    - **Ignoring Error Handling:**  Implement robust error handling with retries and logging.\n    - **Insufficient Data Validation:**  Validate data before writing to DynamoDB.\n    - **Hot Partitioning:** Design partitions to distribute data evenly and prevent overload of specific partitions.\n- **State Management Best Practices:**\n    - Use DynamoDB to persist application state (e.g., user sessions, feature flags).\n    - Implement atomic counters and conditional updates to manage concurrent access.\n- **Error Handling Patterns:**\n    - Use try-catch blocks to handle DynamoDB errors.\n    - Implement retry mechanisms for transient errors (e.g., throttling).\n    - Log errors with sufficient context for debugging.\n    - Use custom exception classes to categorize DynamoDB errors.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Minimize Read Capacity Units (RCUs) and Write Capacity Units (WCUs):** Optimize queries and writes to consume fewer RCUs and WCUs. Use projection expressions to return only the attributes you need.\n    - **Use Batch Operations:** Use `BatchGetItem` and `BatchWriteItem` for bulk operations.\n    - **Optimize Data Sizes:**  Keep item sizes small to reduce storage costs and improve performance. If items exceed the size limit, consider storing larger attributes in S3 and referencing them in DynamoDB.\n    - **Use Parallel Scans (with caution):** Use parallel scans to speed up full table scans, but be aware of the increased RCUs consumption.\n    - **Optimize Index Usage:** Use indexes effectively to support query patterns.  Be mindful of the cost implications of GSI writes.\n    - **Leverage DynamoDB Accelerator (DAX):** Use DAX for in-memory caching to reduce latency and RCU consumption.\n- **Memory Management Considerations:**\n    - Avoid loading large datasets into memory.\n    - Use pagination to process data in chunks.\n    - Release resources promptly after use.\n- **Bundle Size Optimization Strategies:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused dependencies.\n    - Optimize image sizes (if applicable).\n- **Lazy Loading Strategies:**\n    - Load data on demand when needed.\n    - Use placeholders for content that is not immediately visible.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and Prevention:**\n    - **Injection Attacks:** Prevent NoSQL injection by validating and sanitizing user inputs.\n    - **Unauthorized Access:** Implement proper authentication and authorization mechanisms.\n    - **Data Exposure:** Encrypt sensitive data at rest and in transit.\n- **Input Validation Best Practices:**\n    - Validate data types, formats, and ranges.\n    - Sanitize inputs to prevent injection attacks.\n    - Use input validation libraries (e.g., Joi, Validator.js).\n- **Authentication and Authorization Patterns:**\n    - Use AWS Identity and Access Management (IAM) roles and policies to control access to DynamoDB resources.\n    - Implement fine-grained access control using conditional IAM policies.\n    - Consider using AWS Cognito for user authentication and authorization.\n- **Data Protection Strategies:**\n    - Enable encryption at rest and in transit for DynamoDB tables.\n    - Use AWS Key Management Service (KMS) to manage encryption keys.\n    - Implement data masking and tokenization for sensitive data.\n    - Comply with data privacy regulations (e.g., GDPR, CCPA).\n- **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement API authentication and authorization.\n    - Protect against cross-site scripting (XSS) and cross-site request forgery (CSRF) attacks.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Mock DynamoDB client using libraries like `aws-sdk-mock` or `jest-mock-extended`.\n    - Test individual functions and modules in isolation.\n    - Verify that functions correctly interact with the mocked DynamoDB client.\n- **Integration Testing Approaches:**\n    - Test the integration between different modules and components.\n    - Use a local DynamoDB instance (e.g., DynamoDB Local, Docker image) for integration tests.\n    - Verify that data is correctly written to and read from DynamoDB.\n- **End-to-end Testing Recommendations:**\n    - Test the entire application flow from the user interface to DynamoDB.\n    - Use a staging environment that mirrors the production environment.\n    - Verify that the application meets all functional and non-functional requirements.\n- **Test Organization Best Practices:**\n    - Organize tests by module or component.\n    - Use descriptive names for test cases.\n    - Follow the AAA (Arrange, Act, Assert) pattern.\n- **Mocking and Stubbing Techniques:**\n    - Use mocking libraries to create mock objects for DynamoDB client.\n    - Use stubbing to replace real dependencies with controlled test values.\n    - Verify that mocked methods are called with the expected parameters.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Forgetting to handle pagination when querying large datasets.\n    - Not understanding DynamoDB capacity units (RCUs and WCUs) and throttling.\n    - Using inefficient query patterns.\n    - Neglecting to implement proper error handling.\n    - Designing schemas that lead to hot partitions.\n- **Edge Cases:**\n    - Handling large item sizes exceeding DynamoDB's limits.\n    - Dealing with eventual consistency when reading data.\n    - Managing concurrent updates to the same item.\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in aws-sdk/client-dynamodb versions.\n    - Consult the AWS documentation and release notes for migration guides.\n- **Compatibility Concerns:**\n    - Ensure compatibility between aws-sdk/client-dynamodb and other libraries.\n- **Debugging Strategies:**\n    - Use AWS CloudWatch Logs to monitor DynamoDB operations.\n    - Enable DynamoDB Streams to capture changes to DynamoDB tables.\n    - Use the AWS X-Ray service for distributed tracing.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - AWS CLI\n    - AWS SDK for Javascript/Typescript\n    - DynamoDB Local (for local development)\n    - NoSQL Workbench for DynamoDB (for data modeling).\n- **Build Configuration Best Practices:**\n    - Use a build tool (e.g., webpack, Parcel, esbuild) to bundle and optimize code.\n    - Configure environment variables for DynamoDB table names, AWS region, and credentials.\n    - Use `.env` files or AWS Systems Manager Parameter Store to manage configuration data.\n- **Linting and Formatting Recommendations:**\n    - Use ESLint or TSLint for linting.\n    - Use Prettier for code formatting.\n    - Configure linting and formatting rules to enforce consistent code style.\n- **Deployment Best Practices:**\n    - Use infrastructure-as-code tools (e.g., AWS CloudFormation, AWS CDK, Terraform) to provision DynamoDB resources.\n    - Implement blue/green deployments or canary deployments to minimize downtime.\n    - Automate deployments using CI/CD pipelines.\n- **CI/CD Integration Strategies:**\n    - Use CI/CD tools (e.g., Jenkins, GitLab CI, CircleCI, AWS CodePipeline) to automate the build, test, and deployment process.\n    - Run unit and integration tests in the CI/CD pipeline.\n    - Deploy code to staging environments for testing and validation before deploying to production.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx,*.py",
      "format": "mdc",
      "originalFile": "aws-dynamodb.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "dynamodb",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "applications",
      "using",
      "aws-dynamodb",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-dynamodb",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws-ecs",
    "description": "This rule covers best practices for developing, deploying, and maintaining applications using AWS Elastic Container Service (ECS). It includes guidance on code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "aws-ecs",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-ecs.mdc",
    "content": "- **General Principles:**\n  - **Infrastructure as Code (IaC):** Treat your ECS infrastructure as code. Use tools like Terraform, AWS CloudFormation, or AWS CDK to define and manage your ECS clusters, task definitions, and services.\n  - **Configuration Management:** Externalize configuration from your application code. Use environment variables, AWS Secrets Manager, or AWS Systems Manager Parameter Store to manage configuration data.\n  - **Idempotency:** Ensure that your deployment scripts and automation are idempotent. This means that running the same script multiple times should have the same result as running it once.\n  - **Automation:** Automate all aspects of your ECS deployment, from building container images to deploying services and scaling resources.\n\n- **1. Code Organization and Structure:**\n  - **1.1 Directory Structure:**\n    - **Project Root:** The base directory containing all project-related files.\n    - `infrastructure/`: Contains IaC code (Terraform, CloudFormation) for ECS clusters, task definitions, services, VPC, etc.\n    - `application/`: Contains source code for your containerized application.\n      - `src/`: Application source code.\n      - `tests/`: Unit, integration, and end-to-end tests.\n      - `Dockerfile`: Dockerfile for building the application container image.\n    - `scripts/`: Contains deployment, build, and other utility scripts.\n    - `docs/`: Documentation for the project.\n    - `README.md`: Project README file.\n\n  - **1.2 File Naming Conventions:**\n    - **Terraform:** `main.tf`, `variables.tf`, `outputs.tf`, `<module_name>.tf`\n    - **CloudFormation:** `<stack_name>.yml` or `<stack_name>.yaml`\n    - **Docker:** `Dockerfile` (no extension), `.dockerignore`\n    - **Scripts:** `<script_name>.sh` (Bash), `<script_name>.py` (Python)\n    - **Configuration:** `config.yml`, `config.json`, `.env`\n\n  - **1.3 Module Organization:**\n    - **Terraform Modules:** Create reusable Terraform modules for common ECS infrastructure components (e.g., ECS cluster, task definition, load balancer).\n    - **Application Modules:** Organize your application code into logical modules based on functionality (e.g., authentication, API, database access).\n    -  Use separate git repositories for independent services/applications, and ECS services accordingly. This avoids monolithic deployments and allows independent scaling and versioning.\n\n  - **1.4 Component Architecture:**\n    - **Microservices:** Design your application as a collection of microservices, each deployed as an independent ECS service.\n    - **API Gateway:** Use an API gateway (e.g., Amazon API Gateway) to route requests to different ECS services.\n    - **Message Queue:** Use a message queue (e.g., Amazon SQS, Amazon MQ) for asynchronous communication between services.\n    - **Database:** Use a managed database service (e.g., Amazon RDS, Amazon DynamoDB) for data persistence. Ensure proper security and access control configurations.\n\n  - **1.5 Code Splitting:**\n    - Break down large applications or services into smaller, more manageable components that can be deployed independently.\n    - Optimize container images to only include code required for each specific component.\n    - Utilize ECS services to deploy each component separately, enabling independent scaling and upgrades.\n\n- **2. Common Patterns and Anti-patterns:**\n  - **2.1 Design Patterns:**\n    - **Sidecar:** Use sidecar containers (e.g., for logging, monitoring, or service mesh) to add functionality to your main application container without modifying the application code. Use a separate container in the same task definition.\n    - **Backend for Frontend (BFF):** Create a BFF layer that provides a specific API for each client application, improving performance and security.\n    - **Strangler Fig:** Gradually migrate a legacy application to ECS by introducing new microservices and slowly replacing the old functionality.\n    - **Aggregator Pattern:** Use an aggregator service to combine data from multiple backend services into a single response.\n\n  - **2.2 Recommended Approaches:**\n    - **Health Checks:** Implement robust health checks for your containers and configure ECS to use them.  Use both `HEALTHCHECK` in the `Dockerfile` for initial container health and ECS health checks (ELB health checks) for service availability.\n    - **Service Discovery:** Use service discovery (e.g., AWS Cloud Map) to enable services to find each other dynamically.\n    - **Load Balancing:** Use a load balancer (e.g., Application Load Balancer, Network Load Balancer) to distribute traffic across multiple ECS tasks.\n    - **Auto Scaling:** Configure auto scaling to automatically adjust the number of ECS tasks based on demand.  Use CloudWatch metrics (CPU, memory, request count) as scaling triggers.\n    - **Immutable Infrastructure:** Avoid making changes to running containers. Instead, redeploy a new container image with the changes.\n    - **Use ECS Exec for debugging** avoid SSH into running EC2 instances\n\n  - **2.3 Anti-patterns:**\n    - **Hardcoding Configuration:** Avoid hardcoding configuration values in your application code.\n    - **Large Container Images:** Keep your container images small by using multi-stage builds and removing unnecessary dependencies.\n    - **Ignoring Security Best Practices:** Neglecting security best practices can lead to vulnerabilities. Always follow security best practices for container images, task definitions, and IAM roles.\n    - **Manual Scaling:** Manually scaling ECS tasks is inefficient and error-prone. Use auto scaling instead.\n    - **Monolithic Containers:** Avoid creating single containers that run multiple applications. Break them down into smaller, single-purpose containers.\n\n  - **2.4 State Management:**\n    - **Stateless Applications:** Design your applications to be stateless whenever possible. Store state in a database or other external storage service.\n    - **Persistent Storage:** Use persistent storage volumes (e.g., Amazon EFS, Amazon EBS) for stateful applications.\n    - **Container Lifecycle:** Understand the container lifecycle and how ECS manages container restarts and replacements.\n\n  - **2.5 Error Handling:**\n    - **Logging:** Implement comprehensive logging and monitoring for your applications. Log to stdout/stderr, and use a logging driver (e.g., FireLens) to ship logs to a central logging service (e.g., CloudWatch Logs, Splunk).\n    - **Exception Handling:** Implement proper exception handling in your application code.\n    - **Retry Logic:** Implement retry logic for transient errors.\n    - **Dead Letter Queues:** Use dead letter queues (DLQs) to handle messages that cannot be processed after multiple retries.\n\n- **3. Performance Considerations:**\n  - **3.1 Optimization Techniques:**\n    - **Resource Allocation:** Properly size your ECS tasks based on the application's resource requirements (CPU, memory).  Monitor resource utilization and adjust task sizes as needed.\n    - **Container Image Optimization:** Optimize container images by minimizing size, using efficient base images, and leveraging layer caching.  Use tools like `docker image prune` to remove unused images.\n    - **Load Balancing:** Configure load balancing algorithms and connection draining to optimize traffic distribution and minimize downtime.\n    - **Caching:** Implement caching at various levels (e.g., application, CDN) to reduce latency and improve performance.\n    - **Connection Pooling:** Reuse database connections to minimize overhead.\n\n  - **3.2 Memory Management:**\n    - **Memory Limits:** Set appropriate memory limits for your containers.  Monitor memory usage and adjust limits to prevent out-of-memory errors.\n    - **Garbage Collection:** Optimize garbage collection settings for your application's runtime environment.\n    - **Memory Leaks:** Identify and fix memory leaks in your application code.\n\n  - **3.3 Bundle Size Optimization:**\n    - **Code Splitting:** Split your application code into smaller bundles to reduce the initial load time.  Utilize dynamic imports to only load code when it's needed.\n    - **Tree Shaking:** Remove unused code from your application bundle.\n    - **Minification:** Minify your application code to reduce its size.\n    - **Compression:** Compress your application code to reduce its size.\n\n  - **3.4 Lazy Loading:**\n    - Load resources (e.g., images, data) only when they are needed.\n    - Use lazy-loading techniques to improve the initial load time of your application.\n\n- **4. Security Best Practices:**\n  - **4.1 Common Vulnerabilities:**\n    - **Container Image Vulnerabilities:** Unpatched vulnerabilities in container images can be exploited by attackers. Regularly scan container images for vulnerabilities and apply patches.\n    - **IAM Role Misconfiguration:** Overly permissive IAM roles can allow attackers to access sensitive resources. Follow the principle of least privilege and grant only the necessary permissions.\n    - **Network Security Misconfiguration:** Misconfigured network security can expose your ECS services to unauthorized access. Use security groups and network ACLs to restrict network access.\n    - **Secrets Management Vulnerabilities:** Storing secrets in plain text can expose them to attackers. Use a secrets management service (e.g., AWS Secrets Manager) to securely store and manage secrets.\n\n  - **4.2 Input Validation:**\n    - Validate all input data to prevent injection attacks (e.g., SQL injection, command injection).\n    - Use a framework or library to perform input validation.\n\n  - **4.3 Authentication and Authorization:**\n    - Implement authentication and authorization to control access to your ECS services.\n    - Use a standard authentication protocol (e.g., OAuth 2.0, OpenID Connect).\n    - Use fine-grained authorization policies to restrict access to specific resources.\n\n  - **4.4 Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to encrypt data in transit.\n    - Use AWS KMS to encrypt data at rest.\n    - Implement data masking and tokenization to protect sensitive data.\n\n  - **4.5 Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement authentication and authorization for all API endpoints.\n    - Validate all input data to prevent injection attacks.\n    - Protect against Cross-Site Request Forgery (CSRF) attacks.\n\n- **5. Testing Approaches:**\n  - **5.1 Unit Testing:**\n    - Write unit tests for individual components of your application.\n    - Use a unit testing framework (e.g., JUnit, pytest).\n    - Mock external dependencies to isolate the component being tested.\n\n  - **5.2 Integration Testing:**\n    - Write integration tests to verify the interaction between different components of your application.\n    - Use a test environment that is similar to the production environment.\n    - Test the integration with external services (e.g., databases, message queues).\n\n  - **5.3 End-to-End Testing:**\n    - Write end-to-end tests to verify the functionality of the entire application.\n    - Use an end-to-end testing framework (e.g., Selenium, Cypress).\n    - Test the application from the user's perspective.\n\n  - **5.4 Test Organization:**\n    - Organize your tests into a logical directory structure.\n    - Use meaningful names for your test files and test methods.\n    - Use a test runner to execute your tests.\n\n  - **5.5 Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components during testing.\n    - Use a mocking framework (e.g., Mockito, EasyMock).\n    - Create mock objects that simulate the behavior of external dependencies.\n\n- **6. Common Pitfalls and Gotchas:**\n  - **6.1 Frequent Mistakes:**\n    - **Incorrect IAM Permissions:** Granting insufficient or excessive IAM permissions can lead to security vulnerabilities or application failures.\n    - **Misconfigured Network Settings:** Misconfigured network settings can prevent containers from communicating with each other or with external services.\n    - **Insufficient Resource Limits:** Setting insufficient resource limits (CPU, memory) can cause containers to crash or become unresponsive.\n    - **Ignoring Health Checks:** Ignoring health checks can lead to ECS tasks being considered healthy even when they are not.\n    - **Failing to handle SIGTERM signals:**  Applications in containers must gracefully handle SIGTERM signals to allow ECS to shutdown tasks cleanly.\n\n  - **6.2 Edge Cases:**\n    - **Task Placement Constraints:** Be aware of task placement constraints (e.g., availability zone, instance type) and how they can affect task scheduling.\n    - **Service Discovery Limitations:** Understand the limitations of service discovery and how it can affect service resolution.\n    - **Load Balancer Connection Draining:** Be aware of load balancer connection draining and how it can affect application availability during deployments.\n\n  - **6.3 Version-Specific Issues:**\n    - Stay up-to-date with the latest ECS agent and Docker versions to avoid known issues and security vulnerabilities.\n    - Check the AWS documentation for any version-specific issues or known bugs.\n\n  - **6.4 Compatibility Concerns:**\n    - Be aware of compatibility issues between ECS and other AWS services (e.g., VPC, IAM, CloudWatch).\n    - Test your application with different versions of these services to ensure compatibility.\n\n  - **6.5 Debugging Strategies:**\n    - **Logging:** Use comprehensive logging to track application behavior and identify errors.\n    - **Monitoring:** Use monitoring tools (e.g., CloudWatch) to track resource utilization and application performance.\n    - **Debugging Tools:** Use debugging tools (e.g., Docker exec, AWS Systems Manager Session Manager) to troubleshoot running containers.\n    - **ECS Exec:** Utilize the ECS Exec feature to directly connect to containers for debugging purposes.\n\n- **7. Tooling and Environment:**\n  - **7.1 Recommended Tools:**\n    - **Terraform:** For infrastructure as code.\n    - **AWS CLI:** For interacting with AWS services from the command line.\n    - **Docker:** For building and managing container images.\n    - **AWS SAM CLI:** For local development of serverless applications.\n    - **Visual Studio Code (VS Code):** With AWS and Docker extensions for development and debugging.\n    - **cdk8s:** Define Kubernetes applications and ECS using general purpose programming languages.\n\n  - **7.2 Build Configuration:**\n    - **Makefile:** Use a Makefile to automate build, test, and deployment tasks.\n    - **Build Scripts:** Use build scripts to customize the build process.\n    - **CI/CD Pipeline:** Integrate your build process with a CI/CD pipeline (e.g., AWS CodePipeline, Jenkins).\n\n  - **7.3 Linting and Formatting:**\n    - **Linters:** Use linters (e.g., ESLint, Pylint) to enforce code style and identify potential errors.\n    - **Formatters:** Use formatters (e.g., Prettier, Black) to automatically format your code.\n    - **Editor Integration:** Integrate linters and formatters with your code editor.\n\n  - **7.4 Deployment:**\n    - **Blue/Green Deployments:** Use blue/green deployments to minimize downtime during deployments.\n    - **Canary Deployments:** Use canary deployments to gradually roll out new versions of your application.\n    - **Rolling Updates:** Use rolling updates to gradually update ECS tasks with the new version.\n\n  - **7.5 CI/CD Integration:**\n    - **Automated Builds:** Automate the build process using a CI/CD pipeline.\n    - **Automated Tests:** Run automated tests as part of the CI/CD pipeline.\n    - **Automated Deployments:** Automate the deployment process using a CI/CD pipeline.",
    "metadata": {
      "globs": "*.tf,*.yml,*.yaml,*.json,*.sh,*.dockerfile",
      "format": "mdc",
      "originalFile": "aws-ecs.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "ecs",
      "this",
      "rule",
      "covers",
      "best",
      "practices",
      "developing",
      "deploying",
      "maintaining",
      "applications",
      "using",
      "aws-ecs",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-ecs",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws-lambda",
    "description": "Comprehensive guide for AWS Lambda development, covering best practices for code organization, performance, security, testing, and common pitfalls. Focuses on building robust, scalable, and secure serverless applications using AWS Lambda.",
    "author": "sanjeed5",
    "tags": [
      "aws-lambda",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-lambda.mdc",
    "content": "- **Use Documented APIs Only:** Rely solely on AWS Lambda's documented APIs to ensure compatibility and avoid unexpected behavior. Do not use undocumented or internal APIs.\n\n- **Single Responsibility Principle:** Design Lambda functions to perform a single, well-defined task. This promotes modularity, testability, and maintainability.\n\n- **Native AWS Integrations:** Prefer native AWS integrations (e.g., SQS, SNS, Kinesis) for passing data between services instead of custom code, which enhances scalability and reduces complexity.\n\n- **Local Dependencies:** Store and reference dependencies locally within the Lambda function package to minimize latency and improve cold start times.\n\n- **Limit Variable Re-initialization:** Initialize variables outside the function handler to leverage execution context reuse and reduce initialization overhead.\n\n- **Thorough Testing:** Implement a comprehensive testing strategy including unit, integration, and end-to-end tests to ensure function correctness and reliability.\n\n## 1. Code Organization and Structure:\n\n   - **Directory Structure:**\n      - Organize code into logical directories based on functionality (e.g., `src`, `tests`, `utils`).\n      - Separate handler logic from core business logic.\n      - Example:\n        \n        my-lambda-function/\n        ├── src/\n        │   ├── handler.js       # Lambda handler function\n        │   ├── business-logic.js # Core business logic\n        │   └── utils.js          # Utility functions\n        ├── tests/\n        │   ├── handler.test.js  # Unit tests for handler.js\n        │   └── ...\n        ├── package.json         # Dependencies and scripts\n        └── ...\n        \n\n   - **File Naming Conventions:**\n      - Use descriptive and consistent file names.\n      - Follow a naming convention (e.g., `kebab-case`, `PascalCase`) consistently.\n      - Example: `user-service.js`, `UserService.java`.\n\n   - **Module Organization:**\n      - Break down large functions into smaller, reusable modules.\n      - Use appropriate module systems (e.g., ES modules in JavaScript, packages in Python, modules in Go).\n      - Example (JavaScript):\n        javascript\n        // src/user-service.js\n        export function createUser(userData) { ... }\n        export function getUser(userId) { ... }\n        \n\n   - **Component Architecture:**\n      - Design Lambda functions as part of a larger component-based architecture.\n      - Decouple functions from specific triggers (e.g., API Gateway, SQS) to increase reusability.\n      - Implement interfaces or contracts to define interactions between components.\n\n   - **Code Splitting Strategies:**\n      - Use code splitting techniques to reduce Lambda function package size.\n      - Implement dynamic imports or lazy loading for infrequently used modules (where supported by the runtime).\n      - Leverage layers for shared dependencies across multiple functions.\n\n## 2. Common Patterns and Anti-patterns:\n\n   - **Design Patterns:**\n      - **Event-Driven Architecture:** Design functions to respond to events from various AWS services.\n      - **Command Pattern:** Encapsulate requests as objects to decouple request processing from the handler.\n      - **Dependency Injection:** Inject dependencies into functions to improve testability and maintainability.\n\n   - **Recommended Approaches:**\n      - **Configuration Management:** Use environment variables or AWS Systems Manager Parameter Store for configuration data.\n      - **Logging:** Implement structured logging with timestamps, request IDs, and relevant context.\n      - **Idempotency:** Ensure functions are idempotent to handle potential retry scenarios gracefully.\n\n   - **Anti-patterns:**\n      - **Monolithic Functions:** Avoid creating large, complex functions that perform multiple unrelated tasks.\n      - **Hardcoding Secrets:** Never hardcode sensitive information (e.g., API keys, passwords) in code. Use AWS Secrets Manager or environment variables.\n      - **Excessive Dependencies:** Minimize the number of dependencies to reduce package size and improve cold start times.\n\n   - **State Management:**\n      - Use external services (e.g., DynamoDB, Redis) for persistent state management.\n      - Leverage Lambda layers for caching frequently accessed data.\n      - Design functions to be stateless whenever possible.\n\n   - **Error Handling:**\n      - Implement robust error handling mechanisms, including try-catch blocks and error logging.\n      - Use custom exceptions for specific error scenarios.\n      - Return meaningful error messages to the caller.\n      - Implement dead-letter queues (DLQs) for asynchronous invocations to handle failed events.\n\n## 3. Performance Considerations:\n\n   - **Optimization Techniques:**\n      - **Minimize Package Size:** Reduce the size of the deployment package by removing unnecessary files and dependencies.\n      - **Optimize Dependencies:** Use lightweight dependencies and avoid importing entire libraries when only specific functions are needed.\n      - **Code Optimization:** Profile and optimize code for performance bottlenecks.\n      - **Connection Reuse:** Reuse database connections, HTTP clients, and other resources to minimize overhead.\n\n   - **Memory Management:**\n      - Allocate sufficient memory to Lambda functions based on their needs.\n      - Monitor memory usage and adjust the memory allocation accordingly.\n      - Clean up resources (e.g., closing file streams, releasing memory) to avoid memory leaks.\n\n   - **Cold Starts:**\n      - Minimize cold start times by reducing package size, optimizing dependencies, and using provisioned concurrency.\n      - Use initilization logic outside the handler to take advantage of container reuse\n\n   - **Bundle Size Optimization:**\n      - Use tools like Webpack or esbuild to bundle and optimize code for production.\n      - Minify code and remove unused code (dead code elimination).\n\n   - **Lazy Loading Strategies:**\n      - Implement lazy loading or dynamic imports for infrequently used modules to reduce initial load time.\n\n## 4. Security Best Practices:\n\n   - **Common Vulnerabilities:**\n      - **Injection Attacks:** Prevent SQL injection, command injection, and other injection attacks by validating and sanitizing input.\n      - **Cross-Site Scripting (XSS):** Protect against XSS vulnerabilities by encoding output properly.\n      - **Insecure Deserialization:** Avoid deserializing untrusted data to prevent arbitrary code execution.\n      - **Broken Authentication:** Implement strong authentication and authorization mechanisms.\n\n   - **Input Validation:**\n      - Validate all input data to prevent malicious or invalid data from being processed.\n      - Use schema validation libraries to enforce data types and formats.\n      - Sanitize input data to remove potentially harmful characters or code.\n\n   - **Authentication and Authorization:**\n      - Use AWS Identity and Access Management (IAM) roles to grant Lambda functions the necessary permissions.\n      - Implement authentication and authorization mechanisms to protect sensitive resources.\n      - Use AWS Cognito for user authentication and authorization.\n\n   - **Data Protection:**\n      - Encrypt sensitive data at rest and in transit.\n      - Use AWS Key Management Service (KMS) to manage encryption keys.\n      - Mask or redact sensitive data in logs.\n\n   - **Secure API Communication:**\n      - Use HTTPS for all API communication.\n      - Implement API authentication and authorization using API keys, JWT tokens, or other secure mechanisms.\n      - Protect against common web application attacks (e.g., CSRF, DDoS).\n\n## 5. Testing Approaches:\n\n   - **Unit Testing:**\n      - Write unit tests to verify the correctness of individual functions or modules.\n      - Use mocking or stubbing to isolate units of code from external dependencies.\n      - Use testing frameworks (e.g., Jest, Mocha, pytest) to automate unit testing.\n\n   - **Integration Testing:**\n      - Write integration tests to verify the interactions between different components or services.\n      - Test the integration of Lambda functions with other AWS services (e.g., SQS, DynamoDB).\n      - Use tools like AWS SAM Local to run integration tests locally.\n\n   - **End-to-End Testing:**\n      - Write end-to-end tests to verify the entire application flow from end to end.\n      - Simulate user interactions to test the application's functionality.\n      - Use tools like Selenium or Cypress to automate end-to-end testing.\n\n   - **Test Organization:**\n      - Organize tests into separate directories based on the type of test (e.g., unit, integration, e2e).\n      - Use descriptive test names to clearly identify the purpose of each test.\n      - Follow a consistent testing strategy across all projects.\n\n   - **Mocking and Stubbing:**\n      - Use mocking or stubbing to replace external dependencies with controlled test doubles.\n      - Mock AWS SDK calls to isolate Lambda functions from AWS services.\n      - Use mocking frameworks (e.g., Jest, Sinon.js) to simplify mocking and stubbing.\n\n## 6. Common Pitfalls and Gotchas:\n\n   - **Frequent Mistakes:**\n      - **Incorrect IAM Permissions:** Ensure that Lambda functions have the necessary IAM permissions to access required AWS resources.\n      - **Timeout Errors:** Increase the Lambda function timeout if it takes longer than expected to complete.\n      - **Memory Exhaustion:** Allocate sufficient memory to Lambda functions to avoid memory exhaustion errors.\n      - **Unclosed Connections:** Close database connections, HTTP clients, and other resources properly to avoid resource leaks.\n\n   - **Edge Cases:**\n      - **Concurrent Invocations:** Handle concurrent invocations gracefully to avoid race conditions or data corruption.\n      - **Throttling:** Implement retry mechanisms to handle throttling errors from AWS services.\n      - **Error Retries:** Design functions to be idempotent to handle potential retry scenarios gracefully.\n\n   - **Version-Specific Issues:**\n      - Be aware of version-specific issues or compatibility concerns when upgrading Lambda function runtimes or dependencies.\n      - Test Lambda functions thoroughly after upgrading to ensure they still function correctly.\n\n   - **Compatibility Concerns:**\n      - Ensure that Lambda functions are compatible with the supported runtime environment.\n      - Use compatible versions of dependencies to avoid compatibility issues.\n\n   - **Debugging Strategies:**\n      - Use CloudWatch Logs to debug Lambda function execution.\n      - Use AWS X-Ray to trace and analyze Lambda function performance.\n      - Use local debugging tools (e.g., AWS SAM Local) to debug Lambda functions locally.\n\n## 7. Tooling and Environment:\n\n   - **Recommended Tools:**\n      - **AWS SAM:** Use AWS SAM (Serverless Application Model) to define and deploy Lambda functions and other serverless resources.\n      - **AWS CLI:** Use the AWS CLI (Command Line Interface) to manage AWS resources from the command line.\n      - **Terraform/CloudFormation:** Use Infrastructure as Code (IaC) tools like Terraform or CloudFormation to provision and manage AWS infrastructure.\n      - **IDE:** Use an IDE with support for Lambda development (e.g., VS Code with the AWS Toolkit extension).\n\n   - **Build Configuration:**\n      - Use build tools (e.g., npm, yarn, Maven, Gradle) to manage dependencies and build Lambda function packages.\n      - Configure build scripts to automate common tasks (e.g., linting, testing, bundling).\n\n   - **Linting and Formatting:**\n      - Use linters (e.g., ESLint, Pylint) to enforce coding standards and identify potential code quality issues.\n      - Use formatters (e.g., Prettier, Black) to automatically format code consistently.\n\n   - **Deployment:**\n      - Use AWS SAM CLI or other deployment tools to deploy Lambda functions to AWS.\n      - Implement blue/green deployments or canary deployments to minimize downtime during deployments.\n      - Automate deployments using CI/CD pipelines.\n\n   - **CI/CD Integration:**\n      - Integrate Lambda function deployments with CI/CD pipelines to automate testing and deployment.\n      - Use CI/CD tools (e.g., Jenkins, CircleCI, GitHub Actions) to build, test, and deploy Lambda functions.\n\n@file aws-lambda-security.mdc\n@file aws-lambda-performance.mdc",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx,*.py,*.java,*.go,*.c#,*.cs,*.ps1,*.sh",
      "format": "mdc",
      "originalFile": "aws-lambda.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "lambda",
      "comprehensive",
      "guide",
      "development",
      "covering",
      "best",
      "practices",
      "code",
      "organization",
      "performance",
      "aws-lambda",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-lambda",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws-rds",
    "description": "This rule provides best practices and coding standards for developing applications that interact with AWS RDS. It covers code organization, security, performance, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "aws-rds",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws-rds.mdc",
    "content": "# AWS RDS Best Practices and Coding Standards\n\nThis document outlines best practices for developing applications interacting with AWS Relational Database Service (RDS). It covers code organization, common patterns, performance, security, testing, and deployment.\n\n## Library Information:\n\n- Name: aws-rds\n- Tags: database, sql, aws, cloud\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nOrganize your project to promote maintainability and scalability. A suggested directory structure is:\n\n\nproject-root/\n├── modules/                    # Reusable components for RDS interactions\n│   ├── db_config.py          # Database connection configuration (e.g., using SQLAlchemy)\n│   ├── rds_operations.py    # CRUD operations (e.g., using boto3)\n│   └── query_builder.py     # Dynamic SQL query generation\n├── models/                    # Data models (e.g., SQLAlchemy models, Pydantic schemas)\n│   ├── user.py                # Example: User model definition\n│   └── order.py               # Example: Order model definition\n├── services/                  # Application logic interacting with RDS\n│   ├── user_service.py        # Example: User management service\n│   └── reporting_service.py    # Example: Reporting service\n├── tests/                     # Test suite\n│   ├── unit/                 # Unit tests for individual components\n│   ├── integration/            # Integration tests for RDS interactions\n│   └── e2e/                  # End-to-end tests\n├── config/                   # Configuration files\n│   ├── settings.py            # Application settings (database credentials, etc.)\n│   └── logging.yaml           # Logging configuration\n├── migrations/                # Database migration scripts (e.g., using Alembic)\n├── infrastructure/           # Infrastructure-as-Code (IaC) using Terraform or CloudFormation\n│   ├── rds.tf                # RDS instance and security group definition (Terraform example)\n│   └── security_group.tf      # RDS Security Group definition (Terraform example)\n├── scripts/                   # Utility scripts for database management and deployment\n├── README.md                 # Project documentation\n├── requirements.txt         # Python dependencies (example)\n└── .env                       # Environment variables (for local development, never commit this file!)\n\n\n### 1.2 File Naming Conventions\n\n- **Python:** Use snake_case for file and variable names (e.g., `rds_operations.py`, `user_id`).\n- **JavaScript/TypeScript:** Use camelCase for variable names and PascalCase for class and component names (e.g., `getUser`, `UserComponent`).  Generally, kebab-case is recommended for component file names (e.g., `user-component.jsx`).\n- **SQL:** Use snake_case for table and column names (e.g., `users`, `user_name`).  Use `.sql` as the file extension and use uppercase for SQL keywords (e.g., `SELECT`, `FROM`, `WHERE`).\n- **Terraform:** Use snake_case (e.g., `rds_instance.tf`).\n\n### 1.3 Module Organization\n\n- Break down large modules into smaller, more manageable files.\n- Use clear and descriptive module names.\n- Avoid circular dependencies between modules.\n- Use dependency injection to decouple modules and improve testability.\n\n### 1.4 Component Architecture\n\n- **Layered Architecture:** Separate concerns into distinct layers (e.g., data access layer, business logic layer, presentation layer).\n- **Microservices:** For larger applications, consider using a microservices architecture, with each service responsible for a specific domain and interacting with its own RDS instance.\n- **Event-Driven Architecture:**  Use an event-driven architecture to decouple components and improve scalability.  For example, use AWS SNS or SQS to trigger actions based on database changes.\n\n### 1.5 Code Splitting\n\n- Split large files into smaller, more focused files.\n- Organize files by feature or functionality.\n- Use lazy loading for less frequently used modules.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Repository Pattern:** Abstract data access logic behind a repository interface.\n- **Unit of Work Pattern:** Track changes to entities and persist them as a single unit.\n- **Factory Pattern:** Encapsulate object creation logic.\n- **Observer Pattern:** React to database changes or events.\n- **Singleton Pattern:**  Use carefully for database connections. Connection pooling libraries often manage this internally; avoid creating your own Singleton unless necessary for custom connection management logic.\n\n### 2.2 Recommended Approaches\n\n- **Connection Pooling:** Use connection pooling to efficiently manage database connections. Popular libraries include SQLAlchemy (Python) and HikariCP (Java).\n- **ORM (Object-Relational Mapping):** Use an ORM like SQLAlchemy, Django ORM (Python), Hibernate (Java), or Sequelize (JavaScript) to map database tables to objects and simplify data access.\n- **Database Migrations:** Use a migration tool like Alembic (Python) or Flyway (Java) to manage database schema changes.\n- **Asynchronous Operations:** Use asynchronous operations to avoid blocking the main thread when interacting with RDS, especially for long-running queries or large data transfers.\n- **Parameterized Queries:**  Always use parameterized queries to prevent SQL injection attacks.\n\n### 2.3 Anti-patterns\n\n- **Writing Raw SQL Directly in Application Code:**  Avoid embedding raw SQL queries directly within the application code. This makes the code harder to maintain and more vulnerable to SQL injection attacks. Use an ORM or query builder instead.\n- **Ignoring Connection Management:**  Failing to properly open and close database connections can lead to resource exhaustion and performance issues. Always use connection pooling and ensure connections are closed promptly.\n- **Over-fetching Data:**  Avoid retrieving more data than necessary from the database. This can lead to performance problems, especially when dealing with large tables. Use appropriate `WHERE` clauses and select only the required columns.\n- **Ignoring Error Handling:**  Failing to handle database errors gracefully can lead to unexpected application behavior and data corruption. Implement robust error handling mechanisms and log errors appropriately.\n- **Storing Secrets in Code:**  Never store database credentials or other sensitive information directly in the application code or configuration files. Use environment variables or a secrets management service like AWS Secrets Manager.\n- **Lack of Indexing:** Neglecting to add indexes to frequently queried columns can drastically reduce query performance. Analyze query execution plans to identify missing indexes.\n\n### 2.4 State Management\n\n- **Stateless Applications:** Design applications to be stateless to improve scalability and fault tolerance. Use RDS to store persistent data.\n- **Caching:** Use caching to reduce the load on RDS. Implement caching at different levels (e.g., application-level caching, database-level caching using Redis or Memcached).\n\n### 2.5 Error Handling\n\n- **Try-Except Blocks:** Use `try-except` (Python), `try-catch` (Java/JavaScript) blocks to handle potential exceptions during RDS interactions.\n- **Logging:** Log all database errors to a central location for monitoring and debugging.\n- **Retry Mechanism:** Implement a retry mechanism with exponential backoff for transient errors (e.g., network connectivity issues).\n- **Custom Exceptions:** Define custom exception classes for specific RDS-related errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Query Optimization:** Analyze query execution plans and optimize queries for performance. Use indexes, rewrite inefficient queries, and avoid using `SELECT *`.\n- **Connection Pooling:** As mentioned earlier, use connection pooling to reuse database connections and reduce overhead.\n- **Caching:** Implement caching strategies to reduce the number of database queries.\n- **Read Replicas:** Use read replicas to offload read traffic from the primary RDS instance.\n- **Provisioned IOPS:** Use provisioned IOPS (IOPS) for workloads that require consistent high performance.\n- **Database Tuning:** Tune database parameters (e.g., buffer pool size, query cache size) based on workload characteristics.\n- **Partitioning:** Use table partitioning for very large tables to improve query performance and manageability.\n- **Stored Procedures:** Use stored procedures for complex operations to reduce network traffic and improve security.\n\n### 3.2 Memory Management\n\n- **Appropriate Instance Size:** Choose an RDS instance size that is appropriate for the workload. Consider memory requirements for the database server and application.\n- **Monitor Memory Usage:** Monitor memory usage on the RDS instance using CloudWatch metrics and adjust the instance size or database parameters as needed.\n- **Avoid Memory Leaks:** Be careful to avoid memory leaks in the application code, especially when dealing with large datasets or database connections.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n- This is primarily relevant if you are directly rendering data retrieved from RDS in a user interface.\n- **Pagination:** Implement pagination to load data in smaller chunks, improving initial load times.\n- **Virtualization:** Use virtualization techniques (e.g., virtual scrolling) to render large lists of data efficiently.\n- **Memoization:** Use memoization to cache the results of expensive rendering operations.\n\n### 3.4 Bundle Size Optimization\n\n- **Tree Shaking:** Use tree shaking to remove unused code from the JavaScript/TypeScript bundle.\n- **Code Splitting:** Split the code into smaller chunks that can be loaded on demand.\n- **Minification:** Minify the code to reduce the bundle size.\n- **Compression:** Compress the bundle using gzip or Brotli.\n\n### 3.5 Lazy Loading\n\n- **Lazy Loading of Modules:** Load modules on demand to reduce the initial load time of the application.\n- **Lazy Loading of Data:** Load data only when it is needed (e.g., when a user scrolls down a page).\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n- **SQL Injection:**  Exploiting vulnerabilities in SQL queries to execute malicious code.\n- **Cross-Site Scripting (XSS):** Injecting malicious scripts into web pages served from your application.\n- **Cross-Site Request Forgery (CSRF):**  Tricking users into performing actions they did not intend to perform.\n- **Data Breach:**  Unauthorized access to sensitive data stored in RDS.\n- **Denial of Service (DoS):**  Overwhelming the RDS instance with requests, making it unavailable to legitimate users.\n\n### 4.2 Input Validation\n\n- **Whitelist Validation:** Validate input against a whitelist of allowed characters or patterns.\n- **Data Type Validation:** Ensure that input data is of the correct data type.\n- **Length Validation:** Limit the length of input strings to prevent buffer overflows.\n- **Encoding:** Encode input data to prevent HTML injection.\n- **Parameterized Queries (again!):** Use parameterized queries to prevent SQL injection attacks.\n\n### 4.3 Authentication and Authorization\n\n- **IAM Roles:** Use IAM roles to grant permissions to applications to access RDS.\n- **Database Usernames and Passwords:** Use strong database usernames and passwords and store them securely using AWS Secrets Manager. Avoid using the `admin` user for application access.\n- **Least Privilege Principle:** Grant only the necessary permissions to database users.\n- **Multi-Factor Authentication (MFA):** Enable MFA for database user accounts.\n- **Row-Level Security (RLS):** Implement row-level security to restrict access to specific rows in a table.\n- **VPC Security Groups:**  Utilize VPC security groups to control network access to the RDS instance.\n\n### 4.4 Data Protection\n\n- **Encryption at Rest:** Enable encryption at rest for the RDS instance.\n- **Encryption in Transit:** Use SSL/TLS to encrypt data in transit between the application and RDS.\n- **Data Masking:** Mask sensitive data in the database to protect it from unauthorized access.\n- **Data Backup and Recovery:** Implement a data backup and recovery plan to protect against data loss.\n- **Regular Auditing:**  Audit database activity regularly to identify and investigate suspicious behavior.\n\n### 4.5 Secure API Communication\n\n- **HTTPS:** Use HTTPS for all API communication with the application.\n- **API Authentication:** Authenticate all API requests using API keys, JWT tokens, or other authentication mechanisms.\n- **API Authorization:** Authorize all API requests to ensure that users only have access to the resources they are authorized to access.\n- **Rate Limiting:** Implement rate limiting to prevent DoS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- **Focus:** Test individual components in isolation (e.g., functions, classes).\n- **Mocking:** Use mocking to isolate components from external dependencies, such as RDS.\n- **Assertions:** Use assertions to verify that the components are behaving as expected.\n- **Test Coverage:** Aim for high test coverage to ensure that all parts of the code are tested.\n\n### 5.2 Integration Testing\n\n- **Focus:** Test the interactions between different components, including RDS.\n- **Test Databases:** Use test databases for integration tests to avoid affecting production data.\n- **Data Setup and Teardown:** Set up test data before each test and tear down the data after each test to ensure that the tests are isolated.\n- **Transaction Management:** Use transaction management to rollback changes made during tests.\n\n### 5.3 End-to-End (E2E) Testing\n\n- **Focus:** Test the entire application flow, from the user interface to the database.\n- **Automated Testing:** Automate E2E tests to ensure that the application is working correctly.\n- **Realistic Scenarios:** Use realistic scenarios to simulate user behavior.\n- **Browser Automation:** Use browser automation tools (e.g., Selenium, Cypress) to automate E2E tests.\n\n### 5.4 Test Organization\n\n- **Separate Test Directory:** Store all tests in a separate directory.\n- **Mirror Source Code Structure:** Mirror the source code structure in the test directory to make it easy to find the tests for a specific component.\n- **Descriptive Test Names:** Use descriptive test names to make it clear what each test is testing.\n\n### 5.5 Mocking and Stubbing\n\n- **Mocking:** Replace external dependencies with mock objects that simulate their behavior.\n- **Stubbing:** Replace specific methods or functions of external dependencies with stubs that return predefined values.\n- **Mocking Libraries:** Use mocking libraries (e.g., Mockito (Java), pytest-mock (Python), Jest (JavaScript)) to simplify the creation of mock objects and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Not Using Connection Pooling:** Leading to excessive connection overhead and performance issues.\n- **SQL Injection Vulnerabilities:** Due to improper input validation and not using parameterized queries.\n- **Over-fetching Data:** Retrieving more data than necessary, leading to performance problems.\n- **Ignoring Error Handling:** Leading to unexpected application behavior and data corruption.\n- **Not Monitoring RDS Performance:** Failing to monitor RDS performance, leading to undetected performance issues.\n- **Underestimating Database Growth:** Not planning for future database growth, leading to performance problems and storage limitations.\n- **Using Default Security Settings:** Leaving the RDS instance with default security settings, making it vulnerable to attacks.\n\n### 6.2 Edge Cases\n\n- **Handling Large Datasets:** Optimizing queries and using pagination to handle large datasets efficiently.\n- **Concurrent Access:** Handling concurrent access to the database using transactions and locking mechanisms.\n- **Network Connectivity Issues:** Implementing retry mechanisms and handling network connectivity issues gracefully.\n- **Database Failover:** Testing the application's ability to handle database failover seamlessly.\n- **Time Zones:** Correctly handling time zones when storing and retrieving dates and times from RDS.\n\n### 6.3 Version-Specific Issues\n\n- **Check Release Notes:** Always review the release notes for each new version of the RDS engine to identify any breaking changes or known issues.\n- **Compatibility Testing:** Perform compatibility testing to ensure that the application works correctly with the new version of the RDS engine.\n- **Deprecation Warnings:** Pay attention to deprecation warnings and update the code accordingly.\n\n### 6.4 Compatibility Concerns\n\n- **ORM Compatibility:** Ensure that the ORM is compatible with the specific RDS engine being used.\n- **Driver Compatibility:** Use the latest version of the database driver to ensure compatibility with the RDS engine.\n- **API Compatibility:** Ensure that the application's API is compatible with the RDS API.\n\n### 6.5 Debugging Strategies\n\n- **Logging:** Use logging to trace the execution flow of the application and identify potential issues.\n- **Remote Debugging:** Use remote debugging to debug the application running in a production environment.\n- **Query Profiling:** Use query profiling tools to analyze the performance of SQL queries.\n- **Database Monitoring:** Use database monitoring tools to monitor the health and performance of the RDS instance.\n- **CloudWatch Metrics:** Use CloudWatch metrics to monitor CPU utilization, memory usage, disk I/O, and network traffic.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE (Integrated Development Environment):** VS Code, IntelliJ IDEA, PyCharm, Eclipse.\n- **Database Client:** DBeaver, SQL Developer, pgAdmin.\n- **Database Migration Tool:** Alembic, Flyway.\n- **Testing Framework:** pytest, unittest (Python), JUnit (Java), Jest (JavaScript).\n- **Mocking Library:** Mockito (Java), pytest-mock (Python), Jest (JavaScript).\n- **AWS CLI:** The AWS Command Line Interface (CLI) is a unified tool to manage your AWS services.\n- **Terraform/CloudFormation:** Infrastructure-as-Code tools to manage RDS infrastructure.\n\n### 7.2 Build Configuration\n\n- **Dependency Management:** Use a dependency management tool (e.g., pip (Python), Maven (Java), npm/yarn (JavaScript)) to manage project dependencies.\n- **Build Automation:** Use a build automation tool (e.g., Make, Gradle, Maven, npm scripts) to automate the build process.\n- **Environment Variables:** Use environment variables to configure the application for different environments (e.g., development, staging, production).\n\n### 7.3 Linting and Formatting\n\n- **Linters:** Use linters (e.g., pylint (Python), ESLint (JavaScript), Checkstyle (Java)) to enforce coding standards and identify potential issues.\n- **Formatters:** Use formatters (e.g., black (Python), Prettier (JavaScript), Google Java Format (Java)) to automatically format the code.\n\n### 7.4 Deployment\n\n- **Infrastructure as Code:** Use Infrastructure as Code (IaC) tools (e.g., Terraform, CloudFormation) to automate the deployment of RDS infrastructure.\n- **Containerization:** Use containerization (e.g., Docker) to package the application and its dependencies into a portable container.\n- **Orchestration:** Use an orchestration tool (e.g., Kubernetes, ECS) to manage and scale the application.\n- **Blue/Green Deployments:** Use blue/green deployments to minimize downtime during deployments.\n- **Rolling Deployments:** Use rolling deployments to gradually update the application without disrupting service.\n\n### 7.5 CI/CD Integration\n\n- **Continuous Integration (CI):** Integrate the build, test, and linting processes into a CI pipeline to automatically run these checks whenever code is committed.\n- **Continuous Deployment (CD):** Automate the deployment process to automatically deploy the application to production whenever code is committed.\n- **CI/CD Tools:** Use CI/CD tools (e.g., Jenkins, GitHub Actions, CircleCI, GitLab CI) to manage the CI/CD pipeline.\n\n## Additional RDS Best Practices (From Exa Search and Citations):\n\n- **Monitoring Metrics:** Monitor RDS metrics like memory, CPU, storage usage using CloudWatch. Set up alarms for unusual activity.\n- **Automatic Backups:** Enable automatic backups with a window during low IOPS periods.\n- **Scaling DB Instances:** Scale DB instances vertically as needed to meet demand.\n- **Optimize Queries:** Tune queries to minimize resource consumption.\n- **AWS Database Drivers:** Use the AWS suite of drivers for faster failover and integration with AWS Secrets Manager and IAM.\n- **Regular Updates:** Regularly update statistics and monitor performance metrics.\n- **Enough RAM:**  Allocate enough RAM so that your working set resides almost completely in memory to minimize disk I/O.\n- **Client DNS Caching:** Set a time-to-live (TTL) value of less than 30 seconds if your client application is caching the Domain Name Service (DNS) data of your DB instances.\n- **Test Failover:** Test failover for your DB instance to understand how long the process takes for your particular use case.\n\n## References:\n\n- [AWS RDS Documentation](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_BestPractices.html)\n- [AWS Database Blog](https://aws.amazon.com/blogs/database/best-practices-for-configuring-performance-parameters-for-amazon-rds-for-sql-server/)\n- [AWS re:Invent Videos (Links as provided in search results)]\n\nBy adhering to these best practices, developers can build scalable, secure, and performant applications that leverage the power of AWS RDS.",
    "metadata": {
      "globs": "*.sql,*.js,*.py,*.java,*.tf,*.yaml,*.yml",
      "format": "mdc",
      "originalFile": "aws-rds.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "rds",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "applications",
      "that",
      "aws-rds",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws-rds",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-aws",
    "description": "Comprehensive rules and best practices for AWS development using Terraform, covering code organization, security, performance, and testing.  Adherence to these guidelines ensures maintainable, secure, and efficient infrastructure code.",
    "author": "sanjeed5",
    "tags": [
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/aws.mdc",
    "content": "# AWS Development Best Practices using Terraform\n\nThis document outlines best practices for developing and maintaining AWS infrastructure using Terraform. Following these guidelines will help ensure your code is maintainable, secure, and efficient.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n-   **Root Module**: The primary entry point for your infrastructure definition. Contains `main.tf`, `variables.tf`, `outputs.tf`, `providers.tf`, `versions.tf` and `locals.tf`.\n-   **Modules Directory**:  Reusable components of your infrastructure. Each module should have its own directory under `modules/`.\n-   **Examples Directory**: Demonstrates how to use the modules. Each example should be a self-contained Terraform configuration.\n-   **Scripts Directory**: Custom scripts used by Terraform.\n-   **Templates Directory**:  Templates for files that are read using the `templatefile` function, using the extension `.tftpl`.\n-   **Files Directory**: Contains static files referenced by Terraform (e.g., startup scripts).\n-   **Helpers Directory**:  Contains utility scripts that are *not* directly called by Terraform.\n-   **.tfvars files**: Files containing variable definitions.  Use `terraform.tfvars` for common values and create environment specific files in the `envs/` directory (e.g., `envs/dev/terraform.tfvars`, `envs/prod/terraform.tfvars`).\n-   **.gitignore**:  Specifies intentionally untracked files that Git should ignore.\n-   **docs/**: Place any supplemental documentation in a `docs/` subdirectory.\n-   **CODEOWNERS**:  File to document who is responsible for the module. Before any merge request is merged, an owner should approve it.\n\nExample:\n\n\n├── .terraform/              # Terraform working directory\n├── modules/\n│   ├── ec2/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── outputs.tf\n│   │   └── README.md\n│   ├── s3/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── outputs.tf\n│   │   └── README.md\n├── examples/\n│   ├── ec2/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── outputs.tf\n│   │   └── README.md\n│   ├── s3/\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── outputs.tf\n│   │   └── README.md\n├── scripts/\n│   ├── configure_instance.sh\n├── templates/\n│   ├── user_data.tftpl\n├── files/\n│   ├── application.conf\n├── helpers/\n│   ├── backup_database.sh\n├── terraform.tfvars\n├── envs/\n│   ├── dev/\n│   │   ├── terraform.tfvars\n│   ├── prod/\n│   │   ├── terraform.tfvars\n├── main.tf\n├── variables.tf\n├── outputs.tf\n├── providers.tf\n├── versions.tf\n├── locals.tf\n└── .gitignore\n\n\n### 1.2 File Naming Conventions\n\n-   `main.tf`: Primary entry point for resource definitions.\n-   `variables.tf`:  Variable declarations.\n-   `outputs.tf`: Output declarations.\n-   `providers.tf`:  Provider configuration.\n-   `versions.tf`:  Terraform and provider version constraints.\n-   `locals.tf`: Local variable definitions.\n-   `*.tfvars`: Variable value files. Use `terraform.tfvars` for default values and `env/<environment>.tfvars` for environment-specific values.\n\n### 1.3 Module Organization\n\n-   **Reusable Modules**: Create modules for common infrastructure components (e.g., EC2 instances, S3 buckets, VPCs).\n-   **Module Composition**:  Compose complex infrastructure by combining smaller, reusable modules.\n-   **Module Versioning**: Use version control (e.g., Git tags) to manage module versions.\n-   **Module Naming**: Module repositories must use the format `terraform-<PROVIDER>-<NAME>`.  For example: `terraform-aws-ec2`\n-   **Module sources**: When referencing another module on a public registry, pin the Git commit hash by pointing directly to the underlying Git repo URL. Example:\n\n    terraform\n    module \"lambda\" {\n        source = \"github.com/terraform-aws-modules/terraform-aws-lambda.git?ref=e78cdf1f82944897ca6e30d6489f43cf24539374\" # --> v4.18.0\n    }\n    \n\n### 1.4 Component Architecture\n\n-   **Layered Architecture**: Separate infrastructure into logical layers (e.g., network, compute, data).\n-   **Loose Coupling**: Design components to be loosely coupled, minimizing dependencies between them.\n-   **Clear Abstractions**: Use modules to create clear abstractions for complex infrastructure components.\n\n### 1.5 Code Splitting Strategies\n\n-   **Functional Decomposition**: Split code into smaller, manageable functions.\n-   **Resource Grouping**: Group related resources into separate files or modules.\n-   **Environment Separation**: Use separate files or modules for environment-specific configurations.\n-   **Service-Based Separation**: Separate resources by service (e.g., `iam.tf`, `ec2.tf`, `s3.tf`) only if they exceed 150 lines in `main.tf`.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to AWS\n\n-   **Immutable Infrastructure**:  Deploy new infrastructure components instead of modifying existing ones.\n-   **Infrastructure as Code (IaC)**: Manage infrastructure through code, using tools like Terraform.\n-   **Blue/Green Deployments**:  Deploy new versions of applications alongside existing ones, then switch traffic.\n-   **Canary Deployments**:  Deploy new versions of applications to a small subset of users before rolling them out to everyone.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Creating VPCs**: Use the `terraform-aws-modules/vpc/aws` module for creating VPCs.\n-   **Creating EC2 Instances**: Use the `terraform-aws-modules/ec2-instance/aws` module for creating EC2 instances.\n-   **Creating S3 Buckets**: Use the `terraform-aws-modules/s3-bucket/aws` module for creating S3 buckets.\n-   **Managing IAM Roles**: Use the `aws_iam_role` and `aws_iam_policy` resources to manage IAM roles and policies.\n-   **Using Data Sources**: Utilize data sources (e.g., `aws_ami`, `aws_vpc`) to fetch information about existing AWS resources.\n-   **Resource Tagging**:  Tag all AWS resources for cost allocation, automation, and identification.\n-   **State File Storage**: Use a remote backend (e.g., S3 with DynamoDB locking) for storing Terraform state.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Hardcoding Values**:  Avoid hardcoding values in your code. Use variables instead.\n-   **Storing Secrets in Code**:  Never store secrets (e.g., passwords, API keys) in your code. Use AWS Secrets Manager or other secret management solutions.\n-   **Overly Complex Modules**:  Avoid creating modules that are too complex and difficult to understand.\n-   **Ignoring Errors**: Always handle errors gracefully.\n-   **Manual Infrastructure Changes**: Avoid making manual changes to infrastructure outside of Terraform.\n-   **Using embedded resource attributes**: avoid using these embedded resource attributes and instead you should use the unique resource to attach that pseudo-resource. These resource relationships can cause chicken/egg issues that are unique per resource.\n\n### 2.4 State Management Best Practices\n\n-   **Remote Backend**:  Use a remote backend (e.g., S3 with DynamoDB locking) for storing Terraform state. This allows for collaboration and prevents data loss.\n-   **State Locking**:  Enable state locking to prevent concurrent modifications to the state file.\n-   **State Encryption**:  Encrypt the state file at rest and in transit.\n-   **Workspace Management**:  Use Terraform workspaces to manage multiple environments (e.g., development, staging, production).\n-   **Secure State Access**: Restrict access to the state file to authorized users and systems only. Consider implementing least privilege principles.\n-   **Versioning**: Implement a mechanism for versioning your state files, which could include frequent backups and using version control systems.\n-   **Avoid local state**: Never store Terraform state locally.\n\n### 2.5 Error Handling Patterns\n\n-   **Validation Rules**: Use validation rules within variable definitions to check input values.\n-   **Error Propagation**:  Propagate errors up the call stack to be handled at a higher level.\n-   **Retry Logic**: Implement retry logic for transient errors (e.g., network errors, API throttling).\n-   **Logging**:  Log errors and warnings to aid in debugging.\n-   **Custom Error Messages**: Provide clear and informative error messages to users.\n-   **Panic Handling**: Avoid using `panic()` function that stops the execution, implement error handling.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Efficient Resource Usage**:  Use the appropriate instance types and storage classes for your workloads.\n-   **Caching**: Implement caching to reduce latency and improve performance.\n-   **Load Balancing**: Use load balancing to distribute traffic across multiple instances.\n-   **Content Delivery Networks (CDNs)**: Use CDNs to deliver static content closer to users.\n-   **Database Optimization**: Optimize database queries and indexing for faster performance.\n-   **Parallelization**: Use `for_each` and `count` to parallelize resource creation and modification.\n\n### 3.2 Memory Management\n\n-   **Resource Limits**:  Set resource limits on EC2 instances and other AWS resources.\n-   **Memory Profiling**:  Use memory profiling tools to identify memory leaks and optimize memory usage.\n-   **Garbage Collection**:  Configure garbage collection settings for your applications.\n\n### 3.3 Rendering Optimization\n\n-   **Minimize Rendering**: Minimize the amount of data that needs to be rendered.\n-   **Efficient Templates**: Use efficient templates to generate configuration files.\n\n### 3.4 Bundle Size Optimization\n\n-   **Code Splitting**: Split code into smaller bundles that can be loaded on demand.\n-   **Tree Shaking**: Remove unused code from your bundles.\n-   **Minification**: Minify your code to reduce bundle sizes.\n-   **Compression**: Compress your bundles to reduce download times.\n\n### 3.5 Lazy Loading Strategies\n\n-   **Lazy Loading of Resources**: Load resources only when they are needed.\n-   **Virtualization**: Use virtualization to reduce the number of resources that need to be loaded.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **IAM Misconfiguration**: Prevent IAM misconfiguration by following the principle of least privilege.\n-   **Unsecured S3 Buckets**: Secure S3 buckets by enabling encryption, access logging, and versioning.\n-   **Security Group Misconfiguration**:  Configure security groups to allow only necessary traffic.\n-   **SQL Injection**:  Prevent SQL injection by using parameterized queries and input validation.\n-   **Cross-Site Scripting (XSS)**:  Prevent XSS by sanitizing user input and output.\n-   **Cross-Site Request Forgery (CSRF)**: Prevent CSRF by using anti-CSRF tokens.\n-   **Exposed Secrets**: Avoid exposing secrets by using AWS Secrets Manager and IAM roles.\n\n### 4.2 Input Validation\n\n-   **Validate User Input**: Validate user input to prevent malicious code from being injected into your application.\n-   **Use Data Types**: Use appropriate data types for your variables to prevent type-related errors.\n-   **Regular Expressions**: Use regular expressions to validate complex input patterns.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **IAM Roles**:  Use IAM roles to grant permissions to AWS resources.\n-   **Multi-Factor Authentication (MFA)**:  Enable MFA for all user accounts.\n-   **Principle of Least Privilege**:  Grant users only the permissions they need to perform their tasks.\n-   **AWS Cognito**:  Use AWS Cognito to manage user authentication and authorization.\n-   **API Gateway Authorization**: Implement authorization at the API Gateway level to control access to your APIs.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption at Rest**:  Encrypt data at rest using AWS KMS, S3 encryption, or other encryption solutions.\n-   **Encryption in Transit**:  Encrypt data in transit using HTTPS, TLS, or other encryption protocols.\n-   **Data Masking**: Mask sensitive data to prevent unauthorized access.\n-   **Data Redaction**: Redact sensitive data from logs and other output.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS**: Use HTTPS for all API communication.\n-   **API Keys**:  Use API keys to authenticate API requests.\n-   **OAuth 2.0**: Use OAuth 2.0 for authorization.\n-   **Rate Limiting**:  Implement rate limiting to prevent abuse.\n-   **Web Application Firewall (WAF)**:  Use a WAF to protect your APIs from common web attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test Individual Modules**: Unit test individual Terraform modules to ensure they are working correctly.\n-   **Mock AWS Resources**: Mock AWS resources to isolate your modules from external dependencies.\n-   **Test Variable Validation**: Verify variable validation rules work as expected.\n-   **Test Output Values**: Check that module outputs are correct.\n\n### 5.2 Integration Testing\n\n-   **Test Module Integration**:  Test how modules interact with each other.\n-   **Deploy to Test Environment**: Deploy your infrastructure to a test environment and verify that it is working correctly.\n-   **Automated Tests**: Write automated tests to verify that your infrastructure is working correctly.\n\n### 5.3 End-to-End Testing\n\n-   **Test Full Infrastructure**:  Test the entire infrastructure from end to end.\n-   **Simulate User Behavior**:  Simulate user behavior to verify that your infrastructure is working correctly.\n-   **Monitor Performance**: Monitor performance to identify any performance bottlenecks.\n\n### 5.4 Test Organization\n\n-   **Separate Test Directory**: Create a separate directory for your tests.\n-   **Test Naming Conventions**: Use clear naming conventions for your tests.\n-   **Test Documentation**: Document your tests to explain what they are testing.\n\n### 5.5 Mocking and Stubbing\n\n-   **Use Mock Objects**: Use mock objects to isolate your code from external dependencies.\n-   **Use Stub Objects**: Use stub objects to provide canned responses to external dependencies.\n-   **Terratest**:  Utilize Terratest for creating test environments and performing infrastructure tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Forgetting to Enable State Locking**:  Enabling state locking is crucial for preventing corruption and ensuring integrity when multiple users work on the same Terraform project.\n-   **Overlooking IAM Permissions**:  Ensuring the Terraform service account has the necessary IAM permissions to create, modify, and delete resources is vital.\n-   **Incorrect Resource Dependencies**:  Managing resource dependencies correctly to prevent errors during creation or deletion.\n-   **Handling Sensitive Data Insecurely**:  Implementing robust measures for managing sensitive data, such as API keys and passwords, by using AWS Secrets Manager or other appropriate services.\n-   **Neglecting to Monitor Infrastructure**:  Setting up comprehensive monitoring and alerting to detect and respond to infrastructure issues promptly.\n-   **Using hardcoded values**: Always use variables\n\n### 6.2 Edge Cases to be Aware Of\n\n-   **Resource Limits**:  Be aware of AWS resource limits and plan accordingly.\n-   **Availability Zones**: Understand the implications of availability zones and design your infrastructure to be resilient to AZ failures.\n-   **Data Consistency**: Understand the consistency models of different AWS services and design your applications accordingly.\n-   **API Throttling**: Be aware of API throttling limits and implement retry logic.\n\n### 6.3 Version-Specific Issues\n\n-   **Terraform Version Compatibility**:  Ensure that your Terraform code is compatible with the version of Terraform you are using.\n-   **Provider Version Compatibility**: Ensure that your Terraform providers are compatible with the version of Terraform you are using.\n-   **AWS API Version Compatibility**: Be aware of changes to the AWS API and update your code accordingly.\n\n### 6.4 Compatibility Concerns\n\n-   **Backwards Compatibility**: Ensure that your changes are backwards compatible.\n-   **Cross-Region Compatibility**:  Ensure that your infrastructure is compatible across different AWS regions.\n-   **Cross-Account Compatibility**: Ensure that your infrastructure is compatible across different AWS accounts.\n\n### 6.5 Debugging Strategies\n\n-   **Terraform Plan**: Use `terraform plan` to preview changes before applying them.\n-   **Terraform Show**: Use `terraform show` to inspect the current state of your infrastructure.\n-   **Terraform Graph**: Use `terraform graph` to visualize the dependencies between resources.\n-   **Terraform Console**: Use `terraform console` to evaluate Terraform expressions.\n-   **AWS CloudTrail**:  Use AWS CloudTrail to audit API calls and identify errors.\n-   **CloudWatch Logs**:  Use CloudWatch Logs to collect and analyze application logs.\n-   **Enable Debug Logging**: Enable debug logging to get more detailed information about what Terraform is doing.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **Terraform CLI**: The Terraform command-line interface.\n-   **IDE with Terraform Support**: Use an IDE with Terraform support (e.g., VS Code with the Terraform extension).\n-   **tfenv**:  Use tfenv to manage multiple versions of Terraform.\n-   **AWS CLI**:  The AWS command-line interface.\n-   **jq**:  A command-line JSON processor.\n\n### 7.2 Build Configuration\n\n-   **Makefile**:  Use a Makefile to automate common build tasks (e.g., `terraform init`, `terraform plan`, `terraform apply`).\n-   **.terraformignore**: Create a `.terraformignore` to prevent files from being included in the Terraform package.\n\n### 7.3 Linting and Formatting\n\n-   **terraform fmt**:  Use `terraform fmt` to automatically format your Terraform code.\n-   **terraform validate**:  Use `terraform validate` to validate your Terraform code.\n-   **tflint**: Use `tflint` to lint your Terraform code.\n-   **pre-commit hooks**: Enforce code quality standards using pre-commit hooks.\n\n### 7.4 Deployment Best Practices\n\n-   **Automated Deployments**: Use automated deployments to reduce errors and improve consistency.\n-   **Infrastructure as Code (IaC)**: Manage infrastructure as code using tools like Terraform.\n-   **Immutable Infrastructure**: Deploy new infrastructure components instead of modifying existing ones.\n-   **Blue/Green Deployments**: Deploy new versions of applications alongside existing ones, then switch traffic.\n-   **Canary Deployments**:  Deploy new versions of applications to a small subset of users before rolling them out to everyone.\n\n### 7.5 CI/CD Integration\n\n-   **Integrate with CI/CD Pipeline**: Integrate Terraform with your CI/CD pipeline.\n-   **Automated Testing**: Run automated tests as part of your CI/CD pipeline.\n-   **Automated Deployments**: Automatically deploy your infrastructure as part of your CI/CD pipeline.\n-   **Version Control**: Store your Terraform code in version control.\n-   **Terraform Cloud/Enterprise**: Use Terraform Cloud/Enterprise for remote state management and collaboration.\n\nThis document provides a comprehensive set of best practices for AWS development using Terraform. By following these guidelines, you can ensure your code is maintainable, secure, and efficient.",
    "metadata": {
      "globs": "*.tf",
      "format": "mdc",
      "originalFile": "aws.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "aws",
      "comprehensive",
      "rules",
      "best",
      "practices",
      "development",
      "using",
      "terraform",
      "covering",
      "code",
      "organization",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-axios",
    "description": "This rule provides comprehensive guidelines for using Axios effectively, covering best practices, security considerations, and performance optimization. It aims to improve code quality, maintainability, and overall application resilience when working with Axios.",
    "author": "sanjeed5",
    "tags": [
      "axios",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/axios.mdc",
    "content": "- **Avoid hardcoding URLs**: Store API endpoints in configuration files or environment variables to enhance maintainability and avoid redundancy.\n- **Centralize API Logic**: Create dedicated modules or services to encapsulate Axios instances and request logic. This promotes reusability and simplifies debugging.\n- **Handle Errors Gracefully**: Implement comprehensive error handling using try-catch blocks, response interceptors, and centralized error logging. Display user-friendly error messages.\n- **Use Asynchronous Functions**: Leverage `async/await` or Promises for cleaner and more manageable asynchronous code when making Axios requests.\n- **Optimize with Request Interceptors**: Utilize request interceptors for tasks like adding authentication tokens, logging requests, or transforming request data. Response interceptors can be used for error handling or data transformation.\n- **Ensure HTTP Requests When Necessary**: Verify that requests are only made when truly needed, preventing unnecessary network traffic and improving performance. Consider caching strategies.\n\n### 1. Code Organization and Structure:\n\n   - **Directory Structure Best Practices**:\n     - Create an `api` or `services` directory to house all API-related code.\n     - Organize API modules based on resources or features (e.g., `api/users.js`, `api/products.js`).\n     - Separate Axios instance configuration into a dedicated file (e.g., `api/axios-config.js`).\n\n   - **File Naming Conventions**:\n     - Use descriptive names for API modules (e.g., `userApi.js`, `productService.js`).\n     - Follow a consistent naming convention (e.g., camelCase for variables, PascalCase for components).\n\n   - **Module Organization**:\n     - Export individual API functions from each module (e.g., `getUser`, `createUser`).\n     - Use named exports for better code readability and maintainability.\n\n   - **Component Architecture**:\n     - Create reusable components for handling data fetching and display.\n     - Decouple components from specific API calls to improve reusability.\n     - Utilize custom hooks to encapsulate data fetching logic.\n\n   - **Code Splitting Strategies**:\n     - Implement lazy loading for API modules that are not immediately required.\n     - Use dynamic imports to load modules on demand.\n     - Consider route-based code splitting for larger applications.\n\n### 2. Common Patterns and Anti-patterns:\n\n   - **Design Patterns Specific to Axios**:\n     - **Singleton Pattern**: Use a singleton pattern for the Axios instance to ensure a single configuration across the application.\n     - **Adapter Pattern**: Create an adapter layer to transform API responses into a consistent format.\n     - **Factory Pattern**: Use a factory pattern to create different Axios instances with specific configurations.\n\n   - **Recommended Approaches for Common Tasks**:\n     - **Authentication**: Use request interceptors to add authentication headers (e.g., JWT tokens).\n     - **Error Handling**: Implement a centralized error handling function to log errors and display user-friendly messages.\n     - **Data Transformation**: Use response interceptors to transform data before it reaches the components.\n\n   - **Anti-patterns and Code Smells to Avoid**:\n     - **Hardcoding URLs**: Avoid hardcoding API endpoints directly in the code.\n     - **Duplicated Request Logic**: Don't repeat API request logic across multiple components.\n     - **Ignoring Errors**: Never ignore errors returned by Axios; always handle them appropriately.\n\n   - **State Management Best Practices**:\n     - Use a state management library (e.g., Redux, Zustand, Recoil) to manage API data.\n     - Store API responses in a normalized format to improve performance.\n     - Utilize selectors to derive data from the store efficiently.\n\n   - **Error Handling Patterns**:\n     - Implement a global error boundary to catch unexpected errors.\n     - Display user-friendly error messages based on the error type.\n     - Log errors to a central logging service for monitoring and debugging.\n\n### 3. Performance Considerations:\n\n   - **Optimization Techniques**:\n     - **Caching**: Implement caching mechanisms to avoid redundant API calls.\n     - **Request Debouncing**: Debounce frequent API requests to reduce server load.\n     - **Request Cancellation**: Cancel pending requests when the component unmounts or the user navigates away.\n\n   - **Memory Management**:\n     - Clear Axios instances when they are no longer needed.\n     - Avoid creating unnecessary Axios instances.\n\n   - **Rendering Optimization**:\n     - Use memoization techniques to prevent unnecessary re-renders.\n     - Implement pagination or virtualized lists for large datasets.\n\n   - **Bundle Size Optimization**:\n     - Use tree shaking to remove unused code from the Axios library.\n     - Minify and compress the JavaScript bundle.\n\n   - **Lazy Loading Strategies**:\n     - Lazy load API modules that are not immediately required.\n     - Use dynamic imports to load modules on demand.\n\n### 4. Security Best Practices:\n\n   - **Common Vulnerabilities and How to Prevent Them**:\n     - **Cross-Site Scripting (XSS)**: Sanitize user input to prevent XSS attacks.\n     - **Cross-Site Request Forgery (CSRF)**: Implement CSRF protection mechanisms.\n     - **Man-in-the-Middle (MITM) Attacks**: Use HTTPS to encrypt communication between the client and the server.\n\n   - **Input Validation**:\n     - Validate user input on both the client and server sides.\n     - Use appropriate validation libraries to prevent injection attacks.\n\n   - **Authentication and Authorization Patterns**:\n     - Use a secure authentication protocol (e.g., OAuth 2.0, OpenID Connect).\n     - Implement role-based access control (RBAC) to restrict access to sensitive data.\n\n   - **Data Protection Strategies**:\n     - Encrypt sensitive data at rest and in transit.\n     - Use appropriate data masking techniques to protect sensitive information.\n\n   - **Secure API Communication**:\n     - Use HTTPS for all API communication.\n     - Implement rate limiting to prevent abuse.\n     - Monitor API traffic for suspicious activity.\n\n### 5. Testing Approaches:\n\n   - **Unit Testing Strategies**:\n     - Mock Axios requests using libraries like `axios-mock-adapter` or `nock`.\n     - Test individual API functions in isolation.\n     - Verify that requests are made with the correct parameters and headers.\n\n   - **Integration Testing**:\n     - Test the interaction between API modules and components.\n     - Verify that data is fetched and displayed correctly.\n     - Use a testing framework like Jest or Mocha.\n\n   - **End-to-End Testing**:\n     - Test the entire application workflow from the user's perspective.\n     - Use a testing framework like Cypress or Selenium.\n\n   - **Test Organization**:\n     - Organize tests by module or feature.\n     - Use descriptive names for test cases.\n     - Follow a consistent testing style.\n\n   - **Mocking and Stubbing**:\n     - Use mocking to isolate components from external dependencies.\n     - Use stubbing to replace API responses with predefined data.\n\n### 6. Common Pitfalls and Gotchas:\n\n   - **Frequent Mistakes Developers Make**:\n     - Forgetting to handle errors.\n     - Using incorrect HTTP methods.\n     - Hardcoding URLs.\n     - Not setting appropriate headers.\n\n   - **Edge Cases to Be Aware Of**:\n     - Network errors.\n     - Server downtime.\n     - Rate limiting.\n     - API versioning.\n\n   - **Version-Specific Issues**:\n     - Be aware of breaking changes between Axios versions.\n     - Consult the Axios documentation for specific version information.\n\n   - **Compatibility Concerns**:\n     - Ensure that Axios is compatible with the target browsers and environments.\n     - Use polyfills if necessary.\n\n   - **Debugging Strategies**:\n     - Use the browser's developer tools to inspect network requests.\n     - Log Axios requests and responses to the console.\n     - Use a debugging tool like VS Code's debugger.\n\n### 7. Tooling and Environment:\n\n   - **Recommended Development Tools**:\n     - VS Code with the ESLint and Prettier extensions.\n     - Axios DevTools for Chrome and Firefox.\n     - Postman or Insomnia for testing API endpoints.\n\n   - **Build Configuration**:\n     - Use a build tool like Webpack or Parcel to bundle the application.\n     - Configure the build tool to optimize the bundle size.\n\n   - **Linting and Formatting**:\n     - Use ESLint with a consistent set of rules to enforce code quality.\n     - Use Prettier to format the code automatically.\n\n   - **Deployment Best Practices**:\n     - Deploy the application to a secure hosting environment.\n     - Configure HTTPS for all API communication.\n     - Monitor the application for errors and performance issues.\n\n   - **CI/CD Integration**:\n     - Integrate automated testing and deployment into the CI/CD pipeline.\n     - Use a CI/CD tool like Jenkins, GitLab CI, or CircleCI.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "axios.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "axios",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "using",
      "effectively",
      "covering",
      "best",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "axios",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-azure-pipelines",
    "description": "Comprehensive guidelines for Azure Pipelines, covering code structure, security, performance, testing, and deployment. Provides actionable advice for developers working with Azure Pipelines YAML definitions to enhance code quality and CI/CD processes.",
    "author": "sanjeed5",
    "tags": [
      "azure-pipelines",
      "azure",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/azure-pipelines.mdc",
    "content": "- # General Guidelines\n  - Utilize YAML pipelines for version control and ease of replication.\n  - Integrate security practices throughout the pipeline using Azure Key Vault for secret management.\n  - Implement role-based access controls (RBAC) to limit permissions.\n  - Establish monitoring and alerting mechanisms for maintaining pipeline health and addressing issues.\n  - Use Infrastructure as Code (IaC) for consistent deployments.\n\n- # 1. Code Organization and Structure\n  - **Directory Structure Best Practices:**\n    - Organize pipeline definitions into a dedicated directory (e.g., `azure-pipelines`).\n    - Use subdirectories to categorize pipelines based on application, environment, or team (e.g., `azure-pipelines/app1/dev`, `azure-pipelines/app1/prod`).\n    - Store reusable templates and scripts in a separate `templates` or `scripts` directory.\n    - Consider using a `modules` directory for custom modules or extensions related to pipeline functionality.\n  - **File Naming Conventions:**\n    - Use descriptive names for pipeline definitions (e.g., `ci-cd-app1-dev.yml`, `deploy-to-staging.yml`).\n    - Prefix or suffix template files with `template` or `tmpl` (e.g., `build-template.yml`, `deploy-tmpl.yml`).\n    - Use consistent naming for variables, parameters, and stages within YAML files.\n  - **Module Organization Best Practices:**\n    - Break down complex pipelines into smaller, reusable modules using templates.\n    - Use parameters to configure templates for different scenarios.\n    - Store modules in a central repository for sharing across projects.\n  - **Component Architecture Recommendations:**\n    - Design pipelines with a clear separation of concerns (e.g., build, test, deploy).\n    - Use stages to represent distinct phases of the CI/CD process.\n    - Leverage tasks to perform specific actions within each stage.\n    - Define clear inputs and outputs for each component (stage/task).\n  - **Code Splitting Strategies:**\n    - Split large YAML files into smaller, more manageable files using the `extends` keyword.\n    - Use templates to define reusable pipeline components.\n    - Implement parameterization to customize pipeline behavior without duplicating code.\n\n- # 2. Common Patterns and Anti-patterns\n  - **Design Patterns:**\n    - **Template Pattern:** Define a base template with placeholders for customization, allowing for consistent pipeline structure with varying configurations.\n    - **Strategy Pattern:** Use parameters to select different deployment strategies (e.g., blue-green, canary) within a single pipeline.\n    - **Chain of Responsibility:** Implement a sequence of tasks or stages, where each component handles a specific aspect of the deployment process.\n  - **Recommended Approaches for Common Tasks:**\n    - **Secret Management:** Use Azure Key Vault to store sensitive information such as passwords, API keys, and connection strings. Reference secrets in pipelines using variables or tasks.\n    - **Environment Configuration:** Define environment-specific variables and settings using variable groups. Use conditional execution to apply different configurations based on the target environment.\n    - **Artifact Management:** Publish and consume artifacts using the `PublishBuildArtifacts` and `DownloadBuildArtifacts` tasks. Use artifact feeds to store and manage dependencies.\n    - **Rollback Strategies:** Implement rollback mechanisms to revert to a previous version in case of deployment failures. Use deployment slots or blue-green deployments for seamless rollbacks.\n  - **Anti-patterns and Code Smells:**\n    - Hardcoding secrets in pipeline definitions.\n    - Duplicating code across multiple pipelines.\n    - Overly complex and monolithic YAML files.\n    - Lack of error handling and logging.\n    - Insufficient testing and validation.\n  - **State Management Best Practices:**\n    - Use Azure DevOps variables or variable groups to store pipeline state.\n    - Consider using external storage (e.g., Azure Blob Storage, Azure Table Storage) for persistent state.\n    - Implement idempotency to ensure that pipeline operations can be safely retried.\n  - **Error Handling Patterns:**\n    - Use the `try...catch` construct to handle exceptions within pipeline tasks.\n    - Implement retry mechanisms for transient failures.\n    - Configure alerts and notifications for pipeline failures.\n\n- # 3. Performance Considerations\n  - **Optimization Techniques:**\n    - **Parallel Execution:** Use parallel jobs to run multiple tasks concurrently, reducing overall pipeline execution time.\n    - **Caching:** Cache dependencies and build artifacts to speed up subsequent builds.\n    - **Agent Selection:** Choose the appropriate agent size and type based on the workload requirements.\n    - **Task Optimization:** Optimize individual tasks to minimize execution time (e.g., using efficient scripts, optimizing database queries).\n  - **Memory Management:**\n    - Monitor pipeline memory usage and identify potential memory leaks.\n    - Use appropriate data structures and algorithms to minimize memory consumption.\n    - Optimize image sizes for containerized applications.\n  - **Bundle Size Optimization:**\n    - Minimize the size of build artifacts by removing unnecessary files and dependencies.\n    - Use code splitting and tree shaking techniques to reduce bundle size.\n    - Compress artifacts before publishing.\n  - **Lazy Loading:**\n    - Implement lazy loading for large files or datasets to improve pipeline startup time.\n\n- # 4. Security Best Practices\n  - **Common Vulnerabilities and Prevention:**\n    - **Credential Leaks:** Avoid storing secrets in pipeline definitions or source code. Use Azure Key Vault for secure secret management.\n    - **Command Injection:** Sanitize user inputs and avoid executing untrusted code. Use parameterized tasks and scripts to prevent command injection attacks.\n    - **Unauthorized Access:** Implement RBAC to restrict access to sensitive resources and operations.\n    - **Dependency Vulnerabilities:** Regularly scan dependencies for known vulnerabilities and update them to the latest versions.\n  - **Input Validation:**\n    - Validate all user inputs to prevent injection attacks and other security vulnerabilities.\n    - Use regular expressions or other validation techniques to ensure that inputs conform to expected formats.\n    - Implement input sanitization to remove or escape potentially malicious characters.\n  - **Authentication and Authorization:**\n    - Use service principals or managed identities for authentication with Azure resources.\n    - Implement RBAC to control access to pipelines, resources, and environments.\n    - Enforce multi-factor authentication (MFA) for privileged accounts.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure protocols (e.g., HTTPS, TLS) for API communication.\n    - Mask sensitive information in pipeline logs and outputs.\n  - **Secure API Communication:**\n    - Use API keys or access tokens for authentication.\n    - Implement rate limiting to prevent denial-of-service attacks.\n    - Validate API responses to prevent data corruption.\n\n- # 5. Testing Approaches\n  - **Unit Testing:**\n    - Write unit tests for individual pipeline tasks and components.\n    - Use mocking frameworks to isolate components and simulate dependencies.\n    - Ensure that unit tests cover all critical code paths.\n  - **Integration Testing:**\n    - Perform integration tests to verify the interaction between different pipeline stages and tasks.\n    - Test the integration with external services and resources.\n    - Use test environments that closely resemble production environments.\n  - **End-to-end Testing:**\n    - Conduct end-to-end tests to validate the entire CI/CD pipeline from code commit to deployment.\n    - Use automated testing frameworks to automate end-to-end tests.\n    - Test the deployed application in a production-like environment.\n  - **Test Organization:**\n    - Organize tests into a dedicated `tests` directory.\n    - Use a consistent naming convention for test files and methods.\n    - Group tests based on functionality or component.\n  - **Mocking and Stubbing:**\n    - Use mocking frameworks (e.g., Moq, NSubstitute) to create mock objects for dependencies.\n    - Use stubbing to replace complex dependencies with simple, predictable implementations.\n\n- # 6. Common Pitfalls and Gotchas\n  - **Frequent Mistakes:**\n    - Using incorrect YAML syntax.\n    - Forgetting to parameterize reusable components.\n    - Neglecting error handling and logging.\n    - Insufficient testing.\n    - Ignoring security best practices.\n  - **Edge Cases:**\n    - Handling large files or datasets.\n    - Dealing with complex dependencies.\n    - Managing concurrency and race conditions.\n    - Recovering from catastrophic failures.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes in Azure DevOps updates.\n    - Test pipelines after upgrading Azure DevOps versions.\n    - Use version control to track changes to pipeline definitions.\n  - **Compatibility Concerns:**\n    - Ensure compatibility between pipeline tasks and agent versions.\n    - Verify compatibility with external services and resources.\n  - **Debugging Strategies:**\n    - Use pipeline logs to identify errors and warnings.\n    - Enable verbose logging for detailed troubleshooting.\n    - Use remote debugging to step through pipeline execution.\n\n- # 7. Tooling and Environment\n  - **Recommended Development Tools:**\n    - Visual Studio Code with the Azure Pipelines extension.\n    - Azure CLI.\n    - PowerShell.\n    - YAML linters and validators.\n  - **Build Configuration Best Practices:**\n    - Use a consistent build configuration across environments.\n    - Store build configuration in version control.\n    - Use environment variables to customize build behavior.\n  - **Linting and Formatting:**\n    - Use YAML linters (e.g., yamllint) to enforce consistent formatting and syntax.\n    - Configure linters to automatically fix formatting issues.\n  - **Deployment Best Practices:**\n    - Use deployment slots for zero-downtime deployments.\n    - Implement rollback mechanisms for failed deployments.\n    - Monitor deployed applications for performance and errors.\n  - **CI/CD Integration:**\n    - Integrate Azure Pipelines with source control systems (e.g., Azure Repos, GitHub).\n    - Automate build, test, and deployment processes.\n    - Use triggers to automatically start pipelines on code changes.\n\n- # Additional Best Practices\n  - **Infrastructure as Code (IaC):** Use tools like ARM templates or Terraform for consistent deployments.\n  - **Automated Testing:** Automate builds, run tests, and perform code quality checks with each commit.\n  - **Secret Management:** Securely manage secrets using Azure Key Vault.\n  - **Monitoring and Alerting:** Implement robust monitoring and alerting for pipeline health.\n  - **Role-Based Access Control (RBAC):** Enforce RBAC to limit access to sensitive resources.\n  - **Regular Audits:** Perform regular security audits to identify and address vulnerabilities.\n\nBy adhering to these guidelines, developers can create robust, secure, and efficient Azure Pipelines for continuous integration and continuous delivery.",
    "metadata": {
      "globs": "*.yml,*.yaml",
      "format": "mdc",
      "originalFile": "azure-pipelines.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "azure",
      "pipelines",
      "comprehensive",
      "guidelines",
      "covering",
      "code",
      "structure",
      "security",
      "performance",
      "testing",
      "azure-pipelines",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "azure-pipelines",
        "azure",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-azure",
    "description": "This rule provides comprehensive best practices for developing Azure applications, covering code organization, security, performance, testing, and common pitfalls. It aims to improve code quality, security posture, and overall efficiency when working with the Azure ecosystem.",
    "author": "sanjeed5",
    "tags": [
      "azure",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/azure.mdc",
    "content": "# Azure Library Best Practices and Coding Standards\n\nThis document outlines the recommended best practices for developing applications and infrastructure using Azure services. It covers various aspects including code organization, security, performance, testing, and tooling to ensure robust, scalable, and secure solutions.\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability, scalability, and collaboration. The following guidelines provide a structured approach to organizing your Azure projects.\n\n### Directory Structure Best Practices\n\nAdopt a modular and logical directory structure based on the application's architecture and components.\n\n*   **`src/`**: Contains the source code of your application.\n    *   **`modules/`**: Groups related functionalities into independent modules.\n    *   **`components/`**: Contains reusable UI or logical components.\n    *   **`services/`**: Encapsulates external service integrations (e.g., Azure Storage, Cosmos DB).\n    *   **`models/`**: Defines data models and schemas.\n    *   **`utils/`**: Contains utility functions and helper classes.\n*   **`infra/` or `terraform/` or `bicep/`**: Infrastructure-as-Code definitions (Terraform, Bicep, Azure Resource Manager templates).\n*   **`config/`**: Configuration files for different environments (development, staging, production).\n*   **`scripts/`**: Automation scripts for deployment, build processes, etc.\n*   **`tests/`**: Unit, integration, and end-to-end tests.\n*   **`docs/`**: Documentation for the project and its components.\n\nExample:\n\n\nmy-azure-project/\n├── src/\n│   ├── modules/\n│   │   ├── user-management/\n│   │   │   ├── ...\n│   │   ├── data-processing/\n│   │   │   ├── ...\n│   ├── components/\n│   │   ├── button/\n│   │   │   ├── ...\n│   ├── services/\n│   │   ├── storage-service.js\n│   │   ├── cosmosdb-service.js\n│   ├── models/\n│   │   ├── user.js\n│   ├── utils/\n│   │   ├── logger.js\n├── infra/\n│   ├── main.tf\n│   ├── variables.tf\n│   ├── outputs.tf\n├── config/\n│   ├── development.json\n│   ├── production.json\n├── scripts/\n│   ├── deploy.sh\n│   ├── build.sh\n├── tests/\n│   ├── unit/\n│   ├── integration/\n│   ├── e2e/\n├── docs/\n│   ├── README.md\n├── .gitignore\n├── package.json\n\n\n### File Naming Conventions\n\nMaintain consistency in file naming to improve readability and searchability.\n\n*   Use descriptive names that reflect the file's purpose.\n*   Use a consistent case (e.g., camelCase or kebab-case).\n*   Use appropriate file extensions (e.g., `.js`, `.ts`, `.py`, `.tf`, `.bicep`).\n*   For React components, use `ComponentName.jsx` or `ComponentName.tsx`.\n\nExample:\n\n*   `user-service.js` (for a user service module)\n*   `UserProfile.jsx` (for a user profile component)\n*   `storage-account.tf` (for a Terraform file defining a storage account)\n\n### Module Organization\n\nDivide the application into independent and reusable modules based on functionality.\n\n*   Each module should have a clear responsibility and a well-defined interface.\n*   Minimize dependencies between modules to promote loose coupling.\n*   Consider using a module bundler (e.g., Webpack, Parcel) to manage dependencies and optimize the build process.\n\nExample:\n\nA `user-management` module could contain components and services related to user authentication, authorization, and profile management.\n\n### Component Architecture\n\nFor UI-based applications, adopt a component-based architecture (e.g., React, Angular, Vue.js).\n\n*   Divide the UI into reusable components with clear inputs and outputs.\n*   Follow the principles of single responsibility and separation of concerns.\n*   Use a component library (e.g., Material UI, Ant Design) to accelerate development and maintain consistency.\n\n### Code Splitting Strategies\n\nImprove initial load time by splitting the application into smaller chunks that can be loaded on demand.\n\n*   Use dynamic imports to load modules only when they are needed.\n*   Configure your module bundler to create separate chunks for different parts of the application.\n*   Consider using route-based code splitting for single-page applications.\n\n## 2. Common Patterns and Anti-patterns\n\nUnderstanding common patterns and anti-patterns is essential for building efficient, maintainable, and reliable Azure applications.\n\n### Design Patterns Specific to Azure\n\n*   **Retry Pattern:** Implement retry logic to handle transient failures when interacting with Azure services.\n*   **Circuit Breaker Pattern:** Prevent cascading failures by temporarily blocking access to a service that is experiencing problems.\n*   **Queue-Based Load Leveling:** Use queues (e.g., Azure Queue Storage, Azure Service Bus) to decouple components and handle bursts of traffic.\n*   **Cache-Aside Pattern:** Use a cache (e.g., Azure Cache for Redis) to improve performance by storing frequently accessed data.\n*   **Gateway Aggregation Pattern:** Expose multiple backend services through a single API gateway (e.g., Azure API Management).\n\n### Recommended Approaches for Common Tasks\n\n*   **Configuration Management:** Use Azure App Configuration to manage application settings and feature flags.\n*   **Secret Management:** Use Azure Key Vault to securely store and manage secrets, keys, and certificates.\n*   **Logging and Monitoring:** Use Azure Monitor to collect and analyze logs, metrics, and traces.\n*   **Identity and Access Management:** Use Azure Active Directory (Azure AD) for authentication and authorization.\n*   **Data Storage:** Choose the appropriate Azure storage service based on your data requirements (e.g., Azure Blob Storage for unstructured data, Azure Cosmos DB for NoSQL data, Azure SQL Database for relational data).\n\n### Anti-Patterns and Code Smells to Avoid\n\n*   **Hardcoding Secrets:** Never hardcode secrets or API keys in your code. Use Azure Key Vault to manage them securely.\n*   **Ignoring Errors:** Always handle errors gracefully and log relevant information for debugging.\n*   **Over-Engineering:** Avoid unnecessary complexity and focus on delivering business value.\n*   **Long-Running Transactions:** Keep transactions short and avoid holding resources for extended periods.\n*   **Tight Coupling:** Design components and modules to be loosely coupled to improve maintainability and testability.\n*   **Monolithic Functions:** Avoid creating large, complex functions. Break them down into smaller, more manageable units.\n\n### State Management Best Practices\n\n*   For serverless functions, design for statelessness whenever possible. Store state in external storage services like Azure Cosmos DB or Azure Storage.\n*   For web applications, use appropriate state management techniques (e.g., cookies, sessions, local storage, or dedicated state management libraries like Redux or Zustand).\n*   Consider using distributed caching (e.g., Azure Cache for Redis) to improve performance and scalability.\n\n### Error Handling Patterns\n\n*   Use try-catch blocks to handle exceptions gracefully.\n*   Log errors with sufficient detail to aid in debugging.\n*   Implement a centralized error handling mechanism to catch and handle unhandled exceptions.\n*   Provide meaningful error messages to the user.\n*   Use Polly library for implementing resilience policies like retry, circuit breaker, and timeout.\n\n## 3. Performance Considerations\n\nOptimizing performance is crucial for delivering a responsive and scalable Azure application.\n\n### Optimization Techniques\n\n*   **Caching:** Implement caching at various levels (e.g., browser, server, database) to reduce latency and improve performance.\n*   **Compression:** Enable compression (e.g., Gzip) to reduce the size of HTTP responses.\n*   **Connection Pooling:** Use connection pooling to reuse database connections and reduce connection overhead.\n*   **Content Delivery Network (CDN):** Use Azure CDN to cache static assets closer to users.\n*   **Database Optimization:** Optimize database queries and indexes to improve query performance.\n*   **Asynchronous Operations:** Use asynchronous operations to avoid blocking the main thread.\n\n### Memory Management\n\n*   **Dispose Resources:** Dispose of disposable resources (e.g., database connections, file streams) properly to avoid memory leaks.\n*   **Garbage Collection:** Be aware of garbage collection behavior and avoid creating unnecessary objects.\n*   **Large Object Heap (LOH):** Be mindful of the LOH and avoid allocating large objects frequently.\n\n### Rendering Optimization\n\n*   **Virtualization:** Use virtualization techniques (e.g., React Virtualized, Angular CDK Virtual Scroll) to efficiently render large lists of data.\n*   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of event handlers.\n*   **Lazy Loading:** Load images and other resources only when they are visible on the screen.\n\n### Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from your bundles.\n*   **Code Splitting:** Split your code into smaller chunks that can be loaded on demand.\n*   **Minification:** Minify your code to reduce its size.\n*   **Image Optimization:** Optimize images by compressing them and using appropriate formats.\n\n### Lazy Loading Strategies\n\n*   **Component-Based Lazy Loading:** Load components only when they are needed.\n*   **Route-Based Lazy Loading:** Load modules associated with specific routes only when those routes are accessed.\n*   **Image Lazy Loading:** Load images only when they are scrolled into view.\n\n## 4. Security Best Practices\n\nSecurity should be a top priority when developing Azure applications.\n\n### Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input and output to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Use anti-CSRF tokens to prevent CSRF attacks.\n*   **Authentication and Authorization Flaws:** Implement robust authentication and authorization mechanisms.\n*   **Insecure Direct Object References (IDOR):** Validate that users have access to the resources they are requesting.\n*   **Security Misconfiguration:** Follow security best practices for configuring Azure services.\n*   **Sensitive Data Exposure:** Protect sensitive data by encrypting it at rest and in transit.\n\n### Input Validation\n\n*   Validate all user input on both the client and server sides.\n*   Use a schema validation library (e.g., Joi, Yup) to define and enforce data validation rules.\n*   Sanitize user input to remove potentially malicious characters.\n\n### Authentication and Authorization Patterns\n\n*   Use Azure Active Directory (Azure AD) for authentication and authorization.\n*   Implement role-based access control (RBAC) to restrict access to resources based on user roles.\n*   Use multi-factor authentication (MFA) to enhance security.\n*   Follow the principle of least privilege.\n*   Leverage Managed Identities for Azure resources to securely access other Azure services.\n\n### Data Protection Strategies\n\n*   Encrypt sensitive data at rest using Azure Storage Service Encryption (SSE) or Azure Disk Encryption.\n*   Encrypt data in transit using TLS/SSL.\n*   Use Azure Key Vault to store and manage encryption keys.\n*   Implement data masking and tokenization to protect sensitive data.\n\n### Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Implement API authentication using API keys, tokens, or OAuth 2.0.\n*   Use rate limiting to prevent abuse.\n*   Use Azure API Management to manage and secure your APIs.\n\n## 5. Testing Approaches\n\nThorough testing is essential for ensuring the quality and reliability of your Azure applications.\n\n### Unit Testing Strategies\n\n*   Write unit tests for individual components and functions.\n*   Use a unit testing framework (e.g., Jest, Mocha, JUnit, pytest).\n*   Aim for high code coverage.\n*   Follow the Arrange-Act-Assert pattern.\n*   Use mocks and stubs to isolate the code under test.\n\n### Integration Testing\n\n*   Write integration tests to verify the interaction between different components and services.\n*   Test the integration with Azure services (e.g., Azure Storage, Cosmos DB).\n*   Use a testing environment that closely resembles the production environment.\n\n### End-to-End Testing\n\n*   Write end-to-end tests to verify the entire application workflow.\n*   Use a testing framework (e.g., Cypress, Selenium, Playwright).\n*   Automate end-to-end tests as part of your CI/CD pipeline.\n\n### Test Organization\n\n*   Organize tests into a clear directory structure.\n*   Use descriptive test names.\n*   Group related tests together.\n\n### Mocking and Stubbing\n\n*   Use mocks to simulate the behavior of external dependencies.\n*   Use stubs to provide predefined responses for API calls.\n*   Use a mocking framework (e.g., Mockito, Jest Mocks).\n\n## 6. Common Pitfalls and Gotchas\n\nBe aware of common pitfalls and gotchas to avoid making mistakes when developing Azure applications.\n\n### Frequent Mistakes Developers Make\n\n*   **Insufficient Resource Sizing:** Underestimating the required resources can lead to performance issues.\n*   **Ignoring Azure Service Limits:** Being unaware of Azure service limits can cause unexpected errors.\n*   **Improper Error Handling:** Inadequate error handling can make it difficult to diagnose and resolve issues.\n*   **Lack of Monitoring:** Failing to monitor the application's performance and health can lead to undetected problems.\n*   **Neglecting Security:** Overlooking security best practices can expose the application to vulnerabilities.\n\n### Edge Cases to Be Aware Of\n\n*   **Network Latency:** Be aware of network latency when interacting with Azure services.\n*   **Transient Faults:** Implement retry logic to handle transient faults.\n*   **Resource Contention:** Be aware of resource contention and design the application to handle it gracefully.\n*   **Data Consistency:** Understand the data consistency models of Azure storage services.\n\n### Version-Specific Issues\n\n*   Be aware of breaking changes in Azure SDKs and APIs.\n*   Keep your dependencies up to date.\n*   Test your application with different versions of Azure services.\n\n### Compatibility Concerns\n\n*   Ensure that your application is compatible with the target Azure environment.\n*   Test your application on different browsers and devices.\n\n### Debugging Strategies\n\n*   Use Azure Monitor to collect and analyze logs, metrics, and traces.\n*   Use remote debugging to debug your application running in Azure.\n*   Use logging to track the flow of execution and identify errors.\n*   Use breakpoints to pause execution and inspect variables.\n\n## 7. Tooling and Environment\n\nChoosing the right tools and environment can significantly improve your development experience.\n\n### Recommended Development Tools\n\n*   **Visual Studio Code:** A popular code editor with excellent support for Azure development.\n*   **Azure CLI:** A command-line tool for managing Azure resources.\n*   **Azure PowerShell:** A PowerShell module for managing Azure resources.\n*   **Terraform:** An infrastructure-as-code tool for provisioning and managing Azure resources.\n*   **Bicep:** A declarative language for deploying Azure resources.\n*   **Azure SDKs:** Libraries for interacting with Azure services from various programming languages.\n\n### Build Configuration\n\n*   Use a build automation tool (e.g., Azure DevOps, Jenkins, GitHub Actions) to automate the build process.\n*   Configure your build process to run tests, linters, and code formatters.\n*   Use environment variables to configure your application for different environments.\n\n### Linting and Formatting\n\n*   Use a linter (e.g., ESLint, Pylint) to enforce code style guidelines.\n*   Use a code formatter (e.g., Prettier, Black) to automatically format your code.\n*   Configure your editor to automatically run the linter and formatter on save.\n\n### Deployment Best Practices\n\n*   Use Infrastructure-as-Code (IaC) to automate the deployment of Azure resources.\n*   Use a deployment pipeline (e.g., Azure Pipelines, GitHub Actions) to automate the deployment process.\n*   Use blue-green deployments or canary deployments to minimize downtime.\n*   Implement rollback strategies to quickly revert to a previous version if necessary.\n\n### CI/CD Integration\n\n*   Integrate your CI/CD pipeline with Azure DevOps, GitHub Actions, or other CI/CD tools.\n*   Automate the build, test, and deployment processes.\n*   Use environment variables to configure your application for different environments.\n*   Implement automated testing to catch errors early in the development cycle.\n\nBy following these best practices, you can build robust, scalable, secure, and maintainable Azure applications.",
    "metadata": {
      "globs": "*.az,*.tf,*.bicep,*.py,*.js,*.ts,*.json,*.yml,*.yaml,*.ps1,*.sh,*.cs,*.java",
      "format": "mdc",
      "originalFile": "azure.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "azure",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "covering",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "azure",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-bash",
    "description": "This rule enforces best practices and coding standards for Bash scripting to improve code quality, maintainability, and security. It covers naming conventions, formatting, error handling, security, and performance considerations.",
    "author": "sanjeed5",
    "tags": [
      "bash",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/bash.mdc",
    "content": "# Bash Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for writing Bash scripts. Following these guidelines will lead to more maintainable, readable, and robust code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nFor large Bash projects, a well-defined directory structure is crucial. Consider the following structure:\n\n\nproject_root/\n├── bin/          # Executable scripts (main entry points)\n├── lib/          # Library scripts (reusable functions and modules)\n├── config/       # Configuration files (e.g., settings, environment variables)\n├── data/         # Data files (e.g., CSV, JSON)\n├── log/          # Log files generated by scripts\n├── tmp/          # Temporary files used during script execution\n├── tests/        # Unit and integration tests\n├── docs/         # Documentation (e.g., README, design documents)\n└── README.md     # Project README\n\n\n### 1.2. File Naming Conventions\n\n*   **Executable Scripts:** Use descriptive names without extensions (e.g., `process_data`, `backup_system`).\n*   **Library Scripts:** Use `.sh` extension (e.g., `string_utils.sh`, `database_functions.sh`). For bash-specific code use `.bash`.\n*   **Configuration Files:** Use `.conf` or `.cfg` extensions (e.g., `app.conf`, `settings.cfg`).\n*   **Test Files:** Use `_test.sh` suffix (e.g., `string_utils_test.sh`).\n\n### 1.3. Module Organization\n\n*   **Separate Concerns:** Divide your code into logical modules, each responsible for a specific task (e.g., database interaction, string manipulation, system monitoring).\n*   **Reusable Functions:** Place reusable functions in library scripts (`lib/`) and source them in your main scripts using `source lib/string_utils.sh` or `. lib/string_utils.sh`.\n*   **Modular Design:** Aim for a modular design where each module can be easily tested and reused in other projects.\n\n### 1.4. Component Architecture\n\n*   **Functions as Components:** Treat functions as components with well-defined inputs (parameters) and outputs (return values or side effects).\n*   **Configuration Management:** Use configuration files to store settings that can be easily modified without changing the script's code.\n*   **Logging:** Implement a consistent logging mechanism to track script execution and errors.\n\n### 1.5. Code Splitting Strategies\n\n*   **Function Decomposition:** Break down complex tasks into smaller, more manageable functions.\n*   **File Inclusion:** Use `source` or `.` to include reusable code from other files.\n*   **External Commands:** Delegate tasks to external commands when appropriate (e.g., `grep`, `sed`, `awk`).\n*   **Consider a 'main' function:** Wrap the primary logic of the script into a `main` function to improve readability and maintainability. All scripts that are long enough to contain at least one other function should have a `main` function.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Facade:** Create a simplified interface to a complex set of functions or modules.\n*   **Strategy:** Define a family of algorithms and encapsulate each one in a separate function, making them interchangeable.\n*   **Template Method:** Define the skeleton of an algorithm in a function, deferring some steps to subfunctions.\n*   **Chain of Responsibility:** Pass a request along a chain of functions until one of them handles it.\n*   **Singleton (Carefully):**  Use sparingly for global configuration, initialize only once.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **String Manipulation:** Use Bash's built-in string manipulation features (e.g., parameter expansion, substring extraction) instead of external commands like `sed` or `awk` when possible.\n*   **File Handling:** Use Bash's built-in file handling commands (e.g., `read`, `write`, `mkdir`, `rm`) for basic operations.  For more complex operations, consider `find` with `-exec` or `xargs`.\n*   **Looping:** Use `for` loops for iterating over lists of items and `while` loops for conditional execution.\n*   **Conditional Statements:** Use `if`, `elif`, and `else` statements for branching logic. Prefer `[[ ]]` over `[ ]` for string comparisons.\n*   **Exit Early:** Use `return` or `exit` to exit the script as soon as an error is detected.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Hardcoded Values:** Avoid hardcoding values directly in the script. Use constants or configuration files instead.\n*   **Unquoted Variables:** Always quote variables to prevent word splitting and globbing issues.\n*   **Eval:** Avoid using `eval` as it can introduce security vulnerabilities and make the code difficult to understand.\n*   **Backticks:** Use `$(command)` instead of backticks for command substitution.\n*   **Relying on Globals:** Minimize the use of global variables to avoid naming conflicts and unexpected side effects. Use `local` within functions.\n*   **Ignoring Errors:** Always check the return values of commands to handle errors gracefully. Use `set -e` to exit on errors automatically.\n*   **Over-commenting Obvious Code:** Comments should explain *why* the code is doing something, not *what* the code is doing.\n*   **Excessive Piping:** While powerful, long pipelines can become unreadable.  Consider breaking down complex operations into smaller, more manageable steps with intermediate variables.\n\n### 2.4. State Management Best Practices\n\n*   **Environment Variables:** Use environment variables to store global configuration settings that can be accessed by all scripts and functions.\n*   **Temporary Files:** Use temporary files to store intermediate data during script execution. Use `mktemp` to create unique temporary file names and remove them when finished. They should be created under `/tmp` or another location if needed.\n*   **Persistent Storage:** For persistent state, consider using a simple database (e.g., SQLite) or a key-value store (e.g., Redis).\n*   **Configuration Files:** Store persistent configuration options in configuration files.\n\n### 2.5. Error Handling Patterns\n\n*   **`set -e`:** Exit immediately if a command exits with a non-zero status.\n*   **Check Return Values:** Use `$?` to check the return value of a command and handle errors accordingly.\n*   **Error Functions:** Create functions to handle common error scenarios (e.g., logging errors, displaying error messages, exiting the script).\n*   **Signal Handling:** Use `trap` to handle signals (e.g., `SIGINT`, `SIGTERM`) and perform cleanup actions.\n*   **Informative Error Messages:**  Provide clear and informative error messages to help users diagnose problems. The error messages should explain the cause and possibly the recommended solution.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Built-in Commands:** Prefer built-in commands over external commands whenever possible, as they are generally faster.\n*   **String Operations:** Use Bash's built-in string manipulation features instead of external commands like `sed` or `awk` for simple operations.\n*   **Avoid Loops:** Minimize the use of loops, as they can be slow in Bash. Consider using `find` with `-exec` or `xargs` for file processing instead.\n*   **Command Substitution:** Avoid unnecessary command substitution, as it can be expensive.\n*   **Arrays:** Use arrays to store lists of items instead of strings, as they are more efficient for iteration and manipulation.\n*   **Parameter Expansion:** Use parameter expansion features like `${var:-default}` to provide default values for variables without using conditional statements.\n*   **`set -f`:** Disable globbing when not needed to prevent unintended file expansion.\n\n### 3.2. Memory Management\n\n*   **Limit Data Size:** Avoid loading large files or data structures into memory.\n*   **Stream Processing:** Use stream processing techniques to process data incrementally instead of loading it all into memory at once.\n*   **Remove Variables:** Unset or reassign variables to release memory when they are no longer needed.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   **Minimize Output:** Reduce the amount of output generated by the script, as it can slow down execution.\n*   **Use `printf`:** Use `printf` for formatted output instead of `echo`, as it is generally faster and more portable.\n\n### 3.4. Bundle Size Optimization (If Applicable)\n\n*   **N/A:** Bash scripts do not typically have bundle sizes in the same way that web applications do.\n\n### 3.5. Lazy Loading\n\n*   **Source on Demand:** Only source library scripts when they are needed.\n*   **Conditional Execution:** Use conditional statements to execute code blocks only when certain conditions are met.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **Command Injection:** Avoid using `eval` and carefully sanitize any user input used in commands.\n*   **Path Injection:**  Sanitize path names to prevent malicious users from manipulating file operations.\n*   **Denial of Service (DoS):** Implement resource limits to prevent scripts from consuming excessive CPU, memory, or disk space.\n*   **Information Disclosure:** Protect sensitive information (e.g., passwords, API keys) by storing them in environment variables or configuration files with appropriate permissions.\n*   **Shellshock:** Ensure your Bash version is patched against the Shellshock vulnerability.\n\n### 4.2. Input Validation\n\n*   **Sanitize User Input:** Carefully sanitize any user input to prevent command injection and other vulnerabilities.\n*   **Regular Expressions:** Use regular expressions to validate input formats (e.g., email addresses, phone numbers).\n*   **Whitelist Validation:** Validate input against a whitelist of allowed values.\n*   **Length Limits:** Enforce length limits on input fields to prevent buffer overflows.\n\n### 4.3. Authentication and Authorization\n\n*   **Avoid Storing Credentials:** Avoid storing credentials directly in scripts or configuration files. Use environment variables or a secure credential store instead.\n*   **Principle of Least Privilege:** Run scripts with the minimum necessary privileges.\n*   **User Authentication:** Implement user authentication using `sudo` or other authentication mechanisms.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to restrict access to sensitive resources based on user roles.\n\n### 4.4. Data Protection\n\n*   **Encryption:** Use encryption to protect sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in log files and other output.\n*   **Access Control:** Restrict access to sensitive data to authorized users only.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n*   **API Keys:** Use API keys to authenticate requests to external APIs.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n*   **Input Validation:** Validate all input from external APIs to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Functions:** Write unit tests to verify the behavior of individual functions.\n*   **Mock Dependencies:** Use mocking techniques to isolate functions from their dependencies.\n*   **Assert Statements:** Use assert statements to verify that the functions return the expected values.\n*   **Testing Frameworks:** Consider using a bash testing framework like Bats (Bash Automated Testing System).\n\n### 5.2. Integration Testing\n\n*   **Test Interactions:** Write integration tests to verify the interactions between different modules or components.\n*   **Real Environments:** Run integration tests in a real or simulated environment.\n*   **End-to-End Testing:** Write end-to-end tests to verify the entire script from start to finish.\n\n### 5.3. End-to-End Testing\n\n*   **Real Use Cases:** Emulate real-world use cases to test the script's overall functionality.\n*   **System-Level Testing:** Verify that the script interacts correctly with the underlying system.\n\n### 5.4. Test Organization\n\n*   **Separate Test Directory:** Create a separate `tests/` directory to store test files.\n*   **Naming Convention:** Use a consistent naming convention for test files (e.g., `module_name_test.sh`).\n*   **Test Suites:** Organize tests into suites based on functionality or module.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock External Commands:** Create mock versions of external commands to isolate functions from their dependencies.\n*   **Stub Functions:** Create stub versions of functions to control their behavior during testing.\n*   **Environment Variable Mocking:** Mock environment variables to test different configurations.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Forgetting `set -e`:** Not exiting on errors can lead to unexpected behavior.\n*   **Unquoted Variables:** Forgetting to quote variables can lead to word splitting and globbing issues.\n*   **Incorrect Variable Scope:** Using global variables when local variables are needed can lead to naming conflicts.\n*   **Not Checking Return Values:** Not checking return values can lead to errors being ignored.\n*   **Over-reliance on Globals** Using global variables when local variables are preferable can lead to unintended side effects.\n*   **Not using Functions** Code becomes difficult to maintain if its not broken into manageable functions.\n\n### 6.2. Edge Cases\n\n*   **Empty Variables:** Handle empty variables gracefully.\n*   **Special Characters:** Handle special characters in file names and other input.\n*   **Large Files:** Handle large files efficiently to prevent memory issues.\n*   **Race Conditions:** Avoid race conditions when multiple scripts are running concurrently.\n\n### 6.3. Version-Specific Issues\n\n*   **Bash 3 vs. Bash 4:** Be aware of compatibility issues between different versions of Bash.\n*   **POSIX Compliance:** If portability is a concern, stick to POSIX-compliant syntax.\n\n### 6.4. Compatibility Concerns\n\n*   **Operating Systems:** Ensure your scripts are compatible with the target operating systems.\n*   **External Tools:** Be aware of the dependencies on external tools and ensure they are available on the target systems.\n\n### 6.5. Debugging Strategies\n\n*   **`set -x`:** Enable tracing to see the commands being executed.\n*   **`echo` Statements:** Use `echo` statements to print variable values and debug messages.\n*   **Shellcheck:** Use Shellcheck to identify common errors and warnings.\n*   **Interactive Debugging:** Use an interactive debugger like `bashdb` to step through the code.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Text Editor:** Use a text editor with syntax highlighting and code completion for Bash (e.g., VS Code, Sublime Text, Vim).\n*   **Shellcheck:** Use Shellcheck to lint your Bash code.\n*   **Bats:** Use Bats for unit testing.\n*   **Bashdb:** Use Bashdb for interactive debugging.\n*   **Git:** Use Git for version control.\n\n### 7.2. Build Configuration\n\n*   **Makefile:** Use a Makefile to automate build and test processes.\n*   **Dependency Management:** Use a dependency management tool like `dep` to manage external dependencies.\n\n### 7.3. Linting and Formatting\n\n*   **Shellcheck:** Use Shellcheck to lint your Bash code and enforce coding standards.\n*   **shfmt:** Use shfmt for automatic code formatting.\n\n### 7.4. Deployment Best Practices\n\n*   **Package Scripts:** Package your scripts and dependencies into a deployable package (e.g., Debian package, RPM package).\n*   **Configuration Management:** Use configuration management tools (e.g., Ansible, Puppet, Chef) to deploy and configure your scripts on target systems.\n*   **Automated Deployment:** Use automated deployment pipelines to deploy your scripts quickly and reliably.\n*   **Idempotent Scripts:** Ensure your deployment scripts are idempotent, meaning they can be run multiple times without causing unintended side effects.\n\n### 7.5. CI/CD Integration\n\n*   **Continuous Integration (CI):** Integrate your Bash scripts into a CI pipeline to automatically run tests and linting on every commit.\n*   **Continuous Deployment (CD):** Integrate your Bash scripts into a CD pipeline to automatically deploy your scripts to production.\n\n## 8. Naming Conventions\n\nFollow these naming conventions:\n\n*   **Function Names:** Lowercase, with underscores to separate words (e.g., `process_data`, `calculate_total`).\n*   **Variable Names:** Lowercase, with underscores to separate words (e.g., `input_file`, `output_directory`). Loop variables should be similarly named for the variable you're looping through.\n*   **Constant Names:** All caps, separated with underscores (e.g., `MAX_RETRIES`, `DEFAULT_TIMEOUT`). Declared at the top of the file.\n*   **File Names:** Lowercase, with underscores to separate words (e.g., `data_processing.sh`, `configuration_settings.conf`).\n\n## 9. Style and Formatting\n\n*   **Indentation:** Use 2 spaces for indentation. No tabs.\n*   **Line Length:** Limit lines to 80 characters. Use line continuation characters (`\\`) to break long lines.\n*   **Spacing:** Use spaces around operators and after commas.\n*   **Comments:** Write clear and concise comments to explain the purpose and logic of your code. Any function that is not both obvious and short must be commented. Any function in a library must be commented regardless of length or complexity. Use `TODO` comments to mark code that needs to be improved or completed.\n*   **Quoting:** Always quote variables unless careful unquoted expansion is required.\n*   **Braces:** Use `${variable}` instead of `$variable` for clarity.\n*   **Pipelines:** Format pipelines for maximum clarity. Break long pipelines into multiple lines with one pipeline element per line.\n\n## 10. Exit Codes\n*   Ensure exit codes are consistent throughout the scripts.\n*   Use `exit 0` for successful completion.\n*   Use non-zero exit codes (e.g., 1, 2, 127, etc.) to indicate failure.\n*   Standardize exit codes for specific error conditions across your project.\n*   Include custom error messages with meaningful context.\n\nFollowing these best practices and coding standards will help you write more maintainable, readable, secure, and efficient Bash scripts.",
    "metadata": {
      "globs": "*.sh",
      "format": "mdc",
      "originalFile": "bash.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "bash",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "scripting",
      "improve",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "bash",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-beautifulsoup4",
    "description": "This rule file outlines best practices for using the beautifulsoup4 library in Python, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "beautifulsoup4",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/beautifulsoup4.mdc",
    "content": "By following these best practices, you can build robust, efficient, and secure web scrapers using beautifulsoup4.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "beautifulsoup4.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "beautifulsoup4",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "using",
      "library",
      "python",
      "covering",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "beautifulsoup4",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-behave",
    "description": "This rule file provides comprehensive best practices for writing maintainable and effective Behave BDD tests, including code organization, common patterns, performance considerations, and security.",
    "author": "sanjeed5",
    "tags": [
      "behave",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/behave.mdc",
    "content": "",
    "metadata": {
      "globs": "*.feature",
      "format": "mdc",
      "originalFile": "behave.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "behave",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "writing",
      "maintainable",
      "effective",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "behave",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-black",
    "description": "Enforces consistent code formatting using Black, the uncompromising Python code formatter, promoting readability and reducing diffs. Covers best practices related to Black's configuration, usage, and integrations.",
    "author": "sanjeed5",
    "tags": [
      "black",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/black.mdc",
    "content": "- Adopt Black as the primary code formatter for all Python projects.\n- Adhere to Black's default style guide for consistent formatting across projects.\n- Integrate Black into the development workflow using pre-commit hooks and CI/CD pipelines.\n- Configure Black using `pyproject.toml` file for project-specific settings, if needed.\n- Use Black's CLI or editor integrations for seamless formatting.\n\n## Black Code Formatting Best Practices\n\nBlack is the uncompromising Python code formatter. By using it, you agree to cede control over minutiae of hand-formatting. In return, Black gives you speed, determinism, and freedom from `pycodestyle` nagging about formatting. You will save time and mental energy for more important matters.\n\n### Key Principles\n\n- **Consistency:** Black enforces a consistent code style, reducing ambiguity and promoting readability.\n- **Automation:** Black automates the formatting process, eliminating manual effort and reducing formatting-related code review comments.\n- **Integration:** Black integrates seamlessly with popular development tools and workflows.\n- **Minimal Configuration:** Black provides sensible defaults and limits configuration options to ensure consistency.\n\n### 1. Code Organization and Structure\n\nBlack primarily focuses on formatting within files, but it indirectly influences code organization by promoting readability and consistent style. Consider the following:\n\n- **Directory Structure:** Black doesn't enforce a specific directory structure. However, a well-organized project with clear module boundaries will benefit more from consistent formatting.\n- **File Naming Conventions:** Black uses the `.py` extension for python files. Adhering to PEP 8 naming conventions alongside Black is recommended for improved readability (`snake_case` for variables, functions, and modules; `PascalCase` for classes).\n- **Module Organization:** Black formats code within modules. Break large modules into smaller, more manageable files to improve readability and maintainability. Organize related functions and classes within modules.\n- **Component Architecture:** Black can be used with any component architecture. Focus on creating well-defined components with clear interfaces. Consistent formatting within each component enhances maintainability.\n- **Code Splitting Strategies:** Black formats code regardless of the splitting strategy. Break code into smaller functions or classes to improve code readability and organization.\n\n### 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:** Black doesn't impose any specific design patterns. However, it encourages clean, readable code that makes it easier to implement design patterns correctly. For example, consistent formatting makes it easier to identify and understand the structure of a Factory pattern.\n- **Recommended Approaches:**\n    - Use Black on all Python files in your project.\n    - Integrate Black into your pre-commit hooks to automatically format code before committing.\n    - Use Black's CLI to format entire directories or specific files.\n    - Configure Black using `pyproject.toml` to customize settings like line length, if necessary.\n- **Anti-patterns:**\n    - Manually formatting code instead of using Black.\n    - Ignoring Black's formatting suggestions.\n    - Disabling Black for specific files or sections of code without a strong reason.\n- **State Management:** Black doesn't directly address state management, but its consistent formatting promotes code clarity, making state management strategies easier to implement and understand. Consider using established state management patterns like Redux or Context API (if applicable).\n- **Error Handling:** Black encourages readable code, making it easier to implement and understand error handling mechanisms. Use `try...except` blocks to handle exceptions gracefully. Consistent formatting of exception handling code improves maintainability.\n\n### 3. Performance Considerations\n\nBlack's formatting process itself has minimal performance overhead. The main performance considerations are related to the code being formatted, not Black itself.\n\n- **Optimization Techniques:** Black-formatted code is easier to read and understand, which can help identify performance bottlenecks. Use profiling tools to identify slow code and optimize accordingly.\n- **Memory Management:** Black doesn't directly affect memory management. Follow Python's memory management best practices, such as using generators for large datasets and avoiding circular references.\n- **Rendering Optimization:** Not applicable as Black is primarily a code formatter and not directly involved in rendering.\n- **Bundle Size Optimization:** Not applicable as Black is a code formatter. Bundle size optimization techniques are relevant to web applications or other deployments where code size impacts load times.\n- **Lazy Loading:** Not applicable as Black is a code formatter.\n\n### 4. Security Best Practices\n\nBlack improves code readability, which can help identify potential security vulnerabilities. However, Black itself doesn't directly address security. Focus on the following security best practices:\n\n- **Common Vulnerabilities:** Black doesn't prevent common vulnerabilities like SQL injection or cross-site scripting (XSS). Use secure coding practices to avoid these vulnerabilities.\n- **Input Validation:** Implement robust input validation to prevent injection attacks. Black's consistent formatting makes it easier to review input validation code.\n- **Authentication and Authorization:** Use established authentication and authorization patterns to protect your application. Black's consistent formatting can improve the readability of authentication and authorization code.\n- **Data Protection:** Use encryption to protect sensitive data. Follow data protection best practices, such as storing passwords securely.\n- **Secure API Communication:** Use HTTPS to encrypt API communication. Implement API authentication and authorization to prevent unauthorized access.\n\n### 5. Testing Approaches\n\nBlack promotes consistent code formatting, making tests easier to write, read, and maintain.\n\n- **Unit Testing:** Write unit tests for individual functions and classes. Black's consistent formatting makes it easier to write clear and concise unit tests.\n- **Integration Testing:** Write integration tests to verify that different components of your application work together correctly. Consistent formatting makes it easier to understand the interactions between components.\n- **End-to-end Testing:** Write end-to-end tests to verify that your application works as expected from a user's perspective. Consistent formatting makes it easier to debug end-to-end tests.\n- **Test Organization:** Organize your tests into a logical directory structure. Follow a consistent naming convention for test files and functions.\n- **Mocking and Stubbing:** Use mocking and stubbing to isolate units of code during testing. Black's consistent formatting makes it easier to understand the code being tested and create appropriate mocks.\n\n### 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Not integrating Black into the development workflow.\n    - Ignoring Black's formatting suggestions.\n    - Over-configuring Black and deviating from its default style.\n- **Edge Cases:**\n    - Black may have difficulty formatting very complex or deeply nested expressions.\n    - Black's formatting may not always be optimal for specific use cases.\n- **Version-specific Issues:**\n    - Ensure that all developers are using the same version of Black to avoid formatting inconsistencies.\n- **Compatibility Concerns:**\n    - Black may have compatibility issues with older versions of Python or other tools.\n- **Debugging Strategies:**\n    - Use Black's CLI to format code and identify formatting issues.\n    - Use a debugger to step through code and understand its behavior.\n\n### 7. Tooling and Environment\n\n- **Recommended Tools:**\n    - Black: The primary code formatter.\n    - Pre-commit: A tool for managing pre-commit hooks.\n    - VS Code, PyCharm, or other Python IDEs with Black integration.\n- **Build Configuration:**\n    - Configure Black in your project's `pyproject.toml` file.\n    - Integrate Black into your build process to automatically format code.\n- **Linting and Formatting:**\n    - Use Black for formatting and other linters (e.g., Flake8, pylint) for code quality checks.\n    - Configure your linter to ignore formatting errors reported by Black.\n- **Deployment:**\n    - Ensure that your deployment environment has Black installed.\n    - Run Black as part of your deployment process to ensure consistent formatting.\n- **CI/CD Integration:**\n    - Integrate Black into your CI/CD pipeline to automatically format code and run tests.\n\n### Example `.pre-commit-config.yaml`\n\n\nrepos:\n-   repo: https://github.com/psf/black\n    rev: 24.2.2  # Replace with the latest version\n    hooks:\n    -   id: black\n\n\n### Example `pyproject.toml`\n\ntoml\n[tool.black]\nline-length = 88\ntarget-version = ['py38', 'py39', 'py310']\ninclude = '\\.pyi?$'\nexclude = '''\n/(\\.(git|hg|mypy_cache|tox|venv)|_build|build|dist)/  # Removed: |/foo/bar/\n'''\n\n\nBy following these best practices, you can leverage Black to improve code quality, enhance collaboration, and reduce development time.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "black.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "black",
      "enforces",
      "consistent",
      "code",
      "formatting",
      "using",
      "uncompromising",
      "python",
      "formatter",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "black",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-boto3",
    "description": "This rule file outlines best practices for using the boto3 library, including code organization, security, performance, testing, and common pitfalls. It aims to ensure efficient, secure, and maintainable AWS integrations with boto3.",
    "author": "sanjeed5",
    "tags": [
      "boto3",
      "aws",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/boto3.mdc",
    "content": "---\n\n# boto3 Best Practices\n\nThis document outlines best practices for using the boto3 library in Python for interacting with Amazon Web Services (AWS). Following these guidelines will help you write more efficient, secure, and maintainable code.\n\n## 1. Project Setup and Authentication\n\n- **Use Sessions**: Always use boto3 sessions for managing configurations and credentials effectively.\n  python\n  import boto3\n  session = boto3.Session()\n  s3 = session.client('s3')\n  \n- **Avoid Hard-coding Credentials**: Never hard-code AWS credentials in your code. Use environment variables, AWS CLI configuration, IAM roles, or AWS Secrets Manager.\n\n  - **Environment Variables**:\n    python\n    import os\n    aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n    aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n    \n\n  - **AWS CLI Configuration**:\n    Configure your credentials using the AWS CLI (`aws configure`). Boto3 will automatically pick up the credentials.\n\n  - **IAM Roles**: Use IAM roles for EC2 instances or Lambda functions to grant permissions.\n  \n  - **AWS Secrets Manager**: Securely store and retrieve secrets (like database passwords or API keys) using AWS Secrets Manager, accessible via boto3.\n\n## 2. Code Organization and Structure\n\n- **Directory Structure**: Organize your project with a clear directory structure.\n  \n  my_project/\n  ├── src/\n  │   ├── __init__.py\n  │   ├── aws/\n  │   │   ├── __init__.py\n  │   │   ├── s3_utils.py\n  │   │   ├── dynamodb_utils.py\n  │   ├── models/\n  │   │   ├── __init__.py\n  │   │   ├── user.py\n  │   ├── main.py\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── aws/\n  │   │   ├── test_s3_utils.py\n  │   │   ├── test_dynamodb_utils.py\n  ├── requirements.txt\n  ├── .env\n  └── README.md\n  \n\n- **File Naming Conventions**: Use descriptive and consistent file names.\n  - `s3_utils.py`: Contains S3-related utility functions.\n  - `dynamodb_utils.py`: Contains DynamoDB-related utility functions.\n  - `user.py`: Defines a User model or data structure.\n\n- **Module Organization**: Break down your code into logical modules.\n  - `aws/`: Contains modules for interacting with different AWS services.\n  - `models/`: Contains data models representing your application's entities.\n\n- **Component Architecture**: Design your application with reusable components.\n  - Create separate functions or classes for different AWS operations (e.g., uploading files, querying DynamoDB).\n\n- **Code Splitting**: Split large files into smaller, more manageable files.\n  - Group related functions and classes into separate files.\n  - Use clear and concise names for your files and modules.\n\n## 3. Common Patterns and Anti-patterns\n\n- **Design Patterns**: Use appropriate design patterns for boto3 interactions.\n\n  - **Factory Pattern**: Create clients using a factory pattern to abstract client creation.\n    python\n    class AWSClientFactory:\n        def create_client(self, service_name, session=None):\n            if not session:\n                session = boto3.Session()\n            return session.client(service_name)\n\n    factory = AWSClientFactory()\n    s3 = factory.create_client('s3')\n    \n\n  - **Strategy Pattern**: Implement different strategies for handling AWS operations (e.g., different retry mechanisms).\n\n- **Recommended Approaches**: Follow recommended approaches for common tasks.\n\n  - **Uploading Files to S3**: Use `upload_file` or `upload_fileobj` for uploading files to S3.\n    python\n    s3.upload_file('my_local_file.txt', 'my_bucket', 'my_s3_key.txt')\n    \n  - **Downloading Files from S3**: Use `download_file` or `download_fileobj` for downloading files from S3.\n    python\n    s3.download_file('my_bucket', 'my_s3_key.txt', 'my_local_file.txt')\n    \n\n- **Anti-patterns**: Avoid common anti-patterns.\n\n  - **Tight Coupling**: Don't tightly couple your application logic with boto3 code. Abstract AWS interactions behind interfaces.\n  - **Ignoring Errors**: Always handle exceptions when interacting with AWS services.\n  - **Over-permissioning**: Grant only the necessary permissions to IAM roles.\n\n- **State Management**: Manage state effectively in your boto3 applications.\n\n  - **Stateless Functions**: Prefer stateless functions that don't rely on global variables.\n  - **DynamoDB Sessions**: Use DynamoDB for storing session data in web applications.\n\n- **Error Handling**: Implement robust error handling.\n  python\n  from botocore.exceptions import ClientError\n\n  try:\n      response = s3.get_object(Bucket='my_bucket', Key='my_key')\n      print(response['Body'].read().decode('utf-8'))\n  except ClientError as e:\n      if e.response['Error']['Code'] == 'NoSuchKey':\n          print('The specified key does not exist.')\n      else:\n          print(f'An error occurred: {e}')\n  \n\n## 4. Performance Considerations\n\n- **Optimization Techniques**: Optimize boto3 interactions for performance.\n\n  - **Pagination**: Use pagination to handle large datasets.\n    python\n    paginator = s3.get_paginator('list_objects_v2')\n    pages = paginator.paginate(Bucket='my_bucket')\n    for page in pages:\n        for obj in page['Contents']:\n            print(obj['Key'])\n    \n\n  - **Batch Operations**: Use batch operations for efficient data processing.\n    python\n    import boto3\n\n    s3 = boto3.resource('s3')\n    bucket = s3.Bucket('my-bucket')\n\n    delete_keys = [{'Key': 'file1.txt'}, {'Key': 'file2.txt'}]\n\n    response = bucket.delete_objects(Delete={'Objects': delete_keys})\n    print(response)\n    \n  - **Transfer Acceleration**: For faster uploads over long distances, enable S3 Transfer Acceleration.\n    python\n    s3 = boto3.client('s3',\n        config=boto3.session.Config(\n            s3={'use_accelerate_endpoint': True}\n        )\n    )\n    \n\n- **Memory Management**: Be mindful of memory usage when working with large files or datasets.\n\n  - **Streaming**: Use streaming operations to process data in chunks.\n  - **Garbage Collection**: Ensure proper garbage collection to release unused memory.\n\n- **Bundle Size Optimization**: Reduce bundle size by using only necessary boto3 modules.\n\n- **Lazy Loading**: Load boto3 modules only when needed to reduce startup time.\n\n## 5. Security Best Practices\n\n- **Common Vulnerabilities**: Understand and prevent common vulnerabilities.\n\n  - **Credential Leakage**: Protect your AWS credentials from being exposed in code or logs.\n  - **Injection Attacks**: Sanitize inputs to prevent injection attacks.\n  - **Cross-Site Scripting (XSS)**: Protect against XSS attacks when displaying data from AWS.\n\n- **Input Validation**: Validate all inputs to prevent security issues.\n\n  - **Sanitize Inputs**: Remove or escape potentially harmful characters from inputs.\n  - **Use Parameterized Queries**: Use parameterized queries to prevent SQL injection attacks when working with databases.\n\n- **Authentication and Authorization**: Implement proper authentication and authorization mechanisms.\n\n  - **Principle of Least Privilege**: Grant only the necessary permissions to IAM roles and users.\n  - **Multi-Factor Authentication (MFA)**: Enable MFA for sensitive operations.\n\n- **Data Protection**: Protect your data at rest and in transit.\n\n  - **Encryption**: Use server-side encryption (SSE-S3) for data security by default.  For additional security using AWS Key Management Service (KMS) keys, include encryption parameters\n    python\n    response = boto3.client('s3').upload_file(\n        file_path,\n        bucket_name,\n        key,\n        ExtraArgs={\n            'ServerSideEncryption': 'aws:kms',\n            'SSEKMSKeyId': 'your-kms-key-id'\n        }\n    )\n    \n\n  - **Secure Transport**: Enforce HTTPS-only access by applying a bucket policy.\n  - **Versioning**: Enable S3 Versioning for recovery.\n\n- **Secure API Communication**: Ensure secure communication with AWS APIs.\n\n  - **HTTPS**: Always use HTTPS for communication with AWS services.\n\n## 6. Testing Approaches\n\n- **Unit Testing**: Write unit tests for your boto3 components.\n\n  - **Mocking**: Use mocking libraries like `moto` to simulate AWS services during testing.\n  - **Test Cases**: Create comprehensive test cases for different scenarios.\n\n- **Integration Testing**: Test the integration of your boto3 components with AWS services.\n\n  - **LocalStack**: Use LocalStack to simulate AWS services locally for integration testing.\n  - **End-to-End Tests**: Write end-to-end tests to verify the complete application flow.\n\n- **Test Organization**: Organize your tests in a clear and maintainable structure.\n\n  - **Separate Test Files**: Create separate test files for each module or component.\n  - **Descriptive Test Names**: Use descriptive names for your test functions and classes.\n\n- **Mocking and Stubbing**: Use mocking and stubbing techniques to isolate components during testing.\n\n  - **Mock Boto3 Clients**: Mock boto3 clients to avoid making real API calls during unit tests.\n\n  python\n  import boto3\n  from moto import mock_aws\n  import unittest\n\n  class MyTestCase(unittest.TestCase):\n\n      @mock_aws\n      def test_s3_upload(self):\n          s3 = boto3.client('s3')\n          s3.create_bucket(Bucket='mybucket')\n          s3.put_object(Bucket='mybucket', Key='myfile', Body='my content')\n          response = s3.get_object(Bucket='mybucket', Key='myfile')\n          self.assertEqual(response['Body'].read().decode('utf-8'), 'my content')\n\n  if __name__ == '__main__':\n      unittest.main()\n\n  \n\n## 7. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes**: Be aware of common mistakes when using boto3.\n\n  - **Incorrect Region**: Specifying the wrong AWS region.\n  - **Missing Permissions**: Insufficient IAM permissions.\n  - **Not Handling Exceptions**: Ignoring exceptions raised by boto3.\n\n- **Edge Cases**: Consider edge cases when designing your application.\n\n  - **Throttling**: Handle API throttling by implementing retry mechanisms.\n\n- **Version-Specific Issues**: Be aware of version-specific issues with boto3.\n\n  - **API Changes**: Keep up with API changes and deprecations.\n  - **Compatibility**: Test your code with different boto3 versions.\n\n- **Compatibility Concerns**: Address compatibility concerns between boto3 and other technologies.\n\n  - **Python Versions**: Ensure compatibility with different Python versions.\n  - **Dependency Conflicts**: Resolve dependency conflicts with other libraries.\n\n- **Debugging**: Use effective debugging strategies for boto3 applications.\n\n  - **Logging**: Implement detailed logging to track API calls and errors.\n  - **Debugging Tools**: Use debugging tools like `pdb` or IDE debuggers.\n\n## 8. Tooling and Environment\n\n- **Recommended Development Tools**: Use recommended development tools.\n\n  - **IDE**: Use a Python IDE like VS Code, PyCharm, or Sublime Text.\n  - **AWS CLI**: Use the AWS CLI for managing AWS resources.\n\n- **Build Configuration**: Configure your build process for boto3 projects.\n\n  - **Requirements File**: Use a `requirements.txt` file to manage dependencies.\n  - **Virtual Environments**: Use virtual environments to isolate dependencies.\n\n- **Linting and Formatting**: Follow linting and formatting recommendations.\n\n  - **PEP 8**: Adhere to PEP 8 style guidelines.\n  - **Linters**: Use linters like `flake8` or `pylint` to enforce code quality.\n  - **Formatters**: Use formatters like `black` to automatically format your code.\n\n- **Deployment**: Follow deployment best practices.\n\n  - **Infrastructure as Code (IaC)**: Use IaC tools like Terraform or CloudFormation to manage your infrastructure.\n  - **CI/CD**: Implement CI/CD pipelines for automated deployments.\n\n- **CI/CD Integration**: Integrate your boto3 projects with CI/CD systems.\n\n  - **Automated Tests**: Run automated tests during the CI/CD process.\n  - **Deployment Pipelines**: Create deployment pipelines to automate the deployment process.\n\n## 9. Advanced S3 features\n\n- S3 Object Lambda: Process and transform the data returned by S3 GET requests on the fly without modifying the stored object.\n- S3 Lifecycle policies: Automate the transition of objects to more cost-effective storage classes, or schedule their deletion based on defined rules.\n- S3 Event Notifications: Monitor bucket events and trigger actions such as invoking Lambda functions, sending messages via SNS or SQS, when new objects are created.\n\nFor example, you can configure S3 Event Notifications with Boto3 as follows:\npython\nimport boto3\ns3_client = boto3.client('s3')\nnotification_configuration = {\n    'LambdaFunctionConfigurations': [\n        {\n            'LambdaFunctionArn': 'arn:aws:lambda:us-east-1:123456789012:function:ProcessS3Event',\n            'Events': ['s3:ObjectCreated:*'],\n            'Filter': {\n                'Key': {\n                    'FilterRules': [\n                        {'Name': 'suffix', 'Value': '.jpg'}\n                    ]\n                }\n            }\n        }\n    ]\n}\ns3_client.put_bucket_notification_configuration(\n    Bucket='your-bucket-name',\n    NotificationConfiguration=notification_configuration\n)\n\n\n## 10. Best Practices Summary\n\n- **Security**: Prioritize security by avoiding hard-coded credentials, enforcing the principle of least privilege, and using encryption.\n- **Performance**: Optimize performance by using pagination, batch operations, and S3 Transfer Acceleration.\n- **Error Handling**: Implement robust error handling with comprehensive logging.\n- **Testing**: Write unit tests, integration tests, and end-to-end tests using mocking and LocalStack.\n- **Code Organization**: Maintain a clear and modular code structure.\n\nBy following these best practices, you can ensure that your boto3 applications are efficient, secure, and maintainable.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "boto3.mdc"
    },
    "subcategory": "cloud",
    "keywords": [
      "cursor",
      "boto3",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "using",
      "library",
      "including",
      "code",
      "aws",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "boto3",
        "aws",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-bottle",
    "description": "Comprehensive coding standards, best practices, and architectural guidelines for Python backend development with the Bottle microframework, designed to improve code quality, maintainability, and security.",
    "author": "sanjeed5",
    "tags": [
      "bottle",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/bottle.mdc",
    "content": "# Bottle Framework Best Practices\n\nThis document provides comprehensive coding standards, best practices, and architectural guidelines for Python backend development using the Bottle microframework. Adhering to these guidelines will improve code quality, maintainability, security, and overall project success.\n\n## 1. Code Organization and Structure\n\nEffective code organization is crucial for maintainability and scalability.  Here's how to structure your Bottle applications:\n\n### 1.1. Directory Structure Best Practices\n\nA well-organized directory structure makes it easier to navigate and understand the project.\n\n\nmy_bottle_app/\n├── app.py          # Main application entry point\n├── routes/\n│   ├── __init__.py   # Make 'routes' a package\n│   ├── home.py       # Route definitions for the home page\n│   ├── api.py        # Route definitions for the API\n│   └── users.py      # Route definitions for user management\n├── models/\n│   ├── __init__.py\n│   ├── user.py       # User model definition\n│   └── product.py    # Product model definition\n├── views/\n│   ├── __init__.py\n│   ├── home.tpl      # Template for the home page\n│   └── user_list.tpl # Template for listing users\n├── config.py       # Application configuration\n├── db.py           # Database connection and setup\n├── utils/\n│   ├── __init__.py\n│   ├── auth.py       # Authentication utilities\n│   └── helpers.py    # General helper functions\n├── tests/\n│   ├── __init__.py\n│   ├── test_routes.py  # Tests for route handlers\n│   └── test_models.py  # Tests for data models\n├── requirements.txt  # Project dependencies\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   **Python Files:** Use lowercase with underscores (snake_case) for Python file names (e.g., `user_model.py`, `api_routes.py`).\n*   **Template Files:** Use lowercase with underscores, and the `.tpl` extension (e.g., `product_details.tpl`).\n*   **Configuration Files:** Use a descriptive name like `config.py`.\n*   **Test Files:** Prefix test files with `test_` (e.g., `test_user_routes.py`).\n\n### 1.3. Module Organization\n\n*   **Separate Concerns:** Group related functionality into separate modules (e.g., routes, models, utilities).\n*   **Use Packages:** Utilize Python packages (directories with `__init__.py` files) to further organize modules into logical groups.\n*   **Avoid Circular Imports:** Carefully manage dependencies between modules to prevent circular import errors.  Structure your code so that lower-level modules (e.g., models, utilities) don't depend on higher-level modules (e.g., routes).\n\n### 1.4. Component Architecture\n\n*   **MVC (Model-View-Controller):** While Bottle is simple, aim for an MVC-like structure:\n    *   **Models:** Represent data and business logic (e.g., database interactions).\n    *   **Views:** Render the user interface (using Bottle's templating or another engine).\n    *   **Controllers (Routes):** Handle user requests, interact with models, and select the appropriate view.\n*   **Service Layer (Optional):**  For more complex applications, introduce a service layer between routes and models to encapsulate business logic and improve testability.\n\n### 1.5. Code Splitting Strategies\n\n*   **Functional Decomposition:** Break down complex functions into smaller, more manageable functions with single responsibilities.\n*   **Route Grouping:**  Group related routes into separate modules or route blueprints for better organization.\n*   **Configuration Management:** Move configuration settings to a separate module for easy management and environment-specific configurations.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton (Carefully):**  Use sparingly for resources like database connections. Ensure thread safety if using a singleton in a multithreaded environment.\n*   **Factory:**  Useful for creating model instances or other objects in a controlled manner.\n*   **Middleware (Plugins):**  Bottle's plugin system allows you to create reusable middleware components for tasks like authentication, logging, and request processing.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Database Access:** Use an ORM (SQLAlchemy) for database interaction.  This provides an abstraction layer, improves code readability, and helps prevent SQL injection vulnerabilities.\n*   **Templating:** Leverage Bottle's built-in templating engine for simple projects. For more complex templating needs, consider Jinja2 or Mako.\n*   **Request Handling:**  Use Bottle's decorators (`@route`, `@get`, `@post`) for defining routes and handling HTTP requests.\n*   **Error Handling:** Implement custom error handlers for different HTTP status codes to provide informative error messages to the client.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Fat Routes:** Avoid putting too much logic directly in route handlers.  Delegate complex tasks to models, services, or helper functions.\n*   **Global State:** Minimize the use of global variables.  Prefer dependency injection or passing data as arguments.\n*   **Hardcoding Configuration:**  Never hardcode sensitive information like API keys or database credentials. Use environment variables or a configuration file.\n*   **Ignoring Exceptions:**  Don't catch exceptions and do nothing.  Log the error and take appropriate action (e.g., return an error response to the client).\n*   **SQL Injection Vulnerabilities:** Avoid string concatenation when building SQL queries.  Use parameterized queries provided by your ORM or database driver.\n\n### 2.4. State Management\n\n*   **Stateless Architecture:**  Prefer a stateless architecture where each request is independent and doesn't rely on server-side session state.  This improves scalability.\n*   **Sessions (if needed):**  If session state is required, use a session middleware (e.g., Beaker) or a token-based authentication system (JWT).\n*   **Cookies:**  Use cookies for storing non-sensitive information on the client-side.\n\n### 2.5. Error Handling\n\n*   **Specific Exception Handling:** Catch specific exceptions rather than generic `Exception` to handle different error scenarios appropriately.\n*   **Logging:** Use the `logging` module to log errors and other important events.  Configure different logging levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) for different environments.\n*   **Custom Error Pages:** Create custom error pages for different HTTP status codes (404, 500, etc.) to provide a better user experience.\n*   **Return Informative Error Responses:** When an error occurs, return a JSON response with a clear error message and status code.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Caching:** Implement caching for frequently accessed data to reduce database load and improve response times. Use Bottle's caching mechanism or an external caching system like Redis or Memcached.\n*   **Database Optimization:** Optimize database queries by using indexes, avoiding unnecessary joins, and selecting only the required columns.\n*   **Gzip Compression:** Enable Gzip compression for HTTP responses to reduce the amount of data transferred to the client.\n*   **Asynchronous Operations:** Use asynchronous tasks (e.g., Celery) for long-running operations like sending emails or processing large datasets. This prevents blocking the main thread and improves responsiveness.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks in your code.\n\n### 3.2. Memory Management\n\n*   **Avoid Memory Leaks:**  Be careful when dealing with large datasets or long-running processes to avoid memory leaks.  Use generators or iterators to process data in chunks.\n*   **Resource Management:**  Release resources (e.g., database connections, file handles) as soon as they are no longer needed.  Use `try...finally` blocks or context managers (`with` statement) to ensure resources are released even if an exception occurs.\n\n### 3.3. Rendering Optimization\n\n*   **Template Caching:**  Enable template caching to improve rendering performance.  Bottle's built-in templating engine supports caching.\n*   **Minify CSS and JavaScript:**  Minify CSS and JavaScript files to reduce their size and improve loading times.\n*   **Optimize Images:**  Optimize images for the web by using appropriate image formats, compression levels, and dimensions.\n\n### 3.4. Bundle Size Optimization (Applicable if using Bottle to serve static assets)\n\n*   **Code Splitting (For Single Page Apps):** If building a SPA, consider code-splitting your javascript into smaller bundles.\n*   **Tree Shaking:** Use a bundler (like Webpack or Parcel) that supports tree shaking to remove unused code from your JavaScript bundles.\n\n### 3.5. Lazy Loading\n\n*   **Lazy Imports:**  Import modules only when they are needed. This can reduce startup time.\n*   **Database Connection on Demand:**  Establish database connections only when they are required, rather than at application startup.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **SQL Injection:**  Use parameterized queries with an ORM like SQLAlchemy to prevent SQL injection vulnerabilities.\n*   **Cross-Site Scripting (XSS):** Sanitize user input before displaying it in templates to prevent XSS attacks.  Use Bottle's HTML escaping functions or a templating engine that automatically escapes HTML.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection by generating and validating CSRF tokens for state-changing requests. Bottle doesn't have built-in CSRF protection, so you'll need to use a library or implement it manually.\n*   **Authentication Bypass:** Ensure proper authentication and authorization mechanisms are in place to prevent unauthorized access to resources.\n*   **Denial of Service (DoS):**  Implement rate limiting and input validation to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n*   **Validate All User Input:**  Validate all user input on both the client-side and server-side.\n*   **Use Data Type Validation:**  Ensure that input data matches the expected data types.\n*   **Sanitize Input:**  Sanitize input data to remove potentially harmful characters or code.\n*   **Limit Input Length:**  Limit the length of input fields to prevent buffer overflows.\n\n### 4.3. Authentication and Authorization\n\n*   **Use a Strong Authentication Scheme:** Implement a secure authentication scheme like OAuth 2.0 or JWT.\n*   **Hash Passwords:**  Hash passwords using a strong hashing algorithm (e.g., bcrypt or Argon2) before storing them in the database. Never store passwords in plain text.\n*   **Implement Role-Based Access Control (RBAC):**  Implement RBAC to control access to resources based on user roles.\n*   **Use HTTPS:**  Always use HTTPS to encrypt communication between the client and server.\n\n### 4.4. Data Protection\n\n*   **Encrypt Sensitive Data:**  Encrypt sensitive data (e.g., credit card numbers, social security numbers) both in transit and at rest.\n*   **Use Environment Variables:**  Store sensitive configuration data (e.g., API keys, database credentials) in environment variables rather than hardcoding them in the code.\n*   **Regularly Update Dependencies:** Keep your dependencies up to date to patch security vulnerabilities.\n*   **Secure File Uploads:** Validate file types and sizes during upload.  Store uploaded files outside the web root and serve them through a controlled endpoint.\n\n### 4.5. Secure API Communication\n\n*   **API Keys:** Use API keys for authentication and authorization of API clients.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n*   **Input Validation:** Thoroughly validate all data received through the API.\n*   **HTTPS Only:** Require HTTPS for all API communication.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components (e.g., functions, classes) in isolation.\n*   **Use a Testing Framework:** Use a testing framework like `pytest` or `unittest` to write and run unit tests.\n*   **Mock Dependencies:**  Mock external dependencies (e.g., database connections, API calls) to isolate the component being tested.\n*   **Test Edge Cases:**  Test edge cases and boundary conditions to ensure that the component handles unexpected input correctly.\n*   **Follow the Arrange-Act-Assert Pattern:**  Structure your tests using the Arrange-Act-Assert pattern to make them more readable and maintainable.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Integration tests should focus on testing the interactions between different components of the application.\n*   **Use a Test Database:**  Use a separate test database to avoid affecting the production database.\n*   **Test API Endpoints:**  Test API endpoints to ensure that they return the correct data and status codes.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate User Interactions:** End-to-end tests should simulate user interactions with the application to ensure that the entire system works correctly.\n*   **Use a Browser Automation Tool:** Use a browser automation tool like Selenium or Playwright to automate end-to-end tests.\n*   **Test Common User Flows:**  Test common user flows to ensure that the application meets the needs of its users.\n\n### 5.4. Test Organization\n\n*   **Separate Test Files:**  Create separate test files for each module or component.\n*   **Organize Tests by Feature:**  Organize tests into directories based on the feature they are testing.\n*   **Use Descriptive Test Names:**  Use descriptive test names that clearly indicate what the test is verifying.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mocking for External Dependencies:** Use mocking to simulate the behavior of external dependencies (e.g., databases, APIs) in your tests.\n*   **Use Stubbing for Complex Calculations:** Use stubbing to replace complex calculations with precomputed values.\n*   **Use a Mocking Library:**  Use a mocking library like `unittest.mock` or `pytest-mock` to simplify the process of creating mocks and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not Sanitizing User Input:**  Failing to sanitize user input can lead to XSS vulnerabilities.\n*   **Hardcoding Secrets:** Hardcoding sensitive information like API keys or database passwords directly in the code makes them vulnerable to exposure.\n*   **Incorrect Error Handling:** Improper exception handling can result in unhandled errors and application crashes.\n*   **Ignoring Security Updates:** Neglecting dependency updates leaves you exposed to known vulnerabilities.\n\n### 6.2. Edge Cases\n\n*   **Unicode Handling:** Ensure your application handles Unicode characters correctly, especially when dealing with user input or data from external sources.\n*   **Time Zones:** Be mindful of time zones when dealing with dates and times.  Store dates and times in UTC and convert them to the user's local time zone when displaying them.\n*   **Concurrency Issues:** If your application handles concurrent requests, be aware of potential race conditions and synchronization issues.\n\n### 6.3. Version-Specific Issues\n\n*  **Bottle Versions:** Stay informed about changes and bug fixes of specific Bottle versions you are using.  Check the Bottle changelog for changes that may impact your application.\n\n### 6.4. Compatibility Concerns\n\n*   **Python Version Compatibility:**  Ensure your application is compatible with the Python version you are using.  Bottle supports Python 3.6+.\n*   **Dependency Conflicts:**  Be aware of potential dependency conflicts between different libraries. Use a virtual environment to isolate your project's dependencies.\n\n### 6.5. Debugging Strategies\n\n*   **Use a Debugger:** Use a debugger like `pdb` or the built-in debugger in your IDE to step through your code and inspect variables.\n*   **Logging:** Use the `logging` module to log errors and other important events.  Configure different logging levels for different environments.\n*   **Error Handling:**  Implement custom error handlers to catch exceptions and provide informative error messages.\n*   **Testing:**  Write unit tests and integration tests to catch bugs early in the development process.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE:**  Use a powerful IDE like Visual Studio Code, PyCharm, or Sublime Text for code editing, debugging, and testing.\n*   **Virtual Environment Manager:**  Use `venv`, `virtualenv`, or `conda` to create virtual environments for isolating project dependencies.\n*   **Package Manager:** Use `pip` or `conda` to install and manage Python packages.\n*   **Database Client:** Use a database client like DBeaver or pgAdmin to connect to and manage your databases.\n\n### 7.2. Build Configuration\n\n*   **Use `requirements.txt`:** Use a `requirements.txt` file to specify your project's dependencies. Generate this file using `pip freeze > requirements.txt`.\n*   **Specify Versions:** Specify exact versions of your dependencies in `requirements.txt` to ensure consistent builds across different environments.\n*   **Use a Build Tool (Optional):** For more complex projects, consider using a build tool like Make or Invoke to automate build tasks.\n\n### 7.3. Linting and Formatting\n\n*   **Use a Linter:** Use a linter like `flake8` or `pylint` to enforce coding style and identify potential errors.\n*   **Use a Formatter:** Use a code formatter like `black` or `autopep8` to automatically format your code according to PEP 8.\n*   **Configure Your IDE:** Configure your IDE to automatically run the linter and formatter when you save a file.\n\n### 7.4. Deployment Best Practices\n\n*   **Use a Production Web Server:** Use a production-ready web server like Gunicorn or uWSGI to serve your application.\n*   **Use a Reverse Proxy:** Use a reverse proxy like Nginx or Apache to handle static assets, SSL termination, and load balancing.\n*   **Use a Process Manager:** Use a process manager like Supervisor or systemd to ensure that your application is always running.\n*   **Monitor Your Application:** Use a monitoring tool like Prometheus or Grafana to monitor your application's performance and identify potential issues.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD Pipeline:** Use a CI/CD pipeline to automate the process of building, testing, and deploying your application.\n*   **Use a CI/CD Tool:** Use a CI/CD tool like Jenkins, GitLab CI, GitHub Actions, or CircleCI to create your CI/CD pipeline.\n*   **Run Tests Automatically:** Configure your CI/CD pipeline to run tests automatically on every commit.\n*   **Automate Deployment:** Automate the deployment process so that new versions of your application are deployed automatically when the tests pass.\n\nBy following these best practices, you can build robust, maintainable, and secure Bottle applications that meet the needs of your users and your organization.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "bottle.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "bottle",
      "comprehensive",
      "coding",
      "standards",
      "best",
      "practices",
      "architectural",
      "guidelines",
      "python",
      "backend",
      "development",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "bottle",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-bun",
    "description": "This rule provides comprehensive guidance on Bun library coding standards, best practices, and common patterns. It includes performance optimization, security considerations, and testing strategies.",
    "author": "sanjeed5",
    "tags": [
      "bun",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/bun.mdc",
    "content": "# Bun Library Best Practices\n\nThis document outlines the recommended coding standards, best practices, and patterns for developing applications using the Bun library. Following these guidelines ensures maintainability, performance, security, and overall code quality.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nA well-defined directory structure is crucial for maintainability. Consider the following structure as a starting point:\n\n\nproject-root/\n├── src/                  # Source code\n│   ├── components/       # Reusable UI components (if applicable)\n│   ├── services/         # Business logic and API interactions\n│   ├── utils/            # Utility functions\n│   ├── types/            # TypeScript type definitions\n│   ├── routes/           # API route handlers\n│   ├── middleware/       # Middleware functions\n│   ├── models/           # Data models\n│   ├── config/           # Configuration files\n│   ├── index.ts          # Entry point for the application\n├── tests/                # Unit and integration tests\n├── public/               # Static assets (e.g., images, CSS)\n├── .env                  # Environment variables\n├── bun.lockb             # Lockfile for dependencies\n├── package.json          # Project metadata and dependencies\n├── tsconfig.json         # TypeScript configuration\n├── README.md             # Project documentation\n\n\n*   **src/**: Contains the main source code of the application.\n*   **components/**: Houses reusable UI components (if building a web application).\n*   **services/**: Encapsulates business logic and interactions with external APIs.\n*   **utils/**: Contains utility functions used throughout the application.\n*   **types/**: Stores TypeScript type definitions.\n*   **routes/**: Defines API route handlers using Bun's built-in HTTP server.\n*   **middleware/**: Includes middleware functions for request processing.\n*   **models/**: Defines data models used in the application.\n*   **config/**: Contains configuration files for different environments.\n*   **tests/**: Holds unit and integration tests.\n*   **public/**: Stores static assets like images and CSS files.\n*   **.env**: Stores environment variables.\n*   **bun.lockb**:  Lockfile ensuring consistent dependency versions.\n*   **package.json**: Defines project metadata and dependencies.\n*   **tsconfig.json**: Configures TypeScript compiler options.\n*   **README.md**: Provides project documentation and instructions.\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   Prefer camelCase for JavaScript/TypeScript files (e.g., `userService.ts`, `apiHelper.js`).\n*   Use kebab-case for component directories (e.g., `user-profile`).\n*   For React components, use PascalCase for the filename (e.g., `UserProfile.tsx`).\n\n### 1.3. Module Organization\n\n*   Group related functionality into modules.\n*   Use clear and concise module names.\n*   Export only the necessary functions and classes from each module.\n*   Favor explicit imports over global variables.\n\n### 1.4. Component Architecture (if applicable)\n\n*   If building a web application, adopt a component-based architecture (e.g., using React, SolidJS).\n*   Divide the UI into small, reusable components.\n*   Follow the Single Responsibility Principle (SRP) for each component.\n*   Use a consistent component structure (e.g., a folder for each component containing the component file, styles, and tests).\n\n### 1.5. Code Splitting Strategies\n\n*   Use dynamic imports (`import()`) to split code into smaller chunks.\n*   Load only the necessary code for each route or component.\n*   Consider using a library like `esbuild` (Bun's underlying bundler) or `parcel` to automate code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton**: Use for managing global resources (e.g., database connections, configuration).\n*   **Factory**: Use for creating objects without specifying their concrete classes.\n*   **Observer**: Use for implementing event-driven systems.\n*   **Middleware**: Use to handle requests and responses in a centralized manner.\n*   **Dependency Injection**: Use to decouple components and improve testability.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **API Request Handling**: Utilize `fetch` API provided by Bun for making HTTP requests.\n*   **File System Operations**: Use `Bun.file()` and other built-in functions for reading and writing files.\n*   **Process Management**: Leverage `Bun.spawn()` or `Bun.serve()` to manage child processes and servers.\n*   **Environment Variable Access**: Use `Bun.env` or `process.env` to access environment variables.\n*   **Logging**: Implement logging using `console.log` or a dedicated logging library like `pino`.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Global State**: Avoid using global variables for application state. Use state management solutions instead.\n*   **Long Functions**: Break down long functions into smaller, more manageable functions.\n*   **Duplicated Code**: Extract common logic into reusable functions or modules.\n*   **Magic Numbers**: Use named constants instead of hardcoded values.\n*   **Ignoring Errors**: Always handle errors properly using try-catch blocks or error handling middleware.\n\n### 2.4. State Management Best Practices\n\n*   If your application requires complex state management, consider using a library like Zustand, Valtio, or Jotai.\n*   Choose a state management solution that fits the complexity of your application.\n*   Keep state updates predictable and consistent.\n*   Avoid mutating state directly.\n\n### 2.5. Error Handling Patterns\n\n*   Use try-catch blocks to handle synchronous errors.\n*   Use `async/await` with try-catch blocks for asynchronous errors.\n*   Implement error handling middleware to catch unhandled exceptions.\n*   Log errors with relevant information (e.g., stack trace, request details).\n*   Provide informative error messages to the user.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Minimize Dependencies**:  Reduce the number of dependencies to decrease bundle size and install time.\n*   **Code Splitting**:  Split code into smaller chunks that can be loaded on demand.\n*   **Tree Shaking**:  Remove unused code during the build process.\n*   **Caching**:  Cache frequently accessed data to reduce latency.\n*   **Compression**:  Compress responses using gzip or Brotli to reduce network traffic.\n*   **Efficient Algorithms**: Choose the most efficient algorithms for your tasks.\n\n### 3.2. Memory Management\n\n*   Avoid memory leaks by properly releasing resources.\n*   Use weak references to avoid circular dependencies.\n*   Monitor memory usage using tools like `bun --inspect`.\n*   Be mindful of large data structures and use streams when appropriate.\n\n### 3.3. Rendering Optimization (if applicable)\n\n*   Use virtualization for large lists or tables.\n*   Optimize images and other assets.\n*   Use memoization to avoid unnecessary re-renders.\n*   Profile rendering performance using browser developer tools.\n\n### 3.4. Bundle Size Optimization\n\n*   Use a bundler like `esbuild` to minimize bundle size.\n*   Remove unused code and dependencies.\n*   Use code splitting to load only the necessary code.\n*   Consider using a smaller alternative to large libraries.\n\n### 3.5. Lazy Loading Strategies\n\n*   Use dynamic imports (`import()`) to load modules on demand.\n*   Implement lazy loading for images and other assets.\n*   Use a library like `react-lazyload` (if using React) to simplify lazy loading.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS)**: Sanitize user input to prevent malicious scripts from being injected into the page.\n*   **Cross-Site Request Forgery (CSRF)**: Use CSRF tokens to prevent attackers from forging requests on behalf of authenticated users.\n*   **SQL Injection**: Use parameterized queries or an ORM to prevent attackers from injecting malicious SQL code.\n*   **Authentication and Authorization**: Implement robust authentication and authorization mechanisms to protect sensitive data.\n*   **Denial of Service (DoS)**: Implement rate limiting and other measures to prevent attackers from overwhelming the server.\n\n### 4.2. Input Validation\n\n*   Validate all user input on both the client and server sides.\n*   Use a validation library like `zod` or `yup` to define validation schemas.\n*   Sanitize user input to remove potentially harmful characters.\n*   Escape user input when displaying it on the page.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   Use a secure authentication protocol like OAuth 2.0 or OpenID Connect.\n*   Store passwords securely using a hashing algorithm like bcrypt or Argon2.\n*   Implement role-based access control (RBAC) to restrict access to sensitive resources.\n*   Use JSON Web Tokens (JWT) for authentication and authorization.\n\n### 4.4. Data Protection Strategies\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use HTTPS to encrypt communication between the client and server.\n*   Store encryption keys securely using a key management system.\n*   Regularly back up data to prevent data loss.\n\n### 4.5. Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Implement API authentication using API keys or JWTs.\n*   Rate limit API requests to prevent abuse.\n*   Validate API requests and responses.\n*   Use a firewall to protect the API from unauthorized access.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   Write unit tests for individual functions and classes.\n*   Use a testing framework like Jest or Bun's built-in test runner.\n*   Aim for high code coverage.\n*   Use mocks and stubs to isolate units of code.\n*   Test edge cases and error conditions.\n\n### 5.2. Integration Testing\n\n*   Write integration tests to verify the interaction between different modules.\n*   Test the integration of the application with external APIs.\n*   Use a testing framework like Jest or Mocha.\n*   Use a testing database or mock API to isolate the tests.\n\n### 5.3. End-to-End Testing\n\n*   Write end-to-end tests to verify the entire application flow.\n*   Use a testing framework like Playwright or Cypress.\n*   Run tests in a browser environment.\n*   Test the application from the user's perspective.\n\n### 5.4. Test Organization\n\n*   Create a separate `tests` directory for test files.\n*   Organize test files in a way that mirrors the source code structure.\n*   Use descriptive test names.\n*   Follow a consistent testing style.\n\n### 5.5. Mocking and Stubbing\n\n*   Use mocks and stubs to isolate units of code during testing.\n*   Use a mocking library like `jest.mock()` or `sinon`.\n*   Mock external dependencies to avoid relying on external services.\n*   Stub functions to control their behavior during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   **Not Using Strict Mode**: Always use strict mode (`'use strict'`) to catch common coding errors.\n*   **Ignoring Error Handling**: Always handle errors properly using try-catch blocks or error handling middleware.\n*   **Leaking Global Variables**: Avoid creating global variables by using `let` or `const` to declare variables.\n*   **Not Understanding Asynchronous JavaScript**:  Understand how asynchronous JavaScript works to avoid common pitfalls like callback hell.\n*   **Over-Engineering**: Keep the code simple and avoid unnecessary complexity.\n\n### 6.2. Edge Cases to Be Aware Of\n\n*   **Handling Null and Undefined Values**:  Check for null and undefined values before using them to avoid errors.\n*   **Integer Overflow**: Be aware of integer overflow and underflow when performing arithmetic operations.\n*   **Unicode Support**:  Properly handle Unicode characters to avoid encoding issues.\n*   **Time Zone Handling**:  Handle time zones correctly to avoid date and time discrepancies.\n\n### 6.3. Version-Specific Issues\n\n*   Be aware of breaking changes in new versions of Bun.\n*   Test the application with different versions of Bun to ensure compatibility.\n*   Use a version manager like `bunx` to manage different Bun versions.\n\n### 6.4. Compatibility Concerns\n\n*   Ensure the application is compatible with different operating systems and browsers.\n*   Use polyfills to support older browsers.\n*   Test the application on different devices to ensure responsiveness.\n\n### 6.5. Debugging Strategies\n\n*   Use the `bun --inspect` flag to debug the application using Chrome DevTools.\n*   Use `console.log` statements to print debugging information.\n*   Use a debugger like VS Code's built-in debugger.\n*   Use a logging library to log errors and other important events.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **VS Code**: A popular code editor with excellent TypeScript support.\n*   **ESLint**: A linter for identifying and fixing code style issues.\n*   **Prettier**: A code formatter for automatically formatting code.\n*   **Jest**: A testing framework for unit and integration testing.\n*   **Playwright/Cypress**: A testing framework for end-to-end testing.\n*   **Postman/Insomnia**: API client for testing API endpoints.\n\n### 7.2. Build Configuration\n\n*   Use a build tool like `esbuild` or `webpack` to bundle the application.\n*   Configure the build tool to optimize the bundle size and performance.\n*   Use environment variables to configure the build process for different environments.\n\n### 7.3. Linting and Formatting\n\n*   Use ESLint to enforce consistent coding style.\n*   Use Prettier to automatically format code.\n*   Integrate ESLint and Prettier into the development workflow using VS Code extensions or command-line tools.\n*   Configure ESLint and Prettier to follow the project's coding style guidelines.\n\n### 7.4. Deployment Best Practices\n\n*   Use a process manager like `pm2` or `systemd` to manage the application in production.\n*   Deploy the application to a cloud platform like DigitalOcean, Vercel, or Render.\n*   Use a CI/CD pipeline to automate the deployment process.\n*   Monitor the application's performance and health using monitoring tools.\n\n### 7.5. CI/CD Integration\n\n*   Use a CI/CD platform like GitHub Actions, GitLab CI, or CircleCI to automate the build, test, and deployment process.\n*   Configure the CI/CD pipeline to run tests, lint code, and build the application on every commit.\n*   Use environment variables to configure the CI/CD pipeline for different environments.\n*   Deploy the application to a staging environment before deploying it to production.\n\nBy following these best practices, developers can build high-quality, performant, and secure applications using the Bun library. Remember to adapt these guidelines to the specific needs of your project.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx,*.bun",
      "format": "mdc",
      "originalFile": "bun.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "bun",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "library",
      "coding",
      "standards",
      "best",
      "practices",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "bun",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-c-sharp",
    "description": "This rule file provides a comprehensive guide to C# best practices, coding standards, and common patterns for writing maintainable, performant, and secure code.",
    "author": "sanjeed5",
    "tags": [
      "c-sharp",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/c-sharp.mdc",
    "content": "# C# Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to C# best practices, coding standards, and common patterns for writing maintainable, performant, and secure code. It covers various aspects of C# development, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.\n\n**Library Information:**\n- Name: c-sharp\n- Tags: language, microsoft, dotnet, backend\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability, scalability, and collaboration. Here are some best practices for organizing your C# code:\n\n### 1.1. Directory Structure Best Practices\n\n*   **Project Root:** Contains the solution file (.sln) and project directories.\n*   **Project Directory:** Contains the project file (.csproj), source code, and other project-related files.\n    *   `src/`: Contains the main source code.\n        *   `Models/`: Data models and DTOs (Data Transfer Objects).\n        *   `Services/`: Business logic and service classes.\n        *   `Controllers/`: API controllers (if applicable).\n        *   `Repositories/`: Data access logic.\n        *   `Utilities/`: Helper classes and utility functions.\n        *   `Exceptions/`: Custom exception definitions.\n        *   `Interfaces/`: Interface definitions for abstraction.\n        *   `Configuration/`: Configuration-related classes.\n    *   `tests/`: Contains unit tests, integration tests, and end-to-end tests.\n    *   `docs/`: Documentation for the project.\n    *   `build/`: Build scripts and configuration files.\n    *   `Properties/`: Assembly information and project settings.\n\nExample:\n\n\nMyProject/\n├── MyProject.sln\n├── MyProject/\n│   ├── MyProject.csproj\n│   ├── src/\n│   │   ├── Models/\n│   │   ├── Services/\n│   │   ├── Controllers/\n│   │   ├── Repositories/\n│   │   ├── Utilities/\n│   │   ├── Exceptions/\n│   │   ├── Interfaces/\n│   │   └── Configuration/\n│   ├── Properties/\n│   │   └── AssemblyInfo.cs\n│   └── appsettings.json\n├── MyProject.Tests/\n│   ├── MyProject.Tests.csproj\n│   └── UnitTests/\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   **Classes:** PascalCase (e.g., `MyClass.cs`)\n*   **Interfaces:** IPascalCase (e.g., `IMyInterface.cs`)\n*   **Enums:** PascalCase (e.g., `MyEnum.cs`)\n*   **Structs:** PascalCase (e.g., `MyStruct.cs`)\n*   **Delegates:** PascalCase (e.g., `MyDelegate.cs`)\n*   **Configuration Files:** appsettings.json, config.xml\n*   **Test Files:** `MyClassTests.cs`\n\n### 1.3. Module Organization\n\n*   **Namespaces:** Use namespaces to group related classes and interfaces.  Follow a consistent naming convention for namespaces (e.g., `CompanyName.ProjectName.ModuleName`).\n*   **Assemblies:**  Divide large projects into multiple assemblies to improve build times, reduce dependencies, and enable code reuse. Consider functional or domain boundaries when creating assemblies.\n*   **NuGet Packages:** Use NuGet packages to manage dependencies and share code across projects.\n\n### 1.4. Component Architecture\n\n*   **Layered Architecture:** Separate the application into distinct layers (e.g., presentation, business logic, data access) to promote separation of concerns and testability.\n*   **Microservices Architecture:** For large and complex applications, consider a microservices architecture where the application is composed of small, independent services.\n*   **Dependency Injection (DI):** Use DI to manage dependencies between components and improve testability and maintainability. Popular DI containers include Autofac, Ninject, and Microsoft.Extensions.DependencyInjection.\n\n### 1.5. Code Splitting Strategies\n\n*   **By Feature:** Group code related to a specific feature into a separate module or assembly.\n*   **By Layer:** Separate code based on the architectural layer (e.g., presentation, business logic, data access).\n*   **By Responsibility:**  Split classes and methods into smaller, more focused units of work.\n*   **Partial Classes:** Use partial classes to split a large class into multiple files for better organization (use sparingly).\n\n## 2. Common Patterns and Anti-patterns\n\nUnderstanding common design patterns and anti-patterns is essential for writing effective and maintainable C# code.\n\n### 2.1. Design Patterns\n\n*   **Singleton:** Ensures that a class has only one instance and provides a global point of access to it.\n*   **Factory:** Provides an interface for creating objects without specifying their concrete classes.\n*   **Abstract Factory:** Provides an interface for creating families of related objects without specifying their concrete classes.\n*   **Builder:** Separates the construction of a complex object from its representation, allowing the same construction process to create different representations.\n*   **Observer:** Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n*   **Strategy:** Defines a family of algorithms, encapsulates each one, and makes them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\n*   **Dependency Injection (DI):**  A technique whereby one object (or static method) supplies the dependencies of another object. This helps to decouple components.\n*   **Repository:** Mediates between the domain and data mapping layers, acting like an in-memory domain object collection.\n*   **Unit of Work:**  Maintains a list of objects affected by a business transaction and coordinates the writing out of changes.\n*   **Asynchronous Programming Patterns (TAP, EAP, APM):**  Handle asynchronous operations efficiently using async/await.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **String Manipulation:** Use `StringBuilder` for efficient string concatenation in loops.\n*   **File I/O:** Use `using` statements or `try-finally` blocks to ensure proper disposal of file resources.\n*   **Data Access:** Use ORMs like Entity Framework Core or Dapper for simplified data access.\n*   **Asynchronous Operations:** Use `async` and `await` for non-blocking asynchronous operations.\n*   **Configuration Management:** Use `Microsoft.Extensions.Configuration` for managing application configuration.\n*   **Logging:** Use logging frameworks like Serilog or NLog for structured logging.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **God Class:** A class that does too much and has too many responsibilities.\n*   **Long Method:** A method that is too long and complex.\n*   **Feature Envy:** A method that accesses data from another object more than its own.\n*   **Shotgun Surgery:** Changes to one part of the code require changes to many other parts.\n*   **Data Clump:** Groups of data that appear together in multiple places.\n*   **Primitive Obsession:** Using primitive types instead of creating custom classes for domain concepts.\n*   **Switch Statements (over Polymorphism):** Using large switch statements instead of leveraging polymorphism.\n*   **Magic Numbers/Strings:** Hardcoding values directly in the code instead of using constants or configuration settings.\n*   **Ignoring Exceptions:** Catching exceptions without handling them properly.\n*   **Empty Catch Blocks:** Catching exceptions and doing nothing.\n*   **Over-commenting:** Writing excessive comments that are obvious from the code itself.\n*   **Dead Code:** Code that is never executed.\n\n### 2.4. State Management Best Practices\n\n*   **Stateless Services:** Design services to be stateless whenever possible to improve scalability and reliability.\n*   **Session State:** Use session state sparingly and only when necessary. Consider using distributed caching for session state in web applications.\n*   **Caching:** Use caching to improve performance by storing frequently accessed data in memory.\n*   **Redux/Flux:** For complex UI applications, consider using a state management library like Redux or Flux.\n*   **Immutable Data Structures:** Use immutable data structures to simplify state management and prevent unintended side effects.\n\n### 2.5. Error Handling Patterns\n\n*   **Try-Catch-Finally:** Use `try-catch-finally` blocks to handle exceptions and ensure proper resource cleanup.\n*   **Exception Filters:** Use exception filters to catch specific exceptions based on certain conditions.\n*   **Custom Exceptions:** Create custom exception types for specific error conditions in your application.\n*   **Logging Exceptions:** Log exceptions with sufficient context to aid in debugging.\n*   **Graceful Degradation:** Handle errors gracefully and provide informative error messages to the user.\n*   **Throw Early, Catch Late:** Detect errors as early as possible and handle exceptions at a higher level.\n\n## 3. Performance Considerations\n\nOptimizing C# code for performance is crucial for creating responsive and efficient applications.\n\n### 3.1. Optimization Techniques\n\n*   **Avoid Boxing and Unboxing:** Boxing and unboxing value types can be expensive. Use generics to avoid boxing and unboxing.\n*   **Use Value Types When Appropriate:** Value types (structs) can be more efficient than reference types (classes) for small, immutable data structures.\n*   **Minimize Object Allocation:** Object allocation can be expensive. Reuse objects whenever possible.\n*   **Use `StringBuilder` for String Concatenation:** `StringBuilder` is more efficient than string concatenation using the `+` operator, especially in loops.\n*   **Optimize LINQ Queries:** Use LINQ carefully and avoid unnecessary iterations or computations.  Consider using `AsParallel()` for parallel processing of large collections (with caution, as parallelism introduces complexity).\n*   **Use Asynchronous Programming:** Use `async` and `await` to avoid blocking the main thread and improve responsiveness.\n*   **Avoid Excessive Locking:** Minimize the use of locks to prevent contention and improve concurrency.\n*   **Use Lazy Initialization:** Initialize objects only when they are needed to avoid unnecessary initialization overhead.\n*   **Profile Your Code:** Use profiling tools to identify performance bottlenecks and optimize accordingly.  Visual Studio Profiler, dotTrace, and PerfView are good options.\n\n### 3.2. Memory Management Considerations\n\n*   **Garbage Collection:** Understand how the garbage collector works and avoid creating excessive garbage.\n*   **Dispose of Resources:** Implement the `IDisposable` interface and use `using` statements to ensure proper disposal of resources (e.g., file streams, database connections).\n*   **Weak References:** Use weak references to hold references to objects without preventing them from being garbage collected.\n*   **Object Pooling:** Use object pooling to reuse objects and reduce allocation overhead.\n*   **Large Object Heap (LOH):** Be aware of the Large Object Heap and avoid allocating large objects unnecessarily.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   **UI Virtualization:** Use UI virtualization to render only the visible items in a large list or grid.\n*   **Reduce Overdraw:** Minimize the number of times pixels are drawn on top of each other.\n*   **Batch Rendering:** Batch rendering operations to reduce the number of draw calls.\n*   **Use Hardware Acceleration:** Use hardware acceleration to offload rendering tasks to the GPU.\n\n### 3.4. Bundle Size Optimization (If Applicable)\n\n*   **Tree Shaking:** Remove unused code from the bundle.\n*   **Code Minification:** Minify code to reduce its size.\n*   **Code Compression:** Compress code using Gzip or Brotli.\n*   **Image Optimization:** Optimize images to reduce their size without sacrificing quality.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Lazy Initialization:** Use `Lazy<T>` to initialize objects only when they are accessed.\n*   **Virtual Proxy:** Use a virtual proxy to load related data only when it is needed.\n*   **Explicit Loading:** Load related data explicitly using methods like `Include` in Entity Framework Core.\n\n## 4. Security Best Practices\n\nSecurity should be a primary concern in C# development to protect against vulnerabilities and attacks.\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **SQL Injection:** Parameterize database queries to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Encode user input to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Use anti-forgery tokens to prevent CSRF attacks.\n*   **Authentication and Authorization Vulnerabilities:** Implement secure authentication and authorization mechanisms.\n*   **Insecure Direct Object References (IDOR):** Validate user access to objects to prevent IDOR attacks.\n*   **File Upload Vulnerabilities:** Validate file types and sizes to prevent malicious file uploads.\n*   **Denial-of-Service (DoS) Attacks:** Implement rate limiting and other measures to prevent DoS attacks.\n*   **Deserialization Vulnerabilities:** Avoid deserializing untrusted data.\n*   **Dependency Vulnerabilities:** Regularly update dependencies to patch security vulnerabilities.\n\n### 4.2. Input Validation\n\n*   **Validate All User Input:** Validate all user input on both the client and server side.\n*   **Use Regular Expressions:** Use regular expressions to validate input formats.\n*   **Sanitize Input:** Sanitize input to remove or escape potentially malicious characters.\n*   **Use Whitelisting:** Use whitelisting to allow only known good input values.\n*   **Limit Input Length:** Limit the length of input fields to prevent buffer overflows.\n\n### 4.3. Authentication and Authorization\n\n*   **Use Strong Passwords:** Enforce strong password policies and use password hashing algorithms like bcrypt.\n*   **Implement Multi-Factor Authentication (MFA):** Use MFA to add an extra layer of security to the authentication process.\n*   **Use Role-Based Access Control (RBAC):** Use RBAC to control user access to resources based on their roles.\n*   **Use Claims-Based Authentication:** Use claims-based authentication to represent user identities and permissions.\n*   **Implement Proper Session Management:** Implement secure session management practices, including session timeouts and secure cookies.\n*   **OAuth 2.0 and OpenID Connect:** Leverage industry-standard protocols for authentication and authorization.\n\n### 4.4. Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Use Key Management:** Use a secure key management system to store and manage encryption keys.\n*   **Protect Connection Strings:** Protect connection strings and other sensitive configuration data.\n*   **Implement Auditing:** Implement auditing to track user actions and detect security breaches.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and server.\n*   **Implement API Authentication:** Use API keys, JWTs, or other authentication mechanisms to secure API endpoints.\n*   **Rate Limiting:** Implement rate limiting to prevent API abuse.\n*   **Input Validation:** Validate all API input to prevent injection attacks.\n*   **Output Encoding:** Encode API output to prevent XSS attacks.\n\n## 5. Testing Approaches\n\nTesting is a critical part of the software development process and helps ensure the quality and reliability of C# applications.\n\n### 5.1. Unit Testing\n\n*   **Test Individual Units of Code:** Unit tests should focus on testing individual classes, methods, or functions in isolation.\n*   **Use Mocking Frameworks:** Use mocking frameworks like Moq or NSubstitute to isolate units of code and simulate dependencies.\n*   **Follow the Arrange-Act-Assert Pattern:** Arrange the test data, act on the code under test, and assert the expected results.\n*   **Write Clear and Concise Tests:** Write tests that are easy to read and understand.\n*   **Test Edge Cases and Error Conditions:** Test edge cases and error conditions to ensure that the code handles them properly.\n*   **Aim for High Code Coverage:** Aim for high code coverage to ensure that most of the code is tested.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Integration tests should focus on testing the interactions between different components or modules of the application.\n*   **Use Real Dependencies or Test Doubles:** Use real dependencies or test doubles to simulate the environment in which the components will operate.\n*   **Test Data Access Logic:** Test data access logic to ensure that it interacts correctly with the database.\n*   **Test API Endpoints:** Test API endpoints to ensure that they handle requests and responses correctly.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Application Flow:** End-to-end tests should focus on testing the entire application flow from start to finish.\n*   **Use Automation Frameworks:** Use automation frameworks like Selenium or Playwright to automate end-to-end tests.\n*   **Test User Interfaces:** Test user interfaces to ensure that they are functional and user-friendly.\n*   **Test Performance and Scalability:** Test performance and scalability to ensure that the application can handle the expected load.\n\n### 5.4. Test Organization\n\n*   **Create Separate Test Projects:** Create separate test projects for unit tests, integration tests, and end-to-end tests.\n*   **Organize Tests by Feature or Module:** Organize tests by feature or module to improve maintainability.\n*   **Use Descriptive Test Names:** Use descriptive test names that clearly indicate what the test is verifying.\n*   **Use Test Categories:** Use test categories to group related tests together.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mocking Frameworks:** Use mocking frameworks like Moq or NSubstitute to create mock objects and stub dependencies.\n*   **Create Mock Objects for Dependencies:** Create mock objects for dependencies that are difficult or time-consuming to set up.\n*   **Stub Method Calls:** Stub method calls to return specific values or throw exceptions.\n*   **Verify Method Calls:** Verify that methods are called with the expected arguments.\n\n## 6. Common Pitfalls and Gotchas\n\nBeing aware of common pitfalls and gotchas can help developers avoid mistakes and write more robust C# code.\n\n### 6.1. Frequent Mistakes\n\n*   **NullReferenceException:** Not handling null values properly.\n*   **Incorrect Use of Asynchronous Programming:** Blocking the main thread with synchronous operations.\n*   **Memory Leaks:** Not disposing of resources properly.\n*   **Concurrency Issues:** Race conditions, deadlocks, and other concurrency issues.\n*   **Unhandled Exceptions:** Not catching or logging exceptions properly.\n*   **SQL Injection:** Not parameterizing database queries.\n*   **XSS Attacks:** Not encoding user input properly.\n*   **CSRF Attacks:** Not using anti-forgery tokens.\n*   **Ignoring Code Analysis Warnings:** Ignoring warnings from the compiler or code analysis tools.\n\n### 6.2. Edge Cases\n\n*   **Empty Collections:** Handling empty collections properly.\n*   **Zero Values:** Handling zero values properly.\n*   **Maximum and Minimum Values:** Handling maximum and minimum values properly.\n*   **Date and Time Zones:** Handling date and time zones correctly.\n*   **Unicode Characters:** Handling Unicode characters correctly.\n\n### 6.3. Version-Specific Issues\n\n*   **C# Language Features:** Being aware of new language features and how they affect existing code.\n*   **.NET Framework vs. .NET Core vs. .NET:** Understanding the differences between the different .NET platforms.\n*   **Breaking Changes:** Being aware of breaking changes in new versions of the .NET framework.\n\n### 6.4. Compatibility Concerns\n\n*   **Cross-Platform Compatibility:** Ensuring that the code works correctly on different operating systems.\n*   **Backward Compatibility:** Ensuring that the code is compatible with older versions of the .NET framework.\n*   **Interoperability with Other Languages:** Ensuring that the code can interoperate with other languages like C++ or Java.\n\n### 6.5. Debugging Strategies\n\n*   **Use the Visual Studio Debugger:** Use the Visual Studio debugger to step through code, inspect variables, and set breakpoints.\n*   **Use Logging:** Use logging to track the execution flow of the code and log important information.\n*   **Use Unit Tests:** Use unit tests to isolate and debug individual units of code.\n*   **Use Code Analysis Tools:** Use code analysis tools to identify potential problems in the code.\n*   **Use Profiling Tools:** Use profiling tools to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\nChoosing the right tools and configuring the development environment properly can significantly improve productivity and code quality.\n\n### 7.1. Recommended Development Tools\n\n*   **Visual Studio:** The primary IDE for C# development.\n*   **Visual Studio Code:** A lightweight code editor with C# support.\n*   **JetBrains Rider:** A cross-platform .NET IDE.\n*   **NuGet Package Manager:** For managing dependencies.\n*   **Git:** For version control.\n*   **Resharper:** Powerful Visual Studio extension for code analysis, refactoring, and navigation.\n\n### 7.2. Build Configuration\n\n*   **Use MSBuild or dotnet CLI:** Use MSBuild or the dotnet CLI to build the project.\n*   **Configure Build Configurations:** Configure different build configurations for debug and release builds.\n*   **Use NuGet Package Restore:** Use NuGet package restore to automatically download dependencies during the build process.\n*   **Sign Assemblies:** Sign assemblies to prevent tampering.\n*   **Generate Documentation:** Generate documentation from XML comments.\n*   **Enable deterministic builds:** Ensure builds are reproducible by enabling deterministic builds in the project file.\n\n### 7.3. Linting and Formatting\n\n*   **Use StyleCop Analyzers:** Use StyleCop Analyzers to enforce coding style rules.\n*   **Use Roslyn Analyzers:** Use Roslyn analyzers to detect potential problems in the code.\n*   **Configure EditorConfig:** Use EditorConfig to define coding style rules for the project.\n*   **Use Code Formatters:** Use code formatters like the Visual Studio code formatter to automatically format code.\n\n### 7.4. Deployment Best Practices\n\n*   **Choose a Deployment Target:** Choose a deployment target based on the application's requirements (e.g., Azure App Service, AWS Elastic Beanstalk, Docker).\n*   **Use a Deployment Pipeline:** Use a deployment pipeline to automate the deployment process.\n*   **Configure Application Settings:** Configure application settings properly for the deployment environment.\n*   **Monitor Application Health:** Monitor application health to detect and resolve issues.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD Platform:** Use a CI/CD platform like Azure DevOps, GitHub Actions, or Jenkins to automate the build, test, and deployment process.\n*   **Configure Build Triggers:** Configure build triggers to automatically start builds when code is committed.\n*   **Run Unit Tests and Integration Tests:** Run unit tests and integration tests as part of the build process.\n*   **Deploy to Different Environments:** Deploy the application to different environments (e.g., development, staging, production) as part of the deployment pipeline.\n*   **Automated Code Reviews:** Integrate with code review tools to automate aspects of code review.\n\nBy following these best practices and coding standards, developers can write C# code that is maintainable, performant, secure, and reliable.",
    "metadata": {
      "globs": "*.cs",
      "format": "mdc",
      "originalFile": "c-sharp.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "c",
      "sharp",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "coding",
      "standards",
      "c-sharp",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "c-sharp",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-chakra-ui",
    "description": "This rule enforces best practices and coding standards for Chakra UI projects, including accessibility, styling, performance, and security. It aims to provide clear, actionable guidance for developers using Chakra UI.",
    "author": "sanjeed5",
    "tags": [
      "chakra-ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/chakra-ui.mdc",
    "content": "-   **Accessibility**: Ensure all components follow WAI-ARIA standards, including keyboard navigation and screen reader support.\n\n    -   Use semantic HTML elements where appropriate (e.g., `<button>`, `<input>`, `<nav>`).\n    -   Provide alternative text for images using the `alt` prop on the `<Image>` component.\n    -   Ensure sufficient color contrast between text and background colors. Use a tool like [WebAIM's Color Contrast Checker](https://webaim.org/resources/contrastchecker/) to verify.\n    -   Use the `aria-label`, `aria-labelledby`, and `aria-describedby` props to provide descriptive information to assistive technologies.\n    -   Test your components with a screen reader (e.g., NVDA, VoiceOver) to ensure they are accessible.\n-   **Prop-Based Styling**: Use style props instead of CSS classes for faster and more intuitive styling.\n\n    -   Leverage Chakra UI's extensive set of style props for common CSS properties (e.g., `m`, `p`, `bg`, `color`, `fontSize`, `fontWeight`).\n    -   Use the `sx` prop for more advanced styling that goes beyond the available style props.  However, prefer style props where applicable for consistency.\n    -   Apply responsive styles using array or object syntax for different breakpoints.\n-   **Centralized Theming**: Manage colors, sizes, and styles in one place for consistency across the application.\n\n    -   Extend the default Chakra UI theme using the `extendTheme` function to customize colors, fonts, sizes, and component styles.\n    -   Use semantic tokens for theme values (e.g., `colors.brand.primary`, `sizes.spacing.md`) instead of hardcoding values directly in your components.\n    -   Use the `useTheme` hook to access theme values within your components.\n    -   Organize your theme file to ensure easy modifications and readability\n-   **Modular Components**: Build complex UIs by combining small, reusable components like `Box`, `Flex`, and `Stack`.\n\n    -   Follow atomic design principles to structure your components into atoms, molecules, and organisms.\n    -   Create custom components that encapsulate specific UI patterns and logic.\n    -   Use composition to build more complex components from simpler ones.\n    -  Use the `forwardRef` API when building components that need to directly access a DOM node.\n-   **Responsive Design**: Use array syntax for responsive styles and leverage hooks like `useBreakpointValue` for adaptive layouts.\n\n    -   Use the array syntax to define different values for different breakpoints (e.g., `fontSize={['sm', 'md', 'lg']}`).\n    -   Use the object syntax for more explicit breakpoint control (e.g., `templateColumns={{ base: '1fr', md: 'repeat(2, 1fr)' }}`).\n    -   Use the `useBreakpointValue` hook to dynamically adjust layouts based on the current breakpoint.\n    -   Utilize `useMediaQuery` hook for conditional rendering of components or sections.\n-   **Simplicity and Composition**: Keep component APIs simple and break them down into smaller parts to maintain flexibility.\n\n    -   Design components with a minimal set of props to keep their APIs clean and easy to use.\n    -   Use composition to allow consumers to customize the appearance and behavior of your components.\n    -   Avoid creating monolithic components with too many responsibilities.\n-   **Custom Theme Creation**: Extend the default theme to match design requirements and ensure consistent styling.\n\n    -   Use `extendTheme` to customize the default Chakra UI theme and create consistent styling.\n    -   Define custom color palettes, typography, spacing, and breakpoints.\n    -   Override component styles to match your design system.\n-   **Testing and Documentation**: Document components and their usage, and ensure thorough testing for accessibility and functionality.\n\n    -   Write unit tests for your components using Jest and React Testing Library.\n    -   Test for accessibility using `axe-core` and `jest-axe`.\n    -   Document your components with clear and concise JSDoc comments.\n    -   Use a tool like Storybook to create a living style guide for your components.\n    -   Use Typescript to ensure you have strongly typed components.\n\n-   **Code Organization and Structure:**\n    -   **Directory Structure Best Practices:**\n        -   Structure your project based on features or components.\n        -   Common structure: `src/components`, `src/pages`, `src/utils`, `src/theme`, `src/hooks`.\n        -   Place related components, hooks, and styles in the same directory.\n    -   **File Naming Conventions:**\n        -   Use PascalCase for component file names (e.g., `Button.tsx`).\n        -   Use camelCase for hook file names (e.g., `useDisclosure.ts`).\n        -   Use descriptive names for utility functions (e.g., `formatDate.ts`).\n    -   **Module Organization:**\n        -   Group related components and functions into modules.\n        -   Use `index.ts` files to re-export members from a module.\n        -   Avoid circular dependencies between modules.\n    -   **Component Architecture:**\n        -   Use a component-based architecture with reusable components.\n        -   Separate presentational components from container components.\n        -   Prefer functional components with hooks over class components.\n    -   **Code Splitting Strategies:**\n        -   Use dynamic imports to load components and modules on demand.\n        -   Split your application into routes or feature modules.\n        -   Use React.lazy and Suspense for code splitting at the component level.\n\n-   **Common Patterns and Anti-patterns:**\n    -   **Design Patterns Specific to Chakra UI:**\n        -   **Compound Components:** Create components like `Tabs` and `Accordion` where child components share state and logic.\n        -   **Control Props:**  Use props like `value` and `onChange` for controlled components, enabling external state management.\n        -   **Render Props:**  Provide a render prop to allow consumers to customize the rendering of a component.\n    -   **Recommended Approaches for Common Tasks:**\n        -   Use Chakra UI's layout components (`Box`, `Flex`, `Grid`, `Stack`) for structuring your UI.\n        -   Use the `useDisclosure` hook for managing the state of modals, drawers, and other toggleable components.\n        -   Use the `useColorMode` hook for implementing dark mode support.\n    -   **Anti-patterns and Code Smells to Avoid:**\n        -   Avoid using inline styles directly; prefer style props or the `sx` prop.\n        -   Avoid mutating the Chakra UI theme directly; always use `extendTheme` to create a new theme.\n        -   Avoid tightly coupling components to specific data sources; make them more generic and reusable.\n    -   **State Management Best Practices:**\n        -   Use local component state for simple UI state.\n        -   Use context for sharing state between components that are not directly related.\n        -   Use a state management library like Redux or Zustand for more complex application state.\n    -   **Error Handling Patterns:**\n        -   Use try-catch blocks to handle errors gracefully.\n        -   Display user-friendly error messages to the user.\n        -   Log errors to a monitoring service for debugging.\n        -   Implement fallback components to handle unexpected errors during rendering.\n\n-   **Performance Considerations:**\n    -   **Optimization Techniques:**\n        -   Use `React.memo` to memoize functional components and prevent unnecessary re-renders.\n        -   Use `useCallback` and `useMemo` to memoize functions and values that are used as props to child components.\n        -   Avoid creating new objects or functions in render methods.\n    -   **Memory Management:**\n        -   Clean up event listeners and timers in `useEffect` hooks.\n        -   Avoid storing large amounts of data in component state.\n        -   Use weak references to prevent memory leaks.\n    -   **Rendering Optimization:**\n        -   Use virtualization libraries like `react-window` or `react-virtualized` to render large lists efficiently.\n        -   Optimize expensive calculations and data transformations.\n        -   Use the `shouldComponentUpdate` lifecycle method or `React.PureComponent` to prevent unnecessary re-renders in class components (avoid when using hooks).\n    -   **Bundle Size Optimization:**\n        -   Use tree shaking to remove unused code from your bundles.\n        -   Use code splitting to load only the code that is needed for a particular page or feature.\n        -   Use image optimization techniques to reduce the size of your images.\n    -   **Lazy Loading Strategies:**\n        -   Use `React.lazy` and `Suspense` for lazy loading components.\n        -   Use intersection observers to lazy load images and other assets that are not initially visible.\n\n-   **Security Best Practices:**\n    -   **Common Vulnerabilities and How to Prevent Them:**\n        -   **Cross-Site Scripting (XSS):** Sanitize user input to prevent the execution of malicious scripts.\n        -   **Cross-Site Request Forgery (CSRF):** Use CSRF tokens to protect against unauthorized requests.\n        -   **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n    -   **Input Validation:**\n        -   Validate all user input on both the client and server sides.\n        -   Use regular expressions or validation libraries to enforce data formats.\n        -   Escape or encode user input before displaying it in the UI.\n    -   **Authentication and Authorization Patterns:**\n        -   Use a secure authentication protocol like OAuth 2.0 or OpenID Connect.\n        -   Store passwords securely using a hashing algorithm like bcrypt.\n        -   Implement role-based access control (RBAC) to restrict access to sensitive data and functionality.\n    -   **Data Protection Strategies:**\n        -   Encrypt sensitive data at rest and in transit.\n        -   Use HTTPS to secure communication between the client and server.\n        -   Protect API keys and other secrets by storing them in environment variables.\n    -   **Secure API Communication:**\n        -   Use HTTPS for all API requests.\n        -   Validate API responses to ensure they are in the expected format.\n        -   Implement rate limiting to prevent abuse of your APIs.\n\n-   **Testing Approaches:**\n    -   **Unit Testing Strategies:**\n        -   Write unit tests for individual components and functions.\n        -   Test for different input values and edge cases.\n        -   Use mocking and stubbing to isolate components from external dependencies.\n    -   **Integration Testing:**\n        -   Write integration tests to verify the interaction between components.\n        -   Test the flow of data between components.\n        -   Test the integration with external APIs and services.\n    -   **End-to-End Testing:**\n        -   Write end-to-end tests to simulate user interactions and verify the overall functionality of the application.\n        -   Use a testing framework like Cypress or Puppeteer.\n        -   Test for accessibility and performance.\n    -   **Test Organization:**\n        -   Organize your tests into separate directories for unit tests, integration tests, and end-to-end tests.\n        -   Use descriptive names for your test files and test cases.\n        -   Follow a consistent testing style.\n    -   **Mocking and Stubbing:**\n        -   Use mocking to replace external dependencies with mock objects that simulate their behavior.\n        -   Use stubbing to replace specific methods or properties of a dependency with predefined values.\n        -   Use a mocking library like Jest's `jest.mock` or `sinon.js`.\n\n-   **Common Pitfalls and Gotchas:**\n    -   **Frequent Mistakes Developers Make:**\n        -   Not following accessibility guidelines.\n        -   Overusing inline styles.\n        -   Mutating the Chakra UI theme directly.\n        -   Not testing components thoroughly.\n        -   Not optimizing performance.\n    -   **Edge Cases to Be Aware Of:**\n        -   Handling different screen sizes and orientations.\n        -   Handling different input methods (keyboard, mouse, touch).\n        -   Handling different locales and languages.\n        -   Handling different network conditions.\n    -   **Version-Specific Issues:**\n        -   Be aware of breaking changes between Chakra UI versions.\n        -   Read the release notes carefully when upgrading.\n        -   Test your application thoroughly after upgrading.\n    -   **Compatibility Concerns:**\n        -   Ensure your application is compatible with different browsers and devices.\n        -   Use a tool like BrowserStack or Sauce Labs to test your application on different environments.\n    -   **Debugging Strategies:**\n        -   Use the browser's developer tools to inspect the DOM and debug your JavaScript code.\n        -   Use a debugger like VS Code's built-in debugger.\n        -   Use logging statements to track the flow of data and execution.\n\n-   **Tooling and Environment:**\n    -   **Recommended Development Tools:**\n        -   VS Code with the ESLint, Prettier, and TypeScript extensions.\n        -   Chrome Developer Tools or Firefox Developer Tools.\n        -   React Developer Tools browser extension.\n    -   **Build Configuration:**\n        -   Use a build tool like Webpack, Parcel, or Rollup.\n        -   Configure your build tool to optimize your bundles and perform tree shaking.\n        -   Use environment variables to configure your application for different environments.\n    -   **Linting and Formatting:**\n        -   Use ESLint with a configuration like eslint-config-react-app to enforce code style and best practices.\n        -   Use Prettier to format your code automatically.\n        -   Configure your editor to automatically lint and format your code on save.\n    -   **Deployment Best Practices:**\n        -   Use a continuous integration and continuous deployment (CI/CD) pipeline to automate your deployments.\n        -   Deploy your application to a hosting provider like Netlify, Vercel, or AWS.\n        -   Use a content delivery network (CDN) to cache your static assets.\n    -   **CI/CD Integration:**\n        -   Integrate your CI/CD pipeline with your testing and linting tools.\n        -   Automate the process of building, testing, and deploying your application.\n        -   Use a CI/CD platform like GitHub Actions, CircleCI, or Travis CI.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "chakra-ui.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "chakra",
      "ui",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "including",
      "chakra-ui",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "chakra-ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-cheerio",
    "description": "This rule provides best practices for using Cheerio for web scraping and HTML parsing in JavaScript, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "cheerio",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/cheerio.mdc",
    "content": "# Cheerio Best Practices\n\nThis document outlines the best practices for using Cheerio, a fast, flexible, and lean implementation of core jQuery designed specifically for the server.  It focuses on efficient and ethical web scraping, robust code organization, and secure data handling.\n\n## Library Information:\n- Name: cheerio\n- Tags: web-scraping, javascript, html-parsing, nodejs\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a structured directory to enhance maintainability and scalability:\n\n\nproject-root/\n├── src/\n│   ├── scrapers/\n│   │   ├── amazon_scraper.js  # Specific website scrapers\n│   │   ├── generic_scraper.js # Reusable scraping logic\n│   ├── utils/\n│   │   ├── helpers.js         # Utility functions\n│   │   ├── request.js         # HTTP request handling (Axios wrapper)\n│   ├── models/\n│   │   ├── product.js        # Data models\n│   ├── config/\n│   │   ├── config.js         # Configuration settings\n│   ├── index.js             # Main application entry point\n├── tests/\n│   ├── scrapers/\n│   │   ├── amazon_scraper.test.js\n│   ├── utils/\n│   │   ├── helpers.test.js\n├── .env                   # Environment variables\n├── package.json\n├── package-lock.json\n├── README.md\n\n\n### 1.2. File Naming Conventions\n\nUse descriptive names:\n\n-   **Scrapers:** `[website]_scraper.js` (e.g., `amazon_scraper.js`, `ebay_scraper.js`)\n-   **Utilities:** `[module_name].js` (e.g., `request.js`, `data_formatter.js`)\n-   **Tests:** `[module_name].test.js` (e.g., `amazon_scraper.test.js`)\n\n### 1.3. Module Organization\n\n-   **Encapsulation:**  Group related functionalities into modules (e.g., scraper functions, utility functions).\n-   **Separation of Concerns:** Isolate scraping logic, data processing, and storage functionalities.\n-   **Reusability:**  Design modules for reuse across different scrapers.\n\n### 1.4. Component Architecture Recommendations\n\nFor complex scraping applications, consider a component-based architecture:\n\n-   **Scraper Components:** Components that handle scraping data from specific websites. Should handle request logic and initial parsing of HTML\n-   **Parser Components:** Responsible for extracting relevant data from the scraped HTML using cheerio.\n-   **Data Model Components:** Define the structure of the data to be extracted.\n-   **Storage Components:** Save scraped data to files, databases, etc.\n\n### 1.5. Code Splitting Strategies\n\n-   **Scraper-Specific Logic:** Separate logic for each website into individual modules.\n-   **Reusable Utilities:** Move common functions into utility modules.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Strategy Pattern:** Implement different scraping strategies based on website structure or anti-scraping measures.\n-   **Factory Pattern:** Dynamically create scraper instances based on website configuration.\n-   **Observer Pattern:**  Notify subscribers when new data is scraped.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Making HTTP Requests:** Use Axios for making HTTP requests.  Handle retries and timeouts gracefully.\n-   **Loading HTML:** Load HTML into Cheerio using `cheerio.load()`. Handle loading large HTML documents efficiently.\n-   **Selecting Elements:** Use CSS selectors effectively to target desired elements.  Consider specificity and performance.\n-   **Extracting Data:** Extract data from selected elements using `.text()`, `.attr()`, `.val()`, etc.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Overly Complex Selectors:**  Avoid overly long or complex CSS selectors that can be difficult to maintain and may impact performance.  Refactor into smaller, more manageable selectors.\n-   **Ignoring Errors:** Always handle errors and exceptions gracefully.  Log errors and provide meaningful error messages.\n-   **Hardcoding Values:**  Avoid hardcoding URLs, selectors, or configuration values.  Use configuration files or environment variables.\n-   **Lack of Rate Limiting:**  Always implement rate limiting to avoid overloading target websites and getting IP-blocked.\n-   **Lack of Respect for `robots.txt`:** Always check and respect the `robots.txt` file to avoid scraping restricted content.\n-   **Not handling dynamic content**: If the site uses JavaScript to render content, Cheerio alone won't work. Integrate with Puppeteer or Playwright to render the page before parsing it.\n\n### 2.4. State Management Best Practices\n\n-   For simple scripts, use local variables to store scraped data.\n-   For complex applications, consider using state management libraries like Redux or Zustand (although these are usually overkill for typical cheerio use cases).  These are needed more for front-end state management. \n-   For managing concurrency and scheduling, use task queues (see below).\n\n### 2.5. Error Handling Patterns\n\n-   **Try-Catch Blocks:** Wrap scraping logic in `try-catch` blocks to handle exceptions.\n-   **Custom Error Classes:** Define custom error classes to represent specific scraping errors.\n-   **Logging:** Log errors and exceptions to a file or logging service.\n-   **Retry Logic:** Implement retry logic for failed HTTP requests.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Efficient Selectors:** Use the most efficient CSS selectors possible.  Avoid overly complex selectors and prioritize ID selectors or class selectors over attribute selectors.\n-   **Caching:** Cache frequently accessed data to reduce the number of HTTP requests.\n-   **Rate Limiting:** Implement rate limiting to avoid overloading target websites. Space out requests to be respectful and avoid getting blocked.\n-   **Asynchronous Operations:**  Use asynchronous operations (e.g., `async/await`) to avoid blocking the main thread.\n-   **Connection Pooling:** Reuse HTTP connections to reduce overhead.  Axios handles connection pooling automatically.\n-   **Parallel Scraping:** Use concurrent scraping (e.g. `Promise.all`) to speed up data collection. Implement carefully to avoid overwhelming the target server.\n-   **Use streams for large files:** When processing very large scraped files (e.g. JSON), use Node.js streams to avoid loading the entire file into memory at once.\n\n### 3.2. Memory Management\n\n-   **Minimize Data Retention:** Only store the data you need.  Discard unnecessary data as soon as possible.\n-   **Garbage Collection:**  Ensure that unused objects are properly garbage collected.\n-   **Avoid Memory Leaks:**  Be careful to avoid memory leaks, especially when using callbacks or closures.\n\n### 3.3. Rendering Optimization\n\n-   Cheerio doesn't render content; it parses existing HTML. If dynamic content is required, use Puppeteer or Playwright to render the page first.\n\n### 3.4. Bundle Size Optimization\n\n-   Cheerio itself is very lightweight.  However, using too many utility libraries can increase bundle size.\n-   Use tools like Webpack or Parcel to bundle your code and optimize bundle size.\n\n### 3.5. Lazy Loading\n\n-   Lazy load images or other resources that are not immediately visible.\n-   However, this is often not relevant for server-side scraping with Cheerio.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n-   **Cross-Site Scripting (XSS):** Cheerio itself does not directly introduce XSS vulnerabilities. However, if you are displaying scraped data in a web browser, be sure to sanitize the data properly to prevent XSS attacks.\n-   **Denial of Service (DoS):** Implement rate limiting and request timeouts to prevent DoS attacks on target websites.\n-   **Data Injection:** Sanitize and validate scraped data before storing it in a database to prevent data injection attacks.\n\n### 4.2. Input Validation\n\n-   Validate all input data to prevent malicious input from corrupting your application or data.\n-   Validate URLs to prevent scraping unintended websites.\n\n### 4.3. Authentication and Authorization\n\n-   For accessing password-protected websites, implement proper authentication and authorization mechanisms.\n-   Store credentials securely using environment variables or configuration files.\n-   Avoid storing credentials directly in your code.\n\n### 4.4. Data Protection\n\n-   Encrypt sensitive data at rest and in transit.\n-   Use secure protocols (e.g., HTTPS) for all network communication.\n\n### 4.5. Secure API Communication\n\n-   If your scraping application interacts with APIs, use secure API keys and tokens.\n-   Implement proper authentication and authorization mechanisms for API access.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   Unit test individual functions and components.\n-   Use mocking and stubbing to isolate units of code.\n-   Test edge cases and error conditions.\n\n### 5.2. Integration Testing\n\n-   Integrate test different components of your application to ensure that they work together correctly.\n-   Test the interaction between scrapers, parsers, and data storage components.\n\n### 5.3. End-to-End Testing\n\n-   End-to-end test the entire scraping process from start to finish.\n-   Simulate real-world scenarios to ensure that your application works as expected.\n\n### 5.4. Test Organization\n\n-   Organize your tests in a clear and consistent manner.\n-   Use descriptive test names.\n-   Keep your tests small and focused.\n\n### 5.5. Mocking and Stubbing\n\n-   Use mocking and stubbing to isolate units of code during testing.\n-   Mock HTTP requests to avoid making real requests to target websites during testing.\n-   Tools: Jest, Mocha, Sinon.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Ignoring `robots.txt`:** Always respect the `robots.txt` file.\n-   **Not Handling Dynamic Content:** Cheerio cannot render JavaScript. Use Puppeteer or Playwright for dynamic content.\n-   **Overloading Target Websites:** Implement rate limiting to avoid overloading target websites.\n-   **Not Handling Errors:** Always handle errors and exceptions gracefully.\n-   **Using Incorrect Selectors:** Ensure that your CSS selectors are correct and target the desired elements.\n-   **Not Validating Data:** Validate scraped data to prevent data corruption.\n\n### 6.2. Edge Cases\n\n-   Websites with infinite scroll: These sites load content dynamically as you scroll. Use Puppeteer or Playwright to simulate scrolling and load all the content before parsing.\n-   Websites that require JavaScript to function: As stated before, use a headless browser like Puppeteer or Playwright.\n-   Websites with anti-scraping techniques: Websites may use techniques like IP blocking, CAPTCHAs, or dynamic content to prevent scraping. You'll need to implement strategies to avoid these, such as using proxies, solving CAPTCHAs, or rendering JavaScript.\n-   Websites that change their structure frequently: Websites may change their HTML structure, which can break your scraper. You'll need to monitor your scraper and update it as needed.\n\n### 6.3. Version-Specific Issues\n\n-   Be aware of version-specific issues and breaking changes in Cheerio.\n-   Check the Cheerio documentation and release notes for information on known issues.\n\n### 6.4. Compatibility Concerns\n\n-   Ensure that Cheerio is compatible with your version of Node.js.\n-   Be aware of potential compatibility issues with other libraries.\n\n### 6.5. Debugging Strategies\n\n-   Use `console.log()` to print out the values of variables and expressions.\n-   Use a debugger to step through your code and inspect the state of your application.\n-   Use try-catch blocks to catch exceptions and log error messages.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **IDE:** Visual Studio Code, WebStorm\n-   **HTTP Client:** Postman, Insomnia\n-   **Debugging Tools:** Node.js Inspector, Chrome DevTools\n\n### 7.2. Build Configuration\n\n-   Use a build tool like Webpack or Parcel to bundle your code and optimize bundle size.\n-   Configure your build tool to handle different environments (e.g., development, production).\n\n### 7.3. Linting and Formatting\n\n-   Use a linter like ESLint to enforce code style and prevent errors.\n-   Use a formatter like Prettier to automatically format your code.\n-   Configure your linter and formatter to work with Cheerio code.\n\n### 7.4. Deployment Best Practices\n\n-   Deploy your scraping application to a reliable hosting provider.\n-   Use a process manager like PM2 to ensure that your application is always running.\n-   Monitor your application for errors and performance issues.\n\n### 7.5. CI/CD Integration\n\n-   Use a CI/CD tool like Jenkins, Travis CI, or CircleCI to automate the build, test, and deployment process.\n-   Configure your CI/CD pipeline to run your unit tests, integration tests, and end-to-end tests.\n\n\nBy following these best practices, you can build robust, efficient, and secure web scraping applications using Cheerio.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "cheerio.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "cheerio",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "using",
      "scraping",
      "html",
      "parsing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "cheerio",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-circleci",
    "description": "This rule provides comprehensive best practices for configuring and optimizing CircleCI workflows, covering code organization, security, performance, and testing to ensure efficient and reliable CI/CD pipelines.",
    "author": "sanjeed5",
    "tags": [
      "circleci",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/circleci.mdc",
    "content": "# CircleCI Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive guide to CircleCI best practices, covering various aspects of workflow configuration, optimization, security, and testing.\n\n## 1. Code Organization and Structure\n\nWhile CircleCI primarily focuses on workflow orchestration rather than code structure, adhering to a well-organized project structure significantly benefits CI/CD pipeline maintainability and efficiency.  Here are some key recommendations:\n\n### 1.1 Directory Structure\n\n*   **Root Level:**\n    *   `.circleci/`: Contains the `config.yml` file defining the CircleCI workflow.\n    *   `scripts/`: (Optional) Houses custom scripts used within the CI/CD pipeline (e.g., deployment scripts, database setup).\n    *   `docker/`: (Optional) Contains Dockerfiles and related files for containerizing applications.\n    *   `README.md`:  Project documentation.\n    *   `LICENSE`: Project license.\n    *   `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n*   **Application Code:** Follow a consistent structure based on the project's technology stack (e.g., `src/`, `app/`, `lib/`).\n\n### 1.2 File Naming Conventions\n\n*   `config.yml`:  The primary CircleCI configuration file.  Use descriptive comments within this file.\n*   Shell Scripts:  Use `.sh` extension for shell scripts in the `scripts/` directory (e.g., `deploy.sh`, `setup_database.sh`).\n*   Dockerfiles: Use `Dockerfile` (without extension) or a descriptive name like `Dockerfile.dev` or `Dockerfile.prod`.\n\n### 1.3 Module Organization\n\n*   For larger projects, break down complex workflows into reusable modules or Orbs.  Orbs allow you to encapsulate and share common configuration snippets across multiple projects.\n*   Utilize private Orbs within your organization to share proprietary configurations securely.\n\n### 1.4 Component Architecture\n\n*   Consider a modular design for your application, making it easier to test and deploy individual components.  This approach aligns well with microservices architectures.\n*   Use environment variables to configure different components based on the deployment environment (e.g., development, staging, production).\n\n### 1.5 Code Splitting\n\n*   For large applications, consider splitting your code into smaller modules or packages to reduce build times and improve parallelism in your CI/CD pipeline.\n*   Use caching strategies to avoid rebuilding unchanged modules.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Configuration as Code (CaC):**  Manage CircleCI configurations (and application configurations) as code, stored in version control. This ensures traceability, auditability, and reproducibility.\n*   **Infrastructure as Code (IaC):** Use tools like Terraform or CloudFormation to provision and manage infrastructure in a consistent and automated way.\n*   **GitOps:** Use Git as the single source of truth for infrastructure and application configurations. Changes are applied through pull requests, ensuring a controlled and auditable process.\n\n### 2.2 Recommended Approaches\n\n*   **Automated Testing:** Integrate comprehensive automated testing into your pipeline, including unit tests, integration tests, and end-to-end tests.  Fail the build if any tests fail.\n*   **Parallel Execution:** Leverage CircleCI's parallelism feature to run tests and other tasks concurrently, significantly reducing pipeline execution time.\n*   **Caching:** Use caching to store dependencies and build artifacts between jobs, avoiding redundant downloads and builds.\n*   **Orbs:** Utilize community or custom Orbs to simplify common tasks and promote code reuse.\n\n### 2.3 Anti-patterns\n\n*   **Hardcoding Secrets:** Never hardcode sensitive information (API keys, passwords) directly in the `config.yml` file.  Use environment variables or a secrets management tool.\n*   **Ignoring Test Failures:** Do not proceed with deployment if tests fail. Fix the underlying issues first.\n*   **Large, Monolithic Configurations:** Avoid creating a single, massive `config.yml` file. Break down the workflow into smaller, reusable jobs and Orbs.\n*   **Lack of Caching:**  Failing to utilize caching can significantly increase build times.\n*   **Manual Deployments:**  Avoid manual deployments. Automate the entire deployment process.\n\n### 2.4 State Management\n\n*   CircleCI itself is stateless.  For stateful applications, manage state using external databases, caches (e.g., Redis, Memcached), or cloud storage services (e.g., AWS S3, Azure Blob Storage).\n*   Use environment variables to configure the connection to stateful services based on the environment.\n\n### 2.5 Error Handling\n\n*   Implement robust error handling in your scripts and application code.\n*   Use CircleCI's notification features to alert developers when builds fail or errors occur.\n*   Log detailed error messages to aid in debugging.\n*   Consider using tools like Sentry or Rollbar for centralized error tracking.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Parallelism:**  As mentioned earlier, parallelize jobs to reduce overall pipeline execution time.\n*   **Caching:**  Cache dependencies, build artifacts, and Docker layers.\n*   **Resource Classes:** Use appropriate resource classes for your jobs.  Larger resource classes provide more CPU and memory, but also consume more credits.\n*   **Docker Layer Caching:**  Optimize Dockerfiles to leverage layer caching effectively.  Arrange commands from least to most frequently changed to maximize cache hits.\n*   **Optimize Docker Image Size:**  Reduce the size of Docker images by using multi-stage builds and removing unnecessary dependencies.\n\n### 3.2 Memory Management\n\n*   Monitor memory usage during builds, especially when running resource-intensive tasks (e.g., large test suites).\n*   Adjust resource classes if jobs are running out of memory.\n*   Optimize your application code to reduce memory consumption.\n\n### 3.3 Bundle Size Optimization (If Applicable)\n\n*   For web applications, optimize JavaScript bundle sizes using techniques like code splitting, tree shaking, and minification.\n*   Use tools like Webpack Bundle Analyzer to identify large dependencies.\n\n### 3.4 Lazy Loading (If Applicable)\n\n*   For web applications, implement lazy loading to load resources only when they are needed.\n*   Use dynamic imports in JavaScript to load modules on demand.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Exposed Secrets:**  Storing sensitive information in the codebase or configuration files.\n*   **Insecure Dependencies:**  Using outdated or vulnerable dependencies.\n*   **Lack of Access Control:**  Granting excessive permissions to users or services.\n*   **Man-in-the-Middle Attacks:**  Failing to use HTTPS for secure communication.\n\n### 4.2 Input Validation\n\n*   Validate all input data in your application to prevent injection attacks.\n*   Use parameterized queries to prevent SQL injection.\n*   Escape user-provided data when rendering HTML to prevent cross-site scripting (XSS) attacks.\n\n### 4.3 Authentication and Authorization\n\n*   Use strong authentication mechanisms to protect your application.\n*   Implement role-based access control (RBAC) to restrict access to sensitive resources.\n*   Use secure tokens (e.g., JWT) for authentication and authorization.\n\n### 4.4 Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use HTTPS for all API communication.\n*   Regularly back up your data.\n\n### 4.5 Secure API Communication\n\n*   Use API keys or tokens to authenticate API requests.\n*   Implement rate limiting to prevent abuse.\n*   Use HTTPS for all API communication.\n*   Validate API requests and responses.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   Write unit tests for all critical components of your application.\n*   Use a mocking framework to isolate components during unit testing.\n*   Aim for high test coverage (ideally > 80%).\n\n### 5.2 Integration Testing\n\n*   Write integration tests to verify that different components of your application work together correctly.\n*   Test the interaction between your application and external services (e.g., databases, APIs).\n\n### 5.3 End-to-End Testing\n\n*   Write end-to-end tests to simulate user interactions and verify that the entire application works as expected.\n*   Use a browser automation tool like Selenium or Cypress for end-to-end testing.\n\n### 5.4 Test Organization\n\n*   Organize your tests in a logical directory structure (e.g., `tests/unit/`, `tests/integration/`, `tests/e2e/`).\n*   Use descriptive names for your test files and test cases.\n\n### 5.5 Mocking and Stubbing\n\n*   Use mocking to replace external dependencies with controlled test doubles.\n*   Use stubbing to provide pre-defined responses for specific function calls or API requests.\n*   Choose a mocking framework that is appropriate for your programming language and testing framework.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect YAML Syntax:**  YAML is sensitive to indentation.  Use a YAML linter to validate your `config.yml` file.\n*   **Misconfigured Caching:**  Using incorrect cache keys or not invalidating caches when dependencies change.\n*   **Not Using Environment Variables:**  Hardcoding secrets or configuration values instead of using environment variables.\n*   **Ignoring Resource Limits:**  Exceeding resource limits (CPU, memory, disk space) can lead to job failures.\n\n### 6.2 Edge Cases\n\n*   **Network Connectivity Issues:**  Handle transient network connectivity issues gracefully in your scripts.\n*   **API Rate Limiting:**  Implement retry logic with exponential backoff to handle API rate limiting.\n*   **Concurrency Issues:**  Be aware of potential concurrency issues when running parallel jobs.\n\n### 6.3 Version-Specific Issues\n\n*   Be aware of breaking changes between CircleCI versions.  Refer to the CircleCI documentation for upgrade instructions.\n\n### 6.4 Compatibility Concerns\n\n*   Ensure that your CircleCI configuration is compatible with the versions of the tools and libraries you are using.\n\n### 6.5 Debugging Strategies\n\n*   Use CircleCI's debugging features to inspect the state of your jobs.\n*   Add logging statements to your scripts to track the execution flow and identify errors.\n*   Use a remote debugger to step through your code interactively.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Visual Studio Code, IntelliJ IDEA, or other IDEs with YAML support.\n*   **YAML Linter:** Use a YAML linter to validate your `config.yml` file.\n*   **Docker:** Docker for local container development and testing.\n*   **CircleCI CLI:** CircleCI command-line interface for interacting with the CircleCI API.\n\n### 7.2 Build Configuration\n\n*   Use a consistent build process across all environments.\n*   Automate build tasks using build tools like Make, Gradle, or npm.\n*   Configure your build environment using environment variables.\n\n### 7.3 Linting and Formatting\n\n*   Use a linter to enforce code style and identify potential errors.\n*   Use a code formatter to automatically format your code.\n*   Integrate linting and formatting into your CI/CD pipeline.\n\n### 7.4 Deployment\n\n*   Automate the deployment process using deployment tools like Ansible, Chef, or Puppet.\n*   Use a blue-green deployment strategy to minimize downtime during deployments.\n*   Monitor your application after deployment to ensure that it is functioning correctly.\n\n### 7.5 CI/CD Integration\n\n*   Integrate CircleCI with your version control system (e.g., GitHub, Bitbucket).\n*   Configure CircleCI to trigger builds automatically when code is pushed to the repository.\n*   Use CircleCI's notification features to alert developers when builds succeed or fail.\n\nBy following these best practices, you can ensure that your CircleCI workflows are efficient, reliable, and secure. This guide provides a strong foundation for building robust CI/CD pipelines and optimizing your software development process.",
    "metadata": {
      "globs": ".circleci/config.yml",
      "format": "mdc",
      "originalFile": "circleci.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "circleci",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "configuring",
      "optimizing",
      "workflows",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "circleci",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-clerk",
    "description": "This rule file outlines comprehensive best practices for developing applications using the Clerk library, focusing on security, performance, code organization, and testing to ensure robust and maintainable authentication implementations.",
    "author": "sanjeed5",
    "tags": [
      "clerk",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/clerk.mdc",
    "content": "---\n## Clerk Library Best Practices\n\nThis document provides comprehensive guidelines for developing applications using the Clerk library. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling, aiming to help developers build robust, secure, and maintainable applications.\n\n### 1. Code Organization and Structure\n\n*   **Directory Structure:**\n    *   `src/`: Contains the main source code of your application.\n    *   `src/components/`: Reusable UI components. Further categorize components based on their functionality (e.g., `src/components/auth/`, `src/components/profile/`).\n    *   `src/pages/`: (If using a framework like Next.js or Remix) Defines the application's routes.\n    *   `src/lib/clerk/`: Clerk-specific utilities and customizations.  This isolates Clerk configuration and extension logic.\n    *   `src/lib/clerk/hooks.ts`: Custom hooks related to Clerk for reusability.\n    *   `src/lib/clerk/utils.ts`: Utility functions for common Clerk tasks (e.g., formatting user data).\n    *   `src/middleware.ts` (or similar):  Middleware for authentication checks and redirects.\n    *   `tests/`: Unit, integration, and end-to-end tests.\n    *   `config/`: Configuration files (e.g., Clerk API keys, environment variables).\n\n*   **File Naming Conventions:**\n    *   Components: Use PascalCase (e.g., `UserProfile.jsx`, `SignInForm.tsx`).\n    *   Utilities: Use camelCase (e.g., `formatUserData.js`, `clerkApi.ts`).\n    *   Pages/Routes: Follow the framework's conventions (e.g., `index.js` for the homepage).\n    *   Configuration files: `clerk.config.js`, `environment.config.ts`\n\n*   **Module Organization:**\n    *   Group related functionality into modules. For example, all Clerk-related functions and components could be placed within a `src/lib/clerk/` module.\n    *   Use clear and descriptive names for modules and files.\n    *   Favor small, focused modules over large, monolithic ones.\n\n*   **Component Architecture:**\n    *   **Presentational Components:** Focus on UI rendering and receive data and callbacks as props.\n    *   **Container Components:** Handle data fetching, state management, and pass data to presentational components.\n    *   Use Higher-Order Components (HOCs) or render props for cross-cutting concerns like authentication checks.\n    *   Utilize custom hooks to abstract Clerk logic and enhance reusability.\n\n*   **Code Splitting:**\n    *   **Route-Based Splitting:**  Leverage dynamic imports or framework features to split the application bundle based on routes.  This ensures users only download the code necessary for the initial page load.\n    *   **Component-Based Splitting:** Use `React.lazy` or similar techniques to lazy-load components that are not immediately visible or essential.\n    *   Consider using tools like Webpack Bundle Analyzer to identify large dependencies and optimize bundle size.\n\n### 2. Common Patterns and Anti-patterns\n\n*   **Design Patterns:**\n    *   **Provider Pattern:** Use the Clerk provider to wrap your application and make Clerk's functionality accessible to all components.\n    *   **Hook Pattern:** Create custom hooks to abstract Clerk logic (e.g., a `useUser` hook to fetch user data).\n    *   **Strategy Pattern:** Implement different authentication strategies (e.g., email/password, social login) using a common interface.\n\n*   **Recommended Approaches:**\n    *   Use Clerk's pre-built UI components for common authentication flows (sign-in, sign-up, user profile) to save development time and ensure a consistent user experience.\n    *   Leverage Clerk's middleware for authentication checks on protected routes.\n    *   Use environment variables to store Clerk API keys and other sensitive configuration data.\n    *   Implement role-based access control (RBAC) to manage user permissions.\n\n*   **Anti-patterns:**\n    *   **Directly Manipulating Clerk's State:** Avoid modifying Clerk's internal state directly.  Use the provided API methods and hooks.\n    *   **Storing Sensitive Data in the Client:** Never store Clerk API keys or user credentials in the client-side code.\n    *   **Ignoring Error Handling:** Always handle errors that may occur during authentication flows.\n    *   **Over-Customizing UI Components:** While customization is possible, avoid making excessive changes to Clerk's UI components, as this can lead to maintenance issues and compatibility problems during upgrades.\n    *   **Performing complex operations in middleware:** Keep middleware logic lean and focused on authentication checks and redirects to avoid performance bottlenecks.\n\n*   **State Management:**\n    *   For simple applications, Clerk's built-in state management may suffice.  Avoid mixing it with external state if possible. It can lead to unpredictable behavior.\n    *   For complex applications, consider using a state management library like Redux, Zustand or React Context in conjunction with Clerk, making sure to keep the Clerk state separate, and sync the user object to your state manager after Clerk authenticates the user.\n    *   Use appropriate selectors to access user data from the state.\n\n*   **Error Handling:**\n    *   Use `try...catch` blocks to handle errors that may occur during authentication flows.\n    *   Display user-friendly error messages to the user.\n    *   Log errors to a server-side logging service for debugging and monitoring.\n    *   Implement retry mechanisms for transient errors.\n    *   Centralize error handling logic in a dedicated module for consistency.\n\n### 3. Performance Considerations\n\n*   **Optimization Techniques:**\n    *   **Caching:** Cache user data and API responses to reduce the number of requests to Clerk's servers.\n    *   **Code Splitting:** Implement code splitting to reduce the initial bundle size.\n    *   **Lazy Loading:** Lazy-load components and resources that are not immediately needed.\n    *   **Prefetching:** Prefetch data for routes that the user is likely to visit next.\n\n*   **Memory Management:**\n    *   Avoid creating unnecessary objects or data structures.\n    *   Release resources when they are no longer needed.\n    *   Use memory profiling tools to identify and fix memory leaks.\n    *   Be mindful of the size of user objects stored in the state. Avoid storing unnecessary data.\n\n*   **Rendering Optimization:** (If applicable, depends on the UI framework used with Clerk)\n    *   Use memoization techniques to prevent unnecessary re-renders.\n    *   Optimize rendering performance with tools like React Profiler.\n    *   Use virtualization for large lists of data.\n\n*   **Bundle Size Optimization:**\n    *   Use a bundler like Webpack or Parcel to optimize the bundle size.\n    *   Remove unused code and dependencies.\n    *   Use tree shaking to remove dead code.\n    *   Minimize the use of large libraries, use alternative smaller ones.\n\n*   **Lazy Loading:**\n    *   Lazy-load components using `React.lazy` or dynamic imports.\n    *   Lazy-load images and other assets using a library like `react-lazyload`.\n\n### 4. Security Best Practices\n\n*   **Common Vulnerabilities:**\n    *   **Cross-Site Scripting (XSS):** Prevent XSS by sanitizing user input and using a Content Security Policy (CSP).\n    *   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection using tokens.\n    *   **Authentication and Authorization Flaws:** Ensure that authentication and authorization are implemented correctly.\n    *   **Sensitive Data Exposure:** Protect sensitive data by encrypting it and storing it securely.\n\n*   **Input Validation:**\n    *   Validate all user input on both the client and server sides.\n    *   Use a library like `joi` or `yup` to define and enforce validation schemas.\n    *   Escape user input before rendering it to prevent XSS attacks.\n\n*   **Authentication and Authorization:**\n    *   Use Clerk's built-in authentication and authorization features.\n    *   Implement role-based access control (RBAC) to manage user permissions.\n    *   Use multi-factor authentication (MFA) to enhance security.\n    *   Enforce strong password policies.\n\n*   **Data Protection:**\n    *   Encrypt sensitive data at rest and in transit.\n    *   Use HTTPS to secure communication between the client and server.\n    *   Store API keys and other sensitive data in environment variables.\n    *   Regularly audit your application for security vulnerabilities.\n\n*   **Secure API Communication:**\n    *   Use HTTPS for all API requests.\n    *   Validate API responses to prevent data injection attacks.\n    *   Implement rate limiting to prevent denial-of-service attacks.\n    *   Use a secure API gateway to manage API access and security.\n\n### 5. Testing Approaches\n\n*   **Unit Testing:**\n    *   Write unit tests for individual components and functions.\n    *   Use a testing framework like Jest or Mocha.\n    *   Mock dependencies to isolate units under test.\n    *   Focus on testing the logic within components, not the rendering details (if applicable).\n    *   Test edge cases and error conditions.\n\n*   **Integration Testing:**\n    *   Write integration tests to verify the interaction between different components and modules.\n    *   Test the integration between Clerk and your application's backend.\n    *   Use a testing library like React Testing Library to test component interactions.\n\n*   **End-to-End Testing:**\n    *   Write end-to-end tests to verify the entire application flow.\n    *   Use a testing framework like Cypress or Puppeteer.\n    *   Test common user scenarios, such as signing up, signing in, and accessing protected resources.\n    *   Run end-to-end tests in a CI/CD pipeline.\n\n*   **Test Organization:**\n    *   Organize tests into separate directories based on the type of test (unit, integration, end-to-end).\n    *   Use clear and descriptive names for test files and test cases.\n    *   Follow a consistent testing style.\n    *   Run tests automatically on every commit.\n\n*   **Mocking and Stubbing:**\n    *   Use mocking libraries like Jest's `jest.mock` to mock Clerk's API and dependencies during testing.\n    *   Create stubbed Clerk responses to simulate different scenarios.\n    *   Avoid mocking implementation details. Mock the API calls and return known responses.\n\n### 6. Common Pitfalls and Gotchas\n\n*   **Frequent Mistakes:**\n    *   **Misconfiguring Clerk's API Keys:** Ensure that Clerk's API keys are configured correctly in your environment.\n    *   **Incorrectly Implementing Authentication Checks:** Double-check that authentication checks are implemented correctly on protected routes.\n    *   **Failing to Handle Errors:** Always handle errors that may occur during authentication flows.\n    *   **Not Using Environment Variables:** Avoid hardcoding sensitive data in the code. Use environment variables instead.\n    *   **Mixing server-side and client-side rendering approaches:** Understand which components are rendered where, and the impact on auth state.\n\n*   **Edge Cases:**\n    *   **Handling Expired Sessions:** Implement a mechanism to handle expired sessions gracefully.\n    *   **Dealing with Network Errors:** Handle network errors that may occur during API requests.\n    *   **Supporting Different Browsers:** Test your application in different browsers to ensure compatibility.\n    *   **Handling User Deletion:** Handle user deletion and associated data appropriately.\n    *   **Implementing account recovery flows**: Consider how users will reset passwords or regain access to accounts\n\n*   **Version-Specific Issues:**\n    *   Check the Clerk's changelog for breaking changes and migration guides when upgrading to a new version.\n    *   Be aware of deprecated features and plan for their removal.\n    *   Consult Clerk's documentation for version-specific instructions.\n\n*   **Compatibility Concerns:**\n    *   Ensure that Clerk is compatible with the other technologies used in your application (e.g., React, Next.js, Node.js).\n    *   Check for compatibility issues when upgrading dependencies.\n\n*   **Debugging Strategies:**\n    *   Use browser developer tools to inspect network requests and console logs.\n    *   Use a debugger to step through the code and identify issues.\n    *   Check Clerk's server logs for error messages.\n    *   Enable verbose logging in Clerk's configuration to get more detailed information.\n    *   Use remote debugging tools when debugging on mobile devices.\n\n### 7. Tooling and Environment\n\n*   **Recommended Development Tools:**\n    *   **IDE:** VS Code, WebStorm\n    *   **Bundler:** Webpack, Parcel\n    *   **Testing Framework:** Jest, Mocha\n    *   **Linting:** ESLint\n    *   **Formatting:** Prettier\n    *   **Version Control:** Git\n    *   **Package Manager:** npm, yarn, pnpm\n\n*   **Build Configuration:**\n    *   Use a build tool to automate the build process.\n    *   Configure the build tool to optimize the bundle size.\n    *   Use environment variables to configure the build process.\n    *   Generate sourcemaps for debugging production code.\n    *   Automate deployments using CI/CD pipelines.\n\n*   **Linting and Formatting:**\n    *   Use ESLint to enforce code style and identify potential errors.\n    *   Use Prettier to automatically format code.\n    *   Integrate ESLint and Prettier into your IDE and build process.\n    *   Use consistent code style rules across the entire project.\n\n*   **Deployment:**\n    *   Deploy your application to a reliable hosting provider (e.g., Vercel, Netlify, AWS).\n    *   Use a CDN to serve static assets.\n    *   Configure HTTPS to secure communication between the client and server.\n    *   Monitor your application for performance and security issues.\n\n*   **CI/CD Integration:**\n    *   Use a CI/CD tool (e.g., GitHub Actions, GitLab CI, Jenkins) to automate the build, test, and deployment process.\n    *   Run unit tests, integration tests, and end-to-end tests in the CI/CD pipeline.\n    *   Automate deployments to staging and production environments.\n    *   Use code review processes to ensure code quality.\n\nBy adhering to these best practices, developers can build robust, secure, and maintainable applications using the Clerk library.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "clerk.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "clerk",
      "this",
      "rule",
      "file",
      "outlines",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "using",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "clerk",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-click",
    "description": "Comprehensive best practices for developing robust and maintainable command-line interfaces using the Click library in Python. Covers code structure, patterns, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "click",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/click.mdc",
    "content": "# Click CLI Library Best Practices\n\nThis document outlines best practices and coding standards for developing command-line interfaces (CLIs) in Python using the Click library. Click is a powerful and user-friendly library that simplifies the creation of beautiful and functional CLIs.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a well-organized directory structure to enhance maintainability and scalability.\n\n\nmycli/\n├── mycli.py          # Main application entry point (click command group)\n├── commands/\n│   ├── __init__.py     # Makes 'commands' a Python package\n│   ├── cmd_foo.py    # Implementation of 'foo' command\n│   ├── cmd_bar.py    # Implementation of 'bar' command\n│   └── ...\n├── utils/\n│   ├── __init__.py     # Utility functions (e.g., file I/O, API calls)\n│   ├── helper.py       # Helper functions\n│   └── ...\n├── models/\n│   ├── __init__.py     # Data models (e.g., classes, data structures)\n│   ├── data_model.py  # Data models\n│   └── ...\n├── tests/\n│   ├── __init__.py     # Test suite directory\n│   ├── test_mycli.py   # Tests for main application\n│   ├── test_commands/\n│   │   ├── test_cmd_foo.py  # Tests for 'foo' command\n│   │   └── ...\n│   └── ...\n├── README.md         # Project documentation\n├── LICENSE           # License information\n├── pyproject.toml    # Project configuration (dependencies, build)\n└── .gitignore        # Specifies intentionally untracked files that Git should ignore\n\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   Main application file: `mycli.py` (or a similar name reflecting the application's purpose).\n*   Command modules: `cmd_<command_name>.py` (e.g., `cmd_create.py`, `cmd_update.py`).\n*   Utility modules: `helper.py`, `file_utils.py`, etc.\n*   Test files: `test_<module_name>.py` (e.g., `test_mycli.py`, `test_cmd_create.py`).\n\n### 1.3. Module Organization\n\n*   **Main Application Module (`mycli.py`):**\n    *   Define the main `click.group()` that serves as the entry point for the CLI.\n    *   Import and register subcommands from the `commands` package.\n    *   Handle global options and context management.\n*   **Command Modules (`commands` package):**\n    *   Each command module should define a single `click.command()` decorated function.\n    *   Command functions should encapsulate the logic for that specific command.\n    *   Import necessary utility functions and data models from the `utils` and `models` packages.\n*   **Utility Modules (`utils` package):**\n    *   Provide reusable functions for common tasks, such as file I/O, API calls, data validation, etc.\n    *   Keep utility functions generic and independent of specific commands.\n*   **Data Models (`models` package):**\n    *   Define classes and data structures to represent the data used by the CLI application.\n    *   Use dataclasses or attrs for creating data models with less boilerplate.\n\n### 1.4. Component Architecture\n\n*   **Separation of Concerns:** Clearly separate the CLI interface from the application logic.\n*   **Command Layer:** Click commands handle user input, argument parsing, and invoking the underlying application logic.\n*   **Service Layer:** Implement the core application logic in separate modules or classes (services).\n*   **Data Access Layer:** Encapsulate data access and persistence logic in dedicated modules or classes.\n\n### 1.5. Code Splitting Strategies\n\n*   **Command-Based Splitting:** Split the application into separate modules based on the CLI commands.\n*   **Feature-Based Splitting:** Group related commands and utilities into feature-specific modules.\n*   **Layered Splitting:** Divide the application into layers (CLI, service, data access) and organize modules accordingly.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Command Pattern:**  Each CLI command is represented by a separate class or function, making it easy to add, remove, or modify commands.\n*   **Factory Pattern:** Use factories to create objects based on CLI arguments (e.g., creating different types of data exporters based on the `--format` option).\n*   **Dependency Injection:** Inject dependencies (e.g., API clients, database connections) into command functions to improve testability and flexibility.\n*   **Context Object:** Use Click's context object to store and share data across commands (see examples in the Click documentation).\n\n### 2.2. Recommended Approaches\n\n*   **Configuration Management:** Use environment variables or configuration files to manage application settings.\n*   **Logging:** Implement comprehensive logging using the `logging` module to track application behavior and diagnose issues.\n*   **Progress Bars:** Use Click's progress bar (`click.progressbar`) to provide visual feedback for long-running tasks.\n*   **Interactive Prompts:** Use Click's prompts (`click.prompt`) to gather user input interactively.\n*   **File Handling:** Use `click.File` to handle file I/O with automatic error checking and encoding support.\n*   **Exception Handling:** Use try-except blocks to gracefully handle exceptions and provide informative error messages to the user.\n*   **Testing:** Implement a comprehensive test suite to ensure the CLI application's correctness and reliability.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Tight Coupling:** Avoid tight coupling between the CLI interface and the application logic.\n*   **Global State:** Minimize the use of global variables and mutable global state.\n*   **Hardcoded Values:** Avoid hardcoding values in the code; use configuration files or environment variables instead.\n*   **Duplicated Code:** Refactor duplicated code into reusable functions or classes.\n*   **Lack of Error Handling:** Neglecting to handle exceptions can lead to unexpected crashes and poor user experience.\n*   **Inadequate Testing:** Insufficient testing can result in undetected bugs and regressions.\n*   **Overly Complex Commands:** Break down overly complex commands into smaller, more manageable subcommands.\n\n### 2.4. State Management\n\n*   **Context Object:** Use `click.Context.obj` to store and share state between commands. This is the recommended approach for passing data between different parts of your application within a single CLI invocation.\n*   **Environment Variables:**  Use environment variables for global configuration settings that rarely change.\n*   **Files:** Store persistent state (e.g., user preferences, cached data) in files.\n*   **Databases:** For more complex state management, use a database.\n\n### 2.5. Error Handling\n\n*   **`try...except` Blocks:** Wrap potentially failing operations in `try...except` blocks to catch exceptions.\n*   **Click's `click.ClickException`:** Raise `click.ClickException` to display user-friendly error messages.  This will ensure that the error message is formatted correctly and displayed to the user in a consistent manner.\n*   **Custom Exception Classes:** Define custom exception classes for specific error conditions.\n*   **Logging:** Log all errors to aid in debugging and troubleshooting.\n*   **Exit Codes:** Use appropriate exit codes to indicate the success or failure of a command.\n\npython\nimport click\n\n@click.command()\n@click.option('--input', '-i', required=True, type=click.Path(exists=True, dir_okay=False, readable=True))\ndef process_file(input):\n    try:\n        with open(input, 'r') as f:\n            # Process the file content\n            content = f.read()\n            click.echo(f'Processing file: {input}')\n    except FileNotFoundError:\n        raise click.ClickException(f'File not found: {input}')\n    except IOError:\n        raise click.ClickException(f'Could not read file: {input}')\n    except Exception as e:\n        click.echo(f'An unexpected error occurred: {e}', err=True)\n        raise  # Re-raise the exception for higher-level handling or logging\n\nif __name__ == '__main__':\n    try:\n        process_file()\n    except click.ClickException as e:\n        click.echo(f'Error: {e}', err=True)\n\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Minimize I/O Operations:** Reduce the number of file I/O and network operations.\n*   **Use Efficient Data Structures:** Choose appropriate data structures (e.g., sets, dictionaries) for optimal performance.\n*   **Caching:** Cache frequently accessed data to reduce redundant computations.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks.\n\n### 3.2. Memory Management\n\n*   **Large Datasets:** When dealing with large datasets, use generators or iterators to process data in chunks.\n*   **Object Creation:** Avoid creating unnecessary objects.\n*   **Resource Management:** Release resources (e.g., file handles, network connections) when they are no longer needed.\n\n### 3.3. Bundle Size Optimization\n\n*   **Dependency Management:** Use a virtual environment to isolate project dependencies.\n*   **Tree Shaking:** Use tools like `pyinstaller` to remove unused code from the final executable.\n\n### 3.4. Lazy Loading\n\n*   **Import on Demand:** Import modules only when they are needed.\n*   **Command Loading:** Load command modules only when the corresponding command is invoked.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Command Injection:** Prevent command injection by carefully validating user input.\n*   **Path Traversal:** Avoid path traversal vulnerabilities by sanitizing file paths.\n*   **Sensitive Data Exposure:** Protect sensitive data (e.g., passwords, API keys) by storing them securely and avoiding logging them.\n\n### 4.2. Input Validation\n\n*   **Type Checking:** Use Click's type system to validate the type of user input.\n*   **Range Checking:** Validate that numerical inputs fall within acceptable ranges.\n*   **Regular Expressions:** Use regular expressions to validate string inputs.\n*   **Whitelist:** Validate inputs against a whitelist of allowed values.\n*   **Sanitization:** Sanitize user inputs to remove potentially harmful characters.\n\npython\nimport click\nimport re\n\n@click.command()\n@click.option('--email', '-e', required=True)\ndef send_email(email):\n    # Input validation using regex\n    if not re.match(r\"^[\\w\\.-]+@([\\w-]+\\.)+[\\w-]{2,4}$\", email):\n        raise click.ClickException(\"Invalid email format.\")\n    click.echo(f\"Sending email to {email}\")\n\nif __name__ == '__main__':\n    send_email()\n\n\n\n### 4.3. Authentication and Authorization\n\n*   **API Keys:** Use API keys to authenticate users and authorize access to resources.\n*   **OAuth:** Implement OAuth 2.0 for secure API authentication.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to commands and resources based on user roles.\n\n### 4.4. Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Hashing:** Hash passwords and other sensitive data using strong hashing algorithms.\n*   **Data Masking:** Mask sensitive data in logs and other outputs.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **TLS/SSL:** Use TLS/SSL certificates to encrypt data in transit.\n*   **API Rate Limiting:** Implement API rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Functions:** Write unit tests for individual functions and classes.\n*   **Mock Dependencies:** Mock external dependencies (e.g., API calls, database connections) to isolate the code under test.\n*   **Test Edge Cases:** Test edge cases and boundary conditions to ensure code robustness.\n*   **Use `click.testing.CliRunner`:** Use `click.testing.CliRunner` to simulate CLI invocations and verify the output.\n\n### 5.2. Integration Testing\n\n*   **Test Command Combinations:** Test combinations of commands and options to ensure they work together correctly.\n*   **Test Real Dependencies:** Test with real dependencies (e.g., a test database) to ensure the application integrates properly.\n\n### 5.3. End-to-End Testing\n\n*   **Test Full Workflow:** Test the entire CLI application workflow from start to finish.\n*   **Automate Tests:** Automate end-to-end tests to ensure continuous integration and continuous delivery.\n\n### 5.4. Test Organization\n\n*   **Separate Test Directory:** Create a separate `tests` directory for all tests.\n*   **Mirror Source Structure:** Mirror the source code structure in the test directory.\n*   **Descriptive Test Names:** Use descriptive test names to clearly indicate what each test is verifying.\n\n### 5.5. Mocking and Stubbing\n\n*   **`unittest.mock`:** Use the `unittest.mock` module to create mock objects and stubs.\n*   **Mock External Dependencies:** Mock external dependencies to isolate the code under test.\n*   **Stub Return Values:** Stub return values to control the behavior of mocked objects.\n\npython\nimport unittest\nfrom unittest.mock import patch\nfrom click.testing import CliRunner\nfrom mycli import cli  # Assuming your main script is named mycli.py\n\nclass TestMyCLI(unittest.TestCase):\n\n    def test_hello_world(self):\n        runner = CliRunner()\n        result = runner.invoke(cli, ['hello', '--name', 'TestUser'])\n        self.assertEqual(result.exit_code, 0)\n        self.assertEqual(result.output.strip(), 'Hello, TestUser!')\n\n    @patch('mycli.commands.cmd_foo.get_data')  # Assuming cmd_foo.py has a function get_data to mock\n    def test_foo_command(self, mock_get_data):\n        mock_get_data.return_value = ['data1', 'data2']\n        runner = CliRunner()\n        result = runner.invoke(cli, ['foo'])\n        self.assertEqual(result.exit_code, 0)\n        self.assertIn('data1', result.output)\n        self.assertIn('data2', result.output)\n\nif __name__ == '__main__':\n    unittest.main()\n\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Forgetting `@click.command()` or `@click.group()`:**  Commands will not be registered without these decorators.\n*   **Incorrect Argument Types:**  Using the wrong type for a `click.argument` or `click.option` can lead to unexpected behavior.\n*   **Missing `required=True`:**  Forgetting to specify `required=True` for mandatory arguments or options.\n*   **Not Handling Exceptions:**  Failing to handle exceptions can cause the CLI to crash.\n*   **Incorrect File Paths:** Providing incorrect file paths to `click.Path` can lead to errors.\n\n### 6.2. Edge Cases\n\n*   **Unicode Handling:**  Ensure proper handling of Unicode characters in input and output.\n*   **Large Input Files:**  Handle large input files efficiently to avoid memory issues.\n*   **Concurrent Access:**  Handle concurrent access to shared resources (e.g., files, databases) properly.\n\n### 6.3. Version-Specific Issues\n\n*   **Compatibility:**  Check for compatibility issues between Click and other libraries.\n*   **Deprecated Features:**  Be aware of deprecated features and plan for migration.\n\n### 6.4. Compatibility Concerns\n\n*   **Python Versions:**  Ensure compatibility with supported Python versions.\n*   **Operating Systems:**  Test the CLI application on different operating systems (Windows, macOS, Linux).\n*   **Terminal Emulators:**  Be aware of potential compatibility issues with different terminal emulators.\n\n### 6.5. Debugging Strategies\n\n*   **`print()` Statements:**  Use `print()` statements for basic debugging.\n*   **Debuggers:**  Use debuggers (e.g., `pdb`, `ipdb`) for more advanced debugging.\n*   **Logging:**  Use logging to track application behavior and diagnose issues.\n*   **Click's `echo()` Function:** Use Click's `echo()` to ensure consistent output across different platforms and terminal configurations. Also, use `err=True` to distinguish error messages clearly.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n*   **Virtual Environments:** Use virtual environments (e.g., `venv`, `virtualenv`) to isolate project dependencies.\n*   **Package Manager:** Use `pip` for installing and managing Python packages.\n*   **Text Editor/IDE:** Use a text editor or IDE with Python support (e.g., VS Code, PyCharm).\n*   **Linting Tools:** Use linting tools (e.g., `flake8`, `pylint`) to enforce coding style and identify potential errors.\n*   **Formatting Tools:** Use formatting tools (e.g., `black`, `autopep8`) to automatically format code.\n*   **Testing Frameworks:** Use testing frameworks (e.g., `unittest`, `pytest`) to write and run tests.\n\n### 7.2. Build Configuration\n\n*   **`pyproject.toml`:** Use `pyproject.toml` to specify project dependencies and build configuration.\n*   **`setup.py`:** Use `setup.py` to define the project's metadata and entry points.\n*   **Build Tools:** Use build tools (e.g., `setuptools`, `poetry`) to package and distribute the CLI application.\n\n### 7.3. Linting and Formatting\n\n*   **`flake8`:** Use `flake8` to check for PEP 8 violations and other coding style issues.\n*   **`pylint`:** Use `pylint` for more comprehensive code analysis.\n*   **`black`:** Use `black` to automatically format code according to PEP 8.\n*   **Pre-commit Hooks:** Use pre-commit hooks to automatically run linting and formatting tools before committing code.\n\n### 7.4. Deployment\n\n*   **Package Managers:** Deploy the CLI application using package managers (e.g., `pip`, `conda`).\n*   **Executable Bundles:** Create standalone executable bundles using tools like `pyinstaller` or `cx_Freeze`.\n*   **Containers:** Deploy the CLI application in containers (e.g., Docker) for portability and scalability.\n\n### 7.5. CI/CD Integration\n\n*   **Continuous Integration:** Integrate the CLI application into a CI/CD pipeline (e.g., Jenkins, GitLab CI, GitHub Actions).\n*   **Automated Testing:** Automate testing as part of the CI/CD pipeline.\n*   **Automated Deployment:** Automate deployment to staging and production environments.\n\nBy following these best practices, developers can create robust, maintainable, and user-friendly CLI applications using the Click library.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "click.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "click",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "robust",
      "maintainable",
      "command",
      "line",
      "interfaces",
      "using",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "click",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-cloudflare",
    "description": "This rule provides a comprehensive set of best practices and coding standards for developing with the Cloudflare library, specifically focusing on Terraform configurations. It aims to guide developers in creating efficient, secure, and maintainable infrastructure code.",
    "author": "sanjeed5",
    "tags": [
      "cloudflare",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/cloudflare.mdc",
    "content": "# Cloudflare Terraform Best Practices\n\nThis document outlines the recommended best practices and coding standards for working with Cloudflare resources using Terraform. Following these guidelines will help you create robust, scalable, and maintainable infrastructure code.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n*   **Account-Based Segregation:** Organize your Terraform projects by Cloudflare accounts. This allows for clear separation of resources and access control.\n*   **Zone-Based Grouping:** Within each account, further group resources by zones. This makes it easier to manage resources associated with specific domains.\n*   **Product/Feature-Based Organization:** Within each zone, create subdirectories for individual Cloudflare products or features (e.g., `dns`, `page_rules`, `rulesets`, `waf`). This promotes modularity and maintainability.\n*   **Environment Separation:** While not strictly enforced within a single repository, using separate Cloudflare accounts for different environments (development, staging, production) is *strongly* recommended for complete isolation.\n\nExample:\n\n\nexample-tf/\n├── demo_account_a  # Per account segregation of resources\n│   ├── users        # Top level directory for account members as they are \"zoneless\"\n│   │   ├── provider.tf # `provider.tf` is for configuring the providers\n│   │   ├── users.tf    # `<subject>.tf` (users.tf) is for managing the individual resources\n│   │   └── vars.tf     # Manage all variables for this component\n│   ├── zone_a       # Group all zone based features together\n│   │   ├── dns        # Individual (or grouped, your choice) of products or features to manage together\n│   │   │   ├── dns.tf     # `<subject>.tf` (dns.tf) is for managing the individual resources\n│   │   │   ├── provider.tf # `provider.tf` is for configuring the providers\n│   │   │   └── vars.tf    # Manage all variables for this component\n│   │   └── page_rules # ... same as above but for Page Rules (legacy)\n│   │       ├── page_rules.tf\n│   │       ├── provider.tf\n│   │       └── vars.tf\n│   ├── zone_b\n│   │   ├── dns\n│   │   │   ├── dns.tf\n│   │   │   ├── provider.tf\n│   │   │   └── vars.tf\n│   │   └── page_rules\n│   │       ├── page_rules.tf\n│   │       ├── provider.tf\n│   │       └── vars.tf\n│   └── zone_c\n│       ├── dns\n│       │   ├── dns.tf\n│       │   ├── provider.tf\n│       │   └── vars.tf\n│       └── page_rules\n│           ├── page_rules.tf\n│           ├── provider.tf\n│           └── vars.tf\n└── demo_account_b\n    ├── users\n    │   ├── provider.tf\n    │   ├── users.tf\n    │   └── vars.tf\n    ├── zone_a\n    │   ├── dns\n    │   │   ├── dns.tf\n    │   │   ├── provider.tf\n    │   │   └── vars.tf\n    │   └── page_rules\n    │       ├── page_rules.tf\n    │       ├── provider.tf\n    │       └── vars.tf\n    ├── zone_b\n    │   ├── dns\n    │   │   ├── dns.tf\n    │   │   ├── provider.tf\n    │   │   └── vars.tf\n    │   └── page_rules\n    │       ├── page_rules.tf\n    │       ├── provider.tf\n    │       └── vars.tf\n    └── zone_c\n        ├── dns\n        │   ├── dns.tf\n        │   ├── provider.tf\n        │   └── vars.tf\n        └── page_rules\n            ├── page_rules.tf\n            ├── provider.tf\n            └── vars.tf\n\n\n### 1.2 File Naming Conventions\n\n*   `provider.tf`:  Contains provider configuration (e.g., Cloudflare provider settings).\n*   `variables.tf`: Defines input variables for the module/component.\n*   `outputs.tf`:  Declares output values that can be used by other modules/components.\n*   `<resource_type>.tf`:  Contains resource definitions for a specific Cloudflare resource type (e.g., `dns_records.tf`, `page_rules.tf`, `waf_rules.tf`).\n*   `data.tf`: Contains Terraform data sources.\n*   `main.tf`: If `provider.tf` and `outputs.tf` are not required, `main.tf` should contain your main resource and data source definitions.\n\n### 1.3 Module Organization\n\n*   **Avoid Modules (or Use Sparingly):**  While modules can provide abstraction, they can also introduce complexity and make debugging more difficult.  Carefully consider whether a module is truly necessary before creating one.  If you do use modules, keep them small and well-defined.\n*   **Module Structure:**  If using modules, follow a consistent internal structure, including `variables.tf`, `outputs.tf`, and `main.tf`.\n*   **Versioning:** If you share Terraform modules (internal or public), ensure you practice module versioning best practices. A well-defined versioning strategy, such as semantic versioning is recommended.\n\n### 1.4 Component Architecture\n\n*   **Small, Focused Components:** Design your Terraform code as a collection of small, focused components, each responsible for a specific aspect of your Cloudflare configuration.\n*   **Loose Coupling:** Minimize dependencies between components to improve reusability and reduce the impact of changes.\n*   **Well-Defined Interfaces:** Clearly define the input variables and output values for each component to create well-defined interfaces.\n\n### 1.5 Code Splitting Strategies\n\n*   **Resource Type:** Split code based on resource type (e.g., DNS records, Page Rules).\n*   **Functionality:** Split code based on logical functionality (e.g., WAF rules for specific types of attacks).\n*   **Environment:**  While *strongly* recommending separate Cloudflare accounts for environments, you can also use Terraform workspaces to manage different environments within the same codebase, though this is generally discouraged due to potential blast radius of changes.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Cloudflare\n\n*   **Data Source-Driven Configuration:** Use data sources to dynamically fetch information about existing Cloudflare resources (e.g., zone ID, account ID) rather than hardcoding them.\n*   **Looping with `for_each` and `count`:** Use `for_each` or `count` to create multiple similar resources (e.g., multiple DNS records) based on variables or data sources.  Favor `for_each` over `count` when possible, as it provides more explicit resource naming and updating behaviors.\n*   **Dynamic Blocks:** Leverage dynamic blocks to conditionally create resource attributes based on variables or data sources. This allows for more flexible and reusable code.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Creating DNS Records:** Use `cloudflare_record` resource to manage DNS records.  Utilize `for_each` to create multiple records based on a variable containing a list of record definitions.\n*   **Managing Page Rules:** Use the `cloudflare_page_rule` resource to create and manage page rules. Consider using a module to encapsulate common page rule configurations.\n*   **Configuring WAF Rules:** Use the `cloudflare_ruleset` and related resources to create and manage WAF rulesets.  Organize rulesets into logical groups based on functionality.\n*   **Setting up Load Balancers:** Use `cloudflare_load_balancer`, `cloudflare_load_balancer_pool`, and `cloudflare_load_balancer_monitor` resources to create and manage load balancers.\n*   **Worker Deployment**: Use `cloudflare_worker` to manage Cloudflare Workers.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Hardcoding Values:** Avoid hardcoding values such as API keys, account IDs, and zone IDs in your code. Use variables and data sources instead.\n*   **Managing Resources Outside of Terraform:**  Terraform works best when it manages all changes to and the lifecycle of a resource. Avoid making manual changes to Cloudflare resources outside of Terraform, as this can lead to inconsistencies and drift.  If external changes are unavoidable, plan to re-import the resources or reconcile the differences.\n*   **Overly Complex Modules:**  Avoid creating overly complex modules that perform too many tasks.  Break down complex configurations into smaller, more manageable components.\n*   **Ignoring `terraform fmt` and `terraform validate`:** Always run `terraform fmt` to format your code and `terraform validate` to check for syntax errors and other issues before committing changes.\n*   **Storing Secrets in Code:** Never store API tokens or other secrets directly in your Terraform code or version control. Use a secure secret management solution like Vault or environment variables.\n\n### 2.4 State Management Best Practices\n\n*   **Remote State:**  Always use remote state management (e.g., Terraform Cloud, AWS S3, Azure Blob Storage) to store your Terraform state file. This ensures that your state is stored securely and is accessible to all members of your team.\n*   **State Locking:**  Enable state locking to prevent concurrent modifications to your state file.\n*   **Encryption:** Encrypt your state file at rest to protect sensitive information.\n*   **Backup:** Regularly back up your state file to prevent data loss.\n*   **Consider Terraform Cloud:** For teams, consider using Terraform Cloud for state management, collaboration, and automation. It offers features like remote state storage, state locking, plan previews, and automated runs.\n\n### 2.5 Error Handling Patterns\n\n*   **Use `try` and `catch` in Expressions:** Use `try` and `catch` to handle errors in Terraform expressions gracefully.\n*   **Validate Input Variables:** Validate input variables to ensure that they are in the correct format and within the expected range.\n*   **Use `depends_on` Sparingly:** Use `depends_on` only when necessary to explicitly define dependencies between resources. Overuse of `depends_on` can lead to performance issues and deadlocks.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Minimize Resource Dependencies:** Reduce the number of dependencies between resources to improve plan and apply times.\n*   **Use Data Sources Effectively:** Use data sources to retrieve information about existing resources rather than creating new resources when possible.\n*   **Targeted Applies:** Use targeted applies (`terraform apply -target=resource`) to apply changes to specific resources rather than applying the entire configuration.\n\n### 3.2 Memory Management\n\n*   **Large State Files:** Be mindful of large state files. Break down large configurations into smaller, more manageable components to reduce state file size. Review state files periodically and consider refactoring if they become unwieldy.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Exposed API Keys:** Never expose your Cloudflare API keys in your code or version control. Use environment variables or a secure secret management solution instead.\n*   **Insufficient Input Validation:** Validate all input variables to prevent injection attacks and other security vulnerabilities.\n*   **Overly Permissive Permissions:** Grant only the necessary permissions to your Cloudflare API keys and Terraform service accounts.\n\n### 4.2 Input Validation\n\n*   **Variable Validation:** Use the `validation` block in variable definitions to enforce constraints on input values.  This is crucial for preventing unexpected behavior and security vulnerabilities.\n*   **Regular Expressions:** Use regular expressions to validate input strings.\n*   **Type Checking:** Use Terraform's type system to ensure that variables are of the correct type.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **API Tokens vs. Global API Key:** Prefer using API tokens with specific permissions over the global API key, as API tokens can be scoped to specific resources and actions.\n*   **Least Privilege Principle:** Grant only the necessary permissions to your Terraform service accounts.\n*   **Secure Storage:** Store API tokens and other secrets securely using a secret management solution.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in logs and error messages.\n*   **Access Control:** Implement strict access control policies to protect sensitive data.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Always use HTTPS to communicate with the Cloudflare API.\n*   **TLS:** Use TLS 1.2 or higher.\n*   **Certificate Validation:** Validate the Cloudflare API certificate.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Validate Resource Attributes:** Write unit tests to validate the attributes of individual resources.\n*   **Check for Expected Errors:** Write unit tests to check for expected errors.\n*   **Use `terraform show`:** Use `terraform show` to inspect the generated Terraform configuration and verify that it is correct.\n\n### 5.2 Integration Testing\n\n*   **Deploy to a Test Environment:** Deploy your Terraform code to a test environment and verify that it works as expected.\n*   **Automated Testing:** Automate your integration tests using a CI/CD pipeline.\n*   **Check Cloudflare Resources:** After applying a Terraform configuration in a test environment, use the Cloudflare API or UI to verify that the resources have been created and configured correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate Real-World Traffic:** Simulate real-world traffic to your Cloudflare resources to verify that they are functioning correctly.\n*   **Monitor Performance:** Monitor the performance of your Cloudflare resources to identify any bottlenecks or issues.\n\n### 5.4 Test Organization\n\n*   **Separate Test Directory:** Create a separate directory for your Terraform tests.\n*   **Test Naming Conventions:** Follow consistent naming conventions for your tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock Data Sources:** Mock data sources to isolate your tests from external dependencies.\n*   **Stub API Calls:** Stub API calls to control the behavior of the Cloudflare API during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n*   **Rate Limiting:** Be aware of Cloudflare's API rate limits. Implement retry logic to handle rate limit errors.\n*   **Resource Dependencies:** Understand the dependencies between Cloudflare resources. Create resources in the correct order to avoid errors.\n*   **State Drift:** Regularly check for state drift and reconcile any differences between your Terraform state and your Cloudflare resources.\n*   **Idempotency:** Ensure that your Terraform code is idempotent. Applying the same configuration multiple times should have the same result.\n*   **Cloudflare Provider Version:** Lock the Cloudflare provider version in your `terraform` block in `main.tf`. Upgrading the provider can sometimes introduce breaking changes, so testing the upgrade in a non-production environment is suggested first.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Terraform CLI:** The official Terraform command-line interface.\n*   **Terraform Language Server:** Provides code completion, syntax highlighting, and other features for Terraform code in your IDE.\n*   **IDE Extensions:** Use IDE extensions for Terraform to improve your development experience (e.g., VS Code Terraform extension).\n*   **cf-terraforming:** Use `cf-terraforming` tool to import existing Cloudflare resources into Terraform state.\n\n### 7.2 Build Configuration\n\n*   **Terraform Block:** Configure the required providers and Terraform version in the `terraform` block in `main.tf`.\n*   **Provider Configuration:** Configure the Cloudflare provider with your API key and account ID.\n\n### 7.3 Linting and Formatting\n\n*   **`terraform fmt`:** Use `terraform fmt` to automatically format your Terraform code.\n*   **`terraform validate`:** Use `terraform validate` to check for syntax errors and other issues.\n*   **`tflint`:** Consider using `tflint` or other linting tools to enforce coding standards and best practices.\n\n### 7.4 Deployment Best Practices\n\n*   **CI/CD Pipeline:** Automate your Terraform deployments using a CI/CD pipeline.\n*   **Plan Previews:** Always review the Terraform plan before applying changes.\n*   **Apply with Auto-Approve (Carefully):** Use the `-auto-approve` flag with caution. Only use it in automated environments where you have a high degree of confidence in your code.\n*   **Blue/Green Deployments:** Consider using blue/green deployments to minimize downtime during deployments.\n\n### 7.5 CI/CD Integration\n\n*   **Terraform Cloud/Enterprise:** Use Terraform Cloud or Enterprise to manage your Terraform workflows and collaborate with your team.\n*   **GitHub Actions:** Use GitHub Actions to automate your Terraform deployments.\n*   **GitLab CI:** Use GitLab CI to automate your Terraform deployments.\n*   **Jenkins:** Use Jenkins to automate your Terraform deployments.\n\n## 8. Angle Brackets, Square Brackets, and Curly Braces\n\n*   **Angle Brackets (`<` and `>`):** Use angle brackets as placeholders for variables that the user must enter, except in URLs, where you should use curly braces.\n    *   Example: `https://<user-specified domain>.cloudflare.com`\n*   **Square Brackets (`[` and `]`):** Use square brackets to enclose optional items.\n    *   Example: `tag=dns query [search tag=malware]`\n*   **Curly Braces (`{` and `}`):** Use curly braces in code samples or string literals, such as placeholders in URLs.\n    *   Example: `https://api.cloudflare.com/client/v4/organizations/{organization_identifier}/invites`\n\n## 9. Cloudflare's Convention Symbols\n\n*   The `>` symbol leads you through nested menu items and dialog box options to a final action.\n    *   Example: `Options > Settings > General` directs you to pull down the Options menu, select the Settings item, and select General from the last dialog box. Do not use bold formatting for the `>` symbol.\n*   Tip icon: This icon denotes a tip, which alerts you to advisory information.\n*   Note icon: This icon denotes a note, which alerts you to important information.\n*   Info icon: This icon denotes info, which alerts you to important information.\n*   Notice icon: This icon denotes a notice, which alerts you to take precautions to avoid data loss, loss of signal integrity, or degradation of performance.\n*   Caution icon: This icon denotes a caution, which advises you to take precautions to avoid injury.\n*   Blue text: Text in this color indicates a link.\n*   Bold: Use bold when referring to a clickable action or to highlight a title or name in the UI. Bold text denotes items that you must select or click in the software, identifiers in the UI, or parameter names. Do not use bold for programs. In nested menus, use bold for the word not the symbol.\n    *   Example: `Dashboard > This > That`\n*   Italics: Use italics when referring to an option that customers can select from, like in dropdown menus. Do not use italics when referring to the state of a toggle - for example, enabled/disabled should not be italicized.\n*   Monospace: Text in this font denotes text or characters that you should enter from the keyboard, sections of code, programming examples, and syntax examples. This font is also used for the proper names of drives, paths, directories, programs, subprograms, devices, functions, operations, variables, files, API commands, and extensions.\n\nBy adhering to these best practices, you can create more efficient, secure, and maintainable Terraform code for managing your Cloudflare infrastructure.",
    "metadata": {
      "globs": "*.tf",
      "format": "mdc",
      "originalFile": "cloudflare.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "cloudflare",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "cloudflare",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-codemirror",
    "description": "This rule provides guidelines for using CodeMirror effectively, covering code organization, performance, security, testing, and common pitfalls. It aims to ensure robust and maintainable code editor implementations.",
    "author": "sanjeed5",
    "tags": [
      "codemirror",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/codemirror.mdc",
    "content": "# CodeMirror Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing text editors and code-related applications using CodeMirror. Adhering to these guidelines will help ensure maintainability, performance, and a positive user experience.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **Project Root:**\n    *   `.cursor/rules/`: (if using cursor rules) stores project-specific rules. Each rule should correspond to a specific aspect of the project or library.\n    *   `src/`: Contains the main source code for your CodeMirror integration.\n    *   `dist/`: Stores the built or compiled output.\n    *   `node_modules/`: Contains project dependencies (managed by npm or yarn).\n    *   `package.json`: Defines project metadata and dependencies.\n    *   `webpack.config.js` or `vite.config.js`: Configuration file for the bundler (if using one).\n    *   `.eslintrc.js`, `.prettierrc.js`: Configuration files for linting and formatting.\n    *   `tests/`: Contains unit, integration, and end-to-end tests.\n    *   `README.md`: Project documentation.\n\n*   **`src/` directory:**\n    *   `components/`: Reusable CodeMirror components (e.g., custom toolbars, panels).\n    *   `modes/`: Custom language modes (if any).\n    *   `addons/`: Custom CodeMirror addons.\n    *   `utils/` or `helpers/`: Utility functions.\n    *   `config/`: Configuration files (e.g., CodeMirror options).\n    *   `styles/`: Custom CSS or styling modules for CodeMirror.\n    *   `index.js` or `index.ts`: Entry point for the CodeMirror integration.\n\n### 1.2. File Naming Conventions\n\n*   **Components:** Use PascalCase (e.g., `EditorToolbar.js`, `SyntaxHighlightingAddon.ts`).\n*   **Modules:** Use camelCase (e.g., `editorConfig.js`, `stringUtils.ts`).\n*   **Styles:** Use kebab-case (e.g., `editor-styles.css`, `toolbar-theme.scss`).\n*   **Test Files:** Append `.test.js` or `.spec.ts` to the corresponding component/module name (e.g., `EditorToolbar.test.js`).\n\n### 1.3. Module Organization\n\n*   **Modular Design:** Break down CodeMirror-related functionality into small, reusable modules.\n*   **Single Responsibility Principle:** Each module should have a clear and specific purpose.\n*   **Dependency Management:** Explicitly declare dependencies within each module.  Use ES modules (`import`/`export`) or CommonJS (`require`/`module.exports`).\n*   **Avoid Global State:** Minimize the use of global variables or shared mutable state. Pass data and configuration options explicitly to functions and components.\n\n### 1.4. Component Architecture\n\n*   **Presentational and Container Components:**  Separate concerns by creating presentational components (responsible for rendering UI) and container components (responsible for data fetching and state management).\n*   **Component Composition:** Build complex UIs by composing smaller, reusable components.\n*   **Props and Events:** Use props to pass data down to components and events to communicate actions up to parent components.\n\n### 1.5. Code Splitting\n\n*   **Dynamic Imports:** Use dynamic imports (`import()`) to load CodeMirror modes and addons on demand.\n*   **Route-Based Splitting:** If the CodeMirror editor is only used on specific routes in your application, load it only when those routes are visited.\n*   **Webpack or Vite Configuration:** Configure your bundler to automatically split your code into smaller chunks.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Observer Pattern:** Use the Observer pattern to notify other parts of the application when the editor's content changes.\n*   **Strategy Pattern:** Implement different editing strategies based on the selected language mode.\n*   **Factory Pattern:** Use a factory function to create CodeMirror instances with specific configurations.\n\n### 2.2. Recommended Approaches\n\n*   **Configuration Objects:** Encapsulate CodeMirror options in a configuration object to improve readability and maintainability.\n*   **Custom Addons:** Create custom CodeMirror addons to extend the editor's functionality.\n*   **Event Handling:** Use CodeMirror's event system to respond to user interactions and editor changes.\n\n### 2.3. Anti-patterns\n\n*   **Direct DOM Manipulation:** Avoid directly manipulating the CodeMirror DOM elements. Use the CodeMirror API instead.\n*   **Overly Complex Modes:** Keep language modes focused and well-structured.  Delegate complex parsing logic to external libraries if necessary.\n*   **Ignoring Performance:** Be mindful of performance implications when adding new features or customizations.\n\n### 2.4. State Management\n\n*   **Local State:** Use component state for simple, editor-specific data.\n*   **Redux or Context API:** For larger applications, consider using a state management library like Redux or the React Context API to manage the editor's state centrally.\n*   **Immutability:** Treat the editor's state as immutable to simplify debugging and improve performance.\n\n### 2.5. Error Handling\n\n*   **Try-Catch Blocks:** Use try-catch blocks to handle potential errors when interacting with the CodeMirror API.\n*   **Error Boundaries:** In React applications, use error boundaries to catch errors that occur during rendering.\n*   **Logging:** Log errors and warnings to aid in debugging.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Lazy Loading:** Load CodeMirror modes and addons only when they are needed.\n*   **Debouncing:** Debounce event handlers to prevent excessive updates.\n*   **Virtualization:** If you are displaying a large number of lines, consider using a virtualization technique to render only the visible lines.\n*   **Minimize DOM Updates:** Reduce the number of DOM updates by batching changes and using efficient rendering techniques.\n\n### 3.2. Memory Management\n\n*   **Remove Event Listeners:** Remove event listeners when components are unmounted to prevent memory leaks.\n*   **Clear Intervals and Timeouts:** Clear any intervals or timeouts that are no longer needed.\n*   **Object Reuse:**  Reuse objects and data structures whenever possible to reduce memory allocation.\n\n### 3.3. Rendering Optimization\n\n*   **ShouldComponentUpdate:** In React applications, use `shouldComponentUpdate` or `React.memo` to prevent unnecessary re-renders.\n*   **Immutable Data Structures:** Use immutable data structures to efficiently detect changes and trigger re-renders.\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking:** Configure your bundler to remove unused code (tree shaking).\n*   **Minification:** Minify your code to reduce its size.\n*   **Gzip Compression:** Use Gzip compression to reduce the size of your assets during transfer.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Mode-Specific Loading:** Only load the language mode when the user opens a file of that type.\n*   **Addon-Specific Loading:** Load addons only when the user needs their functionality.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Be careful when displaying user-generated content in the editor. Sanitize the input to prevent XSS attacks.\n*   **Code Injection:** Avoid using `eval()` or `Function()` to execute untrusted code.\n\n### 4.2. Input Validation\n\n*   **Sanitize Input:** Sanitize user input before displaying it in the editor.\n*   **Validate Data:** Validate data received from external sources before using it in the editor.\n\n### 4.3. Authentication and Authorization\n\n*   **Secure APIs:** Use secure APIs for data access and authentication.\n*   **Role-Based Access Control:** Implement role-based access control to restrict access to sensitive features.\n\n### 4.4. Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Secure Storage:** Store data in a secure location with appropriate access controls.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Keys:** Protect API keys and prevent them from being exposed in the client-side code.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Components:** Unit test individual CodeMirror components and modules.\n*   **Mock Dependencies:** Mock external dependencies to isolate the components being tested.\n*   **Assertion Libraries:** Use assertion libraries like Jest or Chai to write expressive tests.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions:** Test the interactions between different CodeMirror components and modules.\n*   **Real DOM:** Use a real DOM environment for integration testing.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate User Actions:** Simulate user actions to test the entire CodeMirror workflow.\n*   **Automated Testing:** Use end-to-end testing frameworks like Cypress or Puppeteer to automate the testing process.\n\n### 5.4. Test Organization\n\n*   **Test Directory:** Create a dedicated `tests/` directory for all tests.\n*   **Test Files:** Place test files alongside the corresponding components/modules.\n*   **Test Suites:** Organize tests into logical suites based on functionality.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock CodeMirror Instances:** Mock CodeMirror instances to control their behavior during testing.\n*   **Stub API Calls:** Stub API calls to prevent external dependencies from interfering with the tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not Sanitizing User Input:** Failing to sanitize user input can lead to XSS vulnerabilities.\n*   **Ignoring Performance Issues:** Neglecting performance considerations can result in a slow and unresponsive editor.\n*   **Direct DOM Manipulation:**  Directly manipulating CodeMirror's DOM can break its internal workings.\n\n### 6.2. Edge Cases\n\n*   **Handling Large Files:** CodeMirror can struggle with extremely large files. Consider using virtualization or other optimization techniques.\n*   **Internationalization (i18n):** Ensure that the editor supports different languages and character sets.\n*   **Accessibility (a11y):**  Make the editor accessible to users with disabilities by providing keyboard navigation, screen reader support, and appropriate ARIA attributes.\n\n### 6.3. Version-Specific Issues\n\n*   **Check Release Notes:** Review the CodeMirror release notes for any breaking changes or known issues.\n*   **Test Upgrades:** Thoroughly test CodeMirror upgrades to ensure compatibility with your existing code.\n\n### 6.4. Compatibility Concerns\n\n*   **Browser Compatibility:** Test the editor in different browsers to ensure compatibility.\n*   **Framework Compatibility:**  Ensure that CodeMirror integrates correctly with your chosen framework (e.g., React, Vue, Angular).\n\n### 6.5. Debugging Strategies\n\n*   **Browser Developer Tools:** Use the browser developer tools to inspect the CodeMirror DOM, network requests, and console output.\n*   **Logging:** Add logging statements to your code to track the flow of execution and identify potential issues.\n*   **Debugging Tools:** Use a debugger to step through your code and examine variables.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n*   **Code Editor:** VS Code, Sublime Text, or Atom with CodeMirror-specific plugins.\n*   **Bundler:** Webpack, Vite, or Parcel.\n*   **Linter:** ESLint or JSHint.\n*   **Formatter:** Prettier.\n*   **Testing Framework:** Jest, Mocha, or Jasmine.\n*   **End-to-End Testing Framework:** Cypress or Puppeteer.\n\n### 7.2. Build Configuration\n\n*   **Module Bundling:** Use a module bundler to combine your code and dependencies into optimized bundles.\n*   **Source Maps:** Generate source maps to aid in debugging.\n*   **Code Optimization:** Configure your build process to optimize code for production (e.g., minification, tree shaking).\n\n### 7.3. Linting and Formatting\n\n*   **Consistent Style:** Use a linter and formatter to enforce a consistent coding style.\n*   **Code Quality:** Configure the linter to catch potential code quality issues (e.g., unused variables, syntax errors).\n\n### 7.4. Deployment Best Practices\n\n*   **Optimize Assets:** Optimize your assets (e.g., images, CSS, JavaScript) for production.\n*   **Content Delivery Network (CDN):** Use a CDN to deliver CodeMirror assets to users from geographically distributed servers.\n*   **Caching:** Configure browser caching to reduce the number of requests to your server.\n\n### 7.5. CI/CD Integration\n\n*   **Automated Builds:** Automate the build process using a CI/CD pipeline.\n*   **Automated Tests:** Run automated tests as part of the CI/CD pipeline.\n*   **Deployment Automation:** Automate the deployment process to reduce the risk of errors.",
    "metadata": {
      "globs": "*.js,*.ts,*.html,*.css,*.vue,*.svelte,*.jsx,*.tsx",
      "format": "mdc",
      "originalFile": "codemirror.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "codemirror",
      "this",
      "rule",
      "provides",
      "guidelines",
      "using",
      "effectively",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "codemirror",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-crewai",
    "description": "This rule provides comprehensive best practices for developing with the CrewAI library, covering code organization, performance, security, testing, and common pitfalls. It serves as a guide for building robust and scalable AI applications using CrewAI.",
    "author": "sanjeed5",
    "tags": [
      "crewai",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/crewai.mdc",
    "content": "- **General Best Practices**:\n  - Leverage structured responses from LLM calls using Pydantic for output validation.\n  - Maintain a modular architecture for flexibility and scalability.\n  - Regularly validate outputs from agents and tasks.\n  - Use UV for dependency management and Python 3.12.\n  - Prioritize classes over functions for better organization and maintainability.\n\n- **Code Organization and Structure**:\n  - **Directory Structure:**\n    - `crewai_project/` (Root directory)\n      - `agents/`: Contains agent definitions (e.g., `research_agent.py`, `writer_agent.py`).\n      - `tasks/`: Contains task definitions (e.g., `research_task.py`, `writing_task.py`).\n      - `tools/`: Contains custom tools for agents (e.g., `web_search.py`, `data_analysis.py`).\n      - `models/`: Contains Pydantic models for structured LLM responses (e.g., `article_summary.py`).\n      - `utils/`: Contains utility functions and helper classes (e.g., `api_utils.py`, `string_formatter.py`).\n      - `config/`: Configuration files (e.g., `config.yaml`, `api_keys.json`). **Important:** Never commit API keys directly to the repo. Use environment variables or secure vault.\n      - `tests/`: Unit and integration tests.\n      - `main.py`: Entry point for the CrewAI application.\n      - `requirements.txt` or `pyproject.toml`: Project dependencies.\n  - **File Naming Conventions:**\n    - Use descriptive, lowercase names with underscores (e.g., `data_processing_agent.py`).\n    - Pydantic models should be singular (e.g., `ArticleSummary.py` -> `article_summary.py` and class `ArticleSummary`)\n    - Tests should mirror the source file name with a `_test` suffix (e.g., `data_processing_agent_test.py`).\n  - **Module Organization:**\n    - Group related agents, tasks, and tools into separate modules.\n    - Use clear and concise module names.\n    - Avoid circular dependencies between modules.\n  - **Component Architecture:**\n    - Follow a layered architecture (e.g., agent layer, task layer, tool layer).\n    - Design components with single responsibilities (Single Responsibility Principle).\n    - Prefer composition over inheritance for agent and task configurations.\n  - **Code Splitting:**\n    - Break down complex tasks into smaller, manageable subtasks.\n    - Use helper functions and classes to encapsulate reusable logic.\n    - Consider using a task orchestration framework (e.g., Celery, Dask) for asynchronous task execution if you have long running tasks.\n\n- **Common Patterns and Anti-patterns**:\n  - **Design Patterns:**\n    - **Hierarchical Task Delegation:** Implement a manager agent to oversee task execution and validate outcomes.\n    - **Tool Abstraction:** Create a tool abstraction layer to allow agents to interact with different tools seamlessly.\n    - **Observer Pattern:**  Implement an observer pattern to monitor task progress and trigger events.\n  - **Recommended Approaches:**\n    - Define clear roles for each agent.\n    - Utilize advanced CrewAI features for task delegation.\n    - Ensure efficient communication among agents through well-defined task interfaces.\n  - **Anti-patterns:**\n    - Hardcoding API keys or sensitive information in the code.\n    - Creating overly complex or tightly coupled agents.\n    - Ignoring error handling and validation.\n    - Neglecting proper logging and monitoring.\n    - Allowing agents unrestricted access to tools and resources.\n  - **State Management:**\n    - Use agent's memory (the `memory` attribute) to persist state between tasks.\n    - Consider using a dedicated state management library (e.g., Redis, Memcached) for complex applications.\n    - Ensure that state is properly serialized and deserialized.\n  - **Error Handling:**\n    - Implement try-except blocks to handle exceptions gracefully.\n    - Log errors with detailed information for debugging.\n    - Define custom exception types for specific error scenarios.\n    - Use retry mechanisms for transient errors (e.g., network timeouts).\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Optimize LLM calls by using smaller context windows where possible.\n    - Cache LLM responses to avoid redundant calls.\n    - Use asynchronous operations for I/O-bound tasks.\n    - Optimize tools and utilities for performance.\n    - Implement rate limiting for API calls to avoid exceeding limits.\n  - **Memory Management:**\n    - Be mindful of the memory footprint of agents and tasks.\n    - Avoid storing large amounts of data in agent memory.\n    - Use generators for processing large datasets.\n    - Release resources promptly after use.\n  - **Bundle Size Optimization:** Not directly applicable to CrewAI but important for related web apps or interfaces.\n  - **Lazy Loading:** Not directly applicable to CrewAI but important for related web apps or interfaces.\n\n- **Security Best Practices**:\n  - **Common Vulnerabilities:**\n    - Prompt injection attacks.\n    - Data breaches due to insecure storage of sensitive information.\n    - Unauthorized access to tools and resources.\n  - **Input Validation:**\n    - Validate all inputs from users and external sources.\n    - Sanitize inputs to prevent code injection attacks.\n    - Use regular expressions or validation libraries to enforce input constraints.\n  - **Authentication and Authorization:**\n    - Implement authentication to verify the identity of users and agents.\n    - Use authorization to control access to tools and resources.\n    - Follow the principle of least privilege: grant agents only the necessary permissions.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms for API keys and credentials.\n    - Implement data masking to protect sensitive information.\n    - Comply with relevant data privacy regulations (e.g., GDPR, CCPA).\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement API rate limiting to prevent abuse.\n    - Validate API responses to prevent data corruption.\n    - Use secure authentication mechanisms for API access.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Write unit tests for individual agents, tasks, and tools.\n    - Use mocking and stubbing to isolate components during testing.\n    - Assert that components behave as expected under different conditions.\n  - **Integration Testing:**\n    - Write integration tests to verify the interactions between different components.\n    - Test the end-to-end flow of a CrewAI application.\n    - Use realistic test data to simulate real-world scenarios.\n  - **End-to-end Testing:**\n    - Use tools like Selenium or Playwright to test the entire application flow.\n    - Verify that the application meets the specified requirements.\n    - Test the application in different environments.\n  - **Test Organization:**\n    - Organize tests into separate modules that mirror the source code structure.\n    - Use descriptive test names.\n    - Follow a consistent testing style.\n  - **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to replace external dependencies with mock objects.\n    - Use stubbing to provide canned responses for external dependencies.\n    - Verify that mock objects are called as expected.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Using overly complex prompts that are difficult to understand and maintain.\n    - Failing to handle errors and exceptions gracefully.\n    - Neglecting to validate inputs and outputs.\n    - Not monitoring and logging application behavior.\n  - **Edge Cases:**\n    - Handling unexpected LLM responses.\n    - Dealing with rate limits and API errors.\n    - Managing long-running tasks.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between CrewAI versions.\n    - Consult the CrewAI changelog for information about new features and bug fixes.\n    - Test your application with different CrewAI versions to ensure compatibility.\n  - **Compatibility Concerns:**\n    - Ensure that CrewAI is compatible with the other libraries and frameworks used in your application.\n    - Be aware of potential conflicts between different versions of dependencies.\n  - **Debugging Strategies:**\n    - Use logging to track application behavior.\n    - Use a debugger to step through the code and inspect variables.\n    - Use print statements to debug simple issues.\n    - Use the CrewAI debugger and introspection tools.\n\n- **Tooling and Environment**:\n  - **Recommended Tools:**\n    - VS Code, PyCharm\n    - Debugger: pdb, ipdb\n    - Profiler: cProfile\n  - **Build Configuration:**\n    - Use `pyproject.toml` for managing dependencies and build settings.\n    - Use Poetry or pip-tools for dependency management.\n  - **Linting and Formatting:**\n    - Use Black for code formatting.\n    - Use Pylint or Flake8 for code linting.\n    - Configure pre-commit hooks to automatically format and lint code before committing.\n  - **Deployment:**\n    - Containerize your CrewAI application using Docker.\n    - Deploy your application to a cloud platform (e.g., AWS, Google Cloud, Azure).\n    - Use a deployment framework (e.g., Docker Compose, Kubernetes) to manage your application.\n  - **CI/CD Integration:**\n    - Use a CI/CD platform (e.g., GitHub Actions, GitLab CI, Jenkins) to automate the build, test, and deployment process.\n    - Write automated tests for your application.\n    - Configure CI/CD pipelines to run tests and deploy your application on every commit.\n\n- **LLMs and CrewAI**\n  - CrewAI uses LLMs to provide context, enable decision-making, and generate human-like responses in the agents.\n  - Configure LLMs with environment variables or advanced features for optimization.\n  - Available Models and Capabilities:\n    - GPT-4: High-accuracy tasks, complex reasoning, 8,192 tokens\n    - GPT-4 Turbo: Long-form content, document analysis, 128,000 tokens\n    - GPT-4o & GPT-4o-mini: Cost-effective large context processing, 128,000 tokens\n    - o3-mini: Fast reasoning, complex reasoning, 200,000 tokens\n  - Structured LLM calls can be used for defining response formats using Pydantic models.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "crewai.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "crewai",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "library",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "crewai",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-css",
    "description": "This rule provides best practices for CSS development, covering code organization, performance, security, testing, and common pitfalls. It aims to ensure maintainable, scalable, and efficient CSS code.",
    "author": "sanjeed5",
    "tags": [
      "css",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/css.mdc",
    "content": "- **Use a CSS Preprocessor**: Leverage preprocessors like Sass, Less, or Stylus for features like variables, nesting, mixins, and functions to enhance code organization and maintainability.\n\n- **Code Organization and Structure**:\n  - **Directory Structure**: Organize CSS files into logical directories based on functionality (e.g., `components`, `modules`, `pages`, `themes`).\n  - **File Naming Conventions**: Use meaningful and consistent file names (e.g., `button.css`, `header.module.css`). Consider using a naming convention like BEM (Block, Element, Modifier) or SUIT CSS.\n  - **Module Organization**: Break down large stylesheets into smaller, reusable modules.\n  - **Component Architecture**: Structure CSS based on UI components, ensuring each component has its dedicated stylesheet.\n  - **Code Splitting**: Split CSS into critical (above-the-fold) and non-critical CSS for improved initial page load time. Utilize tools like `Critical CSS` or `PurgeCSS`.\n\n- **Formatting and Style**:\n  - **Indentation**: Use soft-tabs with two spaces for indentation.\n  - **Trailing Whitespace**: Avoid trailing whitespace.\n  - **Declaration Order**: Maintain a consistent declaration order (e.g., alphabetical, grouping related properties).\n  - **Property Units**: Use appropriate units (e.g., `rem` or `em` for font sizes, `vw` or `%` for responsive layouts).\n  - **Quotation**: Use double quotes for attribute values in selectors.\n  - **Line Length**: Keep lines reasonably short (e.g., under 80-100 characters) for readability.\n\n- **Common Patterns and Anti-patterns**:\n  - **BEM (Block, Element, Modifier)**: Use BEM or similar methodologies for clear and maintainable class naming.\n  - **Object-Oriented CSS (OOCSS)**: Apply OOCSS principles to create reusable and scalable styles.\n  - **Avoid !important**: Minimize the use of `!important` to prevent specificity conflicts.\n  - **Avoid Inline Styles**: Prefer external stylesheets or embedded styles over inline styles for better maintainability and separation of concerns.\n  - **Don't use IDs for styling**: Avoid using IDs for styling since they are too specific and make styles harder to override.\n\n- **Understanding CSS Specificity**: Master CSS specificity rules to avoid unexpected style conflicts. Use specific selectors sparingly.\n\n- **Use Flexible/Relative Units**: Employ relative units like `em`, `rem`, and `vw` for creating responsive designs that adapt to different screen sizes.\n\n- **Performance Considerations**:\n  - **Optimize Selectors**: Use efficient CSS selectors to minimize rendering time. Avoid overly complex selectors.\n  - **Minify CSS**: Minify CSS files to reduce file size and improve loading times.\n  - **Compress CSS**: Use Gzip or Brotli compression on the server to further reduce CSS file sizes.\n  - **Browser Caching**: Leverage browser caching to store CSS files locally, reducing server load and improving performance.\n  - **Avoid Expensive Properties**: Avoid CSS properties that are computationally expensive (e.g., `filter`, `box-shadow` with large blur radii) when possible.\n\n- **Security Best Practices**:\n  - **Sanitize User Input**: When using CSS variables based on user input, sanitize the input to prevent CSS injection attacks.\n  - **Content Security Policy (CSP)**: Implement a CSP to control the sources from which CSS can be loaded.\n\n- **Testing Approaches**:\n  - **Unit Testing**: Use tools like `CSS Modules` or `styled-components` to write unit tests for individual CSS components.\n  - **Visual Regression Testing**: Implement visual regression testing to detect unexpected changes in CSS styles.\n  - **Linting**: Use a CSS linter (e.g., `stylelint`) to enforce coding standards and catch potential errors.\n\n- **Common Pitfalls and Gotchas**:\n  - **Specificity Conflicts**: Be aware of specificity issues and use tools to visualize and manage CSS specificity.\n  - **Browser Compatibility**: Test CSS across different browsers and versions to ensure compatibility.\n  - **Vendor Prefixes**: Use vendor prefixes when necessary but consider using tools like `autoprefixer` to automate the process.\n\n- **Tooling and Environment**:\n  - **CSS Linters**: Use `stylelint` to enforce coding standards and identify potential errors.\n  - **CSS Formatters**: Employ tools like `Prettier` to automatically format CSS code consistently.\n  - **Build Tools**: Integrate CSS compilation, minification, and optimization into your build process using tools like `Webpack`, `Parcel`, or `Gulp`.\n  - **CSS Modules**: Use CSS Modules to scope CSS classes locally and avoid naming conflicts.\n\n- **Additional Tips**:\n  - **Document CSS**: Add comments to explain complex or non-obvious CSS rules.\n  - **Keep CSS DRY (Don't Repeat Yourself)**: Reuse CSS code as much as possible using variables, mixins, and inheritance.\n  - **Regularly Review and Refactor**: Regularly review and refactor CSS code to maintain its quality and prevent code bloat.\n  - **Consider Accessibility**: Ensure CSS styles contribute to website accessibility (e.g., sufficient color contrast, proper use of semantic HTML).\n  - **Use CSS Variables (Custom Properties)**: Use CSS variables for theming and to manage values across your CSS.",
    "metadata": {
      "globs": "*.css",
      "format": "mdc",
      "originalFile": "css.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "css",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "organization",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "css",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-cuda",
    "description": "Enforces CUDA coding standards, performance optimizations, and best practices to ensure efficient and maintainable GPU-accelerated code. This rule provides guidance on code organization, memory management, error handling, and more.",
    "author": "sanjeed5",
    "tags": [
      "cuda",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/cuda.mdc",
    "content": "- # CUDA Best Practices Guide\n  This document outlines best practices for CUDA development, focusing on code organization, performance optimization, and common pitfalls.  It is based on NVIDIA's CUDA C++ Best Practices Guide and expands on it with more detailed recommendations.\n\n- ## 1. Code Organization and Structure\n\n  - ### 1.1 Directory Structure\n    - Organize your CUDA project with a clear directory structure.  A common structure includes:\n      \n      project_root/\n      ├── src/\n      │   ├── kernels/      # CUDA kernel source files (.cu)\n      │   ├── host/         # Host-side code (.cpp, .h)\n      │   ├── common/       # Shared utility code (.h, .cpp)\n      │   └── include/      # Header files\n      ├── build/            # Build output directory\n      ├── data/             # Input and output data\n      ├── tests/           # Unit and integration tests\n      └── CMakeLists.txt  # CMake build configuration\n      \n\n  - ### 1.2 File Naming Conventions\n    - Use descriptive file names that clearly indicate the purpose of the file.\n      - Kernel files: `kernel_name.cu` (e.g., `matrix_multiply.cu`)\n      - Host files: `module_name.cpp`, `module_name.h` (e.g., `data_loader.cpp`, `data_loader.h`)\n      - Common files: `utility.h`, `error_handling.cpp`\n\n  - ### 1.3 Module Organization\n    - Divide your code into logical modules based on functionality.\n    - Use namespaces to avoid naming conflicts and improve code organization.\n    - Encapsulate CUDA kernel launches within well-defined functions or classes.\n\n  - ### 1.4 Component Architecture\n    - Design your application with a modular component architecture to facilitate code reuse and maintainability.\n    - Decouple host-side code from CUDA kernels as much as possible.\n    - Use abstraction layers to hide CUDA-specific details from higher-level components.\n\n  - ### 1.5 Code Splitting Strategies\n    - Split large CUDA kernels into smaller, more manageable functions.\n    - Use separate files for different kernels or related functionalities.\n    - Consider using template metaprogramming to generate specialized kernels at compile time.\n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### 2.1 Design Patterns Specific to CUDA\n    - **CUDA Stream Pattern:** Use CUDA streams to overlap data transfers and kernel execution.\n    - **Memory Pooling Pattern:** Implement memory pools to reduce the overhead of frequent memory allocations and deallocations.\n    - **Tiling Pattern:** Divide large data structures into smaller tiles to improve data locality and cache utilization.\n    - **Reduction Pattern:** Use parallel reduction algorithms to efficiently compute aggregate values.\n\n  - ### 2.2 Recommended Approaches for Common Tasks\n    - **Error Handling:** Use the CUDA error handling API to check for errors after each CUDA function call.\n    - **Memory Allocation:** Use `cudaMalloc`, `cudaFree`, and related functions for memory allocation on the device.\n    - **Data Transfer:** Use `cudaMemcpy` to transfer data between host and device memory.\n    - **Kernel Launch:** Use the `<<<gridDim, blockDim, sharedMem>>>` syntax to launch CUDA kernels.\n\n  - ### 2.3 Anti-patterns and Code Smells to Avoid\n    - **Synchronous Memory Transfers:** Avoid blocking memory transfers that stall the GPU.\n    - **Excessive Global Memory Access:** Minimize global memory access by using shared memory and registers.\n    - **Thread Divergence:** Avoid conditional branches that cause threads within a warp to execute different code paths.\n    - **Uncoalesced Memory Access:** Ensure that threads access memory in a coalesced manner to maximize memory bandwidth.\n    - **CPU-GPU Synchronization Bottlenecks:**  Minimize the number of synchronization points between the CPU and GPU.\n\n  - ### 2.4 State Management Best Practices\n    - Encapsulate CUDA context and device management within a dedicated class or module.\n    - Avoid global state variables that can lead to unexpected behavior and concurrency issues.\n    - Use RAII (Resource Acquisition Is Initialization) to ensure that CUDA resources are properly released.\n\n  - ### 2.5 Error Handling Patterns\n    - Check the return value of every CUDA function call and handle errors appropriately.\n    - Use `cudaGetLastError` to retrieve the last error that occurred on the device.\n    - Implement custom error handling routines for specific error conditions.\n    - Log error messages with file name, line number, and a descriptive error message.\n\n- ## 3. Performance Considerations\n\n  - ### 3.1 Optimization Techniques\n    - **Kernel Fusion:** Combine multiple kernels into a single kernel to reduce kernel launch overhead and data transfers.\n    - **Loop Unrolling:** Unroll loops to improve instruction-level parallelism.\n    - **Instruction Scheduling:** Optimize instruction scheduling to reduce pipeline stalls.\n    - **Constant Memory Usage:** Store frequently accessed read-only data in constant memory.\n    - **Texture Memory Usage:** Utilize texture memory for spatially coherent data access patterns.\n\n  - ### 3.2 Memory Management\n    - **Minimize Data Transfers:** Reduce the amount of data transferred between host and device.\n    - **Asynchronous Data Transfers:** Use asynchronous memory transfers with CUDA streams to overlap computation and communication.\n    - **Zero-Copy Memory:** Use zero-copy memory to directly access host memory from the GPU (use with caution due to performance implications).\n    - **Pinned Memory (Page-Locked Memory):** Use pinned memory for efficient asynchronous data transfers.\n\n  - ### 3.3 CUDA Profiler\n    - Use the NVIDIA Nsight Systems and Nsight Compute profilers to identify performance bottlenecks.\n\n- ## 4. Security Best Practices\n\n  - ### 4.1 Common Vulnerabilities and How to Prevent Them\n    - **Buffer Overflows:** Carefully validate input sizes to prevent buffer overflows in CUDA kernels.\n    - **Integer Overflows:** Check for potential integer overflows in calculations involving data sizes and indices.\n    - **Race Conditions:** Protect shared data with appropriate synchronization mechanisms (e.g., atomic operations, mutexes) to prevent race conditions.\n    - **Injection Attacks:** Sanitize input data to prevent injection attacks that could execute arbitrary code on the GPU.\n\n  - ### 4.2 Input Validation\n    - Validate all input data received by CUDA kernels to ensure that it is within the expected range and format.\n    - Check for invalid or malicious input that could lead to security vulnerabilities.\n\n  - ### 4.3 Data Protection Strategies\n    - Encrypt sensitive data stored on the GPU to protect it from unauthorized access.\n    - Use secure communication channels to transfer data between host and device.\n\n- ## 5. Testing Approaches\n\n  - ### 5.1 Unit Testing Strategies\n    - Write unit tests to verify the correctness of individual CUDA kernels and host-side functions.\n    - Use a testing framework like Google Test or Catch2 to automate the testing process.\n    - Mock CUDA runtime functions to isolate kernels during testing.\n    - Use a separate compilation approach to test individual kernel functions.\n\n  - ### 5.2 Integration Testing\n    - Perform integration tests to verify the interaction between different components of the CUDA application.\n    - Test data transfers between host and device, kernel launches, and error handling.\n\n  - ### 5.3 Test Organization\n    - Organize your tests into a logical directory structure.\n    - Use descriptive test names that clearly indicate the purpose of each test.\n    - Group related tests together into test suites.\n\n  - ### 5.4 Mocking and Stubbing\n    - Use mocking and stubbing techniques to isolate components during testing and simulate different scenarios.\n    - Mock CUDA runtime functions to control the behavior of the GPU during testing.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### 6.1 Frequent Mistakes Developers Make\n    - **Ignoring CUDA Error Codes:** Always check the return values of CUDA functions to ensure that they succeed.\n    - **Incorrect Grid and Block Dimensions:** Choose appropriate grid and block dimensions for your kernels.\n    - **Shared Memory Bank Conflicts:** Avoid shared memory bank conflicts to maximize memory bandwidth.\n    - **Thread Divergence:** Minimize thread divergence within warps to improve performance.\n    - **Uncoalesced Memory Access:** Ensure that threads access memory in a coalesced manner.\n\n  - ### 6.2 Version-Specific Issues\n    - Be aware of compatibility issues between different CUDA versions.\n    - Use conditional compilation to handle version-specific code.\n\n  - ### 6.3 Debugging Strategies\n    - Use the NVIDIA Nsight Systems and Nsight Compute debuggers to debug CUDA code.\n    - Insert print statements to track the execution flow and variable values.\n    - Use the `cudaDeviceSynchronize` function to force the GPU to complete all operations before proceeding.\n\n- ## 7. Tooling and Environment\n\n  - ### 7.1 Recommended Development Tools\n    - **CUDA Toolkit:** Install the latest version of the CUDA Toolkit from NVIDIA's website.\n    - **NVIDIA Nsight Systems and Nsight Compute:** Use the Nsight profilers to analyze and optimize CUDA code.\n    - **CMake:** Use CMake to manage the build process.\n    - **Integrated Development Environment (IDE):** Use an IDE such as Visual Studio or Eclipse with CUDA support.\n\n  - ### 7.2 Build Configuration\n    - Use CMake to generate build files for your target platform.\n    - Configure the CUDA compiler (nvcc) with appropriate optimization flags.\n\n  - ### 7.3 Linting and Formatting\n    - Use a linter such as clang-tidy to enforce coding standards and identify potential errors.\n    - Use a code formatter such as clang-format to ensure consistent code formatting.",
    "metadata": {
      "globs": "*.cu",
      "format": "mdc",
      "originalFile": "cuda.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "cuda",
      "enforces",
      "coding",
      "standards",
      "performance",
      "optimizations",
      "best",
      "practices",
      "ensure",
      "efficient",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "cuda",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-customtkinter",
    "description": "This rule provides best practices for developing efficient, maintainable, and scalable GUI applications with CustomTkinter. It covers code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "customtkinter",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/customtkinter.mdc",
    "content": "- **Always use UV when installing dependencies.**\n- **Always use Python 3.10 or higher.** CustomTkinter requires a modern Python version for compatibility and feature support.\n- **Prefer an object-oriented approach.** Encapsulate UI elements and logic within classes for better organization, maintainability, and scalability. Avoid procedural coding for complex applications.\n- **Use virtual environments.**  Create isolated environments for each project to manage dependencies and avoid conflicts.\n- **Use descriptive variable and function names.**  Clear and concise names improve code readability.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - Project Root\n        - `src/` (Source code)\n            - `gui/` (CustomTkinter-related modules)\n                - `__init__.py`\n                - `main_window.py` (Main application window)\n                - `components/` (Reusable UI components)\n                    - `__init__.py`\n                    - `button.py`\n                    - `label.py`\n                - `models/` (Data models if applicable)\n                    - `__init__.py`\n                    - `user.py`\n            - `utils/` (Utility functions and helpers)\n                - `__init__.py`\n                - `config.py`\n                - `helpers.py`\n            - `services/` (API interaction services)\n                - `__init__.py`\n                - `api_service.py`\n        - `tests/` (Tests)\n            - `__init__.py`\n            - `gui/`\n                - `test_main_window.py`\n            - `utils/`\n                - `test_helpers.py`\n        - `data/` (Data files, configuration files)\n        - `requirements.txt` (Dependencies)\n        - `README.md` (Project documentation)\n        - `.gitignore`\n        - `LICENSE`\n        - `pyproject.toml` or `setup.py`\n\n- **File Naming Conventions:**\n    - Python files: `lowercase_with_underscores.py`\n    - Class names: `PascalCase` (e.g., `MainWindow`, `CustomButton`)\n    - Variable names: `lowercase_with_underscores` (e.g., `main_window`, `button_text`)\n    - Constants: `UPPERCASE_WITH_UNDERSCORES` (e.g., `DEFAULT_FONT`, `API_KEY`)\n\n- **Module Organization:**\n    - Group related functionalities into separate modules.\n    - Use `__init__.py` files to define packages and control namespace imports.\n    - Keep modules focused on a single responsibility.\n\n- **Component Architecture:**\n    - Divide the UI into reusable components (e.g., buttons, labels, forms).\n    - Create custom widget classes by inheriting from `customtkinter.CTkBaseClass` or other appropriate customtkinter base classes.\n    - Utilize the Model-View-Controller (MVC) or Model-View-ViewModel (MVVM) design pattern to separate UI logic from data and presentation.\n\n- **Code Splitting:**\n    - Break down large UI components into smaller, manageable parts.\n    - Use functions and methods to encapsulate specific actions.\n    - Consider creating separate modules for complex features.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **MVC (Model-View-Controller):** Separate data (Model), UI (View), and user input handling (Controller).\n    - **MVVM (Model-View-ViewModel):** Similar to MVC, but uses a ViewModel to mediate between the Model and View.\n    - **Observer:** Implement event handling and notifications between components.\n    - **Factory:** Create UI elements dynamically based on configuration or user input.\n    - **Singleton:** Ensures a class only has one instance.\n\n- **Recommended Approaches:**\n    - **Dynamic UI updates:** Use `configure()` to modify widget properties instead of recreating widgets.\n    - **Data binding:**  Link UI elements to data models for automatic updates.\n    - **Theming:** Create reusable themes with consistent styles for your application.\n    - **Asynchronous Operations:** Use `after()` or `threading` module  to handle long-running tasks without blocking the main event loop.\n    - **Use `CTkFont`**: Use this to ensure that the correct font family is used, that is appropriate across all operating systems. \n\n- **Anti-patterns and Code Smells:**\n    - **God object:** Avoid creating a single class that handles too many responsibilities.\n    - **Global variables:** Minimize the use of global variables; use instance variables or dependency injection instead.\n    - **Deeply nested code:** Refactor complex conditional statements and loops into smaller, more readable functions.\n    - **Mixing grid() and pack() layout managers**: Stick to one layout manager per container to avoid unexpected behavior.\n\n- **State Management:**\n    - **Centralized state:** Use a dedicated state management class or library to store and manage application state (e.g., using the observer pattern). This can be a simple class for smaller apps, or something like RxPY for more complex state handling.\n    - **Immutable data:**  Treat state data as immutable and create new copies when modifying it to prevent unexpected side effects.\n    - **Observable state:** Use observable patterns to notify components when the state changes.\n\n- **Error Handling:**\n    - **Try-except blocks:** Wrap potentially failing code with `try-except` blocks to handle exceptions gracefully.\n    - **Logging:** Use the `logging` module to record errors and debug information.\n    - **User feedback:**  Provide informative error messages to the user.\n    - **Specific exception handling:** Handle exceptions in specific branches of your application, rather than catching all errors in a single block.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Minimize UI redraws:** Use `update_idletasks()` to refresh the UI without a full redraw, especially when making multiple changes to widgets.  Only update relevant portions of the UI.\n    - **Efficient layout management:** Choose the appropriate layout manager (grid or pack) and use it consistently.\n    - **Widget caching:** Reuse existing widgets instead of creating new ones whenever possible.\n    - **Batch updates:** Group multiple UI updates into a single operation to reduce the number of redraws.\n    - **Efficient image handling**: Use optimized image formats (e.g., WebP) and resize images appropriately for the UI.\n\n- **Memory Management:**\n    - **Avoid memory leaks:** Be careful with circular references and ensure that objects are properly released when they are no longer needed.\n    - **Resource cleanup:** Close files, release database connections, and other resources when they are no longer needed.\n\n- **Rendering Optimization:**\n    - **Reduce widget complexity:** Avoid using overly complex widgets or layouts.\n    - **Use hardware acceleration:**  Enable hardware acceleration if available to improve rendering performance. This is typically handled by Tkinter itself, but ensure your system supports it.\n\n- **Lazy Loading:**\n    - **Load UI elements on demand:** Load UI elements only when they are needed to reduce the initial load time.\n    - **Virtual scrolling:**  Implement virtual scrolling for large lists or grids to render only the visible items.\n    - **Use `after()` wisely:**  Delegate intensive tasks to run in the background using `after()` to prevent freezing.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Code injection:** Prevent code injection by validating and sanitizing user inputs.\n    - **Cross-site scripting (XSS):**  Escape user-generated content to prevent XSS attacks.\n    - **Data exposure:** Protect sensitive data by encrypting it and storing it securely.\n    - **Denial of Service (DoS):** Prevent DoS attacks by limiting the rate of requests and validating input sizes.\n\n- **Input Validation:**\n    - **Validate all user inputs:**  Check data types, formats, and ranges to prevent invalid data from entering the system.\n    - **Sanitize inputs:** Remove or escape potentially harmful characters from user inputs.\n    - **Use parameterized queries:**  Avoid SQL injection by using parameterized queries when interacting with databases.\n\n- **Authentication and Authorization:**\n    - **Secure password storage:** Use strong hashing algorithms (e.g., bcrypt, Argon2) to store passwords.\n    - **Two-factor authentication (2FA):**  Implement 2FA to enhance account security.\n    - **Role-based access control (RBAC):**  Control access to resources based on user roles.\n    - **Use HTTPS:** Always use HTTPS for secure communication between the client and server.\n\n- **Data Protection:**\n    - **Encryption:** Encrypt sensitive data both in transit and at rest.\n    - **Data masking:** Mask or redact sensitive data when displaying it to users.\n    - **Regular backups:**  Create regular backups of your data to prevent data loss.\n\n- **Secure API Communication:**\n    - **API keys:**  Store API keys securely and protect them from unauthorized access.\n    - **Rate limiting:**  Limit the rate of API requests to prevent abuse.\n    - **Input validation:**  Validate all data received from APIs.\n    - **HTTPS:**  Always use HTTPS when communicating with APIs.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - **Test individual components:**  Write unit tests for each component to ensure that it functions correctly.\n    - **Mock dependencies:**  Use mocking to isolate the component being tested from its dependencies.\n    - **Test edge cases:**  Test edge cases and boundary conditions to identify potential issues.\n    - **Use a testing framework:** Use pytest or unittest.\n\n- **Integration Testing:**\n    - **Test interactions between components:**  Write integration tests to ensure that components work together correctly.\n    - **Test API interactions:**  Test the interaction between the UI and the backend API.\n    - **Use a testing framework:** Use pytest or unittest.\n\n- **End-to-End Testing:**\n    - **Test the entire application workflow:**  Write end-to-end tests to simulate user interactions and ensure that the application functions correctly from start to finish.\n    - **Use a testing framework:** Use playwright or selenium. \n\n- **Test Organization:**\n    - **Separate test files:** Create separate test files for each module or component.\n    - **Follow a consistent naming convention:** Use a consistent naming convention for test files and functions (e.g., `test_<module_name>.py`, `test_<function_name>`).\n\n- **Mocking and Stubbing:**\n    - **Use mocking libraries:**  Use libraries like `unittest.mock` or `pytest-mock` to create mock objects for dependencies.\n    - **Stub external services:**  Use stubs to replace external services with predictable responses during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Forgetting `self`:**  Forgetting to use `self` when accessing instance variables.\n    - **Incorrect layout management:**  Mixing `grid` and `pack` in the same container or not specifying proper row/column configurations.\n    - **Blocking the main loop:** Performing long-running operations in the main thread, causing the UI to freeze. Use `after()` or `threading` for background tasks.\n    - **Incorrect event handling:**  Not properly binding events to UI elements.\n    - **Using the same variable name for Tkinter elements**: Tkinter elements should be named descriptively so that they are not confused with other local variables.\n\n- **Edge Cases:**\n    - **Handling different screen resolutions:**  Test the UI on different screen resolutions to ensure that it looks correct.\n    - **Handling different operating systems:**  Test the UI on different operating systems to ensure that it functions correctly.\n    - **Handling different font sizes:**  Test the UI with different font sizes to ensure that the layout remains consistent.\n\n- **Version-Specific Issues:**\n    - **Check compatibility:**  Consult the CustomTkinter documentation for version-specific issues and compatibility information.\n\n- **Compatibility Concerns:**\n    - **Tkinter versions:** Ensure compatibility between CustomTkinter and the underlying Tkinter version.\n    - **Operating system:**  Test the application on different operating systems to identify potential compatibility issues.\n    - **Python versions:** Ensure that the application is compatible with the target Python versions.\n\n- **Debugging Strategies:**\n    - **Use print statements:**  Insert `print` statements to debug code and inspect variable values.\n    - **Use a debugger:** Use a debugger to step through code and inspect the execution flow.\n    - **Read error messages:**  Carefully read error messages to understand the root cause of the problem.\n\n## 7. Tooling and Environment\n\n- **Recommended Tools:**\n    - **Text editor:** VS Code with Python extension.\n    - **Virtual environment manager:** `venv` or `conda`.\n    - **Package manager:** `pip` or `poetry`.\n    - **Testing framework:** `pytest`.\n    - **Linting and formatting:** `pylint` or `flake8` and `black` or `autopep8`.\n\n- **Build Configuration:**\n    - **Use `pyproject.toml` or `setup.py`:**  Define project metadata, dependencies, and build instructions in `pyproject.toml` or `setup.py`.\n    - **Specify dependencies:**  List all dependencies in `requirements.txt` or `pyproject.toml`.\n\n- **Linting and Formatting:**\n    - **Configure linting rules:**  Configure linting tools to enforce code style and identify potential issues.\n    - **Use a formatter:** Use a code formatter to automatically format code according to a consistent style guide.\n    - **Integrate with CI/CD:** Integrate linting and formatting checks into the CI/CD pipeline.\n\n- **Deployment:**\n    - **Package the application:** Package the application into an executable or installer using tools like `pyinstaller` or `cx_Freeze`.\n    - **Create a virtual environment:** Create a virtual environment for the application and include all dependencies.\n    - **Follow platform-specific guidelines:** Follow platform-specific guidelines for deploying applications.\n\n- **CI/CD Integration:**\n    - **Automate testing:**  Automate unit, integration, and end-to-end tests in the CI/CD pipeline.\n    - **Automate linting and formatting:**  Automate linting and formatting checks in the CI/CD pipeline.\n    - **Automate deployment:**  Automate the deployment process in the CI/CD pipeline.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "customtkinter.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "customtkinter",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "developing",
      "efficient",
      "maintainable",
      "scalable",
      "applications",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "customtkinter",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-cypress",
    "description": "This rule provides a comprehensive guide to Cypress best practices, covering code organization, performance, security, testing strategies, and tooling to ensure robust and maintainable end-to-end tests.",
    "author": "sanjeed5",
    "tags": [
      "cypress",
      "testing",
      "e2e",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "quality-testing",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/cypress.mdc",
    "content": "# Cypress Best Practices: A Comprehensive Guide\n\nThis guide provides a comprehensive set of best practices for using Cypress, a popular end-to-end testing framework for web applications. Following these guidelines will help you write more robust, maintainable, and efficient tests.\n\n## 1. Code Organization and Structure\n\nGood code organization is crucial for maintaining large Cypress test suites. Here are recommendations for structuring your project:\n\n### Directory Structure\n\n\ncypress/\n├── e2e/                   # End-to-end tests\n│   ├── example.cy.js    # Example test file\n│   └── ...\n├── fixtures/            # Test data\n│   ├── example.json     # Example fixture file\n│   └── ...\n├── support/             # Custom commands and utility functions\n│   ├── commands.js      # Custom Cypress commands\n│   ├── e2e.js           # Runs before each test file\n│   └── ...\n├── downloads/           # Directory for downloaded files from tests\n├── screenshots/        # Directory for screenshots of test failures\n├── videos/              # Directory for test execution videos\ncypress.config.js        # Cypress configuration file\npackage.json             # Node.js package file\n\n\n**Explanation:**\n\n*   `e2e/`: Contains your end-to-end tests. Organize tests by feature or component.\n*   `fixtures/`: Stores static test data (JSON files).  Use fixtures to avoid hardcoding data in your tests.\n*   `support/`: Holds custom commands and utility functions. This promotes code reuse and keeps tests concise.\n*   `downloads/`, `screenshots/`, `videos/`: Cypress automatically manages these directories for test artifacts.\n*   `cypress.config.js`: The main configuration file for Cypress.\n*   `package.json`: Standard Node.js package definition.\n\n### File Naming Conventions\n\n*   Test files: `[feature].cy.js` or `[component].spec.js` (e.g., `login.cy.js`, `userProfile.spec.js`).\n*   Fixture files: `[data_description].json` (e.g., `valid_user.json`, `product_details.json`).\n*   Custom command files: `[command_name].js` (if multiple command files are created in support/).\n\n### Module Organization\n\n*   **Custom Commands:** Place custom commands in `cypress/support/commands.js`. Create separate files for related commands and import them into `commands.js` to improve organization.\n*   **Page Objects:** If using the Page Object Model (see below), create separate files for each page object and store them in a dedicated directory (e.g., `cypress/page_objects/`).\n*   **Utility Functions:** Create utility functions for common tasks (e.g., data generation, API calls) and store them in `cypress/support/utils.js` or a similar named file/directory.\n\n### Component Architecture\n\nWhile Cypress is primarily for end-to-end testing, thinking in terms of components can help structure your tests:\n\n*   **Page Object Model (POM):** A design pattern where each page or section of the application is represented as a class.  The class contains selectors for elements on the page and methods for interacting with those elements.  This centralizes element selection and reduces code duplication. **Example:**\n\n    javascript\n    // cypress/page_objects/loginPage.js\n    class LoginPage {\n      getEmailField() {\n        return cy.get('[data-cy=\"email\"]');\n      }\n\n      getPasswordField() {\n        return cy.get('[data-cy=\"password\"]');\n      }\n\n      getSubmitButton() {\n        return cy.get('[data-cy=\"submit\"]');\n      }\n\n      login(email, password) {\n        this.getEmailField().type(email);\n        this.getPasswordField().type(password);\n        this.getSubmitButton().click();\n      }\n    }\n\n    export default new LoginPage();\n\n    // cypress/e2e/login.cy.js\n    import loginPage from '../page_objects/loginPage';\n\n    describe('Login', () => {\n      it('should log in successfully', () => {\n        cy.visit('/login');\n        loginPage.login('test@example.com', 'password');\n        cy.url().should('include', '/dashboard');\n      });\n    });\n    \n\n### Code Splitting\n\n*   Cypress doesn't directly support code splitting in the same way as a frontend application.  However, you can still organize your code into smaller, manageable files to improve maintainability and readability.  Use `require()` or ES module imports (`import/export`) to split your code into modules.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Page Object Model (POM):** See above. Encapsulates page-specific logic.\n*   **Custom Commands:** Create custom commands for frequently used actions.  This makes tests more readable and reduces code duplication.  **Example:**\n\n    javascript\n    // cypress/support/commands.js\n    Cypress.Commands.add('login', (email, password) => {\n      cy.request('POST', '/api/login', { email, password }).then((response) => {\n        cy.setCookie('auth_token', response.body.token);\n        cy.visit('/dashboard'); // Or however the app navigates\n      });\n    });\n\n    // cypress/e2e/dashboard.cy.js\n    describe('Dashboard', () => {\n      it('should display user information', () => {\n        cy.login('user@example.com', 'password');\n        cy.contains('Welcome, User');\n      });\n    });\n    \n*   **Fixtures:** Load test data from fixture files to keep tests data-driven and avoid hardcoding values.  **Example:**\n\n    javascript\n    // cypress/fixtures/user.json\n    {\n      \"email\": \"test@example.com\",\n      \"password\": \"password\"\n    }\n\n    // cypress/e2e/login.cy.js\n    describe('Login', () => {\n      it('should log in with valid credentials', () => {\n        cy.fixture('user').then((user) => {\n          cy.visit('/login');\n          cy.get('[data-cy=\"email\"]').type(user.email);\n          cy.get('[data-cy=\"password\"]').type(user.password);\n          cy.get('[data-cy=\"submit\"]').click();\n          cy.url().should('include', '/dashboard');\n        });\n      });\n    });\n    \n\n### Recommended Approaches for Common Tasks\n\n*   **Logging in:** Use `cy.request()` to programmatically log in (as shown in the examples above).  This is faster and more reliable than logging in through the UI.\n*   **Selecting elements:** Use `data-*` attributes for selecting elements. This makes tests more resilient to changes in CSS or JavaScript.\n*   **Waiting for API calls:** Use `cy.intercept()` to wait for specific API calls before proceeding with the test.  Avoid using `cy.wait()` with fixed timeouts.\n*   **Handling asynchronous operations:** Cypress automatically waits for elements to become available, so avoid using manual timeouts.\n\n### Anti-patterns and Code Smells\n\n*   **Hardcoding data:** Avoid hardcoding data directly in your tests. Use fixtures instead.\n*   **Using brittle selectors:** Avoid using CSS classes or IDs that are likely to change.\n*   **Relying on fixed timeouts:** Avoid using `cy.wait()` with fixed timeouts.  Use `cy.intercept()` or Cypress's built-in waiting mechanisms.\n*   **Chaining too many commands:** While command chaining is powerful, excessive chaining can make tests harder to read and debug. Break down complex chains into smaller, more manageable chunks.\n*   **Sharing state between tests:** Each test should be independent and not rely on the state left by other tests. Use `beforeEach()` to set up a clean state for each test.\n*   **Testing implementation details:** Tests should focus on the user's perspective and not test implementation details that are likely to change.\n*   **Ignoring error messages:** Pay attention to error messages and use them to debug your tests.\n*   **Over-reliance on UI for setup:** Where possible, programmatically set up the application state using `cy.request` to seed data or log in users directly rather than navigating through the UI for every test.\n\n### State Management\n\n*   Cypress tests should be independent and self-contained. Each test should set up its own initial state. Use `beforeEach()` hooks to reset the state before each test.\n*   Use `cy.request()` to seed data or log in users directly to set up the application state.\n*   Avoid sharing state between tests, as this can lead to unreliable and unpredictable results.  Use `cy.clearCookies()`, `cy.clearLocalStorage()`, and `cy.clearSessionStorage()` to clear data between tests.\n\n### Error Handling\n\n*   Cypress provides detailed error messages that can help you debug your tests.  Pay attention to these messages and use them to identify the root cause of the problem.\n*   Use `try...catch` blocks to handle errors in custom commands or utility functions.\n*   Use `Cypress.on('uncaught:exception', (err, runnable) => { ... })` to handle uncaught exceptions in the application.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Minimize UI interactions:** Use `cy.request()` to set up the application state instead of interacting with the UI.\n*   **Use `cy.intercept()` for waiting:** Wait for specific API calls instead of using fixed timeouts.\n*   **Run tests in parallel:** Cypress Cloud enables parallel test execution to reduce overall test time.\n*   **Optimize selectors:** Use efficient selectors that quickly locate elements.\n*   **Filter tests using tags:** Use tags to selectively run tests based on feature or component.\n\n### Memory Management\n\n*   Cypress runs in the browser, so memory management is generally handled by the browser.  However, it's important to be aware of potential memory leaks in your application.\n*   Avoid creating large data structures in your tests.\n*   Use `cy.clearCookies()`, `cy.clearLocalStorage()`, and `cy.clearSessionStorage()` to clear data between tests.\n\n### Rendering Optimization\n\n*   N/A - Cypress doesn't directly handle rendering. Rendering is handled by the application being tested.\n\n### Bundle Size Optimization\n\n*   The size of your test files can affect the performance of your tests.  Keep your test files as small as possible.\n*   Remove unused code from your test files.\n*   Use a bundler (e.g., Webpack, Parcel) to bundle your test files.\n\n### Lazy Loading\n\n*   N/A - Cypress doesn't directly support lazy loading. Lazy loading is a feature of the application being tested.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS vulnerabilities by properly escaping user input in your application.  Cypress can be used to test for XSS vulnerabilities by injecting malicious code into input fields and verifying that it is properly escaped.\n*   **Cross-Site Request Forgery (CSRF):** Prevent CSRF vulnerabilities by using CSRF tokens in your application.  Cypress can be used to test for CSRF vulnerabilities by attempting to submit forms without a valid CSRF token.\n*   **SQL Injection:** Prevent SQL injection vulnerabilities by using parameterized queries or an ORM.  Cypress can be used to test for SQL injection vulnerabilities by injecting malicious SQL code into input fields and verifying that it is properly escaped.\n\n### Input Validation\n\n*   Validate all user input on both the client-side and server-side.\n*   Use strong input validation to prevent malicious input from reaching your application.\n*   Cypress can be used to test input validation by providing invalid input and verifying that the application properly handles it.\n\n### Authentication and Authorization\n\n*   Use a secure authentication and authorization system.\n*   Use strong passwords and enforce password complexity requirements.\n*   Use multi-factor authentication for added security.\n*   Cypress can be used to test authentication and authorization by attempting to access protected resources without proper credentials.\n\n### Data Protection\n\n*   Protect sensitive data by encrypting it at rest and in transit.\n*   Use HTTPS to encrypt data in transit.\n*   Store sensitive data in a secure location.\n*   Cypress can be used to test data protection by verifying that sensitive data is properly encrypted.\n\n### Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Use API keys or other authentication mechanisms to protect your APIs.\n*   Validate all data received from APIs.\n*   Cypress can be used to test API security by attempting to access APIs without proper credentials or by sending invalid data.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   While Cypress excels at end-to-end testing, unit testing is still important for testing individual components in isolation.  Use a unit testing framework like Mocha or Jest for unit testing.\n*   For components that interact heavily with the UI, consider using Cypress Component Testing.\n\n### Integration Testing\n\n*   Integration tests verify that different parts of the application work together correctly.  Cypress can be used to write integration tests by testing the interactions between different components or services.\n\n### End-to-End Testing\n\n*   End-to-end tests verify that the entire application works correctly from the user's perspective.  Cypress is ideal for writing end-to-end tests.\n*   Focus on testing key user flows and critical functionality.\n\n### Test Organization\n\n*   Organize your tests by feature or component.\n*   Use descriptive names for your test files and test cases.\n*   Use tags to categorize your tests.\n*   Create a clear and consistent testing strategy.\n\n### Mocking and Stubbing\n\n*   **Mocking:** Replace a dependency with a mock object that simulates the behavior of the dependency.  Use `cy.stub()` to mock functions and `cy.intercept()` to mock API calls.\n*   **Stubbing:** Override the behavior of a function or API call with a predefined response. Use `cy.stub()` to stub functions and `cy.intercept()` to stub API calls.\n*   Use mocking and stubbing to isolate your tests and control the behavior of external dependencies.  This makes tests more predictable and reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   Using brittle selectors.\n*   Relying on fixed timeouts.\n*   Sharing state between tests.\n*   Testing implementation details.\n*   Ignoring error messages.\n*   Not using custom commands.\n*   Not using fixtures.\n*   Trying to test across different domains (Cypress has limitations here).\n\n### Edge Cases\n\n*   Handling complex UI interactions (e.g., drag-and-drop, file uploads).\n*   Testing asynchronous operations.\n*   Testing WebSockets.\n*   Testing iframes.\n*   Testing third-party integrations.\n\n### Version-Specific Issues\n\n*   Be aware of breaking changes in new versions of Cypress. Refer to the Cypress changelog for details.\n*   Test your tests after upgrading Cypress.\n\n### Compatibility Concerns\n\n*   Cypress primarily supports Chromium-based browsers (Chrome, Edge). Limited support for Firefox and experimental support for Safari.\n*   Be aware of compatibility issues between Cypress and other technologies (e.g., React, Angular, Vue.js).\n\n### Debugging Strategies\n\n*   Use the Cypress Test Runner to step through your tests and inspect the application state.\n*   Use the browser's developer tools to debug your tests.\n*   Use `console.log()` statements to log data to the console.\n*   Use `cy.pause()` to pause test execution and inspect the application state.\n*   Use Cypress Cloud for advanced debugging features such as time travel and video recording.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n*   **IDE:** Visual Studio Code with the Cypress extension.\n*   **Browser:** Chrome or Edge.\n*   **Node.js:** Latest LTS version.\n*   **NPM or Yarn:** Package managers.\n\n### Build Configuration\n\n*   Use a bundler (e.g., Webpack, Parcel) to bundle your test files.\n*   Configure your bundler to optimize your test files for performance.\n*   Use environment variables to configure your tests for different environments.\n\n### Linting and Formatting\n\n*   Use ESLint and Prettier to lint and format your code.\n*   Configure ESLint and Prettier to enforce consistent coding style.\n*   Use the Cypress ESLint plugin to catch common Cypress-specific errors.\n\n### Deployment\n\n*   Run your Cypress tests as part of your CI/CD pipeline.\n*   Use Cypress Cloud to run your tests in parallel and get detailed test results.\n*   Deploy your Cypress tests to a staging environment before deploying to production.\n\n### CI/CD Integration\n\n*   Integrate Cypress with your CI/CD pipeline (e.g., GitHub Actions, Jenkins, CircleCI).\n*   Run your Cypress tests automatically on every commit or pull request.\n*   Use Cypress Cloud to store your test results and track test history.\n*   Configure your CI/CD pipeline to fail if your Cypress tests fail.\n\nBy adhering to these best practices, you can create a robust and maintainable Cypress test suite that ensures the quality of your web application.",
    "metadata": {
      "globs": "*.cy.js,*.cy.ts,*.spec.js,*.spec.ts",
      "format": "mdc",
      "originalFile": "cypress.mdc"
    },
    "subcategory": "e2e-testing",
    "keywords": [
      "cursor",
      "cypress",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "testing",
      "e2e",
      "cursor-rule",
      "mdc",
      "quality-testing",
      "e2e-testing"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "cypress",
        "testing",
        "e2e",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "quality-testing"
    }
  },
  {
    "name": "cursor-d3",
    "description": "Comprehensive best practices and coding standards for D3.js projects, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "d3",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/d3.mdc",
    "content": "By following these best practices and coding standards, developers can create robust, maintainable, and performant data visualizations using the D3.js library.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "d3.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "d3",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "covering",
      "code",
      "organization",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "d3",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-dask",
    "description": "Comprehensive best practices and coding standards for using Dask in Python, focusing on performance, code organization, and common pitfalls. Provides actionable guidance for developers using Dask for parallel and distributed computing.",
    "author": "sanjeed5",
    "tags": [
      "dask",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/dask.mdc",
    "content": "# Dask Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing with Dask, focusing on code organization, performance optimization, security considerations, testing strategies, and common pitfalls to avoid. Following these guidelines will help ensure efficient, maintainable, and robust Dask applications.\n\n## Library Information:\n- Name: dask\n- Tags: ai, ml, data-science, python, parallel-computing, big-data\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability and collaboration. Here are best practices for structuring Dask projects:\n\n### 1.1 Directory Structure\n\nAdopt a logical directory structure that reflects the project's functionality.  A common structure might look like this:\n\n\nproject_root/\n├── data/              # Input datasets, sample data, etc.\n├── src/               # Source code\n│   ├── __init__.py\n│   ├── data_loading/   # Modules for data input and output\n│   │   ├── __init__.py\n│   │   ├── loaders.py   # Functions to load data from different formats (CSV, Parquet, etc.)\n│   │   └── writers.py   # Functions to write data\n│   ├── processing/      # Modules for data processing pipelines\n│   │   ├── __init__.py\n│   │   ├── transformations.py # Dask DataFrame transformations\n│   │   ├── aggregations.py  # Dask DataFrame aggregations and reductions\n│   │   └── utils.py         # Utility functions for processing\n│   ├── models/          # Modules for machine learning models and related code\n│   │   ├── __init__.py\n│   │   ├── train.py       # Training scripts\n│   │   ├── predict.py     # Prediction scripts\n│   │   └── evaluate.py    # Evaluation scripts\n│   ├── utils/           # General utility functions\n│   │   ├── __init__.py\n│   │   └── helpers.py     # Various helper functions\n│   └── visualization/   # Modules for visualization\n│       ├── __init__.py\n│       └── plots.py        # Plotting functions\n├── tests/             # Unit and integration tests\n│   ├── __init__.py\n│   ├── data_loading/   # Tests for data loading modules\n│   ├── processing/      # Tests for processing modules\n│   ├── models/          # Tests for machine learning models\n│   └── utils/           # Tests for utility modules\n├── notebooks/         # Jupyter notebooks for exploration and experimentation\n├── docs/              # Project documentation\n├── requirements.txt   # Python dependencies\n├── pyproject.toml     # Project configuration\n└── dask.yaml          # Dask configuration\n\n\n### 1.2 File Naming Conventions\n\n*   **Python files:** Use lowercase with underscores (e.g., `data_loader.py`, `processing_utils.py`).\n*   **Jupyter Notebooks:**  Descriptive names that clearly indicate the notebook's purpose (e.g., `exploratory_data_analysis.ipynb`, `model_training.ipynb`).\n*   **Configuration Files:**  Use standard names like `dask.yaml` for Dask configuration, and `requirements.txt` or `pyproject.toml` for dependencies.\n\n### 1.3 Module Organization\n\n*   **Keep modules focused:** Each module should have a clear and specific purpose. Avoid creating monolithic modules with unrelated functionality.\n*   **Use `__init__.py`:**  Include `__init__.py` files in subdirectories to make them importable as packages.\n*   **Relative imports:** Use relative imports within packages to avoid ambiguity and improve maintainability (e.g., `from . import utils` instead of `from project.src.utils import utils`).\n\n### 1.4 Component Architecture\n\n*   **Layered architecture:** Separate concerns into distinct layers (e.g., data loading, processing, modeling, visualization). This promotes modularity and testability.\n*   **Microservices (optional):** For larger applications, consider breaking down the application into smaller, independent microservices that communicate with each other.  Dask can be used within each microservice for parallel processing.\n*   **Dask Delayed:**  Use Dask Delayed to create a graph of computations, enabling parallel execution. Define functions using `@dask.delayed` and build up a workflow.\n\n### 1.5 Code Splitting\n\n*   **Functional decomposition:** Break down complex tasks into smaller, well-defined functions.\n*   **Lazy evaluation:**  Leverage Dask's lazy evaluation to defer computation until necessary. This allows you to build complex workflows without immediately executing them.\n*   **Chunking:**  Divide large datasets into smaller chunks that can be processed independently. Dask automatically handles the parallel processing of these chunks.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **MapReduce:** Dask excels at implementing the MapReduce pattern. Use `dask.dataframe.map_partitions` and `dask.array.map_blocks` to apply functions to individual partitions or blocks, followed by aggregations.\n*   **Data pipelines:**  Design data processing workflows as pipelines of Dask operations. This allows for efficient execution and easy modification.\n*   **Scatter/Gather:** Distribute data to workers using `client.scatter` and then collect the results using `client.gather`. This pattern is useful for distributing data that is needed by multiple tasks.\n\n### 2.2 Recommended Approaches\n\n*   **Start with Pandas/NumPy:** Prototype your code using Pandas and NumPy to ensure it works correctly before scaling up with Dask.\n*   **Use Dask collections:**  Prefer using Dask DataFrames and Arrays over Dask Delayed when working with tabular or numerical data.  Dask collections provide optimized implementations for common operations.\n*   **Leverage the Dask Dashboard:**  Use the Dask Dashboard to monitor task execution, resource usage, and identify performance bottlenecks.  The dashboard provides valuable insights into the behavior of your Dask application.\n\n### 2.3 Anti-patterns\n\n*   **Creating large Python objects outside of Dask:** Avoid creating large Pandas DataFrames or NumPy arrays outside of Dask and then passing them to Dask. Instead, let Dask load the data directly.  Use `dd.read_csv` or `da.from_array` instead of loading data with Pandas/NumPy and then converting to Dask.\n*   **Repeatedly calling `compute()`:**  Calling `compute()` multiple times on independent parts of a Dask graph forces Dask to recompute shared dependencies.  Instead, use `dask.compute()` to compute multiple results in a single call.\n*   **Over-partitioning:**  Creating too many small partitions can lead to excessive overhead.  Choose chunk sizes that are large enough to minimize overhead, but small enough to fit in memory.\n*   **Ignoring the Index:** If your DataFrame will be queried often on specific columns, setting those columns as the index can drastically improve performance.\n\n### 2.4 State Management\n\n*   **Minimize global state:**  Avoid using global variables within Dask tasks.  Instead, pass data explicitly as arguments to the tasks.\n*   **Immutable data:**  Treat data as immutable whenever possible.  This simplifies reasoning about the code and avoids unexpected side effects.\n*   **Dask futures for stateful computations:**  For stateful computations, use Dask futures to manage the state of individual tasks. This allows you to track the progress of each task and access its results.\n\n### 2.5 Error Handling\n\n*   **Try-except blocks:**  Use `try-except` blocks to handle exceptions that may occur within Dask tasks.  Log the exceptions and consider retrying the task.\n*   **Dask futures for exception handling:** Dask futures will propagate exceptions from tasks to the main thread. Handle these exceptions appropriately.\n*   **Task retries:**  Use the `retries` argument in `client.submit` to automatically retry failed tasks. This can be useful for handling transient errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Chunk Size Selection:** Choosing appropriate chunk sizes for your Dask arrays or DataFrames. Aim for sizes that allow multiple chunks to fit in memory without causing excessive overhead. A good rule of thumb is to keep chunks around 100 MB, which balances memory use and processing efficiency.\n*   **Persisting Data:** For large datasets, persist intermediate results in memory after initial processing steps to speed up subsequent computations. This reduces the need for repeated data loading and processing.\n*   **Minimizing Task Graph Size:** Minimize the number of tasks by fusing operations where possible and avoiding excessive partitioning. Large task graphs can lead to significant overhead that impacts performance.\n*   **Fusing operations:** Fuse multiple operations into a single task using `dask.delayed` or `dask.dataframe.map_partitions`. This reduces overhead and improves performance.\n*   **Data locality:**  Try to keep data close to the workers that are processing it. This minimizes data transfer and improves performance.  Use `client.scatter` to distribute data to specific workers.\n*   **Using the right scheduler:** The threaded scheduler works well for computations that are mostly CPU-bound. The process scheduler works well for computations that are I/O-bound or involve GIL-releasing operations.  The distributed scheduler is best for large-scale deployments.\n*   **Avoid Oversubscribing Threads:**  Explicitly set the number of threads used by NumPy's linear algebra routines to 1. Export the following environment variables before starting your python process: `export OMP_NUM_THREADS=1`, `export MKL_NUM_THREADS=1`, `export OPENBLAS_NUM_THREADS=1`\n\n### 3.2 Memory Management\n\n*   **Monitor memory usage:**  Use the Dask Dashboard to monitor memory usage and identify memory leaks.\n*   **Garbage collection:**  Explicitly call `gc.collect()` to free up memory that is no longer being used.\n*   **Avoid creating unnecessary copies of data:**  Use in-place operations whenever possible to avoid creating unnecessary copies of data.\n*   **Use `dask.cache` for caching intermediate results:** Cache intermediate results to avoid recomputing them.  This can significantly improve performance for iterative algorithms.\n\n### 3.3 Rendering Optimization\n\n*   **Optimize data transfer:** Reduce the amount of data that needs to be transferred for visualization. This can be done by downsampling the data or by aggregating it before transferring it.\n*   **Use efficient plotting libraries:** Use plotting libraries that are optimized for large datasets, such as Datashader or HoloViews.\n\n### 3.4 Bundle Size Optimization\n\n*   **Only import necessary Dask modules:** Only import the Dask modules that are needed by your application. This reduces the size of the application's dependencies.\n*   **Use tree shaking:** Use a build tool that supports tree shaking to remove unused code from the application's bundle.\n\n### 3.5 Lazy Loading\n\n*   **Dask Delayed:** Dask Delayed allows lazy evaluation of computations by building a graph of tasks that are executed only when the result is needed.\n*   **Dask DataFrames and Arrays:** These collections are lazily evaluated. Operations are not performed until `compute()` is called.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Arbitrary code execution:**  If Dask workers are exposed to untrusted networks, attackers may be able to execute arbitrary code on the workers.\n*   **Data leakage:**  Sensitive data may be leaked if Dask workers are not properly secured.\n\n### 4.2 Input Validation\n\n*   **Validate data types:**  Ensure that input data conforms to the expected types. Use schema validation libraries to enforce data quality.\n*   **Sanitize input data:**  Sanitize input data to prevent injection attacks.\n\n### 4.3 Authentication and Authorization\n\n*   **Use Dask's authentication mechanisms:** Use Dask's authentication mechanisms to secure access to the Dask cluster.  Dask supports various authentication methods, including password-based authentication and Kerberos authentication.\n*   **Implement authorization policies:** Implement authorization policies to restrict access to sensitive data and resources.\n\n### 4.4 Data Protection\n\n*   **Encrypt sensitive data:**  Encrypt sensitive data at rest and in transit.\n*   **Use secure storage:**  Store data in secure storage systems with appropriate access controls.\n*   **Regularly back up data:**  Regularly back up data to protect against data loss.\n\n### 4.5 Secure API Communication\n\n*   **Use HTTPS:**  Use HTTPS to encrypt communication between clients and the Dask cluster.\n*   **Use strong TLS ciphers:**  Configure the Dask cluster to use strong TLS ciphers.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test individual functions and classes:** Write unit tests for individual functions and classes to ensure they behave as expected.\n*   **Use a testing framework:**  Use a testing framework such as pytest or unittest to organize and run tests.\n*   **Mock external dependencies:**  Mock external dependencies to isolate the code being tested.\n\n### 5.2 Integration Testing\n\n*   **Test interactions between components:** Write integration tests to verify that different components of the Dask application work together correctly.\n*   **Test end-to-end workflows:** Write end-to-end tests to verify that the entire Dask application works as expected.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate real-world scenarios:** Design end-to-end tests that simulate real-world scenarios to ensure the Dask application can handle complex data and workloads.\n*   **Test performance:**  Include performance tests to verify that the Dask application meets performance requirements.\n\n### 5.4 Test Organization\n\n*   **Separate test directory:**  Create a separate `tests` directory to store all tests.\n*   **Mirror the source code structure:**  Organize tests in a way that mirrors the source code structure. This makes it easier to find the tests for a particular module.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use the `unittest.mock` module:**  Use the `unittest.mock` module to create mock objects for testing.\n*   **Mock Dask collections:** Mock Dask DataFrames and Arrays to isolate the code being tested.\n*   **Use dependency injection:** Use dependency injection to make it easier to mock dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Not understanding lazy evaluation:** Dask operations are lazy, meaning they are not executed until `compute()` is called. This can lead to unexpected behavior if you are not aware of it.\n*   **Incorrect chunk size selection:** Choosing the wrong chunk size can significantly impact performance. Experiment with different chunk sizes to find the optimal value for your workload.\n*   **Not persisting intermediate results:** Not persisting intermediate results can lead to repeated computations and poor performance.\n*   **Not using the Dask Dashboard:** The Dask Dashboard provides valuable insights into the behavior of your Dask application. Use it to monitor task execution, resource usage, and identify performance bottlenecks.\n\n### 6.2 Edge Cases\n\n*   **Empty DataFrames:** Be aware of how Dask handles empty DataFrames. Operations on empty DataFrames may return unexpected results.\n*   **Missing data:** Be aware of how Dask handles missing data (NaN values). Operations on DataFrames and Arrays with missing data may return unexpected results.\n\n### 6.3 Version-Specific Issues\n\n*   **API changes:**  Dask's API may change between versions. Be sure to consult the Dask documentation for the version you are using.\n*   **Bug fixes:**  New versions of Dask may include bug fixes that address issues you are experiencing. Consider upgrading to the latest version of Dask.\n\n### 6.4 Compatibility Concerns\n\n*   **Pandas and NumPy versions:**  Dask is compatible with specific versions of Pandas and NumPy. Be sure to use compatible versions of these libraries.\n*   **Other libraries:**  Dask may have compatibility issues with other libraries. Consult the Dask documentation for compatibility information.\n\n### 6.5 Debugging Strategies\n\n*   **Use the Dask Dashboard:**  Use the Dask Dashboard to monitor task execution and identify errors.\n*   **Set breakpoints:** Set breakpoints in your code to debug it using a debugger such as pdb or ipdb.\n*   **Log messages:** Add log messages to your code to track the execution flow and identify errors.\n*   **Use `dask.visualize()`:** Use `dask.visualize()` to visualize the Dask task graph. This can help you understand how Dask is executing your code and identify potential problems.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** VS Code, PyCharm, or other Python IDE.\n*   **Dask Dashboard:**  The Dask Dashboard is an essential tool for monitoring Dask applications.\n*   **Debugging tools:** pdb, ipdb, or other Python debuggers.\n*   **Profiling tools:** cProfile or other Python profiling tools.\n\n### 7.2 Build Configuration\n\n*   **Use `pyproject.toml`:**  Use `pyproject.toml` to specify the project's build dependencies and configuration.\n*   **Use a virtual environment:**  Use a virtual environment to isolate the project's dependencies.\n\n### 7.3 Linting and Formatting\n\n*   **Use a linter:**  Use a linter such as pylint or flake8 to check the code for style errors and potential problems.\n*   **Use a formatter:** Use a formatter such as black or autopep8 to automatically format the code.\n\n### 7.4 Deployment Best Practices\n\n*   **Choose the right Dask scheduler:** Choose the appropriate Dask scheduler for your deployment environment. The distributed scheduler is best for large-scale deployments.\n*   **Configure the Dask cluster:** Configure the Dask cluster to meet the needs of your application. Consider factors such as the number of workers, the amount of memory per worker, and the network bandwidth.\n*   **Monitor the Dask cluster:** Monitor the Dask cluster to ensure it is running correctly and meeting performance requirements.\n\n### 7.5 CI/CD Integration\n\n*   **Automate testing:** Automate the testing process using a CI/CD system such as Jenkins or GitLab CI.\n*   **Automate deployment:** Automate the deployment process using a CI/CD system.\n\nBy adhering to these comprehensive guidelines, you can develop robust, efficient, and maintainable Dask applications that leverage the full power of parallel and distributed computing.",
    "metadata": {
      "globs": "*.py,*.ipynb",
      "format": "mdc",
      "originalFile": "dask.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "dask",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "using",
      "python",
      "focusing",
      "performance",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "dask",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-databricks",
    "description": "This rule file provides comprehensive best practices for Databricks development, covering code organization, performance, security, testing, and common pitfalls. Adhering to these guidelines promotes maintainable, efficient, and secure Databricks applications.",
    "author": "sanjeed5",
    "tags": [
      "databricks",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/databricks.mdc",
    "content": "- **Follow these best practices to ensure maintainable, efficient, and secure Databricks applications.**\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n*   **Project Root:**\n    *   `src/`: Contains source code.\n        *   `jobs/`: Contains Databricks job definitions (Python, Scala, or notebooks).\n        *   `libraries/`: Contains reusable code modules (Python packages, JAR files).\n        *   `notebooks/`: Contains Databricks notebooks. Structure notebooks by function or data domain.\n        *   `sql/`: Contains SQL scripts for data transformations and queries.\n    *   `tests/`: Contains unit, integration, and end-to-end tests.\n    *   `config/`: Contains configuration files for different environments (dev, staging, prod).\n    *   `data/`: (Optional) Small sample datasets for development and testing.\n    *   `docs/`: Project documentation.\n    *   `scripts/`: Deployment and utility scripts.\n    *   `.databricks/`: Databricks CLI configuration.\n    *   `requirements.txt` or `pyproject.toml`: Python dependency management.\n    *   `build.sbt`: Scala build definition (if applicable).\n    *   `README.md`: Project overview and instructions.\n*   **Example:**\n\n\nmy_databricks_project/\n├── src/\n│   ├── jobs/\n│   │   ├── daily_etl.py\n│   │   └── model_training.py\n│   ├── libraries/\n│   │   ├── data_utils/\n│   │   │   ├── __init__.py\n│   │   │   ├── data_cleaning.py\n│   │   │   └── data_validation.py\n│   │   └── feature_engineering/\n│   ├── notebooks/\n│   │   ├── data_exploration.ipynb\n│   │   ├── model_evaluation.ipynb\n│   │   └── reporting.ipynb\n│   └── sql/\n│       ├── create_tables.sql\n│       └── transform_data.sql\n├── tests/\n│   ├── unit/\n│   ├── integration/\n│   └── e2e/\n├── config/\n│   ├── dev.conf\n│   ├── staging.conf\n│   └── prod.conf\n├── data/\n├── docs/\n├── scripts/\n├── .databricks/\n├── requirements.txt\n├── build.sbt\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   **Python scripts:** `lowercase_with_underscores.py`\n*   **SQL scripts:** `lowercase_with_underscores.sql`\n*   **Notebooks:** `descriptive-name.ipynb` (use hyphens for readability)\n*   **Configuration files:** `environment.conf` (e.g., `dev.conf`, `prod.conf`)\n*   **Data files:** `descriptive_name.csv`, `descriptive_name.parquet`\n*   **Scala files:** `PascalCaseName.scala`\n\n### 1.3. Module Organization\n\n*   **Separate Concerns:** Group related functions and classes into modules.\n*   **Avoid Circular Dependencies:** Ensure modules don't depend on each other in a circular way.\n*   **Use Packages:** Organize modules into packages for larger projects.\n*   **`__init__.py`:** Use `__init__.py` files to define packages in Python.\n*   **Relative Imports:** Use relative imports (`from . import module`) within packages.\n\n### 1.4. Component Architecture\n\n*   **Layered Architecture:** Consider a layered architecture with separate layers for data access, business logic, and presentation (notebooks).\n*   **Microservices:** For complex applications, consider breaking them down into smaller, independent microservices.\n*   **Data Lakehouse Architecture:** Leverage the Databricks Lakehouse architecture with Delta Lake for reliable and performant data storage.\n*   **Modular Notebooks:** Design notebooks as modular components with clear inputs and outputs.\n\n### 1.5. Code Splitting Strategies\n\n*   **Functions:** Break down large functions into smaller, reusable functions.\n*   **Modules:** Group related functions and classes into modules.\n*   **Libraries:** Create reusable libraries for common tasks.\n*   **Notebook Includes:** Use `%run` to include code from other notebooks.\n*   **DBUtils:** Use `dbutils.fs.cp` and other DBUtils functions for code reuse accross notebooks.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Data Lakehouse Pattern:** Use Delta Lake for ACID transactions, schema enforcement, and data versioning.\n*   **ETL/ELT Pattern:** Design data pipelines using ETL or ELT approaches.\n*   **Model-View-Controller (MVC):** (For complex applications) Separate data, logic, and presentation.\n*   **Singleton Pattern:** (Use carefully) For managing global resources.\n*   **Factory Pattern:** For creating objects in a flexible and decoupled way.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Ingestion:** Use Auto Loader for incremental data loading from cloud storage.\n*   **Data Transformation:** Use Spark DataFrames and SQL for data transformations.\n*   **Data Validation:** Implement data quality checks using Delta Lake constraints and custom validation functions.\n*   **Model Training:** Use MLflow for experiment tracking and model management.\n*   **Model Deployment:** Use Databricks Model Serving or MLflow Model Registry for model deployment.\n*   **Job Orchestration:** Use Databricks Jobs for scheduling and managing data pipelines.\n*   **Configuration Management:** Use Databricks secrets for storing sensitive information.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Hardcoding Values:** Avoid hardcoding values; use configuration files or environment variables.\n*   **Large Notebooks:** Break down large notebooks into smaller, modular notebooks.\n*   **Copy-Pasting Code:** Avoid copy-pasting code; create reusable functions and modules.\n*   **Ignoring Errors:** Handle errors gracefully and log them appropriately.\n*   **Inefficient Data Transformations:** Optimize data transformations using Spark best practices.\n*   **Over-commenting:** Comments should explain the *why* not the *what*.  Code should be self-documenting as much as possible.\n*   **Ignoring Code Style:** Follow a consistent code style (e.g., PEP 8 for Python).\n*   **Storing large dataframes in notebook's memory:** Instead store data in Delta tables or cloud storage.\n\n### 2.4. State Management\n\n*   **Stateless Transformations:** Design data transformations to be stateless whenever possible.\n*   **Delta Lake:** Use Delta Lake for managing state in data pipelines.\n*   **Databricks Secrets:** Use Databricks secrets for managing sensitive information such as API keys and passwords.\n*   **Configuration Files:** Externalize configurable data in configuration files.\n\n### 2.5. Error Handling\n\n*   **`try-except` Blocks:** Use `try-except` blocks to handle exceptions gracefully.\n*   **Logging:** Log errors and warnings to a central logging system.\n*   **Custom Exceptions:** Define custom exceptions for specific error conditions.\n*   **Retry Logic:** Implement retry logic for transient errors.\n*   **Alerting:** Set up alerting for critical errors.\n*   **DBUtils.notebook.exit:** Use `dbutils.notebook.exit()` to gracefully exit notebooks.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Partitioning:** Partition data based on common query patterns.\n*   **Bucketing:** Bucket data for faster joins and aggregations.\n*   **Caching:** Cache frequently accessed data using `spark.cache()` or `spark.persist()`.\n*   **Broadcast Joins:** Use broadcast joins for small tables.\n*   **Predicate Pushdown:** Push down filters to the data source.\n*   **Data Skipping:** Use Delta Lake data skipping to skip irrelevant data files.\n*   **Optimize Writes:** Optimize Delta Lake write performance by controlling file size and number of partitions.\n*   **Avoid User-Defined Functions (UDFs):**  Prefer Spark built-in functions. If UDF is unavoidable, explore vectorization.\n*   **Optimize cluster configuration:** Choose the correct driver and worker instance types.  Right size your cluster.\n*   **Avoid shuffling data:** Minimize data movement across the network.\n\n### 3.2. Memory Management\n\n*   **Avoid Large DataFrames:** Avoid loading large DataFrames into memory at once. Use iterative processing or pagination.\n*   **Garbage Collection:** Monitor garbage collection and tune JVM settings if necessary.\n*   **Spark Memory Configuration:** Configure Spark memory settings (e.g., `spark.driver.memory`, `spark.executor.memory`).\n*   **Off-Heap Memory:** Consider using off-heap memory for large datasets.\n*   **Delta Lake Vacuum:** Regularly vacuum Delta Lake tables to remove old versions and reclaim storage space.\n\n### 3.3. Rendering Optimization (if applicable)\n\n*   **Limit Data Display:** Limit the amount of data displayed in notebooks to avoid performance issues.\n*   **Use Visualizations:** Use visualizations to summarize large datasets.\n*   **Optimize Plotting Libraries:** Optimize plotting library settings for performance.\n\n### 3.4. Bundle Size Optimization (for custom web applications using Databricks)\n\n*   **Code Splitting:** Split code into smaller chunks for lazy loading.\n*   **Tree Shaking:** Remove unused code during the build process.\n*   **Minification:** Minify code to reduce file size.\n*   **Compression:** Compress static assets (CSS, JavaScript, images).\n\n### 3.5. Lazy Loading\n\n*   **Lazy Data Loading:** Load data only when it's needed.\n*   **Spark Lazy Evaluation:** Utilize Spark's lazy evaluation to defer computations.\n*   **Dynamic Imports:** Use dynamic imports to load modules only when they're needed.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Code Injection:** Prevent code injection vulnerabilities by validating user inputs.\n*   **SQL Injection:** Use parameterized queries to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** (If using Databricks for web applications) Prevent XSS vulnerabilities by sanitizing user inputs.\n*   **Broken Authentication:** Use strong authentication and authorization mechanisms.\n*   **Sensitive Data Exposure:** Protect sensitive data by encrypting it at rest and in transit.\n\n### 4.2. Input Validation\n\n*   **Data Types:** Validate data types to prevent type errors.\n*   **Range Checks:** Validate that values are within acceptable ranges.\n*   **Regular Expressions:** Use regular expressions to validate data formats.\n*   **Allow Lists:** Use allow lists to restrict input to known good values.\n\n### 4.3. Authentication and Authorization\n\n*   **Databricks Access Control:** Use Databricks access control to manage user permissions.\n*   **Unity Catalog:** Use Unity Catalog for centralized data governance and access control.\n*   **Service Principals:** Use service principals for automated access to Databricks resources.\n*   **Multi-Factor Authentication (MFA):** Enforce MFA for user accounts.\n\n### 4.4. Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in logs and reports.\n*   **Data Redaction:** Redact sensitive data from data files.\n*   **Data Auditing:** Enable data auditing to track data access and modifications.\n*   **Row-level and Column-level Security:** Implement fine grained access controls through Unity Catalog.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Keys:** Use API keys for authentication.\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Sanitization:** Sanitize all API input parameters to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Frameworks:** Use testing frameworks like `pytest` for Python and `ScalaTest` for Scala.\n*   **Test Coverage:** Aim for high test coverage.\n*   **Test-Driven Development (TDD):** Consider using TDD to write tests before code.\n*   **Mocking and Stubbing:** Use mocking and stubbing to isolate units of code.\n*   **Property-based Testing:** Generate a wide range of test inputs, which is useful when you need a broad range of possible data permutations to test your code.\n\n### 5.2. Integration Testing\n\n*   **Test Data Pipelines:** Test the integration of different components in data pipelines.\n*   **Test Data Quality:** Test data quality by validating data transformations and aggregations.\n*   **Test External Systems:** Test the integration with external systems.\n\n### 5.3. End-to-End Testing\n\n*   **Test Full Workflows:** Test full workflows from data ingestion to reporting.\n*   **Test User Interfaces:** (If applicable) Test user interfaces to ensure they function correctly.\n*   **Automate Testing:** Automate end-to-end tests using CI/CD pipelines.\n\n### 5.4. Test Organization\n\n*   **Separate Test Directories:** Create separate directories for unit, integration, and end-to-end tests.\n*   **Test Naming Conventions:** Use clear and consistent test naming conventions.\n*   **Test Suites:** Organize tests into test suites.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock External Dependencies:** Mock external dependencies such as databases and APIs.\n*   **Stub Functions:** Stub functions to control their behavior during testing.\n*   **Mock DataFrames:** Create mock DataFrames for testing data transformations.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not Understanding Spark's Execution Model:** Understanding lazy evaluation and transformations vs. actions is crucial.\n*   **Inefficient Data Partitioning:** Choosing incorrect partitioning can lead to performance bottlenecks.\n*   **Not Using Delta Lake Features:** Failing to leverage Delta Lake features such as ACID transactions and data versioning.\n*   **Over-reliance on Notebooks:** Putting all code into notebooks instead of creating reusable modules.\n*   **Ignoring Security Best Practices:** Failing to implement proper security measures.\n\n### 6.2. Edge Cases\n\n*   **Handling Null Values:** Be aware of how Spark handles null values in data transformations.\n*   **Time Zone Issues:** Handle time zone conversions carefully.\n*   **Data Skew:** Address data skew by repartitioning or salting data.\n*   **Large Files:** Handle large files efficiently by using streaming or chunking.\n\n### 6.3. Version-Specific Issues\n\n*   **Spark Version Compatibility:** Be aware of compatibility issues between different Spark versions.\n*   **Databricks Runtime Version:** Be aware of the Databricks Runtime version and its limitations.\n*   **Library Version Conflicts:** Manage library version conflicts using dependency management tools.\n\n### 6.4. Compatibility Concerns\n\n*   **Integration with Cloud Services:** Be aware of compatibility issues when integrating with cloud services such as AWS, Azure, and GCP.\n*   **Integration with External Databases:** Be aware of compatibility issues when integrating with external databases such as MySQL, PostgreSQL, and SQL Server.\n*   **Integration with BI Tools:** Be aware of compatibility issues when integrating with BI tools such as Tableau, Power BI, and Looker.\n\n### 6.5. Debugging Strategies\n\n*   **Spark UI:** Use the Spark UI to monitor Spark jobs and identify performance bottlenecks.\n*   **Logging:** Use logging to track the execution of code and identify errors.\n*   **Debugging Tools:** Use debugging tools such as `pdb` for Python and the IntelliJ debugger for Scala.\n*   **Explain Plans:** Use explain plans to understand how Spark executes queries.\n*   **Delta Lake History:** Use Delta Lake history to track data changes and debug data issues.\n*   **Databricks Profiler:** Use Databricks Profiler to analyze code execution and identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Databricks Notebooks:** Use Databricks notebooks for interactive development and exploration.\n*   **Databricks Connect:** Use Databricks Connect to connect to Databricks clusters from local IDEs.\n*   **VS Code:** Use VS Code with the Databricks extension for code editing and debugging.\n*   **IntelliJ IDEA:** Use IntelliJ IDEA for Scala development.\n*   **Jupyter Notebook:** Use Jupyter Notebook for Python development.\n\n### 7.2. Build Configuration\n\n*   **Maven or SBT (Scala):** Use Maven or SBT for building Scala projects.\n*   **`requirements.txt` (Python):** Use `requirements.txt` to manage Python dependencies.\n*    **`pyproject.toml` (Python):** Use `pyproject.toml` with poetry or other modern tools.\n*   **Databricks CLI:** Use the Databricks CLI to manage Databricks resources.\n*   **Workspace Bundles:** Use Databricks Workspace Bundles to define and deploy infrastructure and code.\n\n### 7.3. Linting and Formatting\n\n*   **PEP 8 (Python):** Follow PEP 8 for Python code style.\n*   **`flake8` (Python):** Use `flake8` for linting Python code.\n*   **`black` (Python):** Use `black` for formatting Python code.\n*   **Scalafmt (Scala):** Use Scalafmt for formatting Scala code.\n\n### 7.4. Deployment\n\n*   **Databricks Jobs:** Use Databricks Jobs for scheduling and managing data pipelines.\n*   **Databricks Workflows:** Use Databricks Workflows to orchestrate complex data pipelines.\n*   **Databricks Model Serving:** Use Databricks Model Serving to deploy machine learning models.\n*   **Terraform:** Use Terraform to manage Databricks infrastructure as code.\n*   **Workspace Bundles:** Use Databricks Workspace Bundles for reproducible deployments.\n\n### 7.5. CI/CD Integration\n\n*   **GitHub Actions:** Use GitHub Actions for CI/CD pipelines.\n*   **Azure DevOps:** Use Azure DevOps for CI/CD pipelines.\n*   **Jenkins:** Use Jenkins for CI/CD pipelines.\n*   **Databricks Repos:** Use Databricks Repos for version control and collaboration.\n\nBy following these best practices, you can build maintainable, efficient, and secure Databricks applications that deliver value to your organization. Remember to adapt these guidelines to your specific project requirements and coding style.",
    "metadata": {
      "globs": "**/*.{py,sql,ipynb,scala,r}",
      "format": "mdc",
      "originalFile": "databricks.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "databricks",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "databricks",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-datadog",
    "description": "This rule outlines best practices for coding standards, observability, and effective use of the Datadog library in Python projects. It covers coding style, metric/tag naming, dashboard design, security, and performance optimization.",
    "author": "sanjeed5",
    "tags": [
      "datadog",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/datadog.mdc",
    "content": "- **Coding Standards**\n  - Use `black` for code formatting to ensure consistent style.\n  - Use `isort` to sort imports lexicographically.\n  - Employ `flake8` for style checks and to maintain code quality.\n  - Utilize `bugbear` plugin for `flake8` to identify potential bugs and design issues. Enable the following checks:\n    - `B001`: Avoid bare `except:` clauses; prefer `except Exception:`. Catches unexpected events.\n    - `B003`: Avoid direct assignment to `os.environ`. Use `os.environ.clear()` or `env=` argument to `Popen`.\n    - `B006`: Do not use mutable data structures for argument defaults.\n    - `B007`: Loop control variable should be used within the loop body.\n    - `B301`: Use Python 3 `.iter*` methods on dictionaries.\n    - `B305`: Use `next()` builtin instead of `.next()`.\n    - `B306`: Use `str(e)` or `e.args` to access exception messages.\n    - `B902`: Use `self` for instance methods, and `cls` for class methods.\n  - Enforce consistent logging format with `logging-format` `flake8` plugin. Enable the following checks:\n    - `G001`: Logging statements should not use `string.format()`.\n    - `G002`: Logging statements should not use `%` formatting.\n    - `G003`: Logging statements should not use `+` concatenation.\n    - `G004`: Logging statements should not use f-strings (Python 3.6+).\n    - `G010`: Logging statements should not use `warn`; use `warning` instead.\n    - `G100`: Logging statements should not use extra arguments unless whitelisted.\n    - `G201`: Logging statements should not use `error(..., exc_info=True)`; use `exception(...)` instead.\n    - `G202`: Logging statements should not use redundant `exc_info=True` in `exception`.\n  - Use type checking with `mypy` for improved code quality. Configure `mypy` in `hatch.toml`:\n    toml\n    [env.collectors.datadog-checks]\n    check-types: true\n    mypy-args = [\n    \"--py2\",\n    \"--install-types\",\n    \"--non-interactive\",\n    \"datadog_checks/\",\n    \"tests/\",\n    ]\nmypy-deps = [\n    \"types-mock==0.1.5\",\n    ]\n    \n  - Consider using flags like `--check-untyped-defs` and `--disallow-untyped-defs` for stricter type checking. Configure the files to be checked with mypy.ini file.\n\n- **Metric and Tag Naming Conventions**\n  - Use descriptive and meaningful names for metrics and tags.\n  - Avoid abbreviations that might have multiple meanings.\n  - Maintain consistency in naming across all teams, apps, and services.\n  - Avoid reserved keywords.\n  - Prefix metrics with a namespace depicting the application or service generating the data (e.g., `http.nginx.response_time`).\n  - Metric names must start with a letter.\n  - Metric names can only contain ASCII alphanumerics, underscores, and periods. Other characters are converted to underscores.\n  - Metric names should not exceed 200 characters (preferably less than 100).\n  - Tag names must start with a letter.\n  - Tag names may contain alphanumerics, underscores, minuses, colons, periods, and slashes. Other characters are converted to underscores.\n  - Tags can be up to 200 characters long (including both key and value) and support Unicode, but are converted to lowercase.\n  - Use the `key:value` syntax for tags for optimal functionality. Commonly used metric tag keys are `instance`, `name`, and `role`.\n  - Implement unified service tagging using `env`, `service`, and `version` tags.\n\n- **Effective Dashboard Design**\n  - Design dashboards carefully for effective visualization and correlation.\n  - Utilize out-of-the-box dashboards provided by Datadog.\n  - Contribute to community-curated dashboards to enhance visibility and correlation of observability data.\n  - Follow integration dashboard best practices when contributing.\n  - Consult the \"Effective Dashboards\" repository for dashboard design guidelines.\n\n- **Code Organization and Structure**\n  - **Directory Structure:**\n    - Organize code into modules based on functionality (e.g., `metrics`, `logs`, `tracing`).\n    - Use a `common` directory for shared utilities and helper functions.\n  - **File Naming Conventions:**\n    - Use descriptive file names that reflect the module's purpose (e.g., `metrics_collector.py`, `log_processor.py`).\n  - **Module Organization:**\n    - Keep modules small and focused on a single responsibility.\n    - Use `__init__.py` files to define package structure and expose necessary functionality.\n  - **Component Architecture:**\n    - Design components with clear interfaces and separation of concerns.\n    - Use dependency injection to manage dependencies between components.\n  - **Code Splitting:**\n    - Consider splitting large modules into smaller files to improve maintainability.\n    - Use lazy loading for infrequently used modules.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - Use the Observer pattern for subscribing to Datadog events.\n    - Implement the Decorator pattern for adding custom functionality to Datadog integrations.\n  - **Recommended Approaches:**\n    - Use Datadog's API client libraries for interacting with the Datadog API.\n    - Implement custom checks using Datadog's check framework.\n  - **Anti-patterns:**\n    - Avoid hardcoding API keys or other sensitive information in the code.\n    - Avoid excessive logging, which can impact performance.\n  - **State Management:**\n    - Use appropriate data structures for storing state (e.g., dictionaries, lists).\n    - Consider using a dedicated state management library for complex state management needs.\n  - **Error Handling:**\n    - Implement robust error handling to prevent application crashes.\n    - Use try-except blocks to catch and handle exceptions.\n    - Log errors to Datadog for monitoring and analysis.\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - Use efficient data structures and algorithms.\n    - Minimize network requests to the Datadog API.\n    - Use caching to reduce database load.\n  - **Memory Management:**\n    - Avoid memory leaks by properly releasing resources.\n    - Use garbage collection to clean up unused objects.\n  - **Bundle Size Optimization:**\n    - Remove unused dependencies from the project.\n    - Use code minification to reduce bundle size.\n  - **Lazy Loading:**\n    - Load infrequently used modules or components on demand.\n\n- **Security Best Practices**\n  - **Vulnerabilities:**\n    - Prevent injection attacks by validating user inputs.\n    - Protect against cross-site scripting (XSS) attacks by encoding outputs.\n  - **Input Validation:**\n    - Validate all user inputs to prevent malicious data from entering the system.\n    - Use regular expressions or other validation techniques to enforce input constraints.\n  - **Authentication and Authorization:**\n    - Use strong authentication mechanisms to verify user identities.\n    - Implement authorization policies to control access to resources.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure communication protocols (e.g., HTTPS) for API communication.\n  - **Secure API Communication:**\n    - Use TLS/SSL for secure communication with the Datadog API.\n    - Store API keys securely and do not expose them in the code.\n\n- **Testing Approaches**\n  - **Unit Testing:**\n    - Write unit tests for individual components to verify their functionality.\n    - Use mocking to isolate components from external dependencies.\n  - **Integration Testing:**\n    - Write integration tests to verify interactions between components.\n    - Use a testing framework like pytest for writing and running tests.\n  - **End-to-end Testing:**\n    - Write end-to-end tests to verify the entire application workflow.\n    - Use a tool like Selenium or Cypress for automating browser tests.\n  - **Test Organization:**\n    - Organize tests into separate directories based on component or functionality.\n    - Use descriptive test names to clearly indicate the purpose of each test.\n  - **Mocking and Stubbing:**\n    - Use mocking to simulate external dependencies during testing.\n    - Use stubbing to replace complex components with simplified versions.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - Incorrectly configuring Datadog integrations.\n    - Not properly handling errors or exceptions.\n    - Overusing logging, which can impact performance.\n  - **Edge Cases:**\n    - Handling large volumes of data.\n    - Dealing with intermittent network connectivity issues.\n  - **Version-specific Issues:**\n    - Be aware of compatibility issues between different versions of Datadog and its dependencies.\n  - **Compatibility Concerns:**\n    - Ensure compatibility between Datadog and other technologies used in the project.\n  - **Debugging Strategies:**\n    - Use Datadog's monitoring tools to track down performance bottlenecks and errors.\n    - Use logging to trace the execution flow of the application.\n\n- **Tooling and Environment**\n  - **Recommended Tools:**\n    - Use an IDE like VS Code or PyCharm for development.\n    - Use a version control system like Git for managing code.\n    - Use a build tool like Make or Poetry for building and deploying the application.\n  - **Build Configuration:**\n    - Use a build tool to automate the build process.\n    - Configure the build tool to generate optimized bundles.\n  - **Linting and Formatting:**\n    - Use a linter like Flake8 to enforce coding standards.\n    - Use a formatter like Black to automatically format code.\n  - **Deployment:**\n    - Use a deployment tool like Docker or Kubernetes for deploying the application.\n    - Use a CI/CD pipeline to automate the deployment process.\n  - **CI/CD Integration:**\n    - Integrate Datadog into the CI/CD pipeline to automatically monitor and analyze application performance.\n    - Use Datadog's API to create custom dashboards and alerts.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "datadog.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "datadog",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "observability",
      "effective",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "datadog",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-deno",
    "description": "This rule file provides comprehensive guidelines for Deno development, covering best practices for code organization, security, performance, testing, and documentation. Adhering to these standards ensures maintainable, efficient, and secure Deno applications.",
    "author": "sanjeed5",
    "tags": [
      "deno",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/deno.mdc",
    "content": "- **Use TypeScript**: Always prefer TypeScript for its strong typing, which enhances code quality and maintainability. Provide clear type annotations and use interfaces for better structure.\n- **Documentation with JSDoc**: Utilize JSDoc for documenting all exported symbols. Include concise summaries, type information, and examples. Keep documentation up-to-date with code changes.\n- **Consistent Naming Conventions**: Follow established naming conventions such as camelCase for variables and functions, PascalCase for classes, and UPPER_SNAKE_CASE for constants. This consistency aids readability and maintainability.\n- **Limit Function Parameters**: Functions should ideally take no more than two parameters, using options objects for additional parameters. This makes functions easier to use and test.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure Best Practices**:\n    - `src/`: Contains the main source code of the application.\n    - `src/components/`: Reusable UI components (if applicable).\n    - `src/services/`: Business logic and API interactions.\n    - `src/utils/`: Utility functions and helpers.\n    - `tests/`: Unit and integration tests.\n    - `mod.ts`: The main entry point for the module or application.\n    - `deps.ts`: Centralized dependency management file (more details below).\n    - `dev_deps.ts`: Centralized development dependency management file (more details below).\n    - `deno.json`: Deno configuration file.\n- **File Naming Conventions**:\n    - Use descriptive names with `.ts`, `.tsx`, `.js`, or `.jsx` extensions.\n    - Component files: `ComponentName.tsx` or `component-name.tsx`\n    - Service files: `service-name.ts`\n    - Utility files: `utils.ts` or `string_utils.ts`\n    - Test files: `file_name_test.ts`\n- **Module Organization Best Practices**:\n    - Favor small, focused modules with clear responsibilities.\n    - Avoid circular dependencies.\n    - Use `deps.ts` to manage dependencies centrally. This file exports all external dependencies used in the project, allowing for easy version management and updates. Example:\n\n    typescript\n    // deps.ts\n    export * as log from \"https://deno.land/std@0.224.0/log/mod.ts\";\n    export { assertEquals } from \"https://deno.land/std@0.224.0/assert/mod.ts\";\n    export { serve } from \"https://deno.land/std@0.224.0/http/server.ts\";\n    \n    - Use `dev_deps.ts` to manage development dependencies centrally. Example:\n\n    typescript\n    // dev_deps.ts\n    export {\n      assert,\n      assertEquals,\n      assertExists,\n      assertNotEquals,\n      assertRejects,\n      assertStringIncludes,\n    } from \"https://deno.land/std@0.224.0/assert/mod.ts\";\n    export {\n      FakeTime,\n    } from \"https://deno.land/std@0.224.0/testing/time.ts\";\n    \n\n    - Import dependencies using the `deps.ts` file in other modules:\n\n    typescript\n    // my_module.ts\n    import { log, assertEquals } from \"./deps.ts\";\n\n    log.info(\"Hello, Deno!\");\n    \n- **Component Architecture Recommendations**:\n    - Follow a component-based architecture for UI development (if applicable).\n    - Each component should be self-contained and reusable.\n    - Consider using a state management library like `nano-states` or `unstate` for complex applications.\n- **Code Splitting Strategies**:\n    - Use dynamic imports (`import()`) to load modules on demand.\n    - Split code based on routes or features.\n    - Leverage Deno's built-in module caching for efficient loading.\n    - Use `deno bundle` to create optimized bundles for deployment, but be mindful of over-bundling.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns**: \n    - **Module Pattern**: Encapsulating code within a module to control access and prevent global scope pollution.\n    - **Factory Pattern**: Creating objects without specifying the exact class to instantiate.\n    - **Observer Pattern**: Defining a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n    - **Dependency Injection**:  Making components loosely coupled.  Useful with Deno's module system because you can easily swap out dependencies in tests without relying on complex mocking frameworks.\n- **Recommended Approaches for Common Tasks**:\n    - **HTTP Server**: Use Deno's built-in `Deno.serve` for creating HTTP servers.\n    - **File System Access**: Use `Deno.readTextFile`, `Deno.writeTextFile`, etc., for file system operations.\n    - **Environment Variables**: Access environment variables using `Deno.env.get()`.\n    - **Process Management**: Use `Deno.run` for executing external commands.\n- **Anti-patterns and Code Smells**:\n    - **Global Scope Pollution**: Avoid declaring variables in the global scope.\n    - **Deeply Nested Callbacks**: Refactor code to use async/await for better readability.\n    - **Ignoring Errors**: Always handle potential errors using try/catch blocks or `Result` types.\n    - **Over-Engineering**: Keep code simple and avoid unnecessary complexity.\n    - **Not Using `deps.ts`**:  Failing to centralize and version control your dependencies will make maintenance difficult.\n- **State Management Best Practices**:\n    - For simple applications, use local component state.\n    - For complex applications, consider using a lightweight state management library or a more robust solution like Redux (via a compatible Deno port).\n    - Centralize application state and manage it predictably.\n    - Avoid mutating state directly; use immutable updates.\n- **Error Handling Patterns**:\n    - Use try/catch blocks for synchronous error handling.\n    - Use `.catch()` for handling errors in Promises.\n    - Create custom error types for specific scenarios.\n    - Log errors with sufficient context for debugging.\n    - Consider using a `Result` type to explicitly handle success or failure cases.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques**:\n    - **Minimize I/O Operations**: Batch file reads/writes when possible.\n    - **Efficient Data Structures**: Use appropriate data structures for your use case (e.g., `Map` vs. `Object`).\n    - **Asynchronous Operations**: Leverage async/await for non-blocking operations.\n    - **WebAssembly**: Utilize WebAssembly modules for performance-critical tasks.\n    - **`Deno.bench`**: Use Deno's built-in benchmarking tool to identify performance bottlenecks.  Run with `deno bench`.  Write benchmarks adjacent to the files you are testing.\n- **Memory Management Considerations**:\n    - Be mindful of memory leaks, especially when working with streams and resources.\n    - Use `finally` blocks to ensure resources are properly closed.\n    - Avoid creating unnecessary objects and variables.\n    - Profile your application to identify memory usage patterns.\n- **Rendering Optimization (if applicable)**:\n    - Use virtual DOM techniques for efficient UI updates.\n    - Optimize images and other assets.\n    - Implement lazy loading for offscreen content.\n- **Bundle Size Optimization**:\n    - Use `deno bundle` to create optimized bundles for deployment.\n    - Remove unused code with tree shaking.\n    - Minify JavaScript and CSS files.\n    - Compress assets with gzip or Brotli.\n- **Lazy Loading Strategies**:\n    - Use dynamic imports (`import()`) to load modules on demand.\n    - Implement lazy loading for images and other assets.\n    - Split code based on routes or features.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and Prevention**:\n    - **Remote Code Execution**:  Be extremely cautious with `Deno.run`, validate inputs, and never execute untrusted code.\n    - **Cross-Site Scripting (XSS)**: Sanitize user inputs to prevent XSS attacks (if applicable).\n    - **SQL Injection**: Use parameterized queries or an ORM to prevent SQL injection (if applicable).\n    - **Denial of Service (DoS)**: Implement rate limiting and other measures to prevent DoS attacks.\n    - **Supply Chain Attacks**: Carefully review and pin dependencies in `deps.ts` and `deno.lock`.\n- **Input Validation**:\n    - Validate all user inputs to prevent injection attacks and data corruption.\n    - Use regular expressions or dedicated validation libraries to enforce input formats.\n    - Sanitize inputs to remove potentially malicious characters.\n- **Authentication and Authorization**:\n    - Use secure authentication mechanisms like OAuth 2.0 or JWT.\n    - Implement role-based access control (RBAC) or attribute-based access control (ABAC) for authorization.\n    - Store passwords securely using bcrypt or Argon2.\n- **Data Protection**:\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all communication.\n    - Implement proper access controls to protect data from unauthorized access.\n    - Regularly back up data and test recovery procedures.\n- **Secure API Communication**:\n    - Use HTTPS for all API communication.\n    - Validate API requests and responses.\n    - Implement rate limiting to prevent abuse.\n    - Use API keys or JWT for authentication.\n\n## 5. Testing Approaches\n\n- **Unit Testing**:\n    - Write unit tests for individual components and functions.\n    - Use Deno's built-in testing framework (`Deno.test`).\n    - Mock dependencies to isolate units under test.\n    - Aim for high test coverage.\n- **Integration Testing**:\n    - Write integration tests to verify interactions between different modules.\n    - Test API endpoints and data flows.\n    - Use a test database or mock API for integration tests.\n- **End-to-End Testing**:\n    - Write end-to-end tests to verify the entire application flow.\n    - Use a testing framework like Playwright or Puppeteer.\n    - Test user interactions and UI elements (if applicable).\n- **Test Organization**:\n    - Create a `tests/` directory to store all tests.\n    - Organize tests into subdirectories based on module or feature.\n    - Use descriptive test names.\n    - Run tests using `deno test`.\n- **Mocking and Stubbing**:\n    - Use Deno's built-in mocking capabilities or a mocking library like `sinon`.\n    - Mock external dependencies and API calls.\n    - Use stubs to replace complex functions with simplified versions.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes**:\n    - **Incorrect Permissions**: Not requesting necessary permissions (e.g., `--allow-read`, `--allow-net`).\n    - **Uncaught Exceptions**: Not handling errors properly.\n    - **Global Variable Pollution**: Accidentally declaring variables in the global scope.\n    - **Missing `await`**: Forgetting to `await` asynchronous operations.\n    - **Inconsistent Dependency Versions**: Not managing dependency versions using `deps.ts`.\n- **Edge Cases**:\n    - **Handling large files**: Efficiently stream large files to avoid memory issues.\n    - **Cross-platform compatibility**: Test your application on different operating systems.\n    - **Time zone differences**: Handle time zone conversions carefully.\n- **Version-Specific Issues**:\n    - Be aware of breaking changes in Deno releases.\n    - Consult the Deno release notes for migration guidance.\n- **Compatibility Concerns**:\n    - Ensure compatibility with different browsers and Deno versions (if applicable).\n    - Be mindful of differences between Deno and Node.js APIs.\n- **Debugging Strategies**:\n    - Use Deno's built-in debugger (`deno inspect`).\n    - Use `console.log` statements for basic debugging.\n    - Use a code editor with Deno support for advanced debugging features.\n    - Inspect network requests and responses using browser developer tools.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools**:\n    - **VS Code** with the Deno extension.\n    - **IntelliJ IDEA** with the Deno plugin.\n    - **Deno CLI**.\n- **Build Configuration**:\n    - Use `deno.json` to configure Deno settings, like import maps, linting rules, and formatting options. Example:\n\n    json\n    {\n      \"imports\": {\n        \"*\": \"./src/\",\n        \"std/\": \"https://deno.land/std@0.224.0/\"\n      },\n      \"lint\": {\n        \"rules\": {\n          \"no-explicit-any\": true\n        }\n      },\n      \"fmt\": {\n        \"lineWidth\": 120,\n        \"indentWidth\": 2\n      },\n      \"compilerOptions\": {\n          \"jsx\": \"react-jsx\",\n          \"jsxImportSource\": \"react\"\n      }\n    }\n    \n- **Linting and Formatting**:\n    - Use `deno lint` to check for code style and potential errors. Configure linting rules in `deno.json`.\n    - Use `deno fmt` to format code according to the configured style. Configure formatting options in `deno.json`.\n    - Integrate linting and formatting into your workflow using pre-commit hooks or CI/CD pipelines.\n- **Deployment**:\n    - **Deno Deploy**: For easy serverless hosting of Deno applications.  Requires no configuration files to start.\n    - **Docker**:  Containerize your Deno app for consistent deployments.\n    - **Cloud Providers**: Deploy to AWS, Google Cloud, or Azure using standard deployment methods.\n- **CI/CD Integration**:\n    - Use GitHub Actions, GitLab CI, or other CI/CD platforms to automate testing, linting, formatting, and deployment.\n    - Configure CI/CD pipelines to run tests on every commit or pull request.\n    - Automate deployments to production environments.\n\n## Additional Best Practices\n\n- **Use Underscores in Filenames**: Use `file_server.ts` instead of `file-server.ts`.\n- **Write Tests for New Features**: Each module should contain or be accompanied by tests for its public functionality.\n- **TODO Comments**: TODO comments should include an issue or the author's GitHub username in parentheses. Example: `// TODO(ry): Add tests.`\n- **Be Explicit**: Be explicit, even when it means more code.\n- **Inclusive Code**: Follow the guidelines for inclusive code.\n- **Minimize Dependencies**: Do not make circular imports.\n- **JSDoc**: Provide excellent JSDoc coverage for all exported symbols.\n- **Resolve Linting Problems**: Use `// deno-lint-ignore <rule>` to suppress warnings when necessary, but use sparingly.\n- **Test Module**: Every module with public functionality `foo.ts` should have a test module `foo_test.ts`.\n- **Explicit Unit Tests**: Name unit tests clearly.\n- **Top-Level Functions**: Use the `function` keyword for top-level functions, not arrow syntax.\n- **std Library**: Do not depend on external code in the standard library.\n- **Browser Compatibility**: Document and maintain browser compatibility where appropriate.\n- **Prefer `#` over `private`**:  Prefer `#` (private class fields) over the `private` keyword.\n- **Naming Conventions**: Use camelCase, PascalCase, and UPPER_SNAKE_CASE consistently for variables, functions, classes, types, and constants.\n\nBy adhering to these best practices, you can create maintainable, efficient, and secure Deno applications.",
    "metadata": {
      "globs": "*.ts,*.tsx,*.js,*.jsx,*.md",
      "format": "mdc",
      "originalFile": "deno.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "deno",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "best",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "deno",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-detox",
    "description": "This rule file provides guidelines for writing stable and maintainable end-to-end tests using Detox, covering code structure, testing strategies, and performance considerations. It includes best practices for test ID usage, dealing with flakiness, and integrating with CI/CD pipelines.",
    "author": "sanjeed5",
    "tags": [
      "detox",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/detox.mdc",
    "content": "# Detox E2E Testing Best Practices for React Native\n\nThis document outlines best practices for writing stable, maintainable, and performant end-to-end (E2E) tests for React Native applications using Detox.\n\n## Ground Rules\n\n- **Isolate Tests:** Each test should start fresh and not depend on the execution of previous tests.  Restart the app before each test.\n- **Consistent Input, Consistent Output:** Ensure identical app behavior across test iterations by managing varying server responses and app states. Mock server responses to prevent external variations.\n- **End every test with an expectation:** Ensures a validation phase that confirms the intended outcome of the test.\n\n## 1. Code Organization and Structure\n\n### Directory Structure\n\n\n<project_root>/\n  e2e/\n    config.js          # Detox configuration file\n    utils.js           # Helper functions for tests\n    firstTest.spec.js   # Example test file\n    ...              # More test files\n  src/\n    ...              # Your application source code\n\n\n- **`e2e` directory:**  Dedicated directory for all Detox-related files.\n- **`config.js`:** Contains Detox configuration, including device settings, build paths, and test runner configuration.\n- **`utils.js` (or similar):**  Houses reusable helper functions, such as custom matchers, navigation helpers, and data generation functions.\n- **`*.spec.js` or `*.e2e.js`:** Test files containing the actual test cases. Choose a consistent naming convention.\n\n### File Naming Conventions\n\n- **Test files:** `[ComponentName].spec.js`, `[FeatureName].e2e.js`.\n- **Helper functions:** `helpers.js`, `utils.js`, `testData.js`.\n- **Configuration:** `detox.config.js` or `e2e.config.js`.\n\n### Module Organization\n\n- **Separate test logic from application code:** Tests reside in the `e2e` directory, separate from the `src` directory containing the app's source code.\n- **Group related tests into modules:** For example, put all tests related to user authentication in an `e2e/auth/` directory.\n- **Use helper modules:**  Extract common test logic, like logging in a user or navigating to a specific screen, into reusable helper functions.\n\n### Component Architecture (Page Object Model)\n\n- **Implement the Page Object Model (POM):** Create classes or modules that represent UI screens or components.  Each page object should encapsulate the selectors and actions for that screen.\n\njavascript\n// e2e/pageObjects/LoginPage.js\nconst { element, by, expect } = require('detox');\n\nclass LoginPage {\n  constructor() {\n    this.usernameField = element(by.id('username_input'));\n    this.passwordField = element(by.id('password_input'));\n    this.loginButton = element(by.id('login_button'));\n  }\n\n  async enterUsername(username) {\n    await this.usernameField.typeText(username);\n  }\n\n  async enterPassword(password) {\n    await this.passwordField.typeText(password);\n  }\n\n  async tapLoginButton() {\n    await this.loginButton.tap();\n  }\n\n  async isLoggedIn() {\n    await expect(element(by.id('home_screen'))).toBeVisible();\n  }\n}\n\nmodule.exports = new LoginPage();\n\n\n- **Benefits of POM:**\n    - Improved test readability and maintainability.\n    - Reduced code duplication.\n    - Easier refactoring of UI elements.\n\n### Code Splitting Strategies (Not directly applicable to Detox, but consider app bundle size)\n\n- **Dynamic imports:** Utilize dynamic imports in the app code to load modules only when needed, improving initial load time. This is a React Native concern, not Detox itself, but Detox tests will execute faster on a faster-loading app.\n- **Route-based splitting:** Split your app into separate bundles based on routes or features.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns Specific to Detox\n\n- **Wait for element to be visible:**\n\njavascript\nawait waitFor(element(by.id('my_element'))).toBeVisible().withTimeout(5000);\n\n\n- **Retry flaky tests:** Implement a retry mechanism for tests that occasionally fail due to timing issues or other unpredictable factors. Use Jest's retryTimes:\n\njavascript\njest.retryTimes(3); // Retry the test up to 3 times\n\n\n- **Use `beforeAll` and `beforeEach` wisely:** `beforeAll` is for setup that only needs to happen once for the entire test suite, while `beforeEach` is for setup that must be done before each test.\n\n### Recommended Approaches for Common Tasks\n\n- **Simulating user interactions:**\n\njavascript\nawait element(by.id('my_button')).tap();\nawait element(by.id('my_input')).typeText('Hello, Detox!');\nawait element(by.id('my_scroll_view')).scroll(50, 'down');\n\n\n- **Asserting element visibility and text content:**\n\njavascript\nawait expect(element(by.id('my_element'))).toBeVisible();\nawait expect(element(by.text('Expected Text'))).toBeVisible();\nawait expect(element(by.id('my_element'))).toHaveText('Actual Text');\n\n\n- **Handling alerts and dialogs:**\n\njavascript\nawait expect(element(by.text('Alert Title'))).toBeVisible();\nawait element(by.text('OK')).tap(); // Dismiss the alert\n\n\n### Anti-patterns and Code Smells to Avoid\n\n- **Hardcoded timeouts:** Avoid using `setTimeout` directly. Rely on Detox's built-in synchronization and waiting mechanisms.\n- **Incomplete Test Coverage:** Focus on critical paths and user flows, ensuring comprehensive coverage of the core functionalities.\n- **Over-reliance on Thread.sleep() (or equivalent):** Try to use `waitFor` or Detox's synchronization primitives instead.  Sleeping is almost always a sign that Detox's sync isn't working right.\n- **Ignoring console.log statements:** Keep console log statements clean and helpful for debugging purposes.\n\n### State Management Best Practices (App-level, impacts test environment)\n\n- **Mock external dependencies:** Mock API calls, database interactions, and other external dependencies to ensure consistent test results and isolate the app's logic.\n- **Control app state before each test:** Use `beforeEach` to reset the app's state to a known value before running each test. This can involve clearing data, logging out users, or navigating to a specific screen.\n\n### Error Handling Patterns\n\n- **Use `try...catch` blocks:** Wrap test actions in `try...catch` blocks to handle potential errors gracefully.\n- **Log errors:** Log any errors that occur during test execution to help with debugging.\n- **Fail tests on unexpected errors:** If a test encounters an unexpected error, mark the test as failed to prevent false positives.\n\n## 3. Performance Considerations\n\n### Optimization Techniques (Mainly React Native app optimization)\n\n- **Minimize UI updates:**  Reduce the number of UI updates during animations or interactions to improve rendering performance.\n- **Use virtualization for long lists:** Virtualize long lists to render only the visible items, reducing memory consumption and improving scrolling performance. This improves the app's performance generally, leading to faster test execution.\n- **Optimize image loading:** Optimize image sizes and use caching mechanisms to reduce image loading times.\n\n### Memory Management (React Native app concern)\n\n- **Release resources:** Properly release resources, such as event listeners and timers, when they are no longer needed to prevent memory leaks.\n- **Use memoization:** Use memoization techniques to avoid recomputing expensive values when they haven't changed.\n\n### Rendering Optimization (React Native app concern)\n\n- **Use `shouldComponentUpdate` or `React.memo`:** Implement `shouldComponentUpdate` or `React.memo` to prevent unnecessary re-renders of components.\n- **Avoid inline styles:**  Avoid using inline styles, as they can cause performance issues.\n\n### Bundle Size Optimization (React Native app concern)\n\n- **Use code splitting:** Split your app into smaller chunks to reduce the initial bundle size.\n- **Remove unused code:** Remove any unused code, such as dead code or unused libraries.\n- **Optimize images:** Optimize image sizes and use appropriate image formats.\n\n### Lazy Loading Strategies (React Native app concern)\n\n- **Load components on demand:**  Load components only when they are needed, such as when a user navigates to a specific screen.\n- **Use lazy-loaded images:**  Load images only when they are visible in the viewport.\n\n## 4. Security Best Practices (App Security - Impacts Test Scope)\n\n### Common Vulnerabilities and How to Prevent Them\n\n- **Data injection:** Protect against data injection attacks by validating all user input and using parameterized queries.\n- **Cross-site scripting (XSS):**  Prevent XSS attacks by sanitizing all user-generated content before rendering it.\n- **Man-in-the-middle (MITM) attacks:**  Implement SSL/TLS to encrypt communication between the app and the server.\n\n### Input Validation\n\n- **Validate all user input:** Validate all user input on both the client and server sides to prevent invalid or malicious data from being processed.\n- **Use appropriate validation libraries:** Use established validation libraries to simplify the validation process and ensure consistency.\n\n### Authentication and Authorization Patterns\n\n- **Use secure authentication protocols:** Use secure authentication protocols, such as OAuth 2.0 or OpenID Connect.\n- **Implement proper authorization checks:** Implement proper authorization checks to ensure that users can only access the resources they are authorized to access.\n\n### Data Protection Strategies\n\n- **Encrypt sensitive data:** Encrypt sensitive data, such as passwords and credit card numbers, both in transit and at rest.\n- **Store data securely:** Store data in secure locations, such as encrypted databases or keychains.\n\n### Secure API Communication\n\n- **Use HTTPS:** Always use HTTPS to encrypt communication between the app and the server.\n- **Validate API responses:** Validate API responses to ensure that they are not tampered with.\n\n## 5. Testing Approaches\n\n### Unit Testing Strategies (Generally not used with Detox)\n\n- **Test individual components or functions in isolation:** Use unit tests to verify the behavior of individual components or functions in isolation.\n- **Use mocking to isolate dependencies:** Use mocking to isolate dependencies and ensure that the unit tests are not affected by external factors.\n\n### Integration Testing\n\n- **Test interactions between multiple components or modules:** Use integration tests to verify the interactions between multiple components or modules.\n- **Use stubs to simulate external dependencies:** Use stubs to simulate external dependencies and ensure that the integration tests are not affected by real-world conditions.\n\n### End-to-End Testing\n\n- **Test the entire application from end to end:** Use end-to-end tests to verify the entire application flow from the user's perspective.\n- **Simulate real user interactions:** Simulate real user interactions as closely as possible to ensure that the tests accurately reflect the user experience.\n\n### Test Organization\n\n- **Organize tests by feature or functionality:** Group tests by feature or functionality to improve test discoverability and maintainability.\n- **Use descriptive test names:** Use descriptive test names to clearly indicate what each test is verifying.\n- **Keep tests small and focused:** Keep tests small and focused on verifying a single aspect of the application.\n\n### Mocking and Stubbing (Used sparingly with Detox. More common is configuring the backend)\n\n- **Mock external dependencies:**  Mock external dependencies, such as API calls or database interactions, to ensure consistent test results.\n- **Use stubs to simulate specific scenarios:**  Use stubs to simulate specific scenarios, such as error conditions or edge cases.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes Developers Make\n\n- **Using brittle selectors:** Avoid using selectors that are based on text or position, as these can easily break when the UI changes. Use `testID` whenever possible.\n- **Not handling asynchronous operations correctly:** Ensure that all asynchronous operations are properly handled to prevent race conditions and timing issues.\n- **Ignoring error messages:** Pay attention to error messages and logs to identify and fix problems quickly.\n\n### Edge Cases to Be Aware Of\n\n- **Handling different screen sizes and orientations:**  Test the app on different screen sizes and orientations to ensure that the UI adapts correctly.\n- **Handling network connectivity issues:**  Test the app's behavior when the network connection is slow or unavailable.\n- **Handling different languages and locales:**  Test the app with different languages and locales to ensure that it is properly localized.\n\n### Version-Specific Issues\n\n- **Keep Detox up to date:**  Stay up to date with the latest version of Detox to take advantage of bug fixes and performance improvements.\n- **Be aware of compatibility issues:**  Be aware of compatibility issues between different versions of Detox, React Native, and other dependencies.\n\n### Compatibility Concerns\n\n- **Test on multiple devices and operating systems:**  Test the app on a variety of devices and operating systems to ensure that it is compatible with the target audience.\n- **Use a device farm:**  Use a device farm, such as HeadSpin, to test the app on a wide range of real devices.\n\n### Debugging Strategies\n\n- **Use the Detox CLI:**  Use the Detox CLI to run tests, inspect the app's state, and debug issues.\n- **Use logging statements:**  Use logging statements to track the execution flow and identify potential problems.\n- **Use breakpoints:**  Use breakpoints in your test code to pause execution and inspect variables.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n- **Visual Studio Code:** A popular code editor with excellent support for JavaScript and React Native.\n- **Detox CLI:** The Detox command-line interface for running tests and managing the Detox environment.\n- **HeadSpin:** For running tests on real devices and analyzing performance metrics.\n\n### Build Configuration\n\n- **Configure Detox in `package.json`:** Configure Detox in the `package.json` file, including device settings, build paths, and test runner configuration.\n- **Use different configurations for different environments:** Use different configurations for development, staging, and production environments.\n\n### Linting and Formatting\n\n- **Use ESLint:** Use ESLint to enforce code style and detect potential errors.\n- **Use Prettier:** Use Prettier to automatically format code.\n\n### Deployment Best Practices\n\n- **Automate the deployment process:** Automate the deployment process using tools like Fastlane or Bitrise.\n- **Use continuous integration and continuous delivery (CI/CD):** Use CI/CD to automatically build, test, and deploy the app whenever changes are made.\n\n### CI/CD Integration\n\n- **Integrate Detox tests into your CI/CD pipeline:** Integrate Detox tests into your CI/CD pipeline to automatically run tests whenever changes are made.\n- **Use a CI/CD service like Jenkins, CircleCI, or Travis CI:** Use a CI/CD service like Jenkins, CircleCI, or Travis CI to automate the build, test, and deployment process.\n\n## Working with Test IDs\n\n### Benefits of Test IDs\n\n*   Stable matchers that don't depend on UI text.\n*   Locale-agnostic testing.\n*   Clear code navigability.\n\n### Assigning Test IDs\n\n*   **React Native:** Use the `testID` prop on View components.\n\n    jsx\n    <View>\n      <TouchableOpacity testID=\"Onboarding.Next_button\">\n        <Text>Next</Text>\n      </TouchableOpacity>\n    </View>\n    \n\n*   **iOS Native:** Use the `accessibilityIdentifier` property.\n*   **Android Native:** Use the `viewTag` property.\n\n### Best Practices for Naming Test IDs\n\n*   Use a consistent naming system (e.g., `ITEM_NAME_ALL_CAPS` or `ItemNameUpperCamelCase`).\n*   Use notations for special items (e.g., `_ROOT` for screen roots, `_BTN` for buttons).\n*   Apply consistent prefixes as categories (e.g., `EDIT_PROFILE_SCREEN.DONE_BTN`).\n*   Drill down to details of elements via chains of contexts (e.g., `SITE_LIST_ITEM1.OPTIONS`).\n*   In large projects, use module identifiers (e.g., `AUTH.LOGIN_SCREEN.EDIT_PASSWORD`).\n\n#### Examples of good test ID usage:\n\n\nEDIT_PROFILE_SCREEN.DONE_BTN\nSITE_LIST_ROOT\nSITE_LIST_ITEM1.OPTIONS\n\n\n### Rules of Thumb for test IDs\n\n*   Use unique, simple, and concise names.\n*   Dissociate test ID names from element text/labels.\n*   Do not utilize the element's text / label in the naming of a test ID!\n\n### Finding Test IDs\n\n*   **MacOS Accessibility Inspector:** Use the built-in accessibility inspector to verify test IDs on iOS.\n*   **Detox Layout Inspector:** Set up and use the Detox Layout Inspector for Android.\n* Incorrect or absent testID is a common cause for test failure. If your test can't find your testID and you can't see it either using tools described above, that usually means you haven't passed it down to this component.\nMake sure you keep forwarding it down until it reaches a native component.\n\nBy following these best practices, you can create a robust and maintainable suite of Detox E2E tests for your React Native application.",
    "metadata": {
      "globs": "*.e2e.js,*.e2e.ts,*.spec.js,*.spec.ts",
      "format": "mdc",
      "originalFile": "detox.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "detox",
      "this",
      "rule",
      "file",
      "provides",
      "guidelines",
      "writing",
      "stable",
      "maintainable",
      "tests",
      "using",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "detox",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-digitalocean",
    "description": "This rule provides comprehensive guidelines for DigitalOcean infrastructure and application development, covering code organization, security, performance, and deployment best practices.  It aims to ensure consistent, scalable, and secure cloud solutions on the DigitalOcean platform.",
    "author": "sanjeed5",
    "tags": [
      "digitalocean",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/digitalocean.mdc",
    "content": "# DigitalOcean Development Best Practices\n\nThis document provides comprehensive guidelines for developing infrastructure and applications on DigitalOcean. It covers various aspects, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and recommended tooling.\n\n## 1. Code Organization and Structure\n\n### Directory Structure\n\nA well-defined directory structure is crucial for maintainability and scalability. Consider these patterns:\n\n\nproject-root/\n├── modules/                 # Reusable Terraform modules\n│   ├── droplet/           # Module for creating Droplets\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── outputs.tf\n│   │   └── ...\n│   ├── database/          # Module for creating Managed Databases\n│   │   └── ...\n│   └── ...\n├── environments/            # Environment-specific configurations\n│   ├── dev/                # Development environment\n│   │   ├── main.tf\n│   │   ├── variables.tf\n│   │   ├── terraform.tfvars  # Environment-specific variables\n│   │   └── ...\n│   ├── staging/\n│   │   └── ...\n│   ├── prod/\n│   │   └── ...\n│   └── ...\n├── scripts/                # Utility scripts (e.g., deployment, backup)\n│   ├── deploy.sh\n│   ├── backup.sh\n│   └── ...\n├── tests/                   # Infrastructure tests\n│   ├── integration/\n│   │   └── ...\n│   ├── unit/\n│   │   └── ...\n│   └── ...\n├── README.md\n├── LICENSE\n└── ...\n\n\n*   **`modules/`**: Contains reusable Terraform modules.  Each module encapsulates a specific DigitalOcean resource or set of resources (e.g., Droplet, Load Balancer, Database). This promotes code reuse and reduces duplication.\n*   **`environments/`**: Defines configurations specific to each environment (development, staging, production).  This allows for environment-specific settings without modifying the core module code.  Use `terraform.tfvars` files to store environment-specific variable values.\n*   **`scripts/`**: Includes utility scripts for tasks such as deployment, backups, and monitoring.  Use descriptive names for scripts and include comments explaining their purpose.\n*   **`tests/`**: Contains automated tests to verify the infrastructure.  Separate integration tests (testing the interaction between resources) from unit tests (testing individual modules).\n\n### File Naming Conventions\n\n*   **Terraform files:**  Use `.tf` extension.  Name files descriptively (e.g., `main.tf`, `variables.tf`, `outputs.tf`).  For environment-specific variables, use `terraform.tfvars`.\n*   **YAML/YML files:** Use `.yml` or `.yaml` extensions for configuration files (e.g., Docker Compose, Kubernetes manifests). Choose one consistently within the project.\n*   **Shell scripts:** Use `.sh` extension.  Name scripts according to their function (e.g., `deploy.sh`, `backup.sh`).\n*   **Python scripts:** Use `.py` extension. Follow PEP 8 guidelines for naming variables, functions, and classes.\n\n### Module Organization\n\n*   **Single Responsibility Principle:**  Each module should have a single, well-defined purpose (e.g., creating a Droplet, configuring a firewall).\n*   **Abstraction:**  Modules should abstract away the complexity of underlying DigitalOcean resources, providing a simple and consistent interface for users.\n*   **Versioning:**  Use Terraform module registry to version and share reusable modules. This allows you to track changes and ensure consistent deployments across environments.\n*   **Input Validation:**  Validate input variables to ensure they meet expected criteria (e.g., data type, allowed values).  This helps prevent errors and improves the reliability of your infrastructure.\n\n### Component Architecture\n\n*   **Microservices:**  For complex applications, consider a microservices architecture.  Each microservice can be deployed as a separate Droplet or containerized application within a DigitalOcean Kubernetes cluster.\n*   **Stateless Applications:** Design applications to be stateless whenever possible. This simplifies scaling and improves resilience. Store persistent data in Managed Databases or Object Storage.\n*   **API Gateway:** Use an API gateway to manage external access to your microservices.  This provides a single point of entry and allows you to implement security policies, rate limiting, and other features.\n\n### Code Splitting\n\n*   **Terraform workspaces:** Use Terraform workspaces to manage different environments within the same Terraform configuration. This avoids code duplication and simplifies environment management.\n*   **Modular design:** Follow a modular design approach for your application code. Break down complex functionalities into smaller, manageable modules.\n*   **Lazy loading:** Implement lazy loading for non-critical components to improve initial load time.  This can be particularly useful for web applications.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Infrastructure as Code (IaC):**  Use Terraform, Pulumi, or other IaC tools to manage your DigitalOcean infrastructure programmatically. This ensures consistency, repeatability, and version control.\n*   **Twelve-Factor App:**  Follow the principles of the Twelve-Factor App methodology for building cloud-native applications. This promotes portability, scalability, and maintainability.\n*   **Containerization:**  Use Docker to containerize your applications. This provides a consistent runtime environment and simplifies deployment to DigitalOcean Kubernetes or Droplets.\n*   **Service Discovery:**  Implement service discovery to allow your microservices to locate each other dynamically.  Tools like Consul or etcd can be used for this purpose.\n\n### Recommended Approaches\n\n*   **Automated Backups:** Regularly back up your Managed Databases and Droplet volumes.  Use DigitalOcean's backup features or implement a custom backup solution using scripts and Object Storage.\n*   **Monitoring:**  Set up monitoring for your DigitalOcean resources using DigitalOcean Monitoring or third-party tools like Prometheus and Grafana.  This allows you to track performance, identify issues, and receive alerts.\n*   **Load Balancing:** Use DigitalOcean Load Balancers to distribute traffic across multiple Droplets. This improves performance and availability.\n*   **CDN:** Use DigitalOcean CDN to cache static assets and improve website performance for users around the world.\n\n### Anti-patterns\n\n*   **Manual Infrastructure Management:**  Avoid manually creating or modifying DigitalOcean resources through the web interface.  This can lead to inconsistencies and makes it difficult to track changes.\n*   **Hardcoding Credentials:** Never hardcode API keys, passwords, or other sensitive information in your code. Store them in environment variables or use a secrets management tool like HashiCorp Vault.\n*   **Ignoring Security Updates:**  Keep your Droplet operating systems and application dependencies up-to-date with the latest security patches.  Use automated tools like `unattended-upgrades` to apply security updates automatically.\n*   **Lack of Monitoring:**  Failing to monitor your DigitalOcean resources can lead to undetected performance issues and outages.\n\n### State Management\n\n*   **Terraform State:** Store Terraform state remotely in DigitalOcean Spaces or other supported backends.  This ensures that your Terraform state is stored securely and can be accessed by multiple team members.\n*   **Application State:**  For stateful applications, use Managed Databases or Object Storage to store persistent data. Avoid storing state directly on Droplets.\n\n### Error Handling\n\n*   **Comprehensive Logging:** Implement comprehensive logging throughout your application.  Include enough information to diagnose issues but avoid logging sensitive data.\n*   **Centralized Logging:** Use a centralized logging system to collect and analyze logs from all your DigitalOcean resources.  Tools like ELK stack (Elasticsearch, Logstash, Kibana) can be used for this purpose.\n*   **Alerting:** Set up alerting to notify you of errors, performance issues, and other critical events.\n*   **Retry Logic:** Implement retry logic for transient errors, such as network timeouts. This can improve the resilience of your application.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Resource Selection:** Choose the appropriate Droplet size and Managed Database tier for your workload.  Start with a smaller instance and scale up as needed.\n*   **Caching:** Implement caching at various levels, including CDN, HTTP caching, and application-level caching. Use Redis or Memcached for in-memory caching.\n*   **Database Optimization:** Optimize your database queries and schema. Use indexes to improve query performance.  Consider using a connection pool to reduce database connection overhead.\n*   **Code Profiling:** Profile your application code to identify performance bottlenecks.  Use profiling tools to identify slow-running functions and optimize them.\n\n### Memory Management\n\n*   **Memory Leaks:**  Be aware of memory leaks in your application code.  Use memory profiling tools to identify and fix memory leaks.\n*   **Garbage Collection:** Understand how garbage collection works in your programming language. Tune garbage collection settings to optimize performance.\n\n### Rendering Optimization\n\n*   **Frontend Optimization:**  Optimize your frontend code by minimizing HTTP requests, compressing images, and using a CDN.\n*   **Lazy Loading:** Implement lazy loading for images and other non-critical resources.\n\n### Bundle Size Optimization\n\n*   **Code Minification:**  Minify your JavaScript and CSS code to reduce bundle size.\n*   **Tree Shaking:** Use tree shaking to remove unused code from your JavaScript bundles.\n*   **Code Splitting:**  Split your code into smaller bundles that can be loaded on demand.\n\n### Lazy Loading\n\n*   **Dynamic Imports:** Use dynamic imports to load modules on demand. This can significantly reduce initial load time.\n*   **Intersection Observer:**  Use the Intersection Observer API to lazy load images and other resources when they become visible in the viewport.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities\n\n*   **SQL Injection:**  Prevent SQL injection by using parameterized queries or an ORM.\n*   **Cross-Site Scripting (XSS):**  Prevent XSS by escaping user input and using a Content Security Policy (CSP).\n*   **Cross-Site Request Forgery (CSRF):**  Prevent CSRF by using anti-CSRF tokens.\n*   **Authentication and Authorization:**  Implement strong authentication and authorization mechanisms to protect your application.\n\n### Input Validation\n\n*   **Whitelisting:** Use whitelisting to validate user input. Only allow specific characters, data types, and formats.\n*   **Escaping:** Escape user input before displaying it to prevent XSS attacks.\n*   **Sanitization:** Sanitize user input to remove potentially harmful characters or code.\n\n### Authentication and Authorization\n\n*   **Strong Passwords:** Enforce strong password policies and use a secure password hashing algorithm like bcrypt or Argon2.\n*   **Multi-Factor Authentication (MFA):** Implement MFA for all users.\n*   **Role-Based Access Control (RBAC):** Use RBAC to control access to resources based on user roles.\n*   **Least Privilege:**  Grant users only the minimum necessary privileges.\n\n### Data Protection\n\n*   **Encryption at Rest:**  Encrypt sensitive data at rest using DigitalOcean's encryption features or a third-party encryption solution.\n*   **Encryption in Transit:**  Use HTTPS to encrypt data in transit between your application and users.\n*   **Data Masking:**  Mask sensitive data when displaying it to users.\n*   **Data Retention Policies:**  Implement data retention policies to ensure that data is only stored for as long as necessary.\n\n### Secure API Communication\n\n*   **API Keys:**  Use API keys to authenticate requests to your APIs.\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your APIs.\n*   **API Versioning:** Use API versioning to allow you to make changes to your APIs without breaking existing clients.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   **Test-Driven Development (TDD):**  Consider using TDD to write unit tests before writing your application code.\n*   **Mocking:** Use mocking to isolate components and test them in isolation.\n*   **Test Coverage:** Aim for high test coverage to ensure that your code is thoroughly tested.\n\n### Integration Testing\n\n*   **Real DigitalOcean Resources:**  Use real DigitalOcean resources for integration tests. This ensures that your code works correctly with the DigitalOcean platform.\n*   **Automated Setup and Teardown:**  Automate the setup and teardown of your test environment.\n\n### End-to-End Testing\n\n*   **Browser Automation:** Use browser automation tools like Selenium or Cypress to test your application from end to end.\n*   **Realistic Scenarios:** Test realistic user scenarios to ensure that your application works as expected.\n\n### Test Organization\n\n*   **Separate Test Directory:**  Create a separate directory for your tests.\n*   **Descriptive Test Names:**  Use descriptive names for your test files and test functions.\n\n### Mocking and Stubbing\n\n*   **Mock DigitalOcean API:** Mock the DigitalOcean API to test your code without making actual API calls. This is particularly useful for unit tests.\n*   **Stub External Dependencies:** Stub external dependencies to isolate your code and make tests more reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   **Not Using IaC:**  Manually managing infrastructure is error-prone and time-consuming. Use Terraform or other IaC tools.\n*   **Hardcoding Secrets:**  Storing secrets in code is a major security risk. Use environment variables or a secrets management tool.\n*   **Ignoring Security Updates:**  Failing to apply security updates can leave your systems vulnerable to attack.\n*   **Lack of Monitoring:**  Not monitoring your systems can lead to undetected problems.\n\n### Edge Cases\n\n*   **API Rate Limits:** Be aware of DigitalOcean API rate limits and implement retry logic to handle rate limit errors.\n*   **Resource Limits:** Be aware of DigitalOcean resource limits (e.g., number of Droplets, volumes, databases) and plan accordingly.\n\n### Version-Specific Issues\n\n*   **Terraform Provider Versions:**  Use specific versions of the DigitalOcean Terraform provider to avoid compatibility issues.\n*   **API Versioning:** Be aware of changes in the DigitalOcean API and update your code accordingly.\n\n### Compatibility Concerns\n\n*   **Operating System Compatibility:**  Ensure that your application is compatible with the operating system running on your Droplets.\n*   **Database Compatibility:** Ensure that your application is compatible with the version of Managed Databases you are using.\n\n### Debugging Strategies\n\n*   **Logging:**  Use comprehensive logging to diagnose issues.\n*   **Remote Debugging:** Use remote debugging to debug your application code running on a Droplet.\n*   **Terraform Debugging:** Use Terraform's debugging features to troubleshoot Terraform configurations.\n\n## 7. Tooling and Environment\n\n### Recommended Tools\n\n*   **Terraform:** For Infrastructure as Code.\n*   **Pulumi:** Alternative Infrastructure as Code using familiar programming languages.\n*   **Docker:** For containerization.\n*   **DigitalOcean CLI (doctl):** For managing DigitalOcean resources from the command line.\n*   **Visual Studio Code (VS Code):** Code editor with extensions for Terraform, Docker, and other technologies.\n*   **Git:** Version control system.\n*   **GitHub/GitLab/Bitbucket:** Code hosting and collaboration platforms.\n\n### Build Configuration\n\n*   **Terraform Modules:**  Structure your Terraform code into reusable modules.\n*   **Terraform Workspaces:** Use Terraform workspaces to manage different environments.\n\n### Linting and Formatting\n\n*   **Terraform fmt:** Use `terraform fmt` to format your Terraform code.\n*   **Shellcheck:** Use Shellcheck to lint your shell scripts.\n*   **Pylint:** Use Pylint to lint your Python code.\n*   **Prettier:** Use Prettier to format your JavaScript and CSS code.\n\n### Deployment Best Practices\n\n*   **CI/CD Pipelines:** Use CI/CD pipelines to automate the deployment process.\n*   **Blue/Green Deployments:** Use blue/green deployments to minimize downtime during deployments.\n*   **Canary Deployments:** Use canary deployments to test new versions of your application with a small subset of users before rolling them out to everyone.\n\n### CI/CD Integration\n\n*   **GitHub Actions:** Use GitHub Actions to automate your CI/CD pipelines.\n*   **GitLab CI/CD:** Use GitLab CI/CD to automate your CI/CD pipelines.\n*   **Jenkins:** Use Jenkins to automate your CI/CD pipelines.\n\nBy following these best practices, you can build scalable, secure, and reliable applications on the DigitalOcean platform.",
    "metadata": {
      "globs": "*.tf,*.yml,*.yaml,*.sh,*.py",
      "format": "mdc",
      "originalFile": "digitalocean.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "digitalocean",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "infrastructure",
      "application",
      "development",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "digitalocean",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-discord-api",
    "description": "This rule provides best practices and coding standards for developing applications with the discord-api library. It covers code organization, performance, security, testing, and common pitfalls to ensure robust and maintainable Discord integrations.",
    "author": "sanjeed5",
    "tags": [
      "discord-api",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/discord-api.mdc",
    "content": "## 1. Code Organization and Structure\n\n-   **Directory Structure:**\n    -   `src/`: Contains the main source code of your bot or application.\n        -   `commands/`:  Houses individual command modules, each in its own file or subdirectory.\n        -   `events/`: Stores event handlers for Discord events (e.g., message creation, member join).\n        -   `models/`: Defines data models and schemas (if applicable).\n        -   `services/`: Contains reusable services or utilities (e.g., database connections, API wrappers).\n        -   `config/`: Configuration files (e.g., API keys, bot token).\n        -   `utils/`: Utility functions and helper modules.\n    -   `tests/`: Unit and integration tests.\n    -   `docs/`: Documentation for your bot or application.\n    -   `scripts/`:  Automation scripts (e.g., deployment, database setup).\n-   **File Naming Conventions:**\n    -   Use descriptive and consistent file names.\n    -   Commands: `command_name.js`, `command_name.ts` or `command_name/index.js` for command directories.\n    -   Events: `event_name.js`, `event_name.ts`.\n    -   Models: `model_name.js`, `model_name.ts`.\n    -   Services: `service_name.js`, `service_name.ts`.\n    -   Configuration files: `config.json`, `config.js`, `config.ts`.\n-   **Module Organization:**\n    -   Break down your bot logic into smaller, reusable modules.\n    -   Use ES modules ( `import/export` in JavaScript/TypeScript) or equivalent module systems in other languages to manage dependencies.\n    -   Avoid circular dependencies between modules.\n-   **Component Architecture:**\n    -   **Command Handlers:** Create a dedicated module to handle command parsing, validation, and execution.\n    -   **Event Emitters:** Use event emitters to decouple event handling logic from the core bot logic.\n    -   **Service Layer:**  Abstract external services (e.g., databases, APIs) behind a service layer.\n    -   **Configuration Management:** Use a configuration management library to handle application settings.\n-   **Code Splitting:**\n    -   Use dynamic imports to load command modules or event handlers on demand, reducing startup time.\n    -   Bundle your code using tools like Webpack, Parcel, or Rollup to optimize bundle size.\n    -   If applicable, use lazy loading for components or modules that are not immediately needed.\n\n## 2. Common Patterns and Anti-patterns\n\n-   **Design Patterns:**\n    -   **Command Pattern:** Encapsulate commands as objects, allowing for flexible command management.\n    -   **Observer Pattern:** Use event emitters to decouple event sources from event listeners.\n    -   **Singleton Pattern:** Implement singleton instances for database connections or other shared resources.\n    -   **Factory Pattern:** Create factories for creating Discord API objects (e.g., messages, embeds).\n-   **Recommended Approaches:**\n    -   Use a command framework (e.g., discord.js commands) to streamline command creation and handling.\n    -   Utilize Discord's rate limiting mechanisms effectively.\n    -   Implement robust error handling and logging.\n    -   Store sensitive information (e.g., API keys, bot token) in environment variables.\n-   **Anti-patterns and Code Smells:**\n    -   **Global State:** Avoid using global variables to store bot state, as it can lead to unexpected behavior.\n    -   **Hardcoding:** Do not hardcode configuration values or API keys in your code.\n    -   **Nested Callbacks:** Avoid deeply nested callbacks, which can make your code difficult to read and maintain. Use async/await or promises instead.\n    -   **Ignoring Errors:** Always handle errors properly and log them for debugging.\n    -   **Over-Complicating:** Keep your code as simple as possible while still meeting the requirements.\n-   **State Management:**\n    -   Use a dedicated state management library (e.g., Redux, Zustand) for complex bot state.\n    -   Store persistent data in a database (e.g., MongoDB, PostgreSQL).\n    -   Implement caching to improve performance.\n-   **Error Handling:**\n    -   Use try-catch blocks to handle potential errors.\n    -   Log errors to a file or service for debugging.\n    -   Implement retry mechanisms for transient errors.\n    -   Use Discord's error events to catch API errors.\n    -   Send user-friendly error messages to users in the Discord channel.\n\n## 3. Performance Considerations\n\n-   **Optimization Techniques:**\n    -   Use efficient data structures and algorithms.\n    -   Cache frequently accessed data.\n    -   Optimize database queries.\n    -   Use asynchronous operations to avoid blocking the main thread.\n    -   Shard your bot to distribute the load across multiple processes.\n-   **Memory Management:**\n    -   Avoid memory leaks by properly releasing resources.\n    -   Use garbage collection to reclaim unused memory.\n    -   Be mindful of large data structures that can consume a lot of memory.\n-   **Rendering Optimization:**\n    -   Optimize image sizes and formats.\n    -   Use lazy loading for images and other media.\n    -   Consider using optimized libraries for generating images or videos.\n-   **Bundle Size Optimization:**\n    -   Use tree shaking to remove unused code from your bundle.\n    -   Minify your code to reduce bundle size.\n    -   Compress your bundle using Gzip or Brotli.\n-   **Lazy Loading:**\n    -   Load command modules and event handlers on demand.\n    -   Load images and other media only when they are needed.\n\n## 4. Security Best Practices\n\n-   **Common Vulnerabilities:**\n    -   **Code Injection:** Prevent code injection vulnerabilities by validating user input and avoiding the use of `eval()` or similar functions.\n    -   **Cross-Site Scripting (XSS):**  If your bot interacts with websites or web applications, prevent XSS vulnerabilities by sanitizing user input and escaping output.\n    -   **SQL Injection:**  If your bot interacts with a database, prevent SQL injection vulnerabilities by using parameterized queries or an ORM.\n    -   **Denial of Service (DoS):** Protect your bot from DoS attacks by implementing rate limiting and input validation.\n    -   **Unauthorized Access:** Secure your bot's API endpoints and data by implementing authentication and authorization.\n-   **Input Validation:**\n    -   Validate all user input to prevent malicious or invalid data from being processed.\n    -   Use regular expressions or other validation techniques to enforce data types and formats.\n    -   Sanitize user input to remove potentially harmful characters or code.\n-   **Authentication and Authorization:**\n    -   Use a secure authentication mechanism to verify the identity of users.\n    -   Implement authorization policies to control access to resources and functionality.\n    -   Use role-based access control (RBAC) to manage user permissions.\n-   **Data Protection:**\n    -   Encrypt sensitive data at rest and in transit.\n    -   Use secure storage mechanisms to protect API keys, bot tokens, and other credentials.\n    -   Implement data loss prevention (DLP) measures to prevent sensitive data from being leaked.\n-   **Secure API Communication:**\n    -   Use HTTPS to encrypt communication with the Discord API.\n    -   Verify the server certificate to prevent man-in-the-middle attacks.\n    -   Use secure API keys or tokens to authenticate with the Discord API.\n\n## 5. Testing Approaches\n\n-   **Unit Testing:**\n    -   Write unit tests for individual components and modules.\n    -   Use mocking or stubbing to isolate components from external dependencies.\n    -   Test edge cases and error conditions.\n-   **Integration Testing:**\n    -   Write integration tests to verify the interaction between different components.\n    -   Test the bot's integration with the Discord API.\n    -   Use a test Discord server to run integration tests.\n-   **End-to-End Testing:**\n    -   Write end-to-end tests to verify the entire bot workflow.\n    -   Simulate user interactions to test the bot's functionality.\n    -   Use a testing framework to automate end-to-end tests.\n-   **Test Organization:**\n    -   Organize your tests into separate directories for unit tests, integration tests, and end-to-end tests.\n    -   Use descriptive test names to indicate the purpose of each test.\n    -   Follow a consistent naming convention for test files.\n-   **Mocking and Stubbing:**\n    -   Use mocking libraries to create mock objects that simulate the behavior of external dependencies.\n    -   Use stubbing to replace real dependencies with simplified versions for testing purposes.\n\n## 6. Common Pitfalls and Gotchas\n\n-   **Frequent Mistakes:**\n    -   **Rate Limiting:**  Failing to handle Discord API rate limits properly.\n    -   **Incorrect Intents:**  Not specifying the correct gateway intents for your bot.\n    -   **Asynchronous Operations:**  Not properly handling asynchronous operations, leading to race conditions or unexpected behavior.\n    -   **Data Serialization:** Incorrectly serializing or deserializing data when interacting with the API.\n    -   **Privileged Intents:** Not understanding the requirements for using privileged intents (e.g., presence, guild members, message content).\n-   **Edge Cases:**\n    -   Handling large guilds with many members or channels.\n    -   Dealing with unexpected API errors or outages.\n    -   Handling different user locales and languages.\n    -   Managing concurrency and race conditions.\n-   **Version-Specific Issues:**\n    -   Being aware of breaking changes between different versions of the discord-api library.\n    -   Using deprecated features or APIs.\n    -   Ensuring compatibility with different versions of Node.js or other dependencies.\n-   **Compatibility Concerns:**\n    -   Ensuring compatibility with different operating systems and platforms.\n    -   Avoiding conflicts with other libraries or dependencies.\n    -   Testing the bot on different Discord clients (e.g., web, desktop, mobile).\n-   **Debugging Strategies:**\n    -   Use logging to track the bot's execution flow and identify errors.\n    -   Use a debugger to step through the code and inspect variables.\n    -   Use Discord's developer tools to inspect API requests and responses.\n    -   Test your code thoroughly and write unit tests to catch errors early.\n\n## 7. Tooling and Environment\n\n-   **Recommended Development Tools:**\n    -   **IDE:** Visual Studio Code, IntelliJ IDEA, or other IDE with support for JavaScript/TypeScript.\n    -   **Package Manager:** npm or yarn for managing dependencies.\n    -   **Debugging Tools:** Node.js debugger or Chrome DevTools.\n    -   **Linting Tools:** ESLint or JSHint for enforcing coding standards.\n    -   **Formatting Tools:** Prettier for automatically formatting code.\n-   **Build Configuration:**\n    -   Use a build tool like Webpack, Parcel, or Rollup to bundle your code.\n    -   Configure your build process to minify and compress your code.\n    -   Use environment variables to configure your build process.\n-   **Linting and Formatting:**\n    -   Use ESLint or JSHint to enforce coding standards.\n    -   Use Prettier to automatically format your code.\n    -   Configure your editor to automatically run linters and formatters on save.\n-   **Deployment Best Practices:**\n    -   Use a process manager like PM2 or systemd to keep your bot running.\n    -   Deploy your bot to a cloud platform like Heroku, AWS, or Google Cloud.\n    -   Use a reverse proxy like Nginx or Apache to handle incoming requests.\n    -   Monitor your bot's performance and health.\n-   **CI/CD Integration:**\n    -   Use a CI/CD platform like GitHub Actions, GitLab CI, or CircleCI to automate your build, test, and deployment process.\n    -   Run unit tests and integration tests as part of your CI/CD pipeline.\n    -   Automate the deployment process to reduce manual effort and errors.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx,*.py,*.cs",
      "format": "mdc",
      "originalFile": "discord-api.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "discord",
      "api",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "applications",
      "with",
      "discord-api",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "discord-api",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-django-orm",
    "description": "This rule file provides comprehensive best practices for Django's Object-Relational Mapper (ORM), covering code organization, performance, security, testing, and common pitfalls. It aims to guide developers in building efficient, maintainable, and secure Django applications.",
    "author": "sanjeed5",
    "tags": [
      "django-orm",
      "django",
      "python",
      "backend",
      "web",
      "go",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "mvc",
      "orm",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/django-orm.mdc",
    "content": "## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n- **Application-Centric Structure:** Organize your Django project around applications (apps), where each app represents a specific feature or module.\n- **Dedicated 'models' Module:** Keep all model definitions within the `models.py` file of each app.\n- **Separate Queries:** For complex queries, consider creating a `queries.py` or `managers.py` file within your app to house custom querysets and managers.\n- **Consistent Naming:** Use consistent naming conventions for app and model names.\n\n\nmyproject/\n ├── myproject/\n │   ├── __init__.py\n │   ├── asgi.py\n │   ├── settings.py\n │   ├── urls.py\n │   ├── wsgi.py\n ├── app1/\n │   ├── __init__.py\n │   ├── admin.py\n │   ├── apps.py\n │   ├── models.py\n │   ├── managers.py  # Custom managers and querysets\n │   ├── views.py\n │   ├── urls.py\n │   ├── forms.py\n │   ├── tests.py\n │   └── migrations/\n ├── app2/\n │   └── ...\n └── manage.py\n\n\n### 1.2. File Naming Conventions\n\n- **Models:** Use singular nouns and CamelCase (e.g., `UserProfile`, `BlogPost`).\n- **Fields:** Use lowercase with underscores (snake_case, e.g., `first_name`, `date_joined`).\n- **Managers/Querysets:** Use descriptive names related to their functionality (e.g., `ActiveUsersManager`, `PublishedPostsQuerySet`).\n- **Files:** Use lowercase with underscores (snake_case, e.g., `models.py`, `forms.py`, `urls.py`).\n\n### 1.3. Module Organization\n\n- **Keep Models Concise:** Limit the number of models in each app to a manageable amount (ideally under 10). If an app becomes too large, refactor it into smaller, more focused apps.\n- **Avoid Circular Imports:** Be mindful of circular dependencies between models and other modules within the same app or across apps.  Use string references in `ForeignKey` and `ManyToManyField` definitions to avoid immediate import requirements.\n- **Utilize Abstract Base Classes:** For common fields across multiple models, define an abstract base class and inherit from it. This promotes code reuse and reduces redundancy. Don't forget to set `abstract = True` in the `Meta` class.\n- **Consider Proxy Models:** Use proxy models (`proxy = True` in `Meta`) to change a model's behavior without altering the database schema. This is useful for adding methods or changing the default ordering.\n\n### 1.4. Component Architecture\n\n- **DRY (Don't Repeat Yourself):** Create reusable components such as custom model fields, managers, and querysets.  \n- **Model Mixins:** Use model mixins to add common functionality to multiple models (e.g., a mixin for soft deletion or timestamping).\n- **Form Abstraction:** Create reusable form classes and widgets for data input and validation.\n- **Template Tags and Filters:** Develop custom template tags and filters to simplify common tasks in templates related to model data.\n\n### 1.5. Code Splitting Strategies\n\n- **App-Based Splitting:** Organize models and related code within distinct Django apps.\n- **Manager-Based Splitting:** Divide complex queries into custom managers and querysets.\n- **Mixin-Based Splitting:** Utilize mixins to compartmentalize functionality across models.\n- **Signal-Based Splitting:** Implement signals for decoupling operations, such as triggering tasks when a model is saved or deleted.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Repository Pattern:** Abstract data access logic behind a repository interface, allowing you to switch between different data sources without modifying the rest of your application.\n- **Unit of Work Pattern:** Group multiple database operations into a single transaction to ensure atomicity and consistency.\n- **Specification Pattern:** Encapsulate query logic into reusable specification objects, allowing you to combine and reuse queries across different parts of your application.\n- **Model Decorators:** Use decorators to add functionality to models without modifying the original model class. Useful for things like caching calculated properties.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n- **Filtering Data:** Use `filter()` and `exclude()` for efficient data retrieval.\n- **Ordering Data:** Utilize `order_by()` to specify the order of results.\n- **Aggregating Data:** Employ `aggregate()` to calculate summary statistics.\n- **Creating and Updating Objects:** Use `create()` and `save()` for object manipulation.\n- **Deleting Objects:** Use `delete()` for removing objects.\n- **Prefetch Related:** Use `select_related` for ForeignKey and OneToOneField relationships, and `prefetch_related` for ManyToManyField and reverse ForeignKey relationships.\n\n### 2.3. Anti-patterns and Code Smells\n\n- **Overusing `raw()` Queries:** Prefer Django ORM methods over raw SQL queries to maintain database abstraction and security.\n- **Ignoring Database Indexes:** Neglecting to add indexes to frequently queried columns can lead to significant performance bottlenecks. Use `db_index = True` and `Index` in Meta to specify indices.\n- **Using `null=True` for String-Based Fields:** Avoid `null=True` for `CharField` and `TextField` fields. Use `blank=True` and an empty string (`''`) instead.\n- **Creating Large Querysets without Pagination:** Avoid retrieving large datasets without pagination. Use Django's `Paginator` to break results into manageable chunks.\n- **Performing Logic in Templates:** Keep templates focused on presentation. Move complex logic to views or custom template tags.\n- **N+1 Query Problem:** Accessing related objects in a loop can cause the N+1 query problem. Use `select_related()` and `prefetch_related()` to mitigate this.\n- **Inefficient Use of Exists/Count:** Prefer `exists()` over `count()` when simply checking for the existence of objects.\n- **Unnecessary Database Hits:** Optimize data access patterns to minimize the number of database queries.\n\n### 2.4. State Management\n\n- **Database as Primary State:** Rely on the database as the single source of truth for application state.\n- **Session Management:** Utilize Django's session framework for storing user-specific state.\n- **Caching:** Implement caching strategies to reduce database load and improve response times.\n- **Avoid Global Mutable State:**  Minimize the use of global mutable state, as it can lead to unexpected behavior and concurrency issues.\n\n### 2.5. Error Handling\n\n- **Catch Database Exceptions:** Handle database exceptions (e.g., `IntegrityError`, `OperationalError`) gracefully.\n- **Use Transactions:** Wrap multiple database operations in a transaction to ensure atomicity.\n- **Log Errors:** Log errors and exceptions for debugging and monitoring purposes.  Use `logger.exception()` to capture the traceback.\n- **Custom Exception Handling Middleware:** Consider writing custom middleware to catch and handle database errors at a global level, providing user-friendly error messages.\n- **Validate Data Before Saving:** Always validate data before saving it to the database to prevent errors and data inconsistencies. Use Django's built-in validators or create custom validators.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Query Optimization:** Use `select_related` and `prefetch_related` to reduce the number of database queries.\n- **Indexing:** Add indexes to frequently queried columns.\n- **Caching:** Implement caching strategies for frequently accessed data.\n- **Pagination:** Use pagination for large datasets.\n- **Batch Operations:** Use `bulk_create`, `bulk_update` and `bulk_delete` for bulk operations.\n- **Defer/Only:** use `defer` to exclude fields from the query or `only` to only include specific fields in the query.\n- **Conditional Expressions:** Use `Case`, `When`, and `Value` within queries to perform conditional logic directly in the database.\n\n### 3.2. Memory Management\n\n- **Limit Queryset Size:** Avoid retrieving large datasets into memory. Use pagination or generators.\n- **Use Generators:** For processing large datasets, use generators to process data in chunks.\n- **Garbage Collection:** Understand Python's garbage collection mechanisms and how they affect memory usage.\n- **Profiling:** Use profiling tools to identify memory leaks and optimize memory usage.\n\n### 3.3. Rendering Optimization\n\n- **Template Caching:** Cache frequently used templates to reduce rendering time.\n- **Context Processors:** Minimize the data passed to templates via context processors.\n- **Lazy Loading:** Use lazy loading for images and other resources to improve initial page load time.  Consider using template tags like `{% static %}` and `{% get_static_prefix %}` effectively.\n\n### 3.4. Bundle Size Optimization\n\n- **Remove Unused Code:** Eliminate unused models, fields, and queries.\n- **Optimize Static Files:** Minify and compress static files (CSS, JavaScript, images).\n- **Code Splitting:**  Split JavaScript and CSS into smaller chunks for efficient loading.\n\n### 3.5. Lazy Loading\n\n- **Load Related Data on Demand:** Use lazy loading for related data to improve initial performance. Consider using Django Rest Framework serializers with `depth=0` and selectively increasing the depth when needed.\n- **Database Views:** Create database views for complex queries to improve performance.\n- **QuerySet Iterators:** Instead of converting large querysets into lists, iterate over them using `.iterator()` for memory efficiency.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n- **SQL Injection:** Prevent SQL injection by using Django ORM methods instead of raw SQL queries. Always parameterize your queries.\n- **Cross-Site Scripting (XSS):** Sanitize user input and escape output in templates.\n- **Cross-Site Request Forgery (CSRF):** Use Django's CSRF protection mechanisms.\n- **Authentication and Authorization:** Implement robust authentication and authorization mechanisms.\n- **Session Hijacking:** Secure sessions using HTTPS and appropriate session settings.\n\n### 4.2. Input Validation\n\n- **Use Django Forms:** Employ Django Forms for validating user input.\n- **Sanitize User Input:** Sanitize user input to prevent XSS attacks.\n- **Validate Data Types:** Validate data types to prevent database errors.\n- **Limit Input Length:** Restrict input length to prevent buffer overflows.\n- **Custom Validators:** Create custom validators for complex validation logic.\n- **Consider using DRF Serializers:** Use Django Rest Framework Serializers to add an extra layer of validation to your models and data.\n\n### 4.3. Authentication and Authorization\n\n- **Use Django's Built-in Authentication:** Leverage Django's built-in authentication framework.\n- **Implement Role-Based Access Control (RBAC):** Define roles and permissions for different user types.\n- **Enforce Password Policies:** Enforce strong password policies.\n- **Use Multi-Factor Authentication (MFA):** Implement MFA for sensitive accounts.\n- **Rate Limiting:** Implement rate limiting to prevent brute-force attacks.\n\n### 4.4. Data Protection\n\n- **Use HTTPS:** Use HTTPS to encrypt data in transit.\n- **Encrypt Sensitive Data:** Encrypt sensitive data at rest.\n- **Store Passwords Securely:** Store passwords using a strong hashing algorithm (e.g., bcrypt, Argon2).\n- **Regularly Back Up Data:** Regularly back up your database.\n- **Audit Logging:** Implement audit logging to track user activity and data changes.\n\n### 4.5. Secure API Communication\n\n- **Use API Keys:** Use API keys for authenticating API requests.\n- **Implement OAuth 2.0:** Implement OAuth 2.0 for secure API authorization.\n- **Validate API Input:** Validate API input to prevent injection attacks.\n- **Rate Limiting:** Implement rate limiting to prevent API abuse.\n- **API Versioning:** Use API versioning to manage changes to your API.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- **Test Model Methods:** Unit test model methods to ensure they behave as expected.\n- **Test Custom Managers:** Unit test custom managers to verify their query logic.\n- **Test Validators:** Unit test validators to ensure they correctly validate data.\n- **Mock Database Dependencies:** Use mocking to isolate model tests from the database.\n\n### 5.2. Integration Testing\n\n- **Test Views and Models:** Integrate test views and models to ensure they work together correctly.\n- **Test Forms and Models:** Integrate test forms and models to verify data validation and persistence.\n- **Use Test Fixtures:** Use test fixtures to create consistent test data.\n- **Test Database Interactions:** Test database interactions to ensure they are efficient and correct.\n\n### 5.3. End-to-End Testing\n\n- **Test User Workflows:** End-to-end test user workflows to ensure they are functional and user-friendly.\n- **Test API Endpoints:** End-to-end test API endpoints to ensure they are secure and functional.\n- **Use Selenium or Similar Tools:** Use Selenium or similar tools for automating end-to-end tests.\n- **Test Across Different Browsers:** Test across different browsers to ensure compatibility.\n\n### 5.4. Test Organization\n\n- **Organize Tests by App:** Organize tests by app to improve maintainability.\n- **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what is being tested.\n- **Follow a Consistent Test Structure:** Follow a consistent test structure to improve readability.\n- **Use Test Runners:** Use test runners to automate test execution.\n\n### 5.5. Mocking and Stubbing\n\n- **Mock Database Queries:** Mock database queries to isolate tests from the database.\n- **Stub External Dependencies:** Stub external dependencies to control test environments.\n- **Use Django's `override_settings` Decorator:** Use Django's `override_settings` decorator to modify settings during tests.\n- **Use `patch` for Mocking:** Use `unittest.mock.patch` for mocking objects and functions.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Not Using Indexes:** Forgetting to add indexes to frequently queried columns.\n- **Overusing `null=True`:** Using `null=True` for string-based fields.\n- **Ignoring Database Transactions:** Not using database transactions for critical operations.\n- **Creating Large Querysets:** Creating large querysets without pagination.\n- **Performing Logic in Templates:** Performing logic in templates instead of views.\n- **N+1 Query Problem:** Not addressing the N+1 query problem.\n\n### 6.2. Edge Cases\n\n- **Unicode Handling:** Handling Unicode characters correctly.\n- **Time Zones:** Dealing with time zones accurately.\n- **Concurrency Issues:** Managing concurrency issues in multi-threaded environments.\n- **Database-Specific Differences:** Handling database-specific differences.\n\n### 6.3. Version-Specific Issues\n\n- **Deprecated Features:** Being aware of deprecated features and migrating to newer alternatives.\n- **Compatibility Changes:** Handling compatibility changes between Django versions.\n\n### 6.4. Compatibility Concerns\n\n- **Python Version:** Ensuring compatibility with the supported Python versions.\n- **Database Compatibility:** Ensuring compatibility with the chosen database.\n- **Third-Party Libraries:** Ensuring compatibility with third-party libraries.\n\n### 6.5. Debugging\n\n- **Use Django's Debug Toolbar:** Use Django's Debug Toolbar for profiling and debugging.\n- **Inspect Database Queries:** Inspect database queries to identify performance bottlenecks.\n- **Log Errors and Exceptions:** Log errors and exceptions for debugging purposes.\n- **Use a Debugger:** Use a debugger to step through code and inspect variables.\n- **Read Stack Traces Carefully:** Read stack traces carefully to understand the source of errors.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **IDE:** PyCharm, VS Code with Python extension.\n- **Database Client:** pgAdmin, MySQL Workbench, DB Browser for SQLite.\n- **Virtual Environment Manager:** virtualenv, pipenv, conda.\n- **Debug Toolbar:** Django Debug Toolbar.\n- **Profiling Tools:** cProfile, line_profiler.\n\n### 7.2. Build Configuration\n\n- **Use a Virtual Environment:** Use a virtual environment to isolate project dependencies.\n- **Specify Dependencies:** Specify dependencies in a `requirements.txt` or `Pipfile`.\n- **Use a Build System:** Use a build system (e.g., Make, Fabric) to automate build tasks.\n- **Configure Static File Handling:** Configure static file handling correctly for production.\n\n### 7.3. Linting and Formatting\n\n- **Use a Linter:** Use a linter (e.g., pylint, flake8) to enforce code style.\n- **Use a Formatter:** Use a formatter (e.g., black, autopep8) to automatically format code.\n- **Configure Editor Integration:** Configure editor integration to automatically lint and format code on save.\n- **Follow PEP 8:** Adhere to PEP 8 style guidelines.\n\n### 7.4. Deployment\n\n- **Use a Production-Ready Web Server:** Use a production-ready web server (e.g., Gunicorn, uWSGI).\n- **Use a Reverse Proxy:** Use a reverse proxy (e.g., Nginx, Apache) to handle static files and load balancing.\n- **Use a Database Server:** Use a dedicated database server (e.g., PostgreSQL, MySQL).\n- **Configure Caching:** Configure caching to improve performance.\n- **Secure Deployment:** Secure the deployment environment with appropriate firewalls and security settings.\n- **Use Environment Variables:** Store sensitive configuration data (e.g., database passwords, API keys) in environment variables.\n\n### 7.5. CI/CD Integration\n\n- **Use a CI/CD System:** Use a CI/CD system (e.g., Jenkins, Travis CI, GitLab CI) to automate testing and deployment.\n- **Run Tests Automatically:** Run tests automatically on every commit.\n- **Deploy Automatically:** Deploy automatically on successful builds.\n- **Use Infrastructure as Code:** Use infrastructure as code (e.g., Terraform, Ansible) to automate infrastructure provisioning.\n\n---\n\nBy consistently applying these best practices, you'll establish a robust foundation for building high-quality Django applications that are performant, maintainable, and secure.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "django-orm.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "django",
      "orm",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "object",
      "relational",
      "django-orm",
      "python",
      "backend",
      "web",
      "go",
      "performance",
      "cursor-rule",
      "mdc",
      "mvc",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "django-orm",
        "django",
        "python",
        "backend",
        "web",
        "go",
        "golang",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-django-rest-framework",
    "description": "A comprehensive guide to best practices for developing REST APIs using Django REST Framework (DRF), covering code structure, design patterns, security, performance, and testing.",
    "author": "sanjeed5",
    "tags": [
      "django-rest-framework",
      "django",
      "python",
      "backend",
      "web",
      "rest",
      "api",
      "go",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "mvc",
      "orm",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/django-rest-framework.mdc",
    "content": "---\n# django-rest-framework Best Practices\n\nThis document provides a comprehensive guide to best practices for developing robust, scalable, and maintainable REST APIs using the Django REST Framework (DRF). It covers various aspects of DRF development, including code organization, design patterns, security considerations, performance optimization, testing strategies, and common pitfalls.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nA well-structured project layout is crucial for maintainability and scalability. Here's a recommended directory structure:\n\n\nmyproject/\n  manage.py\n  myproject/\n    __init__.py\n    settings/\n      __init__.py\n      base.py       # Base settings for all environments\n      development.py  # Settings for development environment\n      production.py   # Settings for production environment\n    urls.py         # Root URL configuration\n    asgi.py\n    wsgi.py\n  api/            # Top-level for all apps interacting via REST API\n    __init__.py\n    app1/\n      __init__.py\n      models.py     # Database models\n      serializers.py# DRF serializers\n      views.py        # DRF viewsets and API views\n      urls.py         # App-specific URL configuration\n      permissions.py  # Custom permissions\n      filters.py      # Custom filters\n      tasks.py        # Celery tasks (if applicable)\n      tests.py        # Unit and integration tests\n    app2/...\n  core/            # Core app for user management, etc.\n  utils/          # General utility functions and modules\n  docs/           # API documentation (e.g., OpenAPI specification)\n\n\n### 1.2. File Naming Conventions\n\n*   `models.py`: Contains database models.\n*   `serializers.py`: Contains DRF serializers.\n*   `views.py`: Contains DRF viewsets and API views.\n*   `urls.py`: Contains app-specific URL configurations.\n*   `permissions.py`: Contains custom permissions.\n*   `filters.py`: Contains custom filters.\n*   `tasks.py`: Contains Celery tasks (if applicable).\n*   `tests.py`: Contains unit and integration tests.\n*   Descriptive names for custom serializers, views, permissions, and filters (e.g., `UserSerializer`, `ProductListView`, `IsAdminOrReadOnly`, `ProductFilter`).\n\n### 1.3. Module Organization\n\n*   **Keep apps focused:** Each app should represent a distinct feature or domain within your API.\n*   **Abstract common logic:** Move reusable code into utility modules within each app or in a shared `utils` directory.\n*   **Separate concerns:** Ensure that models, serializers, views, and other components are logically separated within their respective modules.\n\n### 1.4. Component Architecture\n\n*   **Models:** Define the data structure and relationships using Django's ORM.\n*   **Serializers:** Convert model instances to JSON and vice versa, handling data validation.\n*   **Viewsets:** Group related API endpoints (CRUD operations) for a model. Use Generic Views for simpler endpoints.\n*   **Permissions:** Control access to API endpoints based on user roles or other criteria.\n*   **Filters:** Allow clients to filter and sort data.\n*   **Pagination:** Manage large datasets by returning results in pages.\n\n### 1.5. Code Splitting\n\n*   **Break down large viewsets:** Decompose complex viewsets into smaller, more manageable classes or functions.\n*   **Use mixins:** Employ DRF's mixins to reuse common viewset logic.\n*   **Custom methods for complex logic:** Move complex logic out of views and into helper functions or service classes.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Serializer Pattern:** Encapsulates the conversion of model instances to and from JSON.  Enforces data validation rules.\n*   **Service Layer Pattern:** Encapsulates business logic and data access. Decouples views from models.\n*   **Repository Pattern:** An abstraction layer between data access logic and the rest of the application. (Less common in Django, but can be helpful for complex scenarios)\n*   **Factory Pattern:** Creates objects in a centralized location. Simplifies object creation logic.\n*   **Decorator Pattern:** Adds behavior to existing functions or classes. Enhances functionality without modifying core code.\n\n### 2.2. Recommended Approaches\n\n*   **CRUD operations:** Use DRF's ModelViewSet for standard CRUD operations on a model.\n*   **Custom API endpoints:** Create custom views using `APIView` or generic views for specialized functionality.\n*   **Data validation:** Leverage DRF's serializers for robust data validation.\n*   **Authentication:** Use token authentication, session authentication, or OAuth for secure access.\n*   **Authorization:** Implement permission classes to control access to resources.\n*   **Filtering and sorting:** Use DRF's filtering and ordering capabilities.\n*   **Pagination:** Implement pagination for list endpoints with large datasets.\n*   **Versioning:** Implement API versioning to support evolving APIs.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Fat models:** Avoid putting business logic directly into models.\n*   **Fat views:** Keep views thin and delegate business logic to service classes.\n*   **Inconsistent naming:** Use consistent naming conventions throughout the project.\n*   **Lack of documentation:** Document all API endpoints and code components.\n*   **Ignoring errors:** Handle errors gracefully and provide meaningful error messages.\n*   **Over-engineering:** Don't overcomplicate solutions for simple problems.\n*   **Duplicated code:** Identify and refactor duplicated code into reusable functions or components.\n*   **Hardcoded values:** Avoid hardcoding configuration values in the code.\n\n### 2.4. State Management\n\n*   **Stateless API:**  DRF is inherently stateless, relying on tokens, sessions, or other mechanisms for authentication rather than server-side state. Each request should contain all the necessary information for processing.\n*   **Client-side state:** State management should primarily be handled on the client-side using libraries like Redux, Vuex, or React Context.\n*   **Avoid server-side sessions for API state:** Server-side sessions are less scalable and can introduce complexity.\n\n### 2.5. Error Handling\n\n*   **Use DRF's exception handling:** DRF provides built-in exception handling that returns appropriate HTTP status codes and error messages.\n*   **Custom exception handling:**  Extend DRF's exception handling to customize error responses.\n*   **Logging:** Log errors and warnings for debugging and monitoring.\n*   **Meaningful error messages:**  Provide clear and helpful error messages to clients.\n*   **Centralized error handling:**  Create middleware to catch exceptions and log/report.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Database query optimization:**  Use Django's ORM efficiently, using `select_related` and `prefetch_related` to reduce database queries. Analyze queries with Django Debug Toolbar.\n*   **Caching:**  Implement caching (using Django's caching framework or Redis) for frequently accessed data.\n*   **Pagination:** Use pagination for list endpoints with large datasets.\n*   **Filtering:**  Implement efficient filtering mechanisms to reduce the amount of data processed.\n*   **Gzip compression:** Enable Gzip compression to reduce the size of API responses.\n*   **Throttling:**  Implement API throttling to prevent abuse.\n*   **Use `defer()` and `only()`:** Retrieve only the necessary fields from the database.\n*   **Raw SQL Queries:** For very specific and highly optimized queries where the ORM becomes inefficient, consider using raw SQL queries.\n*   **Asynchronous tasks:** Use Celery to offload long-running tasks to background workers.\n*   **Read-only serializers:** Use `read_only=True` for fields that should not be updated by clients.\n*   **Caching Serialized Data:** Cache the results of serializers when appropriate.\n\n### 3.2. Memory Management\n\n*   **Avoid loading large datasets into memory:** Use iterators or generators to process data in chunks.\n*   **Close database connections:** Ensure that database connections are closed properly after use.\n*   **Garbage collection:** Understand Python's garbage collection mechanisms and avoid creating circular references.\n\n### 3.3. Rendering Optimization\n\n*   **Use DRF's built-in renderers:** DRF provides renderers for JSON, XML, and other formats.  Use the appropriate renderer for your API.\n*   **Custom renderers:**  Create custom renderers for specialized output formats.\n*   **Streaming responses:** Use streaming responses for large datasets.\n\n### 3.4. Bundle Size Optimization (If applicable - primarily for client-side rendering)\n\n*   **Tree shaking:**  Remove unused code from JavaScript bundles.\n*   **Code splitting:**  Split JavaScript bundles into smaller chunks that can be loaded on demand.\n*   **Minification:**  Minify JavaScript and CSS files to reduce their size.\n\n### 3.5. Lazy Loading\n\n*   **Lazy load related data:**  Load related data only when it is needed.\n*   **Use DRF's `depth` option:**  Control the depth of nested serialization.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **SQL injection:** Prevent SQL injection by using Django's ORM and parameterized queries.\n*   **Cross-site scripting (XSS):**  Sanitize user input to prevent XSS attacks (more relevant for templates, but consider it for any user-provided data).\n*   **Cross-site request forgery (CSRF):**  Protect against CSRF attacks by using Django's CSRF protection mechanisms.\n*   **Authentication bypass:**  Ensure that authentication is properly enforced for all API endpoints.\n*   **Authorization flaws:**  Implement fine-grained authorization to restrict access to resources.\n*   **Data leakage:**  Avoid exposing sensitive data in API responses.\n*   **Denial of Service (DoS):**  Implement rate limiting and other measures to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n*   **Use DRF's serializers for input validation:** Serializers provide a convenient way to validate incoming data.\n*   **Validate data types:**  Ensure that data types match the expected types.\n*   **Validate data ranges:**  Ensure that data values fall within the allowed ranges.\n*   **Sanitize user input:**  Sanitize user input to prevent XSS attacks.\n*   **Escape output:** Escape data when rendering it in templates to prevent XSS attacks.\n*   **Custom Validation:** Implement custom validation logic in serializers to enforce complex business rules.\n\n### 4.3. Authentication and Authorization\n\n*   **Choose the appropriate authentication scheme:** Use token authentication, session authentication, or OAuth based on your requirements.\n*   **Implement permission classes:**  Use permission classes to control access to resources based on user roles or other criteria.\n*   **Use JWT (JSON Web Tokens) for stateless authentication:** JWTs are a popular choice for stateless authentication in REST APIs.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to manage user permissions based on roles.\n*   **Principle of Least Privilege:** Grant users only the minimum necessary permissions.\n*   **Multi-Factor Authentication (MFA):** Implement MFA for enhanced security.\n*   **Regularly rotate API keys:** Rotate API keys regularly to reduce the risk of compromise.\n\n### 4.4. Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:**  Use HTTPS for all API communication.\n*   **Store passwords securely:**  Use Django's password hashing mechanisms to store passwords securely.\n*   **Data masking:** Mask sensitive data when displaying it to users.\n*   **Data retention policies:** Implement data retention policies to ensure that data is not stored longer than necessary.\n*   **Audit logging:** Implement audit logging to track access to sensitive data.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:**  Use HTTPS for all API communication.\n*   **Implement CORS:**  Configure CORS (Cross-Origin Resource Sharing) to allow requests from specific domains.\n*   **Rate limiting:** Implement API throttling to prevent abuse.\n*   **Input Validation:** Implement robust data validation and sanitization.\n*   **Secure Headers:** Use secure HTTP headers like `X-Content-Type-Options`, `Strict-Transport-Security`, and `X-Frame-Options`.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test serializers:**  Test that serializers correctly serialize and deserialize data, and that validation rules are enforced.\n*   **Test views:**  Test that views return the expected responses for different requests, and that permissions are enforced.\n*   **Test models:** Test model methods and data integrity.\n*   **Isolate units of code:**  Use mocking and stubbing to isolate units of code during testing.\n*   **Follow Arrange-Act-Assert pattern:** Arrange test data, act on the code, and assert the expected result.\n\n### 5.2. Integration Testing\n\n*   **Test API endpoints:**  Test that API endpoints work correctly when integrated with other components.\n*   **Test database interactions:**  Test that database interactions are performed correctly.\n*   **Test authentication and authorization:**  Test that authentication and authorization mechanisms work as expected.\n*   **Use Django's test client:** Use Django's test client to send HTTP requests to API endpoints.\n*   **Test with real database:** Use a separate test database for integration tests.\n\n### 5.3. End-to-End Testing\n\n*   **Test the entire API workflow:**  Test the entire API workflow from end to end.\n*   **Use tools like Selenium or Cypress:**  Use tools like Selenium or Cypress to automate end-to-end tests.\n*   **Test with a production-like environment:** Test with a production-like environment to ensure that the API works correctly in a real-world setting.\n\n### 5.4. Test Organization\n\n*   **Create a separate `tests.py` file for each app:** This promotes modularity and makes it easier to find tests for a specific app.\n*   **Organize tests within `tests.py` by component:** Group tests for serializers, views, models, and other components.\n*   **Use descriptive test names:** Use descriptive test names that clearly indicate what each test is testing.\n*   **Follow a consistent naming convention:** Use a consistent naming convention for test functions and classes.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use mocking to isolate units of code:** Mock external dependencies to isolate units of code during testing.\n*   **Use stubbing to provide controlled responses:** Stub external dependencies to provide controlled responses during testing.\n*   **Use libraries like `unittest.mock`:**  Use libraries like `unittest.mock` for mocking and stubbing.\n*   **Avoid over-mocking:** Only mock the necessary dependencies to keep tests realistic.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not using serializers for validation:**  Skipping serializer validation can lead to data integrity issues and security vulnerabilities.\n*   **Incorrectly configuring permissions:** Misconfigured permissions can expose resources to unauthorized users.\n*   **Over-fetching data:**  Fetching more data than necessary can impact performance.\n*   **Ignoring database query optimization:** Inefficient database queries can lead to slow API responses.\n*   **Not handling errors gracefully:** Unhandled exceptions can cause the API to crash or return unhelpful error messages.\n*   **Using `CharField` without `max_length`**: Can lead to unexpected database errors or vulnerabilities.\n\n### 6.2. Edge Cases\n\n*   **Handling null values:**  Ensure that null values are handled correctly in serializers and views.\n*   **Handling empty lists:**  Ensure that empty lists are handled correctly in serializers and views.\n*   **Handling unicode characters:**  Ensure that unicode characters are handled correctly in serializers and views.\n*   **Concurrency issues:** Be aware of potential concurrency issues when handling data updates.\n*   **Timezones:** Be aware of timezone issues and use timezone-aware datetime objects.\n\n### 6.3. Version-Specific Issues\n\n*   **Consult DRF's release notes:** Refer to DRF's release notes for information on version-specific issues and breaking changes.\n*   **Test with different DRF versions:** Test your API with different DRF versions to ensure compatibility.\n\n### 6.4. Compatibility Concerns\n\n*   **Django version compatibility:**  Ensure that your DRF version is compatible with your Django version.\n*   **Python version compatibility:**  Ensure that your DRF version is compatible with your Python version.\n*   **Third-party library compatibility:**  Ensure that your DRF version is compatible with any third-party libraries that you are using.\n\n### 6.5. Debugging Strategies\n\n*   **Use Django Debug Toolbar:** Use Django Debug Toolbar to inspect database queries, template rendering, and other performance metrics.\n*   **Use logging:**  Use logging to track the flow of execution and identify errors.\n*   **Use a debugger:** Use a debugger to step through code and inspect variables.\n*   **Test API endpoints with a tool like Postman:** Use Postman or a similar tool to test API endpoints and inspect responses.\n*   **Read traceback carefully**: Python tracebacks are extremely helpful in locating the origin of an error.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n*   **Virtual environment:** Use a virtual environment to isolate project dependencies.\n*   **Pip:** Use pip to manage Python packages.\n*   **Django:**  Use Django as the web framework.\n*   **Django REST Framework:**  Use DRF for building REST APIs.\n*   **Django Debug Toolbar:** Use Django Debug Toolbar for debugging and performance analysis.\n*   **Postman or Insomnia:** Use Postman or Insomnia to test API endpoints.\n*   **Git:** Use Git for version control.\n*   **EditorConfig:** Use EditorConfig to maintain consistent coding styles across different editors.\n*   **Black, isort, flake8**: For code formatting and linting\n*   **drf-yasg or Spectacular OpenAPI:** For automatic OpenAPI schema generation.\n\n### 7.2. Build Configuration\n\n*   **Use a `requirements.txt` file:**  Use a `requirements.txt` file to specify project dependencies.\n*   **Use a `setup.py` file:**  Use a `setup.py` file to package and distribute your API.\n*   **Use environment variables:**  Use environment variables to store configuration values.\n*   **Use Docker:**  Use Docker to containerize your API for consistent deployment.\n\n### 7.3. Linting and Formatting\n\n*   **Use PEP 8:** Follow PEP 8 guidelines for Python code.\n*   **Use Black:** Use Black for code formatting.\n*   **Use flake8:**  Use flake8 for code linting.\n*   **Use isort:** Use isort for import sorting.\n*   **Configure pre-commit hooks:** Set up pre-commit hooks to automatically format and lint code before committing.\n\n### 7.4. Deployment\n\n*   **Use a production-ready web server:** Use a production-ready web server like Gunicorn or uWSGI.\n*   **Use a load balancer:** Use a load balancer to distribute traffic across multiple servers.\n*   **Use a database server:**  Use a database server like PostgreSQL or MySQL.\n*   **Use a caching server:** Use a caching server like Redis or Memcached.\n*   **Use a content delivery network (CDN):** Use a CDN to serve static assets.\n*   **Monitor API performance:**  Monitor API performance to identify and address performance issues.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD pipeline:**  Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Use a CI/CD tool like Jenkins, GitLab CI, or CircleCI:** Use a CI/CD tool to manage your CI/CD pipeline.\n*   **Automate testing:**  Automate unit, integration, and end-to-end tests as part of the CI/CD pipeline.\n*   **Automate code formatting and linting:** Automate code formatting and linting as part of the CI/CD pipeline.\n*   **Automate deployment:** Automate deployment to production as part of the CI/CD pipeline.\n\nBy following these best practices, you can create robust, scalable, maintainable, and secure REST APIs using the Django REST Framework.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "django-rest-framework.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "django",
      "rest",
      "framework",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "developing",
      "apis",
      "using",
      "django-rest-framework",
      "python",
      "backend",
      "web",
      "api",
      "go",
      "performance",
      "cursor-rule",
      "mdc",
      "mvc",
      "orm",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "django-rest-framework",
        "django",
        "python",
        "backend",
        "web",
        "rest",
        "api",
        "go",
        "golang",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-django",
    "description": "Comprehensive guide to Django best practices covering code organization, performance, security, testing, and common pitfalls. This rule ensures adherence to community standards for maintainable and efficient Django applications.",
    "author": "sanjeed5",
    "tags": [
      "django",
      "python",
      "backend",
      "web",
      "go",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "mvc",
      "orm",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/django.mdc",
    "content": "# Django Best Practices and Coding Standards\n\nThis guide outlines best practices for developing Django applications to ensure code quality, maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - **Project Root:** Manage.py, settings, urls, wsgi.\n    - **Apps:** Each app should reside in its own directory.\n    - **Static Files:** Separate directory for static files (CSS, JavaScript, images).\n    - **Templates:** Dedicated directory for HTML templates.\n    - **Media:** For user-uploaded files.\n    - **Tests:** Tests for each app in a separate tests/ directory.\n\n- **File Naming Conventions:**\n    - Use lowercase letters with underscores (snake_case) for Python files and variables (e.g., `models.py`, `user_profile`).\n    - Classes should use CamelCase (e.g., `UserProfile`).\n    - Function names should use snake_case (e.g., `get_user_profile`).\n\n- **Module Organization:**\n    - Each app should be a self-contained module.\n    - Group related functionalities into submodules within the app.\n    - Use `__init__.py` files to define packages.\n\n- **Component Architecture:**\n    - Follow the Model-View-Template (MVT) architecture.\n    - Keep models lean and focused on data representation.\n    - Use views for request handling and business logic.\n    - Templates should focus on presentation.\n\n- **Code Splitting Strategies:**\n    - Break down large views into smaller, reusable functions or class-based views.\n    - Use mixins to share functionality across multiple views.\n    - Implement custom template tags and filters for reusable template logic.\n    - Consider using Celery for asynchronous task processing.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Model-View-Template (MVT):** Django's core architectural pattern.\n    - **Form Objects:** Use Django's forms for handling user input and validation.\n    - **Signals:** Implement signals for decoupled event handling.\n    - **Managers:** Use custom model managers to encapsulate query logic.\n    - **DRY (Don't Repeat Yourself):**  Avoid redundant code by extracting reusable components.\n\n- **Recommended Approaches:**\n    - **Database Interactions:** Use Django's ORM for database interactions. Avoid raw SQL queries unless necessary.\n    - **Form Handling:** Leverage Django's form classes for data validation and rendering forms.\n    - **URL Routing:** Use named URL patterns for reverse URL lookup.\n    - **Template Inheritance:** Utilize template inheritance to create a consistent look and feel.\n\n- **Anti-patterns and Code Smells:**\n    - **Fat Models:** Avoid putting too much business logic in models. Use services or utility functions instead.\n    - **Complex Templates:** Keep templates simple and focused on presentation. Move complex logic to views or custom template tags.\n    - **Hardcoded Values:** Avoid hardcoding values in code. Use settings or environment variables.\n    - **Ignoring Security:** Neglecting security best practices can lead to vulnerabilities.\n\n- **State Management:**\n    - Use Django's session framework for managing user sessions.\n    - Avoid storing sensitive data in sessions.\n    - Consider using a dedicated caching system (e.g., Redis, Memcached) for storing frequently accessed data.\n\n- **Error Handling:**\n    - Implement proper error handling using `try...except` blocks.\n    - Use Django's logging framework to log errors and warnings.\n    - Display user-friendly error messages.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Database Optimization:** Use indexes on frequently queried fields.\n    - **Caching:** Implement caching at various levels (e.g., template caching, view caching, database caching).\n    - **Query Optimization:** Use `select_related` and `prefetch_related` to reduce the number of database queries.\n    - **Gzip Compression:** Enable Gzip compression for static files and responses.\n\n- **Memory Management:**\n    - Avoid loading large datasets into memory. Use iterators or generators.\n    - Close database connections and file handles properly.\n    - Be mindful of memory leaks.\n\n- **Rendering Optimization:**\n    - Minimize the use of complex template logic.\n    - Use template caching to cache rendered templates.\n    - Optimize images and other static assets.\n\n- **Lazy Loading Strategies:**\n    - Implement lazy loading for images and other resources that are not immediately visible.\n    - Use pagination to display large datasets in smaller chunks.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input in templates and using Django's `escape` filter.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using Django's CSRF protection.\n    - **SQL Injection:** Use Django's ORM to prevent SQL injection attacks. Avoid raw SQL queries.\n    - **Authentication and Authorization Issues:** Implement proper authentication and authorization mechanisms.\n\n- **Input Validation:**\n    - Validate all user input on both the client-side and server-side.\n    - Use Django's form validation to validate data.\n    - Sanitize user input to remove potentially harmful characters.\n\n- **Authentication and Authorization:**\n    - Use Django's built-in authentication system for user authentication.\n    - Implement proper authorization checks to restrict access to sensitive resources.\n    - Use Django's permission system to manage user permissions.\n\n- **Data Protection:**\n    - Store sensitive data securely using encryption.\n    - Use HTTPS to encrypt communication between the client and server.\n    - Protect against data breaches by implementing proper access controls and monitoring.\n\n- **Secure API Communication:**\n    - Use authentication tokens or API keys to authenticate API requests.\n    - Implement rate limiting to prevent abuse.\n    - Validate all API input.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - Write unit tests for individual functions and classes.\n    - Use Django's testing framework to write and run tests.\n    - Mock external dependencies to isolate units of code.\n\n- **Integration Testing:**\n    - Write integration tests to test the interaction between different components.\n    - Test database interactions, form handling, and view rendering.\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to test the entire application flow.\n    - Use tools like Selenium or Cypress to automate browser testing.\n\n- **Test Organization:**\n    - Organize tests into separate test suites for each app or component.\n    - Use meaningful test names to describe what each test does.\n    - Keep tests concise and focused.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate units of code during testing.\n    - Avoid mocking external dependencies unless necessary.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Incorrect Database Configuration:** Ensure that the database settings are configured correctly.\n    - **Improper Static File Handling:** Configure static file serving properly in production.\n    - **Not Using Django's Built-in Features:** Leverage Django's built-in features instead of reinventing the wheel.\n    - **Ignoring Security Warnings:** Address any security warnings or vulnerabilities reported by Django's security checks.\n\n- **Edge Cases:**\n    - **Handling Time Zones:** Be mindful of time zones and use Django's time zone support.\n    - **Dealing with Unicode:** Handle Unicode characters correctly.\n    - **Managing File Uploads:** Implement proper file upload handling to prevent security vulnerabilities.\n\n- **Version-Specific Issues:**\n    - Be aware of compatibility issues between different Django versions.\n    - Consult the Django release notes for information about breaking changes.\n\n- **Compatibility Concerns:**\n    - Ensure that your code is compatible with different browsers and devices.\n    - Test your application on different platforms.\n\n- **Debugging Strategies:**\n    - Use Django's debugging tools to identify and fix errors.\n    - Use logging to track the execution flow of your application.\n    - Consult the Django documentation and community forums for help.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **IDE:** PyCharm, VS Code, Sublime Text\n    - **Package Manager:** pip, uv\n    - **Database Client:** pgAdmin, MySQL Workbench\n\n- **Build Configuration:**\n    - Use a `requirements.txt` file to manage dependencies.\n    - Use a virtual environment to isolate project dependencies.\n\n- **Linting and Formatting:**\n    - Use Black to format code automatically.\n    - Use flake8 to lint code and identify potential errors.\n\n- **Deployment Best Practices:**\n    - Use a production-ready web server (e.g., Gunicorn, uWSGI).\n    - Configure a reverse proxy (e.g., Nginx, Apache).\n    - Use a database server (e.g., PostgreSQL, MySQL).\n\n- **CI/CD Integration:**\n    - Integrate your project with a CI/CD pipeline to automate testing and deployment.\n    - Use tools like Jenkins, Travis CI, or GitLab CI.\n\n## Additional Notes\n\n- Always follow PEP 8 guidelines for Python code.\n- Write clear and concise comments.\n- Keep your code DRY (Don't Repeat Yourself).\n- Regularly update your dependencies.\n- Monitor your application for performance and security issues.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "django.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "django",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "python",
      "backend",
      "web",
      "go",
      "cursor-rule",
      "mdc",
      "mvc",
      "orm",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "django",
        "python",
        "backend",
        "web",
        "go",
        "golang",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-drizzle",
    "description": "This rule outlines best practices for using Drizzle ORM in TypeScript and JavaScript projects. It covers code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "drizzle",
      "typescript",
      "javascript",
      "types",
      "cursor",
      "cursor-rule",
      "mdc",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/drizzle.mdc",
    "content": "# Drizzle ORM Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to best practices for using Drizzle ORM in your TypeScript and JavaScript projects. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling.\n\n## Library Information:\n- Name: Drizzle ORM\n- Tags: database, orm, typescript, javascript, sql\n\n## 1. Code Organization and Structure\n\nA well-organized project structure is crucial for maintainability and scalability. Here are some recommendations for organizing your Drizzle ORM projects:\n\n### 1.1 Directory Structure\n\n\nproject-root/\n├── src/\n│   ├── db/\n│   │   ├── schema.ts          # Database schema definitions\n│   │   ├── migrations/       # Migration files\n│   │   ├── index.ts           # Database connection and initialization\n│   │   └── utils.ts           # Utility functions for database operations\n│   ├── models/            # Business logic models (if needed)\n│   ├── services/          # Services interacting with the database\n│   ├── utils/             # General utility functions\n│   └── ...\n├── drizzle.config.ts      # Drizzle Kit configuration\n├── package.json\n├── tsconfig.json\n└── ...\n\n\n*   **`src/db/schema.ts`**:  This file contains your database schema definitions using Drizzle's table functions (e.g., `pgTable`, `mysqlTable`, `sqliteTable`).\n*   **`src/db/migrations/`**: This directory stores your database migration files, generated by Drizzle Kit.\n*   **`src/db/index.ts`**:  This file handles the database connection and exports the Drizzle database instance.\n*   **`src/models/`**:  (Optional) If you need to represent database entities with more complex business logic, create model classes or interfaces here.\n*   **`src/services/`**:  This directory contains services that interact with the database, abstracting away the data access logic from your application's core.\n\n### 1.2 File Naming Conventions\n\n*   Schema files: `schema.ts`\n*   Migration files: Use a timestamp-based naming convention (e.g., `0001_initial_schema.sql`).  Drizzle Kit will typically handle this automatically.\n*   Service files:  Use descriptive names based on the entity they manage (e.g., `userService.ts`, `productService.ts`).\n*   Utility files: `utils.ts` or more specific names like `dbUtils.ts`.\n\n### 1.3 Module Organization\n\n*   Group related database operations into separate modules within the `src/db/` directory.\n*   Export the database instance and schema definitions from `src/db/index.ts`.\n*   Use ES module syntax (`import`/`export`) for clear dependency management.\n\n### 1.4 Component Architecture (If Applicable)\n\nIf you are using Drizzle ORM in a frontend application with a component-based architecture (e.g., React, Vue, Angular), consider the following:\n\n*   Create reusable data access components or hooks that encapsulate Drizzle queries.\n*   Separate data fetching logic from UI rendering logic.\n*   Use state management libraries (e.g., Redux, Zustand, React Context) to manage the application's state and efficiently update components when data changes.\n\n### 1.5 Code Splitting\n\n*   For large applications, use code splitting to reduce the initial bundle size.\n*   Consider lazy-loading database-related modules and components that are not immediately needed on initial page load.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Repository Pattern:**  Create repository classes or functions to abstract data access logic.  This promotes separation of concerns and makes your code more testable.\n*   **Unit of Work:** (If needed for complex transactions) Implement a Unit of Work pattern to manage multiple database operations within a single transaction.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Fetching Data:** Use Drizzle's `select` query builder for type-safe data retrieval.  Leverage `where`, `orderBy`, `limit`, and `offset` clauses for efficient querying.\n*   **Inserting Data:** Use the `insert` query builder for inserting new records.  Define TypeScript types for your data to ensure type safety.\n*   **Updating Data:** Use the `update` query builder for updating existing records.  Use `where` clauses to target specific records for updates.\n*   **Deleting Data:** Use the `delete` query builder for deleting records. Use `where` clauses to prevent accidental data loss.\n*   **Migrations:**  Use Drizzle Kit to manage database schema migrations.  Create migration files for each schema change and apply them in a controlled manner.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Writing raw SQL directly in components:** Avoid embedding raw SQL queries directly within UI components or other parts of your application.  Use service functions or repositories to abstract data access.\n*   **Ignoring type safety:**  Take advantage of TypeScript's type system to define types for your database schema and data models.  This will help catch errors at compile time and improve code maintainability.\n*   **Over-fetching data:**  Avoid selecting unnecessary columns or related data when fetching records.  This can lead to performance issues, especially for large tables.\n*   **Not using transactions:** Wrap multiple related database operations within a transaction to ensure data consistency.  This is especially important when updating multiple tables.\n*   **Hardcoding database credentials:** Store database credentials securely using environment variables and avoid committing them to your codebase.\n\n### 2.4 State Management\n\n*   Choose a state management solution that fits your application's complexity (e.g., Redux, Zustand, React Context).\n*   Use state management to store and manage data fetched from the database.\n*   Consider using caching strategies to reduce the number of database queries.\n\n### 2.5 Error Handling\n\n*   Use try-catch blocks to handle potential database errors.\n*   Log errors appropriately, including relevant information such as the query and parameters.\n*   Provide informative error messages to the user (if applicable).\n*   Consider implementing a centralized error handling mechanism.\n\n## 3. Performance Considerations\n\nOptimizing performance is crucial for ensuring a smooth user experience. Here are some performance considerations when using Drizzle ORM:\n\n### 3.1 Optimization Techniques\n\n*   **Indexing:**  Create indexes on frequently queried columns to improve query performance.\n*   **Query optimization:**  Analyze your queries and optimize them for performance.  Use `EXPLAIN` to understand how the database is executing your queries.\n*   **Connection pooling:**  Use a connection pool to reuse database connections and reduce connection overhead.\n*   **Caching:** Implement caching strategies to reduce the number of database queries.  Consider using server-side caching (e.g., Redis, Memcached) or client-side caching (e.g., browser cache).\n*   **Prepared statements:**  Use prepared statements to precompile SQL queries and improve performance for frequently executed queries.\n*   **Batch operations:**  Use batch operations to insert, update, or delete multiple records in a single query.\n\n### 3.2 Memory Management\n\n*   Be mindful of the amount of data you are fetching from the database.  Avoid fetching unnecessary columns or related data.\n*   Use streaming or pagination to process large datasets in smaller chunks.\n*   Release database connections when they are no longer needed.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n*   Optimize UI rendering performance by using techniques such as virtualization, memoization, and lazy loading.\n*   Avoid performing expensive database queries in the UI rendering thread.\n\n### 3.4 Bundle Size Optimization\n\n*   Use tree shaking to remove unused code from your bundle.\n*   Minify your code to reduce the bundle size.\n*   Compress your bundle using gzip or Brotli.\n\n### 3.5 Lazy Loading\n\n*   Lazy load database-related modules and components that are not immediately needed on initial page load.\n\n## 4. Security Best Practices\n\nSecuring your application is paramount.  Here are some security best practices to follow when using Drizzle ORM:\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **SQL Injection:** Drizzle helps prevent SQL injection by using parameterized queries. Always use the built-in query builders and avoid concatenating user input directly into SQL strings.  The `sql` template literal function also provides protection when used correctly.\n*   **Cross-Site Scripting (XSS):**  Sanitize user input before displaying it in the UI to prevent XSS attacks. This is more of a frontend concern, but important to remember when displaying data from the database.\n*   **Cross-Site Request Forgery (CSRF):**  Protect your application against CSRF attacks by implementing CSRF tokens.\n*   **Unauthorized Access:** Implement proper authentication and authorization mechanisms to restrict access to sensitive data.\n\n### 4.2 Input Validation\n\n*   Validate all user input before using it in database queries.  Use server-side validation to ensure data integrity.\n*   Use TypeScript types to enforce data types and constraints.\n\n### 4.3 Authentication and Authorization\n\n*   Use a robust authentication system to verify user identities.\n*   Implement authorization rules to control access to resources based on user roles or permissions.\n*   Consider using a well-established authentication and authorization library (e.g., Passport.js, Auth0, Firebase Authentication).\n\n### 4.4 Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use HTTPS to secure communication between the client and server.\n*   Regularly back up your database to prevent data loss.\n\n### 4.5 Secure API Communication\n\n*   Use secure API endpoints (HTTPS).\n*   Implement rate limiting to prevent abuse.\n*   Validate API requests and responses.\n\n## 5. Testing Approaches\n\nThorough testing is essential for ensuring the quality and reliability of your application. Here are some testing approaches for Drizzle ORM projects:\n\n### 5.1 Unit Testing\n\n*   Write unit tests for your services, repositories, and utility functions.\n*   Mock the database connection to isolate your code and improve test performance.\n*   Use a testing framework such as Jest or Mocha.\n\n### 5.2 Integration Testing\n\n*   Write integration tests to verify the interaction between your application and the database.\n*   Use a test database or in-memory database (e.g., SQLite) for integration tests.\n*   Ensure that your integration tests cover the most important database operations.\n\n### 5.3 End-to-End Testing\n\n*   Write end-to-end tests to verify the complete application flow, including the UI and the database.\n*   Use a testing framework such as Cypress or Puppeteer.\n\n### 5.4 Test Organization\n\n*   Organize your tests into separate directories based on the component or module they are testing.\n*   Use descriptive names for your test files and test cases.\n\n### 5.5 Mocking and Stubbing\n\n*   Use mocking and stubbing techniques to isolate your code and control the behavior of dependencies during testing.\n*   Consider using a mocking library such as Jest's built-in mocking capabilities.\n*   Mock the Drizzle database instance to simulate database operations.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrectly defining schema types:** Pay close attention to defining the correct TypeScript types for your database schema columns. Mismatched types can lead to runtime errors.\n*   **Forgetting to migrate the database:** After making schema changes, remember to generate and apply migrations using Drizzle Kit. Failing to do so will result in inconsistencies between your application and the database.\n*   **Not handling errors properly:**  Implement proper error handling to catch potential database errors and prevent application crashes.\n*   **Ignoring performance considerations:**  Be mindful of query performance and optimize your queries as needed. Avoid fetching unnecessary data or performing expensive operations.\n\n### 6.2 Edge Cases\n\n*   **Concurrency issues:** Be aware of potential concurrency issues when multiple users or processes are accessing the database simultaneously. Use transactions to ensure data consistency.\n*   **Large datasets:** Handle large datasets efficiently by using pagination, streaming, or other optimization techniques.\n*   **Database-specific features:** Be aware of database-specific features and limitations. Drizzle aims to provide a consistent API across different databases, but some features may not be available or may behave differently.\n\n### 6.3 Version-Specific Issues\n\n*   Refer to the Drizzle ORM documentation and release notes for information on version-specific issues and breaking changes.\n*   Keep your Drizzle ORM dependencies up to date to benefit from bug fixes and performance improvements.\n\n### 6.4 Compatibility Concerns\n\n*   Ensure that your Drizzle ORM version is compatible with your database driver and other dependencies.\n*   Test your application thoroughly after upgrading Drizzle ORM or other dependencies.\n\n### 6.5 Debugging Strategies\n\n*   Use logging to track the execution of your queries and identify potential issues.\n*   Use a database client to inspect the database schema and data.\n*   Use the `EXPLAIN` statement to analyze query performance.\n*   Use a debugger to step through your code and inspect variables.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:**  Use a modern IDE such as Visual Studio Code, WebStorm, or Sublime Text.\n*   **TypeScript Compiler:**  Use the TypeScript compiler to transpile your TypeScript code to JavaScript.\n*   **Drizzle Kit:**  Use Drizzle Kit to manage database schema migrations.\n*   **Database Client:**  Use a database client such as Dbeaver, TablePlus, or SQL Developer to inspect your database.\n*   **ESLint:** Use ESLint to lint your code and enforce coding standards.\n*   **Prettier:**  Use Prettier to format your code and ensure consistency.\n\n### 7.2 Build Configuration\n\n*   Use a build tool such as Webpack, Parcel, or Rollup to bundle your code.\n*   Configure your build tool to perform tree shaking, minification, and compression.\n*   Use environment variables to configure your application for different environments.\n\n### 7.3 Linting and Formatting\n\n*   Use ESLint to lint your code and enforce coding standards.\n*   Use Prettier to format your code and ensure consistency.\n*   Configure your IDE to automatically run ESLint and Prettier on save.\n\n### 7.4 Deployment\n\n*   Choose a deployment platform that fits your application's requirements (e.g., Vercel, Netlify, AWS, Heroku).\n*   Configure your deployment environment to use environment variables for database credentials and other sensitive information.\n*   Automate your deployment process using CI/CD.\n*   Ensure that your database is properly configured and secured in your deployment environment.\n\n### 7.5 CI/CD Integration\n\n*   Use a CI/CD platform such as Jenkins, Travis CI, or GitHub Actions to automate your build, test, and deployment process.\n*   Configure your CI/CD pipeline to run your unit tests, integration tests, and end-to-end tests.\n*   Use a linting tool such as ESLint to enforce coding standards and prevent errors.\n*   Deploy your application automatically to your deployment environment after successful builds and tests.\n\nBy following these best practices, you can build robust, scalable, and secure applications using Drizzle ORM.",
    "metadata": {
      "globs": "*.ts,*.tsx,*.js,*.jsx",
      "format": "mdc",
      "originalFile": "drizzle.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "drizzle",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "using",
      "typescript",
      "javascript",
      "projects",
      "types",
      "cursor-rule",
      "mdc",
      "type-safety",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "drizzle",
        "typescript",
        "javascript",
        "types",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-duckdb",
    "description": "This rule file outlines best practices for developing with DuckDB, covering code organization, performance optimization, security considerations, and testing strategies. It aims to improve code quality, maintainability, and overall project health when using DuckDB.",
    "author": "sanjeed5",
    "tags": [
      "duckdb",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/duckdb.mdc",
    "content": "# DuckDB Best Practices and Coding Standards\n\nThis document provides guidelines and best practices for developing with DuckDB. Following these recommendations will lead to more maintainable, performant, and secure DuckDB projects.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n*   **Project Root:**\n    *   `.cursor/`: Contains Cursor rule files.\n    *   `data/`: Stores data files (CSV, Parquet, etc.).  Consider subdirectories based on data source or type.\n    *   `sql/`: Contains SQL scripts (DDL, DML, queries).\n    *   `scripts/`: Python, Bash, or other scripts for data processing and automation.\n    *   `docs/`: Project documentation.\n    *   `tests/`: Test scripts and data.\n    *   `venv/` (or `.venv/`): Virtual environment for Python dependencies (if applicable).\n    *   `Makefile`: Automation of common tasks (e.g., data loading, testing).\n    *   `README.md`: Project overview and instructions.\n    *   `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n\n*   **Example:**\n\n    \n    my_duckdb_project/\n    ├── .cursor/\n    │   └── rules.mdc\n    ├── data/\n    │   ├── raw/\n    │   │   └── sales_data.csv\n    │   └── processed/\n    │       └── sales_summary.parquet\n    ├── sql/\n    │   ├── create_tables.sql\n    │   ├── queries/\n    │   │   ├── monthly_sales.sql\n    │   │   └── top_customers.sql\n    │   └── data_validation.sql\n    ├── scripts/\n    │   └── process_data.py\n    ├── docs/\n    │   └── user_guide.md\n    ├── tests/\n    │   ├── unit/\n    │   │   └── test_queries.py\n    │   └── integration/\n    │       └── test_data_pipeline.py\n    ├── venv/\n    ├── Makefile\n    ├── README.md\n    └── .gitignore\n    \n\n### 1.2. File Naming Conventions\n\n*   **SQL Scripts:** Use descriptive names with underscores (e.g., `create_tables.sql`, `monthly_sales_report.sql`).\n*   **Data Files:** Use names reflecting the data content (e.g., `customer_data.csv`, `product_catalog.parquet`).  Prefix with dates if versioning is needed (e.g., `2024-01-01_customer_data.csv`).\n*   **Scripts:** Use names indicating the script's purpose (e.g., `load_data.py`, `run_tests.sh`).\n*   **DDL Files:** `schema.sql`, `tables.sql` etc. for defining database structures\n\n### 1.3. Module Organization (if using a scripting language like Python)\n\n*   **Separate Modules:**  Divide code into logical modules (e.g., `data_loading.py`, `query_execution.py`, `utils.py`).\n*   **Clear Interfaces:** Define clear functions and classes with well-defined inputs and outputs.\n*   **Avoid Global State:** Minimize the use of global variables to improve code testability and maintainability.\n\n### 1.4. Component Architecture\n\n*   **Data Layer:**  Handles data loading, transformation, and storage using DuckDB.\n*   **Logic Layer:**  Encapsulates business logic and data processing routines.\n*   **Presentation Layer:**  (If applicable)  Presents data to users (e.g., through a web application).\n*   **Configuration Layer:** Loads external configurations (e.g., environment variables) that the script needs to run properly.\n\n### 1.5. Code Splitting Strategies\n\n*   **Split Large SQL Scripts:**  Break down complex SQL scripts into smaller, more manageable files.\n*   **Modularize Python Code:** Use functions and classes to create reusable components.\n*   **Separate Configuration:** Store configuration settings (database paths, API keys) in separate files.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to DuckDB\n\n*   **Embedded Database:**  Use DuckDB as an embedded database for lightweight data analysis and prototyping.\n*   **Data Pipeline:**  Build data pipelines with DuckDB for ETL (Extract, Transform, Load) processes.\n*   **Analytical Queries:** Leverage DuckDB's columnar storage and vectorized execution for efficient analytical queries.\n*   **Federated Querying:** Utilize DuckDB's ability to query data from various sources (CSV, Parquet, JSON, HTTP) using a unified SQL interface.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Loading:**\n    *   Use `COPY` command for efficient bulk loading of data from files.\n    *   Consider Parquet format for optimal storage and query performance.\n    *   Use `read_csv_auto` or `read_parquet` functions.\n*   **Querying:**\n    *   Write clear and concise SQL queries.\n    *   Use parameterized queries to prevent SQL injection.\n    *   Utilize window functions for complex aggregations and ranking.\n*   **Data Transformation:**\n    *   Use SQL functions for data cleaning and transformation.\n    *   Create views for commonly used data transformations.\n*   **Joining Tables:**\n    *   Understand different join types (INNER, LEFT, RIGHT, FULL) and choose the appropriate one.\n    *   Ensure join columns are properly indexed for performance.\n    *   Use explicit `JOIN` syntax for readability.\n*   **Error Handling:** Implement robust error handling to prevent unexpected crashes.\n    *   Utilize `TRY/CATCH` blocks in SQL scripts.\n    *   Log errors to files or databases for debugging and monitoring.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n*   `SELECT *`:  Avoid selecting all columns unless necessary.  Specify only the columns you need to improve performance.\n*   Nested Subqueries:  Excessive use of nested subqueries can impact performance.  Consider using `WITH` clauses (Common Table Expressions - CTEs) to improve readability and performance.\n*   Lack of Indexing:  Missing indexes on frequently queried columns can lead to slow query performance.  Add indexes where appropriate.\n*   Hardcoded Values:  Avoid hardcoding values in SQL queries or scripts.  Use parameters or configuration files instead.\n*   Ignoring Error Handling:  Failing to handle errors gracefully can lead to unexpected application behavior.\n*   Over-complicating Queries: Strive for clarity and simplicity in SQL queries. Break down complex logic into smaller, more manageable steps.\n*   Not closing database connections after usage.\n\n### 2.4. State Management Best Practices\n\n*   **Minimize State:** Keep the amount of mutable state in your application to a minimum.\n*   **Centralized State:** If state is necessary, manage it in a centralized location (e.g., a configuration file or dedicated state management module).\n*   **Immutable Data:** Prefer immutable data structures whenever possible to avoid unintended side effects.\n\n### 2.5. Error Handling Patterns\n\n*   **Try-Catch Blocks:** Use `TRY/CATCH` blocks in SQL scripts to handle potential errors.\n*   **Logging:**  Log errors to files or databases for debugging and monitoring.\n*   **Custom Error Messages:**  Provide informative error messages to help users understand and resolve issues.\n*   **Graceful Degradation:** Design your application to handle errors gracefully and continue functioning (albeit with reduced functionality) if possible.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Column Selection:** Use specific column selections instead of `SELECT *` to improve performance.\n*   **Filtering Before Joining:** Optimize queries by filtering data before joining tables.\n*   **Prepared Statements:** Utilize prepared statements for repeated queries to enhance execution speed.\n*   **Indexing:** Create indexes on frequently queried columns to speed up data retrieval.\n*   **Query Plan Analysis:** Use `EXPLAIN ANALYZE` to understand query execution plans and identify bottlenecks.\n*   **Chunking:** Implement chunking for large datasets to manage memory better.\n*   **Data Types:** Use appropriate data types to minimize storage space and improve query performance.  Avoid using TEXT for numerical data. Use INTEGER or BIGINT where possible.\n*   **Compression:** DuckDB supports lightweight compression. Consider using persistent databases to take advantage of this.\n*   **Parallelism:** DuckDB parallelizes workload based on row groups. Ensure your data is large enough to benefit from multi-core processing. Manually limit the number of threads if necessary using `SET threads = X`.\n\n### 3.2. Memory Management\n\n*   **Memory Limits:** Monitor memory usage and set appropriate memory limits.\n*   **Spilling to Disk:** Larger-than-memory workloads are supported by spilling to disk. Configure the temporary directory using `SET temp_directory = '/path/to/temp_dir.tmp/'`.\n*   **Avoid Large Intermediate Results:**  Optimize queries to minimize the size of intermediate results.\n*   **`preserve_insertion_order`:** Disable `preserve_insertion_order` for large imports/exports if order is not important (`SET preserve_insertion_order = false`).\n\n### 3.3. Avoiding Reading Unnecessary Data (Remote Files)\n\n*   **Column Selection:** Avoid `SELECT *`. Only select columns that are actually used.\n*   **Filter Pushdown:** Apply filters on remote parquet files when possible. DuckDB can use these filters to reduce the amount of data that is scanned.\n*   **Sorting/Partitioning:** Either sort or partition data by columns that are regularly used for filters: this increases the effectiveness of the filters in reducing IO.\n*   **Avoid Reading Data More Than Once:**  If data needs to be accessed multiple times, store it locally.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:**  Prevent SQL injection by using parameterized queries and avoiding string concatenation in SQL statements.\n*   **Data Exposure:**  Protect sensitive data by encrypting it at rest and in transit.  Use appropriate access controls to restrict access to sensitive data.\n*   **Denial of Service (DoS):**  Limit resource consumption (memory, CPU) to prevent DoS attacks.\n*   **Unauthorized Access:** Implement strong authentication and authorization mechanisms to prevent unauthorized access to the database.\n\n### 4.2. Input Validation\n\n*   **Validate User Inputs:** Validate all user inputs to prevent malicious data from entering the database. Check data types, ranges, and formats.\n*   **Sanitize Inputs:** Sanitize user inputs to remove potentially harmful characters or code.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **Role-Based Access Control (RBAC):** Implement RBAC to grant users only the necessary permissions to access data.\n*   **Least Privilege Principle:**  Grant users the minimum level of access required to perform their tasks.\n*   **Secure Connection:** Ensure that connections to the database are encrypted using TLS/SSL.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in non-production environments to protect user privacy.\n*   **Data Auditing:**  Track all data access and modification activities for auditing purposes.\n*   **Regular Backups:** Regularly back up the database to prevent data loss in case of failures.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Test Individual Components:**  Write unit tests to verify the functionality of individual SQL functions, Python modules, or other components.\n*   **Mock Database Connections:** Mock database connections to isolate the code being tested from the actual database.\n*   **Assertion Frameworks:** Use assertion frameworks (e.g., `pytest`, `unittest`) to verify expected results.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions:**  Write integration tests to verify the interactions between different components of the system.\n*   **Real Database:** Use a real DuckDB database for integration tests (preferably a test database).\n*   **Data Validation:** Verify that data is correctly loaded, transformed, and stored in the database.\n\n### 5.3. End-to-End Testing\n\n*   **Test Complete Workflows:** Write end-to-end tests to verify the functionality of complete workflows from start to finish.\n*   **Simulate User Actions:** Simulate user actions to test the system's behavior under realistic conditions.\n\n### 5.4. Test Organization\n\n*   **Separate Test Directory:** Create a separate `tests/` directory to store test scripts.\n*   **Organize Tests:** Organize tests into subdirectories based on the component or feature being tested.\n*   **Descriptive Names:** Use descriptive names for test files and functions.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock External Dependencies:** Mock external dependencies (e.g., file systems, network connections) to isolate the code being tested.\n*   **Stub Database Interactions:** Stub database interactions to control the behavior of the database during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   **Not Using Indexes:**  Forgetting to create indexes on frequently queried columns.\n*   **Incorrect Join Types:** Using the wrong join type (e.g., INNER instead of LEFT).\n*   **SQL Injection Vulnerabilities:** Failing to prevent SQL injection attacks.\n*   **Memory Leaks:** Not properly closing database connections or releasing resources.\n*   **Lack of Error Handling:**  Ignoring potential errors in SQL scripts or Python code.\n\n### 6.2. Edge Cases to Be Aware Of\n\n*   **Null Values:**  Handle null values correctly in SQL queries and data transformations.\n*   **Empty Datasets:**  Test the system's behavior with empty datasets.\n*   **Large Datasets:**  Test the system's behavior with large datasets to ensure performance.\n*   **Concurrency:** Consider potential concurrency issues when multiple users or processes access the database simultaneously.\n\n### 6.3. Version-Specific Issues\n\n*   **Check Release Notes:**  Review the release notes for each new version of DuckDB to identify any breaking changes or known issues.\n*   **Compatibility Testing:** Perform compatibility testing to ensure that the application works correctly with different versions of DuckDB.\n\n### 6.4. Compatibility Concerns\n\n*   **Operating System:** Ensure that the application is compatible with the target operating system (Windows, macOS, Linux).\n*   **Programming Language:**  Ensure that the application is compatible with the programming language being used (Python, Java, etc.).\n*   **Database Drivers:** Use compatible database drivers.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Add logging statements to the code to track execution flow and variable values.\n*   **Print Statements:** Use print statements to display intermediate results and debug issues.\n*   **Debuggers:** Use debuggers (e.g., `pdb` in Python) to step through the code and inspect variables.\n*   **Query Plan Analysis:** Use `EXPLAIN ANALYZE` to understand query execution plans and identify bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Text Editor/IDE:** VSCode, Sublime Text, IntelliJ IDEA, etc.\n*   **Database Client:** DBeaver, DataGrip, SQL Developer, DuckDB CLI.\n*   **Version Control:** Git.\n*   **Virtual Environment Manager:** `venv` (Python), Conda.\n*   **Task Runner:** Make, Invoke (Python).\n\n### 7.2. Build Configuration\n\n*   **Dependency Management:** Use a dependency management tool (e.g., `pip` for Python) to manage project dependencies.\n*   **Configuration Files:**  Use configuration files (e.g., `config.ini`, `settings.json`) to store project settings and parameters.\n\n### 7.3. Linting and Formatting\n\n*   **Linters:** Use linters (e.g., `flake8`, `pylint` for Python, `sqlfluff` for SQL) to enforce code style and identify potential errors.\n*   **Formatters:** Use formatters (e.g., `black` for Python, `sqlformat` for SQL) to automatically format code according to a defined style.\n\n### 7.4. Deployment Best Practices\n\n*   **Containerization:** Use containerization (e.g., Docker) to package the application and its dependencies into a single unit.\n*   **Infrastructure as Code (IaC):** Use IaC tools (e.g., Terraform, CloudFormation) to automate the provisioning and management of infrastructure.\n*   **Configuration Management:** Use configuration management tools (e.g., Ansible, Chef, Puppet) to automate the configuration of servers and applications.\n\n### 7.5. CI/CD Integration\n\n*   **Continuous Integration (CI):** Integrate automated testing into the CI pipeline to ensure code quality.\n*   **Continuous Delivery (CD):** Automate the deployment process to ensure frequent and reliable releases.",
    "metadata": {
      "globs": "*.sql,*.ddl,*.md,*.duckdb",
      "format": "mdc",
      "originalFile": "duckdb.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "duckdb",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "duckdb",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-elasticsearch",
    "description": "This rule provides comprehensive best practices for developing with Elasticsearch, covering code organization, performance, security, testing, and common pitfalls, ensuring efficient and maintainable Elasticsearch applications. These practices apply broadly across languages interacting with Elasticsearch.",
    "author": "sanjeed5",
    "tags": [
      "elasticsearch",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/elasticsearch.mdc",
    "content": "- # Elasticsearch Library Best Practices\n\n  This document provides comprehensive guidelines for developing with Elasticsearch, covering code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.\n\n- ## 1. Code Organization and Structure\n\n  - ### Directory Structure\n\n    - **Project Root:** Contains the main application code, configuration files, and build scripts.\n    - **src/:** Source code for your application. This directory is further subdivided:\n      - **config/:** Configuration files for Elasticsearch connections and settings.\n      - **mappings/:** JSON files defining Elasticsearch index mappings.\n      - **queries/:** Stored Elasticsearch queries for reuse.\n      - **models/:** Data models representing Elasticsearch documents.\n      - **utils/:** Utility functions for interacting with Elasticsearch.\n      - **scripts/:** Scripts for indexing, reindexing, and data migration.\n    - **tests/:** Unit and integration tests.\n    - **docs/:** Documentation for your application and Elasticsearch integration.\n    - **data/:** Sample data for testing and development.\n    - **.cursor/:** Stores cursor rule files if using Cursor IDE.\n\n  - ### File Naming Conventions\n\n    - **Configuration Files:** `elasticsearch.config.json`, `index.mapping.json`\n    - **Data Models:** `user.model.js`, `product.model.py`\n    - **Utility Functions:** `elasticsearch.utils.go`, `query_builder.rb`\n    - **Test Files:** `user.model.test.js`, `elasticsearch.utils_test.py`\n\n  - ### Module Organization\n\n    - Divide your code into logical modules, such as:\n      - **elasticsearch_client:** Handles the Elasticsearch client initialization and connection management.\n      - **index_management:** Manages index creation, deletion, and mapping updates.\n      - **query_builder:** Provides functions for building complex Elasticsearch queries.\n      - **data_ingestion:** Handles data ingestion and indexing processes.\n      - **search_service:** Implements the search logic and result processing.\n\n  - ### Component Architecture\n\n    - Use a layered architecture to separate concerns:\n      - **Presentation Layer:** Handles user input and displays search results.\n      - **Application Layer:** Orchestrates the interaction between the presentation and domain layers.\n      - **Domain Layer:** Contains the core business logic and data models.\n      - **Infrastructure Layer:** Provides access to external services like Elasticsearch.\n\n  - ### Code Splitting\n\n    -  If your application handles large datasets or complex queries, consider code splitting:\n       -  Split large mapping files into smaller, manageable chunks. Use `@file` directives if using Cursor to include them in the primary rule file.\n       -  Implement lazy loading for infrequently used features.\n       -  Optimize queries to minimize the amount of data transferred.\n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### Design Patterns\n\n    - **Repository Pattern:** Abstract data access logic behind a repository interface.\n    - **Factory Pattern:** Create Elasticsearch clients and query builders using factories.\n    - **Builder Pattern:** Construct complex Elasticsearch queries step-by-step.\n    - **Observer Pattern:** Notify subscribers of index updates or data changes.\n\n  - ### Recommended Approaches\n\n    - **Bulk Indexing:** Use the bulk API for efficient indexing of large datasets.\n    - **Scroll API:** Use the scroll API for retrieving large result sets.\n    - **Asynchronous Operations:** Use asynchronous operations for non-blocking Elasticsearch interactions.\n\n  - ### Anti-patterns and Code Smells\n\n    - **Over-sharding:** Avoid creating too many shards, which can lead to performance issues.\n    - **Ignoring Errors:** Always handle Elasticsearch errors and log them appropriately.\n    - **Hardcoding Queries:** Avoid hardcoding queries directly in your code. Use query builders or stored queries.\n    - **Excessive Data Retrieval:** Only retrieve the fields you need from Elasticsearch.\n\n  - ### State Management\n\n    - Keep track of the index state (e.g., creation date, mapping version).\n    - Use version control for index mappings and queries.\n    - Implement rollback mechanisms for data migration.\n\n  - ### Error Handling\n\n    - Use try-except blocks to catch Elasticsearch exceptions.\n    - Log errors with sufficient context for debugging.\n    - Implement retry mechanisms for transient errors.\n    - Implement circuit breaker pattern to prevent cascading failures.\n\n- ## 3. Performance Considerations\n\n  - ### Optimization Techniques\n\n    - **Mapping Optimization:**\n      - Use the appropriate data types for your fields.\n      - Use `keyword` type for fields that are used for filtering or sorting.\n      - Use `text` type for fields that are used for full-text search.\n      - Disable indexing for fields that are only used for retrieval (`\"index\": false`).\n      - Consider using `multi-fields` for different types of searches (e.g., keyword and text).\n    - **Query Optimization:**\n      - Use the `filter` context for queries that do not affect scoring.\n      - Use the `bool` query to combine multiple conditions effectively.\n      - Use the `match` query for full-text searches.\n      - Utilize caching mechanisms for frequently executed queries.\n    - **Indexing Optimization:**\n      - Use the bulk API for indexing large amounts of data.\n      - Increase the refresh interval for less frequent updates.\n      - Optimize shard sizes based on your data volume.\n      - Avoid over-sharding.\n\n  - ### Memory Management\n\n    - Monitor the Elasticsearch heap usage.\n    - Configure the JVM heap size appropriately.\n    - Avoid memory leaks in your application code.\n\n  - ### Rendering Optimization (If Applicable)\n\n    - Implement pagination for large result sets.\n    - Use virtualization techniques for rendering large lists.\n    - Optimize the rendering performance of your UI components.\n\n  - ### Bundle Size Optimization\n\n    - Minimize the size of your application's bundle.\n    - Use code splitting to load only the necessary modules.\n    - Optimize your dependencies and remove unused code.\n\n  - ### Lazy Loading\n\n    - Implement lazy loading for infrequently used features.\n    - Load data on demand as needed.\n    - Use asynchronous operations for loading data.\n\n- ## 4. Security Best Practices\n\n  - ### Common Vulnerabilities\n\n    - **Injection Attacks:** Prevent injection attacks by validating user input and sanitizing data.\n    - **Unauthorized Access:** Implement proper authentication and authorization mechanisms.\n    - **Data Breaches:** Protect sensitive data by encrypting it at rest and in transit.\n\n  - ### Input Validation\n\n    - Validate user input to prevent injection attacks and data corruption.\n    - Sanitize data before indexing it into Elasticsearch.\n    - Use regular expressions or validation libraries to enforce data constraints.\n\n  - ### Authentication and Authorization\n\n    - Use Elasticsearch's built-in security features or a third-party plugin for authentication.\n    - Implement role-based access control (RBAC) to restrict access to sensitive data.\n    - Use API keys or tokens for secure API communication.\n\n  - ### Data Protection\n\n    - Encrypt sensitive data at rest using Elasticsearch's encryption features.\n    - Encrypt data in transit using HTTPS.\n    - Mask or redact sensitive data in logs and error messages.\n\n  - ### Secure API Communication\n\n    - Use HTTPS for all API communication with Elasticsearch.\n    - Validate the server certificate to prevent man-in-the-middle attacks.\n    - Use secure protocols like TLS 1.3 or higher.\n\n- ## 5. Testing Approaches\n\n  - ### Unit Testing\n\n    - Unit test individual components in isolation.\n    - Mock Elasticsearch dependencies to control test behavior.\n    - Use assertion libraries to verify the expected results.\n\n  - ### Integration Testing\n\n    - Integrate test different components to verify their interaction.\n    - Use a test Elasticsearch instance for integration tests.\n    - Verify that data is correctly indexed and retrieved.\n\n  - ### End-to-End Testing\n\n    - Test the entire application from end to end.\n    - Use automated testing frameworks like Selenium or Cypress.\n    - Verify that the application functions correctly in a real-world environment.\n\n  - ### Test Organization\n\n    - Organize your tests into logical categories.\n    - Use descriptive names for your test cases.\n    - Keep your tests concise and focused.\n\n  - ### Mocking and Stubbing\n\n    - Use mocking libraries to create mock Elasticsearch clients and responses.\n    - Use stubbing to simulate different Elasticsearch scenarios.\n    - Verify that your code interacts with Elasticsearch as expected.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### Frequent Mistakes\n\n    - Not understanding Elasticsearch's query DSL.\n    - Not configuring the Elasticsearch cluster properly.\n    - Not monitoring Elasticsearch performance.\n\n  - ### Edge Cases\n\n    - Handling large result sets.\n    - Dealing with complex data types.\n    - Managing index mappings and updates.\n\n  - ### Version-Specific Issues\n\n    - Be aware of breaking changes between Elasticsearch versions.\n    - Test your application thoroughly when upgrading Elasticsearch.\n    - Consult the Elasticsearch documentation for version-specific information.\n\n  - ### Compatibility Concerns\n\n    - Ensure compatibility between Elasticsearch and your application's programming language.\n    - Use compatible versions of Elasticsearch client libraries.\n\n  - ### Debugging Strategies\n\n    - Use Elasticsearch's logging features to troubleshoot issues.\n    - Use the Elasticsearch API to inspect the cluster state.\n    - Use debugging tools to step through your code.\n\n- ## 7. Tooling and Environment\n\n  - ### Recommended Tools\n\n    - **Elasticsearch:** The core search and analytics engine.\n    - **Kibana:** A visualization and exploration tool for Elasticsearch data.\n    - **Logstash:** A data processing pipeline for ingesting data into Elasticsearch.\n    - **Elasticsearch Head/Cerebro:** Cluster management and monitoring tools.\n\n  - ### Build Configuration\n\n    - Use a build tool like Maven, Gradle, or npm to manage dependencies.\n    - Configure your build to package your application and its dependencies.\n\n  - ### Linting and Formatting\n\n    - Use a linter like ESLint or Pylint to enforce code style guidelines.\n    - Use a formatter like Prettier or Black to automatically format your code.\n\n  - ### Deployment\n\n    - Deploy your Elasticsearch cluster to a cloud platform like AWS, Azure, or GCP.\n    - Use containerization technologies like Docker and Kubernetes.\n    - Automate your deployment process using tools like Ansible or Terraform.\n\n  - ### CI/CD\n\n    - Integrate your application with a CI/CD pipeline.\n    - Automate testing, building, and deployment processes.\n    - Use tools like Jenkins, GitLab CI, or CircleCI.\n\n- ## Additional Best Practices\n\n  - **Monitoring:** Implement comprehensive monitoring of Elasticsearch cluster health, resource utilization, and query performance using tools like Prometheus, Grafana, and Elasticsearch's built-in monitoring features.\n  - **Logging:** Configure detailed logging to capture important events, errors, and performance metrics for troubleshooting and analysis. Use structured logging formats like JSON for easier parsing and analysis.\n  - **Backup and Recovery:** Implement regular backups of Elasticsearch data and configurations to prevent data loss. Test the recovery process to ensure it works as expected.\n  - **Capacity Planning:** Regularly assess the capacity requirements of your Elasticsearch cluster based on data growth, query load, and indexing performance. Scale your cluster accordingly to maintain optimal performance.\n  - **Security Auditing:** Conduct regular security audits to identify and address potential vulnerabilities. Review access controls, network configurations, and data encryption settings.\n  - **Stay Updated:** Keep your Elasticsearch cluster and client libraries up to date with the latest security patches and bug fixes. Follow the Elasticsearch community for updates and best practices.\n\n  By following these best practices, you can build robust, scalable, and secure applications with Elasticsearch.",
    "metadata": {
      "globs": "*.py,*.js,*.java,*.go,*.ts,*.kt,*.scala,*.rb,*.php,*.rs,*.c,*.cpp,*.cs,*.swift,*.m,*.h",
      "format": "mdc",
      "originalFile": "elasticsearch.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "elasticsearch",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "elasticsearch",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-electron",
    "description": "Enforces best practices, coding standards, and performance considerations for Electron development. Covers code structure, security, testing, and common pitfalls to ensure robust and maintainable applications.",
    "author": "sanjeed5",
    "tags": [
      "electron",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/electron.mdc",
    "content": "- **General Practices**\n  - Adhere to the official Electron coding style guide. Run `npm run lint` to detect style issues using `cpplint` and `eslint`.\n  - Aim for line lengths between 80 and 100 characters for readability.\n  - Use `sh` instead of `cmd` in code blocks for cross-platform compatibility in documentation.\n  - Select the appropriate Electron version based on project needs and compatibility with dependencies.\n  - Always update electron to the latest stable version to receive security fixes and performance improvements.\n\n- **Code Organization and Structure**\n  - **Directory Structure:**\n    - Structure your project logically. Consider using a structure like:\n      \n      electron-app/\n      ├── main.js         # Main process entry point\n      ├── preload.js      # Preload script (for specific renderers if needed)\n      ├── renderer/\n      │   ├── index.html    # Main HTML file\n      │   ├── script.js     # Renderer process scripts\n      │   ├── style.css     # Stylesheets\n      │   └── components/ # Reusable components (if applicable)\n      ├── assets/         # Static assets (images, fonts, etc.)\n      ├── package.json\n      └── electron-builder.yml # Electron Builder configuration\n      \n    - Organize your code into modules based on functionality (e.g., authentication, data handling, UI components).\n  - **File Naming Conventions:**\n    - Use descriptive and consistent naming conventions.\n    - JavaScript/TypeScript files: `camelCase` for variables and functions, `PascalCase` for classes and components.\n    - CSS/SCSS files: `kebab-case`.\n  - **Module Organization:**\n    - Split your application logic into separate modules for better maintainability and reusability.\n    - Use ES modules (`import`/`export`) or CommonJS (`require`/`module.exports`) for modularization.  Be consistent throughout the project.\n  - **Component Architecture:**\n    - Design reusable UI components for the renderer process.\n    - Use a component-based framework (e.g., React, Vue, Angular) to manage UI complexity.\n  - **Code Splitting:**\n    - Implement code splitting to reduce the initial load time of your application.\n    - Use dynamic imports (`import()`) to load modules on demand.\n    - Consider using webpack or Parcel for bundling and code splitting.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - **Model-View-Controller (MVC):**  Organize application logic into models, views, and controllers to separate concerns.\n    - **Observer Pattern:** Implement a publish-subscribe mechanism for communication between different parts of the application.\n    - **Singleton Pattern:** Use singletons sparingly. If used, implement carefully to avoid unexpected side effects.\n  - **Recommended Approaches:**\n    - **Inter-Process Communication (IPC):** Use `ipcRenderer` and `ipcMain` for communication between the main and renderer processes.  Sanitize all data passed via IPC.\n    - **Native Modules:** Consider using native modules for performance-critical tasks or access to platform-specific APIs.\n    - **Remote Module:** Avoid using the remote module, as it can introduce security vulnerabilities and performance issues. Use IPC instead.\n  - **Anti-patterns:**\n    - **Tight Coupling:** Avoid tightly coupling components or modules to make the code more flexible and testable.\n    - **Global State:** Minimize the use of global state.  Use state management libraries or techniques to manage application state effectively.\n    - **Long-Running Tasks in the Renderer Process:** Move long-running tasks to the main process or use worker threads to prevent blocking the UI.\n  - **State Management:**\n    - For simple applications, use basic state management techniques (e.g., component state, context API).\n    - For complex applications, consider using state management libraries like Redux, Zustand, or Vuex.\n  - **Error Handling:**\n    - Implement robust error handling mechanisms throughout your application.\n    - Use try-catch blocks to handle exceptions and prevent crashes.\n    - Log errors to a file or remote logging service for debugging.\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - **Reduce Load on the Renderer Process:** Minimize the amount of work performed in the renderer process. Offload heavy tasks to the main process or worker threads.\n    - **Hardware Acceleration:** Enable hardware acceleration to improve rendering performance.\n    - **Minimize DOM Manipulations:** Reduce the number of DOM manipulations to improve UI responsiveness.\n  - **Memory Management:**\n    - **Garbage Collection:** Be mindful of memory leaks and optimize code to reduce memory consumption.\n    - **Object Pools:** Use object pools to reuse objects and avoid unnecessary memory allocation.\n  - **Rendering Optimization:**\n    - **Virtual DOM:** Use a virtual DOM library (e.g., React, Vue) to optimize rendering performance.\n    - **CSS Sprites:** Use CSS sprites to reduce the number of HTTP requests for images.\n  - **Bundle Size Optimization:**\n    - **Code Minification:** Minify JavaScript and CSS code to reduce bundle size.\n    - **Tree Shaking:** Use tree shaking to remove unused code from the bundle.\n  - **Lazy Loading:**\n    - **Lazy Load Images:** Lazy load images to improve initial page load time.\n    - **Lazy Load Modules:** Lazy load modules on demand to reduce initial bundle size.\n\n- **Security Best Practices**\n  - **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and escaping output.\n    - **Remote Code Execution (RCE):** Avoid RCE vulnerabilities by validating input and preventing the execution of arbitrary code.\n    - **Insecure Deserialization:** Prevent insecure deserialization vulnerabilities by validating serialized data.\n  - **Input Validation:**\n    - Validate all user input to prevent malicious data from being processed.\n    - Use appropriate data types and formats to prevent type confusion attacks.\n  - **Authentication and Authorization:**\n    - Implement secure authentication and authorization mechanisms to protect sensitive data and resources.\n    - Use strong passwords and multi-factor authentication.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms to protect sensitive data.\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Validate API responses to prevent data injection attacks.\n  - **Enable Context Isolation:** Enable context isolation for the renderer process to prevent access to the main process's JavaScript context.\n  - **Disable Node.js Integration:** Disable Node.js integration in the renderer process unless strictly necessary. If needed, only expose a limited API using contextBridge.\n  - **Handle `new-window` events:** Validate and sanitize all URLs before allowing a new window to be opened from a renderer process.\n\n- **Testing Approaches**\n  - **Unit Testing:**\n    - Write unit tests to verify the functionality of individual components or modules.\n    - Use a testing framework like Jest or Mocha.\n  - **Integration Testing:**\n    - Write integration tests to verify the interaction between different components or modules.\n    - Use a testing framework like Cypress or Puppeteer.\n  - **End-to-End Testing:**\n    - Write end-to-end tests to verify the overall functionality of the application.\n    - Use a testing framework like Cypress or Puppeteer.\n  - **Test Organization:**\n    - Organize tests into separate files or directories based on functionality.\n    - Use descriptive test names to clearly identify the purpose of each test.\n  - **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components or modules during testing.\n    - Use a mocking library like Jest or Sinon.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - **Not Sanitizing User Input:** Failing to sanitize user input can lead to XSS vulnerabilities.\n    - **Using the Remote Module:** The `remote` module provides direct access to main process functionality from the renderer, but bypassing IPC exposes security risks. Use `contextBridge` and IPC.\n    - **Blocking the Main Process:** Performing long-running tasks in the main process can block the UI and make the application unresponsive.\n  - **Edge Cases:**\n    - **Handling Different Screen Resolutions:** Test your application on different screen resolutions to ensure proper UI rendering.\n    - **Handling Different Operating Systems:** Test your application on different operating systems (Windows, macOS, Linux) to ensure compatibility.\n  - **Version-Specific Issues:**\n    - Be aware of version-specific issues and compatibility concerns when upgrading Electron or its dependencies.\n  - **Debugging Strategies:**\n    - Use the Chrome DevTools to debug the renderer process.\n    - Use the Electron DevTools to debug the main process.\n\n- **Tooling and Environment**\n  - **Recommended Development Tools:**\n    - **Visual Studio Code:** A popular code editor with excellent support for Electron development.\n    - **Electron Forge or Electron Builder:** Tools for packaging and distributing Electron applications.\n    - **Chrome DevTools:** A powerful debugging tool for the renderer process.\n  - **Build Configuration:**\n    - Use a build system like webpack or Parcel to bundle your application code.\n    - Configure the build system to optimize code for production.\n  - **Linting and Formatting:**\n    - Use a linter like ESLint to enforce code style and prevent errors.\n    - Use a formatter like Prettier to automatically format code.\n  - **Deployment Best Practices:**\n    - Sign your application code to prevent tampering.\n    - Distribute your application through a secure channel.\n  - **CI/CD Integration:**\n    - Integrate your application with a CI/CD system to automate the build, test, and deployment process.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.html,*.css,*.scss,*.mjs,*.cjs",
      "format": "mdc",
      "originalFile": "electron.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "electron",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "performance",
      "considerations",
      "development",
      "covers",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "electron",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-elk-stack",
    "description": "This rule outlines best practices for developing and maintaining applications within the ELK (Elasticsearch, Logstash, Kibana) stack, including coding standards, configuration, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "elk-stack",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/elk-stack.mdc",
    "content": "## ELK Stack Best Practices\n\nThis document provides comprehensive best practices for working with the ELK (Elasticsearch, Logstash, Kibana) stack, covering various aspects from code organization to security and testing.\n\n### 1. Code Organization and Structure\n\n- **Directory Structure Best Practices:**\n    - Organize configurations (Logstash pipelines, Kibana dashboards) in separate directories, such as `logstash/pipelines`, `kibana/dashboards`, and `elasticsearch/config`.\n    - Maintain a dedicated directory for custom scripts or plugins used within the ELK stack.\n    - Use a version control-friendly structure, where each configuration file is self-contained and easily traceable.\n\n- **File Naming Conventions:**\n    - Use descriptive and consistent naming conventions for configuration files, such as `application-name-pipeline.conf` for Logstash pipelines or `dashboard-name.json` for Kibana dashboards.\n    - Employ prefixes or suffixes to denote the purpose or environment of a configuration (e.g., `dev-`, `prod-`).\n\n- **Module Organization:**\n    - If using custom scripts or plugins, organize them into modules with clear interfaces and documentation.\n    - For Logstash pipelines, consider breaking down complex configurations into smaller, reusable modules using the `include` directive.\n\n- **Component Architecture:**\n    - Design a modular architecture where each component (e.g., data ingestion, processing, visualization) is loosely coupled and can be independently scaled or updated.\n    - Follow a layered approach, separating concerns such as data collection, transformation, storage, and presentation.\n\n- **Code Splitting Strategies:**\n    - For Logstash pipelines, split configurations into smaller files based on functionality (e.g., input, filter, output) to improve readability and maintainability.\n    - Use conditional logic (e.g., `if/else` statements) within Logstash pipelines to handle different data sources or processing requirements.\n\n### 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Pipeline Pattern:** Design data ingestion pipelines using Logstash or Beats to process and transform data before indexing it in Elasticsearch.\n    - **Dashboard Pattern:** Create reusable Kibana dashboards and visualizations to monitor key metrics and identify trends.\n    - **Alerting Pattern:** Implement alerting rules in Kibana or use external tools to trigger notifications based on specific events or thresholds.\n\n- **Recommended Approaches:**\n    - Use structured logging formats (e.g., JSON) to simplify data parsing and analysis.\n    - Implement data enrichment techniques (e.g., GeoIP lookup, user agent parsing) to add context to log data.\n    - Use Index Lifecycle Management (ILM) to automate index rotation, deletion, and optimization.\n\n- **Anti-patterns:**\n    - Avoid using overly complex Logstash pipelines that are difficult to understand and maintain.\n    - Do not store sensitive data (e.g., passwords, API keys) in plain text within configuration files.\n    - Avoid excessive use of wildcard queries in Elasticsearch, which can negatively impact performance.\n\n- **State Management:**\n    - For Logstash pipelines, use persistent queues to ensure data durability and prevent data loss during outages.\n    - Utilize Elasticsearch's snapshot and restore API to back up and restore data in case of disaster.\n\n- **Error Handling:**\n    - Implement error handling in Logstash pipelines to gracefully handle unexpected data formats or processing errors.\n    - Use dead-letter queues to capture failed events and allow for later reprocessing.\n    - Monitor the health of ELK stack components and set up alerts for critical errors.\n\n### 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - Tune Elasticsearch settings such as shard allocation, refresh interval, and bulk indexing size to optimize indexing and search performance.\n    - Use appropriate data types and mappings in Elasticsearch to minimize storage space and improve query performance.\n    - Optimize Logstash pipelines by using efficient filters, reducing the number of operations, and avoiding unnecessary data transformations.\n\n- **Memory Management:**\n    - Configure JVM heap size for Elasticsearch and Logstash based on available memory and data volume.\n    - Monitor memory usage of ELK stack components and adjust settings as needed to prevent memory leaks or out-of-memory errors.\n\n- **Bundle Size Optimization:**\n    - N/A - ELK stack does not use bundles in the traditional web development sense, but optimize configurations and data structures.\n\n- **Lazy Loading Strategies:**\n    - N/A - ELK stack components load configurations on startup, but optimize data ingestion and indexing to improve overall performance.\n\n### 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - Protect against Elasticsearch injection attacks by validating user inputs and sanitizing data before indexing it.\n    - Prevent unauthorized access to ELK stack components by enabling authentication and authorization.\n    - Secure communication between ELK stack components by enabling TLS encryption.\n\n- **Input Validation:**\n    - Validate data ingested into Logstash pipelines to prevent malicious or malformed data from being indexed in Elasticsearch.\n    - Sanitize user inputs in Kibana dashboards to prevent cross-site scripting (XSS) attacks.\n\n- **Authentication and Authorization:**\n    - Enable authentication in Elasticsearch and Kibana to restrict access to authorized users only.\n    - Use role-based access control (RBAC) to grant different levels of permissions to different users or groups.\n\n- **Data Protection:**\n    - Encrypt sensitive data at rest in Elasticsearch using encryption at rest features or external encryption tools.\n    - Implement data masking or anonymization techniques to protect sensitive data in Kibana dashboards.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API communication with ELK stack components.\n    - Implement API rate limiting to prevent denial-of-service (DoS) attacks.\n\n### 5. Testing Approaches\n\n- **Unit Testing:**\n    - Write unit tests for custom scripts or plugins used within the ELK stack.\n    - Mock external dependencies to isolate components during testing.\n\n- **Integration Testing:**\n    - Test the integration between ELK stack components by simulating data ingestion, processing, and visualization scenarios.\n    - Verify that data is correctly indexed in Elasticsearch and displayed in Kibana dashboards.\n\n- **End-to-End Testing:**\n    - Perform end-to-end tests to ensure that the entire ELK stack is functioning correctly and meeting performance requirements.\n    - Simulate real-world scenarios to validate data flow and system behavior.\n\n- **Test Organization:**\n    - Organize tests into separate directories based on component or functionality.\n    - Use a consistent naming convention for test files and test cases.\n\n- **Mocking and Stubbing:**\n    - Use mocking frameworks to create mock objects for external dependencies during unit testing.\n    - Stub out API calls or database queries to isolate components during integration testing.\n\n### 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Not configuring sufficient resources (CPU, memory, disk space) for ELK stack components.\n    - Over-indexing data and creating unnecessarily large indices.\n    - Using inefficient queries or aggregations in Elasticsearch.\n\n- **Edge Cases:**\n    - Handling large volumes of data or high query loads.\n    - Dealing with complex data formats or unstructured log data.\n    - Recovering from node failures or data corruption.\n\n- **Version-Specific Issues:**\n    - Incompatibilities between different versions of ELK stack components.\n    - Deprecated features or APIs in newer versions of Elasticsearch, Logstash, and Kibana.\n\n- **Compatibility Concerns:**\n    - Ensuring compatibility between ELK stack components and other technologies in your environment.\n    - Addressing dependencies and conflicts between different plugins or libraries.\n\n- **Debugging Strategies:**\n    - Use Elasticsearch's explain API to analyze query performance and identify bottlenecks.\n    - Enable debug logging in Logstash pipelines to troubleshoot data processing issues.\n    - Monitor system logs and metrics to identify resource constraints or errors.\n\n### 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - IDEs with support for YAML, JSON, and Groovy.\n    - Command-line tools for interacting with Elasticsearch, Logstash, and Kibana.\n    - Monitoring tools for tracking the health and performance of ELK stack components.\n\n- **Build Configuration:**\n    - Use configuration management tools (e.g., Ansible, Chef) to automate the deployment and configuration of ELK stack components.\n    - Store configuration files in version control to track changes and facilitate collaboration.\n\n- **Linting and Formatting:**\n    - Use linters and formatters to enforce coding standards and improve code quality.\n    - Configure IDEs to automatically format code on save.\n\n- **Deployment Best Practices:**\n    - Deploy ELK stack components on separate servers or virtual machines to isolate workloads and improve scalability.\n    - Use a load balancer to distribute traffic across multiple Elasticsearch nodes.\n\n- **CI/CD Integration:**\n    - Integrate ELK stack deployments into your CI/CD pipeline to automate testing and deployment processes.\n    - Use infrastructure-as-code (IaC) tools to provision and manage ELK stack environments.\n\nBy following these best practices, you can build and maintain a robust, scalable, and secure ELK stack environment that meets your logging and analytics needs.",
    "metadata": {
      "globs": "*.conf, *.yml, *.json, *.log",
      "format": "mdc",
      "originalFile": "elk-stack.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "elk",
      "stack",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "developing",
      "maintaining",
      "applications",
      "within",
      "elasticsearch",
      "elk-stack",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "elk-stack",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-emacs",
    "description": "Comprehensive guide to Emacs Lisp coding standards, best practices, and common pitfalls. Focuses on maintainability, readability, and performance for building robust Emacs extensions.",
    "author": "sanjeed5",
    "tags": [
      "emacs",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/emacs.mdc",
    "content": "- ## Code Organization and Structure\n  - ### Directory Structure\n    - Organize your Emacs Lisp projects into well-defined directories to improve maintainability and discoverability.\n    - `/`: Project root. Contains the main `.el` file (e.g., `my-package.el`) and a README.\n    - `/src`: Source code. Contains the core Emacs Lisp files.\n    - `/lib`: Libraries.  External libraries or dependencies used by your project.\n    - `/test`: Tests.  Unit and integration tests.\n    - `/doc`: Documentation.  User documentation and API references. Consider using `org-mode` for easy export to various formats.\n    - `/.cursor`: Project rules directory for Cursor AI tool.\n  - ### File Naming Conventions\n    - Use lowercase letters and hyphens for file names (e.g., `my-package.el`).\n    - Each file should generally correspond to a single module or component.\n    - Test files should be named following a consistent pattern, such as `my-module-test.el` or `my-module.test.el`.\n    - Always end Emacs Lisp files with the `.el` extension.\n  - ### Module Organization\n    - Encapsulate related functions and variables within modules.\n    - Use `provide` to declare a module and `require` to load dependencies.\n    - Avoid creating overly large files; break them down into smaller, more manageable modules.\n    - Example:\n      lisp\n      (provide 'my-module)\n\n      (require 'another-module)\n      \n      (defun my-module-function (arg)\n        ;; ...\n      )\n      \n  - ### Component Architecture\n    - Design your applications using a component-based architecture to promote code reuse and modularity.\n    - Each component should have a well-defined interface and a clear responsibility.\n    - Favor composition over inheritance.\n    - Example: Separate UI elements from business logic.\n  - ### Code Splitting\n    - Use `autoload` to defer loading of less frequently used functions, improving startup time.\n    - Break up large modules into smaller files and load them on demand.\n    - Ensure that your package provides a mechanism for disabling or uninstalling components to avoid conflicts.\n\n- ## Common Patterns and Anti-patterns\n  - ### Design Patterns\n    - **Command Pattern:** Encapsulate actions as objects, enabling parameterization, queuing, and logging.\n    - **Observer Pattern:** Define a one-to-many dependency between objects, so that when one object changes state, all its dependents are notified and updated automatically (e.g., using hooks).\n    - **Strategy Pattern:** Define a family of algorithms, encapsulate each one, and make them interchangeable (e.g., customizable behavior through user options).\n  - ### Recommended Approaches for Common Tasks\n    - **Configuration Management:** Use `defcustom` for user-configurable options.  Provide default values and documentation.\n    - **UI Creation:** Use `widget` for creating interactive UI elements.\n    - **Asynchronous Operations:** Leverage `timer` and `process` for non-blocking tasks.\n    - **Data Storage:** Consider using SQLite via `sqlite.el` for persistent data storage.\n  - ### Anti-patterns and Code Smells\n    - **Global State Mutation:** Minimize use of global variables.  If necessary, use `defvar` with caution.\n    - **Deeply Nested Conditionals:** Refactor complex logic into smaller, more readable functions.\n    - **Magic Numbers/Strings:** Define constants for frequently used values.\n    - **Duplicated Code:** Extract common logic into reusable functions or macros.\n    - **Ignoring Errors:** Always handle errors and exceptions gracefully.\n  - ### State Management\n    - Prefer lexical scoping with `lexical-binding: t` to create closures and manage state within functions.\n    - Use `cl-letf` to temporarily redefine functions for testing or customization.\n    - Utilize property lists or hash tables to associate state with buffers or other objects.\n  - ### Error Handling\n    - Use `condition-case` to handle exceptions and prevent crashes.\n    - Provide informative error messages to users.\n    - Log errors to a file or the `*Messages*` buffer for debugging.\n    - Always clean up resources (e.g., timers, processes) in the `finally` clause of `condition-case`.\n    - Example:\n      lisp\n      (condition-case err\n          (progn\n            ;; Code that might raise an error\n            (do-something))\n        (error\n         (message \"An error occurred: %s\" err))\n        (finally\n         ;; Clean up resources\n         (cleanup)))\n      \n\n- ## Performance Considerations\n  - ### Optimization Techniques\n    - **Profiling:** Use `profiler.el` or `elp.el` to identify performance bottlenecks.\n    - **Byte Compilation:** Always byte-compile your Emacs Lisp code using `byte-compile-file`.\n    - **Caching:** Cache frequently accessed data to reduce computation time.\n    - **Lazy Loading:** Use `autoload` for functions that are not immediately needed.\n    - **Tail Recursion:** Convert recursive functions to tail-recursive form to avoid stack overflow errors.\n    - **StringBuilder:** Utilize `insert` for building large strings instead of repeated concatenation.\n  - ### Memory Management\n    - Minimize the creation of temporary objects.\n    - Reuse existing data structures when possible.\n    - Be mindful of garbage collection overhead; avoid creating excessive garbage.\n    -  Use weak references where possible, with libraries such as `weak-ref` to avoid memory leaks.\n  - ### Rendering Optimization\n    - Minimize the number of buffer updates.\n    - Use overlays efficiently to avoid performance degradation.\n    - Batch updates when possible.\n  - ### Bundle Size Optimization\n    - Remove unnecessary dependencies.\n    - Use code minification tools to reduce the size of your Emacs Lisp files.\n    - Compress images and other assets.\n  - ### Lazy Loading\n    - Use `autoload` for functions and libraries that are not immediately required.\n    - Load dependencies on demand rather than at startup.\n    - Provide hooks for users to customize which features are loaded.\n\n- ## Security Best Practices\n  - ### Common Vulnerabilities\n    - **Code Injection:** Prevent execution of untrusted code.\n    - **Cross-Site Scripting (XSS):** Sanitize user input to prevent malicious scripts from being injected into UI elements.\n    - **Denial-of-Service (DoS):** Limit resource consumption to prevent attacks that overwhelm the system.\n    - **Path Traversal:** Validate file paths to prevent access to unauthorized files.\n  - ### Input Validation\n    - Sanitize all user input to prevent code injection and XSS attacks.\n    - Validate file paths to prevent path traversal vulnerabilities.\n    - Use regular expressions to enforce input formats.\n  - ### Authentication and Authorization\n    - Use secure authentication mechanisms such as OAuth or API keys.\n    - Implement authorization checks to ensure that users only have access to resources they are authorized to access.\n    - Store credentials securely using the Emacs password manager or a dedicated secrets store.\n  - ### Data Protection\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure communication protocols such as HTTPS.\n    - Protect against data breaches by implementing appropriate access controls.\n  - ### Secure API Communication\n    - Use HTTPS for all API communication.\n    - Validate API responses to prevent data injection attacks.\n    - Implement rate limiting to prevent abuse.\n\n- ## Testing Approaches\n  - ### Unit Testing\n    - Use ERT or Buttercup to write unit tests for your Emacs Lisp code.\n    - Test individual functions and components in isolation.\n    - Mock external dependencies to create a predictable testing environment.\n  - ### Integration Testing\n    - Test the interaction between different components of your Emacs Lisp application.\n    - Verify that data flows correctly between components.\n    - Ensure that your application integrates properly with Emacs itself.\n  - ### End-to-end Testing\n    - Use Director or similar tools to automate end-to-end tests.\n    - Simulate user interactions and verify that the application behaves as expected.\n    - Test the entire application from the user's perspective.\n  - ### Test Organization\n    - Organize your tests into separate files or directories.\n    - Use descriptive names for your test cases.\n    - Group related tests together.\n    - Provide a clear and concise test report.\n  - ### Mocking and Stubbing\n    - Use `cl-letf` or similar techniques to mock external dependencies.\n    - Create stubs for functions that are difficult or impossible to test directly.\n    - Verify that mocked functions are called with the correct arguments.\n\n- ## Common Pitfalls and Gotchas\n  - ### Frequent Mistakes\n    - Forgetting to byte-compile Emacs Lisp code.\n    - Using global variables excessively.\n    - Ignoring error conditions.\n    - Writing overly complex functions.\n    - Failing to document code properly.\n    - Not using lexical binding.\n  - ### Edge Cases\n    - Handling international characters correctly.\n    - Dealing with different Emacs versions and platforms.\n    - Managing asynchronous operations and timers.\n    - Ensuring compatibility with other packages.\n    - Testing in various Emacs configurations (e.g., `-Q` for no init file).\n  - ### Version-Specific Issues\n    - Be aware of API changes between Emacs versions.\n    - Use conditional compilation to support multiple versions of Emacs.\n    - Test your code on different Emacs versions to ensure compatibility.\n  - ### Compatibility Concerns\n    - Avoid using deprecated functions and features.\n    - Test your code with different Emacs configurations to identify compatibility issues.\n    - Provide a mechanism for users to disable or uninstall your package if necessary.\n  - ### Debugging Strategies\n    - Use `edebug` to step through your code and inspect variables.\n    - Print debugging messages to the `*Messages*` buffer.\n    - Use `trace` to monitor function calls.\n    - Enable `debug-on-error` to catch exceptions.\n    - Check the Emacs error log for clues.\n\n- ## Tooling and Environment\n  - ### Recommended Development Tools\n    - **Emacs:** The best tool for developing Emacs Lisp code.\n    - **ERT/Buttercup:** Testing frameworks.\n    - **Flycheck:** Real-time syntax checking and linting.\n    - **Edebug:** Interactive debugger.\n    - **Profiler.el/ELP:** Profiling tools.\n    - **Counsel/Ivy/Helm:** Completion frameworks for improved navigation.\n    - **Magit:** Git integration.\n  - ### Build Configuration\n    - Use a `Makefile` or similar build tool to automate common tasks such as byte-compilation, testing, and documentation generation.\n    - Define dependencies explicitly in your build configuration.\n    - Use version control to track changes to your build configuration.\n  - ### Linting and Formatting\n    - Use `flycheck` with `package-lint` and `elsa` for static code analysis.\n    - Enforce consistent code formatting using `aggressive-indent-mode` or similar tools.\n    - Configure your editor to automatically format code on save.\n  - ### Deployment\n    - Package your Emacs Lisp code into a `.el` file.\n    - Distribute your package via MELPA or a similar repository.\n    - Provide clear instructions on how to install and configure your package.\n  - ### CI/CD Integration\n    - Use GitHub Actions, Travis CI, or similar tools to automate testing and deployment.\n    - Run tests on every commit to ensure code quality.\n    - Automatically deploy your package to MELPA on release.\n\n- ## Best Practices Summary\n  - Always use lexical binding: `;; -*- lexical-binding: t; -*-`.\n  - Prefix all global symbols with a unique project prefix to avoid namespace collisions.\n  - Write clear and concise documentation for all functions and variables using docstrings.\n  - Use `defcustom` for user-configurable options.\n  - Handle errors gracefully using `condition-case`.\n  - Byte-compile your Emacs Lisp code before deploying.\n  - Write unit tests for your code using ERT or Buttercup.\n  - Follow the Emacs Lisp Style Guide.\n  - Leverage the power of Emacs' interactive development environment for real-time feedback.\n\n- @file https://raw.githubusercontent.com/bbatsov/emacs-lisp-style-guide/master/emacs-lisp-style-guide.md\n- @file https://raw.githubusercontent.com/emacs-tw/awesome-elisp/master/README.md",
    "metadata": {
      "globs": "*.el",
      "format": "mdc",
      "originalFile": "emacs.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "emacs",
      "comprehensive",
      "guide",
      "lisp",
      "coding",
      "standards",
      "best",
      "practices",
      "common",
      "pitfalls",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "emacs",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-esbuild",
    "description": "This rule provides comprehensive best practices for using esbuild, focusing on performance, code organization, and security in build configurations and development workflows.",
    "author": "sanjeed5",
    "tags": [
      "esbuild",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/esbuild.mdc",
    "content": "# esbuild Best Practices\n\nThis document outlines best practices for using esbuild as a JavaScript bundler. It covers various aspects, including code organization, performance optimization, security considerations, and common pitfalls to avoid.\n\n## Library Information:\n\n- Name: esbuild\n- Tags: build-tool, javascript, bundler, performance\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n-   **Source Code Directory (`src`):**  House all your source code within a `src` directory. This promotes a clear separation of concerns between your source and build artifacts.\n-   **Configuration Files (`config` or `.config`):** Store esbuild configuration files (e.g., `esbuild.config.js`, `build.js`) in a dedicated `config` or `.config` directory.  This makes it easy to identify and manage build-related settings.\n-   **Assets Directory (`assets`):** Place static assets like images, fonts, and other non-code files in an `assets` directory. This keeps them separate from your code and simplifies asset management.\n-   **Output Directory (`dist` or `build`):**  esbuild commonly uses `dist` or `build` directories for storing the bundled output.  Configure esbuild to output to one of these standard directories.\n\nExample:\n\n\nproject-root/\n├── src/\n│   ├── components/\n│   │   ├── MyComponent.tsx\n│   │   └── ...\n│   ├── utils/\n│   │   ├── helpers.ts\n│   │   └── ...\n│   ├── index.tsx\n│   └── ...\n├── config/\n│   ├── esbuild.config.js\n│   └── ...\n├── assets/\n│   ├── images/\n│   │   ├── logo.png\n│   │   └── ...\n│   ├── fonts/\n│   │   ├── OpenSans.woff2\n│   │   └── ...\n├── dist/\n│   ├── bundle.js\n│   ├── styles.css\n│   └── ...\n├── package.json\n├── tsconfig.json\n└── ...\n\n\n### 1.2. File Naming Conventions\n\n-   **Consistent Case:** Use either camelCase or PascalCase for JavaScript/TypeScript files, but consistently within your project.  PascalCase is generally preferred for React components.\n-   **Descriptive Names:** Choose names that clearly reflect the file's purpose (e.g., `userProfile.tsx`, `apiClient.ts`).\n-   **Module-Specific Names:** If a file exports a single primary entity (e.g., a React component), use the same name for the file (e.g., `MyComponent.tsx` exports `MyComponent`).\n-   **CSS Modules:** Use `.module.css` or `.module.scss` for CSS Modules to scope styles locally to a component.\n-   **Configuration Files:** use `esbuild.config.js` or `build.js` for esbuild's configuration to make it easily identifiable.\n\n### 1.3. Module Organization Best Practices\n\n-   **Feature-Based Modules:** Organize code by feature or functionality.  Each feature should have its own directory containing all related code (components, utils, styles, etc.).\n-   **Reusable Modules:**  Extract reusable code into separate modules (e.g., utility functions, API clients).  Place these modules in a `utils` or `services` directory.\n-   **Avoid Circular Dependencies:**  Circular dependencies can lead to unexpected behavior and bundling issues. Use tools like `madge` to detect and eliminate them.\n-   **Explicit Exports:** Be explicit about what you export from each module using `export` statements. This improves code clarity and tree-shaking.\n\n### 1.4. Component Architecture Recommendations\n\n-   **Component-Based Architecture:**  Adopt a component-based architecture (e.g., using React, Vue, or Svelte).  This promotes code reusability, testability, and maintainability.\n-   **Atomic Design:**  Consider using the Atomic Design methodology to structure components into atoms, molecules, organisms, templates, and pages.\n-   **Separation of Concerns:**  Separate presentation logic (UI) from business logic (data fetching, state management).  Use techniques like custom hooks to extract and reuse business logic.\n\n### 1.5. Code Splitting Strategies\n\n-   **Dynamic Imports:** Use dynamic imports (`import()`) to load code on demand.  This can significantly reduce the initial bundle size and improve page load performance.  esbuild supports dynamic imports out of the box.\n-   **Route-Based Splitting:** Split your application into separate bundles for each route or page.  This ensures that users only download the code they need for the current page.\n-   **Vendor Splitting:**  Separate vendor libraries (e.g., React, Lodash) into a separate bundle.  This allows browsers to cache vendor code separately from your application code.\n-   **Entry Points:** Create multiple entry points for distinct parts of your application (e.g. a landing page vs. an admin panel). esbuild will bundle these into separate output files.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Module Pattern:** Use the module pattern to encapsulate code and create private variables and functions.\n-   **Factory Pattern:** Use factory functions to create objects or components. This allows you to abstract the creation process and easily configure objects with different options.\n-   **Higher-Order Components (HOCs):**  (React-specific) Use HOCs to add functionality to existing components.\n-   **Custom Hooks:** (React-specific) Use custom hooks to extract and reuse stateful logic.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Environment Variables:** Use environment variables to configure your application for different environments (development, staging, production).  Access environment variables using `process.env`.\n-   **Path Aliases:** Configure path aliases to simplify imports.  For example, you can alias `@components` to `src/components`.  esbuild can be configured to understand these aliases.\n-   **CSS Preprocessing:** Integrate CSS preprocessors like Sass or Less using esbuild plugins.  This allows you to use features like variables, mixins, and nesting in your CSS.\n-   **Minification and Tree Shaking:** Always enable minification and tree shaking for production builds to reduce bundle size. esbuild does this automatically with the `--minify` flag.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Global Variables:** Avoid using global variables as they can lead to naming conflicts and make it difficult to reason about your code.\n-   **Long Component Files:**  Break down large component files into smaller, more manageable components.\n-   **Deeply Nested Components:**  Avoid deeply nested component structures as they can make it difficult to understand the component hierarchy.\n-   **Over-reliance on `any`:** In TypeScript, avoid using `any` excessively as it defeats the purpose of type checking.  Use more specific types whenever possible.\n-   **Direct DOM Manipulation (in React/Vue):** Avoid directly manipulating the DOM. Rely on the framework's virtual DOM for efficient updates.\n\n### 2.4. State Management Best Practices\n\n-   **Component State:** Use component state (e.g., `useState` in React) for simple, localized state management.\n-   **Context API:** (React-specific) Use the Context API to share state between components without prop drilling.\n-   **Redux/Zustand/Recoil:** Use a state management library like Redux, Zustand, or Recoil for more complex application state.\n-   **Immutability:**  Maintain immutability when updating state to avoid unexpected side effects and improve performance (especially with React).\n\n### 2.5. Error Handling Patterns\n\n-   **Try-Catch Blocks:** Use `try-catch` blocks to handle synchronous errors.\n-   **Async/Await Error Handling:** Use `try-catch` blocks with `async/await` to handle asynchronous errors.\n-   **Error Boundaries:** (React-specific) Use error boundaries to catch errors that occur during rendering and prevent the entire application from crashing.\n-   **Centralized Error Logging:** Implement a centralized error logging system to track errors in your application.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Minification:** Use esbuild's built-in minification (`--minify`) to reduce the size of your JavaScript and CSS files.\n-   **Tree Shaking:**  esbuild automatically performs tree shaking to remove unused code. Ensure that your code is written in a way that allows for efficient tree shaking (e.g., using ES modules with explicit exports).\n-   **Code Splitting:** Implement code splitting using dynamic imports and route-based splitting to reduce the initial bundle size.\n-   **Image Optimization:** Optimize images using tools like ImageOptim or TinyPNG to reduce their file size.\n-   **Caching:**  Configure your server to cache static assets (JavaScript, CSS, images) to improve loading times for returning users.\n-   **Compression:** Enable gzip or Brotli compression on your server to reduce the size of files transmitted over the network.\n-   **Target Specific Environments:** Use the `target` option to specify the target JavaScript environment.  This allows esbuild to generate code that is optimized for the specific environment.\n-   **Incremental Builds:** Utilize esbuild's `--watch` option and the context API for incremental builds, which significantly speeds up development by only recompiling changed files.\n\n### 3.2. Memory Management\n\n-   **Avoid Memory Leaks:** Be mindful of memory leaks, especially in long-running applications.  Remove event listeners and clear timers when they are no longer needed.\n-   **Use WeakRefs:** Consider using `WeakRef` in situations where you need to hold a reference to an object without preventing it from being garbage collected.\n-   **Profile Your Code:** Use browser developer tools to profile your code and identify memory bottlenecks.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n-   **Virtualization:** Use virtualization techniques (e.g., `react-window`, `react-virtualized`) to efficiently render large lists or tables.\n-   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of expensive operations, such as event handlers or API calls.\n-   **Memoization:** Use memoization techniques (e.g., `React.memo`, `useMemo`) to cache the results of expensive calculations.\n\n### 3.4. Bundle Size Optimization\n\n-   **Analyze Bundle Size:** Use tools like `esbuild-visualizer` or `webpack-bundle-analyzer` to analyze your bundle size and identify large dependencies.\n-   **Reduce Dependency Size:** Look for opportunities to reduce the size of your dependencies.  Consider using smaller alternatives or only importing the specific parts of a library that you need.\n-   **Remove Dead Code:**  Ensure that tree shaking is working effectively to remove unused code.\n\n### 3.5. Lazy Loading Strategies\n\n-   **Lazy-Load Components:** Use dynamic imports to lazy-load components that are not immediately needed.\n-   **Lazy-Load Images:** Use lazy-loading for images that are below the fold to improve initial page load time.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n-   **Cross-Site Scripting (XSS):** Prevent XSS attacks by properly escaping user input and using a Content Security Policy (CSP).\n-   **Injection Attacks:** Prevent injection attacks (e.g., SQL injection, command injection) by validating and sanitizing user input.\n-   **Dependency Vulnerabilities:** Regularly audit your dependencies for known vulnerabilities using tools like `npm audit` or `yarn audit`.  Update to the latest versions of your dependencies to patch vulnerabilities.\n\n### 4.2. Input Validation\n\n-   **Validate All Input:** Validate all user input, both on the client-side and the server-side.\n-   **Use Strong Validation Rules:** Use strong validation rules to ensure that input is in the expected format and range.\n-   **Sanitize Input:** Sanitize input to remove potentially malicious characters or code.\n\n### 4.3. Authentication and Authorization\n\n-   **Use Strong Authentication:** Use strong authentication methods, such as multi-factor authentication (MFA).\n-   **Implement Proper Authorization:** Implement proper authorization to ensure that users only have access to the resources they are authorized to access.\n-   **Securely Store Credentials:** Securely store user credentials using hashing and salting.\n\n### 4.4. Data Protection\n\n-   **Encrypt Sensitive Data:** Encrypt sensitive data both in transit and at rest.\n-   **Use HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n-   **Protect API Keys:** Protect API keys and other sensitive configuration data by storing them in environment variables or a secure configuration store.\n\n### 4.5. Secure API Communication\n\n-   **Use HTTPS:** Always use HTTPS for API communication.\n-   **Validate API Responses:** Validate API responses to ensure that they are in the expected format.\n-   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   **Test Individual Components:** Unit tests should focus on testing individual components or modules in isolation.\n-   **Use Mocking and Stubbing:** Use mocking and stubbing to isolate the component under test from its dependencies.\n-   **Test Edge Cases:** Test edge cases and error conditions to ensure that the component handles them correctly.\n\n### 5.2. Integration Testing\n\n-   **Test Interactions Between Components:** Integration tests should focus on testing the interactions between different components or modules.\n-   **Test API Integrations:** Test integrations with external APIs to ensure that they are working correctly.\n\n### 5.3. End-to-End Testing\n\n-   **Test User Flows:** End-to-end tests should simulate user flows to ensure that the application is working correctly from the user's perspective.\n-   **Use a Testing Framework:** Use a testing framework like Cypress or Playwright to automate end-to-end tests.\n\n### 5.4. Test Organization\n\n-   **Co-locate Tests with Code:** Store test files in the same directory as the code they are testing.\n-   **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what each test is verifying.\n\n### 5.5. Mocking and Stubbing\n\n-   **Use a Mocking Library:** Use a mocking library like Jest or Sinon to create mocks and stubs.\n-   **Mock External Dependencies:** Mock external dependencies, such as API calls or database connections.\n-   **Stub Function Behavior:** Stub the behavior of functions to control their return values or side effects.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Forgetting to Bundle:** Failing to enable bundling can result in performance issues due to multiple HTTP requests.\n-   **Not Minifying:**  Not minifying your code will result in larger file sizes and slower loading times.\n-   **Incorrect `tsconfig.json` Configuration:** Incorrectly configuring your `tsconfig.json` file can lead to compilation errors or unexpected behavior.\n-   **Not Handling Environment Variables:** Failing to properly handle environment variables can result in incorrect configuration in different environments.\n-   **Not Using Path Aliases:**  Not using path aliases can make imports more verbose and difficult to maintain.\n\n### 6.2. Edge Cases\n\n-   **Circular Dependencies:** Circular dependencies can lead to unexpected behavior and bundling issues.\n-   **Dynamic Imports with Variable Paths:**  esbuild's support for dynamic imports with variable paths is limited. Be aware of the restrictions and consider alternative approaches if needed.\n-   **Plugin Compatibility:** Ensure that plugins are compatible with the version of esbuild you are using.\n\n### 6.3. Version-Specific Issues\n\n-   **Breaking Changes:** Be aware of breaking changes in new versions of esbuild. Consult the release notes before upgrading.\n\n### 6.4. Compatibility Concerns\n\n-   **Browser Compatibility:**  Ensure that your code is compatible with the target browsers.  Use Babel or other transpilers if necessary.\n-   **Node.js Compatibility:**  If you are building a Node.js application, ensure that your code is compatible with the target version of Node.js.\n\n### 6.5. Debugging Strategies\n\n-   **Source Maps:**  Enable source maps to make it easier to debug your code in the browser developer tools.\n-   **Console Logging:** Use `console.log` statements to debug your code.\n-   **Debugger Statements:**  Use `debugger` statements to pause execution at specific points in your code.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **VS Code:** A popular code editor with excellent support for JavaScript, TypeScript, and esbuild.\n-   **ESLint:** A linter for JavaScript and TypeScript that can help you identify and fix code quality issues.\n-   **Prettier:** A code formatter that can automatically format your code to a consistent style.\n-   **esbuild-visualizer:** A tool to visualize the contents of your esbuild bundle.\n\n### 7.2. Build Configuration Best Practices\n\n-   **Use a Configuration File:** Store your esbuild configuration in a dedicated configuration file (e.g., `esbuild.config.js`).\n-   **Separate Configurations for Different Environments:** Create separate configurations for different environments (development, staging, production).\n-   **Use Environment Variables:** Use environment variables to configure your build process.\n\n### 7.3. Linting and Formatting\n\n-   **Configure ESLint:** Configure ESLint to enforce coding style and identify potential errors.\n-   **Use Prettier:** Use Prettier to automatically format your code to a consistent style.\n-   **Integrate Linting and Formatting into Your Workflow:** Integrate linting and formatting into your development workflow using tools like Husky or lint-staged.\n\n### 7.4. Deployment\n\n-   **Use a Build Process:** Use a build process to bundle, minify, and optimize your code before deployment.\n-   **Deploy to a CDN:** Deploy static assets to a content delivery network (CDN) for faster loading times.\n-   **Use HTTPS:** Always use HTTPS to encrypt communication between the client and the server.\n\n### 7.5. CI/CD Integration\n\n-   **Automate Build and Testing:** Automate your build and testing process using a continuous integration and continuous delivery (CI/CD) pipeline.\n-   **Run Linting and Formatting Checks:**  Run linting and formatting checks as part of your CI/CD pipeline.\n-   **Deploy Automatically:**  Automate the deployment process to deploy new versions of your application automatically.\n\nThis comprehensive guide provides a solid foundation for using esbuild effectively. Remember to adapt these best practices to your specific project needs and continuously learn as the esbuild ecosystem evolves.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.css,*.json",
      "format": "mdc",
      "originalFile": "esbuild.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "esbuild",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "focusing",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "esbuild",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-eslint",
    "description": "This rule provides comprehensive guidelines for ESLint, covering code organization, common patterns, performance, security, testing, and tooling, ensuring high-quality, maintainable JavaScript/TypeScript code.",
    "author": "sanjeed5",
    "tags": [
      "eslint",
      "typescript",
      "javascript",
      "types",
      "cursor",
      "cursor-rule",
      "mdc",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/eslint.mdc",
    "content": "By following these best practices, you can ensure that your JavaScript/TypeScript code is clean, consistent, and maintainable, reducing the risk of bugs and improving overall code quality.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.vue",
      "format": "mdc",
      "originalFile": "eslint.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "eslint",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "covering",
      "code",
      "organization",
      "common",
      "typescript",
      "javascript",
      "types",
      "cursor-rule",
      "mdc",
      "type-safety",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "eslint",
        "typescript",
        "javascript",
        "types",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-expo",
    "description": "This rule provides comprehensive best practices and coding standards for Expo projects, covering code organization, performance, security, testing, and common pitfalls to ensure maintainable and high-quality applications.",
    "author": "sanjeed5",
    "tags": [
      "expo",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "mobile-development",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/expo.mdc",
    "content": "- **Code Organization and Structure**\n  - **Directory Structure:**\n    - Adopt a feature-based directory structure, grouping related files (components, hooks, styles, tests) within feature folders.\n    - Examples:\n      \n      src/\n      ├── components/\n      │   ├── Button/\n      │   │   ├── Button.tsx\n      │   │   ├── Button.styles.ts\n      │   │   └── Button.test.tsx\n      │   └── ...\n      ├── screens/\n      │   ├── Home/\n      │   │   ├── HomeScreen.tsx\n      │   │   ├── HomeScreen.styles.ts\n      │   │   └── HomeScreen.test.tsx\n      │   └── ...\n      ├── navigation/\n      │   ├── AppNavigator.tsx\n      │   └── ...\n      ├── services/\n      │   ├── api.ts\n      │   └── ...\n      ├── utils/\n      │   ├── helpers.ts\n      │   └── ...\n      ├── App.tsx\n      └── index.tsx\n      \n  - **File Naming Conventions:**\n    - Use descriptive and consistent names for files and directories.\n    - Component files: `ComponentName.tsx` or `ComponentName.js`\n    - Style files: `ComponentName.styles.ts` or `ComponentName.styles.js`\n    - Hook files: `useHookName.ts` or `useHookName.js`\n    - Test files: `ComponentName.test.tsx` or `ComponentName.test.js`\n  - **Module Organization:**\n    - Group related components, hooks, and utilities into modules.\n    - Use `index.ts` (or `index.js`) files to export members from a module for easier importing.\n    - Example:\n      \n      // src/components/Button/index.ts\n      export { default as Button } from './Button';\n      \n  - **Component Architecture:**\n    - Favor functional components with hooks for managing state and side effects.\n    - Separate concerns by creating presentational (UI) and container (logic) components.\n    - Use component composition to build complex UIs from smaller, reusable components.\n  - **Code Splitting Strategies:**\n    - Implement lazy loading for screens or components that are not immediately needed.\n    - Utilize `React.lazy` and `Suspense` for dynamic imports.\n    - Expo supports dynamic imports; leverage them to reduce initial bundle size.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - **Higher-Order Components (HOCs):** Use cautiously; prefer hooks or render props for better composability.\n    - **Render Props:** A pattern for sharing code between React components using a prop whose value is a function.\n    - **Compound Components:** Create components that implicitly share state (e.g., Tabs and Tab).\n  - **Recommended Approaches:**\n    - Use Expo's APIs for accessing device features (camera, location, notifications) instead of relying on native modules directly where possible.\n    - Leverage Expo's managed workflow for a smoother development experience.\n  - **Anti-patterns:**\n    - Directly manipulating the DOM (use React's state and props instead).\n    - Writing complex logic directly within components (extract into hooks or utility functions).\n    - Neglecting error handling and edge cases.\n  - **State Management:**\n    - Use React Context for simple state management.\n    - Consider libraries like Zustand, Redux, or Jotai for more complex state management needs.\n    - Leverage `useReducer` for managing complex state transitions.\n  - **Error Handling:**\n    - Implement try-catch blocks to handle potential errors.\n    - Use error boundary components to catch errors during rendering.\n    - Log errors using a centralized logging service (e.g., Sentry).\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - Use `React.memo` to prevent unnecessary re-renders of components.\n    - Implement `shouldComponentUpdate` (for class components) or `useMemo` and `useCallback` (for functional components) to optimize rendering.\n    - Debounce or throttle event handlers to reduce the frequency of updates.\n  - **Memory Management:**\n    - Avoid creating large arrays or objects in component state if not necessary.\n    - Clean up event listeners and timers when components unmount.\n    - Release resources when they are no longer needed.\n  - **Rendering Optimization:**\n    - Virtualize long lists using `FlatList` or `SectionList` to improve scrolling performance.\n    - Optimize image sizes and formats to reduce loading times.\n    - Use the `useNativeDriver: true` prop in animations for better performance.\n  - **Bundle Size Optimization:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused code and dependencies.\n    - Optimize images and other assets.\n  - **Lazy Loading:**\n    - Implement lazy loading for images and other resources that are not immediately visible.\n    - Use the `<Image>` component from `react-native` or `expo-image` with placeholder and loading indicators.\n\n- **Security Best Practices**\n  - **Common Vulnerabilities:**\n    - Cross-Site Scripting (XSS) - Not typically a risk in React Native/Expo, but be mindful when rendering user-provided content via WebView.\n    - Data injection - Protect against SQL or command injection if interacting with backend systems.\n    - Insecure data storage - Never store sensitive information (API keys, credentials) directly in the app code.\n  - **Input Validation:**\n    - Validate user input on both the client and server sides.\n    - Use appropriate data types and formats.\n    - Sanitize user input to prevent injection attacks.\n  - **Authentication and Authorization:**\n    - Use secure authentication mechanisms (e.g., OAuth 2.0, JWT).\n    - Implement proper authorization to restrict access to sensitive data and functionality.\n    - Store authentication tokens securely (e.g., using Expo SecureStore).\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all API communication.\n    - Avoid storing sensitive information in logs.\n  - **Secure API Communication:**\n    - Use HTTPS for all API requests.\n    - Validate API responses.\n    - Implement rate limiting to prevent abuse.\n\n- **Testing Approaches**\n  - **Unit Testing:**\n    - Write unit tests for individual components, hooks, and utility functions.\n    - Use testing libraries like Jest and React Testing Library.\n    - Mock dependencies to isolate units of code.\n  - **Integration Testing:**\n    - Test the interactions between multiple components or modules.\n    - Use tools like Detox or Appium for end-to-end testing on real devices or emulators.\n  - **End-to-end Testing:**\n    - Simulate user interactions to test the entire application flow.\n    - Use tools like Detox or Appium for end-to-end testing on real devices or emulators.\n  - **Test Organization:**\n    - Organize tests in a clear and maintainable structure.\n    - Group tests by component or module.\n    - Use descriptive names for test cases.\n  - **Mocking and Stubbing:**\n    - Use mocking to isolate units of code and simulate dependencies.\n    - Use stubbing to replace complex or external dependencies with simplified versions.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - Forgetting to clean up event listeners or timers.\n    - Mutating state directly instead of using `setState` or state update functions.\n    - Over-rendering components due to unnecessary state updates.\n  - **Edge Cases:**\n    - Handling different screen sizes and orientations.\n    - Dealing with slow network connections or API failures.\n    - Managing application state during interruptions (e.g., phone calls).\n  - **Version-specific Issues:**\n    - Be aware of breaking changes in React Native and Expo SDK updates.\n    - Test your application thoroughly after upgrading dependencies.\n  - **Compatibility Concerns:**\n    - Test your application on different devices and operating systems.\n    - Use platform-specific code only when necessary.\n  - **Debugging Strategies:**\n    - Use the React Native debugger or Chrome DevTools for debugging.\n    - Use console.log statements or debugging tools to inspect variables and application state.\n    - Use error boundary components to catch and log errors.\n\n- **Tooling and Environment**\n  - **Recommended Tools:**\n    - VS Code with Expo and ESLint extensions\n    - Expo CLI for managing Expo projects.\n    - React Native Debugger or Chrome DevTools for debugging.\n  - **Build Configuration:**\n    - Use environment variables to configure different build environments (development, staging, production).\n    - Configure your build process to optimize assets and reduce bundle size.\n  - **Linting and Formatting:**\n    - Use ESLint with the Airbnb or Standard style guide.\n    - Use Prettier to automatically format your code.\n    - Configure your editor to automatically run ESLint and Prettier on save.\n  - **Deployment:**\n    - Use Expo Application Services (EAS) for building and deploying your application.\n    - Follow Expo's deployment documentation for best practices.\n  - **CI/CD Integration:**\n    - Integrate your application with a CI/CD pipeline (e.g., GitHub Actions, CircleCI).\n    - Automate testing, linting, and deployment processes.\n\n- **Expo Specific Recommendations**\n  - **Use Expo Modules:** Prefer Expo modules for accessing native features over community libraries when available, as they are guaranteed to be compatible and well-maintained within the Expo ecosystem.\n  - **EAS Build:**  Use Expo Application Services (EAS) for building native binaries.  This simplifies the build process and handles much of the complexity of native builds.\n  - **Expo Updates:** Implement Expo Updates for over-the-air updates.  This allows for quicker iteration and bug fixes without requiring users to download a new version from the app store.\n  - **Managed Workflow:** Stick to the managed workflow whenever possible.  It handles much of the native configuration and simplifies development.\n  - **Expo SecureStore:** Use `expo-secure-store` to securely store sensitive data like API keys and tokens.\n  - **Environment Variables:** Use `.env` files and `expo-constants` to manage environment-specific configurations.\n  - **Asset Management:**  Place assets (images, fonts) in the `assets` folder and use the `Image` and `Font` components to load them.\n\n- **TypeScript Best Practices**\n  - **Strict Mode:** Enable TypeScript's strict mode (`strict: true` in `tsconfig.json`) for enhanced type safety.\n  - **Explicit Types:**  Explicitly define types for function parameters, return values, and variables.\n  - **Interfaces vs. Types:** Use interfaces for defining contract between objects, and types for defining data structures.\n  - **Utility Types:** Leverage TypeScript's utility types (e.g., `Partial`, `Required`, `Readonly`, `Pick`, `Omit`) for more concise and maintainable code.\n  - **Type Guards:** Use type guards to narrow down types within conditional blocks.\n  - **Async/Await:** Use `async/await` for asynchronous operations to improve code readability and avoid callback hell.\n\n- **Resources**\n  - Expo Documentation: [https://docs.expo.dev/](https://docs.expo.dev/)\n  - React Native Documentation: [https://reactnative.dev/](https://reactnative.dev/)\n  - Expo JavaScript Style Guide: [https://github.com/expo/expo/blob/main/guides/Expo%20JavaScript%20Style%20Guide.md](https://github.com/expo/expo/blob/main/guides/Expo%20JavaScript%20Style%20Guide.md)",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "expo.mdc"
    },
    "subcategory": "react-native",
    "keywords": [
      "cursor",
      "expo",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "react-native"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "expo",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-express",
    "description": "This rule provides comprehensive guidance on best practices for developing robust, maintainable, and performant Express.js applications, covering aspects from code organization and security to testing and deployment.",
    "author": "sanjeed5",
    "tags": [
      "express",
      "nodejs",
      "backend",
      "javascript",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "api",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/express.mdc",
    "content": "- # Express.js Best Practices\n\n  This document outlines best practices for developing Express.js applications to ensure code quality, maintainability, performance, and security.\n\n  ## 1. Code Organization and Structure\n\n  - ### Directory Structure Best Practices\n\n    - **Modular Structure:** Organize your application into logical modules based on functionality (e.g., `controllers`, `models`, `routes`, `middleware`, `services`).\n    - **Configuration:** Separate configuration files for different environments (development, production, testing).\n    - **Public Assets:** Keep static assets (CSS, JavaScript, images) in a dedicated `public` directory.\n    - **Views:** Store template files in a `views` directory. Use a template engine like EJS or Pug.\n    - **Example Structure:**\n\n      \n      my-express-app/\n      ├── controllers/\n      │   ├── userController.js\n      │   └── productController.js\n      ├── models/\n      │   ├── user.js\n      │   └── product.js\n      ├── routes/\n      │   ├── userRoutes.js\n      │   └── productRoutes.js\n      ├── middleware/\n      │   ├── authMiddleware.js\n      │   └── errorMiddleware.js\n      ├── services/\n      │   ├── userService.js\n      │   └── productService.js\n      ├── config/\n      │   ├── config.js\n      │   └── db.js\n      ├── views/\n      │   ├── index.ejs\n      │   └── user.ejs\n      ├── public/\n      │   ├── css/\n      │   │   └── style.css\n      │   ├── js/\n      │   │   └── script.js\n      │   └── images/\n      ├── app.js         # Main application file\n      ├── package.json\n      └── .env           # Environment variables\n      \n\n  - ### File Naming Conventions\n\n    - **Descriptive Names:** Use clear and descriptive names for files and directories.\n    - **Case Convention:** Use camelCase for JavaScript files and directories.  For components consider PascalCase.\n    - **Route Files:** Name route files according to the resource they handle (e.g., `userRoutes.js`, `productRoutes.js`).\n    - **Controller Files:** Name controller files according to the resource they handle (e.g., `userController.js`, `productController.js`).\n    - **Model Files:** Name model files after the data model they represent (e.g., `user.js`, `product.js`).\n\n  - ### Module Organization\n\n    - **ES Modules:** Use ES modules (`import`/`export`) for modularity.\n    - **Single Responsibility Principle:** Each module should have a single, well-defined responsibility.\n    - **Loose Coupling:** Minimize dependencies between modules to improve reusability and testability.\n\n  - ### Component Architecture\n\n    - **Reusable Components:** Break down the application into reusable components (e.g., UI components, service components).\n    - **Separation of Concerns:** Separate presentation logic (views) from business logic (controllers/services).\n    - **Component Composition:** Compose complex components from simpler ones.\n\n  - ### Code Splitting Strategies\n    - **Route-Based Splitting:** Split code based on application routes to reduce initial load time. Use dynamic imports (`import()`) to load modules on demand.\n    - **Component-Based Splitting:** Split code based on components, loading components only when they are needed.\n\n  ## 2. Common Patterns and Anti-patterns\n\n  - ### Design Patterns Specific to Express\n\n    - **Middleware Pattern:** Use middleware functions to handle request processing, authentication, logging, etc.\n    - **MVC Pattern:** Implement the Model-View-Controller (MVC) pattern to separate concerns and improve code organization.\n    - **Observer Pattern:** Implement the observer pattern when you need to notify multiple objects about state changes.\n\n  - ### Recommended Approaches for Common Tasks\n\n    - **Route Handling:** Use Express Router to define routes in separate modules.\n    - **Error Handling:** Use custom error handling middleware to catch and handle errors gracefully. See section 6 for more details.\n    - **Data Validation:** Use middleware for validating request data before processing it.\n    - **Asynchronous Operations:** Use `async/await` or Promises to handle asynchronous operations.\n\n  - ### Anti-patterns and Code Smells to Avoid\n\n    - **God Object:** Avoid creating a single, massive object that handles too many responsibilities.\n    - **Callback Hell:** Avoid deeply nested callbacks; use Promises or `async/await` instead.\n    - **Ignoring Errors:** Always handle errors properly instead of ignoring them.\n    - **Global Variables:** Minimize the use of global variables to avoid naming conflicts and unexpected behavior.\n    - **Hardcoding Secrets:** Never hardcode sensitive information (API keys, passwords) in your code. Use environment variables instead.\n\n  - ### State Management Best Practices\n\n    - **Stateless Controllers:** Keep controllers stateless to improve scalability and testability.\n    - **Session Management:** Use session management middleware (e.g., `express-session`) to manage user sessions.\n    - **Caching:** Implement caching strategies (e.g., Redis, Memcached) to improve performance.\n\n  - ### Error Handling Patterns\n\n    - **Centralized Error Handling:** Create a custom error handling middleware to catch and handle errors from different parts of the application.\n    - **Error Logging:** Log errors to a file or a monitoring service for debugging and analysis.\n    - **Custom Error Objects:** Create custom error objects with specific error codes and messages.\n    - **Graceful Error Messages:** Return user-friendly error messages instead of exposing internal errors.\n    - **Example Error Handler Middleware:**\n\n      javascript\n      // middleware/errorMiddleware.js\n      const errorHandler = (err, req, res, next) => {\n        console.error(err.stack);\n        const statusCode = res.statusCode === 200 ? 500 : res.statusCode;\n        res.status(statusCode);\n        res.json({\n          message: err.message,\n          stack: process.env.NODE_ENV === 'production' ? null : err.stack,\n        });\n      };\n\n      module.exports = errorHandler;\n      \n\n  ## 3. Performance Considerations\n\n  - ### Optimization Techniques\n\n    - **Gzip Compression:** Use Gzip compression to reduce the size of responses.\n    - **Caching:** Implement caching at different levels (e.g., browser caching, server-side caching) to reduce server load.\n    - **Connection Pooling:** Use connection pooling for database connections to improve performance.\n    - **Load Balancing:** Distribute traffic across multiple servers using a load balancer.\n\n  - ### Memory Management\n\n    - **Avoid Memory Leaks:** Be mindful of memory leaks, especially when working with large datasets or long-running processes.  Use tools like `memwatch` to profile.\n    - **Garbage Collection:** Understand how garbage collection works in Node.js and optimize your code accordingly.\n    - **Streams:** Use streams for handling large files or data streams to avoid loading the entire data into memory.\n\n  - ### Rendering Optimization\n\n    - **Template Caching:** Enable template caching in your template engine to improve rendering performance.\n    - **Minify Assets:** Minify CSS and JavaScript files to reduce their size.\n    - **Lazy Loading Images:** Lazy load images to improve initial page load time.\n\n  - ### Bundle Size Optimization\n\n    - **Tree Shaking:** Use tree shaking to remove unused code from your bundles.\n    - **Code Splitting:** Split your code into smaller chunks to reduce the size of initial bundles.\n    - **Dependency Analysis:** Analyze your dependencies to identify and remove unnecessary packages.\n\n  - ### Lazy Loading Strategies\n\n    - **Lazy Load Modules:** Load modules only when they are needed using dynamic imports (`import()`).\n    - **Lazy Load Images and Other Assets:** Use lazy loading for images and other assets that are not immediately visible on the page.\n\n  ## 4. Security Best Practices\n\n  - ### Common Vulnerabilities and How to Prevent Them\n\n    - **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and encoding output.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using CSRF tokens.\n    - **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n    - **NoSQL Injection:** Sanitize user input and avoid constructing queries from strings to prevent NoSQL injection attacks.\n    - **Command Injection:** Avoid executing shell commands based on user input. If necessary, sanitize the input and use appropriate escaping.\n    - **Denial of Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n    - **Man-in-the-Middle (MitM):** Use HTTPS to encrypt communication between the client and server and protect against MitM attacks.\n    - **HTTP Parameter Pollution (HPP):** Avoid using the same parameter multiple times in a request to prevent HPP attacks.\n\n  - ### Input Validation\n\n    - **Server-Side Validation:** Always validate user input on the server-side, even if you have client-side validation.\n    - **Data Sanitization:** Sanitize user input to remove potentially harmful characters or code.\n    - **Schema Validation:** Use schema validation libraries (e.g., Joi, express-validator) to validate request data against a predefined schema.\n\n  - ### Authentication and Authorization Patterns\n\n    - **Authentication:** Use a secure authentication mechanism (e.g., JWT, OAuth) to verify user identities.\n    - **Authorization:** Implement role-based access control (RBAC) or attribute-based access control (ABAC) to control access to resources.\n    - **Secure Password Storage:** Use a strong hashing algorithm (e.g., bcrypt) to store user passwords securely.\n    - **Multi-Factor Authentication (MFA):** Implement MFA to add an extra layer of security.\n\n  - ### Data Protection Strategies\n\n    - **Encryption:** Encrypt sensitive data at rest and in transit.\n    - **Data Masking:** Mask sensitive data in logs and other outputs.\n    - **Access Control:** Restrict access to sensitive data to authorized users and processes.\n\n  - ### Secure API Communication\n\n    - **HTTPS:** Use HTTPS for all API communication.\n    - **API Keys:** Use API keys to authenticate clients.\n    - **Rate Limiting:** Implement rate limiting to prevent abuse and DoS attacks.\n    - **Input Validation:** Validate all input data to prevent injection attacks.\n    - **Output Encoding:** Encode all output data to prevent XSS attacks.\n\n  ## 5. Testing Approaches\n\n  - ### Unit Testing Strategies\n\n    - **Test-Driven Development (TDD):** Write unit tests before writing the actual code.\n    - **Test Individual Modules:** Test individual modules in isolation to ensure they work correctly.\n    - **Mock Dependencies:** Mock external dependencies (e.g., databases, APIs) to isolate the module being tested.\n\n  - ### Integration Testing\n\n    - **Test Interactions Between Modules:** Test the interactions between different modules to ensure they work together correctly.\n    - **Test API Endpoints:** Test API endpoints to ensure they return the expected results.\n\n  - ### End-to-End Testing\n\n    - **Test the Entire Application Flow:** Test the entire application flow from start to finish.\n    - **Simulate User Interactions:** Simulate user interactions to ensure the application behaves as expected.\n\n  - ### Test Organization\n\n    - **Separate Test Files:** Create separate test files for each module or component.\n    - **Descriptive Test Names:** Use clear and descriptive names for test cases.\n    - **Arrange-Act-Assert Pattern:** Follow the Arrange-Act-Assert pattern in your tests.\n\n  - ### Mocking and Stubbing\n\n    - **Use Mocking Libraries:** Use mocking libraries (e.g., Jest, Sinon) to create mocks and stubs.\n    - **Mock External Dependencies:** Mock external dependencies to isolate the module being tested.\n    - **Stub Function Calls:** Stub function calls to control the behavior of dependencies.\n\n  ## 6. Common Pitfalls and Gotchas\n\n  - ### Frequent Mistakes Developers Make\n\n    - **Not Handling Errors Properly:** Always handle errors properly to prevent unexpected behavior.\n    - **Ignoring Security Vulnerabilities:** Be aware of common security vulnerabilities and take steps to prevent them.\n    - **Not Using Middleware Wisely:** Use middleware wisely to handle common tasks such as authentication, logging, and error handling.\n    - **Over-Engineering:** Avoid over-engineering your code by keeping it simple and focused.\n\n  - ### Edge Cases to Be Aware Of\n\n    - **Handling Large File Uploads:** Use streams or middleware libraries for handling large file uploads to prevent memory issues.\n    - **Dealing with Timezones:** Be aware of timezone issues when working with dates and times.\n    - **Handling Unicode Characters:** Properly handle Unicode characters to prevent encoding issues.\n    - **Dealing with Concurrent Requests:** Implement concurrency control mechanisms to handle concurrent requests safely.\n\n  - ### Version-Specific Issues\n\n    - **Deprecated Features:** Be aware of deprecated features and use the recommended alternatives.\n    - **Breaking Changes:** Be aware of breaking changes when upgrading to a new version of Express.js.\n\n  - ### Compatibility Concerns\n\n    - **Browser Compatibility:** Test your application in different browsers to ensure it works correctly.\n    - **Operating System Compatibility:** Test your application on different operating systems to ensure it works correctly.\n    - **Node.js Version Compatibility:** Ensure your application is compatible with the supported versions of Node.js.\n\n  - ### Debugging Strategies\n\n    - **Use Debugging Tools:** Use debugging tools (e.g., Node.js Inspector, Chrome DevTools) to debug your code.\n    - **Log Statements:** Use log statements to track the flow of execution and identify issues.\n    - **Error Messages:** Read error messages carefully to understand the cause of the error.\n\n  ## 7. Tooling and Environment\n\n  - ### Recommended Development Tools\n\n    - **IDE:** Use a good IDE such as VS Code, WebStorm, or Sublime Text.\n    - **Debugger:** Use a debugger to step through your code and identify issues.\n    - **Linter:** Use a linter (e.g., ESLint) to enforce coding standards.\n    - **Formatter:** Use a formatter (e.g., Prettier) to format your code automatically.\n\n  - ### Build Configuration\n\n    - **Use a Build Tool:** Use a build tool (e.g., Webpack, Parcel) to bundle and optimize your code.\n    - **Configure Build Scripts:** Configure build scripts in your `package.json` file to automate the build process.\n    - **Use Environment Variables:** Use environment variables to configure your application for different environments.\n\n  - ### Linting and Formatting\n\n    - **Use ESLint:** Use ESLint to enforce coding standards and identify potential issues.\n    - **Use Prettier:** Use Prettier to format your code automatically.\n    - **Configure Editor Integration:** Configure your editor to automatically run ESLint and Prettier on save.\n\n  - ### Deployment Best Practices\n\n    - **Use a Process Manager:** Use a process manager (e.g., PM2, Forever) to keep your application running in production.\n    - **Use a Reverse Proxy:** Use a reverse proxy (e.g., Nginx, Apache) to handle incoming requests and forward them to your application.\n    - **Use a Load Balancer:** Use a load balancer to distribute traffic across multiple servers.\n    - **Use HTTPS:** Use HTTPS to encrypt communication between the client and server.\n    - **Monitor Your Application:** Monitor your application to identify and resolve issues.\n\n  - ### CI/CD Integration\n\n    - **Use a CI/CD Pipeline:** Use a CI/CD pipeline (e.g., Jenkins, Travis CI, CircleCI, GitHub Actions) to automate the build, test, and deployment process.\n    - **Run Tests Automatically:** Configure your CI/CD pipeline to run tests automatically on every commit.\n    - **Automate Deployment:** Automate the deployment process to reduce the risk of errors.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "express.mdc"
    },
    "subcategory": "nodejs",
    "keywords": [
      "cursor",
      "express",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "developing",
      "robust",
      "maintainable",
      "nodejs",
      "backend",
      "javascript",
      "cursor-rule",
      "mdc",
      "web",
      "api",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "express",
        "nodejs",
        "backend",
        "javascript",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-fabric-js",
    "description": "This rule provides comprehensive best practices for developing applications with Fabric.js, covering code organization, performance optimization, security considerations, and testing strategies. It aims to help developers create efficient, maintainable, and secure Fabric.js-based applications.",
    "author": "sanjeed5",
    "tags": [
      "fabric-js",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/fabric-js.mdc",
    "content": "# Fabric.js Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing applications using Fabric.js. Following these guidelines will result in more maintainable, performant, and secure code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a modular directory structure to separate concerns and improve code organization.  A typical Fabric.js project might have the following structure:\n\n\nproject-root/\n├── src/\n│   ├── components/\n│   │   ├── CanvasComponent.js       # Component for Fabric.js Canvas\n│   │   ├── ObjectControls.js        # Component for Object Manipulation Controls\n│   │   ├── ...\n│   ├── utils/\n│   │   ├── canvasUtils.js         # Utility functions for canvas operations\n│   │   ├── imageFilters.js        # Custom image filters\n│   │   ├── ...\n│   ├── services/\n│   │   ├── canvasService.js        # Service for managing canvas state\n│   │   ├── ...\n│   ├── models/\n│   │   ├── fabricObject.js      # Custom Fabric.js object definitions\n│   │   ├── ...\n│   ├── App.js                   # Main application component\n│   └── index.js                 # Entry point\n├── public/\n│   ├── index.html\n│   ├── ...\n├── .cursor/\n│   ├── rules/\n│   │   └── fabricjs_best_practices.mdc\n├── .gitignore\n├── package.json\n├── webpack.config.js           # Example build configuration (if using Webpack)\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive file names. For example, `CanvasComponent.js` instead of `canvas.js`.  Name files according to the component they contain.\n*   Follow a consistent naming convention (e.g., PascalCase for components, camelCase for functions and variables).\n\n### 1.3. Module Organization\n\n*   Break down the application into smaller, reusable modules.  Use ES modules (`import`/`export`) to manage dependencies.\n*   Each module should have a single responsibility.  A single canvas utility module, a module for custom objects, etc.\n*   Avoid circular dependencies between modules.\n\n### 1.4. Component Architecture\n\n*   Adopt a component-based architecture, especially when using frameworks like React, Vue, or Angular. Fabric.js can be integrated into components that manage different aspects of the canvas.\n*   Create reusable components for common Fabric.js elements and interactions. For example, create a component that encapsulates custom object controls.\n*   Separate the presentation logic from the business logic. Components should primarily focus on rendering the canvas and handling user interactions, while services or utility functions handle data manipulation and API calls.\n\n### 1.5. Code Splitting\n\n*   If the application is large, use code splitting to reduce the initial load time. Frameworks like React and Vue provide built-in support for code splitting.\n*   Consider lazy-loading parts of the application that are not immediately needed, such as advanced image filters or custom object editors.\n*   Webpack's dynamic `import()` is a great way to implement code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Observer Pattern:** Use the Observer pattern for managing canvas events. For example, subscribe to `object:modified` to update the application state when an object is changed.\n*   **Factory Pattern:** Use the Factory pattern for creating Fabric.js objects. This allows you to create objects with consistent configurations and avoid code duplication.  Create a `FabricObjectFactory` service.\n*   **Strategy Pattern:** Employ the Strategy pattern for implementing different rendering strategies or image filters.  Allows for easy switching of rendering algorithms.\n\n### 2.2. Recommended Approaches\n\n*   **Object Manipulation:** Use Fabric.js's built-in methods for manipulating objects (`set()`, `get()`, `scale()`, `rotate()`, etc.).  Leverage these methods instead of directly manipulating properties to ensure proper updates and event triggering.\n*   **Event Handling:**  Utilize Fabric.js's extensive event system for handling user interactions and object changes.  Subscribe to relevant events like `mouse:down`, `object:moving`, and `selection:created` to implement custom behaviors.\n*   **Asynchronous Operations:** Use Promises and `async/await` for asynchronous operations, such as loading images or applying filters. This helps avoid callback hell and makes the code more readable.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Direct DOM Manipulation:** Avoid directly manipulating the DOM of the canvas element. Use Fabric.js's API for all canvas operations.  This can lead to inconsistencies and performance issues.\n*   **Global State:** Avoid storing the Fabric.js canvas instance or object states in global variables. Use a state management library or component state to manage the application state.\n*   **Over-rendering:** Avoid unnecessary re-renders of the entire canvas. Use `canvas.renderOnAddRemove = false` and call `canvas.renderAll()` only when necessary. Also use `fabric.StaticCanvas` if interactivity isn't required.\n*   **Deeply Nested Callbacks:** Avoid deeply nested callbacks when working with asynchronous operations. Use Promises and `async/await` to simplify the code.\n\n### 2.4. State Management\n\n*   Choose a state management library based on the complexity of the application.  Options include: \n    *   **React Context API:** For simple applications.\n    *   **Redux:** For complex applications with predictable state management.\n    *   **Vuex:** For Vue.js applications.\n    *   **Zustand or Jotai:** Lightweight, unopinionated state management solutions.\n*   Store the minimal amount of state necessary.  Avoid storing derived data in the state.\n*   Use immutable data structures to prevent accidental state mutations.\n*   Consider using a state management library specifically designed for canvas applications, if available.\n\n### 2.5. Error Handling\n\n*   Use `try...catch` blocks to handle exceptions that may occur during Fabric.js operations, such as loading images or parsing JSON.\n*   Log errors to the console or a logging service.  Provide informative error messages to help debug the application.\n*   Implement a global error handler to catch unhandled exceptions.  Display a user-friendly error message and prevent the application from crashing.\n*   Consider using `canvas.discardActiveObject()` after error to prevent object interaction when error occur.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Static Canvas:** Use `fabric.StaticCanvas` when interactivity is not needed.\n*   **Object Selectability:** Set `object.selectable = false` when objects don't need to be selectable.\n*   **Control and Border Visibility:** Set `object.hasControls = false` and `object.hasBorders = false` when controls and borders are not needed.\n*   **Rotating Point Visibility:** Set `object.hasRotatingPoint = false` when rotation is not needed.\n*   **Canvas Selection:** Disable canvas selection with `canvas.selection = false` when selection is not needed.\n*   **Skip Target Find:** Use `canvas.skipTargetFind = true` to avoid Fabric detecting object corners on mouse movement.\n*   **Render on Add/Remove:** Set `canvas.renderOnAddRemove = false` when adding or removing many objects.\n*   **Object Visibility:** Set `object.visible = false` for objects outside the canvas drawing area.\n*   **Caching:** Use caching to improve rendering performance. Fabric.js automatically caches objects, but you can manually control caching with `object.cache = true` and `object.dirty = true`.\n*   **Offscreen Canvas:** Pre-render complex objects or repeating elements on an offscreen canvas and then draw the offscreen canvas onto the main canvas.\n*   **Integer Coordinates:** Avoid floating-point coordinates by rounding coordinates used in `drawImage()` using `Math.floor()`.\n*   **CSS Transforms:** Use CSS transforms for scaling the canvas instead of scaling the canvas context.\n*   **Transparency:** Set the `alpha` option to `false` when creating a drawing context with `HTMLCanvasElement.getContext()` if transparency is not needed.\n*   **Batch Calls:** Batch canvas calls together to reduce the number of draw operations. For example, draw a polyline instead of multiple separate lines.\n*   **Avoid State Changes:** Avoid unnecessary canvas state changes.  Minimize changes to fill, stroke, shadow, etc.\n*    **Render Differences:** Render only screen differences, not the whole new state.\n*   **Shadow Blur:** Avoid the `shadowBlur` property whenever possible, as it is computationally expensive.\n*   **Text Rendering:** Minimize text rendering, as it can be slow.\n*   **Clear Canvas:** Experiment with different ways to clear the canvas (`clearRect()`, `fillRect()`, resizing the canvas) to find the most performant method.\n*   **Animations:** Use `window.requestAnimationFrame()` instead of `setInterval()` for animations.\n\n### 3.2. Memory Management\n\n*   **Object Disposal:** When objects are no longer needed, remove them from the canvas and dispose of them using `object.dispose()` to release memory. Also consider removing event listeners manually.\n*   **Image Handling:** Be mindful of image sizes, and resize images before loading them into the canvas if necessary.  Avoid loading very large images that can consume a lot of memory.\n*   **Garbage Collection:** Force garbage collection when memory usage is high (though this is generally discouraged and should be a last resort).  Consider using tools to profile memory usage and identify memory leaks.\n\n### 3.3. Rendering Optimization\n\n*   **Layered Canvases:** Use multiple layered canvases for complex scenes where some elements change frequently while others remain static.\n*   **Plain CSS:** Use plain CSS for large background images instead of rendering them on the canvas.\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from the Fabric.js library. Configure your build tool (e.g., Webpack, Parcel) to enable tree shaking.\n*   **Code Splitting:** Use code splitting to reduce the initial load time by loading only the necessary code.\n*   **Minification:** Minify the JavaScript code to reduce the bundle size.\n*   **Gzip Compression:** Use Gzip compression to reduce the size of the transferred files.\n*   **Use Modules Selectively:**  Import only the necessary modules from Fabric.js. For example, `import { Canvas, Rect } from 'fabric'` instead of `import { fabric } from 'fabric'`.\n\n### 3.5. Lazy Loading\n\n*   Lazy-load components or features that are not immediately needed. For example, lazy-load advanced image filters or custom object editors.\n*   Use dynamic imports (`import()`) to load modules on demand.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS vulnerabilities by carefully sanitizing user input before rendering it on the canvas.  Be especially careful when allowing users to enter text or upload images.\n*   **Image Upload Vulnerabilities:**  Validate image uploads to prevent malicious files from being uploaded. Check file extensions, MIME types, and image dimensions.  Consider using a dedicated image processing library to sanitize images.\n*   **Serialization Vulnerabilities:** Be careful when serializing and deserializing Fabric.js objects. Avoid using `eval()` or other unsafe methods for deserialization.\n\n### 4.2. Input Validation\n\n*   Validate all user input before using it to manipulate the canvas.  This includes text, image URLs, and object properties.\n*   Use regular expressions or other validation techniques to ensure that the input matches the expected format.\n*   Sanitize user input to prevent XSS vulnerabilities.\n\n### 4.3. Authentication and Authorization\n\n*   Implement authentication and authorization to restrict access to sensitive features or data.  Use a secure authentication protocol, such as OAuth 2.0 or JWT.\n*   Store user credentials securely using hashing and salting.\n*   Implement role-based access control to limit access to specific features based on user roles.\n\n### 4.4. Data Protection\n\n*   Protect sensitive data by encrypting it at rest and in transit.  Use HTTPS to secure communication between the client and server.\n*   Store sensitive data securely using a database or other secure storage mechanism.\n*   Implement data loss prevention (DLP) measures to prevent sensitive data from being leaked.\n\n### 4.5. Secure API Communication\n\n*   Use HTTPS to secure communication with APIs.\n*   Validate all data received from APIs.\n*   Implement rate limiting to prevent abuse.\n*   Use a secure authentication protocol, such as OAuth 2.0 or JWT.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   Write unit tests for individual components and functions.\n*   Use a testing framework like Jest or Mocha.\n*   Mock external dependencies, such as the Fabric.js canvas instance, to isolate the unit under test.\n*   Test edge cases and error conditions.\n\n### 5.2. Integration Testing\n\n*   Write integration tests to verify the interaction between different components and modules.\n*   Test the integration of Fabric.js with other libraries or frameworks.\n*   Use a testing framework like Cypress or Puppeteer to automate integration tests.\n\n### 5.3. End-to-End Testing\n\n*   Write end-to-end tests to verify the entire application workflow.\n*   Simulate user interactions and verify that the application behaves as expected.\n*   Use a testing framework like Selenium or Playwright to automate end-to-end tests.\n\n### 5.4. Test Organization\n\n*   Organize tests in a clear and consistent manner.  Use a directory structure that mirrors the application's structure.\n*   Write descriptive test names that clearly indicate what is being tested.\n*   Use a test runner to execute the tests and generate reports.\n\n### 5.5. Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate units of code during testing.\n*   Mock Fabric.js objects and methods to control their behavior during tests.  For example, mock the `canvas.add()` method to verify that an object is added to the canvas.\n*   Use a mocking library like Sinon.js or Jest's built-in mocking capabilities.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Incorrect Object Coordinates:** Misunderstanding Fabric.js's coordinate system can lead to incorrect object placement.\n*   **Incorrect Object Origin:** The origin of an object affects its rotation and scaling behavior. Ensure the origin is set correctly.\n*   **Ignoring Events:** Not using Fabric.js's event system for managing user interactions and object changes.\n*   **Over-reliance on `renderAll()`:** Unnecessary calls to `renderAll()` can lead to performance issues.\n*   **Forgetting to Dispose Objects:** Failing to dispose of objects when they are no longer needed can lead to memory leaks.\n*   **Conflicting Event Listeners:** Using native DOM event listeners in a way that conflicts with Fabric.js's event system.\n*   **Not Handling Asynchronous Operations Correctly:** Failing to use Promises and `async/await` for asynchronous operations can lead to callback hell.\n\n### 6.2. Edge Cases\n\n*   **Text Rendering on Different Browsers:** Text rendering can vary across different browsers and operating systems.  Test the application on different platforms to ensure consistent text rendering.\n*   **Image Loading Issues:**  Images may fail to load due to network errors or CORS restrictions.  Implement error handling to gracefully handle image loading failures.\n*   **Object Serialization with Custom Properties:** When serializing objects with custom properties, ensure that the properties are properly handled during serialization and deserialization.\n*   **Zoom and Pan Interactions:**  Implement zoom and pan interactions carefully to avoid performance issues.  Use caching and other optimization techniques to improve performance.\n*   **Touch Device Support:** Ensure that the application works correctly on touch devices.  Handle touch events and gestures appropriately.\n\n### 6.3. Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of Fabric.js. Consult the release notes and migration guides when upgrading Fabric.js.\n*   **Bug Fixes:**  Check the Fabric.js issue tracker for known bugs and fixes.  Consider using a specific version of Fabric.js that is known to be stable and reliable.\n\n### 6.4. Compatibility Concerns\n\n*   **Browser Compatibility:**  Ensure that the application is compatible with the target browsers.  Test the application on different browsers and versions.\n*   **Device Compatibility:** Ensure that the application is compatible with different devices, such as desktops, laptops, tablets, and smartphones.\n*   **Library Conflicts:**  Avoid conflicts with other JavaScript libraries or frameworks.  Use a module bundler like Webpack or Parcel to manage dependencies and prevent conflicts.\n\n### 6.5. Debugging Strategies\n\n*   **Console Logging:** Use `console.log()` to log messages and variables to the console.  Use `console.error()` for error messages and `console.warn()` for warnings.\n*   **Debugging Tools:** Use browser developer tools to inspect the canvas, Fabric.js objects, and event listeners.  Set breakpoints and step through the code to identify issues.\n*   **Fabric.js Debug Mode:** Enable Fabric.js debug mode to get more detailed information about canvas operations. Set `fabric.enableGLVite = true`.\n*   **Profiling Tools:** Use profiling tools to identify performance bottlenecks.  For example, use Chrome DevTools' Performance tab to profile the application's performance.\n*   **Remote Debugging:** Use remote debugging to debug the application on a mobile device or other remote environment.\n*   **Check for Canvas Errors:**  Wrap drawing operations in try/catch blocks to catch errors during rendering. Check if there are errors in the console, like WebGL context errors.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n*   **Code Editor:** Visual Studio Code, Sublime Text, or Atom.\n*   **Module Bundler:** Webpack, Parcel, or Rollup.\n*   **Testing Framework:** Jest, Mocha, or Jasmine.\n*   **Linting Tool:** ESLint or JSHint.\n*   **Code Formatter:** Prettier.\n*   **Version Control System:** Git.\n\n### 7.2. Build Configuration\n\n*   Configure the build tool to enable tree shaking and code splitting.\n*   Use a minifier to reduce the size of the JavaScript code.\n*   Configure the build tool to generate source maps for debugging.\n*   Use a task runner like Gulp or Grunt to automate build tasks.\n\n### 7.3. Linting and Formatting\n\n*   Use a linter like ESLint to enforce code style and identify potential errors.  Configure ESLint to use a consistent coding style guide, such as Airbnb or Google.\n*   Use a code formatter like Prettier to automatically format the code.  Configure Prettier to work with ESLint.\n*   Use editor integrations to automatically lint and format the code on save.\n\n### 7.4. Deployment\n\n*   Deploy the application to a web server, such as Apache or Nginx.\n*   Use a content delivery network (CDN) to serve static assets.\n*   Configure the web server to use Gzip compression.\n*   Use HTTPS to secure communication between the client and server.\n*   Consider using a service like Netlify or Vercel for easy deployment.\n\n### 7.5. CI/CD Integration\n\n*   Use a continuous integration (CI) system to automate the build, test, and deployment process.  Examples include Jenkins, Travis CI, CircleCI, GitHub Actions, GitLab CI.\n*   Configure the CI system to run the linter, code formatter, and tests on every commit.\n*   Configure the CI system to automatically deploy the application to the staging or production environment when the tests pass.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "fabric-js.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "fabric",
      "js",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "with",
      "fabric-js",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "fabric-js",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-fastapi",
    "description": "Comprehensive guidelines for developing robust, scalable, and maintainable FastAPI applications. Covers code structure, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "fastapi",
      "python",
      "backend",
      "api",
      "cursor",
      "cursor-rule",
      "mdc",
      "async",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/fastapi.mdc",
    "content": "# FastAPI Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive set of best practices and coding standards for developing FastAPI applications. These guidelines cover various aspects of development, including project structure, common patterns, performance considerations, security, testing, and tooling.\n\n## 1. Code Organization and Structure\n\nA well-structured codebase is crucial for maintainability, scalability, and collaboration. Adopting a consistent and predictable project structure makes it easier for developers to navigate and understand the application.\n\n### 1.1 Directory Structure Best Practices\n\nInspired by projects like Netflix's Dispatch, a feature-based directory structure is recommended, especially for larger applications:\n\n\nfastapi-project/\n├── alembic/               # Database migrations\n├── src/                   # Source code\n│   ├── auth/              # Authentication module\n│   │   ├── router.py      # API endpoints for authentication\n│   │   ├── schemas.py     # Pydantic models for request/response\n│   │   ├── models.py      # Database models\n│   │   ├── dependencies.py# Dependency injection definitions\n│   │   ├── config.py      # Local configurations\n│   │   ├── constants.py   # Constants and error codes\n│   │   ├── exceptions.py  # Custom exceptions\n│   │   ├── service.py     # Business logic\n│   │   └── utils.py       # Utility functions\n│   ├── aws/               # AWS integration module (example)\n│   │   ├── ...\n│   ├── posts/             # Posts module\n│   │   ├── ...\n│   ├── config.py          # Global configurations\n│   ├── models.py          # Global models\n│   ├── exceptions.py      # Global exceptions\n│   ├── pagination.py      # Pagination logic\n│   ├── database.py        # Database connection and ORM setup\n│   └── main.py            # Main application entry point\n├── tests/                 # Tests\n│   ├── auth/\n│   ├── aws/\n│   └── posts/\n├── templates/             # Jinja2 Templates\n│   └── index.html\n├── requirements/\n│   ├── base.txt           # Base dependencies\n│   ├── dev.txt            # Development dependencies\n│   └── prod.txt           # Production dependencies\n├── .env                   # Environment variables\n├── .gitignore             # Git ignore file\n├── logging.ini            # Logging configuration\n└── alembic.ini          # Alembic configuration\n\n\nKey aspects of this structure:\n\n*   `src/`:  The root directory containing all application code.\n*   Module-based organization:  Features are grouped into modules (e.g., `auth`, `posts`). Each module contains its own set of `router.py`, `schemas.py`, `models.py`, etc. This promotes loose coupling and high cohesion.\n*   `main.py`: The entry point of the FastAPI application.\n*   `config.py`: Stores global configurations.\n*   `database.py`: Handles database connection and ORM setup (e.g., SQLAlchemy).\n*   `requirements/`:  Separate dependency files for different environments.\n\n### 1.2 File Naming Conventions\n\n*   Python files: Use lowercase with underscores (e.g., `user_service.py`).\n*   Pydantic schemas:  Use PascalCase with the suffix \"Schema\" or \"Model\" (e.g., `UserSchema`, `PostModel`).\n*   Database models: Use PascalCase (e.g., `User`, `Post`).\n*   Routers: Typically named `router.py` within each module.\n*   Configuration files: `config.py`\n*   Tests: `test_<module_name>.py` or `test_<feature>.py`\n\n### 1.3 Module Organization\n\n*   **Routers**: Contain API endpoint definitions.\n*   **Schemas**: Define data structures using Pydantic models for request and response validation and serialization.\n*   **Models**: Represent database entities (if using an ORM).\n*   **Services**: Implement business logic, interacting with the database or other services.\n*   **Dependencies**: Define dependency injection functions used in route handlers.\n*   **Constants**: Store module-specific constants and error codes.\n*   **Configuration**: Store module-specific environment variables and settings.\n*   **Exceptions**: Define custom exceptions for specific modules.\n*   **Utils**: Contains general-purpose utility functions.\n\n### 1.4 Component Architecture\n\n*   **Layered Architecture:** Separate the application into distinct layers (e.g., presentation, business logic, data access). This improves maintainability and testability.\n*   **Loose Coupling:** Design components to be independent and minimize dependencies between them. This allows for easier modification and replacement of components.\n*   **High Cohesion:** Ensure that each component has a single, well-defined responsibility.\n*   **Dependency Injection:**  Use FastAPI's built-in dependency injection system to manage dependencies between components. This promotes testability and reusability. Favor interface-based dependency injection for added flexibility.\n\n### 1.5 Code Splitting Strategies\n\n*   **Feature-Based Splitting:** Divide the codebase into modules based on application features (e.g., user management, product catalog, order processing). This makes it easier to understand and maintain the code.\n*   **Vertical Slicing:** Group related components (e.g., routers, schemas, models, services) into slices that represent specific use cases or functionalities.\n*   **Horizontal Splitting:** Separate components based on technical layers (e.g., presentation, business logic, data access). This is useful for enforcing separation of concerns but can lead to more complex dependencies if not managed carefully.\n\n## 2. Common Patterns and Anti-patterns\n\nEmploy established design patterns and avoid common anti-patterns to write clean, efficient, and maintainable FastAPI code.\n\n### 2.1 Design Patterns Specific to FastAPI\n\n*   **Repository Pattern:** Abstract data access logic behind a repository interface. This allows you to switch data sources easily (e.g., from a database to a mock for testing) and centralizes data access concerns.\n*   **Service Layer Pattern:** Encapsulate business logic in service classes. Routers then call the service layer. Promotes testability and keeps routes thin and focused on request/response handling.\n*   **Dependency Injection:**  Utilize FastAPI's dependency injection system extensively for request validation, authentication, authorization, and accessing shared resources like database connections.\n*   **Asynchronous Operations:** Favor `async` functions for I/O-bound tasks to improve performance and concurrency.\n*   **Pydantic Models for Validation:** Use Pydantic models for request and response data validation. Enforce data types, constraints, and custom validation logic.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Configuration Management:** Use Pydantic's `BaseSettings` to manage environment variables and application settings.\n*   **Database Interactions:** Use an ORM like SQLAlchemy for interacting with databases. Define database models and use them for data access.\n*   **Authentication and Authorization:** Implement authentication and authorization using strategies like JWT (JSON Web Tokens) or OAuth 2.0. Use FastAPI's security utilities.\n*   **Error Handling:** Use `HTTPException` for returning meaningful error responses to the client. Define custom exception classes for specific error conditions.\n*   **Logging:** Configure logging using Python's `logging` module. Log important events and errors for debugging and monitoring.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Fat Route Handlers:** Avoid putting too much logic directly inside route handlers. Delegate complex tasks to service classes or utility functions.\n*   **Tight Coupling:** Minimize dependencies between components to improve maintainability and testability.\n*   **Ignoring Asynchronous Operations:** Blocking I/O in async routes can negate the benefits of concurrency. Ensure all I/O operations in async routes are non-blocking.\n*   **Lack of Data Validation:** Failing to validate input data can lead to security vulnerabilities and unexpected behavior. Always use Pydantic models for data validation.\n*   **Hardcoding Values:** Avoid hardcoding values in the code. Use configuration files or environment variables instead.\n*   **Returning Pydantic objects directly from routes.** FastAPI makes an extra conversion. Return a dict.\n\n### 2.4 State Management Best Practices\n\n*   **Stateless Applications:** FastAPI applications are typically stateless, meaning they don't store any persistent data within the application itself. This makes them easier to scale and deploy.\n*   **External Data Stores:** Store application state in external data stores like databases, caches, or message queues.\n*   **Dependency Injection for State:** Use dependency injection to provide access to shared resources or stateful objects to route handlers.\n\n### 2.5 Error Handling Patterns\n\n*   **Centralized Exception Handling:** Implement a global exception handler to catch unhandled exceptions and return appropriate error responses.\n*   **Custom Exception Classes:** Define custom exception classes for specific error conditions. This makes it easier to identify and handle different types of errors.\n*   **Logging Errors:** Log all errors for debugging and monitoring.\n*   **Meaningful Error Messages:** Return meaningful error messages to the client to help them understand what went wrong.\n\n## 3. Performance Considerations\n\nFastAPI is known for its performance, but optimizations are still crucial for high-load applications.\n\n### 3.1 Optimization Techniques\n\n*   **Asynchronous Operations:** Utilize `async` and `await` for I/O-bound operations to prevent blocking the event loop.\n*   **Database Connection Pooling:** Use a database connection pool to reuse database connections and reduce connection overhead.\n*   **Caching:** Implement caching for frequently accessed data to reduce database load and improve response times. Use tools like Redis or Memcached.\n*   **Gzip Compression:** Enable gzip compression for API responses to reduce the size of the data transmitted over the network.\n*   **Load Balancing:** Distribute traffic across multiple instances of the application to improve scalability and availability.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks in the code.\n\n### 3.2 Memory Management\n\n*   **Resource Management:** Properly manage resources like database connections, file handles, and network sockets. Close resources when they are no longer needed.\n*   **Data Structures:** Use efficient data structures like sets and dictionaries for fast lookups.\n*   **Generators:** Use generators for processing large datasets to avoid loading the entire dataset into memory at once.\n*   **Object Reuse:** Reuse objects whenever possible to reduce memory allocation overhead. Consider using object pools for frequently used objects.\n\n### 3.3 Rendering Optimization\n\n*   **Template Caching:** Enable template caching for Jinja2 templates to reduce rendering overhead.\n*   **Minimize Template Logic:** Keep template logic simple and avoid complex computations in templates.\n*   **Content Delivery Network (CDN):** Use a CDN to serve static assets like images, CSS, and JavaScript files.\n\n### 3.4 Bundle Size Optimization (for Frontend Integration)\n\n*   **Code Splitting:** Split the frontend code into smaller bundles that can be loaded on demand.\n*   **Tree Shaking:** Remove unused code from the frontend bundles using tree shaking techniques.\n*   **Minification:** Minify the frontend code to reduce its size.\n*   **Image Optimization:** Optimize images for the web by compressing them and using appropriate image formats.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Loading of Modules:** Use lazy loading to load modules only when they are needed.\n*   **Lazy Loading of Data:** Load data on demand instead of loading it all at once.\n*   **Asynchronous Loading:** Use asynchronous loading to load data in the background without blocking the main thread.\n\n## 4. Security Best Practices\n\nSecurity is paramount. Protect your FastAPI application from common web vulnerabilities.\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM with proper escaping.\n*   **Cross-Site Scripting (XSS):** Prevent XSS by sanitizing user input and escaping output data.\n*   **Cross-Site Request Forgery (CSRF):** Prevent CSRF by using CSRF tokens.\n*   **Authentication and Authorization Flaws:** Implement robust authentication and authorization mechanisms to protect sensitive data and resources.\n*   **Insecure Direct Object References (IDOR):** Prevent IDOR by verifying that users have access to the objects they are requesting.\n*   **Denial of Service (DoS):** Prevent DoS attacks by implementing rate limiting and input validation.\n\n### 4.2 Input Validation\n\n*   **Pydantic Models:** Use Pydantic models to define data types, constraints, and validation rules for request bodies and query parameters.\n*   **Custom Validation Logic:** Implement custom validation logic for complex validation scenarios.\n*   **Sanitization:** Sanitize user input to remove potentially harmful characters or code.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **JWT (JSON Web Tokens):** Use JWT for stateless authentication. Generate a JWT when a user logs in and verify the JWT on subsequent requests.\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization. Allow users to grant third-party applications access to their data without sharing their credentials.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Attribute-Based Access Control (ABAC):** Implement ABAC to control access to resources based on user attributes and resource attributes.\n*  **CORS (Cross-Origin Resource Sharing):** Configure CORS middleware properly to allow requests only from trusted origins.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Hashing:** Hash passwords and other sensitive data using a strong hashing algorithm like bcrypt or Argon2.\n*   **Data Masking:** Mask sensitive data in logs and other output.\n*   **Data Anonymization:** Anonymize data to protect user privacy.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Always use HTTPS to encrypt communication between the client and the server.\n*   **TLS/SSL Certificates:** Use valid TLS/SSL certificates to establish secure connections.\n*   **Strict Transport Security (HSTS):** Enable HSTS to force browsers to use HTTPS for all requests to the application.\n*   **Content Security Policy (CSP):** Configure CSP to prevent XSS attacks by controlling the sources from which the browser is allowed to load resources.\n\n## 5. Testing Approaches\n\nWrite comprehensive tests to ensure the quality and reliability of your FastAPI application.\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Individual Components:** Write unit tests to test individual components like functions, classes, and modules in isolation.\n*   **Mock Dependencies:** Use mocking frameworks like `unittest.mock` or `pytest-mock` to mock external dependencies and isolate the component being tested.\n*   **Test Edge Cases:** Test edge cases and boundary conditions to ensure that the component handles unexpected input correctly.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Components:** Write integration tests to test the interactions between different components of the application.\n*   **Use a Test Database:** Use a separate test database for integration tests to avoid affecting the production database.\n*   **Test API Endpoints:** Write integration tests to test the API endpoints of the application.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Application Flow:** Write end-to-end tests to test the entire application flow, from the client to the database.\n*   **Use a Testing Framework:** Use a testing framework like Selenium or Cypress to automate end-to-end tests.\n*   **Test User Interface (UI):** Test the user interface of the application to ensure that it is working correctly.\n\n### 5.4 Test Organization\n\n*   **Organize Tests by Module:** Organize tests into separate directories or files based on the module or component being tested.\n*   **Use Descriptive Test Names:** Use descriptive test names that clearly indicate what the test is verifying.\n*   **Follow a Consistent Naming Convention:** Follow a consistent naming convention for test files and test functions.\n*   **Keep Tests Concise:** Keep tests concise and focused on a single aspect of the component being tested.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking Frameworks:** Use mocking frameworks like `unittest.mock` or `pytest-mock` to create mock objects and stub out external dependencies.\n*   **Mock External APIs:** Mock external APIs to isolate the component being tested and avoid making actual API calls during testing.\n*   **Stub Database Interactions:** Stub database interactions to avoid affecting the database during testing.\n*   **Verify Interactions:** Verify that the component being tested interacts with the mock objects as expected.\n\n## 6. Common Pitfalls and Gotchas\n\nBe aware of common pitfalls and gotchas that can arise when developing FastAPI applications.\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Incorrectly Using `Depends`:** Ensure `Depends` is used properly to inject dependencies into route handlers.\n*   **Blocking I/O in Async Routes:** Avoid blocking I/O operations in async routes.\n*   **Not Handling Exceptions:** Implement proper exception handling to prevent unhandled exceptions from crashing the application.\n*   **Ignoring Security Best Practices:** Follow security best practices to protect the application from vulnerabilities.\n*   **Not Writing Tests:** Write comprehensive tests to ensure the quality and reliability of the application.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **Unicode Handling:** Be aware of unicode handling issues when processing user input.\n*   **Time Zones:** Handle time zones correctly when working with dates and times.\n*   **Large File Uploads:** Handle large file uploads efficiently to prevent memory exhaustion.\n*   **Concurrency Issues:** Be aware of concurrency issues when working with shared resources in a multi-threaded or multi-process environment.\n\n### 6.3 Version-Specific Issues\n\n*   **Check Changelogs:** Review the changelogs for FastAPI and its dependencies to be aware of any breaking changes or new features.\n*   **Test Compatibility:** Test the application with different versions of FastAPI and its dependencies to ensure compatibility.\n\n### 6.4 Compatibility Concerns\n\n*   **Python Version:** Ensure that the application is compatible with the target Python version.\n*   **Operating System:** Test the application on different operating systems to ensure compatibility.\n*   **Database Compatibility:** Ensure that the application is compatible with the target database.\n\n### 6.5 Debugging Strategies\n\n*   **Use a Debugger:** Use a debugger like `pdb` or `ipdb` to step through the code and inspect variables.\n*   **Logging:** Use logging to track the execution flow and identify errors.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks.\n*   **Remote Debugging:** Use remote debugging to debug applications running on remote servers.\n\n## 7. Tooling and Environment\n\nUtilize the right tools and environment for efficient FastAPI development.\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** VS Code, PyCharm, or other IDE with Python support.\n*   **Virtual Environment Manager:** `venv`, `conda`, or `poetry` for managing project dependencies.\n*   **Package Manager:** `pip` or `poetry` for installing and managing Python packages.\n*   **Debugger:** `pdb` or `ipdb` for debugging Python code.\n*   **Profiler:** `cProfile` or `py-spy` for profiling Python code.\n\n### 7.2 Build Configuration\n\n*   **`requirements.txt`:** Use `requirements.txt` to specify project dependencies. Generate it using `pip freeze > requirements.txt`.\n*   **`pyproject.toml`:**  Consider using `pyproject.toml` (with Poetry or similar tools) for more advanced dependency management and build configuration.\n\n### 7.3 Linting and Formatting\n\n*   **Linters:** Use linters like `flake8`, `pylint`, or `ruff` to enforce code style and identify potential errors.\n*   **Formatters:** Use code formatters like `black` or `autopep8` to automatically format the code according to PEP 8 standards.\n*   **Pre-commit Hooks:** Use pre-commit hooks to automatically run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n*   **Containerization:** Use Docker to containerize the application for easy deployment and scaling.\n*   **Reverse Proxy:** Use a reverse proxy like Nginx or Apache to handle incoming requests and forward them to the application.\n*   **Process Manager:** Use a process manager like Supervisor or systemd to manage the application process.\n*   **Load Balancing:** Use a load balancer to distribute traffic across multiple instances of the application.\n*   **Monitoring:** Monitor the application using tools like Prometheus or Grafana.\n\n### 7.5 CI/CD Integration\n\n*   **Continuous Integration (CI):** Set up a CI pipeline to automatically build, test, and lint the code on every commit.\n*   **Continuous Delivery (CD):** Set up a CD pipeline to automatically deploy the application to the production environment after the CI pipeline has passed.\n*   **Version Control:** Use a version control system like Git to manage the code and track changes.\n*   **Automated Testing:** Integrate automated tests into the CI/CD pipeline to ensure that the application is working correctly before deployment.\n*   **Automated Rollbacks:** Implement automated rollbacks to revert to a previous version of the application if a deployment fails.\n\n## Conclusion\n\nBy adhering to these best practices, you can develop robust, scalable, and maintainable FastAPI applications that are secure, performant, and easy to test. This guide provides a foundation for building high-quality APIs with FastAPI.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "fastapi.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "fastapi",
      "comprehensive",
      "guidelines",
      "developing",
      "robust",
      "scalable",
      "maintainable",
      "applications",
      "covers",
      "code",
      "python",
      "backend",
      "api",
      "cursor-rule",
      "mdc",
      "async",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "fastapi",
        "python",
        "backend",
        "api",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-ffmpeg",
    "description": "This rule outlines the best practices and coding standards for developing with FFmpeg, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "ffmpeg",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ffmpeg.mdc",
    "content": "# FFmpeg Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing with FFmpeg. Adhering to these guidelines will promote code quality, maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nThe FFmpeg project itself has a specific, well-defined directory structure. While you don't necessarily need to replicate this exactly in your own projects, you can adapt principles from it.\n\n*   `libavcodec/`: Contains all the codecs (encoders and decoders).  Organize your codec-related code in a similar manner if extending FFmpeg.\n*   `libavformat/`: Contains the container format handling (muxers and demuxers).\n*   `libavfilter/`: Contains the audio and video filters.\n*   `libavutil/`: Contains utility functions used throughout the project (e.g., memory management, data structures).\n*   `libswscale/`: Contains the video scaling and pixel format conversion functions.\n*   `libswresample/`: Contains the audio resampling and format conversion functions.\n*   `doc/`: Documentation.\n*   `tools/`: Tools like `ffmpeg`, `ffprobe`, and `ffplay`.\n\nFor projects *using* FFmpeg, a good directory structure is crucial:\n\n\nproject/\n├── src/\n│   ├── ffmpeg_integration/\n│   │   ├── audio_processing.c\n│   │   ├── video_processing.c\n│   │   ├── format_handling.c\n│   │   └── ...\n│   ├── core/\n│   │   ├── data_structures.c\n│   │   ├── utils.c\n│   │   └── ...\n│   ├── main.c\n│   └── ...\n├── include/\n│   ├── ffmpeg_integration/\n│   │   ├── audio_processing.h\n│   │   ├── video_processing.h\n│   │   ├── format_handling.h\n│   │   └── ...\n│   ├── core/\n│   │   ├── data_structures.h\n│   │   ├── utils.h\n│   │   └── ...\n│   └── ...\n├── tests/\n│   ├── unit/\n│   │   ├── test_audio_processing.c\n│   │   ├── test_video_processing.c\n│   │   └── ...\n│   ├── integration/\n│   │   ├── test_end_to_end.c\n│   │   └── ...\n│   └── ...\n├── build/\n├── data/\n├── docs/\n└── ...\n\n\n### 1.2 File Naming Conventions\n\n*   Use descriptive file names. For example, `audio_encoder.c`, `video_decoder.c`, `format_muxer.c`.\n*   Header files should have the same base name as their corresponding source files (e.g., `audio_encoder.c` and `audio_encoder.h`).\n*   Test files can be prefixed with `test_` or postfixed with `_test` (e.g., `test_audio_encoder.c` or `audio_encoder_test.c`).\n\n### 1.3 Module Organization\n\n*   Group related functionalities into modules. Each module should have a clear responsibility (e.g., audio encoding, video decoding, format handling).\n*   Use header files to define the public interface of each module.\n*   Hide implementation details within the source files.\n*   Minimize dependencies between modules.\n\n### 1.4 Component Architecture\n\n*   Adopt a layered architecture. Separate concerns into different layers (e.g., presentation layer, business logic layer, data access layer).\n*   Use an abstraction layer to decouple your application from the FFmpeg API. This will make it easier to switch to a different multimedia library in the future.\n*   Consider using a plugin architecture if you need to support different codecs or formats.\n\n### 1.5 Code Splitting Strategies\n\n*   Split large source files into smaller, more manageable files.\n*   Group related functions and data structures into separate source files.\n*   Use header files to define the interface between source files.\n*   Consider splitting code based on functionality or layer.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Factory Pattern:** Use a factory pattern to create instances of codecs or formats based on their names or IDs.\n*   **Strategy Pattern:** Use a strategy pattern to implement different encoding or decoding algorithms.\n*   **Observer Pattern:**  Use an observer pattern for asynchronous events, like when a frame is decoded or an error occurs.\n*   **Resource Acquisition Is Initialization (RAII):** Use RAII to ensure that resources (e.g., memory buffers, codec contexts) are properly released when they are no longer needed.  FFmpeg APIs often require explicit deallocation.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Encoding:**\n    *   Select appropriate codecs based on the desired quality, bitrate, and compatibility.\n    *   Configure the encoder parameters properly (e.g., bitrate, frame rate, resolution).\n    *   Handle the encoding process asynchronously to avoid blocking the main thread.\n*   **Decoding:**\n    *   Check for errors after each decoding operation.\n    *   Allocate sufficient memory for the decoded frames.\n    *   Convert the decoded frames to a suitable pixel format.\n*   **Muxing/Demuxing:**\n    *   Choose the appropriate container format based on the desired features and compatibility.\n    *   Set the stream parameters correctly (e.g., codec, bitrate, frame rate).\n    *   Handle metadata properly.\n*   **Filtering:**\n    *   Construct filter graphs carefully to achieve the desired effects.\n    *   Optimize the filter graph for performance.\n    *   Handle errors that may occur during filtering.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Ignoring Error Codes:** Always check the return values of FFmpeg functions and handle errors appropriately.\n*   **Leaking Resources:** Always free allocated memory and close opened files.\n*   **Global State:** Avoid using global variables as much as possible.\n*   **Magic Numbers:** Use named constants instead of hardcoded numerical values.\n*   **Long Functions:** Break down long functions into smaller, more manageable functions.\n*   **Unnecessary Transcoding:**  Avoid transcoding between lossy formats if possible. Transcode from lossless to lossy whenever feasible, as mentioned in the provided search results.\n*   **Busy-waiting:** Avoid using tight loops that continuously poll for events. Use asynchronous mechanisms instead.\n\n### 2.4 State Management\n\n*   Use structs to encapsulate the state of FFmpeg operations (e.g., encoding, decoding, filtering).\n*   Pass the state structs to functions that need to access the state.\n*   Avoid using global variables to store state information.\n*   Consider using a state machine to manage the different states of FFmpeg operations.\n\n### 2.5 Error Handling\n\n*   Always check the return values of FFmpeg functions.  Most functions return 0 on success and a negative value on failure.\n*   Use `av_strerror()` to get a human-readable error message.\n*   Log error messages to a file or console.\n*   Handle errors gracefully. Don't just crash the application.\n*   Use exception handling (if appropriate for the language) to catch unexpected errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Codec Selection:** Choose the most efficient codecs for your needs (e.g., use hardware acceleration if available).\n*   **Bitrate Control:** Use appropriate bitrate control methods (e.g., constant bitrate (CBR), variable bitrate (VBR)).\n*   **Multi-threading:** Use multi-threading to parallelize encoding, decoding, and filtering operations.\n*   **SIMD Instructions:** Utilize SIMD (Single Instruction, Multiple Data) instructions (e.g., SSE, AVX) to accelerate processing.\n*   **Caching:** Cache frequently accessed data to reduce memory access overhead.\n*   **Reduce Memory Copies:** Minimize unnecessary memory copies.\n*   **Hardware Acceleration:** Utilize hardware acceleration (e.g., VAAPI, NVENC, QSV) for encoding and decoding.  As the FFmpeg documentation and release notes indicate, there is constant work on expanding HW acceleration capabilities for various codecs.\n*   **Filter Graph Optimization:** Optimize your filter graphs to reduce the number of operations performed.\n\n### 3.2 Memory Management\n\n*   Use `av_malloc()` and `av_free()` to allocate and free memory.\n*   Always free allocated memory when it is no longer needed.\n*   Avoid memory leaks.\n*   Use memory pools to reduce memory allocation overhead.\n*   Be aware of potential buffer overflows.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n*   Use hardware acceleration for rendering (e.g., OpenGL, Direct3D).\n*   Optimize your rendering pipeline to reduce the number of draw calls.\n*   Use efficient data structures for storing video frames.\n\n### 3.4 Bundle Size Optimization (If Applicable)\n\n*   Only include the codecs and formats that you need in your application.\n*   Use a linker to remove unused code.\n*   Compress your application binary.\n\n### 3.5 Lazy Loading (If Applicable)\n\n*   Load codecs and formats on demand.\n*   Use asynchronous loading to avoid blocking the main thread.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **Buffer Overflows:** Ensure that input buffers are large enough to hold the data being read into them. Use functions like `av_strlcpy()` or `av_strlcat()` to prevent overflows.\n*   **Integer Overflows:** Check for potential integer overflows before performing arithmetic operations.\n*   **Format String Vulnerabilities:** Avoid using user-supplied input directly in format strings.\n*   **Denial of Service (DoS):** Limit the resources that can be consumed by FFmpeg operations (e.g., maximum bitrate, maximum frame size).\n*   **Arbitrary Code Execution:** Be extremely careful when using user-supplied plugins or filters. Validate the code before executing it.\n*   **Input Validation flaws:** As the Android Stagefright bug illustrated (mentioned in search results), carefully validate sizes and other parameters in subtitle parsing.\n\n### 4.2 Input Validation\n\n*   Validate all input parameters before passing them to FFmpeg functions.\n*   Check the range of numerical values.\n*   Sanitize strings to prevent format string vulnerabilities.\n*   Use whitelists to restrict the allowed values for certain parameters.\n\n### 4.3 Authentication and Authorization (If Applicable)\n\n*   Use strong authentication mechanisms to protect your application from unauthorized access.\n*   Implement proper authorization policies to restrict access to sensitive resources.\n*   Use secure communication protocols (e.g., HTTPS) to protect data in transit.\n\n### 4.4 Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use secure storage mechanisms to protect your data from unauthorized access.\n*   Implement proper access control policies to restrict access to data.\n*   Consider watermarking video and audio content to deter piracy.\n\n### 4.5 Secure API Communication\n\n*   Use secure protocols (e.g., HTTPS) to communicate with FFmpeg APIs.\n*   Validate all data received from FFmpeg APIs.\n*   Implement proper error handling to detect and respond to security threats.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   Test individual components in isolation.\n*   Use mocking and stubbing to isolate the components being tested.\n*   Write unit tests for all critical functionalities.\n*   Use a test framework (e.g., Check, CUnit) to automate the testing process.\n*   Aim for high code coverage.\n\n### 5.2 Integration Testing\n\n*   Test the interaction between different components.\n*   Simulate real-world scenarios.\n*   Use a test environment that is as close as possible to the production environment.\n\n### 5.3 End-to-End Testing\n\n*   Test the entire application from start to finish.\n*   Verify that all components are working correctly together.\n*   Use automated testing tools to automate the testing process.\n\n### 5.4 Test Organization\n\n*   Organize your tests into separate directories based on the component being tested.\n*   Use descriptive names for test files and test functions.\n*   Group related tests into test suites.\n\n### 5.5 Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate the components being tested.\n*   Create mock objects that mimic the behavior of real objects.\n*   Use stub functions to replace the implementation of certain functions.\n*   Use a mocking framework (e.g., CMock) to simplify the mocking process.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   Forgetting to initialize FFmpeg libraries (e.g., calling `avformat_network_init()` when using network protocols).\n*   Using deprecated APIs.\n*   Not handling codec context correctly.\n*   Misunderstanding time base conversions.\n*   Incorrectly setting pixel formats.\n*   Not properly flushing encoders at the end of encoding.\n\n### 6.2 Edge Cases\n\n*   Handling corrupted or incomplete input files.\n*   Dealing with variable frame rate videos.\n*   Supporting different audio and video codecs.\n*   Handling metadata correctly.\n*   Properly managing threading and synchronization when using multiple threads.\n\n### 6.3 Version-Specific Issues\n\n*   Be aware of API changes between different FFmpeg versions.  Pay close attention to the `APIchanges` files released with each version (as seen in the provided search results).\n*   Use conditional compilation to support different versions of FFmpeg.\n*   Consult the FFmpeg documentation for the specific version you are using.\n\n### 6.4 Compatibility Concerns\n\n*   Ensure that your application is compatible with different operating systems and architectures.\n*   Test your application on different devices.\n*   Use conditional compilation to support different platforms.\n*   Consider using a cross-platform build system (e.g., CMake).\n\n### 6.5 Debugging\n\n*   Use a debugger (e.g., GDB) to step through the code and inspect variables.\n*   Use logging to track the execution of your application.\n*   Use a memory checker (e.g., Valgrind) to detect memory leaks and other memory errors.\n*   Use FFmpeg's built-in debugging tools (e.g., `-report` option).\n*   Check the FFmpeg mailing lists and forums for known issues and solutions.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Visual Studio, CLion, Eclipse.\n*   **Compiler:** GCC, Clang, MSVC.\n*   **Debugger:** GDB, LLDB.\n*   **Memory Checker:** Valgrind.\n*   **Build System:** CMake, Make.\n*   **Linting/Formatting:**  clang-format, cppcheck.\n\n### 7.2 Build Configuration\n\n*   Use a build system (e.g., CMake, Make) to automate the build process.\n*   Configure the build system to include the necessary FFmpeg libraries and header files.\n*   Use compiler flags to optimize the code for performance.\n*   Create separate build configurations for debug and release builds.\n\n### 7.3 Linting and Formatting\n\n*   Use a linter (e.g., cppcheck) to check for coding errors and style violations.\n*   Use a code formatter (e.g., clang-format) to automatically format the code according to a consistent style.\n*   Enforce coding standards through automated checks during the build process.\n*   Follow the FFmpeg coding style guidelines (K&R style, 4-space indentation, as mentioned in the search results).\n\n### 7.4 Deployment\n\n*   Package your application and its dependencies into a single distribution package.\n*   Use a package manager (e.g., apt, yum, Homebrew) to install your application.\n*   Consider using a containerization technology (e.g., Docker) to deploy your application.\n\n### 7.5 CI/CD Integration\n\n*   Integrate your tests into a Continuous Integration/Continuous Deployment (CI/CD) pipeline.\n*   Run the tests automatically whenever code is committed to the repository.\n*   Use a CI/CD tool (e.g., Jenkins, Travis CI, GitHub Actions) to automate the CI/CD process.\n*   Automate the deployment process.",
    "metadata": {
      "globs": "*.c",
      "format": "mdc",
      "originalFile": "ffmpeg.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "ffmpeg",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ffmpeg",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-fiber",
    "description": "This rule provides comprehensive best practices for developing robust, maintainable, and scalable applications using the Fiber web framework in Go. It covers code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "fiber",
      "go",
      "backend",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/fiber.mdc",
    "content": "",
    "metadata": {
      "globs": "*.go",
      "format": "mdc",
      "originalFile": "fiber.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "fiber",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "robust",
      "maintainable",
      "scalable",
      "go",
      "backend",
      "performance",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "fiber",
        "go",
        "golang",
        "backend",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-firebase",
    "description": "This rule provides guidelines for Firebase library usage, covering code organization, performance, security, testing, and common pitfalls. It aims to ensure efficient, secure, and maintainable Firebase projects.",
    "author": "sanjeed5",
    "tags": [
      "firebase",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/firebase.mdc",
    "content": "---\n\n## Firebase Library Best Practices\n\nThis document outlines best practices for developing applications using the Firebase library. It covers various aspects, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling/environment setup. By following these guidelines, developers can create robust, scalable, and secure Firebase applications.\n\n### 1. Code Organization and Structure\n\n- **Directory Structure Best Practices:**\n    - Adopt a modular structure to separate concerns.\n    - Organize code based on features or domains (e.g., `auth`, `database`, `storage`).\n    - Common directory structure:\n        \n        project-root/\n        ├── src/\n        │   ├── components/\n        │   │   ├── Auth/\n        │   │   │   ├── Login.js\n        │   │   │   ├── Signup.js\n        │   │   ├── UI/\n        │   │   │   ├── Button.js\n        │   │   │   ├── Input.js\n        │   ├── services/\n        │   │   ├── firebase.js (Firebase initialization)\n        │   │   ├── authService.js (Authentication logic)\n        │   │   ├── databaseService.js (Database interactions)\n        │   ├── models/\n        │   │   ├── User.js (Data models)\n        │   ├── utils/\n        │   │   ├── helpers.js (Utility functions)\n        │   ├── App.js (Main application component)\n        │   └── index.js (Entry point)\n        ├── tests/\n        │   ├── components/\n        │   ├── services/\n        ├── .env (Environment variables)\n        ├── firebase.json (Firebase configuration)\n        └── package.json\n        \n- **File Naming Conventions:**\n    - Use descriptive and consistent names.\n    - Component files: `ComponentName.js` or `ComponentName.jsx` (e.g., `Login.js`).\n    - Service files: `serviceNameService.js` (e.g., `authService.js`).\n    - Style files: `ComponentName.module.css` or `ComponentName.scss`.\n    - Test files: `ComponentName.test.js` or `ComponentName.spec.js`.\n- **Module Organization Best Practices:**\n    - Encapsulate Firebase logic within dedicated modules/services.\n    - Create a `firebase.js` module for initializing Firebase:\n        javascript\n        // firebase.js\n        import { initializeApp } from \"firebase/app\";\n        import { getAuth } from \"firebase/auth\";\n        import { getFirestore } from \"firebase/firestore\";\n        import { getStorage } from \"firebase/storage\";\n\n        const firebaseConfig = {\n          apiKey: process.env.REACT_APP_FIREBASE_API_KEY,\n          authDomain: process.env.REACT_APP_FIREBASE_AUTH_DOMAIN,\n          projectId: process.env.REACT_APP_FIREBASE_PROJECT_ID,\n          storageBucket: process.env.REACT_APP_FIREBASE_STORAGE_BUCKET,\n          messagingSenderId: process.env.REACT_APP_FIREBASE_MESSAGING_SENDER_ID,\n          appId: process.env.REACT_APP_FIREBASE_APP_ID,\n        };\n\n        const app = initializeApp(firebaseConfig);\n        const auth = getAuth(app);\n        const db = getFirestore(app);\n        const storage = getStorage(app);\n\n        export { auth, db, storage };\n        \n    - Use environment variables to store sensitive Firebase configuration.\n- **Component Architecture Recommendations:**\n    - Favor functional components with hooks (React) for managing state and side effects.\n    - Separate UI components from Firebase data fetching logic.\n    - Use Higher-Order Components (HOCs) or custom hooks for reusable Firebase authentication or data access patterns.\n- **Code Splitting Strategies:**\n    - Implement lazy loading for routes and components to reduce initial bundle size.\n    - Use dynamic imports for conditionally loading Firebase modules.\n    - Example:\n        javascript\n        // Lazy load a component\n        const MyComponent = React.lazy(() => import('./MyComponent'));\n        \n        <React.Suspense fallback={<div>Loading...</div>}>\n          <MyComponent />\n        </React.Suspense>\n        \n\n### 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Repository Pattern:** Abstract Firebase data access behind a repository interface.\n    - **Observer Pattern:** Utilize Firebase's real-time listeners for data synchronization.\n    - **Factory Pattern:** Create Firebase service instances (e.g., Firestore, Auth) using a factory function.\n- **Recommended Approaches for Common Tasks:**\n    - **Authentication:** Use Firebase Authentication for user management. Implement multiple authentication methods (email/password, social login, etc.).\n    - **Data Access:** Utilize Firestore or Realtime Database for storing and retrieving data. Implement efficient querying and data modeling.\n    - **Storage:** Use Firebase Storage for storing files and media. Secure storage access using Firebase Storage Rules.\n    - **Cloud Functions:** Use Cloud Functions for backend logic and serverless tasks. Trigger functions based on Firebase events.\n- **Anti-patterns and Code Smells:**\n    - **Directly manipulating Firebase data in UI components:** Leads to tight coupling and makes testing difficult. Use services to abstract data access.\n    - **Over-fetching data:** Retrieve only the necessary data to avoid performance issues. Use specific queries and projections.\n    - **Ignoring security rules:** Exposes your database to unauthorized access. Define and test security rules thoroughly.\n    - **Writing complex logic in security rules:** Can lead to performance issues and difficult maintenance. Keep security rules simple and focused on access control.\n    - **Hardcoding Firebase configuration:** Makes it difficult to manage multiple environments (development, staging, production).\n- **State Management Best Practices:**\n    - **Local State:** Use React's `useState` or `useReducer` for component-specific state.\n    - **Context API:** Share Firebase authentication state across components.\n        javascript\n        // AuthContext.js\n        import React, { createContext, useState, useEffect } from 'react';\n        import { auth } from './firebase';\n\n        export const AuthContext = createContext();\n\n        export const AuthProvider = ({ children }) => {\n          const [currentUser, setCurrentUser] = useState(null);\n          const [loading, setLoading] = useState(true);\n\n          useEffect(() => {\n            const unsubscribe = auth.onAuthStateChanged(user => {\n              setCurrentUser(user);\n              setLoading(false);\n            });\n\n            return unsubscribe;\n          }, []);\n\n          const value = { currentUser, loading };\n\n          return (\n            <AuthContext.Provider value={value}>\n              {!loading && children}\n            </AuthContext.Provider>\n          );\n        };\n        \n    - **Third-Party Libraries:** Consider Redux, Zustand, or Recoil for complex state management needs.\n- **Error Handling Patterns:**\n    - Implement try-catch blocks for Firebase operations.\n    - Handle Firebase-specific errors gracefully.\n        javascript\n        import { createUserWithEmailAndPassword } from \"firebase/auth\";\n        import { auth } from './firebase';\n\n        const signUp = async (email, password) => {\n          try {\n            const userCredential = await createUserWithEmailAndPassword(auth, email, password);\n            const user = userCredential.user;\n            console.log(\"User created: \", user);\n            return user;\n          } catch (error) {\n            console.error(\"Error creating user: \", error.message);\n            // Handle specific Firebase errors (e.g., auth/email-already-in-use)\n            throw error;\n          }\n        };\n        \n    - Provide informative error messages to the user.\n    - Log errors for debugging and monitoring.\n\n### 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Index Firestore fields:** Optimize query performance by creating indexes on frequently queried fields.\n    - **Limit data retrieval:** Use `limit()` and `startAt()` to retrieve only the necessary data.\n    - **Use denormalization judiciously:**  Consider denormalizing data to reduce the number of reads required for common operations, but be mindful of data consistency.\n    - **Batch writes:** Group multiple write operations into a single batch to reduce network overhead.\n    - **Optimize Cloud Functions:**  Minimize function execution time by optimizing code and reducing dependencies.\n- **Memory Management:**\n    - Properly unsubscribe from Firebase listeners to avoid memory leaks.\n    - Release resources when components unmount.\n    - Utilize garbage collection effectively.\n- **Rendering Optimization:**\n    - Use memoization techniques (e.g., `React.memo`) to prevent unnecessary re-renders.\n    - Virtualize long lists to improve rendering performance.\n- **Bundle Size Optimization:**\n    - Use tree shaking to remove unused Firebase modules.\n    - Minify and compress code.\n    - Analyze bundle size using tools like Webpack Bundle Analyzer.\n- **Lazy Loading Strategies:**\n    - Implement lazy loading for images and other assets.\n    - Use code splitting to load Firebase modules only when needed.\n    - Example for images:\n        html\n        <img src=\"image.jpg\" loading=\"lazy\" alt=\"Image\" />\n        \n\n### 4. Security Best Practices\n\n- **Common Vulnerabilities and Prevention:**\n    - **Data breaches:** Prevent unauthorized access by enforcing strict security rules.\n    - **Authentication bypass:** Secure authentication flows by validating user credentials and using multi-factor authentication.\n    - **Denial-of-service (DoS) attacks:** Implement rate limiting and monitoring to mitigate abusive traffic.\n- **Input Validation:**\n    - Validate all user inputs on the client-side and server-side.\n    - Sanitize inputs to prevent injection attacks.\n    - Implement data type validation and length constraints.\n- **Authentication and Authorization:**\n    - **Use Firebase Authentication:** Leverage Firebase Authentication for user management and authentication.\n    - **Implement Firebase Security Rules:** Define security rules to control access to Firebase resources.\n    - **Use Custom Claims:** Assign custom claims to users based on their roles and permissions.\n    - **App Check:** Use App Check to prevent unauthorized clients from accessing your Firebase resources.\n- **Data Protection:**\n    - **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n    - **Regularly backup data:** Implement regular data backups to prevent data loss.\n    - **Comply with privacy regulations:** Adhere to privacy regulations like GDPR and CCPA.\n- **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement proper authorization mechanisms to restrict access to API endpoints.\n    - Protect API keys and service account credentials.\n\n### 5. Testing Approaches\n\n- **Unit Testing:**\n    - **Isolate components:** Test individual components in isolation.\n    - **Mock Firebase dependencies:** Mock Firebase services to avoid external dependencies.\n        javascript\n        // Example using Jest\n        jest.mock('./firebase', () => ({\n          auth: {\n            currentUser: {},\n            onAuthStateChanged: jest.fn()\n          },\n          db: {\n            collection: jest.fn().mockReturnThis(),\n            doc: jest.fn().mockReturnThis(),\n            get: jest.fn().mockResolvedValue({})\n          }\n        }));\n        \n    - **Test authentication logic:** Verify authentication flows and error handling.\n    - **Use Jest, Mocha, or other testing frameworks.**\n- **Integration Testing:**\n    - **Test interactions between components:** Verify that components work together correctly.\n    - **Use the Firebase Emulator Suite:** Test against a local Firebase environment.\n    - **Test data flow:** Ensure that data is correctly stored and retrieved from Firebase.\n- **End-to-End Testing:**\n    - **Simulate user interactions:** Test the entire application flow from the user's perspective.\n    - **Use Cypress, Selenium, or Puppeteer:** Automate end-to-end tests.\n    - **Test authentication and authorization:** Verify that users can access the correct resources.\n- **Test Organization:**\n    - **Organize tests by component or feature:** Create separate test suites for each component or feature.\n    - **Use descriptive test names:** Clearly describe what each test verifies.\n    - **Follow a consistent testing style:** Adhere to a consistent testing style for all tests.\n- **Mocking and Stubbing:**\n    - **Mock Firebase services:** Use mocking libraries to simulate Firebase services.\n    - **Stub API responses:** Stub API responses to control test data.\n    - **Verify function calls:** Ensure that functions are called with the correct arguments.\n\n### 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Misconfigured security rules:** Leads to unauthorized access.\n    - **Inefficient queries:** Causes performance issues.\n    - **Ignoring error handling:** Makes it difficult to debug and maintain the application.\n    - **Exposing API keys:** Compromises the security of the application.\n- **Edge Cases:**\n    - **Offline scenarios:** Handle offline scenarios gracefully.\n    - **Concurrent data updates:** Manage concurrent data updates to prevent data loss.\n    - **Large datasets:** Optimize data retrieval and rendering for large datasets.\n- **Version-Specific Issues:**\n    - **Breaking changes:** Be aware of breaking changes in Firebase SDK updates.\n    - **Deprecated features:** Avoid using deprecated features.\n    - **Compatibility issues:** Ensure compatibility with other libraries and frameworks.\n- **Compatibility Concerns:**\n    - **Browser compatibility:** Test the application on different browsers.\n    - **Device compatibility:** Test the application on different devices.\n    - **Framework compatibility:** Ensure compatibility with the chosen framework (e.g., React, Angular, Vue).\n- **Debugging Strategies:**\n    - **Use Firebase console:** Monitor Firebase usage and identify issues.\n    - **Use browser developer tools:** Debug client-side code using browser developer tools.\n    - **Use logging:** Log errors and debug messages to identify and resolve issues.\n\n### 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **Firebase CLI:** Manage Firebase projects and deploy applications.\n    - **Firebase Emulator Suite:** Emulate Firebase services locally for testing.\n    - **IDE:** Use VS Code, WebStorm, or other IDEs with Firebase extensions.\n- **Build Configuration:**\n    - **Use a build tool:** Use Webpack, Parcel, or Rollup to bundle and optimize code.\n    - **Configure environment variables:** Use `.env` files to store environment-specific configuration.\n    - **Set up build scripts:** Define build scripts for development, testing, and production.\n- **Linting and Formatting:**\n    - **Use ESLint and Prettier:** Enforce consistent code style and identify potential issues.\n    - **Configure linting rules:** Customize linting rules to match project requirements.\n    - **Automate linting and formatting:** Integrate linting and formatting into the build process.\n- **Deployment Best Practices:**\n    - **Use Firebase Hosting:** Deploy static assets and web applications to Firebase Hosting.\n    - **Use Cloud Functions:** Deploy backend logic to Cloud Functions.\n    - **Configure deployment targets:** Define deployment targets for different environments.\n- **CI/CD Integration:**\n    - **Integrate with CI/CD pipelines:** Automate the build, test, and deployment process.\n    - **Use GitHub Actions, CircleCI, or other CI/CD tools:** Integrate with popular CI/CD platforms.\n    - **Automate testing and deployment:** Automatically run tests and deploy code on every commit or pull request.\n\nBy adhering to these best practices, developers can create efficient, secure, and maintainable Firebase applications. Remember to stay up-to-date with the latest Firebase documentation and best practices to leverage the full potential of the Firebase platform.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.html,*.css,*.scss,*.vue,*.swift,*.kt,*.java,*.py,*.go,*.rb,*.php,*.c,*.cpp,*.cs",
      "format": "mdc",
      "originalFile": "firebase.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "firebase",
      "this",
      "rule",
      "provides",
      "guidelines",
      "library",
      "usage",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "firebase",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-flake8",
    "description": "Comprehensive guide for using Flake8 effectively in Python projects, covering code style, error prevention, security, testing, and optimization. It outlines best practices, patterns, and common pitfalls to help developers maintain high code quality and adherence to standards.",
    "author": "sanjeed5",
    "tags": [
      "flake8",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/flake8.mdc",
    "content": "# Flake8 Best Practices: A Comprehensive Guide\n\nThis document provides a detailed guide on effectively using Flake8 in Python projects to maintain high code quality, enforce coding standards, and prevent common errors. It covers various aspects, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\n### Directory Structure Best Practices\n\n- **Flat is better than nested (but not *too* flat):** Aim for a balance. A deeply nested structure can be hard to navigate, but a completely flat structure becomes unwieldy for larger projects.\n- **Package-oriented:** Organize your code into packages (directories with `__init__.py` files) representing logical components of your application.\n- **Separate concerns:** Keep source code, tests, documentation, and other assets in separate top-level directories (e.g., `src`, `tests`, `docs`).\n\nExample:\n\n\nmy_project/\n├── src/\n│   ├── my_package/\n│   │   ├── __init__.py\n│   │   ├── module1.py\n│   │   ├── module2.py\n│   ├── another_package/\n│   │   ├── __init__.py\n│   │   ├── ...\n├── tests/\n│   ├── __init__.py\n│   ├── test_module1.py\n│   ├── test_module2.py\n├── docs/\n│   ├── ...\n├── .flake8\n├── pyproject.toml\n└── README.md\n\n\n### File Naming Conventions\n\n- **Lowercase with underscores:**  Use lowercase letters and underscores for module and package names (e.g., `my_module.py`, `my_package/`).\n- **Descriptive names:** Choose names that clearly indicate the purpose of the file or module.\n- **Test files:** Prefix test files with `test_` (e.g., `test_my_module.py`). This is a common convention recognized by testing frameworks like `pytest`. Use underscores instead of hyphens.\n\n### Module Organization Best Practices\n\n- **Single responsibility principle:** Each module should have a clear, single purpose.\n- **Import order:** Follow a consistent import order:\n    1.  Standard library imports\n    2.  Third-party imports\n    3.  Local application/package imports\n\n    Separate each group with a blank line.\n- **Avoid circular dependencies:** Design your modules to minimize or eliminate circular dependencies.\n- **Explicit relative imports:** Within packages, use explicit relative imports (`from . import module`) instead of implicit relative imports (which are deprecated in Python 3). These can be enforced with plugins like `flake8-import-order`.\n\n### Component Architecture Recommendations\n\n- **Layered architecture:** Consider a layered architecture (e.g., presentation layer, business logic layer, data access layer) to separate concerns and improve maintainability.  This can enhance testability.\n- **Microservices (for larger projects):** For very large projects, explore a microservices architecture, where each service is a self-contained unit with its own codebase and deployment pipeline. This requires more overhead but offers better scalability and fault isolation.\n- **Dependency Injection:** Use dependency injection to decouple components and facilitate testing.\n\n### Code Splitting Strategies\n\n- **Function size:** Keep functions short and focused. If a function becomes too long, consider splitting it into smaller, more manageable functions.\n- **Class size:** Similarly, keep classes focused. A class should represent a single concept or responsibility.\n- **Module splitting:** If a module becomes too large, consider splitting it into multiple modules based on logical groupings of functionality.\n- **Package splitting:** For larger projects, split packages into subpackages to improve organization.\n- **Lazy loading:** Defer the loading of modules or components until they are actually needed to improve startup time.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns Specific to Flake8 (Indirectly)\n\nFlake8 doesn't directly enforce design patterns, but it encourages practices that support good design:\n\n- **Factory Pattern:**  Using factories to create objects can improve code flexibility and testability. Flake8 won't directly enforce it, but a well-designed factory would adhere to Flake8's style guidelines.\n- **Strategy Pattern:** Employing strategy patterns for algorithms can make code more modular and easier to maintain. Flake8’s advice on function length is key.\n- **SOLID Principles:**  Flake8 aids the application of SOLID principles by promoting clean, well-structured code that is easier to extend, maintain, and test. It improves readability.\n\n### Recommended Approaches for Common Tasks\n\n- **Configuration:** Use a `.flake8` or `setup.cfg` file to configure Flake8 settings (e.g., ignored rules, maximum line length).\n- **Ignoring specific errors:** Use `# noqa` comments at the end of lines to ignore specific errors.  Be specific with error codes (e.g., `# noqa: E501`) rather than using a blanket `# noqa`.\n- **Integrating with pre-commit hooks:** Use pre-commit hooks to automatically run Flake8 before committing code.\n- **Using plugins:** Leverage plugins to extend Flake8's capabilities (e.g., `flake8-bugbear`, `flake8-docstrings`).\n\n### Anti-patterns and Code Smells\n\n- **Long functions/methods:**  Functions and methods that are excessively long and complex.\n- **Duplicated code:** Code that is repeated in multiple places.\n- **Magic numbers:** Hardcoded numerical values that lack explanation.\n- **Global variables:** Excessive use of global variables can lead to unpredictable behavior.\n- **Deeply nested code:** Excessive indentation can make code hard to read and understand.\n- **Ignoring errors indiscriminately:** Using blanket `# noqa` comments without specifying error codes.\n\n### State Management Best Practices\n\n- **Minimize mutable state:** Reduce the use of mutable state to avoid unexpected side effects. Favour immutable data structures.\n- **Clear ownership:** Ensure clear ownership of state.  Avoid shared mutable state as much as possible.\n- **State management libraries:** For complex state management, consider using libraries like Redux or MobX (if applicable in your context, e.g., for GUI applications).\n\n### Error Handling Patterns\n\n- **Specific exceptions:** Catch specific exceptions rather than using a broad `except Exception:`.\n- **Context managers:** Use `try...finally` or `with` statements (context managers) to ensure resources are properly released, even if exceptions occur.\n- **Logging:** Log exceptions and errors to help with debugging.\n- **Raise exceptions appropriately:** Raise exceptions when appropriate to signal errors to calling code.\n- **Avoid swallowing exceptions:** Don't catch exceptions and do nothing.  At least log the error.\n\n## 3. Performance Considerations\n\n### Optimization Techniques Specific to Flake8 (Indirectly)\n\nFlake8 does not directly optimize code, but it encourages practices that lead to better performance:\n\n- **Avoid unnecessary loops:** Optimize loops to minimize the number of iterations and operations performed.\n- **Use efficient data structures:** Choose the appropriate data structure for the task at hand (e.g., `set` for membership testing, `dict` for lookups).\n- **Minimize object creation:** Creating objects can be expensive. Reuse objects where possible.\n- **Use generators and iterators:** Use generators and iterators to process large datasets in a memory-efficient way.\n- **List comprehensions & Generator expressions:** Use these to simplify code and increase its execution speed, where appropriate.\n\n### Memory Management Considerations\n\n- **Avoid memory leaks:** Be careful not to create memory leaks by holding onto objects longer than necessary.\n- **Use weak references:** Use weak references to avoid creating circular references that prevent garbage collection.\n- **Profile your code:** Use profiling tools to identify memory bottlenecks.\n\n### Bundle Size Optimization (If Applicable - e.g., web applications)\n\n- **Dead code elimination:** Remove unused code to reduce bundle size.\n- **Code splitting:** Split your code into smaller chunks that can be loaded on demand.\n- **Minification:** Minify your code to reduce file size.\n- **Compression:** Use compression techniques (e.g., gzip) to reduce the size of files served to the client.\n\n### Lazy Loading Strategies\n\n- **Import-time optimization:** Defer the loading of modules or components until they are actually needed.\n- **Route-based code splitting:**  Load only the code required for the current route (if applicable in your context).\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and Prevention\n\n- **SQL Injection:** Prevent SQL injection by using parameterized queries or ORMs.\n- **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input before displaying it in HTML.\n- **Cross-Site Request Forgery (CSRF):** Implement CSRF protection mechanisms (e.g., CSRF tokens).\n- **Authentication and Authorization:** Implement secure authentication and authorization mechanisms to protect sensitive data.  Don't store passwords in plain text; use hashing algorithms like bcrypt.\n- **Input Validation:** Validate all user input to prevent malicious data from entering your application.\n\n### Input Validation Best Practices\n\n- **Whitelist validation:** Validate input against a whitelist of allowed values.\n- **Regular expressions:** Use regular expressions to validate input formats.\n- **Data type validation:** Ensure that input data is of the expected type.\n- **Length validation:** Limit the length of input strings to prevent buffer overflows.\n\n### Authentication and Authorization Patterns\n\n- **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n- **JSON Web Tokens (JWT):** Use JWTs for authentication and authorization.\n- **Role-based access control (RBAC):** Implement RBAC to control access to resources based on user roles.\n\n### Data Protection Strategies\n\n- **Encryption:** Encrypt sensitive data at rest and in transit.\n- **Hashing:** Use hashing to store passwords securely.\n- **Data masking:** Mask sensitive data when displaying it to users.\n- **Data anonymization:** Anonymize data to protect user privacy.\n\n### Secure API Communication\n\n- **HTTPS:** Use HTTPS for all API communication.\n- **API Keys:** Securely manage API keys.\n- **Rate Limiting:** Implement rate limiting to prevent abuse.\n- **Input sanitization**: Sanitize data being passed to the API to prevent injection vulnerabilities.\n\n## 5. Testing Approaches\n\n### Unit Testing Strategies\n\n- **Test-driven development (TDD):** Write tests before writing code.\n- **Isolate units:** Isolate units of code during testing to ensure that tests are focused and reliable.\n- **Use mocks and stubs:** Use mocks and stubs to replace dependencies during testing.\n- **Assertion libraries:** Use assertion libraries to write clear and concise tests.\n\n### Integration Testing Approaches\n\n- **Test interactions between components:** Test the interactions between different components of your application.\n- **Use real dependencies (when appropriate):** Use real dependencies during integration testing to ensure that components work together correctly.\n- **Test data persistence:** Test data persistence to ensure that data is stored and retrieved correctly.\n\n### End-to-End Testing Recommendations\n\n- **Simulate user behavior:** Simulate user behavior to test the entire application flow.\n- **Use automated testing tools:** Use automated testing tools (e.g., Selenium, Cypress) to automate end-to-end tests.\n- **Test cross-browser compatibility:** Test your application in different browsers to ensure cross-browser compatibility.\n\n### Test Organization Best Practices\n\n- **Separate test code from production code:** Keep test code in a separate directory from production code.\n- **Organize tests by module/component:** Organize tests into modules and components that mirror the structure of your production code.\n- **Use descriptive test names:** Use descriptive test names that clearly indicate what the test is verifying.\n\n### Mocking and Stubbing Techniques\n\n- **Use mocking libraries:** Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to create mocks and stubs.\n- **Mock external dependencies:** Mock external dependencies to isolate units of code during testing.\n- **Stub return values:** Stub return values to control the behavior of mocked objects.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n- **Ignoring Flake8 warnings:** Ignoring Flake8 warnings can lead to code quality issues and potential errors.\n- **Over-reliance on `# noqa`:** Overusing `# noqa` comments can mask underlying problems in your code.\n- **Inconsistent coding style:** Inconsistent coding style can make code harder to read and understand.\n- **Not configuring Flake8:** Not configuring Flake8 can lead to suboptimal results.\n\n### Edge Cases\n\n- **Complex regular expressions:** Complex regular expressions can be difficult to understand and maintain.\n- **Dynamic code generation:** Dynamic code generation can make it difficult for Flake8 to analyze code.\n- **Large files:** Large files can slow down Flake8 analysis.\n\n### Version-Specific Issues\n\n- **Plugin compatibility:** Ensure that plugins are compatible with the version of Flake8 you are using.\n- **Configuration changes:** Be aware of configuration changes between different versions of Flake8.\n\n### Compatibility Concerns\n\n- **Python version compatibility:** Ensure that your code is compatible with the Python versions you are targeting.\n- **Dependency conflicts:** Be aware of potential dependency conflicts between Flake8 and other libraries.\n\n### Debugging Strategies\n\n- **Read Flake8 error messages:** Understand the meaning of Flake8 error messages to identify the root cause of problems.\n- **Use a debugger:** Use a debugger to step through your code and identify errors.\n- **Simplify your code:** Simplify your code to make it easier to debug.\n- **Write unit tests:** Write unit tests to isolate and test individual units of code.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n- **Text editors/IDEs:** VS Code, PyCharm, Sublime Text\n- **Version control:** Git\n- **Virtual environments:** `venv`, `virtualenv`, `conda`\n- **Build tools:** `setuptools`, `poetry`, `pipenv`\n\n### Build Configuration Best Practices\n\n- **Use a `pyproject.toml` file:** Use a `pyproject.toml` file to specify project metadata, dependencies, and build settings.\n- **Specify dependencies explicitly:** Specify dependencies explicitly to ensure that your project is reproducible.\n- **Use version pinning:** Use version pinning to lock down the versions of your dependencies.\n\n### Linting and Formatting\n\n- **Flake8:** Use Flake8 for linting and style checking.\n- **Black:** Use Black for code formatting.\n- **isort:** Use isort for import sorting.\n- **Pre-commit hooks:** Use pre-commit hooks to automatically run linters and formatters before committing code.\n\n### Deployment Best Practices\n\n- **Containerization:** Use Docker to containerize your application.\n- **Cloud platforms:** Deploy your application to a cloud platform (e.g., AWS, Azure, Google Cloud).\n- **Continuous integration/continuous deployment (CI/CD):** Use CI/CD pipelines to automate the deployment process.\n\n### CI/CD Integration Strategies\n\n- **Integrate Flake8 into your CI/CD pipeline:** Run Flake8 as part of your CI/CD pipeline to automatically check code quality.\n- **Fail the build on Flake8 errors:** Configure your CI/CD pipeline to fail the build if Flake8 detects errors.\n- **Use automated testing:** Run automated tests as part of your CI/CD pipeline to ensure that your application is working correctly.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "flake8.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "flake8",
      "comprehensive",
      "guide",
      "using",
      "effectively",
      "python",
      "projects",
      "covering",
      "code",
      "style",
      "error",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "flake8",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-flask-restful",
    "description": "A comprehensive guide to best practices for developing RESTful APIs using Flask and Flask-RESTful, covering code organization, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "flask-restful",
      "flask",
      "python",
      "backend",
      "web",
      "rest",
      "api",
      "cursor",
      "cursor-rule",
      "mdc",
      "microframework",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/flask-restful.mdc",
    "content": "# flask-restful Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive guide to developing RESTful APIs using Flask and Flask-RESTful, emphasizing maintainability, scalability, and performance. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, and common pitfalls.\n\n## Library Information:\n\n- Name: flask-restful\n- Tags: web, api, python, flask\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nA well-organized directory structure is crucial for maintainability. Here's a recommended structure:\n\n\nproject/\n├── api/\n│   ├── __init__.py\n│   ├── resources/\n│   │   ├── __init__.py\n│   │   ├── user.py       # User resource\n│   │   ├── item.py       # Item resource\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── user_model.py # User model\n│   │   ├── item_model.py # Item model\n│   ├── schemas/\n│   │   ├── __init__.py\n│   │   ├── user_schema.py # User schema (using Marshmallow)\n│   │   ├── item_schema.py # Item schema\n│   ├── utils/\n│   │   ├── __init__.py\n│   │   ├── auth.py      # Authentication utilities\n│   ├── app.py          # Flask application initialization\n│   ├── config.py       # Configuration settings\n├── tests/\n│   ├── __init__.py\n│   ├── test_user.py    # Unit tests for user resource\n│   ├── test_item.py    # Unit tests for item resource\n├── migrations/       # Alembic migrations (if using SQLAlchemy)\n├── venv/             # Virtual environment\n├── requirements.txt  # Project dependencies\n├── Pipfile           # Pipenv file\n├── Pipfile.lock      # Pipenv lock file\n├── README.md\n\n\n*   **api/**: Contains all API-related code.\n*   **api/resources/**: Defines the API resources (e.g., User, Item).\n*   **api/models/**: Defines the data models (e.g., User, Item).\n*   **api/schemas/**: Defines the serialization/deserialization schemas (using Marshmallow or similar).\n*   **api/utils/**: Utility functions (e.g., authentication, authorization).\n*   **api/app.py**: Initializes the Flask application.\n*   **api/config.py**: Stores configuration settings (e.g., database URI).\n*   **tests/**: Contains unit and integration tests.\n*   **migrations/**: Contains database migration scripts (if using SQLAlchemy).\n*   **venv/**: The virtual environment (should not be committed to version control).\n*   **requirements.txt**: Lists project dependencies. Alternatively `Pipfile` and `Pipfile.lock` for pipenv\n*   **README.md**: Project documentation.\n\n### 1.2 File Naming Conventions\n\n*   Python files: Use snake_case (e.g., `user_model.py`, `item_resource.py`).\n*   Class names: Use PascalCase (e.g., `UserModel`, `ItemResource`).\n*   Variable names: Use snake_case (e.g., `user_id`, `item_name`).\n*   Constants: Use SCREAMING_SNAKE_CASE (e.g., `MAX_RETRIES`, `API_VERSION`).\n\n### 1.3 Module Organization\n\n*   Group related resources into modules (e.g., a `user` module containing `user_model.py`, `user_resource.py`, `user_schema.py`).\n*   Use Blueprints to organize related views and other code.  Blueprints can be registered with the app, tying all operations to it.\n*   Keep modules small and focused on a single responsibility.\n*   Use clear and descriptive module names.\n\n### 1.4 Component Architecture\n\nA common component architecture involves the following layers:\n\n*   **Resource Layer:** Exposes the API endpoints using `flask-restful`'s `Resource` class.\n*   **Service Layer:** Contains the business logic and interacts with the data models.\n*   **Model Layer:** Defines the data models and interacts with the database (if applicable).\n*   **Schema Layer:** Defines the serialization/deserialization logic using libraries like Marshmallow.\n\n### 1.5 Code Splitting Strategies\n\n*   **Functional Decomposition:** Split code into functions based on their functionality.\n*   **Modular Decomposition:** Split code into modules based on related functionality (e.g., user management, item management).\n*   **Layered Architecture:**  As described above, separate the resource, service, model, and schema layers.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Resource Controller:** Use `flask-restful`'s `Resource` class to define API endpoints.  It provides a structured way to handle different HTTP methods for a given resource.\n*   **Data Access Object (DAO):** Encapsulate database access logic within DAOs to abstract the database implementation from the rest of the application.\n*   **Repository Pattern:** Similar to DAO, but provides a higher-level abstraction for accessing data, often used with ORMs like SQLAlchemy.\n*   **Serialization/Deserialization:** Use libraries like Marshmallow to handle the serialization and deserialization of data between Python objects and JSON.\n*   **Middleware:** Implement custom middleware to handle tasks like authentication, logging, and request validation.\n*   **Factory Pattern:** Used to create objects, especially resources and their dependencies, decoupling code from concrete implementations.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Input Validation:** Use Marshmallow schemas for input validation.  Define the expected data types, required fields, and validation rules in the schema.\n*   **Authentication:** Implement authentication using JWT (JSON Web Tokens). Use libraries like `Flask-JWT-Extended` or `Authlib` to handle JWT generation, verification, and storage.\n*   **Authorization:** Implement authorization using roles and permissions.  Use decorators to restrict access to specific endpoints based on user roles.\n*   **Error Handling:** Implement centralized error handling using Flask's `errorhandler` decorator.  Return meaningful error messages and appropriate HTTP status codes to the client.\n*   **Pagination:** Implement pagination for large datasets to improve performance.  Use query parameters to specify the page number and page size.\n*   **API Versioning:** Use URL prefixes or custom headers to version your API. This allows you to introduce breaking changes without affecting existing clients.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API. Use libraries like `Flask-Limiter` to limit the number of requests that can be made from a specific IP address within a given time period.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Fat Resources:** Avoid putting too much logic directly into the resource classes. Delegate business logic to service classes.\n*   **Tight Coupling:** Avoid tight coupling between resources and models. Use interfaces or abstract classes to decouple components.\n*   **Ignoring Errors:** Always handle errors gracefully and return meaningful error messages to the client.\n*   **Lack of Input Validation:**  Failing to validate input can lead to security vulnerabilities and data corruption.\n*   **Hardcoding Configuration:**  Avoid hardcoding configuration values in the code. Use environment variables or configuration files instead.\n*   **Inconsistent Naming:**  Use consistent naming conventions throughout the codebase.\n*   **Over-engineering:** Avoid over-engineering solutions. Keep the code simple and focused on solving the specific problem.\n\n### 2.4 State Management\n\nFlask-RESTful is designed to be stateless. However, if you need to manage state, consider the following:\n\n*   **Session Management:** Use Flask's session management capabilities for storing user-specific data across requests.\n*   **Caching:** Use caching mechanisms (e.g., Redis, Memcached) for storing frequently accessed data to improve performance.\n*   **Database:**  Store persistent state in a database.\n\n### 2.5 Error Handling\n\n*   **Global Exception Handling:** Use `app.errorhandler` to handle exceptions globally. This provides a centralized way to catch unhandled exceptions and return appropriate error responses.\n*   **Custom Exceptions:** Define custom exception classes for specific error conditions.  This makes it easier to handle errors in a consistent way.\n*   **Logging:**  Log errors and exceptions to a file or a logging service. This helps with debugging and troubleshooting.\n*   **HTTP Status Codes:** Return appropriate HTTP status codes to indicate the success or failure of a request.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Database Optimization:** Optimize database queries, use indexes, and consider caching database results.\n*   **Caching:** Use caching mechanisms (e.g., Redis, Memcached) to store frequently accessed data.\n*   **Gunicorn with multiple workers:** Gunicorn is a WSGI server that can run multiple worker processes to handle concurrent requests. This can significantly improve performance.\n*   **Asynchronous Tasks:** Use Celery or other task queues for long-running tasks to avoid blocking the main thread.\n*   **Code Profiling:** Use profiling tools to identify performance bottlenecks in the code.\n*   **Connection Pooling:** Use connection pooling to reduce the overhead of establishing database connections.\n*   **Avoid N+1 Query Problem:**  When fetching related data, use eager loading or join queries to avoid the N+1 query problem.\n\n### 3.2 Memory Management\n\n*   **Use Generators:** Use generators for processing large datasets to avoid loading the entire dataset into memory.\n*   **Close Database Connections:**  Always close database connections after use to release resources.\n*   **Limit Data Serialization:** Avoid serializing large amounts of data unnecessarily.\n*   **Garbage Collection:**  Be aware of Python's garbage collection mechanism and avoid creating circular references.\n\n### 3.3 Rendering Optimization\n\n*   **Use Templates:** Use Jinja2 templates for rendering HTML content.  Templates can be cached to improve performance.\n*   **Minimize DOM Manipulation:**  Minimize DOM manipulation in the client-side JavaScript code.  Use techniques like virtual DOM to improve performance.\n*   **Compress Responses:** Use gzip compression to reduce the size of the responses.\n\n### 3.4 Bundle Size Optimization\n\n*   **Use a CDN:** Use a Content Delivery Network (CDN) to serve static assets like CSS, JavaScript, and images.\n*   **Minify CSS and JavaScript:**  Minify CSS and JavaScript files to reduce their size.\n*   **Tree Shaking:** Use tree shaking to remove unused code from the JavaScript bundles.\n\n### 3.5 Lazy Loading\n\n*   **Lazy Load Images:**  Use lazy loading for images to improve page load time.\n*   **Lazy Load Modules:** Use lazy loading for modules that are not immediately needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **SQL Injection:**  Occurs when user input is directly inserted into SQL queries.\n*   **Cross-Site Scripting (XSS):**  Occurs when malicious JavaScript code is injected into the website.\n*   **Cross-Site Request Forgery (CSRF):**  Occurs when a malicious website tricks the user into performing an action on the legitimate website.\n*   **Authentication and Authorization Flaws:**  Occurs when authentication or authorization mechanisms are not properly implemented.\n*   **Denial of Service (DoS):** Occurs when an attacker floods the server with requests, making it unavailable to legitimate users.\n\n### 4.2 Input Validation\n\n*   **Validate All Input:** Validate all user input, including query parameters, request bodies, and headers.\n*   **Use Whitelisting:** Use whitelisting to allow only specific characters or values.  Avoid blacklisting, which can be easily bypassed.\n*   **Escape Output:**  Escape output to prevent XSS vulnerabilities.\n\n### 4.3 Authentication and Authorization\n\n*   **Use JWT (JSON Web Tokens):** Use JWT for authentication.  JWTs are a standard way to represent claims securely between two parties.\n*   **Implement Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Use Strong Passwords:** Enforce strong password policies, such as minimum length, complexity, and expiration.\n*   **Implement Two-Factor Authentication (2FA):** Implement 2FA for added security.\n*   **Rate Limiting:** Apply rate limits to prevent brute-force attacks.\n\n### 4.4 Data Protection\n\n*   **Encrypt Sensitive Data:**  Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **Store Passwords Securely:**  Store passwords securely using a one-way hash function like bcrypt or Argon2.\n*   **Regularly Back Up Data:**  Regularly back up data to prevent data loss.\n\n### 4.5 Secure API Communication\n\n*   **Use HTTPS:**  Always use HTTPS for API communication.\n*   **Validate SSL Certificates:** Validate SSL certificates to prevent man-in-the-middle attacks.\n*   **Use API Keys:**  Use API keys to identify and authenticate clients.\n*   **Implement CORS:** Implement Cross-Origin Resource Sharing (CORS) to control which domains can access the API.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components in isolation.\n*   **Mock Dependencies:**  Use mocking to isolate the component being tested from its dependencies.\n*   **Test Edge Cases:**  Test edge cases and boundary conditions.\n*   **Use Assertions:** Use assertions to verify that the code behaves as expected.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Components:** Integration tests should focus on testing the interactions between components.\n*   **Use a Test Database:** Use a test database for integration tests.\n*   **Test the API Endpoints:** Test the API endpoints to ensure that they return the correct data.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Application:**  End-to-end tests should focus on testing the entire application, including the front-end and back-end.\n*   **Use a Testing Framework:** Use a testing framework like Selenium or Cypress to automate end-to-end tests.\n\n### 5.4 Test Organization\n\n*   **Separate Test Files:**  Create separate test files for each module or component.\n*   **Use Descriptive Test Names:** Use descriptive test names to indicate what is being tested.\n*   **Organize Tests by Feature:** Organize tests by feature to make it easier to find and run tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking Libraries:** Use mocking libraries like `unittest.mock` or `pytest-mock` to create mock objects.\n*   **Stub External Dependencies:**  Stub external dependencies to isolate the component being tested.\n*   **Verify Interactions:** Verify that the component being tested interacts with its dependencies as expected.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect HTTP Method:** Using the wrong HTTP method for an operation (e.g., using GET to create a resource).\n*   **Missing Content-Type Header:**  Failing to set the `Content-Type` header in the request.\n*   **Incorrect JSON Format:** Sending or receiving invalid JSON data.\n*   **Ignoring the `request` Object:** Not properly handling the request object.\n*   **Failing to Handle Errors:** Not gracefully handling exceptions and returning meaningful error messages.\n*   **Not Protecting Against CSRF:** Not implementing CSRF protection.\n\n### 6.2 Edge Cases\n\n*   **Empty Data:**  Handling cases where the database returns empty data.\n*   **Invalid Input:** Handling cases where the user provides invalid input.\n*   **Network Errors:** Handling network errors and timeouts.\n*   **Concurrent Requests:** Handling concurrent requests and race conditions.\n\n### 6.3 Version-Specific Issues\n\n*   **Compatibility with Flask and Other Libraries:** Ensuring compatibility between flask-restful and other libraries.\n*   **Deprecated Features:** Being aware of deprecated features and migrating to the new ones.\n\n### 6.4 Compatibility Concerns\n\n*   **Python Versions:**  Ensuring compatibility with different Python versions.\n*   **Database Drivers:**  Ensuring compatibility with different database drivers.\n*   **Operating Systems:** Ensuring compatibility with different operating systems.\n\n### 6.5 Debugging Strategies\n\n*   **Use Logging:** Use logging to track the flow of execution and identify errors.\n*   **Use a Debugger:** Use a debugger to step through the code and inspect variables.\n*   **Read Error Messages Carefully:**  Pay attention to error messages and stack traces.\n*   **Use Postman or curl:** Use Postman or curl to test API endpoints.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Virtual Environment:** Use a virtual environment (e.g., `venv`, `pipenv`, `conda`) to isolate project dependencies.\n*   **IDE:** Use an Integrated Development Environment (IDE) like VS Code, PyCharm, or Sublime Text.\n*   **REST Client:** Use a REST client like Postman or Insomnia to test API endpoints.\n*   **Database Client:** Use a database client like DBeaver or pgAdmin to manage databases.\n\n### 7.2 Build Configuration\n\n*   **Use a Build System:** Use a build system like Make or Fabric to automate build tasks.\n*   **Specify Dependencies:** Specify all project dependencies in a `requirements.txt` file or Pipfile.\n*   **Use a Configuration File:** Use a configuration file to store configuration values.\n\n### 7.3 Linting and Formatting\n\n*   **Use a Linter:** Use a linter like pylint or flake8 to enforce code style guidelines.\n*   **Use a Formatter:** Use a formatter like black or autopep8 to automatically format the code.\n\n### 7.4 Deployment\n\n*   **Use a WSGI Server:** Use a WSGI server like Gunicorn or uWSGI to deploy the application.\n*   **Use a Reverse Proxy:** Use a reverse proxy like Nginx or Apache to handle incoming requests and route them to the WSGI server.\n*   **Use a Load Balancer:** Use a load balancer to distribute traffic across multiple servers.\n*   **Use a Process Manager:** Use a process manager like Systemd or Supervisor to manage the WSGI server process.\n\n### 7.5 CI/CD Integration\n\n*   **Use a CI/CD Tool:** Use a CI/CD tool like Jenkins, GitLab CI, or CircleCI to automate the build, test, and deployment process.\n*   **Run Tests Automatically:** Run unit tests and integration tests automatically on every commit.\n*   **Deploy Automatically:** Deploy the application automatically after the tests pass.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "flask-restful.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "flask",
      "restful",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "developing",
      "apis",
      "using",
      "flask-restful",
      "python",
      "backend",
      "web",
      "rest",
      "api",
      "cursor-rule",
      "mdc",
      "microframework",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "flask-restful",
        "flask",
        "python",
        "backend",
        "web",
        "rest",
        "api",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-flask",
    "description": "This rule provides comprehensive best practices for developing Flask applications, covering code structure, security, performance, and testing.",
    "author": "sanjeed5",
    "tags": [
      "flask",
      "python",
      "backend",
      "web",
      "cursor",
      "cursor-rule",
      "mdc",
      "microframework",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/flask.mdc",
    "content": "- ## Code Organization and Structure:\n  - **Directory Structure Best Practices:**\n    - Follow a modular and organized project structure. A common structure is:\n      \n      project_root/\n      ├── app/\n      │   ├── __init__.py\n      │   ├── models.py\n      │   ├── views.py  # Or controllers.py\n      │   ├── forms.py\n      │   ├── utils.py # Helper functions\n      │   ├── api/\n      │   │   ├── __init__.py\n      │   │   ├── routes.py\n      │   ├── templates/\n      │   │   └── ...\n      │   ├── static/\n      │   │   └── ...\n      ├── tests/\n      │   ├── __init__.py\n      │   ├── conftest.py # Fixtures for tests\n      │   ├── test_models.py\n      │   ├── test_views.py\n      ├── migrations/\n      │   └── ... # Alembic migrations\n      ├── venv/ # Virtual environment\n      ├── .env    # Environment variables (use with caution, not for sensitive data in production)\n      ├── config.py # Application configuration\n      ├── requirements.txt or pyproject.toml # Dependencies\n      ├── run.py      # Application entry point\n      \n    - Use Blueprints to organize routes and views into logical modules. Blueprints promote reusability and maintainability.\n  - **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - Examples: `models.py`, `views.py`, `forms.py`, `utils.py`, `routes.py`, `test_*.py`.\n    - Maintain consistency throughout the project.\n  - **Module Organization:**\n    - Group related functionality into modules. For instance, database models in `models.py`, user authentication logic in `auth.py`, and utility functions in `utils.py`.\n    - Use `__init__.py` files to make directories packages, allowing you to import modules within the directory using relative paths.\n  - **Component Architecture:**\n    - Design components with clear responsibilities and interfaces.\n    - Consider using a layered architecture (e.g., presentation, business logic, data access) to separate concerns.\n    - Use dependency injection to decouple components.\n  - **Code Splitting Strategies:**\n    - Decompose large modules into smaller, more manageable files.\n    - Extract reusable code into separate modules or packages.\n    - Employ lazy loading for modules that are not immediately needed.\n\n- ## Common Patterns and Anti-patterns:\n  - **Design Patterns Specific to Flask:**\n    - **Application Factory:** Use the application factory pattern to create Flask application instances. This allows for different configurations for different environments (development, testing, production).\n      python\n      def create_app(config_name):\n          app = Flask(__name__)\n          app.config.from_object(config[config_name])\n          config[config_name].init_app(app)\n\n          # Initialize extensions (e.g., db, mail) here\n          db.init_app(app)\n          mail.init_app(app)\n\n          # Register blueprints\n          from .main import main as main_blueprint\n          app.register_blueprint(main_blueprint)\n\n          return app\n      \n    - **Blueprints:** Organize application functionality into reusable blueprints.\n      python\n      from flask import Blueprint\n\n      bp = Blueprint('my_blueprint', __name__, url_prefix='/my_blueprint')\n\n      @bp.route('/route')\n      def my_route():\n          return 'Hello from my_blueprint'\n      \n  - **Recommended Approaches for Common Tasks:**\n    - **Database Interactions:** Use Flask-SQLAlchemy or another ORM for database interactions. Define models to represent database tables.\n    - **Form Handling:** Use Flask-WTF for form handling. This provides CSRF protection and simplifies form validation.\n    - **Authentication:** Use Flask-Login for user authentication. It provides utilities for managing user sessions and protecting routes.\n    - **API Development:** Use Flask-RESTful or Flask-API for building RESTful APIs. Consider using Marshmallow for serializing and deserializing data.\n  - **Anti-patterns and Code Smells to Avoid:**\n    - **Global State:** Avoid using global variables to store application state. Use the `g` object or session variables instead.\n    - **Tight Coupling:** Design components with loose coupling to improve maintainability and testability.\n    - **Fat Models/Views:** Keep models and views focused on their primary responsibilities. Move complex business logic to separate modules.\n    - **Hardcoding Configuration:** Avoid hardcoding configuration values. Use environment variables or a configuration file.\n  - **State Management Best Practices:**\n    - Use the Flask `session` object to store user-specific data across requests.\n    - For application-wide state, consider using a database or a caching mechanism.\n    - Avoid storing sensitive data in the session without proper encryption.\n  - **Error Handling Patterns:**\n    - Use `try...except` blocks to handle exceptions gracefully.\n    - Implement custom error handlers for specific exceptions. Return appropriate HTTP status codes and error messages.\n    - Use logging to record errors and warnings.\n    - Use Flask's `abort()` function to raise HTTP exceptions.\n\n- ## Performance Considerations:\n  - **Optimization Techniques:**\n    - **Caching:** Implement caching to reduce database queries and improve response times. Use Flask-Caching or Redis.\n    - **Database Optimization:** Optimize database queries and use indexes to improve performance.\n    - **Profiling:** Use a profiler to identify performance bottlenecks in your code.\n  - **Memory Management:**\n    - Avoid memory leaks by properly closing database connections and releasing resources.\n    - Use generators to process large datasets efficiently.\n  - **Rendering Optimization:**\n    - Minimize the number of database queries in templates.\n    - Use template caching to reduce rendering time.\n  - **Bundle Size Optimization:**\n    - For larger front-end applications, use a bundler like Webpack or Parcel to optimize JavaScript and CSS files. Minify and compress assets.\n  - **Lazy Loading Strategies:**\n    - Implement lazy loading for images and other assets to improve initial page load time.\n    - Use code splitting to load only the necessary JavaScript code for each page.\n\n- ## Security Best Practices:\n  - **Common Vulnerabilities and How to Prevent Them:**\n    - **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input in templates. Use Jinja2's autoescaping feature.\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using Flask-WTF, which provides CSRF protection.\n    - **Authentication and Authorization Issues:** Implement secure authentication and authorization mechanisms. Use strong passwords and protect user credentials.\n  - **Input Validation:**\n    - Validate all user input to prevent malicious data from entering your application.\n    - Use Flask-WTF for form validation.\n  - **Authentication and Authorization Patterns:**\n    - Use Flask-Login for user authentication.\n    - Implement role-based access control (RBAC) to restrict access to certain resources.\n    - Use JWT (JSON Web Tokens) for API authentication.\n  - **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between the client and the server.\n    - Store passwords securely using a strong hashing algorithm (e.g., bcrypt).\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement authentication and authorization for API endpoints.\n    - Validate API requests and responses.\n    - Use rate limiting to prevent abuse.\n\n- ## Testing Approaches:\n  - **Unit Testing Strategies:**\n    - Write unit tests to verify the functionality of individual components.\n    - Use pytest or unittest for writing and running tests.\n    - Mock external dependencies to isolate components during testing.\n  - **Integration Testing:**\n    - Write integration tests to verify the interaction between different components.\n    - Test the integration between the application and the database.\n  - **End-to-End Testing:**\n    - Write end-to-end tests to simulate user interactions with the application.\n    - Use Selenium or Cypress for end-to-end testing.\n  - **Test Organization:**\n    - Organize tests into separate directories based on functionality.\n    - Use descriptive test names.\n    - Follow the Arrange-Act-Assert pattern in your tests.\n  - **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components during testing.\n    - Use the `unittest.mock` module or a third-party mocking library like `mock`.\n\n- ## Common Pitfalls and Gotchas:\n  - **Frequent Mistakes Developers Make:**\n    - **Not using a virtual environment:** Always use a virtual environment to isolate project dependencies.\n    - **Not handling exceptions properly:** Handle exceptions gracefully to prevent application crashes.\n    - **Exposing sensitive data:** Avoid exposing sensitive data in logs or error messages.\n  - **Edge Cases to Be Aware Of:**\n    - **Handling Unicode correctly:** Be aware of Unicode encoding issues when working with text data.\n    - **Dealing with time zones:** Use a consistent time zone throughout the application.\n  - **Version-Specific Issues:**\n    - Be aware of compatibility issues when upgrading Flask or its dependencies.\n    - Consult the Flask documentation for version-specific information.\n  - **Compatibility Concerns:**\n    - Ensure that your application is compatible with different browsers and operating systems.\n    - Test your application on different devices.\n  - **Debugging Strategies:**\n    - Use the Flask debugger to identify and fix errors.\n    - Use logging to record errors and warnings.\n    - Use a profiler to identify performance bottlenecks.\n\n- ## Tooling and Environment:\n  - **Recommended Development Tools:**\n    - **Virtual Environment Manager:** `virtualenv`, `venv`, or `conda`\n    - **Package Manager:** `pip` or `pipenv` or `poetry`\n    - **IDE/Text Editor:** VS Code, PyCharm, Sublime Text\n    - **Debugger:** `pdb` or `ipdb`\n    - **Profiler:** `cProfile`\n  - **Build Configuration:**\n    - Use a `requirements.txt` or `pyproject.toml` file to specify project dependencies.\n    - Use a build system like `setuptools` or `poetry` to package your application.\n  - **Linting and Formatting:**\n    - Use a linter like `flake8` or `pylint` to enforce code style guidelines.\n    - Use a formatter like `black` or `autopep8` to automatically format your code.\n  - **Deployment Best Practices:**\n    - Use a production-ready WSGI server like Gunicorn or uWSGI.\n    - Use a reverse proxy like Nginx or Apache to serve static files and handle SSL termination.\n    - Deploy your application to a cloud platform like AWS, Google Cloud, or Azure.\n  - **CI/CD Integration:**\n    - Use a CI/CD pipeline to automate testing, building, and deployment.\n    - Use tools like Jenkins, Travis CI, or GitHub Actions.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "flask.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "flask",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "covering",
      "python",
      "backend",
      "web",
      "cursor-rule",
      "mdc",
      "microframework",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "flask",
        "python",
        "backend",
        "web",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-flutter",
    "description": "Comprehensive guidelines and best practices for Flutter development, covering code organization, performance optimization, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "flutter",
      "cursor",
      "cursor-rule",
      "mdc",
      "dart",
      "mobile",
      "cross-platform",
      "ios",
      "android",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "mobile-development",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/flutter.mdc",
    "content": "- Adhere to the official Flutter style guide.  This forms the foundation for maintainable and consistent code.\n- Utilize the latest stable version of Flutter, keeping up-to-date with new features and security patches. Review Flutter's breaking changes and migration guides during updates.\n\n## 1. Code Organization and Structure\n\n- **1.1 Directory Structure Best Practices:**\n    - **`lib/` (Source Code):**\n        -  Use a feature-based structure, grouping related components into modules.\n        -  Example:\n           \n           lib/\n           ├── auth/\n           │   ├── models/\n           │   ├── providers/\n           │   ├── screens/\n           │   ├── services/\n           │   ├── widgets/\n           │   └── auth.dart\n           ├── home/\n           │   ├── models/\n           │   ├── screens/\n           │   ├── widgets/\n           │   └── home.dart\n           ├── common/\n           │   ├── models/\n           │   ├── widgets/\n           │   └── utils/\n           ├── core/\n           │   ├── services/\n           │   ├── theme/\n           │   └── utils/\n           ├── main.dart\n           └── app.dart\n           \n    - **`test/` (Tests):** Mirror the `lib/` structure for easy test discovery.\n    - **`android/`, `ios/`, `web/`, `macos/`, `windows/`, `linux/` (Platform-Specific Code):**  Contain platform-specific native code. Limit direct modification unless necessary; utilize Flutter's platform channels.\n    - **`assets/` (Assets):** Store images, fonts, and other static resources.  Organize subfolders by type (e.g., `images/`, `fonts/`, `data/`).  Use `pubspec.yaml` to declare assets.\n\n- **1.2 File Naming Conventions:**\n    -  Use `snake_case` for file names (e.g., `user_profile_screen.dart`).\n    -  For classes within a file, the file name typically reflects the main class it contains.  Example: `user_profile_screen.dart` containing `UserProfileScreen`.\n    -  Exceptions: Grouping multiple related enums, typedefs, or small helper functions into a single file is acceptable if it improves clarity.\n\n- **1.3 Module Organization:**\n    -  A module encapsulates a specific feature or functionality.  Modules should have well-defined interfaces and minimize dependencies on other modules.\n    -  Implement a layered architecture within each module (e.g., UI, business logic, data access).\n    -  Consider using packages for large, independent features to promote reusability across projects.\n\n- **1.4 Component Architecture:**\n    -  Favor a component-based architecture using Flutter widgets.  Break down complex UIs into smaller, reusable widgets.\n    -  Separate presentation logic from business logic.\n    -  Widgets should be pure functions of their input data (state).\n    -  Follow the principles of Single Responsibility Principle (SRP) for widget design.\n\n- **1.5 Code Splitting Strategies:**\n    -  **Deferred Loading:** Load features on demand to reduce initial app size.\n    -  **Route-Based Splitting:** Split code based on app routes.\n    -  **Feature-Based Splitting:** Split code based on features.\n    -  Use the `dart:ui` library's `loadFontFromList` or `ImageProvider.loadBuffer`  to load font or image resources dynamically.\n\n## 2. Common Patterns and Anti-patterns\n\n- **2.1 Design Patterns Specific to Flutter:**\n    -  **BLoC (Business Logic Component):** Separates business logic from the UI, making the code more testable and maintainable.\n    -  **Provider:** Simple dependency injection and state management solution.\n    -  **Riverpod:** An improved version of Provider with compile-time safety.\n    -  **GetX:** A microframework that provides state management, dependency injection, and route management.\n    -  **MVVM (Model-View-ViewModel):** Another pattern for separating concerns.  Often used with reactive programming.\n    -  **Redux/Flux:** For predictable state management, especially in complex applications.\n    -  **InheritedWidget:** Implicit dependency injection for theming and configuration.\n\n- **2.2 Recommended Approaches for Common Tasks:**\n    -  **State Management:** Choose a state management solution that fits the complexity of the app.\n    -  **Networking:** Use the `http` package or `dio` for making API requests.\n    -  **Asynchronous Operations:** Use `async/await` for handling asynchronous operations.\n    -  **Data Persistence:** Use `shared_preferences` for simple data storage or SQLite (using packages like `sqflite`) or NoSQL databases (using packages like `hive` or `isar`) for structured data.\n    -  **Navigation:** Use `go_router` or `auto_route` for type-safe navigation.\n    -  **Form Handling:** Use `Form` widget with `TextFormField` and validators.\n\n- **2.3 Anti-patterns and Code Smells to Avoid:**\n    -  **Massive Widgets:** Widgets with too much logic or UI code. Break them down into smaller, reusable components.\n    -  **Logic in Widgets:** Avoid putting business logic directly inside widgets.\n    -  **Deeply Nested Widgets:** Can lead to performance issues and difficult-to-read code.  Simplify the widget tree.\n    -  **Unmanaged State:** Forgetting to dispose of resources like `StreamSubscription` or `AnimationController` leading to memory leaks.\n    -  **Hardcoded Values:** Avoid hardcoding values like colors, sizes, and strings in the code. Use constants or theme data.\n    -  **Ignoring Errors:** Not handling exceptions properly can lead to unexpected crashes.  Use `try-catch` blocks and logging.\n\n- **2.4 State Management Best Practices:**\n    -  Choose a state management solution that fits the complexity of the app.\n    -  Keep the state as close to where it is needed as possible. Avoid global state for everything.\n    -  Use immutable data structures to prevent unexpected state changes.\n    -  Separate state from UI components to improve testability.\n    -  Manage side effects properly.\n    -  Consider reactive programming with streams for complex state transitions.\n\n- **2.5 Error Handling Patterns:**\n    -  Use `try-catch` blocks to handle exceptions.\n    -  Implement custom error classes for specific error scenarios.\n    -  Log errors to a file or remote service for debugging.\n    -  Show user-friendly error messages.\n    -  Use `ErrorWidget` to display custom error screens.\n    -  Handle asynchronous errors using `Future.catchError` or `Stream.handleError`.\n\n## 3. Performance Considerations\n\n- **3.1 Optimization Techniques:**\n    -  **Avoid Unnecessary Widget Rebuilds:** Use `const` constructors for immutable widgets, `shouldRebuild` method in `StatefulWidget`, and `ValueKey` for widgets that change position in a list.\n    -  **Minimize `setState` Calls:** Use state management solutions to optimize state updates.\n    -  **Use `ListView.builder` or `GridView.builder`:**  For large lists or grids, build widgets lazily.\n    -  **Use `RepaintBoundary`:**  Isolate parts of the UI that don't need to be repainted often.\n    -  **Use `Opacity` and `Clip` Sparingly:**  These operations can be expensive.\n    -  **Use `Transform` carefully:** transforms can break batching and cause additional draw calls.\n\n- **3.2 Memory Management:**\n    -  Dispose of resources like `StreamSubscription`, `AnimationController`, and `TextEditingController` in the `dispose` method.\n    -  Avoid creating unnecessary objects.\n    -  Use the `dart:developer` package's memory profiling tools to identify memory leaks.\n    -  Minimize the use of global variables and static fields.\n\n- **3.3 Rendering Optimization:**\n    -  Use the Flutter Performance Overlay to identify performance bottlenecks.\n    -  Reduce the complexity of the widget tree.\n    -  Optimize image loading and caching.\n    -  Avoid using custom paint operations unless necessary.\n\n- **3.4 Bundle Size Optimization:**\n    -  Use `flutter build apk --split-per-abi` or `flutter build appbundle` to split the APK/AAB by ABI (Application Binary Interface).\n    -  Remove unused assets and code.\n    -  Compress images.\n    -  Use code obfuscation and minification.\n    -  Use deferred loading for infrequently used features.\n\n- **3.5 Lazy Loading Strategies:**\n    -  **Image Lazy Loading:** Load images only when they are visible on the screen.\n    -  **Data Lazy Loading:** Load data in chunks as the user scrolls.\n    -  Use the `VisibilityDetector` package to detect when a widget becomes visible.\n    -  Use pagination or infinite scrolling for large datasets.\n\n## 4. Security Best Practices\n\n- **4.1 Common Vulnerabilities and How to Prevent Them:**\n    -  **Data Injection:** Sanitize user input to prevent SQL injection, XSS, and other injection attacks.\n    -  **Sensitive Data Storage:** Avoid storing sensitive data in plain text. Use encryption and secure storage mechanisms.\n    -  **Insecure API Communication:** Use HTTPS for all API communication.\n    -  **Code Tampering:** Use code obfuscation to make it harder to reverse engineer the app.\n    -  **Man-in-the-Middle Attacks:** Implement certificate pinning to prevent MITM attacks.\n\n- **4.2 Input Validation:**\n    -  Validate all user input on both the client and server sides.\n    -  Use regular expressions or custom validation logic to enforce data constraints.\n    -  Encode data properly before displaying it in the UI.\n\n- **4.3 Authentication and Authorization Patterns:**\n    -  Use secure authentication protocols like OAuth 2.0 or OpenID Connect.\n    -  Implement multi-factor authentication (MFA) for added security.\n    -  Use role-based access control (RBAC) to restrict access to sensitive data and functionality.\n    -  Store authentication tokens securely.\n\n- **4.4 Data Protection Strategies:**\n    -  Encrypt sensitive data at rest and in transit.\n    -  Use secure storage mechanisms like the Keychain (iOS) or Keystore (Android).\n    -  Follow the principle of least privilege when granting access to data.\n\n- **4.5 Secure API Communication:**\n    -  Use HTTPS for all API communication.\n    -  Implement proper authentication and authorization.\n    -  Validate API responses.\n    -  Rate limit API requests to prevent abuse.\n\n## 5. Testing Approaches\n\n- **5.1 Unit Testing Strategies:**\n    -  Test individual functions, classes, and widgets in isolation.\n    -  Use mock objects to isolate the code under test from its dependencies.\n    -  Write tests for all critical business logic.\n\n- **5.2 Integration Testing:**\n    -  Test the interaction between different parts of the app.\n    -  Test the integration with external services like APIs and databases.\n\n- **5.3 End-to-End Testing:**\n    -  Test the entire app from start to finish.\n    -  Simulate user interactions to ensure that the app works as expected.\n\n- **5.4 Test Organization:**\n    -  Create a `test/` directory that mirrors the `lib/` directory structure.\n    -  Use descriptive test names.\n    -  Keep tests small and focused.\n\n- **5.5 Mocking and Stubbing:**\n    -  Use mocking frameworks like `mockito` to create mock objects.\n    -  Use stubbing to replace external dependencies with predefined values.\n    -  Avoid over-mocking, as it can make tests less effective.\n\n## 6. Common Pitfalls and Gotchas\n\n- **6.1 Frequent Mistakes Developers Make:**\n    -  Not disposing of resources.\n    -  Ignoring errors.\n    -  Hardcoding values.\n    -  Using `setState` excessively.\n    -  Creating massive widgets.\n    -  Not validating user input.\n    -  Over-complicating the state management.\n\n- **6.2 Edge Cases to Be Aware Of:**\n    -  Network connectivity issues.\n    -  Device orientation changes.\n    -  Background app state.\n    -  Low memory conditions.\n    -  Localization and internationalization.\n\n- **6.3 Version-Specific Issues:**\n    -  Be aware of breaking changes in new Flutter releases.\n    -  Test the app on different Flutter versions to ensure compatibility.\n    -  Use version constraints in `pubspec.yaml` to specify the required Flutter version.\n\n- **6.4 Compatibility Concerns:**\n    -  Test the app on different devices and operating systems.\n    -  Consider accessibility for users with disabilities.\n    -  Follow platform-specific guidelines for UI and functionality.\n\n- **6.5 Debugging Strategies:**\n    -  Use the Flutter DevTools for debugging and profiling.\n    -  Use logging to track down errors.\n    -  Use breakpoints to step through the code.\n    -  Use the Flutter Inspector to inspect the widget tree.\n\n## 7. Tooling and Environment\n\n- **7.1 Recommended Development Tools:**\n    -  Visual Studio Code or Android Studio.\n    -  Flutter DevTools.\n    -  Android Emulator or iOS Simulator.\n    -  Git for version control.\n\n- **7.2 Build Configuration:**\n    -  Use `flutter build` to build the app for different platforms.\n    -  Configure build settings in `pubspec.yaml`.\n    -  Use different build configurations for development, staging, and production.\n\n- **7.3 Linting and Formatting:**\n    -  Use `flutter_lints` package for linting.\n    -  Use `dart format` or Prettier for code formatting.\n    -  Configure the IDE to automatically format the code on save.\n\n- **7.4 Deployment Best Practices:**\n    -  Follow the deployment guidelines for each platform.\n    -  Use code signing to ensure the authenticity of the app.\n    -  Use version control to manage releases.\n    -  Monitor the app for crashes and errors after deployment.\n\n- **7.5 CI/CD Integration:**\n    -  Use a CI/CD tool like GitHub Actions, GitLab CI, or Jenkins to automate the build, test, and deployment process.\n    -  Configure the CI/CD pipeline to run linting, formatting, and testing.\n    -  Automate the release process to the app stores.\n\nThis document provides comprehensive guidelines and best practices for Flutter development.  Following these guidelines will help you write maintainable, performant, and secure Flutter apps.",
    "metadata": {
      "globs": "*.dart",
      "format": "mdc",
      "originalFile": "flutter.mdc"
    },
    "subcategory": "flutter",
    "keywords": [
      "cursor",
      "flutter",
      "comprehensive",
      "guidelines",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "organization",
      "performance",
      "cursor-rule",
      "mdc",
      "dart",
      "mobile",
      "cross-platform",
      "ios",
      "android",
      "mobile-development"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "flutter",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "mobile-development"
    }
  },
  {
    "name": "cursor-fontawesome",
    "description": "This rule file provides comprehensive guidelines for using Font Awesome effectively, covering setup, styling, accessibility, performance, and security best practices. It ensures consistent and optimized usage across projects.",
    "author": "sanjeed5",
    "tags": [
      "fontawesome",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/fontawesome.mdc",
    "content": "# Font Awesome Best Practices\n\nThis document outlines best practices for using Font Awesome in web development projects. These guidelines cover setup, styling, accessibility, performance, security, and common pitfalls.\n\n## 1. Setup and Usage\n\n*   **Font Awesome Kits (Recommended):**\n    *   Use Font Awesome Kits for easy customization and automatic updates.\n    *   Add the Kit's embed code ( `<script>` tag) to the `<head>` of your HTML document.\n    *   Example:\n        html\n        <script src=\"https://kit.fontawesome.com/<your_kit_code>.js\" crossorigin=\"anonymous\"></script>\n        \n*   **Package Manager (npm, yarn):**\n    *   Install Font Awesome as a dependency:\n        bash\n        npm install @fortawesome/fontawesome-free\n        # or\n        yarn add @fortawesome/fontawesome-free\n        \n    *   Import the necessary CSS or JavaScript files in your application.\n*   **CDN (Content Delivery Network):**\n    *   Use a CDN for quick setup, but be aware of potential performance implications and dependency on external services.\n    *   Include the CDN link in your HTML:\n        html\n        <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" integrity=\"...\" crossorigin=\"anonymous\" />\n        \n*   **Icon Usage:**\n    *   Use CSS classes to insert icons into your project.\n        html\n        <i class=\"fas fa-heart\"></i>  <!-- Solid heart icon -->\n        <i class=\"far fa-heart\"></i>  <!-- Regular heart icon -->\n        <i class=\"fab fa-github\"></i> <!-- GitHub icon -->\n        \n\n## 2. Code Organization and Structure\n\n*   **Directory Structure:**\n    *   Place Font Awesome CSS and font files in a dedicated directory (e.g., `assets/fontawesome`). This is less relevant when using kits or CDNs.\n*   **File Naming Conventions:**\n    *   Stick to the default file names provided by Font Awesome (e.g., `fontawesome.min.css`, `fontawesome.js`).\n*   **Module Organization:**\n    *   When using a package manager, import Font Awesome modules in your application's entry point or relevant components.\n    *   Example (JavaScript):\n        javascript\n        import '@fortawesome/fontawesome-free/css/all.min.css';\n        \n*   **Component Architecture:**\n    *   Create reusable icon components in your UI framework (e.g., React, Vue, Angular) to encapsulate Font Awesome usage and styling.\n    *   Example (React):\n        jsx\n        import React from 'react';\n\n        const Icon = ({ name, style }) => (\n          <i className={`fa${style ? 'b' : 's'} fa-${name}`}></i>\n        );\n\n        export default Icon;\n        \n*   **Code Splitting:**\n    *   When using a package manager, ensure your build tool (e.g., Webpack, Parcel) correctly bundles Font Awesome files and supports code splitting if needed.\n\n## 3. Styling and Accessibility\n\n*   **Styling:**\n    *   Use Font Awesome's styling options to customize icon size, color, and animations.\n    *   Use CSS classes for styling (e.g., `fa-xs`, `fa-sm`, `fa-lg`, `fa-2x`, `fa-spin`, `fa-pulse`).\n    *   Example:\n        html\n        <i class=\"fas fa-heart fa-2x\" style=\"color: red;\"></i>\n        \n*   **Accessibility (Crucial):**\n    *   **Decorative Icons:** Use `aria-hidden=\"true\"` for icons that are purely decorative.\n        html\n        <i class=\"fas fa-star\" aria-hidden=\"true\"></i>\n        \n    *   **Informative Icons:** Provide meaningful text alternatives for icons that convey information or are interactive.\n        *   Use `aria-label` for interactive elements (e.g., buttons, links).\n            html\n            <a href=\"/cart\" aria-label=\"View your shopping cart\">\n              <i class=\"fas fa-shopping-cart\" aria-hidden=\"true\"></i>\n            </a>\n            \n        *   Use visually hidden text (e.g., using CSS class `sr-only`) to provide a text alternative.\n            html\n            <span class=\"sr-only\">Search</span>\n            <i class=\"fas fa-search\" aria-hidden=\"true\"></i>\n            \n        *   Use the `title` attribute to provide a tooltip for sighted users (optional, but recommended).\n            html\n             <i class=\"fas fa-info-circle\" aria-hidden=\"true\" title=\"More information\"></i>\n             \n\n## 4. Performance Considerations\n\n*   **CDN Usage:**\n    *   Using a reputable CDN can improve performance through caching and optimized delivery. Ensure the CDN supports modern protocols like HTTP/2 or HTTP/3.\n*   **Self-Hosting:**\n    *   Self-hosting gives you more control over resources but requires proper server configuration and optimization.\n    *   Consider using a CDN in front of your origin server for better performance.\n*   **Web Fonts vs. SVG:**\n    *   Font Awesome offers both web fonts and SVG versions.\n    *   SVGs generally offer better performance and scalability but may require more setup.\n    *   Web fonts can cause rendering issues (e.g., FOIT - Flash of Invisible Text).  Consider using `font-display: swap;` in your CSS to mitigate this.\n*   **Subsetting (Pro Feature):**\n    *   Use Font Awesome's Pro subsetting feature to include only the icons you need, reducing the overall file size.\n*   **Lazy Loading:**\n    *   If you have a large number of icons on a page, consider lazy loading them to improve initial page load time. This can be complex and might require custom JavaScript.\n\n## 5. Common Patterns and Anti-Patterns\n\n*   **Pattern: Icon Component:** Creating a reusable icon component is a common and effective pattern.\n*   **Pattern: Consistent Styling:** Define a set of CSS classes or variables for consistent icon styling across your project.\n*   **Anti-Pattern: Overusing Icons:** Avoid using too many icons, as it can clutter the UI and reduce readability.\n*   **Anti-Pattern: Inconsistent Icon Usage:**  Ensure icons are used consistently throughout the application to maintain a cohesive user experience.\n*   **Anti-Pattern: Neglecting Accessibility:**  Failing to provide proper text alternatives for icons is a major accessibility issue.\n\n## 6. Security Best Practices\n\n*   **Vulnerability: Cross-Site Scripting (XSS):**\n    *   Prevent XSS by sanitizing any user-provided input used in conjunction with Font Awesome icons.\n    *   Never directly embed user input into CSS class names or HTML attributes.\n*   **Dependency Management:**\n    *   Keep Font Awesome dependencies up-to-date to patch security vulnerabilities.\n    *   Use a dependency management tool (e.g., npm, yarn) to manage and update dependencies securely.\n*   **Subresource Integrity (SRI):**\n    *   When using a CDN, use SRI hashes to verify the integrity of the Font Awesome files.\n        html\n        <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css\" integrity=\"sha512-...\" crossorigin=\"anonymous\" />\n        \n\n## 7. Testing Approaches\n\n*   **Unit Testing:**\n    *   If you create custom icon components, write unit tests to ensure they render correctly and handle different icon names and styles.\n*   **Integration Testing:**\n    *   Test the integration of Font Awesome icons within your application's UI to ensure they are displayed correctly in different browsers and devices.\n*   **End-to-End Testing:**\n    *   Use end-to-end tests to verify the overall user experience with Font Awesome icons, including accessibility and styling.\n\n## 8. Common Pitfalls and Gotchas\n\n*   **Version Conflicts:** Ensure all Font Awesome files are from the same version to avoid compatibility issues.\n*   **CSS Specificity:** Be aware of CSS specificity when styling Font Awesome icons, as it can override your custom styles.\n*   **Font Loading Issues:**  Address font loading issues (e.g., FOIT) by using `font-display: swap;`.\n*   **Incorrect Class Names:** Double-check icon class names for typos.\n*   **Missing Font Awesome Kit Code:** Ensure the Font Awesome Kit code is correctly added to your HTML.\n\n## 9. Tooling and Environment\n\n*   **Development Tools:**\n    *   Use a code editor with syntax highlighting and autocompletion for CSS and HTML.\n    *   Use browser developer tools to inspect and debug Font Awesome styles and rendering.\n*   **Build Configuration:**\n    *   Configure your build tool (e.g., Webpack, Parcel) to correctly handle Font Awesome files and optimize for production.\n*   **Linting and Formatting:**\n    *   Use a linter (e.g., ESLint, Stylelint) to enforce code style and best practices for Font Awesome usage.\n*   **CI/CD Integration:**\n    *   Integrate Font Awesome dependency updates and security checks into your CI/CD pipeline.",
    "metadata": {
      "globs": "*.html,*.css,*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "fontawesome.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "fontawesome",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "guidelines",
      "using",
      "font",
      "awesome",
      "effectively",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "fontawesome",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-gcp-cli",
    "description": "Provides guidelines for using gcp-cli, including best practices for scripting, configuration management, security, and performance. Focuses on automation, predictable output, and secure authentication within Google Cloud environments.",
    "author": "sanjeed5",
    "tags": [
      "gcp-cli",
      "go",
      "backend",
      "performance",
      "gcp",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/gcp-cli.mdc",
    "content": "- **Scripting Best Practices**:\n  - **Use the `--quiet` flag**: Suppress prompts for non-interactive script execution.\n  - **Leverage output formatting**: Employ `--format=json`, `--format=yaml`, `--format=csv`, or `--format=text` for predictable, parsable output.\n  - **Handle exit statuses**: Ensure scripts check exit codes for error handling. A non-zero exit status indicates an error.\n  - **Avoid relying on standard error messages**: These are subject to change and shouldn't be parsed for critical logic.\n\n- **Configuration Management**:\n  - **Utilize named configurations**: Create multiple configurations using `gcloud config configurations create` for managing different environments (development, staging, production) or projects.\n  - **Set properties**: Define the active account (`gcloud config set core/account`), default project (`gcloud config set core/project`), and default region/zone (`gcloud config set compute/region` and `gcloud config set compute/zone`) either globally or per-command.\n\n- **Authentication and Authorization**:\n  - **Service accounts for production**: Use service accounts with appropriate IAM roles for scripts running in production environments. Create and manage service accounts via the Google Cloud Console.\n  - **User accounts for interactive sessions**: Use user accounts for interactive sessions and local development.\n  - **Activate service accounts securely**: Use `gcloud auth activate-service-account --key-file [KEY_FILE]` to activate service accounts, ensuring the key file is securely managed.\n  - **Avoid storing service account keys in code**: Employ environment variables or secret management solutions to store and retrieve service account keys.\n  - **Impersonate Service Accounts (if applicable)**: If a user needs to act as a service account, use `gcloud config set auth/impersonate_service_account SERVICE_ACCT_EMAIL` after authenticating with `gcloud auth login`.\n\n- **Filtering and Formatting Output**:\n  - **Filter output**: Use the `--filter` flag to narrow down results based on specific criteria.\n  - **Format output**: Use the `--format` flag to control the output format (JSON, YAML, CSV, Text, List).\n  - **Utilize projections**: Combine `--format` with projections to extract specific fields from the output.\n  - **Example: List instances in a specific zone**: `gcloud compute instances list --filter=\"zone:us-central1-a\"`\n  - **Example: List projects in JSON format**: `gcloud projects list --format=\"json\" --filter=\"labels.env=test AND labels.version=alpha\"`\n\n- **Code Organization and Structure (Shell Scripts)**:\n  - **Modularize scripts**: Break down large scripts into smaller, reusable functions.\n  - **Use descriptive function names**: Improve readability and maintainability.\n  - **Implement argument parsing**: Use `getopts` for robust argument handling.\n  - **Add comments**: Explain the purpose and functionality of code blocks.\n  - **Use consistent indentation**: Improves readability.\n\n- **Code Organization and Structure (Terraform)**:\n  - **Follow the Terraform Standard Directory Structure**: Organize configurations into modules.\n  - **Use Modules**: Encapsulate reusable infrastructure components into modules.\n  - **Variables**: Use variables to parameterize your configurations.\n  - **Outputs**: Use outputs to expose important information about your infrastructure.\n  - **Remote State Management**: Store Terraform state remotely (e.g., in Google Cloud Storage) for collaboration and versioning. Secure the bucket with appropriate IAM permissions.\n\n- **Code Organization and Structure (Python)**:\n  - **Package your gcp-cli interaction code into reusable modules and classes.**\n  - **Follow PEP 8 Style Guide for Python Code**.\n  - **Use Virtual Environments** for dependency management.\n\n- **Common Patterns and Anti-patterns**:\n  - **Pattern**: Use `xargs` or `parallel` to execute gcloud commands in parallel for faster processing.\n  - **Anti-pattern**: Hardcoding credentials or sensitive information directly in scripts or configuration files. Use environment variables or secret management solutions instead.\n\n- **Performance Considerations**:\n  - **Use pagination**: When retrieving large datasets, use the `--page-size` flag to limit the number of results per page and iterate through the pages.\n  - **Minimize API calls**: Batch operations where possible to reduce the number of API requests.\n  - **Caching**: Cache API responses to avoid redundant requests. Implement caching mechanisms within your scripts or applications.\n\n- **Security Best Practices**:\n  - **Least Privilege**: Grant service accounts only the necessary IAM roles and permissions.\n  - **Regularly rotate service account keys**: Implement a key rotation policy to minimize the impact of compromised keys.\n  - **Use VPC Service Controls**: Restrict data exfiltration and unauthorized access to Google Cloud services.\n  - **Audit Logging**: Enable audit logging to track API calls and resource changes.\n  - **Input Validation**: Always validate user inputs and data received from external sources to prevent injection attacks.\n\n- **Testing Approaches**:\n  - **Unit tests**: Mock gcloud CLI calls to isolate and test individual components.\n  - **Integration tests**: Verify the interaction between different Google Cloud services and your gcp-cli scripts.\n  - **End-to-end tests**: Simulate real-world scenarios and validate the entire workflow.\n  - **Use `gcloud config configurations activate` in testing** to isolate test environments.\n\n- **Common Pitfalls and Gotchas**:\n  - **Default project settings**: Ensure the correct project is configured before running gcloud commands.\n  - **IAM propagation delays**: Be aware of potential delays when granting or revoking IAM permissions.\n  - **API throttling**: Handle API rate limits gracefully by implementing retry mechanisms with exponential backoff.\n  - **Version Compatibility**: Be aware of potential breaking changes when upgrading the gcloud CLI. Test your scripts after upgrades.\n\n- **Tooling and Environment**:\n  - **Use a dedicated development environment**: Isolate your development environment from production to avoid accidental changes.\n  - **Use a version control system**: Track changes to your gcp-cli scripts and configuration files.\n  - **Set up CI/CD pipelines**: Automate testing and deployment of your gcp-cli scripts.\n  - **Recommended tools**: Shellcheck (for shell script linting), Terraform Validate (for Terraform configuration validation), Pylint (for python code linting).\n\n- **Referenced Rules**:\n  - @file python_best_practices.mdc\n  - @file terraform_best_practices.mdc\n  - @file shell_script_best_practices.mdc",
    "metadata": {
      "globs": "*.sh,*.yaml,*.tf,*.py",
      "format": "mdc",
      "originalFile": "gcp-cli.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "gcp",
      "cli",
      "provides",
      "guidelines",
      "using",
      "including",
      "best",
      "practices",
      "scripting",
      "configuration",
      "management",
      "security",
      "gcp-cli",
      "go",
      "backend",
      "performance",
      "cloud",
      "infrastructure",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "gcp-cli",
        "go",
        "golang",
        "backend",
        "performance",
        "gcp",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-gcp",
    "description": "This rule provides best practices for developing and managing infrastructure and applications on Google Cloud Platform (GCP), encompassing code organization, security, performance, and deployment strategies.",
    "author": "sanjeed5",
    "tags": [
      "gcp",
      "go",
      "backend",
      "performance",
      "cloud",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/gcp.mdc",
    "content": "---\n## GCP Library Best Practices\n\nThis document outlines best practices for developing and managing applications and infrastructure on Google Cloud Platform (GCP). It covers various aspects, including code organization, common patterns, performance, security, testing, common pitfalls, and tooling.\n\n### 1. Code Organization and Structure\n\n-   **Follow a Standard Module Structure (especially for Terraform)**:\n    -   Start every module with a `main.tf` file. This file contains the primary resources defined in the module.\n    -   Include a `README.md` file for module documentation. This should explain the module's purpose, usage, inputs, and outputs.\n    -   Group related resources logically in separate files (e.g., `network.tf`, `compute.tf`, `storage.tf`).\n    -   Use folders to logically group files.\n-   **Directory Structure Best Practices:**\n    -   `modules/`: Contains reusable Terraform modules. Each module should encapsulate a specific set of resources or functionality.\n    -   `environments/`: Contains environment-specific configurations (e.g., `dev/`, `staging/`, `prod/`). Each environment directory should contain its own `terraform.tfvars` and `backend.tf` (or equivalent).\n    -   `scripts/`: Contains utility scripts (e.g., Python, Bash) for automation.\n    -   `docs/`: Contains documentation for the project.\n    -   `examples/`: Contains example configurations or usage scenarios.\n-   **File Naming Conventions:**\n    -   Use descriptive names for Terraform files (e.g., `vpc.tf`, `firewall.tf`, `iam.tf`).\n    -   Use underscores for resource names and avoid repeating resource types in names (e.g., `instance_web_server` instead of `web_server_instance`).\n    -   Use consistent naming conventions for variables and outputs.\n-   **Module Organization:**\n    -   Keep modules small and focused. Each module should have a single responsibility.\n    -   Use input variables to parameterize modules. This makes them reusable and configurable.\n    -   Define outputs for modules to expose important information. This allows other modules or configurations to consume the module's results.\n-   **Component Architecture (for application code):**\n    -   Adopt a layered architecture (e.g., presentation, business logic, data access).\n    -   Use dependency injection to decouple components and improve testability.\n    -   Design components for reusability and maintainability.\n    -   Use well-defined interfaces between components.\n-   **Code Splitting Strategies (especially for client-side code):**\n    -   Split code into logical chunks based on functionality or features.\n    -   Use lazy loading to load code only when it's needed. This can improve initial page load time.\n    -   Consider using code splitting tools like Webpack or Parcel.\n\n### 2. Common Patterns and Anti-patterns\n\n-   **Design Patterns Specific to GCP:**\n    -   **Service Facade:** Abstract complex GCP service interactions behind a simple interface.\n    -   **Pub/Sub Fanout:** Use Cloud Pub/Sub to distribute messages to multiple subscribers for parallel processing.\n    -   **Cloud Functions Chaining:** Chain Cloud Functions together to create complex workflows.\n    -   **Idempotent Operations:** Ensure operations can be safely retried without unintended side effects, especially crucial in distributed systems like GCP.\n-   **Recommended Approaches for Common Tasks:**\n    -   **Configuration Management:** Use environment variables or Cloud KMS for storing sensitive configuration data.\n    -   **Secret Management:** Use Cloud Secret Manager to securely store and manage secrets.\n    -   **Data Storage:** Choose the appropriate storage solution based on the data type and access patterns (e.g., Cloud Storage for objects, Cloud SQL for relational data, Cloud Datastore for NoSQL data).\n    -   **Logging:** Use Cloud Logging for centralized logging and monitoring.\n    -   **Monitoring:** Utilize Cloud Monitoring and Cloud Trace for performance monitoring and troubleshooting.\n    -   **Identity and Access Management (IAM):**  Adopt the principle of least privilege. Grant users and service accounts only the necessary permissions.\n-   **Anti-patterns and Code Smells to Avoid:**\n    -   **Hardcoding Credentials:** Never hardcode credentials in code or configuration files. Use environment variables, secret management, or IAM roles.\n    -   **Overly Complex IAM Roles:** Avoid creating overly complex IAM roles with too many permissions. This can lead to security vulnerabilities.\n    -   **Ignoring Error Handling:** Always handle errors gracefully and provide informative error messages.\n    -   **Long-Running Processes in Cloud Functions:**  Cloud Functions have time limits. Offload long-running processes to other services like Cloud Run or Compute Engine.\n    -   **Lack of Monitoring:** Failing to monitor your application can lead to undetected performance issues and errors.\n    -   **Ignoring Security Updates:**  Regularly update your dependencies and software to address security vulnerabilities.\n-   **State Management Best Practices:**\n    -   **Use Terraform State:** Store Terraform state remotely in Cloud Storage for collaboration and version control.\n    -   **Stateless Applications:** Design applications to be stateless whenever possible. If state is required, store it in a persistent storage solution like Cloud SQL or Cloud Datastore.\n    -   **Avoid Local Storage:** Do not rely on local storage for persistent data. Use Cloud Storage or other persistent storage solutions.\n-   **Error Handling Patterns:**\n    -   **Centralized Error Handling:** Implement a centralized error handling mechanism to handle exceptions consistently.\n    -   **Logging and Monitoring:** Log all errors to Cloud Logging and set up alerts for critical errors in Cloud Monitoring.\n    -   **Retry Mechanisms:** Implement retry mechanisms for transient errors.\n    -   **Circuit Breaker Pattern:** Use the circuit breaker pattern to prevent cascading failures in distributed systems.\n\n### 3. Performance Considerations\n\n-   **Optimization Techniques:**\n    -   **Caching:** Implement caching at various levels (e.g., browser, CDN, server-side) to reduce latency and improve performance. Consider using Cloud CDN or Memorystore.\n    -   **Load Balancing:** Use Cloud Load Balancing to distribute traffic across multiple instances for high availability and scalability.\n    -   **Database Optimization:** Optimize database queries and indexing to improve performance. Consider using Cloud SQL Insights for query analysis.\n    -   **Asynchronous Operations:** Use asynchronous operations for long-running tasks to prevent blocking the main thread.\n-   **Memory Management (for application code):**\n    -   **Efficient Data Structures:** Choose appropriate data structures to minimize memory usage.\n    -   **Garbage Collection:** Understand how garbage collection works in your chosen language and optimize code to minimize memory leaks.\n    -   **Resource Pooling:** Use resource pooling to reuse expensive resources like database connections.\n-   **Rendering Optimization (for web applications):**\n    -   **Minimize DOM Manipulation:** Minimize DOM manipulation to improve rendering performance.\n    -   **Use Virtual DOM:** Use a virtual DOM library like React or Vue.js to optimize rendering updates.\n    -   **Optimize Images:** Optimize images for web use by compressing them and using appropriate formats (e.g., WebP).\n-   **Bundle Size Optimization (for web applications):**\n    -   **Code Splitting:** Split code into smaller chunks to reduce initial bundle size.\n    -   **Tree Shaking:** Use tree shaking to remove unused code from the bundle.\n    -   **Minification:** Minify code to reduce bundle size.\n-   **Lazy Loading Strategies (for web applications):**\n    -   **Lazy Load Images:** Lazy load images that are not initially visible on the page.\n    -   **Lazy Load Modules:** Lazy load modules that are not immediately required.\n    -   **Intersection Observer:** Use the Intersection Observer API to detect when elements are visible in the viewport.\n\n### 4. Security Best Practices\n\n-   **Common Vulnerabilities and How to Prevent Them:**\n    -   **SQL Injection:** Prevent SQL injection by using parameterized queries or object-relational mappers (ORMs).\n    -   **Cross-Site Scripting (XSS):** Prevent XSS by sanitizing user inputs and encoding outputs.\n    -   **Cross-Site Request Forgery (CSRF):** Prevent CSRF by using anti-CSRF tokens.\n    -   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms to protect sensitive data.\n-   **Input Validation:**\n    -   **Validate All Inputs:** Validate all user inputs on both the client-side and server-side.\n    -   **Use Regular Expressions:** Use regular expressions to validate input formats.\n    -   **Sanitize Inputs:** Sanitize inputs to remove potentially malicious characters.\n-   **Authentication and Authorization Patterns:**\n    -   **Identity-Aware Proxy (IAP):** Use IAP to control access to applications running on Compute Engine, GKE, and App Engine.\n    -   **Firebase Authentication:** Use Firebase Authentication to easily implement authentication in web and mobile applications.\n    -   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n    -   **Service Accounts:** Use service accounts to authenticate applications running on GCP.\n-   **Data Protection Strategies:**\n    -   **Encryption at Rest:** Encrypt data at rest using Cloud KMS or Cloud Storage encryption.\n    -   **Encryption in Transit:** Encrypt data in transit using HTTPS (TLS).\n    -   **Data Loss Prevention (DLP):** Use Cloud DLP to prevent sensitive data from being leaked.\n-   **Secure API Communication:**\n    -   **HTTPS:** Always use HTTPS for API communication.\n    -   **API Keys:** Use API keys to authenticate API clients.\n    -   **JWTs:** Use JWTs for secure API authorization.\n    -   **Rate Limiting:** Implement rate limiting to prevent abuse.\n\n### 5. Testing Approaches\n\n-   **Unit Testing Strategies:**\n    -   **Test Individual Units:** Test individual units of code (e.g., functions, classes) in isolation.\n    -   **Use Mocking:** Use mocking to isolate units of code from dependencies.\n    -   **Test Edge Cases:** Test edge cases and boundary conditions.\n-   **Integration Testing:**\n    -   **Test Interactions:** Test the interactions between different units of code or components.\n    -   **Test Database Interactions:** Test interactions with databases and other external systems.\n    -   **Use Test Databases:** Use test databases to avoid affecting production data.\n-   **End-to-End Testing:**\n    -   **Test Complete Workflows:** Test complete workflows from start to finish.\n    -   **Simulate User Interactions:** Simulate user interactions to ensure the application behaves as expected.\n    -   **Use Automated Testing Tools:** Use automated testing tools to automate end-to-end tests.\n-   **Test Organization:**\n    -   **Organize Tests by Component:** Organize tests by component or module.\n    -   **Use a Consistent Naming Convention:** Use a consistent naming convention for test files and test cases.\n    -   **Keep Tests Separate from Code:** Keep tests separate from production code.\n-   **Mocking and Stubbing:**\n    -   **Use Mocking Libraries:** Use mocking libraries to create mock objects and stubs.\n    -   **Mock External Dependencies:** Mock external dependencies like APIs and databases.\n    -   **Stub Responses:** Stub responses from external services to control test behavior.\n\n### 6. Common Pitfalls and Gotchas\n\n-   **Frequent Mistakes Developers Make:**\n    -   **Incorrect IAM Permissions:** Assigning overly broad IAM permissions.\n    -   **Misconfiguring Network Settings:** Misconfiguring firewall rules or VPC settings.\n    -   **Ignoring Cost Optimization:** Failing to optimize resource usage and costs.\n    -   **Not Using Managed Services:**  Trying to manage infrastructure manually instead of using GCP managed services.\n    -   **Lack of Automation:** Not automating deployments and infrastructure management.\n-   **Edge Cases to be Aware of:**\n    -   **Network Latency:** Account for network latency in distributed systems.\n    -   **Concurrency Issues:** Handle concurrency issues correctly in multi-threaded applications.\n    -   **Data Consistency:** Ensure data consistency across distributed systems.\n-   **Version-Specific Issues:**\n    -   **API Compatibility:** Be aware of API compatibility issues when upgrading GCP SDKs or services.\n    -   **Deprecated Features:** Avoid using deprecated features.\n-   **Compatibility Concerns:**\n    -   **Cross-Browser Compatibility:** Ensure web applications are compatible with different browsers.\n    -   **Mobile Compatibility:** Ensure web applications are responsive and compatible with mobile devices.\n-   **Debugging Strategies:**\n    -   **Use Cloud Debugger:** Use Cloud Debugger to debug applications running on GCP.\n    -   **Use Logging:** Use Cloud Logging to log debug information.\n    -   **Use Monitoring:** Use Cloud Monitoring to monitor application performance and identify issues.\n    -   **Local Debugging:** Debug applications locally before deploying them to GCP.\n\n### 7. Tooling and Environment\n\n-   **Recommended Development Tools:**\n    -   **Google Cloud SDK (gcloud):** Command-line tool for interacting with GCP services.\n    -   **Terraform:** Infrastructure as code tool for managing GCP resources.\n    -   **IDE with GCP Support:** Use an IDE with GCP support (e.g., VS Code with the Google Cloud Code extension).\n    -   **Docker:** Containerization platform for building and deploying applications.\n-   **Build Configuration:**\n    -   **Use Build Automation Tools:** Use build automation tools like Maven, Gradle, or npm.\n    -   **Define Build Steps:** Define clear build steps for compiling, testing, and packaging applications.\n    -   **Manage Dependencies:** Manage dependencies using dependency management tools like Maven, Gradle, or npm.\n-   **Linting and Formatting:**\n    -   **Use Linters:** Use linters to enforce code style and identify potential issues.\n    -   **Use Formatters:** Use formatters to automatically format code.\n    -   **Configure Linters and Formatters:** Configure linters and formatters to match project coding standards.\n-   **Deployment Best Practices:**\n    -   **Automate Deployments:** Automate deployments using CI/CD pipelines.\n    -   **Use Infrastructure as Code:** Use infrastructure as code (e.g., Terraform) to manage infrastructure.\n    -   **Blue/Green Deployments:** Use blue/green deployments to minimize downtime.\n    -   **Canary Deployments:** Use canary deployments to gradually roll out new features.\n    -   **Rollback Strategy:** Have a rollback strategy in place to revert to a previous version if necessary.\n-   **CI/CD Integration:**\n    -   **Use Cloud Build:** Use Cloud Build for CI/CD pipelines on GCP.\n    -   **Integrate with Version Control:** Integrate CI/CD pipelines with version control systems (e.g., GitHub, GitLab, Cloud Source Repositories).\n    -   **Automate Testing:** Automate testing as part of the CI/CD pipeline.\n    -   **Automate Deployments:** Automate deployments as part of the CI/CD pipeline.\n\nBy following these best practices, developers can build robust, secure, and scalable applications and infrastructure on Google Cloud Platform.",
    "metadata": {
      "globs": "*.tf,*.py,*.js,*.go,*.java,*.proto,*.sh,*.yaml,*.yml",
      "format": "mdc",
      "originalFile": "gcp.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "gcp",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "developing",
      "managing",
      "infrastructure",
      "applications",
      "google",
      "go",
      "backend",
      "performance",
      "cloud",
      "cursor-rule",
      "mdc"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "gcp",
        "go",
        "golang",
        "backend",
        "performance",
        "cloud",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-gensim",
    "description": "This rule provides coding standards and best practices for using the gensim library, focusing on NLP, topic modeling, performance, and code organization. It offers actionable guidelines for developers to create effective and maintainable gensim-based applications.",
    "author": "sanjeed5",
    "tags": [
      "gensim",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/gensim.mdc",
    "content": "# gensim Library Best Practices and Coding Standards\n\nThis document outlines the best practices for coding standards when working with the gensim library for Natural Language Processing (NLP) and topic modeling in Python. Following these guidelines will lead to more maintainable, efficient, and robust code.\n\n## Library Information:\n- Name: gensim\n- Tags: python, nlp, topic-modeling\n\n## 1. Code Organization and Structure:\n\n### 1.1 Directory Structure Best Practices:\n\nAdopt a clear and structured directory organization for your gensim projects. A well-defined structure enhances code readability and maintainability.\n\n\nmy_gensim_project/\n├── data/                   # Raw and processed datasets\n│   ├── raw/              # Original datasets (read-only)\n│   └── processed/        # Processed data (e.g., corpus, dictionary)\n├── models/                 # Trained gensim models\n│   ├── lda/              # LDA models\n│   └── lsi/              # LSI models\n├── scripts/                # Scripts for data processing, model training, etc.\n│   ├── preprocess.py     # Data preprocessing script\n│   ├── train_model.py    # Model training script\n│   └── evaluate.py       # Model evaluation script\n├── utils/                  # Utility functions and modules\n│   ├── helpers.py        # Helper functions for common tasks\n│   └── visualization.py # Visualization functions\n├── notebooks/              # Jupyter notebooks for exploration and experimentation\n│   ├── exploration.ipynb\n│   └── analysis.ipynb\n├── tests/                  # Unit and integration tests\n│   ├── test_preprocess.py\n│   ├── test_train_model.py\n│   └── conftest.py       # pytest configuration file (optional)\n├── README.md               # Project documentation\n├── requirements.txt        # Project dependencies\n└── .gitignore              # Git ignore file\n\n\n### 1.2 File Naming Conventions:\n\nUse descriptive and consistent file names.  This makes it easier to understand the purpose of each file.\n\n- Use lowercase letters and underscores for Python files (e.g., `preprocess.py`, `train_model.py`).\n- Use descriptive names that clearly indicate the file's purpose (e.g., `lda_model.pkl`, `corpus.mm`).\n- For data files, include the data source or processing stage in the name (e.g., `raw_data.txt`, `processed_corpus.txt`).\n- Use a consistent naming scheme for test files (e.g., `test_module.py` for testing `module.py`).\n\n### 1.3 Module Organization:\n\nOrganize your code into logical modules. Each module should handle a specific aspect of your NLP pipeline (e.g., data loading, preprocessing, model training).\n\n- Create separate modules for data loading, preprocessing, model training, evaluation, and visualization.\n- Keep modules focused and avoid large, monolithic files.\n- Use clear and descriptive names for modules and functions.\n- Consider using packages to group related modules.\n\n### 1.4 Component Architecture Recommendations:\n\nDesign your gensim applications with a component-based architecture. This promotes code reusability and maintainability.\n\n- Break down your application into smaller, independent components, such as:\n  - `DataLoader`: Loads and preprocesses data.\n  - `CorpusBuilder`: Creates a corpus from the preprocessed data.\n  - `ModelTrainer`: Trains a gensim model on the corpus.\n  - `ModelEvaluator`: Evaluates the trained model.\n  - `Visualizer`: Visualizes the model results.\n- Each component should have a clear interface and well-defined responsibilities.\n- Use dependency injection to manage dependencies between components.\n\n### 1.5 Code Splitting Strategies:\n\nSplit large files into smaller, manageable chunks. This improves code readability and reduces the likelihood of merge conflicts.\n\n- Break down large functions into smaller, more focused helper functions.\n- Split large modules into smaller, more focused submodules.\n- Use appropriate abstraction techniques (e.g., classes, interfaces) to encapsulate related functionality.\n- Consider using decorators or context managers to handle common tasks, such as logging or error handling.\n\n## 2. Common Patterns and Anti-patterns:\n\n### 2.1 Design Patterns:\n\n- **Factory Pattern:** Use factory patterns to create different types of gensim models or data transformations based on configuration.\n- **Strategy Pattern:** Employ strategy patterns to switch between different preprocessing techniques or similarity measures at runtime.\n- **Observer Pattern:** Implement observer patterns to react to model training events, such as logging progress or saving intermediate results.\n- **Pipeline Pattern:**  Structure your NLP workflow as a pipeline, applying a sequence of transformations to your data.\n\n### 2.2 Recommended Approaches for Common Tasks:\n\n- **Text Preprocessing:** Use `gensim.utils.simple_preprocess` for basic text preprocessing, including tokenization and lowercasing. For more advanced preprocessing, integrate with NLTK or spaCy.\n- **Creating a Dictionary:**  Use `gensim.corpora.Dictionary` to create a dictionary from your tokenized documents.  Filter out infrequent and extremely frequent words using `filter_extremes()` to improve model quality and performance.\n- **Creating a Corpus:**  Use `dictionary.doc2bow` to convert your documents into a bag-of-words corpus.  For large corpora, use `gensim.corpora.MmCorpus` to store the corpus on disk.\n- **Training a Topic Model:** Use `gensim.models.LdaModel` or `gensim.models.LsiModel` to train a topic model on your corpus. Tune the model parameters (e.g., number of topics, alpha, beta) to optimize topic coherence.\n- **Evaluating a Topic Model:**  Use `gensim.models.CoherenceModel` to evaluate the coherence of your topic model.  Visualize the model topics using `pyLDAvis` or other visualization tools.\n\n### 2.3 Anti-patterns and Code Smells:\n\n- **Global Variables:** Avoid using global variables for gensim models, corpora, or dictionaries. Pass these objects as arguments to functions or classes.\n- **Hardcoded Paths:** Avoid hardcoding file paths in your code. Use configuration files or environment variables to manage file paths.\n- **Lack of Error Handling:**  Implement proper error handling to gracefully handle unexpected exceptions. Log errors and provide informative error messages to the user.\n- **Ignoring Warnings:**  Pay attention to warnings generated by gensim. These warnings often indicate potential problems with your code or data.\n- **Overly Complex Functions:** Avoid writing overly complex functions that perform too many tasks. Break down large functions into smaller, more focused helper functions.\n\n### 2.4 State Management:\n\n- Encapsulate state within classes.\n- Use immutable data structures where possible.\n- Avoid modifying shared state directly.\n- Consider using a state management library for complex applications.\n\n### 2.5 Error Handling:\n\n- Use try-except blocks to catch exceptions.\n- Log exceptions with traceback information.\n- Provide informative error messages to the user.\n- Consider using custom exception classes for gensim-specific errors.\n\n## 3. Performance Considerations:\n\n### 3.1 Optimization Techniques:\n\n- **Use `MmCorpus` for large corpora:**  Store your corpus on disk using `gensim.corpora.MmCorpus` to reduce memory consumption.\n- **Use `LdaMulticore` for parallel training:**  Train LDA models in parallel using `gensim.models.LdaMulticore` to speed up training time.\n- **Optimize preprocessing:**  Use efficient string processing techniques and avoid unnecessary computations during preprocessing.\n- **Filter extreme values:** Use the `filter_extremes()` function to remove words that are too frequent or infrequent, which can improve the performance of the model\n- **Batch Processing:**  Process large datasets in batches to reduce memory consumption.\n- **Vectorization:**  Use NumPy's vectorized operations to speed up numerical computations.\n- **Caching:**  Cache intermediate results to avoid redundant computations.\n\n### 3.2 Memory Management:\n\n- **Use generators for large datasets:**  Load and process data using generators to avoid loading the entire dataset into memory at once.\n- **Delete unused objects:**  Explicitly delete unused objects using `del` to release memory.\n- **Use memory profiling tools:**  Use memory profiling tools to identify memory leaks and optimize memory usage.\n- **Limit vocabulary size:** Reduce the vocabulary size by filtering out infrequent words.\n\n### 3.3 Rendering Optimization (If Applicable):\n\n- N/A - gensim is primarily a backend library and does not directly involve rendering.\n\n### 3.4 Bundle Size Optimization:\n\n- N/A - gensim is primarily a backend library.\n\n### 3.5 Lazy Loading:\n\n- Load gensim models and data only when they are needed. This can reduce the initial startup time of your application.\n- Use lazy initialization for expensive operations.\n\n## 4. Security Best Practices:\n\n### 4.1 Common Vulnerabilities:\n\n- **Arbitrary Code Execution:**  Avoid loading untrusted gensim models from external sources, as this could lead to arbitrary code execution.\n- **Denial of Service:**  Protect against denial-of-service attacks by limiting the size of input data and the complexity of model training.\n- **Data Injection:**  Sanitize input data to prevent data injection attacks, such as SQL injection or cross-site scripting (XSS).\n\n### 4.2 Input Validation:\n\n- Validate all input data to ensure that it conforms to the expected format and range. This can prevent errors and security vulnerabilities.\n- Use regular expressions or other validation techniques to check the validity of input strings.\n- Check the size of input data to prevent denial-of-service attacks.\n\n### 4.3 Authentication and Authorization:\n\n- N/A - gensim itself does not provide authentication or authorization mechanisms. These mechanisms should be implemented at the application level.\n\n### 4.4 Data Protection:\n\n- Encrypt sensitive data at rest and in transit.\n- Use secure communication protocols (e.g., HTTPS) to protect data in transit.\n- Implement access control policies to restrict access to sensitive data.\n- Anonymize or pseudonymize data to protect user privacy.\n\n### 4.5 Secure API Communication:\n\n- N/A - gensim itself does not provide APIs for communication with other services. Secure API communication should be implemented at the application level.\n\n## 5. Testing Approaches:\n\n### 5.1 Unit Testing:\n\n- Write unit tests for individual functions and classes. This ensures that each component of your code works as expected.\n- Use a testing framework like `pytest` or `unittest` to write and run your unit tests.\n- Mock external dependencies to isolate the code under test.\n- Cover all branches of your code with unit tests.\n\n### 5.2 Integration Testing:\n\n- Write integration tests to verify that different components of your application work together correctly.\n- Test the interaction between your gensim code and other libraries or services.\n- Use realistic test data to simulate real-world scenarios.\n\n### 5.3 End-to-End Testing:\n\n- Write end-to-end tests to verify that your entire application works as expected.\n- Test the application from the user's perspective.\n- Automate your end-to-end tests to ensure that they are run regularly.\n\n### 5.4 Test Organization:\n\n- Organize your tests into a logical directory structure that mirrors your code structure.\n- Use descriptive names for your test files and test functions.\n- Group related tests into test classes.\n\n### 5.5 Mocking and Stubbing:\n\n- Use mocking and stubbing techniques to isolate the code under test.\n- Mock external dependencies to avoid relying on external services or data.\n- Use stubs to provide predefined responses to function calls.\n\n## 6. Common Pitfalls and Gotchas:\n\n### 6.1 Frequent Mistakes:\n\n- **Incorrect Data Types:** Ensure that you are using the correct data types for gensim functions and classes. For example, gensim expects input documents to be a list of tokens, not a string.\n- **Incorrect Model Parameters:**  Tune the model parameters (e.g., number of topics, alpha, beta) to optimize topic coherence. Incorrect model parameters can lead to poor results.\n- **Ignoring Preprocessing Steps:** Proper preprocessing is critical to the success of topic modelling. Always preprocess your data before training a gensim model.\n- **Forgetting to Save/Load Models:** Trained models should be saved to disk using `model.save` and loaded using `gensim.models.LdaModel.load` or equivalent methods for other models.\n\n### 6.2 Edge Cases:\n\n- **Empty Documents:** Handle empty documents gracefully. Empty documents can cause errors during corpus creation or model training.\n- **Documents with Only Stop Words:**  Remove stop words from your documents to improve model quality. However, be aware that removing all stop words from a document can result in an empty document.\n- **Very Short Documents:**  Very short documents may not contain enough information to be effectively modeled.\n\n### 6.3 Version-Specific Issues:\n\n- Be aware of compatibility issues between different versions of gensim. Refer to the gensim documentation for information on version-specific changes.\n- Use a virtual environment to manage dependencies and avoid version conflicts.\n\n### 6.4 Compatibility Concerns:\n\n- Ensure that your version of gensim is compatible with other libraries you are using, such as NumPy, SciPy, and scikit-learn.\n- Use a virtual environment to manage dependencies and avoid version conflicts.\n\n### 6.5 Debugging Strategies:\n\n- Use a debugger to step through your code and inspect variables.\n- Print intermediate results to verify that your code is working as expected.\n- Use logging to track the execution of your code and identify potential problems.\n- Read the gensim documentation and search for solutions online.\n\n## 7. Tooling and Environment:\n\n### 7.1 Recommended Development Tools:\n\n- **Python:** Use Python 3.7 or later.\n- **Virtual Environment:** Use a virtual environment to manage dependencies and avoid version conflicts.\n- **IDE:** Use an IDE such as VS Code, PyCharm, or Jupyter Notebook.\n- **Testing Framework:** Use a testing framework such as `pytest` or `unittest`.\n- **Memory Profiler:** Use a memory profiler such as `memory_profiler` to identify memory leaks and optimize memory usage.\n\n### 7.2 Build Configuration:\n\n- Use a `requirements.txt` file to specify project dependencies.\n- Use a `setup.py` file to define your project metadata and package your code for distribution.\n- Use a build tool such as `Make` or `tox` to automate the build process.\n\n### 7.3 Linting and Formatting:\n\n- Use a linter such as `flake8` or `pylint` to enforce coding standards.\n- Use a formatter such as `black` or `autopep8` to automatically format your code.\n- Configure your IDE to automatically run the linter and formatter on save.\n\n### 7.4 Deployment:\n\n- Use a containerization tool such as Docker to package your application and its dependencies into a portable container.\n- Use a deployment platform such as AWS, Google Cloud, or Azure to deploy your application to the cloud.\n- Use a process manager such as `systemd` or `supervisor` to manage your application's processes.\n\n### 7.5 CI/CD Integration:\n\n- Use a continuous integration/continuous deployment (CI/CD) tool such as Jenkins, Travis CI, or CircleCI to automate the build, test, and deployment process.\n- Configure your CI/CD pipeline to run your linters, formatters, and tests on every commit.\n- Configure your CI/CD pipeline to automatically deploy your application to the cloud when tests pass.\n\nBy adhering to these best practices, you can significantly improve the quality, maintainability, and performance of your gensim projects.  Always consult the official gensim documentation for the most up-to-date information and guidance.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "gensim.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "gensim",
      "this",
      "rule",
      "provides",
      "coding",
      "standards",
      "best",
      "practices",
      "using",
      "library",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "gensim",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-git",
    "description": "This rule outlines best practices for effective use of Git, including code organization, commit strategies, branching models, and collaborative workflows.",
    "author": "sanjeed5",
    "tags": [
      "git",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/git.mdc",
    "content": "- **Commit Strategies:**\n  - **Atomic Commits:** Keep commits small and focused. Each commit should address a single, logical change. This makes it easier to understand the history and revert changes if needed.\n  - **Descriptive Commit Messages:** Write clear, concise, and informative commit messages. Explain the *why* behind the change, not just *what* was changed. Use a consistent format (e.g., imperative mood: \"Fix bug\", \"Add feature\").\n  - **Commit Frequently:** Commit early and often. This helps avoid losing work and makes it easier to track progress.\n  - **Avoid Committing Broken Code:** Ensure your code compiles and passes basic tests before committing.\n  - **Sign Your Commits (Optional but Recommended):** Use GPG signing to verify the authenticity of your commits.\n\n- **Branching Model:**\n  - **Use Feature Branches:** Create branches for each new feature or bug fix. This isolates changes and allows for easier code review.\n  - **Gitflow or Similar:** Consider adopting a branching model like Gitflow for managing releases, hotfixes, and feature development.\n  - **Short-Lived Branches:** Keep branches short-lived. The longer a branch exists, the harder it becomes to merge.\n  - **Regularly Rebase or Merge:** Keep your feature branches up-to-date with the main branch (e.g., `main`, `develop`) by rebasing or merging regularly.\n  - **Avoid Direct Commits to Main Branch:**  Protect your main branch from direct commits.  Use pull requests for all changes.\n\n- **Code Organization:**\n  - **Consistent Formatting:**  Use a consistent coding style guide (e.g., PEP 8 for Python, Google Style Guide for other languages) and enforce it with linters and formatters (e.g., `flake8`, `pylint`, `prettier`).\n  - **Modular Code:** Break down your codebase into smaller, manageable modules or components. This improves readability, maintainability, and testability.\n  - **Well-Defined Interfaces:**  Define clear interfaces between modules and components to promote loose coupling.\n  - **Avoid Global State:** Minimize the use of global variables and state to reduce complexity and potential conflicts.\n  - **Documentation:** Document your code with comments and docstrings. Explain the purpose of functions, classes, and modules.\n\n- **Collaboration and Code Review:**\n  - **Pull Requests:** Use pull requests for all code changes. This provides an opportunity for code review and discussion.\n  - **Code Review Checklist:** Create a code review checklist to ensure consistency and thoroughness.\n  - **Constructive Feedback:** Provide constructive feedback during code reviews. Focus on improving the code, not criticizing the author.\n  - **Address Feedback:** Respond to and address feedback from code reviews promptly.\n  - **Pair Programming:** Consider pair programming for complex or critical tasks.\n\n- **Ignoring Files and Directories:**\n  - **.gitignore:** Use a `.gitignore` file to exclude files and directories that should not be tracked by Git (e.g., build artifacts, temporary files, secrets).\n  - **Global .gitignore:** Configure a global `.gitignore` file to exclude files that you never want to track in any Git repository.\n\n- **Handling Secrets and Sensitive Information:**\n  - **Never Commit Secrets:** Never commit secrets, passwords, API keys, or other sensitive information to your Git repository.\n  - **Environment Variables:** Store secrets in environment variables and access them at runtime.\n  - **Secret Management Tools:** Use secret management tools like HashiCorp Vault or AWS Secrets Manager to store and manage secrets securely.\n  - **git-secret or similar:** If secrets must exist in the repo (strongly discouraged), encrypt them.\n\n- **Submodules and Subtrees:**\n  - **Use Sparingly:** Use Git submodules and subtrees sparingly, as they can add complexity.\n  - **Understand the Implications:** Understand the implications of using submodules and subtrees before adopting them.\n  - **Consider Alternatives:** Consider alternatives to submodules and subtrees, such as package managers or build systems.\n\n- **Large File Storage (LFS):**\n  - **Use for Large Files:** Use Git LFS for storing large files (e.g., images, videos, audio files).  This prevents your repository from becoming bloated.\n  - **Configure LFS:** Configure Git LFS properly to track the large files in your repository.\n\n- **Reverting and Resetting:**\n  - **Understand the Differences:** Understand the differences between `git revert`, `git reset`, and `git checkout` before using them.\n  - **Use with Caution:** Use `git reset` and `git checkout` with caution, as they can potentially lose data.\n  - **Revert Public Commits:** Use `git revert` to undo changes that have already been pushed to a public repository. This creates a new commit that reverses the changes.\n\n- **Tagging Releases:**\n  - **Create Tags:** Create tags to mark significant releases or milestones.\n  - **Semantic Versioning:** Follow semantic versioning (SemVer) when tagging releases.\n  - **Annotated Tags:** Use annotated tags to provide additional information about the release.\n\n- **Dealing with Merge Conflicts:**\n  - **Understand the Conflict:** Understand the source of the merge conflict before attempting to resolve it.\n  - **Communicate with Others:** Communicate with other developers who may be affected by the conflict.\n  - **Use a Merge Tool:** Use a merge tool to help resolve the conflict.\n  - **Test After Resolving:** Test your code thoroughly after resolving the conflict.\n\n- **Repository Maintenance:**\n  - **Regularly Clean Up:** Regularly clean up your Git repository by removing unused branches and tags.\n  - **Optimize the Repository:** Optimize the repository with `git gc` to improve performance.\n\n- **CI/CD Integration:**\n  - **Automate Testing:** Integrate Git with a CI/CD system to automate testing and deployment.\n  - **Run Tests on Every Commit:** Run tests on every commit to ensure code quality.\n\n- **Common Pitfalls and Gotchas:**\n  - **Accidental Commits:** Accidentally committing sensitive information or large files.\n  - **Merge Conflicts:** Difficulty resolving merge conflicts.\n  - **Losing Work:** Losing work due to incorrect use of `git reset` or `git checkout`.\n  - **Ignoring .gitignore:** Forgetting to add files to `.gitignore`.\n\n- **Tooling and Environment:**\n  - **Git Clients:** Use a Git client that suits your needs (e.g., command line, GUI).\n  - **IDE Integration:** Use Git integration in your IDE to streamline workflows.\n  - **Online Repositories:** Use a reliable online Git repository hosting service (e.g., GitHub, GitLab, Bitbucket).",
    "metadata": {
      "globs": "**/.git/*",
      "format": "mdc",
      "originalFile": "git.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "git",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "effective",
      "including",
      "code",
      "organization",
      "commit",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "git",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-github-actions",
    "description": "This rule provides comprehensive guidelines for GitHub Actions development, covering best practices, coding standards, performance, security, and testing.  It aims to ensure efficient, reliable, secure, and maintainable workflows.",
    "author": "sanjeed5",
    "tags": [
      "github-actions",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/github-actions.mdc",
    "content": "# GitHub Actions Best Practices and Coding Standards\n\nThis guide provides comprehensive guidelines for developing efficient, reliable, secure, and maintainable GitHub Actions workflows. It covers various aspects of GitHub Actions development, including code organization, common patterns, performance considerations, security best practices, testing approaches, and tooling.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n-   **Workflows Directory:**  Store all workflow files in the `.github/workflows` directory. This is the standard location recognized by GitHub.\n-   **Reusable Actions Directory (Optional):** If you create custom reusable actions, consider storing them in a dedicated directory like `actions/` within your repository.\n-   **Scripts Directory (Optional):** For complex workflows, you might have supporting scripts (e.g., shell scripts, Python scripts). Store these in a `scripts/` directory.\n-   **Example Directory Structure:**\n\n    \n    .github/\n    └── workflows/\n        ├── main.yml\n        ├── deploy.yml\n        └── release.yml\n    actions/\n        ├── my-custom-action/\n        │   ├── action.yml\n        │   └── index.js\n    scripts/\n        ├── cleanup.sh\n        └── build.py\n    \n\n### 1.2 File Naming Conventions\n\n-   **Workflow Files:** Use descriptive and consistent names for workflow files (e.g., `deploy-staging.yml`, `code-analysis.yml`). Avoid generic names like `main.yml` if possible, especially in repositories with multiple workflows.\n-   **Action Files:**  Name action files `action.yml` or `action.yaml` to clearly indicate their purpose.\n-   **Script Files:**  Use appropriate extensions for scripts (e.g., `.sh` for shell scripts, `.py` for Python scripts).\n\n### 1.3 Module Organization\n\n-   **Reusable Workflows:** Break down complex workflows into smaller, reusable workflows using the `uses:` syntax. This promotes modularity, reduces duplication, and improves maintainability.\n-   **Composite Actions:**  For reusable steps within a workflow, consider creating composite actions.  These group multiple steps into a single action.\n-   **Modular Scripts:** If you're using scripts, organize them into modules or functions for better readability and reusability.\n\n### 1.4 Component Architecture\n\n-   **Workflow as a Component:** Treat each workflow as a self-contained component responsible for a specific task (e.g., building, testing, deploying).\n-   **Separation of Concerns:**  Separate concerns within a workflow. For example, use different jobs for building, testing, and deploying.\n-   **Inputs and Outputs:**  Define clear inputs and outputs for reusable workflows and composite actions to improve their composability.\n\n### 1.5 Code Splitting Strategies\n\n-   **Job Splitting:**  Divide a workflow into multiple jobs that run in parallel to reduce overall execution time.\n-   **Step Splitting:** Break down long-running steps into smaller, more manageable steps.\n-   **Conditional Execution:** Use `if:` conditions to conditionally execute jobs or steps based on specific criteria (e.g., branch name, file changes).\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to GitHub Actions\n\n-   **Fan-out/Fan-in:** Use matrix builds to parallelize testing across different environments, then aggregate the results in a subsequent job.\n-   **Workflow Orchestration:** Use reusable workflows to orchestrate complex processes involving multiple steps and dependencies.\n-   **Event-Driven Workflows:** Trigger workflows based on specific GitHub events (e.g., push, pull request, issue creation) to automate tasks.\n-   **Policy Enforcement:** Implement workflows that enforce coding standards, security policies, or other organizational guidelines.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Dependency Caching:** Use the `actions/cache` action to cache dependencies (e.g., npm packages, Maven artifacts) to speed up subsequent workflow runs.\n-   **Secret Management:** Store sensitive information (e.g., API keys, passwords) as GitHub Secrets and access them in your workflows using the `${{ secrets.SECRET_NAME }}` syntax.  Never hardcode secrets in your workflow files.\n-   **Artifact Storage:** Use the `actions/upload-artifact` and `actions/download-artifact` actions to store and retrieve build artifacts (e.g., compiled binaries, test reports).\n-   **Environment Variables:** Use environment variables to configure workflows and steps.  Set environment variables at the workflow, job, or step level.\n-   **Workflow Status Badges:** Add workflow status badges to your repository's README file to provide a visual indication of the workflow's health.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Hardcoding Secrets:**  Never hardcode secrets directly in your workflow files. Use GitHub Secrets instead.\n-   **Ignoring Errors:**  Don't ignore errors or warnings in your workflows.  Implement proper error handling to ensure workflows fail gracefully.\n-   **Overly Complex Workflows:** Avoid creating overly complex workflows that are difficult to understand and maintain.  Break them down into smaller, reusable workflows.\n-   **Lack of Testing:**  Don't skip testing your workflows. Implement unit tests, integration tests, and end-to-end tests to ensure they function correctly.\n-   **Unnecessary Dependencies:** Avoid including unnecessary dependencies in your workflows. This can increase build times and introduce security vulnerabilities.\n-   **Directly Modifying `GITHUB_PATH` or `GITHUB_ENV`:** While these environment variables exist, using the recommended step outputs is preferred for cleaner, more robust interaction with other steps.\n\n### 2.4 State Management Best Practices\n\n-   **Artifacts:**  Use artifacts for persisting files between jobs. Upload at the end of one job, download at the start of another.\n-   **Environment Variables:** Define environment variables at the workflow or job level to pass configuration settings between steps.\n-   **Outputs:**  Use step outputs to pass data between steps within a job.\n-   **GitHub API:** Use the GitHub API to store and retrieve data related to your workflows (e.g., workflow run status, deployment information).\n-   **External Databases:** For more complex state management requirements, consider using an external database.\n\n### 2.5 Error Handling Patterns\n\n-   **`if: always()`:** Ensures a step runs even if a previous step failed, useful for cleanup or notification tasks. `if: always()` should be used with caution, as it can mask underlying issues.\n-   **`continue-on-error: true`:** Allows a job to continue even if a step fails. This is useful for non-critical steps or when you want to collect information about multiple failures before failing the workflow.\n-   **`try...catch...finally` (within Scripts):**  Use `try...catch...finally` blocks in your scripts to handle exceptions and ensure proper cleanup.\n-   **Notifications:**  Send notifications (e.g., email, Slack) when workflows fail or succeed to keep stakeholders informed.\n-   **Workflow Retries:**  Consider using the `retry:` keyword to automatically retry failed jobs.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Caching:**  Use the `actions/cache` action aggressively to cache dependencies and intermediate build artifacts.\n-   **Concurrency:** Use concurrency to prevent multiple workflows from running at the same time. \n-   **Parallel Execution:**  Run jobs in parallel to reduce overall execution time.\n-   **Optimized Images:** Optimize images before uploading them to your repository to reduce their size.\n-   **Minify Code:** Minify JavaScript and CSS files to reduce their size.\n\n### 3.2 Memory Management\n\n-   **Resource Limits:**  Be aware of the resource limits imposed by GitHub Actions runners.  Monitor memory and CPU usage to prevent workflows from exceeding these limits.\n-   **Garbage Collection:**  Ensure that your scripts and actions properly manage memory and avoid memory leaks.\n-   **Large Datasets:** If you're processing large datasets, consider using streaming techniques or splitting the data into smaller chunks.\n\n### 3.3 Rendering Optimization\n\n- N/A - Not typically relevant for GitHub Actions workflows themselves, but may be applicable to applications built and deployed by workflows.\n\n### 3.4 Bundle Size Optimization\n\n- N/A - Not typically relevant for GitHub Actions workflows themselves, but may be applicable to applications built and deployed by workflows.\n\n### 3.5 Lazy Loading Strategies\n\n- N/A - Not typically relevant for GitHub Actions workflows themselves, but may be applicable to applications built and deployed by workflows.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **Code Injection:** Prevent code injection by validating all inputs and sanitizing data before using it in scripts or commands.\n-   **Secret Exposure:**  Avoid exposing secrets in logs or error messages.  Mask secrets using the `::add-mask::` command.\n-   **Third-Party Actions:**  Carefully vet third-party actions before using them in your workflows.  Pin actions to specific versions or commits to prevent unexpected changes.\n-   **Privilege Escalation:**  Run workflows with the least privileges necessary to perform their tasks.\n-   **Workflow Command Injection:** Be cautious when dynamically constructing commands.  If possible, use parameters or environment variables instead of concatenating strings.\n\n### 4.2 Input Validation\n\n-   **Validate Inputs:** Validate all inputs to your workflows and actions to prevent malicious data from being processed.\n-   **Data Sanitization:** Sanitize data before using it in scripts or commands to prevent code injection vulnerabilities.\n-   **Regular Expressions:** Use regular expressions to validate the format of inputs.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **GitHub Tokens:** Use GitHub tokens to authenticate with the GitHub API.  Grant tokens the minimum necessary permissions.\n-   **Service Accounts:** Use service accounts to authenticate with external services.  Store service account credentials as GitHub Secrets.\n-   **Role-Based Access Control (RBAC):** Implement RBAC to control access to your workflows and actions.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption:** Encrypt sensitive data at rest and in transit.\n-   **Data Masking:** Mask sensitive data in logs and error messages.\n-   **Data Retention:**  Establish a data retention policy to ensure that sensitive data is not stored indefinitely.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS:** Use HTTPS for all API communication.\n-   **TLS:** Use TLS encryption to protect data in transit.\n-   **API Keys:** Protect API keys and other credentials. Store them as GitHub Secrets and use them securely in your workflows.\n-   **Rate Limiting:** Implement rate limiting to prevent abuse of your APIs.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test Reusable Actions:** Unit test your custom reusable actions to ensure they function correctly.\n-   **Test Scripts:** Unit test your scripts to ensure they handle different inputs and edge cases correctly.\n-   **Mock Dependencies:** Use mocking to isolate units of code and test them in isolation.\n\n### 5.2 Integration Testing\n\n-   **Test Workflow Integration:** Integrate test your workflows to ensure that all components work together correctly.\n-   **Test API Integrations:** Test your integrations with external APIs to ensure they function correctly.\n-   **Test Database Integrations:** Test your integrations with databases to ensure data is read and written correctly.\n\n### 5.3 End-to-end Testing\n\n-   **Full Workflow Tests:** Run end-to-end tests to verify that your workflows function correctly from start to finish.\n-   **Simulate Real-World Scenarios:** Simulate real-world scenarios to ensure that your workflows can handle different situations.\n\n### 5.4 Test Organization\n\n-   **Dedicated Test Directory:**  Create a dedicated `tests/` directory for your tests.\n-   **Test Naming Conventions:**  Follow consistent naming conventions for your test files and functions.\n-   **Test Suites:** Organize your tests into test suites based on functionality or component.\n\n### 5.5 Mocking and Stubbing\n\n-   **Mock External Services:** Mock external services to isolate your tests from external dependencies.\n-   **Stub Functions:** Stub functions to control the behavior of dependencies during testing.\n-   **Mock GitHub API:** Mock the GitHub API to test your workflows without making real API calls.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Incorrect Syntax:** YAML syntax can be tricky. Use a linter or validator to catch syntax errors.\n-   **Incorrect Indentation:** Indentation is crucial in YAML. Use consistent indentation throughout your workflow files.\n-   **Missing Permissions:**  Grant workflows the necessary permissions to access resources (e.g., repository contents, secrets).\n-   **Typos in Secrets:** Double-check the names of your secrets to avoid typos.\n-   **Not Pinning Action Versions:**  Always pin actions to specific versions or commits to prevent unexpected changes.\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **Rate Limits:** Be aware of GitHub API rate limits. Implement retry logic to handle rate limit errors.\n-   **Concurrent Workflow Runs:** Handle concurrent workflow runs gracefully to avoid conflicts.\n-   **Network Issues:** Implement error handling to handle network issues and transient errors.\n-   **Large File Sizes:** Be aware of the maximum file sizes supported by GitHub Actions.\n\n### 6.3 Version-Specific Issues\n\n-   **Action Compatibility:** Ensure that your actions are compatible with the version of GitHub Actions you are using.\n-   **Runner Images:** Be aware of the changes in runner images and update your workflows accordingly.\n\n### 6.4 Compatibility Concerns\n\n-   **Cross-Platform Compatibility:** Ensure that your workflows are compatible with different operating systems (e.g., Linux, Windows, macOS).\n-   **Browser Compatibility:** If your workflows involve web applications, test them in different browsers.\n\n### 6.5 Debugging Strategies\n\n-   **Workflow Logs:** Examine workflow logs to identify errors and warnings.\n-   **Debugging Actions:** Use debugging actions to inspect the state of your workflows.\n-   **Step-by-Step Debugging:**  Insert `echo` statements or debugging actions to trace the execution of your workflows step by step.\n-   **Local Testing:** Use tools like `act` to test your workflows locally before pushing them to GitHub.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **VS Code with GitHub Actions Extension:**  Use VS Code with the GitHub Actions extension for syntax highlighting, code completion, and validation.\n-   **GitHub CLI:** Use the GitHub CLI to interact with the GitHub API from your workflows.\n-   **`act`:** Use `act` to test your workflows locally.\n-   **YAML Linter:** Use a YAML linter to catch syntax errors in your workflow files.\n\n### 7.2 Build Configuration\n\n-   **`.github/workflows/`:** Place all workflow files in this directory.\n-   **`action.yml`:** For reusable actions, define their metadata in this file.\n\n### 7.3 Linting and Formatting\n\n-   **YAML Lint:** Use a YAML linting tool to enforce consistent formatting and catch syntax errors.\n-   **Shellcheck:** Use Shellcheck to lint your shell scripts.\n-   **Prettier:** Use Prettier to format your JavaScript and CSS files.\n\n### 7.4 Deployment Best Practices\n\n-   **Environment Variables:** Use environment variables to configure your deployments.\n-   **Deployment Strategies:** Use appropriate deployment strategies (e.g., blue/green deployment, canary deployment) to minimize downtime.\n-   **Rollback Strategies:**  Implement rollback strategies to revert to a previous version if a deployment fails.\n\n### 7.5 CI/CD Integration\n\n-   **Continuous Integration (CI):**  Run automated tests on every commit to ensure code quality.\n-   **Continuous Delivery (CD):** Automate the deployment process to deliver new features and bug fixes to users quickly.\n-   **Automated Releases:**  Automate the release process to create and publish releases automatically.\n\n## Conclusion\n\nBy following these best practices and coding standards, you can create efficient, reliable, secure, and maintainable GitHub Actions workflows. Remember to adapt these guidelines to your specific needs and context. Continuously review and improve your workflows to ensure they meet your evolving requirements.",
    "metadata": {
      "globs": ".github/workflows/*.yml",
      "format": "mdc",
      "originalFile": "github-actions.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "github",
      "actions",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "best",
      "github-actions",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "github-actions",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-gitlab-ci",
    "description": "Enforces best practices for GitLab CI/CD configurations, promoting efficient, maintainable, and secure pipelines. This rule covers aspects from code organization to security and testing strategies.",
    "author": "sanjeed5",
    "tags": [
      "gitlab-ci",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/gitlab-ci.mdc",
    "content": "# GitLab CI Best Practices\n\nThis document outlines the best practices for configuring GitLab CI/CD pipelines to ensure efficient, maintainable, and secure software development workflows.\n\n## 1. Code Organization and Structure\n\nA well-structured project enhances maintainability and collaboration. While GitLab CI primarily focuses on automation, the underlying code it builds significantly impacts pipeline performance and success.\n\n### Directory Structure Best Practices\n\nWhile not directly enforced by GitLab CI, consider structuring your repository to support efficient dependency management and modular builds.\n\n*   **Monorepo vs. Polyrepo:**  Choose a strategy that suits your team's size and project complexity. Monorepos can simplify dependency management but may lead to larger CI execution times if not properly configured.  Polyrepos offer better isolation but increase complexity.\n*   **Component-based structure:** Organize your code into logical components or modules. This allows for selective building and testing of individual components, reducing overall pipeline execution time.\n*   **`ci/` or `.gitlab/` directory:**  Dedicate a directory (e.g., `ci/`, `.gitlab/`) to store CI-related scripts, templates, and configurations. This keeps the root directory clean and organized.\n\n### File Naming Conventions\n\n*   `.gitlab-ci.yml` **(required):**  The primary configuration file for GitLab CI/CD. It **must** be placed in the root directory of your project.\n*   `*.gitlab-ci.yml` **(optional):** Use include statements to reference additional configurations in subdirectories. Name them according to their purpose (e.g., `deploy.gitlab-ci.yml`, `test.gitlab-ci.yml`).\n*   `*.sh`, `*.py`, etc.: Scripts referenced by `.gitlab-ci.yml` should have descriptive names (e.g., `run_tests.sh`, `deploy_to_staging.py`).\n\n### Module Organization\n\n*   **Define dependencies:** Explicitly declare dependencies between modules or components. This enables GitLab CI to build and test them in the correct order.\n*   **Separate CI configurations:** For large projects, consider creating separate `.gitlab-ci.yml` files for each module.  Use `include:` to chain them into a larger workflow.\n\n### Component Architecture Recommendations\n\n*   **Microservices:** If using a microservices architecture, each service should have its own GitLab CI configuration and pipeline.\n*   **Modular monolith:** For a monolithic architecture, break down the build process into stages that build and test individual components or modules.\n\n### Code Splitting Strategies\n\n*   **Feature flags:**  Use feature flags to enable or disable code sections without redeploying.  GitLab offers feature flag management.\n*   **Dynamic imports:** (Applicable for some languages like Javascript) Dynamically load modules only when needed to decrease initial loading times and build size.\n\n## 2. Common Patterns and Anti-patterns\n\nAdhering to proven patterns and avoiding anti-patterns contributes to pipeline reliability and maintainability.\n\n### Design Patterns\n\n*   **Pipeline as Code:** Treat your `.gitlab-ci.yml` as code. Version control it, review it, and test it.\n*   **Infrastructure as Code (IaC):** Use IaC tools (e.g., Terraform, Ansible) to manage the infrastructure used by your pipelines. This ensures consistency and reproducibility.\n*   **Secrets Management:** Use GitLab's built-in secrets management to store sensitive information (e.g., API keys, passwords) securely. Never hardcode secrets in your `.gitlab-ci.yml` file.\n*   **Idempotent Scripts:** Ensure your scripts are idempotent, meaning they can be run multiple times without causing unintended side effects.\n*   **Fail Fast:** Design your pipelines to fail as early as possible to avoid wasting resources on builds that are likely to fail.\n*   **Artifact Caching:** Cache frequently used dependencies and build artifacts to reduce build times.\n\n### Recommended Approaches for Common Tasks\n\n*   **Dependency Management:** Use appropriate package managers (e.g., npm, pip, Maven) to manage dependencies.\n*   **Testing:** Implement a comprehensive testing strategy, including unit tests, integration tests, and end-to-end tests.\n*   **Deployment:** Use a robust deployment strategy, such as blue/green deployment or rolling deployment.\n*   **Notifications:** Configure notifications to alert team members of pipeline failures or successes.\n\n### Anti-patterns and Code Smells\n\n*   **Hardcoding secrets:** Never hardcode secrets in your `.gitlab-ci.yml` file.  Use GitLab's secret variables.\n*   **Ignoring failures:** Always address pipeline failures promptly.  Ignoring failures can lead to more serious problems down the line.\n*   **Overly complex pipelines:** Keep your pipelines as simple as possible. Break down complex tasks into smaller, more manageable stages.\n*   **Lack of testing:** Insufficient testing can lead to bugs in production.  Implement a comprehensive testing strategy.\n*   **Manual deployments:** Automate deployments as much as possible.  Manual deployments are error-prone and time-consuming.\n*   **Long-running branches:** Avoid long-running feature branches.  Merge frequently to the main branch to reduce merge conflicts.\n\n### State Management Best Practices\n\n*   **GitLab CI Variables:** Use CI/CD variables for configurations that change between environments or pipeline runs.\n*   **External Databases/Key-Value Stores:** For more complex state, consider using an external database or key-value store (e.g., Redis, etcd).\n\n### Error Handling Patterns\n\n*   **`allow_failure: true`:** Use with caution. Only use `allow_failure: true` for jobs that are not critical to the overall success of the pipeline.\n*   **`retry:`:** Use `retry:` to automatically retry failed jobs. This can be useful for jobs that are prone to transient errors.\n*   **Error Reporting:** Implement error reporting to capture and track pipeline failures.  Integrate with tools like Sentry or Rollbar.\n\n## 3. Performance Considerations\n\nOptimizing pipeline performance reduces build times and improves developer productivity.\n\n### Optimization Techniques\n\n*   **Parallelization:** Run jobs in parallel to reduce overall pipeline execution time. Use matrix builds for tasks that can be run independently with different configurations.\n*   **Caching:** Cache frequently used dependencies and build artifacts to avoid downloading them repeatedly.\n*   **Optimize Docker images:** Use small, optimized Docker images to reduce image pull times.\n*   **Efficient Scripting:** Write efficient scripts that avoid unnecessary operations.\n*   **Selective Builds:** Trigger builds only when necessary by using `only:` and `except:` rules. For example, trigger builds only on changes to specific files or branches.\n*   **Interruptible jobs:**  Mark jobs as interruptible so they can be cancelled if a newer build is triggered. Avoid using this on critical steps that could leave the system in an inconsistent state.\n\n### Memory Management\n\n*   **Resource Limits:** Set memory limits for jobs to prevent them from consuming excessive resources.\n*   **Garbage Collection:** Ensure your scripts properly clean up temporary files and release memory.\n\n### Rendering Optimization (If Applicable)\n\n*   (N/A - Primarily relevant for UI-based projects, less applicable to CI configuration files).\n\n### Bundle Size Optimization (If Applicable)\n\n*   (N/A - Primarily relevant for front-end projects, less applicable to CI configuration files themselves, but important for the code being built by the CI pipeline).\n\n### Lazy Loading (If Applicable)\n\n* (N/A - Primarily relevant for front-end projects, less applicable to CI configuration files themselves, but important for the code being built by the CI pipeline).\n\n## 4. Security Best Practices\n\nSecuring your pipelines protects your code, infrastructure, and data.\n\n### Common Vulnerabilities and Prevention\n\n*   **Secret Exposure:** Prevent secrets from being exposed in logs or environment variables.  Use GitLab's secret variables and avoid printing them to the console.\n*   **Dependency Vulnerabilities:** Regularly scan your dependencies for vulnerabilities using tools like Snyk or GitLab's Dependency Scanning.\n*   **Code Injection:** Prevent code injection vulnerabilities by validating user inputs and sanitizing data.\n*   **Unauthorized Access:** Restrict access to your pipelines to authorized users only.\n\n### Input Validation\n\n*   **Sanitize inputs:** Sanitize inputs from external sources (e.g., environment variables, user inputs) to prevent code injection.\n\n### Authentication and Authorization\n\n*   **Use GitLab's authentication:** Use GitLab's built-in authentication mechanisms to protect your pipelines.\n*   **Limit access:** Limit access to your pipelines to authorized users only.\n\n### Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use secure protocols:** Use secure protocols (e.g., HTTPS, SSH) to communicate with external services.\n\n### Secure API Communication\n\n*   **Use API tokens:** Use API tokens to authenticate with external services.\n*   **Validate responses:** Validate responses from external services to prevent data tampering.\n\n## 5. Testing Approaches\n\nThorough testing ensures the quality and reliability of your code.\n\n### Unit Testing\n\n*   **Test individual components:** Unit tests should test individual components in isolation.\n*   **Use mocking and stubbing:** Use mocking and stubbing to isolate components from their dependencies.\n\n### Integration Testing\n\n*   **Test interactions between components:** Integration tests should test the interactions between different components.\n*   **Use real dependencies:** Use real dependencies or mock dependencies that closely resemble the real ones.\n\n### End-to-End Testing\n\n*   **Test the entire application:** End-to-end tests should test the entire application, from the user interface to the database.\n*   **Use automated testing tools:** Use automated testing tools like Selenium or Cypress.\n\n### Test Organization\n\n*   **Organize tests by component:** Organize tests by component to make them easier to find and maintain.\n*   **Use a consistent naming convention:** Use a consistent naming convention for tests to make them easier to identify.\n\n### Mocking and Stubbing\n\n*   **Use mocking libraries:** Use mocking libraries to create mock objects for testing.\n*   **Stub external dependencies:** Stub external dependencies to isolate components from the outside world.\n\n## 6. Common Pitfalls and Gotchas\n\nUnderstanding common pitfalls helps avoid errors and wasted time.\n\n### Frequent Mistakes\n\n*   **Incorrect syntax:** Using incorrect YAML syntax in `.gitlab-ci.yml`.\n*   **Missing dependencies:** Forgetting to declare dependencies in your pipeline.\n*   **Overly complex pipelines:** Creating overly complex pipelines that are difficult to understand and maintain.\n*   **Not using caching:** Failing to cache dependencies and build artifacts.\n*   **Exposing secrets:** Exposing secrets in logs or environment variables.\n\n### Edge Cases\n\n*   **Large repositories:** Large repositories can take a long time to clone and build.\n*   **Complex dependencies:** Complex dependencies can be difficult to manage.\n*   **Unstable infrastructure:** Unstable infrastructure can cause pipeline failures.\n\n### Version-Specific Issues\n\n*   Consult the GitLab documentation for version-specific issues.\n*   Keep your GitLab Runner up to date.\n\n### Compatibility Concerns\n\n*   Ensure compatibility between GitLab CI and other technologies used in your project (e.g., Docker, Kubernetes).\n\n### Debugging Strategies\n\n*   **Review pipeline logs:** Review pipeline logs to identify errors.\n*   **Use debugging tools:** Use debugging tools to step through your code and identify problems.\n*   **Simplify the pipeline:** Simplify the pipeline to isolate the problem.\n*   **Reproduce the problem locally:** Try to reproduce the problem locally to make it easier to debug.\n\n## 7. Tooling and Environment\n\nSelecting the right tools and configuring the environment correctly is crucial for efficient CI/CD.\n\n### Recommended Development Tools\n\n*   **Git:** A version control system.\n*   **Docker:** A containerization platform.\n*   **GitLab Runner:** A CI/CD runner.\n*   **IDE:** An integrated development environment (e.g., VS Code, IntelliJ).\n\n### Build Configuration Best Practices\n\n*   **Use a Docker image:** Use a Docker image as the base for your build environment.\n*   **Install dependencies:** Install dependencies using a package manager (e.g., npm, pip, Maven).\n*   **Run tests:** Run tests to ensure the quality of your code.\n*   **Build artifacts:** Build artifacts that can be deployed to production.\n\n### Linting and Formatting\n\n*   **Use linters:** Use linters to enforce code style and identify potential errors.\n*   **Use formatters:** Use formatters to automatically format your code.\n\n### Deployment Best Practices\n\n*   **Use a deployment strategy:** Use a deployment strategy such as blue/green deployment or rolling deployment.\n*   **Automate deployments:** Automate deployments as much as possible.\n*   **Monitor deployments:** Monitor deployments to ensure they are successful.\n\n### CI/CD Integration Strategies\n\n*   **Use GitLab CI/CD:** Use GitLab CI/CD to automate your build, test, and deployment processes.\n*   **Integrate with other tools:** Integrate GitLab CI/CD with other tools in your development workflow (e.g., Slack, Jira).\n\nBy adhering to these best practices, you can create GitLab CI/CD pipelines that are efficient, maintainable, and secure, enabling you to deliver high-quality software faster and more reliably.",
    "metadata": {
      "globs": ".gitlab-ci.yml",
      "format": "mdc",
      "originalFile": "gitlab-ci.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "gitlab",
      "ci",
      "enforces",
      "best",
      "practices",
      "configurations",
      "promoting",
      "efficient",
      "maintainable",
      "secure",
      "pipelines",
      "gitlab-ci",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "gitlab-ci",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-go",
    "description": "This rule provides a comprehensive set of best practices for developing Go applications, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "go",
      "backend",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/go.mdc",
    "content": "- # Go Best Practices\n\n  This document outlines best practices for developing Go applications, covering various aspects of the development lifecycle.\n\n- ## 1. Code Organization and Structure\n\n  - ### 1.1 Directory Structure\n\n    - **Recommended Structure:**\n\n      \n      project-name/\n      ├── cmd/\n      │   └── project-name/\n      │       └── main.go  # Application entry point\n      ├── internal/\n      │   ├── app/         # Application-specific business logic\n      │   ├── domain/      # Core domain logic and types\n      │   └── pkg/          # Reusable internal packages\n      ├── pkg/           # External packages (libraries for other projects)\n      ├── api/           # API definitions (protobuf, OpenAPI specs)\n      ├── web/           # Web assets (HTML, CSS, JavaScript)\n      ├── scripts/       # Build, deployment, or utility scripts\n      ├── configs/       # Configuration files\n      ├── .gitignore\n      ├── go.mod\n      ├── go.sum\n      └── README.md\n      \n\n    - **Explanation:**\n\n      - `cmd`:  Contains the main applications for your project. Each subdirectory should represent a separate application.\n      - `internal`:  Holds code that's private to your application. Other projects shouldn't import these.\n        - `internal/app`: High-level application logic.\n        - `internal/domain`: Core business logic, data models, and interfaces.\n        - `internal/pkg`: Reusable utilities and helpers within the internal codebase.\n      - `pkg`: Contains reusable libraries that can be used by other projects. Use this for code you want to share.\n      - `api`: Defines API contracts (e.g., Protocol Buffers or OpenAPI/Swagger definitions).\n      - `web`: Stores static web assets like HTML, CSS, and JavaScript files.\n      - `scripts`: Contains scripts for building, testing, deploying, and other tasks.\n      - `configs`: Houses configuration files for various environments.\n\n  - ### 1.2 File Naming Conventions\n\n    - **General:**  Use lowercase and snake_case for file names (e.g., `user_service.go`).\n    - **Test Files:**  Append `_test.go` to the name of the file being tested (e.g., `user_service_test.go`).\n    - **Main Package:** The file containing the `main` function is typically named `main.go`.\n\n  - ### 1.3 Module Organization\n\n    - **Go Modules:**  Use Go modules for dependency management.  Initialize a module with `go mod init <module-name>`. The module name should reflect the repository path (e.g., `github.com/your-username/project-name`).\n    - **Versioning:** Follow semantic versioning (SemVer) for your modules.  Use tags in your Git repository to represent releases (e.g., `v1.0.0`).\n    - **Vendoring:** Consider vendoring dependencies using `go mod vendor` to ensure reproducible builds, especially for critical applications. However, be mindful of vendor directory size.\n\n  - ### 1.4 Component Architecture\n\n    - **Layered Architecture:**  Structure your application into layers (e.g., presentation, service, repository, data access). This promotes separation of concerns and testability.\n    - **Clean Architecture:** A variation of layered architecture that emphasizes dependency inversion and testability. Core business logic should not depend on implementation details.\n    - **Microservices:** For larger applications, consider a microservices architecture where different parts of the application are deployed as independent services.\n    - **Dependency Injection:** Use dependency injection to decouple components and make them easier to test. Frameworks like `google/wire` or manual dependency injection can be used.\n\n  - ### 1.5 Code Splitting\n\n    - **Package Organization:**  Group related functionality into packages.  Each package should have a clear responsibility.  Keep packages small and focused.\n    - **Interface Abstraction:**  Use interfaces to define contracts between components.  This allows you to swap implementations without changing the code that depends on the interface.\n    - **Functional Options Pattern:** For functions with many optional parameters, use the functional options pattern to improve readability and maintainability.\n\n      go\n      type Server struct {\n          Addr     string\n          Port     int\n          Protocol string\n          Timeout  time.Duration\n      }\n\n      type Option func(*Server)\n\n      func WithAddress(addr string) Option {\n          return func(s *Server) {\n              s.Addr = addr\n          }\n      }\n\n      func WithPort(port int) Option {\n          return func(s *Server) {\n              s.Port = port\n          }\n      }\n\n      func NewServer(options ...Option) *Server {\n          srv := &Server{\n              Addr:     \"localhost\",\n              Port:     8080,\n              Protocol: \"tcp\",\n              Timeout:  30 * time.Second,\n          }\n\n          for _, option := range options {\n              option(srv)\n          }\n\n          return srv\n      }\n\n      // Usage\n      server := NewServer(WithAddress(\"127.0.0.1\"), WithPort(9000))\n      \n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### 2.1 Design Patterns\n\n    - **Factory Pattern:** Use factory functions to create instances of complex objects.\n    - **Strategy Pattern:** Define a family of algorithms and encapsulate each one in a separate class, making them interchangeable.\n    - **Observer Pattern:** Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n    - **Context Pattern:**  Use the `context` package to manage request-scoped values, cancellation signals, and deadlines.  Pass `context.Context` as the first argument to functions that perform I/O or long-running operations.\n\n      go\n      func handleRequest(ctx context.Context, req *http.Request) {\n          select {\n          case <-ctx.Done():\n              // Operation cancelled\n              return\n          default:\n              // Process the request\n          }\n      }\n      \n\n    - **Middleware Pattern:**  Chain functions to process HTTP requests.  Middleware can be used for logging, authentication, authorization, and other cross-cutting concerns.\n\n      go\n      func loggingMiddleware(next http.Handler) http.Handler {\n          return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n              log.Printf(\"Request: %s %s\", r.Method, r.URL.Path)\n              next.ServeHTTP(w, r)\n          })\n      }\n      \n\n  - ### 2.2 Recommended Approaches for Common Tasks\n\n    - **Configuration Management:** Use a library like `spf13/viper` or `joho/godotenv` to load configuration from files, environment variables, and command-line flags.\n    - **Logging:** Use a structured logging library like `sirupsen/logrus` or `uber-go/zap` to log events with context and severity levels.\n    - **Database Access:** Use the `database/sql` package with a driver for your specific database (e.g., `github.com/lib/pq` for PostgreSQL, `github.com/go-sql-driver/mysql` for MySQL). Consider an ORM like `gorm.io/gorm` for more complex database interactions. Use prepared statements to prevent SQL injection.\n    - **HTTP Handling:** Use the `net/http` package for building HTTP servers and clients. Consider using a framework like `gin-gonic/gin` or `go-chi/chi` for more advanced routing and middleware features. Always set appropriate timeouts.\n    - **Asynchronous Tasks:** Use goroutines and channels to perform asynchronous tasks. Use wait groups to synchronize goroutines.\n    - **Input Validation:** Use libraries like `go-playground/validator` for validating input data. Always sanitize user input to prevent injection attacks.\n\n  - ### 2.3 Anti-patterns and Code Smells\n\n    - **Ignoring Errors:** Never ignore errors. Always handle errors explicitly, even if it's just logging them.\n\n      go\n      // Bad\n      _, _ = fmt.Println(\"Hello, world!\")\n\n      // Good\n      _, err := fmt.Println(\"Hello, world!\")\n      if err != nil {\n          log.Println(\"Error printing: \", err)\n      }\n      \n\n    - **Panic Usage:** Avoid using `panic` for normal error handling. Use it only for truly exceptional situations where the program cannot continue.\n    - **Global Variables:** Minimize the use of global variables. Prefer passing state explicitly as function arguments.\n    - **Shadowing Variables:** Avoid shadowing variables, where a variable in an inner scope has the same name as a variable in an outer scope. This can lead to confusion and bugs.\n    - **Unbuffered Channels:** Be careful when using unbuffered channels. They can easily lead to deadlocks if not used correctly.\n    - **Overusing Goroutines:** Don't launch too many goroutines, as it can lead to excessive context switching and resource consumption.  Consider using a worker pool to limit the number of concurrent goroutines.\n    - **Mutable Global State:** Avoid modifying global state, especially concurrently, as it can introduce race conditions.\n    - **Magic Numbers/Strings:** Avoid using hardcoded numbers or strings directly in your code. Define them as constants instead.\n    - **Long Functions:** Keep functions short and focused. If a function is too long, break it down into smaller, more manageable functions.\n    - **Deeply Nested Code:** Avoid deeply nested code, as it can be difficult to read and understand. Use techniques like early returns and helper functions to flatten the code structure.\n\n  - ### 2.4 State Management\n\n    - **Local State:**  For simple components, manage state locally within the component using variables.\n    - **Shared State:** When multiple goroutines need to access and modify shared state, use synchronization primitives like mutexes, read-write mutexes, or atomic operations to prevent race conditions.\n\n      go\n      var mu sync.Mutex\n      var counter int\n\n      func incrementCounter() {\n          mu.Lock()\n          defer mu.Unlock()\n          counter++\n      }\n      \n\n    - **Channels for State Management:** Use channels to pass state between goroutines. This can be a safer alternative to shared memory and locks.\n    - **Context for Request-Scoped State:** Use `context.Context` to pass request-scoped state, such as user authentication information or transaction IDs.\n    - **External Stores (Redis, Databases):** For persistent state or state that needs to be shared across multiple services, use an external store like Redis or a database.\n\n  - ### 2.5 Error Handling Patterns\n\n    - **Explicit Error Handling:** Go treats errors as values. Always check for errors and handle them appropriately.\n    - **Error Wrapping:** Wrap errors with context information to provide more details about where the error occurred. Use `fmt.Errorf` with `%w` verb to wrap errors.\n\n      go\n      func readFile(filename string) ([]byte, error) {\n          data, err := ioutil.ReadFile(filename)\n          if err != nil {\n              return nil, fmt.Errorf(\"failed to read file %s: %w\", filename, err)\n          }\n          return data, nil\n      }\n      \n\n    - **Error Types:** Define custom error types to represent specific error conditions. This allows you to handle errors more precisely.\n\n      go\n      type NotFoundError struct {\n          Resource string\n      }\n\n      func (e *NotFoundError) Error() string {\n          return fmt.Sprintf(\"%s not found\", e.Resource)\n      }\n      \n\n    - **Sentinel Errors:** Define constant errors that can be compared directly using `==`. This is simpler than error types but less flexible.\n\n      go\n      var ErrNotFound = errors.New(\"not found\")\n\n      func getUser(id int) (*User, error) {\n          if id == 0 {\n              return nil, ErrNotFound\n          }\n          // ...\n      }\n      \n\n    - **Error Grouping:** Use libraries like `go.uber.org/multierr` to collect multiple errors and return them as a single error.\n    - **Defers for Resource Cleanup:** Use `defer` to ensure that resources are cleaned up, even if an error occurs.\n\n      go\n      func processFile(filename string) error {\n          file, err := os.Open(filename)\n          if err != nil {\n              return err\n          }\n          defer file.Close() // Ensure file is closed\n          // ...\n      }\n      \n\n- ## 3. Performance Considerations\n\n  - ### 3.1 Optimization Techniques\n\n    - **Profiling:** Use the `pprof` package to profile your application and identify performance bottlenecks. `go tool pprof` allows you to analyze CPU and memory usage.\n\n      bash\n      go tool pprof http://localhost:6060/debug/pprof/profile  # CPU profiling\n      go tool pprof http://localhost:6060/debug/pprof/heap     # Memory profiling\n      \n\n    - **Benchmarking:** Use the `testing` package to benchmark critical sections of your code.\n\n      go\n      func BenchmarkFunction(b *testing.B) {\n          for i := 0; i < b.N; i++ {\n              // Code to benchmark\n          }\n      }\n      \n\n    - **Efficient Data Structures:** Choose the right data structures for your needs. For example, use `sync.Map` for concurrent access to maps.\n    - **String Concatenation:** Use `strings.Builder` for efficient string concatenation, especially in loops.\n\n      go\n      var sb strings.Builder\n      for i := 0; i < 1000; i++ {\n          sb.WriteString(\"hello\")\n      }\n      result := sb.String()\n      \n\n    - **Reduce Allocations:** Minimize memory allocations, as garbage collection can be expensive. Reuse buffers and objects when possible.\n    - **Inline Functions:** Use the `//go:inline` directive to inline frequently called functions. However, use this sparingly, as it can increase code size.\n    - **Escape Analysis:** Understand how Go's escape analysis works to minimize heap allocations. Values that don't escape to the heap are allocated on the stack, which is faster.\n    - **Compiler Optimizations:** Experiment with compiler flags like `-gcflags=-S` to see the generated assembly code and understand how the compiler is optimizing your code.\n    - **Caching:** Implement caching strategies to reduce database or network calls. Use in-memory caches like `lru` or distributed caches like Redis.\n\n  - ### 3.2 Memory Management\n\n    - **Garbage Collection Awareness:** Be aware of how Go's garbage collector works. Understand the trade-offs between memory usage and CPU usage.\n    - **Reduce Heap Allocations:** Try to allocate memory on the stack whenever possible to avoid the overhead of garbage collection.\n    - **Object Pooling:** Use object pooling to reuse frequently created and destroyed objects. This can reduce the number of allocations and improve performance.\n    - **Slices vs. Arrays:** Understand the difference between slices and arrays. Slices are dynamically sized and backed by an array. Arrays have a fixed size. Slices are generally more flexible, but arrays can be more efficient in some cases.\n    - **Copying Data:** Be mindful of copying data, especially large data structures. Use pointers to avoid unnecessary copies.\n\n  - ### 3.3 Rendering Optimization (if applicable)\n    - This section is less relevant for back-end Go applications. If your Go application serves HTML templates:\n    - **Template Caching:** Cache parsed templates to avoid reparsing them on every request.\n    - **Efficient Template Engine:** Use an efficient template engine like `html/template` from the standard library.\n    - **Minimize DOM Manipulations (if using JavaScript):** Reduce the number of DOM manipulations in your JavaScript code, as they can be expensive.\n\n  - ### 3.4 Bundle Size Optimization (if applicable)\n    - This section is mostly irrelevant for back-end Go applications. If your Go application serves static assets:\n    - **Minification:** Minify your CSS and JavaScript files to reduce their size.\n    - **Compression:** Compress your assets using Gzip or Brotli.\n    - **Code Splitting (JavaScript):** Split your JavaScript code into smaller chunks that can be loaded on demand.\n\n  - ### 3.5 Lazy Loading (if applicable)\n    - This is mostly relevant for front-end applications, or database connections:\n    - **Database Connections:** Only establish database connections when they are needed.\n    - **Expensive Resources:** Load expensive resources (e.g., images, large data structures) only when they are actually used.\n\n- ## 4. Security Best Practices\n\n  - ### 4.1 Common Vulnerabilities\n\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM that automatically escapes user input.\n    - **Cross-Site Scripting (XSS):** If your Go application renders HTML, prevent XSS by escaping user input before rendering it.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using CSRF tokens.\n    - **Command Injection:** Avoid executing external commands directly with user input. If you must, sanitize the input carefully.\n    - **Path Traversal:** Prevent path traversal attacks by validating and sanitizing file paths provided by users.\n    - **Denial of Service (DoS):** Protect against DoS attacks by setting appropriate timeouts and resource limits. Use rate limiting to prevent abuse.\n    - **Authentication and Authorization Issues:** Implement robust authentication and authorization mechanisms to protect sensitive data and functionality.\n    - **Insecure Dependencies:** Regularly audit your dependencies for known vulnerabilities. Use tools like `govulncheck` to identify vulnerabilities.\n\n  - ### 4.2 Input Validation\n\n    - **Validate All Input:** Validate all input data, including user input, API requests, and data from external sources.\n    - **Use Validation Libraries:** Use validation libraries like `go-playground/validator` to simplify input validation.\n    - **Sanitize Input:** Sanitize user input to remove potentially harmful characters or code.\n    - **Whitelist vs. Blacklist:** Prefer whitelisting allowed values over blacklisting disallowed values.\n    - **Regular Expressions:** Use regular expressions to validate complex input formats.\n\n  - ### 4.3 Authentication and Authorization\n\n    - **Use Strong Authentication:** Use strong authentication mechanisms like multi-factor authentication (MFA).\n    - **Password Hashing:** Hash passwords using a strong hashing algorithm like bcrypt or Argon2.\n    - **JWT (JSON Web Tokens):** Use JWT for stateless authentication.  Verify the signature of JWTs before trusting them.\n    - **RBAC (Role-Based Access Control):** Implement RBAC to control access to resources based on user roles.\n    - **Least Privilege:** Grant users only the minimum privileges necessary to perform their tasks.\n    - **OAuth 2.0:** Use OAuth 2.0 for delegated authorization, allowing users to grant third-party applications access to their data without sharing their credentials.\n\n  - ### 4.4 Data Protection\n\n    - **Encryption:** Encrypt sensitive data at rest and in transit.\n    - **TLS (Transport Layer Security):** Use TLS to encrypt communication between clients and servers.\n    - **Data Masking:** Mask sensitive data in logs and displays.\n    - **Regular Backups:** Regularly back up your data to prevent data loss.\n    - **Access Control:** Restrict access to sensitive data to authorized personnel only.\n    - **Data Minimization:** Collect only the data that is necessary for your application.\n\n  - ### 4.5 Secure API Communication\n\n    - **HTTPS:** Use HTTPS for all API communication.\n    - **API Keys:** Use API keys to authenticate clients.\n    - **Rate Limiting:** Implement rate limiting to prevent abuse.\n    - **Input Validation:** Validate all input data to prevent injection attacks.\n    - **Output Encoding:** Encode output data appropriately to prevent XSS attacks.\n    - **CORS (Cross-Origin Resource Sharing):** Configure CORS properly to allow requests from trusted origins only.\n\n- ## 5. Testing Approaches\n\n  - ### 5.1 Unit Testing\n\n    - **Focus on Individual Units:** Unit tests should focus on testing individual functions, methods, or packages in isolation.\n    - **Table-Driven Tests:** Use table-driven tests to test multiple inputs and outputs for a single function.\n\n      go\n      func TestAdd(t *testing.T) {\n          testCases := []struct {\n              a, b     int\n              expected int\n          }{\n              {1, 2, 3},\n              {0, 0, 0},\n              {-1, 1, 0},\n          }\n\n          for _, tc := range testCases {\n              result := Add(tc.a, tc.b)\n              if result != tc.expected {\n                  t.Errorf(\"Add(%d, %d) = %d; expected %d\", tc.a, tc.b, result, tc.expected)\n              }\n          }\n      }\n      \n\n    - **Test Coverage:** Aim for high test coverage. Use `go test -cover` to measure test coverage.\n    - **Clear Assertions:** Use clear and informative assertions. Libraries like `testify` provide helpful assertion functions.\n    - **Test Naming:** Use descriptive test names that clearly indicate what is being tested.\n\n  - ### 5.2 Integration Testing\n\n    - **Test Interactions Between Components:** Integration tests should test the interactions between different components of your application.\n    - **Use Real Dependencies (where possible):** Use real dependencies (e.g., real databases) in integration tests, where possible. This provides more realistic testing.\n    - **Mock External Services:** Mock external services that are not under your control.\n    - **Test Data Setup and Teardown:** Set up test data before each test and tear it down after each test to ensure that tests are independent.\n\n  - ### 5.3 End-to-End Testing\n\n    - **Test the Entire Application:** End-to-end tests should test the entire application, from the user interface to the backend.\n    - **Automated Browser Testing:** Use automated browser testing tools like Selenium or Cypress to simulate user interactions.\n    - **Test Real-World Scenarios:** Test real-world scenarios to ensure that the application works as expected in production.\n    - **Data Persistence:** Be careful of data persistence between tests. Clean up any generated data after each test run.\n\n  - ### 5.4 Test Organization\n\n    - **Test Files:** Place test files in the same directory as the code being tested. Use the `_test.go` suffix.\n    - **Package Tests:** Write tests for each package in your application.\n    - **Test Suites:** Use test suites to group related tests together.\n\n  - ### 5.5 Mocking and Stubbing\n\n    - **Interfaces for Mocking:** Use interfaces to define contracts between components, making it easier to mock dependencies.\n    - **Mocking Libraries:** Use mocking libraries like `gomock` or `testify/mock` to generate mocks for interfaces.\n\n      go\n      //go:generate mockgen -destination=mocks/mock_user_repository.go -package=mocks github.com/your-username/project-name/internal/domain UserRepository\n\n      type UserRepository interface {\n          GetUser(id int) (*User, error)\n      }\n      \n\n    - **Stubbing:** Use stubs to replace dependencies with simple, predefined responses.\n    - **Avoid Over-Mocking:** Don't over-mock your code. Mock only the dependencies that are necessary to isolate the unit being tested.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### 6.1 Frequent Mistakes\n\n    - **Nil Pointer Dereferences:** Be careful of nil pointer dereferences. Always check for nil before accessing a pointer.\n    - **Data Races:** Avoid data races by using synchronization primitives like mutexes or channels.\n    - **Deadlocks:** Be careful of deadlocks when using goroutines and channels. Ensure that channels are closed properly and that goroutines are not waiting on each other indefinitely.\n    - **For Loop Variable Capture:** Be careful when capturing loop variables in goroutines. The loop variable may change before the goroutine is executed. Copy the loop variable to a local variable before passing it to the goroutine.\n\n      go\n      for _, item := range items {\n          item := item // Copy loop variable to local variable\n          go func() {\n              // Use local variable item\n          }()\n      }\n      \n\n    - **Incorrect Type Conversions:** Be careful when converting between types. Ensure that the conversion is valid and that you handle potential errors.\n    - **Incorrect Error Handling:** Ignoring or mishandling errors is a common pitfall. Always check errors and handle them appropriately.\n    - **Over-reliance on Global State:** Using global variables excessively leads to tight coupling and makes code difficult to test and reason about.\n\n  - ### 6.2 Edge Cases\n\n    - **Integer Overflow:** Be aware of integer overflow when performing arithmetic operations.\n    - **Floating-Point Precision:** Be aware of the limitations of floating-point precision.\n    - **Time Zones:** Be careful when working with time zones. Use the `time` package to handle time zones correctly.\n    - **Unicode Handling:** Be careful when handling Unicode characters. Use the `unicode/utf8` package to correctly encode and decode UTF-8 strings.\n\n  - ### 6.3 Version-Specific Issues\n\n    - **Go 1.18 Generics:**  Understand how generics work in Go 1.18 and later versions.  Use them judiciously to improve code reusability and type safety.\n    - **Module Compatibility:**  Be aware of compatibility issues between different versions of Go modules.  Use `go mod tidy` to update your dependencies and resolve compatibility issues.\n\n  - ### 6.4 Compatibility Concerns\n\n    - **C Interoperability:** Be aware of the complexities of C interoperability when using the `cgo` tool. Ensure that memory is managed correctly and that there are no data races.\n    - **Operating System Differences:** Be aware of differences between operating systems (e.g., file path separators, environment variables). Use the `os` package to handle operating system-specific behavior.\n\n  - ### 6.5 Debugging Strategies\n\n    - **Print Statements:** Use `fmt.Println` or `log.Println` to print debugging information.\n    - **Delve Debugger:** Use the Delve debugger (`dlv`) to step through your code and inspect variables.\n\n      bash\n      dlv debug ./cmd/your-application\n      \n\n    - **pprof Profiling:** Use the `pprof` package to profile your application and identify performance bottlenecks.\n    - **Race Detector:** Use the race detector (`go run -race`) to identify data races in your code.\n    - **Logging:** Add detailed logging to your application to help diagnose issues in production.\n    - **Core Dumps:** Generate core dumps when your application crashes to help diagnose the cause of the crash.\n    - **Code Reviews:** Have your code reviewed by other developers to catch potential issues.\n\n- ## 7. Tooling and Environment\n\n  - ### 7.1 Recommended Development Tools\n\n    - **GoLand:** A commercial IDE from JetBrains with excellent Go support.\n    - **Visual Studio Code:** A free and open-source editor with Go support via the Go extension.\n    - **Vim:** A powerful text editor with Go support via plugins.\n    - **gopls:** The official Go language server, providing features like code completion, linting, and formatting.\n\n  - ### 7.2 Build Configuration\n\n    - **Makefile:** Use a Makefile to automate build and deployment tasks.\n\n      makefile\n      build:\n          go build -o bin/your-application ./cmd/your-application\n\n      run:\n          go run ./cmd/your-application\n\n      test:\n          go test ./...\n      \n\n    - **GoReleaser:** Use GoReleaser to automate the release process, including building binaries for multiple platforms, generating checksums, and creating release notes.\n    - **Docker:** Use Docker to containerize your application for easy deployment.\n\n      dockerfile\n      FROM golang:1.21-alpine AS builder\n      WORKDIR /app\n      COPY go.mod go.sum ./\n      RUN go mod download\n      COPY . .\n      RUN go build -o /bin/your-application ./cmd/your-application\n\n      FROM alpine:latest\n      WORKDIR /app\n      COPY --from=builder /bin/your-application .\n      CMD [\"./your-application\"]\n      \n\n  - ### 7.3 Linting and Formatting\n\n    - **gofmt:** Use `gofmt` to automatically format your Go code according to the standard style guidelines.  Run it regularly to keep your code consistent.\n\n      bash\n      gofmt -s -w .\n      \n\n    - **golint:** Use `golint` to check your code for style and potential issues.\n    - **staticcheck:** Use `staticcheck` for more comprehensive static analysis.\n    - **revive:**  A fast, configurable, extensible, flexible, and beautiful linter for Go.\n    - **errcheck:** Use `errcheck` to ensure that you are handling all errors.\n    - **.golangci.yml:** Use a `.golangci.yml` file to configure `golangci-lint` with your preferred linting rules.\n\n  - ### 7.4 Deployment\n\n    - **Cloud Platforms:** Deploy your application to cloud platforms like AWS, Google Cloud, or Azure.\n    - **Kubernetes:** Deploy your application to Kubernetes for scalability and high availability.\n    - **Systemd:** Use systemd to manage your application as a service on Linux systems.\n    - **Serverless Functions:** Consider using serverless functions for small, event-driven applications.\n\n  - ### 7.5 CI/CD Integration\n\n    - **GitHub Actions:** Use GitHub Actions to automate your CI/CD pipeline.\n    - **GitLab CI:** Use GitLab CI to automate your CI/CD pipeline.\n    - **Jenkins:** Use Jenkins to automate your CI/CD pipeline.\n    - **CircleCI:** Use CircleCI to automate your CI/CD pipeline.\n    - **Automated Testing:** Run unit tests, integration tests, and end-to-end tests automatically as part of your CI/CD pipeline.\n    - **Automated Deployment:** Automate the deployment process to reduce the risk of human error.\n    - **Infrastructure as Code:** Use Infrastructure as Code (IaC) tools like Terraform or CloudFormation to automate the provisioning and management of your infrastructure.",
    "metadata": {
      "globs": "*.go",
      "format": "mdc",
      "originalFile": "go.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "go",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "covering",
      "code",
      "backend",
      "performance",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "go",
        "golang",
        "backend",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-godot",
    "description": "Comprehensive coding standards and best practices for Godot Engine development, covering code organization, performance, testing, and security to ensure maintainable, efficient, and secure game projects. These rules are primarily for GDScript but also reference relevant C# practices where applicable.",
    "author": "sanjeed5",
    "tags": [
      "godot",
      "go",
      "backend",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/godot.mdc",
    "content": "# Godot Engine Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for Godot Engine development using GDScript and C#. Adhering to these guidelines will lead to more maintainable, efficient, and secure game projects.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **`scenes/`**: Stores all `.tscn` (scene) and `.escn` (external scene) files. Organize scenes into subdirectories based on game areas, features, or entity types (e.g., `scenes/characters/`, `scenes/levels/`, `scenes/ui/`).\n*   **`scripts/`**: Contains all GDScript (`.gd`) and C# (`.cs`) scripts. Mirror the scene directory structure where applicable to maintain consistency (e.g., `scripts/characters/`, `scripts/levels/`).\n*   **`assets/` (or `art/` / `textures/` / `audio/`):** Stores all non-code assets like textures, audio files, models, animations, and fonts. Subdivide further based on asset type (e.g., `assets/textures/`, `assets/audio/`, `assets/models/`).\n*   **`addons/`**: Reserved for third-party addons and plugins.\n*   **`data/` (or `resources/`):** Holds data files like JSON, CSV, or custom resource files used for game configuration, localization, or level data.\n*   **`shaders/`**: Stores custom shader files (`.shader`).\n*   **`autoload/`**: If using autoloaded scripts (singletons), consider a dedicated folder.\n\n\nmy_project/\n├── scenes/\n│   ├── characters/\n│   │   ├── player.tscn\n│   │   └── enemy.tscn\n│   ├── levels/\n│   │   ├── level_1.tscn\n│   │   └── level_2.tscn\n│   └── ui/\n│       └── main_menu.tscn\n├── scripts/\n│   ├── characters/\n│   │   ├── player.gd\n│   │   └── enemy.gd\n│   └── ui/\n│       └── main_menu.gd\n├── assets/\n│   ├── textures/\n│   │   ├── player.png\n│   │   └── enemy.png\n│   ├── audio/\n│   │   ├── background.ogg\n│   │   └── jump.wav\n│   └── models/\n│       └── character.glb\n├── addons/\n│   └── ...\n├── data/\n│   └── levels.json\n└── shaders/\n    └── water.shader\n\n\n### 1.2. File Naming Conventions\n\n*   **Scenes:** Use PascalCase (e.g., `Player.tscn`, `MainMenu.tscn`).\n*   **Scripts (GDScript):** Use snake_case (e.g., `player_controller.gd`, `ui_manager.gd`).\n*   **Scripts (C#):** Use PascalCase (e.g., `PlayerController.cs`, `UIManager.cs`).\n*   **Assets:** Use descriptive names with appropriate extensions (e.g., `player_idle.png`, `background_music.ogg`, `sword.glb`). Consider using snake_case for assets as well to maintain consistency.\n\n### 1.3. Module Organization\n\n*   **Separate Concerns:** Divide your project into logical modules based on functionality (e.g., player controller, AI, UI, physics, networking). Each module should have its own directory and scripts.\n*   **Autoloads (Singletons):** Use autoloads sparingly. Overuse can lead to tightly coupled code.  Good candidates are global managers like `GameManager`, `InputManager`, or `AudioManager`.\n*   **Custom Resources:** Create custom resource types for reusable data containers. This promotes data-driven design (e.g., `CharacterData`, `WeaponData`).\n\n### 1.4. Component Architecture\n\n*   **Favor Composition over Inheritance:** Use nodes and scripts as components that can be attached to other nodes. This allows for more flexible and reusable code. Godot's scene system is built around this concept.\n*   **Signals:** Use signals for communication between nodes. This promotes loose coupling and allows nodes to react to events without knowing the details of other nodes.\n\n### 1.5. Code Splitting Strategies\n\n*   **Separate Logic from Presentation:** Keep scene files focused on visual representation and node hierarchy. Move game logic, input handling, and AI to separate scripts.\n*   **Helper Functions:** Create utility scripts with reusable functions to avoid code duplication.\n*   **Script Classes (GDScript):** Define classes within scripts to encapsulate related data and functions. Use `class_name` to register the class as a global type.\n*   **Partial Classes (C#):** Use partial classes to split a large class into multiple files, improving organization.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton (Autoload):** As mentioned before, use autoloads for global managers.\n*   **Observer (Signals):** Use signals for event-driven communication between nodes.\n*   **State Machine:** Implement state machines to manage the behavior of game entities (e.g., player states: idle, walking, jumping, attacking).\n*   **Object Pool:** For frequently created and destroyed objects (e.g., bullets, particles), use an object pool to reduce memory allocation overhead.\n*   **Factory:** Use factories to create instances of objects based on certain conditions or configurations.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Input Handling:** Use the `Input` singleton and input actions for consistent input handling. Define input maps in the project settings.\n*   **Scene Management:** Use `get_tree().change_scene_to_file()` or `get_tree().change_scene_to_packed()` for scene transitions.\n*   **Timers:** Use the `Timer` node for delayed execution or repeated events.  Avoid using `yield(get_tree().create_timer(time), \"timeout\")` unless absolutely necessary, prefer the Timer node and signals for readability.\n*   **Animation:** Utilize the `AnimationPlayer` node for complex animations. For simple animations, consider tweens.\n*   **Networking:** Use Godot's built-in networking API for multiplayer games. Consider using a higher-level networking library like ENet or Nakama for more advanced features.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **God Classes:** Avoid creating large classes that handle too many responsibilities. Break them down into smaller, more focused components.\n*   **Tight Coupling:** Minimize dependencies between nodes. Use signals and interfaces to promote loose coupling.\n*   **Spaghetti Code:** Avoid deeply nested conditional statements and loops. Use functions and classes to break down complex logic into smaller, more manageable pieces.\n*   **Magic Numbers:** Avoid using hardcoded numbers in your code. Use constants or variables instead.\n*   **Premature Optimization:** Don't optimize your code before you identify performance bottlenecks. Focus on writing clear and maintainable code first.\n\n### 2.4. State Management\n\n*   **Finite State Machines (FSMs):** Use FSMs to manage the different states of game entities, such as player characters or AI agents. This helps to organize and control complex behavior.\n*   **State Design Pattern:** Implement the State design pattern to encapsulate the logic for each state in separate classes or scripts. This makes it easier to add, remove, or modify states without affecting other parts of the code.\n*   **Hierarchical State Machines (HSMs):** For more complex state management scenarios, consider using HSMs to create nested states. This allows you to define common behavior in parent states and override it in child states as needed.\n\n### 2.5. Error Handling\n\n*   **`assert()`:** Use `assert()` for debugging to check for conditions that should always be true.  These checks are disabled in release builds.\n*   **`try...except` (GDScript) / `try...catch` (C#):** Use try-except/try-catch blocks to handle exceptions and prevent crashes. Handle expected errors gracefully (e.g., file not found).\n*   **Error Signals:** Emit custom signals to notify other nodes of errors.  This allows for centralized error handling and logging.\n*   **Return Values:** Use return values to indicate success or failure. For example, a function that loads a file could return `OK` or `ERR_FILE_NOT_FOUND`.\n*   **Logging:** Use `print()` (for debugging) and a dedicated logging system (for production) to track errors and warnings.  Use a custom logging system that can be disabled in release builds.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Culling:** Use frustum culling and occlusion culling to reduce the number of objects that need to be rendered.\n*   **Level of Detail (LOD):** Use LOD to reduce the complexity of models and textures based on their distance from the camera.\n*   **Batching:** Batch multiple draw calls into a single draw call to reduce the overhead of rendering.\n*   **Object Pooling:** Reuse objects instead of creating and destroying them frequently.\n*   **Optimized Data Structures:** Use appropriate data structures for your data (e.g., dictionaries for fast lookups, arrays for ordered data).\n*   **Profiling:** Use Godot's built-in profiler to identify performance bottlenecks.\n*   **Multi-threading:** Utilize multi-threading for long running operations.\n*   **Avoid `get_node()` in Loops:** Cache node references to avoid repeated calls to `get_node()` within loops.\n*   **Use Typed Arrays:** In GDScript, use Typed Arrays (e.g., `PackedByteArray`, `PackedFloat32Array`) for efficient storage and manipulation of large amounts of data.\n\n### 3.2. Memory Management\n\n*   **Resource Management:** Load resources only when needed and unload them when they are no longer used. Use `ResourceLoader.load()` and `Resource.free()`.\n*   **Circular References:** Avoid circular references between objects, as this can prevent them from being garbage collected.\n*   **Object Pooling:** As mentioned before, use object pooling to reduce memory allocation overhead.\n*   **Weak References:**  If you need to reference an object without preventing it from being garbage collected, use a `WeakRef`.\n\n### 3.3. Rendering Optimization\n\n*   **Reduce Draw Calls:** Minimize the number of draw calls by using techniques such as batching and instancing.\n*   **Optimize Shaders:** Write efficient shaders that use the minimum number of instructions.\n*   **Texture Compression:** Use compressed textures to reduce memory usage and improve performance.\n*   **Mipmaps:** Use mipmaps to improve texture filtering quality and reduce aliasing.\n*   **Limit Overdraw:** Reduce overdraw by avoiding overlapping transparent objects.\n*   **CanvasItem Z Index:** Group similar Z index values to improve rendering performance.\n\n### 3.4. Bundle Size Optimization\n\n*   **Compress Textures:** Use compressed textures to reduce the size of your textures.\n*   **Optimize Audio Files:** Use compressed audio formats such as OGG Vorbis or MP3.\n*   **Remove Unused Assets:** Remove any unused assets from your project.\n*   **Use Asset Packs:** Use asset packs to share assets between multiple projects.\n*   **Enable Texture Compression:**  In project settings, enable texture compression for release builds.\n\n### 3.5. Lazy Loading\n\n*   **Load Scenes Asynchronously:** Load scenes in the background to prevent the game from freezing during scene transitions.  Use `ResourceLoader.load_interactive()`.\n*   **Stream Audio:** Stream audio files instead of loading them into memory all at once.\n*   **Load Resources on Demand:** Load resources only when they are needed, such as when a player enters a new area.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Injection Attacks:** Prevent SQL injection, code injection, and other injection attacks by validating all user inputs.\n*   **Cross-Site Scripting (XSS):**  Not typically a concern for standalone games, but relevant if integrating web-based content or APIs.\n*   **Denial of Service (DoS):** Protect your game from DoS attacks by limiting the number of requests that can be made from a single IP address.\n*   **Data Tampering:** Prevent players from tampering with game data by encrypting sensitive data and validating it on the server.\n*   **Reverse Engineering:**  Obfuscate your code to make it more difficult for players to reverse engineer your game.\n\n### 4.2. Input Validation\n\n*   **Validate All Inputs:** Validate all user inputs, including text fields, number fields, and dropdown menus.\n*   **Use Regular Expressions:** Use regular expressions to validate input formats.\n*   **Sanitize Inputs:** Sanitize inputs to remove potentially harmful characters.\n*   **Limit Input Length:** Limit the length of input fields to prevent buffer overflows.\n*   **Client-Side and Server-Side Validation:** Implement both client-side and server-side validation to prevent malicious users from bypassing client-side checks.\n\n### 4.3. Authentication and Authorization\n\n*   **Use Secure Authentication Protocols:** Use secure authentication protocols such as OAuth 2.0 or JWT.\n*   **Store Passwords Securely:** Store passwords using a strong hashing algorithm such as Argon2 or bcrypt.\n*   **Implement Role-Based Access Control (RBAC):** Use RBAC to control access to different parts of your game based on user roles.\n*   **Two-Factor Authentication (2FA):** Implement 2FA to add an extra layer of security to user accounts.\n\n### 4.4. Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data such as passwords, API keys, and user data using a strong encryption algorithm such as AES.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between your game and your server.\n*   **Protect API Keys:** Protect your API keys from being exposed by storing them securely on the server.\n*   **Secure Local Storage:** If storing data locally, encrypt it to prevent unauthorized access.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Always use HTTPS for all API communication.\n*   **Validate API Responses:** Validate API responses to ensure that they are valid and haven't been tampered with.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n*   **API Key Rotation:** Rotate your API keys regularly to prevent them from being compromised.\n*   **Proper Error Handling:** Implement proper error handling to prevent sensitive information from being leaked in error messages.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Write unit tests to test individual components of your game, such as functions, classes, and nodes.\n*   **Use a Testing Framework:** Use a testing framework such as Gut (Godot Unit Testing) to write and run your unit tests.\n*   **Mock Dependencies:** Mock external dependencies to isolate the component being tested.\n*   **Test Boundary Conditions:** Test boundary conditions and edge cases to ensure that your code handles them correctly.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Write integration tests to test the interactions between different components of your game.\n*   **Use Realistic Scenarios:** Use realistic scenarios to test how the components work together in real-world situations.\n*   **Verify Data Flow:** Verify that data flows correctly between the components being tested.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Game:** Write end-to-end tests to test the entire game from start to finish.\n*   **Automate Testing:** Automate your end-to-end tests to ensure that they are run regularly.\n*   **Use a Testing Tool:** Use a testing tool such as Selenium or Appium to automate your end-to-end tests.\n\n### 5.4. Test Organization\n\n*   **Create a `test/` Directory:** Create a `test/` directory in your project to store your tests.\n*   **Mirror the Source Code Structure:** Mirror the source code structure in your test directory to make it easier to find the tests for a given component.\n*   **Use Descriptive Names:** Use descriptive names for your tests to make it clear what they are testing.\n*   **Keep Tests Short and Focused:** Keep your tests short and focused on testing a single aspect of the code.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mocks to Isolate Components:** Use mocks to replace external dependencies with controlled test doubles.\n*   **Use Stubs to Provide Predefined Responses:** Use stubs to provide predefined responses to external dependencies.\n*   **Use a Mocking Framework:** Use a mocking framework such as Moq or NSubstitute to create mocks and stubs easily.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Forgetting to Connect Signals:**  Ensure that you connect signals to their handlers correctly. A common mistake is to connect the signal within the editor but forget to connect dynamically created signals in code.\n*   **Incorrect Node Paths:** Double-check node paths when using `get_node()`. Incorrect paths will lead to `null` references and errors.\n*   **Not Freeing Resources:** Remember to free resources when they are no longer needed to prevent memory leaks.\n*   **Using Global Variables Excessively:** Avoid using global variables excessively, as this can make your code difficult to maintain and debug.\n*   **Ignoring the Godot Documentation:** The Godot documentation is a valuable resource. Consult it frequently to learn about new features and best practices.\n\n### 6.2. Edge Cases\n\n*   **Floating-Point Precision:** Be aware of floating-point precision issues when comparing floating-point numbers. Use `is_equal_approx()` instead of `==`.\n*   **Race Conditions:** Be aware of race conditions when using threads. Use locks and other synchronization primitives to prevent data corruption.\n*   **Resource Loading Errors:** Handle resource loading errors gracefully.  Use `is_valid()` to check if a resource loaded successfully.\n*   **Input Events:**  Understand the difference between different input event types (e.g., `InputEventKey`, `InputEventMouseButton`) and handle them accordingly.\n\n### 6.3. Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between Godot versions. Consult the changelog when upgrading to a new version.\n*   **GDScript Compatibility:** Ensure that your GDScript code is compatible with the Godot version you are using.\n*   **C# Version Compatibility:** Be aware of the C# version supported by your Godot version. Ensure your code is compatible. Older versions of Godot are tied to older C# versions, new versions are tied to .NET.\n\n### 6.4. Compatibility Concerns\n\n*   **Platform-Specific Code:** Use platform-specific code sparingly. Use conditional compilation or separate scripts for platform-specific functionality.\n*   **Graphics Driver Compatibility:** Test your game on different graphics drivers to ensure that it works correctly.\n*   **Hardware Compatibility:** Test your game on different hardware configurations to ensure that it runs smoothly.\n\n### 6.5. Debugging Strategies\n\n*   **Use the Godot Editor Debugger:** Use the Godot editor debugger to step through your code and inspect variables.\n*   **Use `print()` Statements:** Use `print()` statements to log information to the console.\n*   **Use the Remote Debugger:** Use the remote debugger to debug your game on a different device.\n*   **Attach a C# Debugger:** Attach a C# debugger (e.g., Visual Studio Debugger) to your project to debug C# code.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Godot Editor:** The official Godot Engine editor.\n*   **Visual Studio Code:** A popular code editor with excellent support for GDScript and C#.\n*   **Visual Studio:** A powerful IDE for C# development, commonly used for Godot C# projects.\n*   **Git:** A version control system for tracking changes to your code.\n*   **GitHub/GitLab/Bitbucket:** Online repositories for storing and collaborating on your code.\n\n### 7.2. Build Configuration\n\n*   **Project Settings:** Configure your project settings carefully, including input maps, rendering settings, and export settings.\n*   **Custom Build Steps:** Use custom build steps to automate tasks such as asset processing and code generation.\n*   **Export Templates:** Create export templates for different platforms to optimize your game for each platform.\n\n### 7.3. Linting and Formatting\n\n*   **GDScript Linter:** Use a GDScript linter to check your code for style errors and potential problems.  Consider creating a custom linter rule set.\n*   **C# Code Style:** Configure Visual Studio or VS Code to automatically format your C# code according to the C# coding conventions.\n*   **EditorConfig:** Use an EditorConfig file to define coding style settings for your project.\n\n### 7.4. Deployment\n\n*   **Exporting:** Use Godot's export functionality to create builds for different platforms.\n*   **Distribution Platforms:** Distribute your game through platforms such as Steam, Itch.io, Google Play Store, and Apple App Store.\n*   **Consider platform-specific requirements:** Each platform has specific requirements for builds. For example, you will need developer accounts, store assets, and signed builds.\n*   **Auto-updating:** Using auto-updating on desktop builds can improve the player experience for long running projects.\n\n### 7.5. CI/CD Integration\n\n*   **Automated Builds:** Set up a CI/CD pipeline to automatically build and test your game whenever you commit changes to your code repository.\n*   **Automated Testing:** Integrate your unit tests, integration tests, and end-to-end tests into your CI/CD pipeline.\n*   **Automated Deployment:** Automate the deployment of your game to different distribution platforms.\n*   **Use cloud build services:** Services such as GitHub actions, GitLab CI, and cloud build are capable of fully automating the deployment process.\n\n## 8. GDScript Style Guide Summary\n\nThis section summarizes key GDScript style guide recommendations.\n\n*   **Formatting:**\n    *   Use LF line endings, UTF-8 encoding, and tabs for indentation (editor default).\n    *   Limit line length to 100 characters (preferably 80).\n    *   Use one statement per line.\n    *   Format multiline statements for readability using parentheses.\n    *   Avoid unnecessary parentheses.\n    *   Use plain English boolean operators (`and`, `or`, `not`).\n    *   Use whitespace around operators and after commas.\n    *   Use double quotes for strings unless single quotes avoid escapes.\n    *   Don't omit leading or trailing zeros in floating-point numbers.\n    *   Use lowercase for letters in hexadecimal numbers.\n    *   Use underscores in literals for large numbers.\n*   **Naming Conventions:**\n    *   Files: `snake_case.gd`\n    *   Classes: `PascalCase`\n    *   Nodes: `PascalCase`\n    *   Functions: `snake_case`\n    *   Variables: `snake_case`\n    *   Signals: `snake_case` (past tense)\n    *   Constants: `CONSTANT_CASE`\n    *   Enums: `PascalCase` (names), `CONSTANT_CASE` (members)\n*   **Code Order (within a script):**\n    1.  `@tool`\n    2.  `class_name`\n    3.  `extends`\n    4.  Docstring (`## comment`)\n    5.  Signals\n    6.  Enums\n    7.  Constants\n    8.  `@export` variables\n    9.  Public variables\n    10. Private variables\n    11. `@onready` variables\n    12. `_init()`\n    13. `_enter_tree()`\n    14. `_ready()`\n    15. Other virtual methods\n    16. Public methods\n    17. Private methods\n    18. Subclasses\n*   **Static Typing:**\n    *   Use explicit type hints (`: Type`) when the type is ambiguous or for clarity.\n    *   Use inferred types (`:=`) when the type is obvious from the assignment.\n\nBy following these best practices and coding standards, you can create more maintainable, efficient, and secure Godot Engine projects.",
    "metadata": {
      "globs": "*.gd",
      "format": "mdc",
      "originalFile": "godot.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "godot",
      "comprehensive",
      "coding",
      "standards",
      "best",
      "practices",
      "engine",
      "development",
      "covering",
      "code",
      "go",
      "backend",
      "performance",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "godot",
        "go",
        "golang",
        "backend",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-google-maps-js",
    "description": "This rule provides guidelines for Google Maps JavaScript API development, covering code organization, performance, security, testing, and common pitfalls. It promotes best practices to ensure efficient, secure, and maintainable map applications.",
    "author": "sanjeed5",
    "tags": [
      "google-maps-js",
      "go",
      "backend",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/google-maps-js.mdc",
    "content": "# Google Maps JavaScript API Best Practices\n\nThis document outlines best practices for developing applications using the Google Maps JavaScript API. Following these guidelines will help you create efficient, maintainable, and secure mapping solutions.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a clear and consistent directory structure to improve code maintainability and collaboration. A suggested structure is:\n\n\nproject-root/\n  src/\n    components/\n      MapComponent.js  # or .jsx, .ts, .tsx\n      MarkerComponent.js\n      InfoWindowComponent.js\n    services/\n      mapService.js     # Handles API calls and data processing\n      geolocationService.js\n    utils/\n      utils.js          # Helper functions\n    styles/\n      MapComponent.css\n    App.js            # Main application component\n  public/\n    index.html      # HTML entry point\n  .env              # API keys and environment variables\n  package.json      # Dependencies and scripts\n  webpack.config.js # or equivalent\n\n\n### 1.2. File Naming Conventions\n\n*   **Components:** Use PascalCase (e.g., `MapComponent.js`).\n*   **Services/Utilities:** Use camelCase (e.g., `mapService.js`, `geolocationService.js`).\n*   **Styles:** Match component names (e.g., `MapComponent.css`).\n*   **Images/Assets:** Use kebab-case (e.g., `custom-marker.png`).\n\n### 1.3. Module Organization\n\n*   **ES Modules:** Use `import` and `export` for modularity.\n*   **Single Responsibility Principle:** Each module should have a specific purpose.\n*   **Avoid Circular Dependencies:** Refactor code to eliminate circular dependencies between modules.\n\n### 1.4. Component Architecture\n\n*   **Component-Based Approach:** Break down the UI into reusable components (Map, Marker, InfoWindow, etc.).\n*   **Presentational and Container Components:** Separate concerns: presentational components focus on UI, while container components handle logic and data.\n*   **Props and State:** Use props to pass data down to components and state to manage component-specific data.\n\n### 1.5. Code Splitting\n\n*   **Dynamic Imports:** Use dynamic imports (`import()`) to load map-related code chunks on demand.\n*   **Webpack/Parcel/Rollup:** Configure your bundler to create separate chunks for different parts of the application.\n*   **Route-Based Splitting:** If the map is only used on specific routes, load the map-related code only when the route is accessed.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Observer Pattern:** Use the Observer pattern to handle map events (e.g., marker clicks, map bounds changes). This decouples event sources from event handlers.\n*   **Singleton Pattern:** Use a Singleton pattern (carefully) for global map services to ensure a single instance across the application. Be mindful of testability.\n*   **Factory Pattern:** Employ the Factory pattern to create different types of markers or overlays based on data.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Loading the API:** Asynchronously load the Google Maps JavaScript API using a Promise. Use `async/await` syntax for cleaner code.\n*   **Marker Management:** Use a data-driven approach for marker creation and updates. Store marker data in an array and iterate over it to create markers.\n*   **InfoWindows:** Create InfoWindow instances outside of loops to avoid memory leaks. Update the content of the existing InfoWindow instead of creating new ones.\n*   **Event Handling:** Use event listeners provided by the API (e.g., `map.addListener('click', ...)`). Avoid inline event handlers.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Direct DOM Manipulation:** Avoid directly manipulating the DOM inside map components. Use the API's methods for adding and updating elements.\n*   **Global Variables:** Minimize the use of global variables to prevent naming conflicts and improve code encapsulation.\n*   **Nested Callbacks:** Avoid deeply nested callbacks (callback hell). Use Promises and `async/await` for asynchronous operations.\n*   **Tight Coupling:** Design components to be loosely coupled, making them easier to test and reuse.\n\n### 2.4. State Management\n\n*   **Local Component State:** Use React's `useState` hook or similar for component-specific state.\n*   **Context API:** Use the Context API for sharing global map configurations or data across components.\n*   **Redux/Mobx:** For larger applications, consider using a state management library like Redux or Mobx to manage complex application state.\n\n### 2.5. Error Handling\n\n*   **API Loading Errors:** Handle errors that occur during API loading (e.g., invalid API key, network issues).\n*   **Geolocation Errors:** Gracefully handle geolocation errors (e.g., user denied permission, browser doesn't support geolocation).\n*   **Try-Catch Blocks:** Use `try-catch` blocks to catch and handle exceptions during API calls and data processing.\n*   **User Notifications:** Display user-friendly error messages instead of crashing the application.\n*   **Logging:** Implement logging to track errors and debug issues.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Raster Images for Markers:** Use raster images (PNG, JPG) instead of SVG for a large number of custom markers (hundreds or more) for optimal performance.\n*   **Marker Clustering:** Implement marker clustering for maps with a high density of markers. Libraries like `markerclustererplus` can help.\n*   **Viewport Optimization:** Only render markers and overlays that are visible within the current viewport (map bounds). This reduces the number of DOM elements and improves rendering performance.\n*   **Debouncing/Throttling:** Use debouncing or throttling to limit the frequency of map updates in response to user interactions (e.g., panning, zooming).\n*   **Custom Overlays Judiciously:** Be mindful when using custom overlays. Avoid heavy computations in the `OverlayView.draw()` method, as it's called on every pan and zoom. Defer adding and removing content until the map is stationary.\n\n### 3.2. Memory Management\n\n*   **Remove Event Listeners:** Remove event listeners when they are no longer needed to prevent memory leaks.\n*   **Release Resources:** Release resources (e.g., marker instances, InfoWindow instances) when they are no longer in use.\n*   **Avoid Unnecessary DOM Updates:** Minimize the number of DOM updates to improve rendering performance.\n\n### 3.3. Rendering Optimization\n\n*   **Hardware Acceleration:** Ensure that hardware acceleration is enabled in the browser for smoother map rendering.\n*   **CSS Transitions:** Use CSS transitions for smooth animations when updating map elements.\n*   **WebGL:** Explore WebGL features for advanced visualizations and rendering (if applicable).\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from the bundle. Ensure your bundler is configured correctly for tree shaking.\n*   **Code Splitting:** Split the code into smaller chunks to reduce the initial load time.\n*   **Minification:** Minify the code to reduce the bundle size.\n*   **Compression:** Compress the bundle using Gzip or Brotli.\n\n### 3.5. Lazy Loading\n\n*   **Lazy Loading of Map Component:** Load the map component only when it is needed (e.g., when a specific route is accessed).\n*   **Lazy Loading of Markers:** Load markers only when they are visible within the viewport.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **API Key Exposure:** Protect your API key and prevent it from being exposed in client-side code or version control. Restrict API key usage to specific domains or IP addresses.\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n*   **Clickjacking:** Protect against clickjacking attacks by setting the `X-Frame-Options` header.\n*   **Data Injection:** Validate data received from the Google Maps API to prevent data injection attacks.\n\n### 4.2. Input Validation\n\n*   **Validate User Input:** Validate user input (e.g., addresses, coordinates) before passing it to the Google Maps API.\n*   **Sanitize Data:** Sanitize data received from the Google Maps API before displaying it to the user.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of the API.\n\n### 4.3. Authentication and Authorization\n\n*   **Secure API Key Storage:** Never store API keys directly in client-side code. Use environment variables or a backend proxy to manage API keys.\n*   **Restrict API Key Usage:** Restrict API key usage to specific domains or IP addresses in the Google Cloud Console.\n*   **Backend Authentication:** Implement backend authentication for sensitive operations (e.g., geocoding, directions). This prevents unauthorized access to the API.\n\n### 4.4. Data Protection\n\n*   **HTTPS:** Always use HTTPS to encrypt data transmitted between the client and the server.\n*   **Data Encryption:** Encrypt sensitive data stored on the server.\n*   **Data Minimization:** Only collect and store the data that is necessary for the application.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Always use HTTPS for API requests.\n*   **Validate Responses:** Validate the responses received from the API.\n*   **Handle Errors:** Properly handle errors returned by the API.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Write unit tests for individual map components (MapComponent, MarkerComponent, etc.).\n*   **Mock API Calls:** Mock API calls to isolate components from external dependencies.\n*   **Test Event Handling:** Test event handling logic (e.g., marker click events).\n\n### 5.2. Integration Testing\n\n*   **Test Component Interactions:** Write integration tests to verify that components work together correctly.\n*   **Test API Integrations:** Test the integration with the Google Maps API.\n*   **Use a Test Environment:** Use a test environment to avoid making changes to the production environment.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate User Interactions:** Simulate user interactions to test the entire application flow.\n*   **Verify Functionality:** Verify that the application functions as expected.\n*   **Use a Testing Framework:** Use a testing framework like Cypress or Puppeteer for end-to-end testing.\n\n### 5.4. Test Organization\n\n*   **Directory Structure:** Maintain a clear directory structure for tests.\n*   **Test Naming:** Use descriptive names for tests.\n*   **Test Descriptions:** Provide clear descriptions of what each test does.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock the Google Maps API:** Mock the Google Maps API to isolate components during testing.\n*   **Use Mocking Libraries:** Use mocking libraries like Jest or Sinon to create mocks and stubs.\n*   **Control Test Data:** Use stubs to control the data returned by the API during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Forgetting to Enable Billing:** Ensure that billing is enabled for your Google Maps Platform project.\n*   **Exceeding API Usage Limits:** Monitor API usage and optimize code to avoid exceeding usage limits.\n*   **Using Deprecated Features:** Avoid using deprecated features of the API.\n*   **Ignoring Browser Compatibility:** Test the application in different browsers to ensure compatibility.\n\n### 6.2. Edge Cases\n\n*   **Handling No Geolocation Support:** Gracefully handle the case where the browser doesn't support geolocation.\n*   **Handling Network Errors:** Handle network errors that occur during API calls.\n*   **Handling Invalid Data:** Handle invalid data returned by the API.\n\n### 6.3. Version-Specific Issues\n\n*   **Check the API Version:** Be aware of the API version you are using and any version-specific issues.\n*   **Read the Release Notes:** Read the release notes for new versions of the API to be aware of any changes.\n\n### 6.4. Compatibility Concerns\n\n*   **Library Conflicts:** Avoid using libraries that are known to conflict with the Google Maps JavaScript API (e.g., Prototype, older versions of MooTools and DateJS).\n*   **CSS Conflicts:** Avoid CSS conflicts by using specific CSS classes for map elements and avoiding overriding internal API styles.\n\n### 6.5. Debugging Strategies\n\n*   **Use Browser Developer Tools:** Use browser developer tools to debug JavaScript code, inspect network requests, and analyze performance.\n*   **Check the Console:** Check the console for error messages and warnings.\n*   **Use Debugging Tools:** Use debugging tools like `console.log` or a debugger to step through the code and inspect variables.\n*   **Read the Documentation:** Refer to the Google Maps JavaScript API documentation for troubleshooting information.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Code Editor:** Use a code editor like VS Code, Sublime Text, or Atom.\n*   **Browser Developer Tools:** Use browser developer tools for debugging and performance analysis.\n*   **Bundler:** Use a bundler like Webpack, Parcel, or Rollup.\n*   **Linting Tools:** Use linting tools like ESLint to enforce code style and identify potential errors.\n\n### 7.2. Build Configuration\n\n*   **Configure the Bundler:** Configure the bundler to optimize code for production (e.g., minification, compression).\n*   **Use Environment Variables:** Use environment variables to manage API keys and other configuration settings.\n*   **Set Up Build Scripts:** Set up build scripts to automate the build process.\n\n### 7.3. Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce code style and identify potential errors.\n*   **Prettier:** Use Prettier to automatically format code.\n*   **Code Style Guide:** Follow a consistent code style guide (e.g., Airbnb, Google).\n\n### 7.4. Deployment\n\n*   **Deploy to a Web Server:** Deploy the application to a web server (e.g., Netlify, Vercel, AWS S3).\n*   **Use HTTPS:** Ensure that the application is served over HTTPS.\n*   **Configure Caching:** Configure caching to improve performance.\n\n### 7.5. CI/CD Integration\n\n*   **Set Up a CI/CD Pipeline:** Set up a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Use a CI/CD Tool:** Use a CI/CD tool like Jenkins, Travis CI, or CircleCI.\n*   **Automated Testing:** Automate testing as part of the CI/CD pipeline.\n\nBy following these best practices, you can develop robust, efficient, and maintainable Google Maps JavaScript API applications.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.html,*.css",
      "format": "mdc",
      "originalFile": "google-maps-js.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "google",
      "maps",
      "js",
      "this",
      "rule",
      "provides",
      "guidelines",
      "javascript",
      "development",
      "covering",
      "code",
      "google-maps-js",
      "go",
      "backend",
      "performance",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "google-maps-js",
        "go",
        "golang",
        "backend",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-gradle",
    "description": "Comprehensive rules for Gradle best practices, covering code organization, performance, security, testing, and more. Provides actionable guidance to improve Gradle project maintainability and efficiency.",
    "author": "sanjeed5",
    "tags": [
      "gradle",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/gradle.mdc",
    "content": "- **Use the Gradle Wrapper**: Always use the Gradle wrapper (`gradlew` and `gradlew.bat`) to ensure consistent Gradle versions across different environments. This avoids compatibility issues and simplifies collaboration.\n  - Command: `gradle wrapper` to generate the wrapper files.\n\n- **Organize Build Files**: Maintain a clear structure by separating project-level (`build.gradle` in the root) and module-level (`build.gradle` in each module) build files. Use `settings.gradle` (or `settings.gradle.kts` for Kotlin DSL) to define included modules.\n  - Improves performance by avoiding unnecessary directory searches.\n  - Ensures proper project inclusion in multi-module builds.\n\n- **Optimize Build Performance**: Employ several strategies to improve build speed:\n  - **Enable parallel builds**: Add `org.gradle.parallel=true` to `gradle.properties`.\n  - **Use build caching**: Add `org.gradle.caching=true` to `gradle.properties`.\n  - **Configure daemon**: Add `org.gradle.daemon=true` to `gradle.properties` (typically enabled by default).\n  - **Minimize dynamic dependencies**: Use fixed versions instead of ranges or `latest.release`.\n  - **Configure JVM Memory**: Set appropriate JVM memory in `gradle.properties` like `org.gradle.jvmargs=-Xmx4g -XX:MaxMetaspaceSize=1g`\n  - **Incremental build**: Avoid `gradle clean` unless absolutely necessary to leverage incremental build feature.\n  - **Configure task inputs and outputs**:  Declare task inputs and outputs properly to enable up-to-date checks and caching.\n\n- **Security Practices**: Protect sensitive information by:\n  - **Storing credentials in `gradle.properties`**: Exclude `gradle.properties` from version control (add it to `.gitignore`).\n  - **Using environment variables**: Access credentials from environment variables during the build process for CI/CD environments.\n  - **Avoiding hardcoding secrets**: Never hardcode API keys, passwords, or other sensitive data in build files or source code.\n\n- **Automate Code Standards**: Implement custom Gradle tasks or plugins to enforce coding standards:\n  - **Use linting tools**: Integrate linters (e.g., Checkstyle, SpotBugs, PMD) into the build process.\n  - **Enforce code formatting**: Use code formatters (e.g., ktlint for Kotlin) and enforce formatting rules.\n  - **Create custom tasks**: Define custom tasks to check for specific code patterns or enforce project-specific rules.\n\n- **Separate Source Files**: Organize source files by language (e.g., `src/main/java`, `src/main/kotlin`) and test type (e.g., `src/test/java`, `src/integrationTest/java`).\n  - Improves readability and maintainability.\n  - Enables independent execution of different test types.\n\n- **Use Standard Conventions**: Stick to Gradle's default conventions as much as possible.\n  - Simplifies project structure and reduces configuration overhead.\n  - Makes it easier for new developers to understand the project.\n\n- **Always Define a Settings File**: Include `settings.gradle` (or `settings.gradle.kts`) in the root directory to avoid performance impacts during project discovery.\n  - Explicitly defines the project name and included subprojects.\n\n- **Use `buildSrc` to Abstract Imperative Logic**: Encapsulate complex build logic in the `buildSrc` directory.\n  - `buildSrc` is treated as an included build, automatically compiled and added to the build script classpath.\n  - Provides a clean separation of concerns and improves code reusability.\n  - Easier to maintain, refactor, and test the code in `buildSrc`.\n\n- **Declare Properties in `gradle.properties` File**: Store build configuration properties in `gradle.properties` rather than in build scripts.\n  - Improves build script readability and maintainability.\n  - Allows for easy modification of build properties without changing the build script.\n\n- **Avoid Overlapping Task Outputs**: Ensure that tasks write outputs to unique directories to prevent conflicts and ensure proper up-to-date checking.\n  - Prevents Gradle's build cache from being compromised.\n\n- **Standardize Builds with a Custom Gradle Distribution**: Create a custom Gradle distribution with initialization scripts to enforce common conventions and rules across all projects in an organization.\n  - Ensures consistent build environments and simplifies maintenance.\n\n- **Stop Cleaning Your Project (Unless Necessary)**: Avoid running `gradle clean` unnecessarily, as it prevents Gradle from using incremental build features and significantly slows down the build process.\n\n- **Move Tasks to `buildSrc`**: Move custom task definitions to the `buildSrc` directory to keep build scripts clean and reusable.\n\n- **Run Tests in Parallel**: Enable parallel test execution to reduce test execution time:\n  - Add `maxParallelForks = <number_of_cores>` to the `test` task configuration in `build.gradle`.\n\n- **Version Your Project**: Use a versioning scheme (e.g., semantic versioning) to track changes and releases.\n  - Use plugins like `axion-release` to automate versioning based on Git tags.\n\n- **Encapsulate Task Declarations in a Plugin**: Move task declarations into custom Gradle plugins to promote reusability and reduce duplication.\n\n- **Use the Latest Gradle Version**: Keep Gradle updated to benefit from performance improvements, new features, and security patches.\n\n- **Optimize Your Repositories**: Declare repositories in the correct order to avoid unnecessary network requests.\n  - List frequently accessed repositories first.\n\n- **Never Commit Passwords**: Externalize credentials using `gradle.properties` or environment variables.\n\n- **Adopt Kotlin DSL**: Favor Kotlin DSL (`build.gradle.kts`) over Groovy DSL (`build.gradle`). Kotlin DSL provides type safety, better IDE support, and improved code completion.\n\n- **Dependency Management**: \n   - **Use dependency catalogs**: Define dependencies in a central `libs.versions.toml` file for consistent dependency management across modules (available with Gradle 7.4+).\n   - **Avoid dynamic versions**: Always use explicit dependency versions to ensure reproducible builds.\n   - **Check for dependency updates**: Use dependency analysis tools to identify outdated dependencies and security vulnerabilities.\n\n- **Code Organization and Structure (Expanded)**:\n   - **Directory Structure**:  Adhere to standard directory structures, such as `src/main/java` for Java source code, `src/main/resources` for resources, `src/test/java` for unit tests, and `src/integrationTest/java` for integration tests.\n   - **File Naming**: Follow consistent naming conventions for Gradle files (e.g., `build.gradle`, `settings.gradle`, `gradle.properties`).\n   - **Module Organization**: Organize projects into modules based on functionality or feature sets.  This promotes code reuse, improves build times, and allows for more granular dependency management.\n   - **Component Architecture**:  Consider using component-based architectures to isolate independent parts of your code.  Each component has its own build file, source folder, and dependencies. This promotes modularity and reusability.\n   - **Code Splitting**: Decompose complex build scripts and tasks into smaller, more manageable pieces.\n\n- **Common Patterns and Anti-patterns (Expanded)**:\n   - **Dependency Injection**: Leverage dependency injection frameworks (e.g., Dagger, Guice) to manage dependencies in custom tasks and plugins.\n   - **Declarative Configuration**: Prefer declarative configuration over imperative scripting. This promotes readability and simplifies maintenance.\n   - **Avoid Global State**:  Minimize the use of global state in custom tasks and plugins to prevent unintended side effects.\n   - **Tight Coupling**:  Avoid tight coupling between build logic and application code. This promotes modularity and testability.\n\n- **Performance Considerations (Expanded)**:\n   - **Configuration Avoidance**: Use `afterEvaluate` sparingly, as it can delay configuration and impact build performance.  Consider using configuration caching instead.\n   - **Task Ordering**: Ensure tasks are executed in the correct order. Inappropriate task dependencies slow down the build process.\n\n- **Testing Approaches (Expanded)**:\n   - **Test Organization**: Organize tests in a clear and consistent manner. Follow a similar directory structure as source code (e.g., `src/test/java`).\n   - **Test Doubles**: Use mocking and stubbing techniques to isolate units of code for testing. Libraries like Mockito and PowerMock facilitate test double creation.  Use carefully PowerMock, as can be problematic.\n\n- **Tooling and Environment (Expanded)**:\n   - **Android Studio**: Use Android Studio as the primary IDE for Android projects. It offers excellent Gradle integration and debugging support.\n   - **CI/CD Integration**: Integrate Gradle builds with CI/CD systems (e.g., Jenkins, GitLab CI, GitHub Actions) to automate testing and deployment processes.\n   - **Code Analysis Tools**: Integrate code analysis tools (e.g., SonarQube) into the build process to identify code quality issues and security vulnerabilities.\n   - **IDE plugins**: Use IDE plugins, such as the Gradle build scan plugin, to analyze and optimize build performance.\n\n- **Common Pitfalls and Gotchas (Expanded)**:\n  - **Dependency Conflicts**: Be aware of potential dependency conflicts and use dependency resolution strategies to manage them.\n  - **Cache Invalidation**: Understand how Gradle's build cache works and how to invalidate it when necessary.\n  - **Plugin Compatibility**: Ensure compatibility between Gradle versions and plugins.  Upgrade plugins carefully.\n  - **Daemon issues**: The gradle daemon sometime cause unexplainable build errors. Restarting or stopping it can solve some build issues.\n\n- **Android Specific Best Practices**:\n  - **Resource Management**: Optimize image resources to reduce APK size. Use vector drawables where possible.\n  - **Proguard/R8**: Use Proguard (or R8) to shrink and obfuscate code in release builds.\n  - **APK Analyzer**: Use APK Analyzer to inspect the contents of APK files and identify areas for optimization.\n  - **Build variants**: Use build variants to create different versions of the app for different purposes (e.g., debug, release, flavor-specific).\n\n- **Multi-project Builds**:\n   - **Centralized Dependency Management:**  Manage dependencies centrally within the root project or through a convention plugin, applying these dependencies to child modules.  This promotes consistency and simplifies dependency updates.\n   - **Convention Plugins:** Create custom plugins that apply common configurations (dependencies, plugins, settings) to all subprojects. This reduces code duplication and improves maintainability.\n   - **Composite Builds:** Use composite builds (including local projects in your build) for collaborative development or when working on multiple projects simultaneously.\n\n- **Kotlin DSL Specific Best Practices**:\n  - **Explicit Typing**: Use explicit typing to leverage Kotlin's type safety and improve code readability.\n  - **Extension Functions**: Define extension functions to extend the Gradle API and add custom functionality.\n  - **Coroutines:**  Utilize Kotlin coroutines for asynchronous operations in custom tasks and plugins.\n\n- **Monitoring and Observability**:\n  - **Gradle Build Scans:**  Use Gradle Build Scans (using `--scan`) to capture detailed build information, analyze performance bottlenecks, and identify areas for improvement.\n  - **Custom Metrics:** Implement custom metrics to track key build statistics (build duration, task execution times) and monitor build health.\n\n- **Continuous Improvement:**\n   - **Regular Audits:**  Perform regular audits of Gradle build configurations and scripts to identify areas for optimization and improvement.\n   - **Stay Updated:**  Keep abreast of the latest Gradle releases, best practices, and community recommendations.\n   - **Share Knowledge:**  Document Gradle build configurations, custom tasks, and plugins. Share knowledge and best practices with other team members.\n\nBy adhering to these best practices, developers can create robust, maintainable, and efficient Android applications using Gradle as their build tool.",
    "metadata": {
      "globs": "*.gradle*",
      "format": "mdc",
      "originalFile": "gradle.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "gradle",
      "comprehensive",
      "rules",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "gradle",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-grafana",
    "description": "Comprehensive guide for Grafana development best practices, covering code organization, performance, security, testing, and common pitfalls to ensure robust and maintainable Grafana solutions. Includes guidance for creating efficient dashboards, data sources, and plugins.",
    "author": "sanjeed5",
    "tags": [
      "grafana",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/grafana.mdc",
    "content": "By adhering to these comprehensive best practices, you can build robust, maintainable, and secure Grafana solutions that provide valuable insights into your data and systems.",
    "metadata": {
      "globs": "*.ts,*.tsx,*.js,*.jsx,*.json,*.yml,*.yaml,*.md,*.mdc",
      "format": "mdc",
      "originalFile": "grafana.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "grafana",
      "comprehensive",
      "guide",
      "development",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "grafana",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-graphql",
    "description": "This rule provides comprehensive best practices and coding standards for GraphQL development, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "graphql",
      "api",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/graphql.mdc",
    "content": "- **Naming Conventions**:\n  - Use `camelCase` for field names, argument names, and directive names. This is a widely accepted convention that enhances readability and consistency.\n  - Use the suffix `Input` when naming input types (e.g., `UserInput`). This clearly distinguishes input types from other types in your schema.\n  - Avoid verb prefixes like `get` in field names (e.g., use `users` instead of `getUsers`). This maintains clarity and consistency in your schema.\n\n- **Schema Design and Query Optimization**:\n  - Design your schema to prevent over-fetching or under-fetching of data. Use fragments to request only the necessary data.\n  - Use variables for parameters instead of hard-coded values. This enhances flexibility and maintainability, and allows for query caching.\n  - Implement pagination for large datasets to avoid overwhelming the client and improve performance.\n  - Use field aliases to rename fields in the response, which can be useful for backward compatibility or to simplify the client-side code.\n\n- **Code Organization and Structure**:\n  - **Directory Structure**: Organize your GraphQL schema files into a logical directory structure.  Consider grouping related types and resolvers together (e.g., `schemas/user/`, `resolvers/user/`).\n  - **File Naming Conventions**: Use descriptive names for schema files (e.g., `user.graphql`, `product.graphql`).\n  - **Module Organization**:  Break down your schema into smaller, reusable modules. Use schema stitching or federation to combine these modules into a single API.\n  - **Component Architecture**: If using a GraphQL client library like Apollo Client or Relay, structure your components to efficiently manage GraphQL queries and data fetching.\n\n- **Common Patterns and Anti-patterns**:\n  - **Design Patterns**: Consider using patterns like the Facade pattern to simplify complex resolvers or the DataLoader pattern to batch and cache data fetching.\n  - **Anti-patterns**: Avoid creating overly complex queries that fetch too much data in a single request.  Also avoid using deeply nested resolvers, as this can lead to performance issues.\n  - **State Management**:  Choose a state management solution that integrates well with your GraphQL client library.  Consider using Apollo Client's cache or Relay's store for client-side data management.\n  - **Error Handling**: Implement robust error handling in your resolvers.  Return user-friendly error messages and log detailed error information on the server.\n\n- **Performance Considerations**:\n  - **Optimization Techniques**: Use techniques like query batching, caching, and persisted queries to optimize performance.\n  - **Memory Management**: Be mindful of memory usage in your resolvers, especially when dealing with large datasets.\n  - **Lazy Loading**: Implement lazy loading for non-critical data to improve initial page load times.\n\n- **Security Best Practices**:\n  - **Input Validation**: Validate all user inputs to prevent injection attacks and other security vulnerabilities. Use appropriate data types and constraints in your schema.\n  - **Authentication and Authorization**: Implement strong authentication and authorization mechanisms to protect your API. Use role-based access control (RBAC) to restrict access to sensitive data.\n  - **Data Protection**: Protect sensitive data by encrypting it at rest and in transit. Use HTTPS to secure API communication.\n  - **Rate Limiting**: Implement rate limiting to prevent denial-of-service (DoS) attacks.\n  - **Query Complexity Analysis**: Limit the complexity of GraphQL queries to prevent malicious users from overloading the server. Tools like `graphql-cost-analysis` can help.\n\n- **Testing Approaches**:\n  - **Unit Testing**: Write unit tests for your resolvers to ensure they are functioning correctly.\n  - **Integration Testing**:  Write integration tests to verify that your GraphQL API integrates correctly with your data sources and other services.\n  - **End-to-end Testing**:  Write end-to-end tests to simulate user interactions with your API and verify that the entire system is working as expected.\n  - **Test Organization**: Organize your tests into a logical directory structure. Use clear and descriptive names for your test files.\n  - **Mocking and Stubbing**: Use mocking and stubbing to isolate your resolvers from external dependencies during testing.\n\n- **Common Pitfalls and Gotchas**:\n  - **N+1 Problem**: Be aware of the N+1 problem, where fetching a list of items requires N additional queries to fetch related data. Use DataLoader to batch and cache these queries.\n  - **Circular Dependencies**: Avoid circular dependencies between your schema types, as this can lead to errors.\n\n- **Tooling and Environment**:\n  - **Recommended Development Tools**: Use tools like GraphQL Playground or GraphiQL for exploring and testing your API. Consider using a GraphQL IDE like Apollo Studio or Altair GraphQL Client for advanced features.\n  - **Linting and Formatting**: Use a GraphQL linter and formatter to enforce code style and prevent errors.  Consider using ESLint with the `eslint-plugin-graphql` plugin.\n  - **Deployment Best Practices**:  Deploy your GraphQL API behind a CDN to improve performance and availability.  Use a GraphQL gateway to manage authentication, authorization, and rate limiting.\n  - **CI/CD Integration**: Integrate your GraphQL API into your CI/CD pipeline to automate testing and deployment.",
    "metadata": {
      "globs": "*.graphql",
      "format": "mdc",
      "originalFile": "graphql.mdc"
    },
    "subcategory": "other",
    "keywords": [
      "cursor",
      "graphql",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "development",
      "api",
      "backend",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "other"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "graphql",
        "api",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-guzzle",
    "description": "This rule provides comprehensive guidelines for using the Guzzle HTTP client in PHP projects, covering code organization, common patterns, performance, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "guzzle",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/guzzle.mdc",
    "content": "By following these best practices, you can ensure that your Guzzle-based code is efficient, maintainable, secure, and reliable.",
    "metadata": {
      "globs": "*.php",
      "format": "mdc",
      "originalFile": "guzzle.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "guzzle",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "using",
      "http",
      "client",
      "projects",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "guzzle",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-hardhat",
    "description": "This rule outlines best practices for Hardhat development, covering code organization, security, testing, and performance. It aims to provide a comprehensive guide for developers working with the Hardhat Ethereum development environment.",
    "author": "sanjeed5",
    "tags": [
      "hardhat",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/hardhat.mdc",
    "content": "# Hardhat Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to best practices for developing smart contracts and decentralized applications (dApps) using Hardhat. It covers code organization, security, testing, performance, and other essential aspects of Hardhat development.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n\nhardhat-project/\n├── contracts/          # Solidity smart contracts\n│   ├── MyContract.sol\n│   └── ...\n├── scripts/            # Deployment and interaction scripts\n│   ├── deploy.js\n│   ├── interact.js\n│   └── ...\n├── test/               # Unit and integration tests\n│   ├── MyContract.test.js\n│   └── ...\n├── hardhat.config.js   # Hardhat configuration file\n├── package.json        # Node.js package file\n├── README.md           # Project documentation\n└── .gitignore          # Git ignore file\n\n\n-   **contracts/:**  Store all Solidity smart contracts in this directory.  Consider subdirectories for different modules or features.\n-   **scripts/:**  Keep deployment, interaction, and other utility scripts in this directory.  Organize scripts by function or deployment environment.\n-   **test/:**  Place all unit and integration tests in this directory.  Mirror the `contracts/` directory structure for test files.\n-   **hardhat.config.js:**  Configure Hardhat settings in this file, including compiler versions, network configurations, and task definitions. Consider using TypeScript.\n-   **package.json:**  Manage project dependencies and scripts using npm or yarn.\n-   **README.md:**  Provide clear and concise documentation for your project.\n-   **.gitignore:** Exclude unnecessary files from source control (e.g., build artifacts, node_modules).\n\n### 1.2. File Naming Conventions\n\n-   **Solidity Files:** Use PascalCase with the `.sol` extension for Solidity contract files (e.g., `MyContract.sol`).\n-   **JavaScript/TypeScript Files:** Use camelCase with the `.js` or `.ts` extension for JavaScript/TypeScript files (e.g., `deploy.js`, `myContract.test.ts`).\n-   **Test Files:**  Use the `.test.js` or `.test.ts` suffix to identify test files (e.g., `MyContract.test.js`).\n\n### 1.3. Module Organization\n\n-   **Separate Concerns:**  Divide your contracts into logical modules or components based on their functionality.\n-   **Interfaces:**  Use interfaces to define the public API of your contracts.\n-   **Libraries:**  Create reusable libraries for common functionalities to avoid code duplication.\n-   **Abstract Contracts:**  Use abstract contracts to define common logic and state variables for related contracts.\n\n### 1.4. Component Architecture\n\n-   **Modular Design:** Design contracts as independent, reusable components.\n-   **Composition:** Combine smaller components to create more complex systems.\n-   **Minimal Dependencies:** Reduce dependencies between components to improve maintainability and testability.\n\n### 1.5. Code Splitting Strategies\n\n-   **Separate Logic and Data:**  Keep contract logic separate from data storage to improve readability and maintainability.\n-   **External Libraries:**  Utilize external libraries (e.g., OpenZeppelin) for common functionalities to reduce code size and improve security.\n-   **Proxy Patterns:**  Consider using proxy patterns to enable upgradeability and code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Hardhat/Solidity\n\n-   **Ownable:**  Control access to privileged functions using the Ownable pattern (from OpenZeppelin).\n-   **Pausable:**  Implement a Pausable contract to temporarily halt contract functionality in case of emergencies.\n-   **Pull over Push:**  Favor pull-based payment mechanisms over push-based mechanisms to mitigate reentrancy attacks.\n-   **Proxy patterns (e.g., UUPS, Transparent Proxy):** For contract upgrades.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Deployment:**  Use Hardhat's deployment scripts and network configurations to automate contract deployment.\n-   **Testing:**  Employ Hardhat's testing framework and Chai matchers for comprehensive unit and integration testing.\n-   **Interaction:**  Utilize Hardhat's console and Ethers.js for interacting with deployed contracts.\n-   **Verification:**  Verify contract source code on Etherscan to enhance transparency and trust.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n-   **Unchecked Arithmetic:**  Use SafeMath or Solidity 0.8+ to prevent integer overflow/underflow.\n-   **Reentrancy:**  Protect against reentrancy attacks by using the Checks-Effects-Interactions pattern or reentrancy guards (from OpenZeppelin).\n-   **Denial of Service (DoS):**  Avoid patterns that can lead to DoS attacks, such as unbounded loops or expensive operations.\n-   **Timestamp Dependence:**  Avoid relying on block timestamps for critical logic, as they can be manipulated by miners.\n-   **Insufficient Gas Limits:** Ensure functions have sufficient gas limits, especially for complex operations.\n-   **Hardcoding Addresses/Values:** Use configuration files or environment variables for addresses and other configurable values.\n\n### 2.4. State Management Best Practices\n\n-   **Minimize State Variables:**  Reduce the number of state variables to minimize storage costs and improve performance.\n-   **Use Appropriate Data Types:** Choose the most efficient data types for state variables (e.g., `uint256` instead of `uint`).\n-   **Immutability:** Use `immutable` variables when the value is assigned at construction and never changed after.\n-   **Constants:** Use `constant` variables for gas optimization when the value is known at compile time and never changed after.\n-   **Events:**  Emit events to track state changes and enable off-chain monitoring.\n\n### 2.5. Error Handling Patterns\n\n-   **Require Statements:**  Use `require` statements to validate inputs and enforce preconditions.\n-   **Revert Statements:**  Use `revert` statements to handle exceptional conditions and return informative error messages.\n-   **Custom Errors:** Use custom errors (Solidity 0.8.4+) for gas optimization and detailed error reporting.\n-   **Try/Catch (Solidity 0.8.16+):** Implement Try/Catch blocks when calling external contracts.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Gas Optimization:**  Minimize gas consumption to reduce transaction costs.\n-   **Data Packing:**  Pack multiple small variables into a single storage slot to reduce storage costs.\n-   **Short Circuiting:**  Use short-circuiting evaluation in logical expressions to avoid unnecessary computations.\n-   **Assembly Optimization:**  Use inline assembly for performance-critical sections of code.\n-   **Caching:** Cache values that are frequently accessed.\n\n### 3.2. Memory Management\n\n-   **Minimize Memory Usage:**  Reduce memory usage to avoid out-of-gas errors.\n-   **Storage vs. Memory:**  Use storage for persistent data and memory for temporary data.\n-   **Delete Unused Variables:** Delete variables in memory after use to free up space.\n\n### 3.3. Rendering Optimization (If applicable - for frontend DApps)\n\n-   **Lazy Loading:**  Load components and data only when they are needed.\n-   **Virtualization:**  Use virtualization techniques to render large lists efficiently.\n-   **Memoization:**  Memoize computationally expensive functions to avoid redundant calculations.\n\n### 3.4. Bundle Size Optimization (If applicable - for frontend DApps)\n\n-   **Code Splitting:**  Split the application code into smaller bundles to improve initial load time.\n-   **Tree Shaking:**  Remove unused code from the bundle using tree shaking.\n-   **Minification:**  Minify JavaScript and CSS files to reduce bundle size.\n\n### 3.5. Lazy Loading Strategies (If applicable - for frontend DApps)\n\n-   **Dynamic Imports:**  Use dynamic imports to load modules on demand.\n-   **Intersection Observer:**  Use the Intersection Observer API to load resources when they become visible.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n-   **Reentrancy:** Use Checks-Effects-Interactions pattern. Employ reentrancy guards (@openzeppelin/contracts/security/ReentrancyGuard.sol).\n-   **Integer Overflow/Underflow:** Use SafeMath or Solidity 0.8+.\n-   **Denial of Service (DoS):**  Limit gas costs, avoid unbounded loops, and implement rate limiting.\n-   **Timestamp Dependence:**  Avoid relying on block timestamps for critical logic.\n-   **Front Running:**  Design contracts to be resilient to front-running attacks.\n-   **Signature Replay:** Prevent signature replay attacks by using nonces or other unique identifiers.\n-   **Cross-Site Scripting (XSS):**  Sanitize user inputs in frontend DApps to prevent XSS attacks.\n-   **SQL Injection:**  Use parameterized queries to prevent SQL injection attacks in backend systems.\n-   **Improper Access Control:**  Enforce strict access control policies to protect sensitive data and functions.\n\n### 4.2. Input Validation\n\n-   **Sanitize Inputs:**  Sanitize and validate all user inputs to prevent malicious data from entering the system.\n-   **Check Data Types:**  Verify that inputs are of the expected data types.\n-   **Limit Input Length:**  Restrict the length of input strings to prevent buffer overflows.\n-   **Regular Expressions:**  Use regular expressions to validate complex input patterns.\n\n### 4.3. Authentication and Authorization Patterns\n\n-   **Role-Based Access Control (RBAC):**  Implement RBAC to manage user permissions.\n-   **Attribute-Based Access Control (ABAC):**  Use ABAC for more fine-grained access control.\n-   **Multi-Factor Authentication (MFA):**  Implement MFA to enhance security.\n-   **OAuth:**  Use OAuth for secure delegation of access to third-party applications.\n\n### 4.4. Data Protection Strategies\n\n-   **Encryption:**  Encrypt sensitive data at rest and in transit.\n-   **Hashing:**  Use hashing to store passwords securely.\n-   **Salting:**  Salt passwords to prevent rainbow table attacks.\n-   **Key Management:**  Implement secure key management practices.\n\n### 4.5. Secure API Communication (If applicable - for backend systems)\n\n-   **HTTPS:**  Use HTTPS for all API communication.\n-   **API Keys:**  Use API keys to authenticate API requests.\n-   **Rate Limiting:**  Implement rate limiting to prevent abuse.\n-   **Input Validation:** Validate and sanitize all API inputs.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n-   **Test Driven Development (TDD):**  Write tests before writing code.\n-   **Black Box Testing:**  Test the functionality of the contract without knowledge of the internal implementation.\n-   **White Box Testing:**  Test the internal implementation of the contract, including branches and loops.\n-   **Coverage Analysis:**  Use coverage analysis tools to ensure that all code is covered by tests.\n\n### 5.2. Integration Testing\n\n-   **Test Contract Interactions:**  Test the interactions between multiple contracts.\n-   **Test External Dependencies:**  Test the integration with external dependencies, such as oracles or other smart contracts.\n\n### 5.3. End-to-End Testing (If applicable - for frontend DApps)\n\n-   **Simulate User Flows:**  Simulate real-world user flows to test the entire application stack.\n-   **Automated Testing:**  Use automated testing tools to run end-to-end tests regularly.\n\n### 5.4. Test Organization\n\n-   **Arrange-Act-Assert:**  Organize tests using the Arrange-Act-Assert pattern.\n-   **Descriptive Test Names:**  Use descriptive names for tests to clearly indicate their purpose.\n-   **Test Suites:**  Group related tests into test suites.\n\n### 5.5. Mocking and Stubbing\n\n-   **Mock External Dependencies:**  Use mocking to isolate contracts from external dependencies during testing.\n-   **Stub Function Calls:**  Use stubbing to replace function calls with predefined values or behaviors.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n-   **Incorrectly handling gas costs**\n-   **Failing to validate inputs**\n-   **Ignoring security best practices**\n-   **Not writing enough tests**\n-   **Misunderstanding Ethereum's execution model**\n-   **Not using the latest compiler version**\n\n### 6.2. Edge Cases to Be Aware Of\n\n-   **Integer overflow/underflow**\n-   **Reentrancy attacks**\n-   **Denial-of-service attacks**\n-   **Front-running attacks**\n-   **Signature replay attacks**\n\n### 6.3. Version-Specific Issues\n\n-   **Solidity compiler bugs:** Be aware of known bugs in the Solidity compiler and use appropriate workarounds.\n-   **Hardhat version compatibility:** Ensure that Hardhat and its plugins are compatible with each other.\n\n### 6.4. Compatibility Concerns\n\n-   **EVM version compatibility:**  Consider the target EVM version when developing contracts.\n-   **Web3.js/Ethers.js compatibility:** Ensure compatibility with the chosen JavaScript library for interacting with the blockchain.\n\n### 6.5. Debugging Strategies\n\n-   **Console.log:**  Use `console.log` statements to debug code.\n-   **Hardhat console:** Use the Hardhat console for interactive debugging.\n-   **Truffle debugger:**  Use the Truffle debugger for more advanced debugging.\n-   **Remix IDE:** Use Remix IDE for online debugging.\n-   **Solidity stack traces:**  Use Solidity stack traces to identify the source of errors.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **Hardhat:**  Ethereum development environment.\n-   **Visual Studio Code:**  Code editor with Solidity support.\n-   **Remix IDE:**  Online Solidity IDE.\n-   **Etherscan:**  Blockchain explorer.\n-   **Ganache:**  Local Ethereum blockchain.\n-   **OpenZeppelin:** Secure smart contract libraries.\n\n### 7.2. Build Configuration\n\n-   **Hardhat configuration file:**  Configure Hardhat settings in the `hardhat.config.js` file.\n-   **Compiler version:**  Specify the Solidity compiler version in the Hardhat configuration file.\n-   **Optimization settings:** Configure optimization settings in the Hardhat configuration file.\n\n### 7.3. Linting and Formatting\n\n-   **Solhint:**  Solidity linter.\n-   **Prettier:**  Code formatter.\n-   **ESLint:**  JavaScript/TypeScript linter.\n\n### 7.4. Deployment Best Practices\n\n-   **Automated deployments:**  Use Hardhat's deployment scripts to automate contract deployment.\n-   **Network configurations:**  Configure network settings in the Hardhat configuration file.\n-   **Gas price estimation:** Estimate gas prices before deploying contracts.\n-   **Contract verification:**  Verify contract source code on Etherscan after deployment.\n\n### 7.5. CI/CD Integration\n\n-   **Continuous integration:**  Integrate Hardhat with CI/CD systems (e.g., GitHub Actions, Jenkins) to automate testing and deployment.",
    "metadata": {
      "globs": "*.js,*.ts,*.sol,*.json",
      "format": "mdc",
      "originalFile": "hardhat.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "hardhat",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "hardhat",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-heroku",
    "description": "Comprehensive best practices and coding standards for developing, deploying, and maintaining applications on the Heroku platform. This rule emphasizes the Twelve-Factor App methodology and provides detailed guidance for optimizing application architecture, performance, security, and maintainability on Heroku.",
    "author": "sanjeed5",
    "tags": [
      "heroku",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/heroku.mdc",
    "content": "- Follow the Twelve-Factor App methodology for building software-as-a-service applications.\n  - **Codebase:** Maintain a single codebase tracked in version control (e.g., Git) for each application. Multiple deploys should be created from this single codebase.\n  - **Dependencies:** Explicitly declare and isolate dependencies using a dependency management tool (e.g., `requirements.txt` for Python, `package.json` for Node.js, `Gemfile` for Ruby).\n  - **Config:** Store configuration settings (database credentials, API keys, etc.) in environment variables. Avoid hardcoding configuration values in the application code.\n  - **Backing Services:** Treat backing services (databases, message queues, caches) as attached resources accessed via URLs or connection strings.\n  - **Build, Release, Run:** Strictly separate the build, release, and run stages. Build creates the executable, release combines the build with the config, and run executes the release in the execution environment.\n  - **Processes:** Execute the application as one or more stateless processes. Persist data in backing services.\n  - **Port Binding:** Export services via port binding. The application should be self-contained and listen for requests on a port.\n  - **Concurrency:** Scale out via the process model. Use multiple processes to handle concurrency.\n  - **Disposability:** Maximize robustness with fast startup and graceful shutdown.\n  - **Dev/Prod Parity:** Keep development, staging, and production environments as similar as possible.\n  - **Logs:** Treat logs as event streams. Write logs to standard output, and let the platform handle aggregation.\n  - **Admin Processes:** Run admin/management tasks as one-off processes.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:** Organize your project with a clear directory structure. Examples:\n    - `/`: Project root\n    - `/app`: Application source code\n    - `/config`: Configuration files\n    - `/tests`: Unit and integration tests\n    - `/scripts`: Deployment and maintenance scripts\n    - `/docs`: Documentation\n  - **File Naming Conventions:** Use descriptive and consistent file names (e.g., `user_model.py`, `user_controller.js`).\n  - **Module Organization:** Break down your application into modular components with well-defined interfaces.\n  - **Component Architecture:** Use a component-based architecture to promote code reuse and maintainability. Consider using frameworks like React, Angular, or Vue.js for front-end development.\n  - **Code Splitting:** Implement code splitting to reduce initial load times.  Load modules on demand.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:** Use established design patterns (e.g., MVC, Observer, Factory) to structure your code.\n  - **Recommended Approaches:** Use environment variables for configuration, stateless processes, and logging to stdout.\n  - **Anti-patterns:** Avoid hardcoding configuration values, sticky sessions, and relying on local file storage for persistent data.\n  - **State Management:** Choose a state management solution appropriate for your application (e.g., Redux, Vuex, Context API) to handle global application state.\n  - **Error Handling:** Implement robust error handling with try-except blocks and logging of exceptions. Use a centralized error reporting system (e.g., Sentry, Rollbar) to track errors in production.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:** Use caching (e.g., Redis, Memcached) to reduce database load. Optimize database queries. Use asynchronous tasks for long-running operations.\n  - **Memory Management:** Avoid memory leaks by properly managing resources. Use garbage collection tools to identify and fix memory issues.\n  - **Rendering Optimization:** Optimize front-end rendering by minimizing DOM manipulations and using techniques like virtual DOM.\n  - **Bundle Size Optimization:** Reduce bundle size by minifying code, removing unused code, and using tree shaking.\n  - **Lazy Loading:** Implement lazy loading for images, modules, and other resources to improve initial load times.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:** Prevent common vulnerabilities like SQL injection, cross-site scripting (XSS), and cross-site request forgery (CSRF).\n  - **Input Validation:** Validate all user inputs to prevent malicious data from entering your application.\n  - **Authentication and Authorization:** Implement secure authentication and authorization mechanisms (e.g., OAuth, JWT). Use HTTPS to encrypt all communication.\n  - **Data Protection:** Encrypt sensitive data at rest and in transit. Use strong passwords and secure password storage.\n  - **Secure API Communication:** Validate API requests, use rate limiting to prevent abuse, and secure API keys.\n\n- **Testing Approaches:**\n  - **Unit Testing:** Write unit tests for individual components to ensure they function correctly.\n  - **Integration Testing:** Write integration tests to verify the interaction between different components.\n  - **End-to-end Testing:** Write end-to-end tests to simulate user interactions and verify the application as a whole.\n  - **Test Organization:** Organize your tests in a clear and maintainable structure. Use test runners like Jest, Mocha, or pytest.\n  - **Mocking and Stubbing:** Use mocking and stubbing to isolate components during testing.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:** Forgetting to configure environment variables, deploying code without testing, and not handling errors properly.\n  - **Edge Cases:** Be aware of edge cases like slow network connections, unexpected user inputs, and resource limitations.\n  - **Version-Specific Issues:** Check for version-specific issues in the Heroku documentation and release notes.\n  - **Compatibility Concerns:** Ensure compatibility between Heroku and the technologies you are using (e.g., language versions, database drivers).\n  - **Debugging Strategies:** Use logging, debugging tools (e.g., Heroku logs, remote debugging), and error reporting systems to diagnose issues.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:** Use a code editor like VS Code or Sublime Text, a version control system like Git, and a dependency management tool appropriate for your language.\n  - **Build Configuration:** Configure your build process using buildpacks or Dockerfiles.\n  - **Linting and Formatting:** Use linters and formatters (e.g., ESLint, Prettier) to enforce code style and catch errors.\n  - **Deployment Best Practices:** Use Heroku CLI for deployment. Automate deployments using CI/CD.\n  - **CI/CD Integration:** Integrate your application with a CI/CD pipeline (e.g., GitHub Actions, CircleCI, Travis CI) for automated testing and deployment.\n\n- **Specific Heroku Considerations**\n  - **Dynos:** Understand the different types of dynos available on Heroku and choose the appropriate dyno type for your application.\n  - **Buildpacks:** Use buildpacks to automatically configure your application's environment on Heroku. You can also create custom buildpacks.\n  - **Add-ons:** Use Heroku add-ons to easily integrate third-party services into your application (e.g., databases, caching, logging).\n  - **Heroku CLI:** Familiarize yourself with the Heroku CLI for managing your applications, databases and deployments.\n  - **Procfile:** Use a Procfile to define the processes that run in your application. This typically includes web, worker, and other processes.\n\n- **Continuous Integration/Continuous Deployment (CI/CD)**\n  - Implement a robust CI/CD pipeline for automated testing and deployment.\n  - Use tools like GitHub Actions, CircleCI, or Jenkins to automate the build, test, and deploy processes.\n  - Configure automated testing to run on every code commit.\n  - Implement automated deployment to staging and production environments.\n  - Use feature flags to enable continuous deployment without breaking changes to production code.\n\n- **Monitoring and Logging**\n  - Use Heroku's built-in logging capabilities to monitor application performance and identify errors.\n  - Integrate with third-party logging services like Sumo Logic, Datadog, or New Relic for advanced monitoring and analytics.\n  - Set up alerts for critical errors and performance issues.\n  - Use log aggregation tools to centralize and analyze logs from multiple dynos.\n\n- **Scaling and Performance**\n  - Monitor application performance metrics to identify bottlenecks.\n  - Scale dynos horizontally to handle increased traffic.\n  - Use caching strategies to reduce database load and improve response times.\n  - Optimize database queries and indexes.\n  - Implement load balancing to distribute traffic across multiple dynos.\n\n- **Security Hardening**\n  - Implement robust security measures to protect against common web vulnerabilities.\n  - Use HTTPS to encrypt all communication between clients and the server.\n  - Implement proper input validation and output encoding to prevent XSS and SQL injection attacks.\n  - Use a Content Security Policy (CSP) to restrict the sources of content that can be loaded by the browser.\n  - Protect against CSRF attacks by implementing CSRF tokens.\n  - Regularly update dependencies to patch security vulnerabilities.\n  - Conduct regular security audits to identify and address potential security weaknesses.\n\n- **Database Management**\n  - Choose the appropriate database for your application's needs (e.g., PostgreSQL, MySQL, MongoDB).\n  - Use database connection pooling to improve performance.\n  - Optimize database queries and indexes.\n  - Implement database backups and recovery strategies.\n  - Use database migrations to manage schema changes.\n  - Secure database credentials and access.\n\nBy adhering to these best practices, developers can build and maintain robust, scalable, and secure applications on the Heroku platform.",
    "metadata": {
      "globs": "*",
      "format": "mdc",
      "originalFile": "heroku.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "heroku",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "deploying",
      "maintaining",
      "applications",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "heroku",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-htmx",
    "description": "This rule provides comprehensive best practices for htmx development, covering code organization, security, performance, testing, and common pitfalls. It aims to guide developers in building robust, maintainable, and secure htmx applications.",
    "author": "sanjeed5",
    "tags": [
      "htmx",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/htmx.mdc",
    "content": "# htmx Best Practices and Coding Standards\n\nThis document outlines the recommended best practices and coding standards for developing htmx applications. Adhering to these guidelines will help ensure code quality, maintainability, security, and performance.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nWhile htmx doesn't enforce a specific directory structure, a well-organized project is crucial for maintainability. Consider the following structure as a starting point:\n\n\nproject-root/\n├── assets/             # Static assets (CSS, JavaScript, images, fonts)\n│   ├── css/\n│   ├── js/\n│   ├── img/\n│   └── fonts/\n├── components/       # Reusable HTML snippets/components\n│   ├── button.html\n│   ├── form.html\n│   └── ...\n├── layouts/          # Page layouts (e.g., base.html, default.html)\n│   ├── base.html\n│   └── ...\n├── pages/            # Individual pages (e.g., index.html, about.html)\n│   ├── index.html\n│   └── ...\n├── scripts/          # Server-side scripts (Python, Node.js, etc.)\n│   ├── app.py          # Example using Flask\n│   └── ...\n├── templates/        # Server-side templates (e.g., Jinja2, Django Templates)\n│   ├── ...\n├── .env              # Environment variables\n├── requirements.txt  # Python dependencies (if applicable)\n└── package.json       # Node.js dependencies (if applicable)\n\n\n*   **`assets/`**:  Contains all static assets like CSS, JavaScript (including htmx extensions), images, and fonts.  Organize further into subdirectories for each asset type.\n*   **`components/`**: Stores reusable HTML snippets. These components can be included in various pages or other components to avoid code duplication.\n*   **`layouts/`**: Defines the overall structure of pages.  Common elements like headers, footers, and navigation are placed here, allowing pages to inherit a consistent look and feel.\n*   **`pages/`**: Contains the HTML files for individual pages of your application. These pages usually include content and may use components and layouts.\n*   **`scripts/`**: Holds server-side scripts responsible for handling requests, processing data, and rendering HTML responses.  These scripts interact with htmx via the HTTP protocol.\n*   **`templates/`**: Used in conjunction with server-side scripting, these are templates processed by the backend to generate HTML dynamically. (Only relevant if you are using a template engine on the backend).\n\n### 1.2 File Naming Conventions\n\n*   **HTML files:** Use descriptive names in lowercase with hyphens (e.g., `product-details.html`, `user-profile.html`).\n*   **CSS files:** Similar to HTML, use lowercase with hyphens (e.g., `main.css`, `style.css`, `components.css`).\n*   **JavaScript files:**  Use camelCase for file names (e.g., `utils.js`, `htmxConfig.js`).\n*   **Component files:**  Reflect the component's purpose (e.g., `product-card.html`, `search-form.html`).\n*   **Image files:** Use descriptive names related to the image content (e.g., `product-image-1.jpg`, `user-avatar.png`).\n\n### 1.3 Module Organization\n\nFor larger htmx projects, consider modularizing your JavaScript code. This promotes code reuse and maintainability. CommonJS or ES modules can be used, depending on your build setup.\n\njavascript\n// utils.js\nexport function formatDate(date) {\n  // ...\n}\n\nexport function truncateText(text, limit) {\n  // ...\n}\n\n// main.js\nimport { formatDate, truncateText } from './utils.js';\n\n// ...\n\n\n### 1.4 Component Architecture\n\nBreak down your user interface into reusable components. This makes your code easier to understand, test, and maintain. For example, a product card, a search form, or a navigation menu can be created as separate components.\n\nhtml\n<!-- product-card.html -->\n<div class=\"product-card\">\n  <h3>{{ product.name }}</h3>\n  <img src=\"{{ product.image }}\" alt=\"{{ product.name }}\">\n  <p>{{ product.description }}</p>\n  <button hx-post=\"/add-to-cart/{{ product.id }}\">Add to Cart</button>\n</div>\n\n\n### 1.5 Code Splitting Strategies\n\nIn htmx, code splitting can refer to different aspects. While htmx itself doesn't require complex JavaScript bundles, consider these:\n\n*   **HTML Components:** Split large pages into smaller, more manageable components. Load these components on demand using htmx requests to improve initial page load time.\n*   **CSS Files:** Separate your CSS into logical modules (e.g., base styles, component styles, page-specific styles) to avoid loading unnecessary styles on every page.\n*   **htmx Extensions:** Only include the htmx extensions that you are actively using. Do not include all extensions if only a few are needed.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to htmx\n\n*   **Progressive Enhancement:** Design your application to work without JavaScript first, then enhance it with htmx. This ensures accessibility and a baseline level of functionality for all users.\n*   **Hypermedia as the Engine of Application State (HATEOAS):**  The core philosophy of htmx. The server should provide all the necessary links and forms for the client to interact with the application.  The client simply follows these links and submits the forms; it doesn't need to know the specific URLs or request methods.\n*   **Server-Side Rendering (SSR):**  Focus on rendering HTML on the server.  This improves initial page load time, SEO, and accessibility.  htmx enhances this by enabling dynamic updates without full page reloads.\n*   **Component-Based UI:** Design your UI as a collection of reusable components.  Each component manages its own state and behavior, making the application easier to understand and maintain.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Form Handling:** Use htmx to submit forms and update the UI based on the server's response. Validate user input on both the client and server sides.\n*   **Pagination:** Implement pagination using htmx to load content in chunks. The server provides links to the next and previous pages, and htmx handles the loading and rendering of the new content.\n*   **Real-Time Updates:** Use WebSockets or Server-Sent Events (SSE) with htmx to display real-time data. The server pushes updates to the client, and htmx updates the UI accordingly.\n*   **Dynamic Search:**  Implement live search functionality by sending AJAX requests to the server as the user types.  Display the search results in real-time using htmx.\n*   **Modal Dialogs:** Use htmx to load the content of modal dialogs on demand. This avoids loading unnecessary content on initial page load.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Over-reliance on JavaScript:** htmx aims to reduce the amount of JavaScript required for web development. Avoid using JavaScript for tasks that can be easily accomplished with htmx attributes.\n*   **Complex Client-Side Logic:**  Keep your client-side logic as simple as possible. Move complex logic to the server-side, where it can be more easily tested and maintained.\n*   **Mixing htmx with other Front-end frameworks (React, Angular, Vue):** While technically possible, this defeats the purpose of using htmx. Using htmx with other front-end frameworks will likely increase complexity.\n*   **Ignoring Security Best Practices:**  htmx does not automatically protect against security vulnerabilities.  Always follow security best practices, such as input validation and output escaping, to prevent XSS attacks.\n*   **Creating API Endpoints that return JSON to only convert it to HTML:** htmx shines when your endpoints return HTML. Avoid the extra steps needed for JSON parsing on the client side.\n\n### 2.4 State Management Best Practices\n\nhtmx promotes a server-centric approach to state management. The server maintains the application's state, and the client simply displays it. This simplifies client-side code and reduces the risk of inconsistencies between the client and server.\n\n*   **Server-Side Sessions:** Store user-specific data in server-side sessions. This ensures that sensitive data is not exposed to the client.\n*   **Hidden Input Fields:** Use hidden input fields to store data that needs to be persisted across requests. This is useful for maintaining state in forms.\n*   **Cookies:**  Use cookies to store small amounts of data on the client-side. Be mindful of cookie size limits and security implications.\n*   **URL Parameters:**  Use URL parameters to represent state that can be shared or bookmarked. This is useful for implementing features like filtering and sorting.\n*    **`hx-vals`:** Use `hx-vals` for temporary client-side state that is not critical and doesn't need to be persisted on the server.  This is suitable for things like the current step in a multi-step form or the visibility state of a component.\n\n### 2.5 Error Handling Patterns\n\n*   **HTTP Status Codes:**  Use appropriate HTTP status codes to indicate the success or failure of a request.  For example, use `200 OK` for successful requests, `400 Bad Request` for invalid input, and `500 Internal Server Error` for server-side errors.\n*   **htmx Error Handling:**  htmx provides the `htmx:responseError` event for handling errors. Use this event to display error messages to the user or take other appropriate actions.\n*   **Server-Side Error Pages:**  Configure your server to display custom error pages for different HTTP status codes.  This provides a user-friendly experience even when errors occur.\n*   **Client-Side Error Messages:**  Display informative error messages to the user when a request fails.  Avoid displaying technical details that could expose sensitive information.\n*   **Error Logging:**  Log errors on the server-side to help diagnose and fix problems.  Include relevant information such as the request URL, user ID, and error message.\n*   **Graceful Degradation:** Even when errors occur, ensure that your application degrades gracefully. Provide alternative functionality or a clear explanation of the problem.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Minimize DOM Updates:**  htmx is efficient at updating the DOM, but excessive updates can still impact performance.  Use the `hx-swap` attribute to control how content is swapped into the DOM and minimize unnecessary changes.\n*   **Optimize Server-Side Rendering:**  Ensure that your server-side rendering is as efficient as possible.  Use caching, compression, and other optimization techniques to reduce the time it takes to generate HTML.\n*   **Compress Static Assets:**  Compress your CSS, JavaScript, and image files to reduce their size and improve loading times.  Use tools like Gzip or Brotli for compression.\n*   **Use a CDN:**  Serve your static assets from a Content Delivery Network (CDN) to improve loading times for users around the world.\n*   **Lazy Load Images:**  Load images only when they are visible in the viewport. This reduces initial page load time and improves performance.\n*   **Throttle and Debounce Events:** When using events like `keyup` or `mousemove` with `hx-trigger`, use the `throttle` and `debounce` modifiers to limit the number of requests sent to the server.\n\n### 3.2 Memory Management\n\n*   **Avoid Memory Leaks:**  Be careful to avoid memory leaks in your JavaScript code.  Remove event listeners when they are no longer needed and avoid creating circular references.\n*   **Minimize DOM Elements:**  Reduce the number of DOM elements on your page as much as possible.  Complex layouts with many nested elements can impact performance.\n*   **Use Event Delegation:**  Use event delegation to attach event listeners to a parent element instead of attaching them to individual child elements. This reduces the number of event listeners and improves performance.\n\n### 3.3 Rendering Optimization\n\n*   **Use Efficient CSS Selectors:**  Use efficient CSS selectors to minimize the time it takes to apply styles to your elements.  Avoid complex selectors that traverse the DOM unnecessarily.\n*   **Avoid Reflows and Repaints:**  Avoid triggering reflows and repaints in your JavaScript code.  These operations can be expensive and impact performance.  Read properties before making changes to the DOM, and batch your DOM updates.\n*   **Use Hardware Acceleration:**  Take advantage of hardware acceleration to improve rendering performance.  Use CSS properties like `transform` and `opacity` to trigger hardware acceleration.\n\n### 3.4 Bundle Size Optimization\n\n*   **Minimize Dependencies:**  Use only the dependencies that you absolutely need.  Avoid including large libraries that you only use for a small number of features.\n*   **Tree Shaking:**  Use a bundler that supports tree shaking to remove unused code from your JavaScript bundles.\n*   **Code Splitting:**  Split your code into smaller chunks that can be loaded on demand.  This reduces the initial download size and improves performance.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Load Images:** Load images only when they are visible in the viewport. This reduces initial page load time and improves performance. Use the `loading=\"lazy\"` attribute on `<img>` elements.\n*   **Lazy Load Components:**  Load components only when they are needed.  Use htmx to load the component's HTML when it is first requested.\n*   **Intersection Observer API:**  Use the Intersection Observer API to detect when an element enters the viewport. This can be used to trigger the lazy loading of images or components.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):**  Prevent XSS attacks by escaping user input and avoiding the use of `innerHTML`. Use template engines that automatically escape output.\n*   **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using anti-CSRF tokens in your forms. Most server-side frameworks provide built-in CSRF protection.\n*   **SQL Injection:**  Prevent SQL injection attacks by using parameterized queries or ORMs.  Never construct SQL queries by concatenating user input.\n*   **Authentication and Authorization:**  Implement proper authentication and authorization mechanisms to protect your application from unauthorized access.\n*   **Sensitive Data Exposure:**  Avoid exposing sensitive data in URLs or client-side code. Store sensitive data securely on the server-side.\n\n### 4.2 Input Validation\n\n*   **Client-Side Validation:**  Use client-side validation to provide immediate feedback to the user and prevent invalid data from being submitted to the server. However, never rely solely on client-side validation.\n*   **Server-Side Validation:**  Always validate user input on the server-side. This is the only way to ensure that your application is protected from invalid or malicious data.\n*   **Sanitize User Input:**  Sanitize user input to remove or escape potentially harmful characters. This can help prevent XSS and other attacks.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **Cookie-Based Authentication:**  Use cookies to store authentication tokens. Set the `Secure`, `HttpOnly`, and `SameSite` attributes to protect your cookies from unauthorized access.\n*   **Session Management:**  Use server-side sessions to store user-specific data. This prevents sensitive data from being exposed to the client.\n*   **Role-Based Access Control (RBAC):**  Implement RBAC to control access to different parts of your application based on user roles. This ensures that users can only access the resources that they are authorized to access.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:**  Encrypt sensitive data both in transit and at rest. Use HTTPS to encrypt data in transit, and use strong encryption algorithms to encrypt data at rest.\n*   **Hashing:**  Use hashing to store passwords and other sensitive data. Never store passwords in plaintext.\n*   **Data Masking:**  Mask sensitive data in your application's UI to prevent it from being exposed to unauthorized users.  For example, you can mask credit card numbers or social security numbers.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:**  Always use HTTPS to encrypt communication between the client and server.\n*   **API Authentication:**  Require API clients to authenticate themselves before accessing your API.  Use API keys, OAuth, or other authentication mechanisms.\n*   **Rate Limiting:**  Implement rate limiting to prevent API abuse. This limits the number of requests that a client can make in a given period of time.\n*   **Input Validation:**  Validate all input to your API to prevent injection attacks and other security vulnerabilities.\n*   **Output Sanitization:**  Sanitize all output from your API to prevent XSS attacks.\n*   **CORS (Cross-Origin Resource Sharing):** Configure CORS carefully to allow only trusted domains to access your API.\n\n### 4.6 The Golden Rules of htmx Security (reiterated):\n\n*   **Only call routes you control**: Use relative URLs to avoid executing untrusted code.\n*   **Always use an auto-escaping template engine**: Prevent XSS attacks by ensuring dynamic content is escaped.\n*   **Only serve user-generated content inside HTML tags**: Avoid inserting user content in dangerous contexts like script or style tags.\n*   **Secure your cookies**: Use attributes like Secure, HttpOnly, and SameSite=Lax for authentication cookies.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Server-Side Logic:**  Write unit tests for your server-side logic to ensure that it is working correctly.  Use a testing framework like pytest (Python), Jest (Node.js), or JUnit (Java).\n*   **Test htmx Endpoints:** Write tests for your htmx endpoints. This could involve making requests to your endpoints and checking the HTML responses.\n*   **Mock External Dependencies:**  Mock external dependencies, such as databases or APIs, to isolate your code and make your tests more reliable.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Components:**  Write integration tests to ensure that your components are working together correctly. This includes testing the interactions between htmx attributes and JavaScript code.\n*   **Test Data Flow:**  Test the flow of data through your application to ensure that data is being processed and displayed correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate User Interactions:**  Write end-to-end tests to simulate user interactions with your application. This includes testing the entire workflow from start to finish.\n*   **Test UI Rendering:**  Test the rendering of your UI to ensure that it is displaying correctly. This includes testing the layout, styles, and content of your pages.\n\n### 5.4 Test Organization\n\n*   **Organize Tests by Feature:**  Organize your tests by feature to make it easier to find and run tests for specific parts of your application.\n*   **Use a Consistent Naming Convention:**  Use a consistent naming convention for your tests to make them easier to understand and maintain.\n*   **Keep Tests Independent:**  Keep your tests independent of each other to avoid cascading failures.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking to Isolate Code:**  Use mocking to isolate your code and make your tests more reliable. This involves replacing external dependencies with mock objects that simulate their behavior.\n*   **Use Stubbing to Control Behavior:**  Use stubbing to control the behavior of your mock objects. This allows you to test different scenarios and edge cases.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Incorrect `hx-target` and `hx-swap` Usage:**  Pay close attention to the `hx-target` and `hx-swap` attributes.  Incorrect usage can lead to unexpected results and broken UI.\n*   **Forgetting Server-Side Validation:**  Always validate user input on the server-side. Client-side validation is not sufficient for security.\n*   **Over-complicating Client-Side Logic:**  htmx is designed to simplify client-side code.  Avoid adding unnecessary complexity.\n*   **Ignoring Accessibility:**  Make sure your htmx application is accessible to all users. Use semantic HTML, provide alternative text for images, and ensure that your application is keyboard-navigable.\n*   **Not handling edge cases and error conditions**: Ensure you have covered the most common error conditions, such as server errors, network issues, and no results.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **Handling Empty Responses:**  Consider how your application should behave when the server returns an empty response.  Should the target element be cleared, or should a default message be displayed?\n*   **Handling Concurrent Requests:**  Be aware of the potential for concurrent requests.  Use the `hx-sync` attribute to manage synchronization between requests.\n*   **Handling Browser History:**  htmx does not automatically manage browser history.  If you need to support browser history, you will need to use JavaScript or a dedicated htmx extension.\n*   **Unexpected interactions with browser extensions**: Some browser extensions, especially those that modify HTTP headers, can interfere with htmx's behavior.  Test your application with common extensions enabled to identify and address any conflicts.\n\n### 6.3 Version-Specific Issues\n\n*   **Refer to the Official Documentation:**  Always refer to the official htmx documentation for the latest information and best practices.\n*   **Check Release Notes:** Review the release notes for each new version of htmx to identify any breaking changes or known issues.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:**  htmx is compatible with modern browsers.  However, older browsers may require polyfills.\n*   **Server-Side Framework Compatibility:**  htmx can be used with any server-side framework that can generate HTML.  However, some frameworks may require specific configuration.\n\n### 6.5 Debugging Strategies\n\n*   **Use Browser Developer Tools:**  Use your browser's developer tools to inspect network requests, examine the DOM, and debug JavaScript code.\n*   **htmx Events:**  Listen for htmx events, such as `htmx:beforeRequest`, `htmx:afterRequest`, and `htmx:responseError`, to gain insight into what is happening in your application.\n*   **Server-Side Logging:**  Add logging to your server-side code to help diagnose problems.\n*   **Simplify the Problem:** Break down complex htmx interactions into smaller, more manageable steps to isolate the source of the problem.\n*   **Inspect HTTP Headers:** Pay attention to the HTTP headers in both the request and response. Check the `Content-Type`, `HX-Request`, and other relevant headers.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Text Editor or IDE:**  Use a text editor or IDE with support for HTML, CSS, and JavaScript. Popular options include VS Code, Sublime Text, and Atom.\n*   **Browser Developer Tools:**  Use your browser's developer tools to inspect network requests, examine the DOM, and debug JavaScript code.\n*   **htmx Extension for Chrome:**  Install the htmx extension for Chrome to enable features like attribute highlighting and event inspection.\n*   **Server-Side Development Tools:** Use the development tools appropriate for your chosen server-side framework (e.g., Python debugger, Node.js inspector).\n\n### 7.2 Build Configuration\n\n*   **Use a Task Runner:**  Use a task runner like Gulp or Grunt to automate common development tasks, such as minifying CSS and JavaScript, optimizing images, and running tests.\n*   **Use a Module Bundler:**  Use a module bundler like Webpack or Parcel to bundle your JavaScript modules into a single file.\n*   **Configure Code Linting and Formatting:** Integrate linters (like ESLint, stylelint) and formatters (like Prettier) to automatically enforce consistent coding styles and catch common errors.\n\n### 7.3 Linting and Formatting\n\n*   **Use a Code Linter:**  Use a code linter to automatically detect errors and enforce coding style guidelines. Popular linters include ESLint (JavaScript) and stylelint (CSS).\n*   **Use a Code Formatter:**  Use a code formatter to automatically format your code according to a consistent style. Popular formatters include Prettier and js-beautify.\n\n### 7.4 Deployment Best Practices\n\n*   **Use a Version Control System:**  Use a version control system like Git to track changes to your code. This makes it easier to collaborate with others and revert to previous versions if necessary.\n*   **Automate Deployment:**  Automate your deployment process using a tool like Jenkins, Travis CI, or CircleCI. This makes it easier to deploy your application to production quickly and reliably.\n*   **Use a Continuous Integration/Continuous Deployment (CI/CD) Pipeline:**  Implement a CI/CD pipeline to automatically build, test, and deploy your application whenever changes are made to your codebase.\n*   **Monitor Your Application:**  Monitor your application in production to detect and resolve problems quickly.\n\n### 7.5 CI/CD Integration\n\n*   **Set Up a CI/CD Pipeline:**  Set up a CI/CD pipeline to automatically build, test, and deploy your application. This makes it easier to release new features and bug fixes quickly and reliably.\n*   **Run Tests Automatically:**  Configure your CI/CD pipeline to run your tests automatically whenever changes are made to your codebase. This helps to ensure that your code is working correctly before it is deployed to production.\n*   **Automate Deployment:**  Automate your deployment process using a tool like Jenkins, Travis CI, or CircleCI. This makes it easier to deploy your application to production quickly and reliably.\n\nBy adhering to these best practices and coding standards, you can build htmx applications that are robust, maintainable, secure, and performant. Remember to stay up-to-date with the latest htmx documentation and community resources to ensure that you are using the most effective techniques.",
    "metadata": {
      "globs": "*.html",
      "format": "mdc",
      "originalFile": "htmx.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "htmx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "htmx",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-httpx",
    "description": "This rule provides comprehensive best practices for using the httpx library, covering code organization, performance, security, testing, and common pitfalls. Adhering to these guidelines will improve code quality, maintainability, and security when working with httpx.",
    "author": "sanjeed5",
    "tags": [
      "httpx",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/httpx.mdc",
    "content": "# httpx Best Practices\n\nThis document outlines recommended practices for using the `httpx` library in Python. Following these guidelines will help ensure maintainable, performant, and secure code.\n\n## Library Information:\n\n- Name: httpx\n- Tags: web, python, http-client, async\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n- **Dedicated Modules:** Organize httpx-related code into dedicated modules or packages.\n- **Configuration:** Separate configuration settings (timeouts, headers, proxies) from the core logic.\n- **Data Models:** Define data models (e.g., using `dataclasses` or `pydantic`) to represent request and response data.\n\nExample:\n\n\nmy_project/\n├── httpx_client/\n│   ├── __init__.py\n│   ├── client.py      # httpx client setup, session management\n│   ├── utils.py       # Utility functions for request/response handling\n│   ├── models.py      # Data models for requests and responses\n│   └── exceptions.py  # Custom exceptions\n├── ...\n\n\n### 1.2 File Naming Conventions\n\n- Use descriptive names that reflect the file's purpose (e.g., `api_client.py`, `request_utils.py`).\n- Follow PEP 8 conventions (snake_case).\n\n### 1.3 Module Organization\n\n- **Layered Architecture:** Consider a layered architecture with modules for:\n    - **Client Initialization:**  Handles httpx client setup (connection pooling, timeouts).\n    - **Request Building:**  Constructs httpx Request objects.\n    - **Response Handling:** Parses and validates responses, handles errors.\n- **Abstraction:** Abstract away direct httpx calls behind service functions or classes.\n\n### 1.4 Component Architecture\n\n- **Reusable Components:** Design reusable components for common tasks like:\n    - **Authentication:** Implementing custom authentication flows.\n    - **Rate Limiting:** Managing API rate limits.\n    - **Retry Logic:** Handling transient errors with retry mechanisms.\n\n### 1.5 Code Splitting Strategies\n\n- **Feature-Based Splitting:** Split code based on features or API endpoints.\n- **Abstraction:** Use interfaces or abstract base classes for httpx clients to facilitate mocking and testing.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Factory Pattern:** Use a factory function or class to create httpx clients with different configurations.\n- **Strategy Pattern:** Implement different request strategies based on the API requirements.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Client Instance Usage:** Always use `httpx.Client()` or `httpx.AsyncClient()` for making requests. This enables connection pooling.\n- **Context Managers:** Use the client as a context manager (`with httpx.Client() as client:`) or explicitly close the connection pool (`client.close()`).\n- **Timeouts:** Always set timeouts to prevent hanging requests.\n- **Error Handling:** Use `try-except` blocks to handle `HTTPStatusError` and `RequestError`.\n- **Async Support:** Utilize `httpx.AsyncClient()` for concurrent requests.\n- **Configuration Sharing:** Configure default headers, parameters, and authentication at the client level.\n\npython\nimport httpx\n\nwith httpx.Client(timeout=10.0, headers={'User-Agent': 'MyApp/1.0'}) as client:\n    try:\n        response = client.get('https://example.com/api/data')\n        response.raise_for_status() # Raise HTTPStatusError for bad responses (4xx or 5xx)\n        data = response.json()\n        # Process data\n    except httpx.HTTPStatusError as e:\n        print(f\"HTTP Error: {e}\")\n    except httpx.RequestError as e:\n        print(f\"Request Error: {e}\")\n\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Global Client Instances:** Avoid creating global httpx client instances without proper management of their lifecycle.\n- **Ignoring Errors:** Never ignore exceptions raised by httpx. Always handle them appropriately.\n- **Hardcoding URLs:** Avoid hardcoding URLs directly in the code. Use configuration files or environment variables.\n\n### 2.4 State Management\n\n- **Statelessness:** Design components to be as stateless as possible.\n- **Dependency Injection:** Use dependency injection to provide httpx clients to components that need them.\n\n### 2.5 Error Handling Patterns\n\n- **Custom Exceptions:** Define custom exception classes to represent specific httpx-related errors.\n- **Logging:** Log errors and warnings with sufficient context.\n- **Retry Logic:** Implement retry logic for transient errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Connection Pooling:** httpx automatically uses connection pooling when using `httpx.Client()` or `httpx.AsyncClient()`.  Ensure you are leveraging this by reusing client instances.\n- **HTTP/2:** Enable HTTP/2 support if the server supports it.\n- **Keep-Alive:** Ensure keep-alive connections are enabled.\n- **Asynchronous Operations:** Use `httpx.AsyncClient()` for concurrent I/O-bound operations.\n\n### 3.2 Memory Management\n\n- **Streaming Responses:** Use response streaming (`response.iter_bytes()`, `response.iter_text()`) for large responses to avoid loading the entire response into memory.\n- **Chunked Uploads:** Use chunked uploads for large file uploads.\n\n### 3.3 Bundle Size Optimization\n\n- **Tree Shaking:** Ensure your build tools perform tree shaking to remove unused httpx code.\n\n### 3.4 Lazy Loading\n\n- **On-Demand Initialization:** Initialize httpx clients only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n- **Injection Attacks:** Sanitize user inputs to prevent injection attacks.\n- **Man-in-the-Middle Attacks:** Always use HTTPS and verify SSL certificates.\n- **Sensitive Data Exposure:** Avoid logging sensitive data (API keys, passwords).\n\n### 4.2 Input Validation\n\n- **Validate Request Data:** Validate all data before sending it to the API.\n- **Validate Response Data:** Validate responses from the API.\n\n### 4.3 Authentication and Authorization\n\n- **Secure Authentication:** Use secure authentication mechanisms (OAuth 2.0, JWT).\n- **Least Privilege:** Grant only the necessary permissions to users.\n\n### 4.4 Data Protection\n\n- **Encryption:** Encrypt sensitive data at rest and in transit.\n- **Data Masking:** Mask sensitive data in logs and error messages.\n\n### 4.5 Secure API Communication\n\n- **HTTPS:** Always use HTTPS.\n- **TLS 1.3:** Use TLS 1.3 or higher.\n- **Certificate Pinning:** Consider certificate pinning for added security (advanced).\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- **Mocking:** Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to mock httpx calls.\n- **Isolate Components:** Isolate components that use httpx for unit testing.\n\n### 5.2 Integration Testing\n\n- **Test Against Real APIs:** Perform integration tests against real APIs (with appropriate mocking or stubbing).\n\n### 5.3 End-to-End Testing\n\n- **Simulate User Flows:** Simulate end-to-end user flows that involve httpx calls.\n\n### 5.4 Test Organization\n\n- **Separate Test Files:** Create separate test files for each module or component.\n\n### 5.5 Mocking and Stubbing Techniques\n\n- **Mock Responses:** Mock httpx responses to simulate different API scenarios.\n- **Patch httpx Functions:** Patch httpx functions to control their behavior during tests.\n- **RESPX:** Use RESPX for advanced mocking of httpx requests and responses.\n\npython\nimport httpx\nimport pytest\nimport respx\n\n@respx.mock\nasync def test_get_data():\n    respx.get(\"https://example.com/api/data\").mock(return_value=httpx.Response(200, json={\"key\": \"value\"}))\n    async with httpx.AsyncClient() as client:\n        response = await client.get(\"https://example.com/api/data\")\n        assert response.status_code == 200\n        assert response.json() == {\"key\": \"value\"}\n\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Forgetting to Close Clients:** Always close httpx clients to release resources.\n- **Ignoring Timeouts:** Not setting timeouts can lead to hanging requests.\n- **Incorrect Error Handling:** Improper error handling can mask critical errors.\n- **Misunderstanding Connection Pooling:** Not reusing client instances negates connection pooling benefits.\n- **Not Handling Asynchronous Context Correctly**: Using `await` improperly when using `AsyncClient()`.\n\n### 6.2 Edge Cases\n\n- **Character Encoding Issues:** Handle character encoding issues when processing text responses.\n- **SSL Certificate Errors:** Handle SSL certificate errors gracefully.\n- **Network Connectivity Issues:** Implement robust error handling for network connectivity issues.\n\n### 6.3 Version-Specific Issues\n\n- **Consult httpx Documentation:** Refer to the httpx documentation for version-specific issues and compatibility notes.\n\n### 6.4 Compatibility Concerns\n\n- **Asynchronous Libraries:** Ensure compatibility with other asynchronous libraries (e.g., asyncio).\n- **Third-Party Packages:** Be aware of compatibility issues with third-party packages that use httpx.\n\n### 6.5 Debugging Strategies\n\n- **Logging:** Use logging to trace httpx requests and responses.\n- **Debugging Tools:** Use debugging tools (e.g., pdb, ipdb) to inspect httpx code.\n- **Wireshark/tcpdump:** Use network analysis tools (Wireshark, tcpdump) to capture and analyze network traffic.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n- **Development Environment:** Use a modern IDE (e.g., VS Code, PyCharm).\n- **Dependency Management:** Use a dependency management tool (e.g., pipenv, poetry).\n- **Testing Framework:** Use a testing framework (e.g., pytest, unittest).\n- **Mocking Libraries:** Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`, RESPX).\n\n### 7.2 Build Configuration\n\n- **Reproducible Builds:** Ensure reproducible builds using dependency locking.\n\n### 7.3 Linting and Formatting\n\n- **PEP 8 Compliance:** Use a linter (e.g., flake8, pylint) to enforce PEP 8 compliance.\n- **Code Formatting:** Use a code formatter (e.g., black, autopep8) to automatically format code.\n\n### 7.4 Deployment\n\n- **Containerization:** Use containerization (e.g., Docker) to ensure consistent deployments.\n- **Environment Variables:** Configure httpx clients using environment variables.\n\n### 7.5 CI/CD Integration\n\n- **Automated Testing:** Integrate automated testing into your CI/CD pipeline.\n- **Code Analysis:** Integrate code analysis tools into your CI/CD pipeline.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "httpx.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "httpx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "library",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "httpx",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-huggingface",
    "description": "This rule provides guidelines for best practices when working with the Hugging Face Transformers library, covering code organization, performance, testing, security, and common pitfalls. It emphasizes community standards and maintainability.",
    "author": "sanjeed5",
    "tags": [
      "huggingface",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/huggingface.mdc",
    "content": "# Hugging Face Transformers Library Best Practices\n\nThis document outlines best practices and coding standards for using the Hugging Face Transformers library. It covers various aspects, including code organization, performance, testing, security, and common pitfalls.\n\n## Philosophy: Embrace the Single Model File Policy\n\n- **Single Model File Policy:** Prioritize having all the code for a model's forward pass within a single file. While it might seem to contradict the DRY (Don't Repeat Yourself) principle, this improves readability and accessibility, especially for newcomers.  This makes it easier to understand the entire model architecture without navigating through multiple files.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nWhile the Transformers library promotes the single model file policy, good project-level organization is still crucial. A typical project structure might look like this:\n\n\nmy_project/\n├── data/\n│   ├── raw/\n│   ├── processed/\n│   └── ...\n├── models/\n│   ├── modeling_bert.py  # Example: BERT model definition\n│   ├── ...\n├── scripts/\n│   ├── train.py\n│   ├── evaluate.py\n│   ├── preprocess.py\n│   └── ...\n├── utils/\n│   ├── data_utils.py\n│   ├── model_utils.py\n│   └── ...\n├── tests/\n│   ├── test_models.py\n│   ├── test_data_utils.py\n│   └── ...\n├── notebooks/ # optional\n│   ├── exploration.ipynb\n│   └── ...\n├── requirements.txt\n├── pyproject.toml\n└── README.md\n\n\n- **`data/`:**  Stores raw and processed datasets.\n- **`models/`:** Contains model definitions (adhering to the single model file policy).\n- **`scripts/`:**  Holds training, evaluation, and preprocessing scripts.\n- **`utils/`:**  Includes utility functions for data handling, model management, etc.\n- **`tests/`:** Contains unit, integration, and end-to-end tests.\n- **`notebooks/`:** (Optional) Jupyter notebooks for experimentation.\n\n### 1.2 File Naming Conventions\n\n- Use descriptive and consistent file names.\n- For model files, follow the naming convention `modeling_<model_name>.py` (e.g., `modeling_bert.py`).\n- For utility files, use `*_utils.py` (e.g., `data_utils.py`).\n- Use lowercase letters and underscores for file names (snake_case).\n\n### 1.3 Module Organization\n\n- Keep modules focused and avoid creating overly large modules.  Each module should have a clear responsibility.\n- Import necessary modules within functions or classes to improve readability and avoid unnecessary dependencies at the module level.\n- Use relative imports within the project structure (e.g., `from . import data_utils`) to avoid conflicts and improve portability.\n\n### 1.4 Component Architecture\n\n- Design models as modular components.  While adhering to the single model file policy, the internal structure of the model can be highly modular.  Use classes to encapsulate different parts of the model (e.g., embedding layer, attention mechanism, feedforward network).\n- Each component should have a well-defined interface.\n- Leverage inheritance when appropriate to share common functionality between similar components.\n\n### 1.5 Code Splitting Strategies\n\n- For extremely large models, consider splitting the model definition into multiple files, but maintain a clear entry point that encapsulates the entire model. A primary file should import and orchestrate the other components.\n- Consider splitting preprocessing and postprocessing logic into separate modules to improve readability and maintainability.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Hugging Face\n\n- **Configuration-Driven Design:** Use `PretrainedConfig` objects to define model parameters. This allows for easy configuration and sharing of model architectures.\n- **Tokenizers and Pipelines:** Leverage the built-in tokenizers and pipelines for efficient text processing. Understand how to customize them for specific tasks.\n- **Model Cards:** Create comprehensive model cards that document the model's architecture, training data, evaluation metrics, and intended use cases. This is crucial for reproducibility and transparency.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Loading Pre-trained Models:** Use `AutoModel` and `AutoTokenizer` classes to automatically load the appropriate model and tokenizer based on the model name.\n\n   python\n   from transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n   model_name = \"bert-base-uncased\"\n   model = AutoModelForSequenceClassification.from_pretrained(model_name)\n   tokenizer = AutoTokenizer.from_pretrained(model_name)\n   \n\n- **Fine-tuning Models:** Use the `Trainer` class for efficient fine-tuning.  Customize the training loop when necessary for advanced control.\n\n   python\n   from transformers import Trainer, TrainingArguments\n\n   training_args = TrainingArguments(\n       output_dir=\"./results\",\n       evaluation_strategy=\"epoch\",\n       num_train_epochs=3\n   )\n\n   trainer = Trainer(\n       model=model,\n       args=training_args,\n       train_dataset=train_dataset,\n       eval_dataset=eval_dataset\n   )\n\n   trainer.train()\n   \n\n- **Inference:** Use pipelines for simple inference tasks or write custom inference loops for more control.\n\n   python\n   from transformers import pipeline\n\n   classifier = pipeline(\"sentiment-analysis\")\n   result = classifier(\"This is a great movie!\")\n   \n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n- **Ignoring `model_max_length`:** When initializing tokenizers and models, be mindful of the `model_max_length` parameter. Ensure that input sequences are properly truncated or padded to avoid errors or performance issues.\n- **Hardcoding Paths:** Avoid hardcoding file paths.  Use relative paths or environment variables to make the code more portable.\n- **Lack of Documentation:**  Write clear and concise documentation for all functions, classes, and modules. This is especially important given the single model file policy, as comprehensive inline documentation becomes critical.\n- **Over-Complicating Model Definitions:** Keep model definitions as simple as possible while still meeting the requirements.  Avoid unnecessary complexity.\n- **Ignoring Warnings:**  Pay attention to warnings raised by the Transformers library. They often indicate potential issues.\n\n### 2.4 State Management Best Practices\n\n- Avoid global variables.  Encapsulate state within classes or functions.\n- Use immutable data structures when possible to prevent accidental modifications.\n- Manage model weights carefully. Load and save weights using the `state_dict` method.\n\n   python\n   # Save model weights\n   torch.save(model.state_dict(), \"model.pth\")\n\n   # Load model weights\n   model.load_state_dict(torch.load(\"model.pth\"))\n   \n\n### 2.5 Error Handling Patterns\n\n- Use `try...except` blocks to handle potential exceptions, such as file not found errors or invalid input data.\n- Provide informative error messages to help users understand the cause of the error.\n- Use logging to record errors and debug information.\n\n   python\n   import logging\n\n   logging.basicConfig(level=logging.INFO)\n\n   try:\n       model = AutoModelForSequenceClassification.from_pretrained(\"invalid-model\")\n   except OSError as e:\n       logging.error(f\"Failed to load model: {e}\")\n   \n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Mixed Precision Training:** Use mixed precision training (e.g., using `torch.cuda.amp` in PyTorch) to reduce memory usage and improve training speed.\n- **Gradient Accumulation:** Use gradient accumulation to simulate larger batch sizes when memory is limited.\n- **Quantization:** Quantize models to reduce their size and improve inference speed.\n- **ONNX Runtime:** Convert models to ONNX format and use the ONNX Runtime for faster inference.\n\n### 3.2 Memory Management\n\n- Delete unused variables and tensors to free up memory.\n- Use `torch.no_grad()` during inference to disable gradient calculations and reduce memory usage.\n- Consider using techniques like gradient checkpointing to reduce memory usage during training, especially for very large models.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n- If the application involves rendering model outputs (e.g., text generation), optimize the rendering process to minimize latency and improve user experience.\n- Use efficient text rendering libraries.\n- Cache rendered outputs when possible.\n\n### 3.4 Bundle Size Optimization (If Applicable)\n\n- If the application is deployed as a web application or mobile app, optimize the bundle size to reduce download times.\n- Use code splitting to load only the necessary code for each feature.\n- Use minification and compression to reduce the size of JavaScript and CSS files.\n\n### 3.5 Lazy Loading Strategies\n\n- Load models and data lazily to reduce startup time and memory usage.\n- Use generators to process large datasets in chunks.\n- Only load the parts of the model that are needed for the current task.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n- **Prompt Injection:**  Be aware of prompt injection attacks, where malicious users craft inputs that can manipulate the model's behavior.  Implement input validation and sanitization techniques to mitigate this risk.\n- **Data Poisoning:**  Protect against data poisoning attacks by carefully vetting training data sources.\n- **Model Stealing:**  Implement measures to protect model weights from being stolen. Consider using encryption or access controls.\n\n### 4.2 Input Validation\n\n- Validate all inputs to ensure that they are within the expected range and format.\n- Sanitize inputs to remove potentially harmful characters or code.\n- Use regular expressions to enforce input constraints.\n\n### 4.3 Authentication and Authorization Patterns\n\n- Implement authentication to verify the identity of users.\n- Use authorization to control access to resources based on user roles.\n- Store credentials securely using encryption and hashing.\n\n### 4.4 Data Protection Strategies\n\n- Encrypt sensitive data at rest and in transit.\n- Use access controls to restrict access to data.\n- Anonymize or pseudonymize data to protect user privacy.\n\n### 4.5 Secure API Communication\n\n- Use HTTPS to encrypt communication between the client and the server.\n- Use API keys or tokens to authenticate requests.\n- Implement rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n- Write unit tests for all individual functions, classes, and modules.\n- Use a testing framework like `pytest` or `unittest`.\n- Test edge cases and boundary conditions.\n\n### 5.2 Integration Testing\n\n- Write integration tests to verify the interaction between different components of the system.\n- Test the flow of data through the system.\n- Use mocks and stubs to isolate components during testing.\n\n### 5.3 End-to-end Testing\n\n- Write end-to-end tests to verify the entire system from end to end.\n- Simulate user interactions to test the system's functionality.\n- Use a testing framework like `Selenium` or `Cypress` for web applications.\n\n### 5.4 Test Organization\n\n- Organize tests into separate files or directories based on the component being tested.\n- Use descriptive names for test functions and classes.\n- Keep tests concise and focused.\n\n### 5.5 Mocking and Stubbing\n\n- Use mocks and stubs to isolate components during testing.\n- Mock external dependencies, such as API calls or database connections.\n- Use a mocking library like `unittest.mock` or `pytest-mock`.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n- **Incorrect Tokenization:** Using the wrong tokenizer or not properly handling special tokens can lead to inaccurate results.\n- **Oversized Inputs:** Forgetting to truncate or pad input sequences to the model's maximum length can cause errors or performance issues.\n- **Incorrect Device Placement:** Running models on the CPU when a GPU is available can significantly slow down training and inference.\n- **Ignoring Data Preprocessing:** Failing to properly preprocess data (e.g., cleaning, normalizing) can negatively impact model performance.\n\n### 6.2 Edge Cases to be Aware Of\n\n- **Rare Words:** Handle rare or out-of-vocabulary words gracefully.\n- **Long Sequences:** Models may struggle with extremely long sequences.\n- **Adversarial Examples:** Models can be fooled by adversarial examples.\n\n### 6.3 Version-Specific Issues\n\n- Be aware of breaking changes in new versions of the Transformers library.\n- Check the release notes for details on any changes that may affect your code.\n- Use version pinning in `requirements.txt` or `pyproject.toml` to ensure that your code runs with the correct version of the library.\n\n### 6.4 Compatibility Concerns\n\n- Ensure that your code is compatible with the target hardware and software environment.\n- Test your code on different platforms and configurations.\n- Use conditional imports to handle different dependencies.\n\n### 6.5 Debugging Strategies\n\n- Use logging to track the flow of execution and identify errors.\n- Use a debugger to step through the code and inspect variables.\n- Use print statements to output intermediate values.\n- Use a profiler to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE:** Visual Studio Code, PyCharm\n- **Version Control:** Git\n- **Package Manager:** pip, conda, uv\n- **Testing Framework:** pytest\n- **Linting:** pylint, flake8\n- **Formatting:** black, autopep8\n\n### 7.2 Build Configuration\n\n- Use `requirements.txt` or `pyproject.toml` to manage dependencies.\n- Use a build system like `Make` or `Poetry` to automate the build process.\n- Create a virtual environment for each project to isolate dependencies.\n\n### 7.3 Linting and Formatting\n\n- Use a linter to enforce code style guidelines.\n- Use a formatter to automatically format code.\n- Configure the linter and formatter to run automatically on save.\n\n### 7.4 Deployment Best Practices\n\n- Containerize your application using Docker.\n- Use a cloud platform like AWS, Azure, or GCP to deploy your application.\n- Use a deployment tool like Kubernetes to manage your application.\n\n### 7.5 CI/CD Integration\n\n- Use a CI/CD pipeline to automate the testing and deployment process.\n- Use a CI/CD tool like Jenkins, GitHub Actions, or GitLab CI.\n- Run tests automatically on every commit.\n- Deploy the application automatically when tests pass.\n\n## Additional Recommendations\n\n- **Utilize NVIDIA RTX GPUs:**  Leverage RTX GPUs for enhanced performance due to their high-speed VRAM and dedicated AI accelerators.  This is especially important for larger models and higher batch sizes.\n- **Token Management:** Understand how to manage tokens effectively to optimize performance, as performance is often measured in tokens per second.\n- **Batch API:** Consider using the OpenAI Batch API for cost efficiency and higher rate limits, especially when immediate responses are not required.\n\nBy following these best practices, you can write more maintainable, efficient, and secure code when working with the Hugging Face Transformers library.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "huggingface.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "huggingface",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "when",
      "working",
      "with",
      "hugging",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "huggingface",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-hypothesis",
    "description": "Comprehensive guide covering best practices for the Hypothesis Python library, including coding standards, testing, performance, and security.  Provides actionable guidance for developers to write maintainable, robust, and efficient property-based tests.",
    "author": "sanjeed5",
    "tags": [
      "hypothesis",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/hypothesis.mdc",
    "content": "# Hypothesis Library Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for using the Hypothesis Python library effectively.  Following these best practices will lead to more maintainable, robust, and efficient property-based tests.\n\n## I. General Python Coding Standards (Applicable to Hypothesis Projects)\n\nThese are general Python coding standards that should be adhered to in any Python project, including those using Hypothesis.\n\n*   **PEP 8 Compliance:**  Adhere strictly to PEP 8 style guidelines for Python code. This includes:\n    *   Indentation: Use 4 spaces per indentation level.\n    *   Line Length: Limit lines to a maximum of 79 characters (or 72 for comments and docstrings).\n    *   Blank Lines:  Use blank lines to separate top-level function and class definitions (two lines) and method definitions inside a class (one line).\n    *   Imports: Group imports into standard library, third-party, and local application/library-specific imports, separated by blank lines.\n    *   Whitespace: Avoid extraneous whitespace.\n    *   Naming Conventions: Follow appropriate naming conventions for variables, functions, classes, and constants.\n*   **PEP 257 Compliance:** Follow PEP 257 for docstring conventions.\n    *   Write docstrings for all public modules, functions, classes, and methods.\n    *   Use triple double quotes (`\"\"\"`) for docstrings.\n    *   Include a summary line, use case (if appropriate), arguments, return type and semantics (unless None is returned), and examples in multiline docstrings.\n*   **Use Python 3.12+:** Ensure that your project uses a modern version of Python (3.12 or higher) for access to the latest features and security updates.\n*   **Virtual Environments:** Use virtual environments (e.g., `venv` or `virtualenv`) to isolate project dependencies.\n*   **Dependency Management:** Use a dependency management tool like `pip` with a `requirements.txt` or `pyproject.toml` file to specify project dependencies. It's recommended to use a modern package installer such as [UV](https://astral.sh/blog/uv) for faster and more reproducible builds.\n*   **Code Reviews:**  Conduct regular code reviews to ensure code quality and adherence to coding standards.\n*   **Type Hinting:** Use type hints to improve code readability and enable static analysis.\n*   **Linters and Formatters:** Use linters (e.g., `flake8`, `pylint`) and formatters (e.g., `black`, `autopep8`) to automatically enforce coding standards.\n*   **Error Handling:** Implement robust error handling using `try...except` blocks.\n*   **Logging:** Use the `logging` module for structured logging.\n*   **Clear and Concise Code:** Write code that is easy to understand and maintain.\n*   **Modularity:** Design your code with a modular architecture.\n*   **Documentation:** Write clear and comprehensive documentation.\n*   **Follow SOLID principles** When designing code and modules.\n\n## II. Hypothesis-Specific Best Practices\n\nThese guidelines are specifically tailored to the Hypothesis library for property-based testing.\n\n### A. Writing Properties\n\n*   **Focus on Properties, Not Examples:** Hypothesis excels when you define *properties* that should always hold true for a wide range of inputs, rather than just providing a fixed set of examples.  A property describes a general relationship that should be invariant.\n*   **Define Strategies Clearly:** Strategies are the core of Hypothesis. Define strategies that generate diverse and representative data for your properties. Hypothesis provides many built-in strategies, and you can combine and customize them.\n*   **Shrinking is Crucial:** Hypothesis shrinks failing examples to the smallest and simplest form that still causes the failure.  This simplifies debugging.  Ensure your strategies are designed to allow effective shrinking.\n*   **Avoid Direct Assertion:** Generally, avoid directly asserting specific values within your properties.  Instead, focus on asserting relationships between inputs and outputs. This strengthens the test and covers more potential cases.\n*   **Use Assume Sparingly:** The `assume()` function tells Hypothesis to discard certain examples. Overuse of `assume()` can make your tests less effective and potentially mask bugs. Try to refine your strategies instead of filtering excessively.\n*   **Make Properties Declarative:** Properties should describe *what* should happen, not *how* it should happen.  This makes the tests more robust and easier to understand.\n*   **Test Invariants, Not Implementations:** Properties should test the high-level invariants of your code, rather than implementation details. This makes the tests more resilient to code changes.\n*   **Minimize Side Effects:** Properties should be as pure as possible, with minimal side effects. This makes the tests more predictable and easier to debug.\n*   **Consider Edge Cases:** Think about edge cases and boundary conditions that might violate your properties.  Design your strategies to include these cases.\n*   **Use Composite Strategies:** Composite strategies allow you to combine multiple strategies to generate complex data structures. Use them to create realistic and diverse test cases.\n*   **Label Strategies:** Label strategies with descriptive names to improve the readability of your test output.\n*   **Use Dataclasses for Structured Data:** Define dataclasses to represent structured data in your properties. This improves code readability and maintainability.\n\n### B. Strategy Design\n\n*   **Start with Built-in Strategies:** Hypothesis provides a rich set of built-in strategies for generating common data types.  Start with these strategies and customize them as needed.\n*   **Constrain Strategies Appropriately:** Use constraints (e.g., `min_value`, `max_value`, `length`) to narrow the range of values generated by your strategies and improve test performance.\n*   **Use `sampled_from` for Discrete Values:** The `sampled_from` strategy is useful for generating discrete values from a list or set.\n*   **Combine Strategies with `one_of`:** The `one_of` strategy allows you to combine multiple strategies to generate a variety of data types.\n*   **Use `lists`, `sets`, and `dictionaries` to Generate Collections:** These strategies generate collections of data.  Specify the element type and size constraints as needed.\n*   **Consider `recursive` Strategies for Nested Structures:** The `recursive` strategy allows you to generate nested data structures, such as trees or graphs.\n*   **Write Custom Strategies When Necessary:** If the built-in strategies are not sufficient, you can write custom strategies to generate data specific to your application.\n*   **Use `register_type_strategy` for Custom Types:** Register custom strategies for your custom types to make them available to other strategies.\n*   **Think About Shrinking When Designing Strategies:** Design your strategies with shrinking in mind.  The goal is to shrink failing examples to the smallest and simplest form possible.\n\n### C. Code Organization\n\n*   **Separate Tests from Implementation:** Keep your hypothesis tests in a separate directory from your implementation code (e.g., `tests/`).\n*   **Organize Tests by Module:**  Mirror the structure of your implementation code in your test directory.  Create a test module for each implementation module.\n*   **Use Descriptive Test Names:**  Give your tests descriptive names that indicate the property being tested.\n*   **Use Fixtures for Setup and Teardown:** Use pytest fixtures to handle setup and teardown tasks for your tests.\n*   **Create Helper Functions for Common Tasks:**  Create helper functions to encapsulate common tasks in your tests.\n*   **Use a `conftest.py` file:** Use a `conftest.py` file to define fixtures and other configuration options that are shared across multiple test modules.\n*   **Keep Test Modules Small:**  Break large test modules into smaller, more manageable modules.\n\n### D. Error Handling\n\n*   **Test for Expected Exceptions:** Use `pytest.raises` to assert that your code raises the expected exceptions under certain conditions.\n*   **Use Context Managers for Exception Handling:**  Use context managers to handle exceptions and ensure that resources are properly released.\n*   **Log Errors and Warnings:** Use the `logging` module to log errors and warnings in your tests.\n*   **Use `report` to Add Context to Failures:** Use `hypothesis.report` to add information about the current state of the system under test to the failure report.\n*   **Fail Fast:**  Write tests that fail quickly when a property is violated.\n\n### E. Performance Considerations\n\n*   **Minimize Computation in Properties:**  Properties should be as lightweight as possible to avoid slowing down the tests.\n*   **Use Caching to Avoid Redundant Computations:** Use caching to avoid redundant computations in your properties.\n*   **Optimize Strategies for Performance:**  Optimize your strategies to generate data efficiently.\n*   **Use `max_examples` to Limit Test Run Time:**  Use the `max_examples` setting to limit the number of examples generated by Hypothesis and prevent tests from running indefinitely.\n*   **Profile Slow Tests:**  Use profiling tools to identify slow tests and optimize their performance.\n*   **Consider Data Generation Overhead:** Be aware that complex strategy definitions can have a significant performance overhead.\n*    **Avoid Unnecessary `assume` Calls:**  Excessive use of `assume` can lead to wasted test cycles.\n\n### F. Security Best Practices\n\n*   **Test for Input Validation:** Use Hypothesis to test the input validation logic of your code. Generate a wide range of inputs, including invalid inputs, to ensure that your code handles them correctly.\n*   **Test for Common Vulnerabilities:**  Use Hypothesis to test for common vulnerabilities, such as SQL injection, cross-site scripting (XSS), and buffer overflows.\n*   **Use Strategies to Generate Malicious Inputs:**  Create strategies that generate malicious inputs to test the security of your code.\n*   **Sanitize Inputs:** Sanitize all inputs to prevent vulnerabilities.\n*   **Escape Outputs:** Escape all outputs to prevent vulnerabilities.\n*   **Use Secure API Communication:** Use HTTPS for secure API communication.\n*   **Implement Authentication and Authorization:** Implement authentication and authorization to protect your data.\n*   **Limit User Privileges:** Limit user privileges to the minimum necessary to perform their tasks.\n*   **Monitor Your Application for Security Threats:** Monitor your application for security threats and respond promptly to any incidents.\n\n### G. Common Pitfalls and Gotchas\n\n*   **Overuse of `assume()`:** As mentioned before, overuse of `assume()` can hide bugs.\n*   **Complex Strategy Definitions:**  Complex strategy definitions can be difficult to understand and maintain.\n*   **Unrealistic Test Data:**  Generating unrealistic test data can lead to false positives or false negatives.\n*   **Slow Test Execution:**  Slow test execution can make it difficult to iterate quickly.\n*   **Lack of Understanding of Shrinking:**  A lack of understanding of shrinking can make it difficult to debug failing tests.\n*   **Not Testing Edge Cases:**  Failing to test edge cases can lead to bugs in production.\n*   **Ignoring Hypothesis Output:** Ignoring the Hypothesis output can cause you to miss important information about failing tests.\n*   **Incorrect Type Annotations:** Incorrect type annotations can cause Hypothesis to generate incorrect data.\n*   **Misunderstanding of Strategy Composition:** Misunderstanding how strategies are composed can lead to unexpected results.\n\n### H. Tooling and Environment\n\n*   **pytest:** Use pytest as your test runner. It integrates seamlessly with Hypothesis and provides a rich set of features for writing and running tests.\n*   **hypothesis-auto:** Use the `hypothesis-auto` extension to automatically generate strategies for your dataclasses and other data types.\n*   **black:** Use black to automatically format your code and ensure PEP 8 compliance.\n*   **flake8:** Use flake8 to lint your code and identify potential problems.\n*   **mypy:** Use mypy to statically type check your code and identify type errors.\n*   **tox:** Use tox to automate testing in multiple environments.\n*   **CI/CD:** Integrate your tests into your CI/CD pipeline to ensure that your code is always tested before it is deployed.\n*   **VS Code or PyCharm:** Use a good IDE (like VS Code with the Python extension, or PyCharm) for code editing, debugging, and testing.\n\n### I. Testing Approaches\n\n*   **Unit Testing:**  Focus on testing individual units of code in isolation.\n*   **Integration Testing:** Test how different units of code interact with each other.\n*   **End-to-End Testing:** Test the entire application from end to end.\n*   **Property-Based Testing:** Use Hypothesis to generate a wide range of inputs and test the properties of your code.\n*   **Mutation Testing:**  Use mutation testing to assess the quality of your tests.\n\n### J. Recommended Workflow\n\n1.  **Start with a Property:** Define the property that you want to test.\n2.  **Define a Strategy:** Create a strategy to generate data for your property.\n3.  **Write the Test:** Write the test using Hypothesis and pytest.\n4.  **Run the Test:** Run the test and see if it passes.\n5.  **Fix Any Bugs:** If the test fails, fix the bug in your code.\n6.  **Repeat:** Repeat steps 1-5 until you are confident that your code is correct.\n\n## III. Example Hypothesis Test\n\npython\nimport pytest\nfrom hypothesis import given, strategies as st\n\ndef add(x, y):\n    return x + y\n\n@given(st.integers(), st.integers())\ndef test_addition_is_commutative(x, y):\n    assert add(x, y) == add(y, x)\n\n\n## IV. Conclusion\n\nBy following these best practices, you can use Hypothesis to write more effective and robust property-based tests that improve the quality and reliability of your Python code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "hypothesis.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "hypothesis",
      "comprehensive",
      "guide",
      "covering",
      "best",
      "practices",
      "python",
      "library",
      "including",
      "coding",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "hypothesis",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-insomnia",
    "description": "This rule file provides best practices for using the Insomnia API Client, including project organization, environment management, testing, and collaboration to improve API development workflows.",
    "author": "sanjeed5",
    "tags": [
      "insomnia",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/insomnia.mdc",
    "content": "- **Project Organization and Structure:**\n  - **Workspace Structure:** Organize requests into workspaces based on projects or functional areas. Within workspaces, use folders to group related requests (e.g., authentication, user management, product catalog).\n  - **Environment Management:** Leverage Insomnia's environment variables for managing configurations (API keys, base URLs, authentication tokens) across different environments (development, staging, production).  Use environment variables to store sensitive data and secrets instead of hardcoding them directly into requests. Create separate environments for each stage of the API lifecycle (development, testing, staging, production). This allows you to easily switch between different configurations without modifying your requests.\n  - **File Naming Conventions:**  Use descriptive file names for Insomnia collections (e.g., `users-api.insomnia.json`, `product-management.insomnia.yaml`). Ensure that your naming convention is clear and consistent. Name files according to their function and the API they're targeting. Using date-based versioning can also be valuable.\n  - **Collection Splitting:** For large API definitions, consider splitting collections into smaller, more manageable files based on API modules or resources. Use Insomnia's import/export functionality to combine them when needed.\n  - **Git Integration:** Store your Insomnia collections and environment files in a Git repository to track changes, collaborate with team members, and implement version control. Using Git also gives you a backup of your configuration.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Environment Overrides:** Use environment overrides to customize settings for specific requests without modifying the base environment.\n    - **Chained Requests:**  Utilize chained requests to pass data from one request to another, enabling complex workflows (e.g., creating a user, then retrieving the user's details).\n    - **Dynamic Values:** Generate dynamic values (e.g., timestamps, UUIDs) using Insomnia's built-in functions to create realistic test data.\n  - **Recommended Approaches:**\n    - **API Testing:** Use Insomnia to test HTTP-based RESTful APIs as well as GraphQL APIs. Take advantage of API testing as part of your testing strategy to test your application's core business rules and help deliver better software faster.\n    - **GraphQL Support:** Leverage Insomnia's built-in GraphQL support for constructing and executing GraphQL queries.\n    - **Authentication Handling:** Configure authentication (API keys, OAuth 2.0, JWT) at the environment or request level for consistent authentication across all requests.\n  - **Anti-patterns:**\n    - **Hardcoding Sensitive Data:** Avoid storing sensitive information directly in request bodies or headers. Use environment variables instead.\n    - **Ignoring Response Validation:** Always validate API responses (status codes, headers, data) to ensure that the API is functioning correctly.\n  - **State Management:** Insomnia itself is stateless; however, you can simulate stateful interactions using chained requests and environment variables to store and reuse data across multiple requests.\n  - **Error Handling:** Use Insomnia's response inspection tools to analyze error responses. Define specific tests to assert that error responses are handled correctly.\n\n- **Performance Considerations:**\n  - **Request Optimization:** Minimize request payload size and optimize request headers to improve API performance.\n  - **Connection Pooling:** Insomnia automatically manages connection pooling for efficient API communication.\n  - **Response Caching (Client-Side):** Consider using a proxy or interceptor to cache API responses locally for faster testing and development.\n\n- **Security Best Practices:**\n  - **Vulnerability Prevention:**\n    - **Rate Limiting:**  Simulate rate limiting scenarios to test your API's resilience to abuse.\n    - **Input Validation:** Thoroughly validate all inputs (headers, query parameters, request body) to prevent injection attacks.\n  - **Input Validation:** Utilize Insomnia's request body editor to ensure that the data being sent is correctly formatted and validated against the API's expected schema.\n  - **Authentication and Authorization:**\n    - **OAuth 2.0 Flows:** Implement OAuth 2.0 flows within Insomnia to test API authorization.\n    - **JWT Validation:** Validate JWT tokens returned by the API to ensure their integrity.\n  - **Data Protection:**\n    - **HTTPS:** Always use HTTPS for secure API communication. Insomnia automatically handles HTTPS requests.\n    - **End-to-End Encryption:** Ensure that sensitive data is encrypted both in transit and at rest. Consider using a VPN for added security.\n  - **Security Helpers**: Take advantage of security helpers, code creation, and environment variables.\n\n- **Testing Approaches:**\n  - **Unit Testing:** While Insomnia isn't a unit testing framework, you can use it to create individual requests that target specific API endpoints and validate their responses.\n  - **Integration Testing:** Use Insomnia to test the interaction between different API services and components.\n  - **End-to-End Testing:** Create comprehensive test suites in Insomnia to simulate real-world user scenarios and validate the entire API workflow.\n  - **Test Organization:** Organize tests into folders based on API resources or functional areas.\n  - **Mocking and Stubbing:**  Insomnia's mocking capabilities are essential during early stages of development or when dependent services are not available. Kong Insomnia’s mocking capabilities allow teams to simulate API responses without needing access to the actual API or back-end systems, facilitating parallel development and ensuring seamless integration testing. Kong Insomnia offers the option to mock on cloud or local for data sensitive customers.\n  - **Test Automation:** Integrate Insomnia with CI/CD pipelines to automate API testing as part of your development workflow.  Utilize the Insomnia CLI or Newman (Postman's CLI tool) to run your Insomnia collections as part of your automated test suite.\n  - **Assertions:**\n    - Validate the structure and content of API responses using Insomnia's response inspection tools and custom JavaScript assertions.\n    - Verify HTTP status codes, headers, and response times to ensure that the API is performing as expected.\n\n- **Common Pitfalls and Gotchas:**\n  - **Incorrect Environment Variables:**  Double-check that environment variables are correctly configured and referenced in your requests.\n  - **Missing Authentication Headers:** Ensure that all authenticated requests include the necessary authentication headers.\n  - **Invalid Request Payloads:**  Validate that your request payloads are correctly formatted and match the API's expected schema.\n  - **Rate Limit Exceeded Errors:**  Be aware of API rate limits and implement appropriate retry mechanisms.\n  - **Data Type Mismatches:**  Ensure that the data types in your request payloads match the API's expected data types.\n  - **Handling Large Responses:** Insomnia might struggle with extremely large API responses. Consider using a tool like `jq` to process large JSON responses.\n  - **Import/Export Issues:** Be aware of potential compatibility issues when importing or exporting Insomnia collections. Always test imported collections to ensure that they function correctly.\n  - **Version Compatibility:** Test Insomnia against the versions of APIs that you intend to target. Old API versions might have compatibility issues.\n  - **Debugging strategies:**\n    - **Response Inspection:** Use Insomnia's response inspection tools to examine the API's responses. Check the status code, headers, and body for errors or unexpected data.\n    - **Request Logging:** Enable request logging to capture detailed information about the API requests being sent. This can help you diagnose issues with the request payload, headers, or authentication.\n    - **Console Output:** Use the `console.log()` function in Insomnia's request scripts to output debug messages to the console. This can help you track the flow of data and identify potential problems.\n    - **Network Monitoring:** Use a network monitoring tool (e.g., Wireshark) to capture and analyze the network traffic between Insomnia and the API server. This can help you identify issues with the network connection, SSL/TLS configuration, or API server behavior.\n\n- **Tooling and Environment:**\n  - **Recommended Tools:**\n    - Insomnia Designer: Use Insomnia Designer to visually design and document your APIs.\n    - Insomnia CLI: Use the Insomnia CLI to automate API testing and integrate it with your CI/CD pipelines.\n    - JSON Formatter: Use a JSON formatter to validate and format your JSON request payloads.\n    - YAML Linter: Use a YAML linter to validate your YAML API definitions.\n  - **Build Configuration:** Store your Insomnia collections and environment files in a Git repository to track changes, collaborate with team members, and implement version control.\n  - **Linting and Formatting:** Enforce consistent code style and API design by using linting and formatting tools.\n  - **Deployment:**  Store your API keys and other sensitive information as environment variables on your deployment server. Use a secure deployment pipeline to ensure that your Insomnia collections and environment files are deployed correctly.\n  - **CI/CD Integration:** Use Insomnia CLI to integrate API testing into your CI/CD pipelines. Configure automated API tests to run whenever code is committed or deployed.\n\n- **Additional Best Practices:**\n  - **Documentation:** Maintain clear and up-to-date documentation for your API collections and environments.\n  - **Collaboration:** Use Insomnia's team collaboration features to share API collections and environments with your team members.\n  - **Regular Updates:** Keep Insomnia up-to-date to take advantage of the latest features and security patches.\n  - **Modular Design:** Break down large API collections into smaller, more manageable modules to improve maintainability.\n\nBy following these best practices, you can leverage Insomnia to streamline your API development workflow, improve API quality, and ensure the security of your API services.\n\n- **References**\n  - @file:./insomnia_example_rule.mdc (Example rule for chaining)",
    "metadata": {
      "globs": "*.json,*.yaml,*.yml,*.graphql,*.proto",
      "format": "mdc",
      "originalFile": "insomnia.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "insomnia",
      "this",
      "rule",
      "file",
      "provides",
      "best",
      "practices",
      "using",
      "client",
      "including",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "insomnia",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-ionic",
    "description": "This rule provides comprehensive best practices for Ionic Framework development, covering code organization, performance, security, testing, and more.  Following these guidelines will result in more maintainable, performant, and secure Ionic applications.",
    "author": "sanjeed5",
    "tags": [
      "ionic",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "mobile-development",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ionic.mdc",
    "content": "---\n# Ionic Framework Best Practices\n\nThis document outlines best practices for developing Ionic applications. Following these guidelines will help ensure your applications are maintainable, performant, secure, and testable.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nA well-organized directory structure is crucial for maintainability. Consider this structure as a starting point:\n\n\nsrc/\n  app/\n    components/\n      my-component/\n        my-component.component.ts\n        my-component.component.html\n        my-component.component.scss\n        my-component.component.spec.ts\n    pages/\n      home/\n        home.page.ts\n        home.page.html\n        home.page.scss\n        home.page.spec.ts\n    services/\n      data.service.ts\n    app.component.ts\n    app.module.ts\n    app-routing.module.ts\n  assets/\n  theme/\n    variables.scss\n  environments/\n    environment.ts\n    environment.prod.ts\n\n\n*   **`src/app`**: Contains the core application code.\n*   **`src/app/components`**: Reusable UI components.\n*   **`src/app/pages`**:  Individual application pages/views.\n*   **`src/app/services`**:  Application services for data access, business logic, etc.\n*   **`src/assets`**: Static assets like images, fonts, etc.\n*   **`src/theme`**: Global styles and variables.\n*   **`src/environments`**: Environment-specific configuration.\n\n### 1.2 File Naming Conventions\n\nUse consistent file naming conventions:\n\n*   Components: `my-component.component.ts`, `my-component.component.html`, `my-component.component.scss`\n*   Pages: `home.page.ts`, `home.page.html`, `home.page.scss`\n*   Services: `data.service.ts`\n*   Modules: `app.module.ts`, `my-module.module.ts`\n*   Interfaces: `my-interface.ts`\n*   Enums: `my-enum.ts`\n\nThis consistency improves readability and maintainability.\n\n### 1.3 Module Organization\n\n*   **Feature Modules:** Group related components, pages, and services into feature modules. This promotes modularity and lazy loading.\n*   **Shared Module:** Create a shared module for commonly used components, directives, and pipes.\n*   **Core Module:**  A core module is used for application-wide services that you only need to instantiate once.  Import it only into the `AppModule`.\n*   **Lazy Loading:**  Lazy load feature modules to improve initial load time.\n\ntypescript\n// Example of a Feature Module\nimport { NgModule } from '@angular/core';\nimport { CommonModule } from '@angular/common';\nimport { MyComponent } from './my-component/my-component.component';\nimport { MyPage } from './my-page/my-page.page';\nimport { MyService } from './my-service/my-service.service';\nimport { MyRoutingModule } from './my-routing.module';\n\n@NgModule({\n  declarations: [MyComponent, MyPage],\n  imports: [CommonModule, MyRoutingModule],\n  providers: [MyService],\n})\nexport class MyModule {}\n\n\n### 1.4 Component Architecture\n\n*   **Smart vs. Dumb Components:**\n    *   **Smart Components (Pages):** Handle data fetching, state management, and interactions with services.\n    *   **Dumb Components (Components):** Receive data via inputs and emit events via outputs. Focus on presentation and UI logic.\n*   **Component Reusability:** Design components to be reusable across different parts of the application.\n*   **Avoid Direct DOM Manipulation:** Use Angular's data binding and directives instead of directly manipulating the DOM.\n*   **Follow the Single Responsibility Principle (SRP):** Ensure each component has a specific purpose.\n\n### 1.5 Code Splitting\n\n*   **Lazy Loading Modules:** As mentioned, lazy load feature modules to reduce the initial bundle size.\n*   **Route-Based Code Splitting:** Split code based on application routes.\n*   **Conditional Loading:** Load components or modules only when they are needed.\n\n## 2. Common Patterns and Anti-Patterns\n\n### 2.1 Design Patterns\n\n*   **Model-View-Controller (MVC):**  Ionic, built on Angular, largely follows the MVC pattern.\n*   **Singleton:**  Use singletons for services that need to maintain global state (e.g., authentication service).\n*   **Observer:** Use RxJS Observables for asynchronous operations and data streams.\n*   **Facade:** Provide a simplified interface to a complex subsystem.\n*   **Dependency Injection:** Use Angular's dependency injection system to provide components with their dependencies.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Data Fetching:** Use Angular's `HttpClient` with RxJS Observables for making API requests.\n*   **Form Handling:** Use Angular's reactive forms or template-driven forms for managing form data.\n*   **Navigation:** Use the Ionic `NavController` for navigating between pages.\n*   **State Management:** Use a state management library like NgRx or Akita for complex applications.\n*   **UI Components:** Leverage Ionic's built-in UI components for a consistent look and feel.\n\n### 2.3 Anti-Patterns and Code Smells\n\n*   **Massive Components:** Avoid creating components that are too large or complex. Break them down into smaller, reusable components.\n*   **Direct DOM Manipulation:** As mentioned, avoid directly manipulating the DOM.\n*   **Nested Subscriptions:** Avoid deeply nested RxJS subscriptions, which can lead to memory leaks and difficult-to-debug code. Use operators like `switchMap`, `mergeMap`, or `concatMap` to flatten subscriptions.\n*   **Overusing `any` Type:** Avoid using the `any` type excessively. Use specific types to improve type safety and code maintainability.\n*   **Ignoring Errors:** Always handle errors properly to prevent unexpected behavior.\n*   **Global Variables:** Avoid using global variables, which can lead to naming conflicts and unpredictable behavior.\n\n### 2.4 State Management\n\n*   **Component State:** For simple component-specific state, use Angular's `@Input` and `@Output` decorators.\n*   **Service State:** For application-wide state that needs to be shared between components, use a service with RxJS `BehaviorSubject` or `ReplaySubject`.\n*   **NgRx/Akita:** For complex applications with significant state management needs, consider using a state management library like NgRx or Akita.\n    * NgRx leverages Redux principles, offering a predictable state container with actions, reducers, and effects. This is suitable for large-scale applications needing centralized state management, change tracking, and debugging tools. However, NgRx can introduce boilerplate and complexity.\n    * Akita, a state management pattern on top of RxJS, simplifies the process with less boilerplate and easier learning curve compared to Redux-based solutions. It’s suitable for small to medium-sized applications requiring scalable yet simple state management.\n\n### 2.5 Error Handling\n\n*   **Centralized Error Handling:** Create a centralized error handling service to handle errors consistently across the application.\n*   **Error Interceptors:** Use Angular's `HttpInterceptor` to intercept HTTP requests and handle errors globally.\n*   **User-Friendly Error Messages:** Display user-friendly error messages to the user.\n*   **Logging:** Log errors to a server for debugging and monitoring purposes.\n*   **Retry Mechanism:** Implement a retry mechanism for transient errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Lazy Loading:** As previously emphasized, use lazy loading for modules and components.\n*   **Ahead-of-Time (AOT) Compilation:** Use AOT compilation to compile the application during the build process, which improves startup time.\n*   **Change Detection Optimization:**\n    *   **`OnPush` Change Detection:** Use `OnPush` change detection strategy for components that only depend on input properties.  This can significantly improve performance.\n    *   **`trackBy` Function:** Use the `trackBy` function in `*ngFor` loops to improve rendering performance when the underlying data changes.\n*   **Virtual Scrolling:** Use virtual scrolling for long lists to render only the visible items.\n*   **Image Optimization:** Optimize images by compressing them and using appropriate formats.\n*   **Minify and Bundle:** Minify and bundle JavaScript and CSS files to reduce file sizes.\n*   **Caching:** Implement caching strategies for frequently accessed data.\n*   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of event handlers.\n\n### 3.2 Memory Management\n\n*   **Unsubscribe from Observables:** Always unsubscribe from RxJS subscriptions to prevent memory leaks. Use the `takeUntil` operator or a `Subject` to manage subscriptions.\n*   **Avoid Circular Dependencies:** Avoid circular dependencies between modules, which can lead to memory leaks.\n*   **Release Resources:** Release resources when they are no longer needed.\n*   **Use `async` Pipe:** Use the `async` pipe in templates to automatically unsubscribe from Observables.\n\n### 3.3 Rendering Optimization\n\n*   **Reduce DOM Updates:** Minimize the number of DOM updates by using Angular's data binding and change detection mechanisms effectively.\n*   **Use CSS Transforms:** Use CSS transforms instead of directly manipulating the DOM for animations and transitions.\n*   **Avoid Complex Expressions in Templates:** Avoid complex expressions in templates, which can impact rendering performance. Move complex logic to component classes.\n*   **Virtual DOM:** Angular uses a virtual DOM, but understanding how change detection works is critical to performance.\n\n### 3.4 Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from the bundle.\n*   **Code Splitting:** As mentioned, use code splitting to reduce the initial bundle size.\n*   **Remove Unused Dependencies:** Remove any unused dependencies from the `package.json` file.\n*   **Use Production Build:** Use the production build flag (`--prod`) when building the application for deployment.\n*   **Analyze Bundle Size:** Use tools like `webpack-bundle-analyzer` to analyze the bundle size and identify areas for optimization.\n\n### 3.5 Lazy Loading\n\n*   **Lazy Load Modules:**  This is a primary optimization strategy in Ionic.\n*   **Lazy Load Images:**  Use libraries that support lazy loading of images.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **Cross-Site Scripting (XSS):**  Prevent XSS attacks by sanitizing user input and avoiding the use of `innerHTML`. Use Angular's built-in sanitization features.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection by using tokens in HTTP requests.\n*   **Injection Attacks:** Prevent SQL injection and other injection attacks by using parameterized queries and input validation.\n*   **Insecure Data Storage:** Avoid storing sensitive data in local storage or cookies. Use secure storage mechanisms like the Ionic Native Storage plugin or a secure backend.\n*   **Man-in-the-Middle (MITM) Attacks:** Use HTTPS to encrypt communication between the app and the server.\n*   **Certificate Pinning:** Implement certificate pinning to prevent MITM attacks.\n\n### 4.2 Input Validation\n\n*   **Client-Side Validation:** Implement client-side validation to provide immediate feedback to the user.\n*   **Server-Side Validation:** Always perform server-side validation to ensure data integrity.\n*   **Sanitize User Input:** Sanitize user input to prevent XSS attacks.\n*   **Use Regular Expressions:** Use regular expressions to validate input formats.\n\n### 4.3 Authentication and Authorization\n\n*   **Use Secure Authentication:** Use a secure authentication mechanism like OAuth 2.0 or JWT (JSON Web Token).\n*   **Implement Role-Based Access Control (RBAC):** Implement RBAC to control access to different parts of the application based on user roles.\n*   **Store Tokens Securely:** Store authentication tokens securely using the Ionic Native Storage plugin or a secure backend.\n*   **Refresh Tokens:** Use refresh tokens to automatically renew authentication tokens.\n*   **Implement Multi-Factor Authentication (MFA):** Implement MFA for increased security.\n\n### 4.4 Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:** Use HTTPS for all communication between the app and the server.\n*   **Secure API Keys:** Protect API keys by storing them securely and using them only when necessary.\n*   **Data Masking:** Mask sensitive data in the UI.\n*   **Regular Security Audits:** Conduct regular security audits to identify and address potential vulnerabilities.\n\n### 4.5 Secure API Communication\n\n*   **Use HTTPS:** Use HTTPS for all API communication.\n*   **Validate API Responses:** Validate API responses to ensure data integrity.\n*   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of API endpoints.\n*   **Use API Gateways:** Use API gateways to manage and secure API traffic.\n*   **Secure API Keys:** Protect API keys by storing them securely and using them only when necessary.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Components in Isolation:** Test components in isolation using mocking and stubbing techniques.\n*   **Test Services in Isolation:** Test services in isolation by mocking their dependencies.\n*   **Use Test Doubles:** Use test doubles like stubs, mocks, and spies to isolate the code under test.\n*   **Test Boundary Conditions:** Test boundary conditions to ensure the code handles edge cases correctly.\n*   **Use Code Coverage Tools:** Use code coverage tools to measure the percentage of code that is covered by tests.\n\n### 5.2 Integration Testing\n\n*   **Test Component Interactions:** Test the interactions between components.\n*   **Test Service Interactions:** Test the interactions between services.\n*   **Test Data Flow:** Test the flow of data through the application.\n*   **Use Mock HTTP Backend:** Use a mock HTTP backend to simulate API responses.\n\n### 5.3 End-to-End Testing\n\n*   **Test User Flows:** Test the complete user flows through the application.\n*   **Use a Testing Framework:** Use a testing framework like Cypress or Protractor for end-to-end testing.\n*   **Test on Real Devices:** Test the application on real devices to ensure it works correctly in different environments.\n\n### 5.4 Test Organization\n\n*   **Locate Tests with Source Files:**  Keep test files in the same directory as the source files they test (e.g., `my-component.component.spec.ts` next to `my-component.component.ts`).\n*   **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what the test is verifying.\n*   **Organize Tests by Feature:** Organize tests by feature to improve test maintainability.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking Libraries:** Use mocking libraries like Jasmine or Sinon.js to create mocks and stubs.\n*   **Mock Dependencies:** Mock dependencies to isolate the code under test.\n*   **Stub API Responses:** Stub API responses to simulate different scenarios.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Not Unsubscribing from Observables:** Forgetting to unsubscribe from RxJS subscriptions.\n*   **Directly Manipulating the DOM:** Directly manipulating the DOM instead of using Angular's data binding.\n*   **Overusing `any` Type:** Overusing the `any` type.\n*   **Ignoring Errors:** Ignoring errors.\n*   **Not Validating User Input:** Not validating user input.\n*   **Storing Sensitive Data in Local Storage:** Storing sensitive data in local storage.\n*   **Not Using HTTPS:** Not using HTTPS for API communication.\n\n### 6.2 Edge Cases\n\n*   **Handling Network Errors:** Handling network errors gracefully.\n*   **Handling Different Screen Sizes:** Handling different screen sizes and resolutions.\n*   **Handling Different Operating Systems:** Handling different operating systems (iOS and Android).\n*   **Handling Different Device Capabilities:** Handling different device capabilities (e.g., camera, GPS).\n\n### 6.3 Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes in new versions of Ionic and Angular.  Carefully review release notes.\n*   **Deprecated Features:** Avoid using deprecated features.\n*   **Compatibility Issues:** Test the application with different versions of Ionic and Angular to ensure compatibility.\n\n### 6.4 Compatibility Concerns\n\n*   **Plugin Compatibility:** Ensure that plugins are compatible with the target platform and version of Ionic.\n*   **Browser Compatibility:** Ensure that the application works correctly in different browsers.\n*   **Cordova vs. Capacitor:**  Understand the differences and implications of using Cordova versus Capacitor.  Capacitor is generally recommended for new projects.\n\n### 6.5 Debugging Strategies\n\n*   **Use Browser Developer Tools:** Use browser developer tools to debug JavaScript, CSS, and network requests.\n*   **Use Debugging Tools:** Use debugging tools like VS Code's debugger to step through code and inspect variables.\n*   **Use Logging:** Use logging to track the flow of execution and identify potential issues.\n*   **Use Remote Debugging:** Use remote debugging to debug the application on real devices.\n*   **Learn to read Stack Traces:** Understanding the stack trace is crucial for identifying the source of errors.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code:** VS Code is a popular IDE for Ionic development with excellent support for TypeScript, HTML, and CSS.\n*   **Ionic CLI:** The Ionic CLI is a command-line tool for creating, building, and deploying Ionic applications.\n*   **Chrome DevTools:** Chrome DevTools is a powerful tool for debugging and profiling Ionic applications.\n*   **Postman/Insomnia:** Use Postman or Insomnia to test API endpoints.\n\n### 7.2 Build Configuration\n\n*   **Use Environment Variables:** Use environment variables to configure the application for different environments (e.g., development, production).\n*   **Configure Build Scripts:** Configure build scripts to automate build tasks.\n*   **Use a Build System:** Use a build system like Webpack or Parcel to manage dependencies and bundle assets.\n*   **Optimize Build Configuration:** Optimize the build configuration to reduce build time and bundle size.\n\n### 7.3 Linting and Formatting\n\n*   **Use ESLint:** Use ESLint to enforce coding standards and identify potential issues.\n*   **Use Prettier:** Use Prettier to automatically format code.\n*   **Configure Editor Integration:** Configure editor integration to automatically lint and format code on save.\n\n### 7.4 Deployment\n\n*   **Build for Production:** Build the application for production using the `--prod` flag.\n*   **Use a Deployment Platform:** Use a deployment platform like Firebase Hosting, Netlify, or AWS Amplify.\n*   **Configure HTTPS:** Configure HTTPS for the deployment environment.\n*   **Monitor Application Performance:** Monitor application performance after deployment.\n\n### 7.5 CI/CD\n\n*   **Use a CI/CD Pipeline:** Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Use a CI/CD Tool:** Use a CI/CD tool like Jenkins, CircleCI, or Travis CI.\n*   **Automate Testing:** Automate unit, integration, and end-to-end tests in the CI/CD pipeline.\n*   **Automate Deployment:** Automate deployment to different environments in the CI/CD pipeline.",
    "metadata": {
      "globs": "*.ts,*.html,*.scss",
      "format": "mdc",
      "originalFile": "ionic.mdc"
    },
    "subcategory": "cross-platform",
    "keywords": [
      "cursor",
      "ionic",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "framework",
      "development",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "cross-platform"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ionic",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-isort",
    "description": "This rule provides comprehensive guidelines for using isort in Python projects, covering code organization, common patterns, performance, security, testing, tooling, and common pitfalls. It aims to standardize import sorting and improve code quality.",
    "author": "sanjeed5",
    "tags": [
      "isort",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/isort.mdc",
    "content": "# isort Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive guide to using isort effectively in Python projects. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, tooling, and common pitfalls.\n\n## Library Information:\n- Name: isort\n- Tags: development, python, formatter, imports\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nWhile isort primarily focuses on import sorting within files, the overall directory structure impacts how imports are organized and how isort rules are applied.\n\n- **Flat Structure (Small Projects):** For smaller projects, a flat structure might suffice, with all modules in a single directory.\n- **Modular Structure (Larger Projects):** For larger projects, adopt a modular structure using packages and subpackages. This enhances maintainability and reusability.\n\n  \n  project_name/\n  ├── package1/\n  │   ├── __init__.py\n  │   ├── module1.py\n  │   └── module2.py\n  ├── package2/\n  │   ├── __init__.py\n  │   └── module3.py\n  ├── main.py\n  └── pyproject.toml (isort configuration)\n  \n\n### 1.2 File Naming Conventions Specific to isort\n\n- isort doesn't enforce specific file naming conventions but follows PEP 8 recommendations.\n- Use descriptive and consistent file names. For example, `utils.py`, `models.py`, `services.py`.\n- Lowercase with underscores for module names: `my_module.py`\n\n### 1.3 Module Organization Best Practices\n\n- **Grouping Related Functionality:** Organize modules based on related functionality.  For example, place database-related functions in a `db` module.\n- **Avoiding Circular Imports:** Be cautious of circular import dependencies, where two or more modules import each other, leading to potential runtime errors.  isort can help detect these through proper import ordering.\n- **Using Relative Imports:** Utilize relative imports within packages for internal references.\n  python\n  # Within package1/module1.py\n  from .module2 import some_function  # Relative import\n\n  # From outside the package\n  from package1.module1 import some_function\n  \n\n### 1.4 Component Architecture Recommendations\n\n- **Layered Architecture:** Consider a layered architecture (e.g., presentation, business logic, data access) to separate concerns and facilitate modularity.\n- **Microservices:** In larger applications, microservices can be used to break down the application into smaller, independent services.  Each service can have its own isort configuration.\n\n### 1.5 Code Splitting Strategies\n\n- **Splitting Large Modules:** Decompose large modules into smaller, more manageable modules to improve readability and maintainability. Each module will have its own independent import sorting managed by isort\n- **Lazy Loading:** Implement lazy loading for modules that are not immediately required to improve startup time. This may require dynamic imports, which isort can handle.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to isort\n\nisort itself doesn't directly relate to traditional design patterns like Singleton or Factory. However, its proper usage facilitates cleaner code, which makes it easier to apply other design patterns.\n\n- **Import Facade:**  Use a module to consolidate and re-export imports from other modules to simplify external dependencies.\n\n  python\n  # my_package/imports.py\n  from .module1 import ClassA\n  from .module2 import function_b\n\n  __all__ = ['ClassA', 'function_b']\n  \n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Sorting Imports:** Use isort to automatically sort imports alphabetically and group them by type (standard library, third-party, local).\n- **Integrating with Black:** Configure isort to be compatible with Black to enforce consistent code formatting.\n- **Using `pyproject.toml`:** Define isort's configuration in the `pyproject.toml` file for project-specific settings.\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Ignoring isort:** Not using isort consistently across the project leads to inconsistent import styles and reduced readability.\n- **Manual Sorting:** Manually sorting imports is error-prone and time-consuming. Use isort to automate the process.\n- **Conflicting Configurations:** Having multiple, conflicting isort configurations in different parts of the project can cause inconsistencies.\n- **Overly Complex Imports:** Avoid deep nesting or overly complex import statements, which reduce readability.\n\n### 2.4 State Management\n\n- isort is not directly involved with State Management.\n\n### 2.5 Error Handling\n\n- isort generally handles errors gracefully, such as when encountering syntax errors in files.\n- Ensure that isort configuration is valid to avoid unexpected behavior.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Caching:** isort utilizes caching to improve performance on subsequent runs. Ensure the cache directory is properly configured.\n- **Parallel Processing:**  isort supports parallel processing for faster sorting of multiple files.\n- **Minimizing File Size:** Sort imports to avoid any unnecessary circular dependency issues\n\n### 3.2 Memory Management\n\n- isort is generally memory-efficient. However, processing extremely large files may require additional memory.\n\n### 3.3 Rendering Optimization\n\n- isort doesn't involve rendering.\n\n### 3.4 Bundle Size Optimization\n\n- isort doesn't directly impact bundle size, as it's a development tool.\n\n### 3.5 Lazy Loading\n\n- isort works with modules using lazy loading; it sorts the import statements as they are written.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n- isort itself doesn't introduce security vulnerabilities, but improper coding practices can.\n\n### 4.2 Input Validation\n\n- isort doesn't handle external input; hence, input validation is not directly relevant.\n\n### 4.3 Authentication and Authorization\n\n- Authentication/Authorization not applicable to isort\n\n### 4.4 Data Protection\n\n- isort doesn't manage data.\n\n### 4.5 Secure API Communication\n\n- isort doesn't involve API communication.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- Although isort is primarily a formatting tool, consider writing unit tests to ensure its configuration produces the desired output.\n- Test cases can include verifying that imports are sorted correctly under various scenarios.\n\n### 5.2 Integration Testing\n\n- Integrate isort with other tools like Black and Flake8 in your CI/CD pipeline.  Integration tests can verify that these tools work together seamlessly.\n\n### 5.3 End-to-End Testing\n\n- isort doesn't directly require end-to-end testing.\n\n### 5.4 Test Organization\n\n- Keep test files separate from source code, usually in a dedicated `tests/` directory.\n\n### 5.5 Mocking and Stubbing\n\n- Not applicable for isort testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Incorrect Configuration:**  Misconfiguring the `pyproject.toml` file, leading to unexpected sorting behavior.\n- **Ignoring Warnings:** Ignoring warnings from isort can result in subtle bugs and inconsistent code.\n- **Not Integrating with Pre-commit:**  Failing to integrate isort with pre-commit hooks allows unformatted code to be committed.\n\n### 6.2 Edge Cases\n\n- **Complex Import Paths:**  isort might have trouble with extremely complex or dynamically generated import paths.\n- **Conditional Imports:** Be careful with conditional imports (imports within `if` statements), as isort might not always handle them correctly.\n\n### 6.3 Version-Specific Issues\n\n- Check for compatibility issues between isort versions and other tools or libraries.\n\n### 6.4 Compatibility Concerns\n\n- Ensure isort is compatible with other linters (e.g., Flake8) and formatters (e.g., Black) used in the project.\n\n### 6.5 Debugging Strategies\n\n- **Verbose Mode:** Use isort's verbose mode to get more detailed output about its actions.\n- **Configuration Testing:** Create small test files to experiment with isort configurations.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **VS Code:**  Use VS Code with the Python extension for seamless integration with isort, Black, and Flake8.\n- **PyCharm:** PyCharm provides excellent support for Python development, including built-in linting and formatting tools.\n\n### 7.2 Build Configuration\n\n- Use `pyproject.toml` to manage isort's configuration. Store configuration in version control\n- Use pre-commit hooks to ensure isort is run before each commit.\n\n### 7.3 Linting and Formatting\n\n- Integrate isort, Black, and Flake8 for comprehensive code linting and formatting.\n- Configure these tools to follow PEP 8 guidelines.\n\n### 7.4 Deployment\n\n- isort is not a deployment tool.  Ensure that your deployment process includes running linters and formatters.\n\n### 7.5 CI/CD Integration\n\n- Integrate isort into your CI/CD pipeline to automatically check code quality on each commit or pull request.\n- Use tools like GitHub Actions or GitLab CI to automate the process.\n\nBy following these best practices, you can effectively use isort to maintain consistent and high-quality code in your Python projects.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "isort.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "isort",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "using",
      "python",
      "projects",
      "covering",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "isort",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-java",
    "description": "Enforces best practices for Java development, covering code style, performance, security, and testing. Provides guidelines for writing clean, maintainable, and efficient Java code.",
    "author": "sanjeed5",
    "tags": [
      "java",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/java.mdc",
    "content": "- # Java Best Practices\n\n  This document outlines comprehensive best practices for Java development, covering code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling. Adhering to these guidelines will help you write clean, maintainable, efficient, and secure Java code.\n\n- ## 1. Code Organization and Structure\n\n  - ### 1.1 Directory Structure\n\n    - **Maven Standard Layout:**  Use the standard Maven directory structure for most projects.  This provides a consistent and predictable layout that's easily understood by other developers and tools.\n      \n      src/\n        main/\n          java/\n            com/example/  <- Your package structure starts here\n          resources/\n        test/\n          java/\n            com/example/\n          resources/\n        pom.xml  <- Maven project file\n      \n    - **Gradle Layout:** Gradle supports the Maven layout and provides other ways to configure the source directories. Choose a layout that best fits your project's needs.\n\n    - **Package by Feature:** Organize packages by feature rather than by layer (e.g., controllers, services, repositories).  This improves cohesion and reduces dependencies between features.\n      \n      src/\n        main/\n          java/\n            com/example/\n              user/\n                UserController.java\n                UserService.java\n                UserRepository.java\n              product/\n                ProductController.java\n                ProductService.java\n                ProductRepository.java\n      \n    - **Modularization:**  For large projects, consider using Java modules (Jigsaw, introduced in Java 9) to improve encapsulation and reduce dependencies.\n\n  - ### 1.2 File Naming Conventions\n\n    - **Classes and Interfaces:** Use `PascalCase` (e.g., `UserController`, `UserService`).\n    - **Methods and Variables:** Use `camelCase` (e.g., `getUserById`, `userName`).\n    - **Constants:** Use `UPPER_SNAKE_CASE` (e.g., `MAX_RETRIES`, `DEFAULT_TIMEOUT`).\n    - **Packages:** Use all lowercase (e.g., `com.example.user`).\n    - **Avoid abbreviations:** Use meaningful and descriptive names.\n\n  - ### 1.3 Module Organization\n\n    - **`module-info.java`:**  Use `module-info.java` to define module dependencies and exported packages.  This allows for strong encapsulation and controlled access to internal APIs.\n    - **Explicit Dependencies:**  Declare all module dependencies explicitly in `module-info.java`.  Avoid relying on transitive dependencies.\n    - **Minimize Exports:** Only export the packages that are intended for public use.  Keep internal packages hidden from other modules.\n\n  - ### 1.4 Component Architecture\n\n    - **Dependency Injection:** Use dependency injection (DI) to manage component dependencies. Frameworks like Spring and Guice simplify DI.\n    - **Inversion of Control (IoC):**  Apply IoC to decouple components and improve testability.\n    - **Layered Architecture:**  Structure your application into layers (e.g., presentation, business logic, data access).  This promotes separation of concerns and maintainability.\n    - **Microservices:** For large, complex applications, consider a microservices architecture. This allows for independent development, deployment, and scaling of individual services.\n\n  - ### 1.5 Code Splitting\n\n    - **Feature Toggles:** Use feature toggles to enable or disable features at runtime. This allows for incremental deployment and testing of new features.\n    - **Dynamic Loading:**  Use dynamic class loading to load modules or components on demand. This can reduce the initial startup time and memory footprint of your application.\n    - **Conditional Compilation:** Use conditional compilation (e.g., with Maven profiles) to include or exclude code based on the environment. This allows for different configurations for development, testing, and production.\n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### 2.1 Design Patterns\n\n    - **Singleton:**  Use the Singleton pattern sparingly and only when a single instance of a class is truly required. Consider dependency injection as an alternative.\n    - **Factory:**  Use the Factory pattern to create objects without specifying their concrete classes.  This promotes loose coupling and allows for easy substitution of different implementations.\n    - **Strategy:** Use the Strategy pattern to encapsulate different algorithms or behaviors. This allows you to switch between algorithms at runtime.\n    - **Observer:**  Use the Observer pattern to define a one-to-many dependency between objects. This allows for loose coupling and easy addition of new observers.\n    - **Template Method:** Use the Template Method pattern to define the skeleton of an algorithm in a base class, allowing subclasses to override specific steps without changing the overall structure.\n    - **Builder:** Use the Builder pattern to construct complex objects with many optional parameters. This improves readability and reduces the risk of errors.\n\n  - ### 2.2 Recommended Approaches\n\n    - **Resource Management:** Always use try-with-resources to ensure proper resource management (e.g., closing streams, connections). This prevents resource leaks.\n      java\n      try (FileInputStream fis = new FileInputStream(\"file.txt\")) {\n          // Use the file input stream\n      }\n      \n    - **String Concatenation:** Use `StringBuilder` or `StringBuffer` for string concatenation, especially in loops.  Avoid using the `+` operator for repeated string concatenation.\n      java\n      StringBuilder sb = new StringBuilder();\n      for (int i = 0; i < 100; i++) {\n          sb.append(i);\n      }\n      String result = sb.toString();\n      \n    - **Collections:** Prefer Java Collections over arrays for their flexibility and utility. Use generics to ensure type safety.\n\n  - ### 2.3 Anti-patterns and Code Smells\n\n    - **God Class:** Avoid creating large classes that do too much.  Break down large classes into smaller, more manageable components.\n    - **Long Method:** Avoid creating long methods.  Break down long methods into smaller, more focused methods.\n    - **Shotgun Surgery:**  Avoid making many small changes in multiple classes.  This indicates a lack of cohesion and can make it difficult to maintain the code.\n    - **Data Clumps:** Avoid passing the same group of data items together in multiple methods. Create a class to encapsulate the data items.\n    - **Primitive Obsession:** Avoid using primitive types excessively. Create value objects to represent domain concepts.\n    - **Switch Statements:** Limit use of switch statements especially with larger number of cases. Consider using polymorphism with Strategy pattern.\n    - **Empty Catch Blocks:** Avoid empty catch blocks.  Always handle exceptions appropriately, either by logging them, rethrowing them, or taking corrective action.\n\n  - ### 2.4 State Management\n\n    - **Immutability:**  Prefer immutable objects whenever possible.  Immutable objects are thread-safe and easier to reason about.\n    - **Stateless Services:** Design services to be stateless. This improves scalability and simplifies testing.\n    - **Session Management:**  Use session management frameworks (e.g., Spring Session) to manage user sessions in web applications.\n\n  - ### 2.5 Error Handling\n\n    - **Exceptions for Exceptional Cases:**  Use exceptions only for exceptional cases, not for normal control flow.\n    - **Specific Exception Types:**  Catch specific exception types rather than generic `Exception`. This allows you to handle different types of errors differently.\n    - **Logging:** Log exceptions with sufficient context to aid debugging.  Include the stack trace and any relevant data.\n    - **Custom Exceptions:** Create custom exception types to represent application-specific errors.\n    - **Don't Swallow Exceptions:** Never swallow exceptions without logging or handling them. It hides the exception making debugging much harder.\n\n- ## 3. Performance Considerations\n\n  - ### 3.1 Optimization Techniques\n\n    - **Caching:**  Use caching to store frequently accessed data in memory. Frameworks like Caffeine and Guava Cache provide efficient caching implementations.\n    - **Connection Pooling:**  Use connection pooling to reuse database connections. This reduces the overhead of creating and closing connections.\n    - **Efficient Algorithms:**  Choose appropriate algorithms for specific tasks.  Consider the time and space complexity of different algorithms.\n    - **Lazy Initialization:** Use lazy initialization to defer the creation of objects until they are actually needed.\n    - **Minimize Object Creation:**  Reduce unnecessary object creation. Use object pooling or reuse existing objects whenever possible.\n\n  - ### 3.2 Memory Management\n\n    - **Garbage Collection:**  Understand how Java's garbage collector works.  Avoid creating objects that are quickly discarded, as this puts pressure on the garbage collector.\n    - **Memory Profiling:**  Use memory profiling tools to identify memory leaks and optimize memory usage.\n    - **Large Objects:** Be careful when handling large objects. They can cause fragmentation and increase garbage collection times.\n\n  - ### 3.3 Rendering Optimization (If Applicable)\n\n    - **Buffering:** Use buffering to reduce the number of I/O operations when rendering large amounts of data.\n    - **Compression:** Use compression to reduce the size of rendered data.\n\n  - ### 3.4 Bundle Size Optimization (If Applicable)\n\n    - **Code Minification:**  Use code minification to reduce the size of your codebase.\n    - **Dead Code Elimination:**  Remove unused code to reduce the bundle size.\n\n  - ### 3.5 Lazy Loading\n\n    - **On-Demand Loading:**  Load resources or components only when they are needed.\n    - **Virtual Proxy:**  Use a virtual proxy to delay the loading of a heavy resource until it is accessed.\n\n- ## 4. Security Best Practices\n\n  - ### 4.1 Common Vulnerabilities\n\n    - **SQL Injection:**  Prevent SQL injection by using parameterized queries or prepared statements.  Never concatenate user input directly into SQL queries.\n    - **Cross-Site Scripting (XSS):**  Prevent XSS by encoding user input before displaying it in web pages.\n    - **Cross-Site Request Forgery (CSRF):**  Prevent CSRF by using anti-CSRF tokens.\n    - **Authentication and Authorization Issues:**  Implement proper authentication and authorization mechanisms to protect sensitive resources.\n    - **Denial of Service (DoS):**  Protect against DoS attacks by limiting request rates and implementing rate limiting.\n    - **Insecure Deserialization:** Prevent insecure deserialization by avoiding deserialization of untrusted data, or using secure deserialization methods.\n    - **Dependency Vulnerabilities:**  Use tools like OWASP Dependency-Check to identify and mitigate vulnerabilities in third-party libraries.\n\n  - ### 4.2 Input Validation\n\n    - **Whitelisting:**  Use whitelisting to validate input against a list of allowed values.  Avoid blacklisting, as it is difficult to anticipate all possible malicious inputs.\n    - **Regular Expressions:**  Use regular expressions to validate input patterns (e.g., email addresses, phone numbers).\n    - **Length Limits:**  Enforce length limits on input fields to prevent buffer overflows.\n    - **Encoding:** Encode user input to prevent XSS attacks.\n\n  - ### 4.3 Authentication and Authorization\n\n    - **Strong Passwords:**  Enforce strong password policies (e.g., minimum length, complexity).\n    - **Hashing:**  Hash passwords using a strong hashing algorithm (e.g., bcrypt, Argon2) and a salt.\n    - **Two-Factor Authentication (2FA):**  Implement 2FA to provide an extra layer of security.\n    - **Role-Based Access Control (RBAC):**  Use RBAC to control access to resources based on user roles.\n    - **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n\n  - ### 4.4 Data Protection\n\n    - **Encryption:**  Encrypt sensitive data at rest and in transit.\n    - **Data Masking:**  Mask sensitive data in logs and error messages.\n    - **Access Control:**  Restrict access to sensitive data to authorized users only.\n\n  - ### 4.5 Secure API Communication\n\n    - **HTTPS:** Use HTTPS for all API communication.\n    - **TLS/SSL:**  Configure TLS/SSL properly to ensure secure communication.\n    - **API Keys:**  Use API keys to authenticate API clients.\n    - **Rate Limiting:**  Implement rate limiting to prevent abuse of your APIs.\n    - **Input Validation:**  Validate all input to your APIs to prevent injection attacks.\n\n- ## 5. Testing Approaches\n\n  - ### 5.1 Unit Testing\n\n    - **JUnit:**  Use JUnit for unit testing.\n    - **Mockito:**  Use Mockito for mocking dependencies.\n    - **Arrange-Act-Assert:**  Follow the Arrange-Act-Assert pattern in your unit tests.\n    - **Test Coverage:**  Aim for high test coverage.\n    - **Independent Tests:** Write independent tests such that failure of one test doesn't affect another test.\n\n  - ### 5.2 Integration Testing\n\n    - **Testcontainers:** Use Testcontainers to create lightweight, disposable instances of databases and other services for integration testing.\n    - **Spring Boot Test:** Use Spring Boot's testing support for integration testing Spring applications.\n\n  - ### 5.3 End-to-End Testing\n\n    - **Selenium:**  Use Selenium for end-to-end testing of web applications.\n    - **Cypress:** Consider Cypress as an alternative to Selenium for end-to-end tests.\n\n  - ### 5.4 Test Organization\n\n    - **Test Directory:**  Place your tests in a separate `test` directory.\n    - **Naming Conventions:**  Use clear naming conventions for your tests (e.g., `UserServiceTest`).\n    - **Test Suites:**  Group related tests into test suites.\n\n  - ### 5.5 Mocking and Stubbing\n\n    - **Mockito:**  Use Mockito to create mocks and stubs for your tests.\n    - **Verify Interactions:**  Verify that your code interacts with dependencies as expected.\n    - **Avoid Over-Mocking:**  Avoid mocking too many dependencies.  Focus on mocking the dependencies that are critical to the test.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### 6.1 Frequent Mistakes\n\n    - **NullPointerExceptions:** Handle null values carefully to avoid `NullPointerException`.\n    - **Resource Leaks:**  Ensure that all resources are properly closed to avoid resource leaks.\n    - **Thread Safety Issues:**  Be aware of thread safety issues when writing multithreaded code.\n    - **Ignoring Exceptions:** Never ignore exceptions without logging or handling them. It hides the exception making debugging much harder.\n\n  - ### 6.2 Edge Cases\n\n    - **Boundary Conditions:**  Test boundary conditions to ensure that your code handles edge cases correctly.\n    - **Empty Collections:**  Handle empty collections gracefully.\n    - **Invalid Input:**  Validate input to ensure that it is within the expected range.\n\n  - ### 6.3 Version-Specific Issues\n\n    - **Deprecated APIs:**  Be aware of deprecated APIs and avoid using them.\n    - **Compatibility Issues:**  Test your code with different versions of Java to ensure compatibility.\n\n  - ### 6.4 Compatibility Concerns\n\n    - **JVM Compatibility:**  Ensure that your code is compatible with different JVM implementations.\n    - **Library Compatibility:**  Be aware of compatibility issues between different libraries.\n\n  - ### 6.5 Debugging Strategies\n\n    - **Logging:**  Use logging to track the execution of your code and identify errors.\n    - **Debugging Tools:**  Use debugging tools to step through your code and inspect variables.\n    - **Remote Debugging:**  Use remote debugging to debug applications running on remote servers.\n    - **JVM Profilers:** Use profilers like JProfiler or VisualVM to identify performance bottlenecks and memory leaks.\n\n- ## 7. Tooling and Environment\n\n  - ### 7.1 Recommended Tools\n\n    - **IntelliJ IDEA:**  A powerful IDE for Java development with excellent code completion, refactoring, and debugging support.\n    - **Eclipse:** Another popular IDE for Java development.\n    - **Maven:**  A build automation tool for managing dependencies, building, and deploying Java projects.\n    - **Gradle:**  A build automation tool that provides more flexibility and control than Maven.\n\n  - ### 7.2 Build Configuration\n\n    - **Dependency Management:**  Use Maven or Gradle to manage dependencies.\n    - **Version Control:**  Use version control (e.g., Git) to track changes to your codebase.\n    - **Build Profiles:**  Use build profiles to configure different builds for different environments.\n\n  - ### 7.3 Linting and Formatting\n\n    - **Checkstyle:** Use Checkstyle to enforce coding standards.\n    - **PMD:** Use PMD to find potential bugs and code smells.\n    - **SpotBugs:** Use SpotBugs to find potential bugs.\n    - **Formatter:** Use automatic code formatting tools like IntelliJ's built-in formatter or plugins like `google-java-format` for consistency.\n\n  - ### 7.4 Deployment\n\n    - **Docker:** Use Docker to containerize your applications.\n    - **Kubernetes:** Use Kubernetes to orchestrate your containers.\n    - **Cloud Platforms:** Deploy your applications to cloud platforms like AWS, Azure, or Google Cloud.\n\n  - ### 7.5 CI/CD\n\n    - **Jenkins:** Use Jenkins for continuous integration and continuous delivery.\n    - **GitHub Actions:** Use GitHub Actions for CI/CD.\n    - **GitLab CI:** Use GitLab CI for CI/CD.\n    - **Automated Testing:**  Automate your unit, integration, and end-to-end tests in your CI/CD pipeline.\n\nBy adhering to these best practices, you can improve the quality, maintainability, and performance of your Java code. Remember to adapt these guidelines to your specific project requirements and team preferences.",
    "metadata": {
      "globs": "*.java",
      "format": "mdc",
      "originalFile": "java.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "java",
      "enforces",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "style",
      "performance",
      "security",
      "cursor-rule",
      "mdc",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "java",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-jax",
    "description": "This rule provides best practices and coding standards for the JAX library, emphasizing functional programming, JIT compilation, automatic differentiation, and immutable data structures. It also covers performance considerations, common pitfalls, and tooling recommendations.",
    "author": "sanjeed5",
    "tags": [
      "jax",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/jax.mdc",
    "content": "- **Functional Programming**: JAX emphasizes a functional programming style. Ensure functions are pure (no side effects, no reliance on global variables) for consistent JIT compilation and optimization.\n\n- **JIT Compilation**: Use `@jax.jit` to decorate functions for performance optimization, especially those called multiple times with the same input shapes. Understand the implications of tracing and static arguments.\n\n- **Automatic Differentiation**: Leverage `jax.grad()` for efficient gradient calculations and higher-order derivatives.  Be mindful of how JAX handles gradients with control flow and other transformations.\n\n- **Vectorization with `vmap`**: Utilize `jax.vmap()` for automatic vectorization instead of explicit loops. This improves performance by mapping operations across array dimensions.\n\n- **Immutable Data Structures**: JAX arrays are immutable. Use `.at[].set()` for updates. Understand that these operations are out-of-place, returning a new array. In-place updates *may* occur under jit-compilation if the original value isn't reused, but rely on the functional style.\n\n- **Random Number Generation**: Use `jax.random` for random number generation. Employ explicit PRNG state management. Always split the key using `jax.random.split()` before generating random numbers to avoid reusing the same state.\n\n- **Control Flow**: Be aware of limitations when using Python control flow with `jax.jit`. Use `static_argnums` to specify arguments for tracing on concrete values if necessary. Consider structured control flow primitives like `lax.cond`, `lax.while_loop`, `lax.fori_loop`, and `lax.scan` for better traceability and avoiding large loop unrolling.  Understand which control flow constructs are differentiable.\n\n- **Dynamic Shapes**: Avoid dynamic shapes within JAX transformations like `jax.jit`, `jax.vmap`, and `jax.grad`.  The shapes of output arrays must not depend on values within other arrays. Use techniques like `jnp.where` to work around the need for dynamically-sized arrays.\n\n- **NaN Handling**: Use the NaN-checker during debugging by setting `JAX_DEBUG_NANS=True` or using `jax.config.update(\"jax_debug_nans\", True)`.  Be aware that this adds overhead and should be disabled in production.\n\n- **Double Precision**: Enable double-precision numbers by setting the `jax_enable_x64` configuration variable at startup (`JAX_ENABLE_X64=True` environment variable, `jax.config.update(\"jax_enable_x64\", True)`, or `jax.config.parse_flags_with_absl()`).  Note that not all backends support 64-bit convolutions.\n\n- **Non-array Inputs**: JAX generally expects NumPy arrays as inputs to its API functions. Avoid passing Python lists or tuples directly; convert them to arrays first.\n\n- **Out-of-Bounds Indexing**: JAX handles out-of-bounds indexing by clamping the index to the bounds of the array for retrieval operations. Array update operations at out-of-bounds indices are skipped. Use the optional parameters of `ndarray.at` for finer-grained control.\n\n- **Miscellaneous Divergences from NumPy**: Be aware of differences in type promotion rules, unsafe type casts, and other corner cases where JAX's behavior may differ from NumPy.\n\n## Code Organization and Structure:\n\n- **Directory Structure**: Consider a structure like this:\n  \n  project_root/\n  ├── src/\n  │   ├── __init__.py\n  │   ├── models/\n  │   │   ├── __init__.py\n  │   │   ├── model_a.py\n  │   │   └── model_b.py\n  │   ├── layers/\n  │   │   ├── __init__.py\n  │   │   ├── layer_a.py\n  │   │   └── layer_b.py\n  │   ├── utils/\n  │   │   ├── __init__.py\n  │   │   ├── data_loading.py\n  │   │   └── evaluation.py\n  │   ├── train.py\n  │   └── predict.py\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── models/\n  │   │   ├── test_model_a.py\n  │   │   └── test_model_b.py\n  │   ├── utils/\n  │   │   ├── test_data_loading.py\n  │   │   └── test_evaluation.py\n  │   └── test_train.py\n  ├── notebooks/\n  │   ├── exploration.ipynb\n  │   └── analysis.ipynb\n  ├── data/\n  │   ├── raw/\n  │   └── processed/\n  ├── models/\n  │   └── saved_models/\n  ├── .gitignore\n  ├── README.md\n  ├── requirements.txt\n  └── setup.py\n  \n\n- **File Naming**: Use descriptive, lowercase names with underscores (e.g., `data_loading.py`, `model_a.py`).\n\n- **Module Organization**: Group related functionalities into modules.  Use clear and concise module names.\n\n- **Component Architecture**: Favor a modular architecture. Decouple components where possible. Use interfaces or abstract base classes when appropriate.\n\n- **Code Splitting**: Split large files into smaller, more manageable modules.  Consider splitting based on functionality or abstraction level.\n\n## Common Patterns and Anti-patterns:\n\n- **Design Patterns**: Consider patterns like:\n    - **Strategy**: For selecting different computation strategies at runtime.\n    - **Factory**: For creating JAX models or layers.\n    - **Observer**: For monitoring training progress.\n\n- **Recommended Approaches**: \n    - Using `jax.tree_util` for working with nested data structures (pytrees).\n    - Caching intermediate results with `lru_cache` (with caution, as it introduces state).\n    - Using `jax.experimental.optimizers` for defining optimization schedules.\n\n- **Anti-patterns**: \n    - Mutable global state within JIT-compiled functions.\n    - Excessive use of `static_argnums` (leads to recompilation).\n    - Ignoring the immutability of JAX arrays.\n    - Using Python loops instead of vectorized operations (`vmap`).\n    - Unnecessary host-device data transfers.\n    - Reusing PRNG keys without splitting.\n\n- **State Management**: \n    - Avoid global mutable state. Pass state explicitly as function arguments.\n    - Consider using immutable data structures for state.\n    - If mutable state is absolutely necessary (e.g., in some RL settings), use JAX's stateful computation tools carefully (e.g., `jax.lax.scan` with a carry).\n\n- **Error Handling**: \n    - Use `try...except` blocks for handling potential errors during data loading or preprocessing.\n    - Employ assertions to check for invalid input or unexpected conditions.\n    - Utilize logging to track errors and debug issues.\n    - The `JAX_DEBUG_NANS` and `JAX_DEBUG_NANS=True` flag is critical when debugging `NaN`.\n\n## Performance Considerations:\n\n- **Optimization Techniques**: \n    - JIT compilation (`jax.jit`).\n    - Vectorization (`jax.vmap`).\n    - Parallelization (`jax.pmap`).\n    - Fusion of operations.\n    - Reducing host-device data transfers.\n    - Choose appropriate data types (e.g., `float32` instead of `float64` if sufficient).\n    - Use `jax.numpy` functions instead of NumPy functions where possible.\n    - Avoid scalar operations inside JIT-compiled loops; use array operations.\n\n- **Memory Management**: \n    - Minimize the creation of large intermediate arrays.\n    - Reuse arrays where possible (using `.at[].set()` for in-place updates if safe to do so).\n    - Be aware of memory fragmentation.\n    - If you are dealing with datasets larger than memory, explore data streaming/sharding approaches.\n\n- **Rendering Optimization**:  (Relevant if using JAX for visualization, e.g., with OpenGL or similar libraries)\n    - Batch rendering operations.\n    - Optimize data transfer to the rendering device (e.g., GPU).\n    - Consider using specialized rendering libraries that are compatible with JAX arrays.\n\n- **Bundle Size Optimization**: (For JAX-based applications deployed in web environments)\n    - Tree-shake unused code.\n    - Minify JavaScript bundles.\n    - Use code splitting to load only necessary modules.\n    - Compress assets (e.g., images, data files).\n\n- **Lazy Loading**: \n    - Load data or models only when needed.\n    - Use iterators or generators for large datasets.\n    - Implement a loading indicator to provide feedback to the user.\n\n## Security Best Practices:\n\n- **Common Vulnerabilities**: \n    - Input data poisoning.\n    - Model inversion attacks.\n    - Adversarial examples.\n    - Side-channel attacks (less relevant in typical JAX applications, but important in cryptographic applications).\n\n- **Input Validation**: \n    - Validate input data types and ranges.\n    - Sanitize input data to prevent injection attacks.\n    - Use schema validation libraries (e.g., `cerberus`, `jsonschema`).\n\n- **Authentication and Authorization**:  (If building APIs or web services with JAX)\n    - Implement secure authentication mechanisms (e.g., OAuth 2.0, JWT).\n    - Use role-based access control (RBAC) to restrict access to sensitive resources.\n    - Protect API endpoints with appropriate authentication and authorization checks.\n\n- **Data Protection**: \n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms for models and data.\n    - Implement data masking or anonymization techniques to protect personally identifiable information (PII).\n\n- **Secure API Communication**: \n    - Use HTTPS for all API communication.\n    - Implement proper rate limiting to prevent denial-of-service attacks.\n    - Use secure coding practices to prevent common web vulnerabilities (e.g., cross-site scripting, SQL injection).\n\n## Testing Approaches:\n\n- **Unit Testing**: \n    - Test individual functions or classes in isolation.\n    - Use `pytest` or `unittest` for writing unit tests.\n    - Mock external dependencies to isolate the code under test.\n    - Test different input scenarios and edge cases.\n    - Use `jax.random.PRNGKey` with a fixed seed for reproducible tests.\n\n- **Integration Testing**: \n    - Test the interaction between different components or modules.\n    - Verify that data flows correctly between components.\n    - Test the integration with external services or databases.\n\n- **End-to-End Testing**: \n    - Test the entire application flow from start to finish.\n    - Simulate real user interactions.\n    - Verify that the application meets the specified requirements.\n    - Use tools like Selenium or Cypress for end-to-end testing.\n\n- **Test Organization**: \n    - Organize tests into separate directories or modules.\n    - Use descriptive test names.\n    - Follow a consistent testing style.\n\n- **Mocking and Stubbing**: \n    - Use `unittest.mock` or `pytest-mock` for mocking external dependencies.\n    - Create stubs for complex or time-consuming operations.\n    - Mock JAX functions (e.g., `jax.random.normal`) to control the output of random number generators.\n\n## Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes**: \n    - Mutable global state in JIT-compiled functions.\n    - Incorrect use of `static_argnums`.\n    - Ignoring JAX array immutability.\n    - Using Python loops instead of `vmap`.\n    - Reusing PRNG keys without splitting.\n\n- **Edge Cases**: \n    - Handling `NaN` and `Inf` values.\n    - Dealing with numerical instability.\n    - Working with sparse data.\n    - Optimizing for different hardware backends (CPU, GPU, TPU).\n\n- **Version-Specific Issues**: \n    - Be aware of breaking changes between JAX versions.\n    - Consult the JAX documentation for the latest updates and bug fixes.\n\n- **Compatibility Concerns**: \n    - Ensure compatibility between JAX and other libraries (e.g., TensorFlow, PyTorch).\n    - Be aware of potential conflicts between JAX and NumPy versions.\n\n- **Debugging Strategies**: \n    - Use the JAX debugger (`jax.debug.print`).\n    - Set `JAX_DEBUG_NANS=True` to detect `NaN` values.\n    - Use `jax.make_jaxpr` to inspect the JAX program representation.\n    - Use `jax.debug.visualize_jaxpr` to visualize the JAX program flow (requires graphviz).\n    - Profile your code to identify performance bottlenecks.\n    - Use a debugger (e.g., `pdb`) to step through your code and inspect variables.\n\n## Tooling and Environment:\n\n- **Recommended Development Tools**: \n    - VS Code with the Python extension.\n    - Jupyter Notebook or JupyterLab for interactive development.\n    - IPython for a powerful interactive shell.\n    - TensorBoard for visualizing training progress.\n\n- **Build Configuration**: \n    - Use `requirements.txt` or `setup.py` to manage dependencies.\n    - Specify JAX version requirements.\n    - Use a virtual environment (e.g., `venv`, `conda`) to isolate dependencies.\n\n- **Linting and Formatting**: \n    - Use `flake8` or `pylint` for linting.\n    - Use `black` or `autopep8` for formatting.\n    - Configure your editor to automatically lint and format code on save.\n\n- **Deployment Best Practices**: \n    - Package your application into a Docker container.\n    - Use a cloud platform (e.g., AWS, Google Cloud, Azure) for deployment.\n    - Use a deployment framework (e.g., Flask, FastAPI) for serving APIs.\n    - Monitor your application for performance and errors.\n\n- **CI/CD Integration**: \n    - Use a CI/CD platform (e.g., GitHub Actions, Travis CI, CircleCI).\n    - Automate testing, linting, and formatting.\n    - Automate deployment to staging and production environments.\n\n\nThis comprehensive guide should help developers write better JAX code, avoid common pitfalls, and build high-performance machine learning applications.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "jax.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "jax",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "library",
      "emphasizing",
      "functional",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "jax",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-jenkins",
    "description": "Comprehensive best practices for Jenkins, covering code organization, security, performance, testing, and common pitfalls.  Provides guidelines for writing robust, maintainable, and secure Jenkins pipelines and configurations.",
    "author": "sanjeed5",
    "tags": [
      "jenkins",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/jenkins.mdc",
    "content": "# Jenkins Library Best Practices and Coding Standards\n\nThis document outlines best practices for developing and maintaining Jenkins pipelines and configurations to ensure robustness, security, and efficiency.\n\n## 1. Code Organization and Structure\n\n*   **Directory Structure:**\n    *   `/vars/`: Store shared pipeline libraries (Groovy files).  Each file in this directory represents a callable method.\n    *   `/resources/`:  Place non-Groovy resources like configuration files or scripts used by the pipeline.\n    *   `Jenkinsfile`:  The primary pipeline definition file, typically at the root of the repository.\n    *   `.cursor/rules`: Where .mdc rule files should be\n*   **File Naming Conventions:**\n    *   Pipeline definitions: `Jenkinsfile` (recommended), or `<project-name>.jenkins`\n    *   Shared libraries: `lowercaseCamelCase.groovy` (e.g., `buildImage.groovy`)\n    *   Resource files:  Descriptive names with appropriate extensions (e.g., `settings.xml`, `deploy.sh`)\n*   **Module Organization:**\n    *   Break down complex pipelines into smaller, reusable shared libraries.\n    *   Group related functions within shared libraries into logical modules.\n    *   Use descriptive names for shared libraries to indicate their purpose (e.g., `awsUtils.groovy`, `dockerBuild.groovy`).\n*   **Component Architecture:**\n    *   Adopt a modular design for shared libraries, separating concerns and promoting reusability.\n    *   Create abstract functions that can be extended or customized for specific projects.\n    *   Avoid tightly coupling shared libraries to specific projects or environments.\n*   **Code Splitting Strategies:**\n    *   Split long `Jenkinsfile`s into multiple files using `load()` or shared libraries.  This improves readability and maintainability.\n    *   Delegate complex tasks to external scripts or tools invoked from the pipeline.\n    *   Use environment variables to parameterize pipeline behavior and avoid hardcoding values.\n\n## 2. Common Patterns and Anti-patterns\n\n*   **Design Patterns:**\n    *   **Strategy Pattern:** Implement different build or deployment strategies based on input parameters.\n    *   **Template Method Pattern:** Define a base pipeline structure with customizable steps for specific projects.\n    *   **Facade Pattern:**  Create a simplified interface to complex systems or tools.\n*   **Recommended Approaches:**\n    *   Use declarative pipelines for improved readability and maintainability.\n    *   Employ shared libraries to promote code reuse and consistency.\n    *   Automate testing and security scanning within the pipeline.\n    *   Monitor pipeline performance and optimize for speed and efficiency.\n    *   Use a version control system (e.g., Git) to track changes to pipeline definitions and shared libraries.\n*   **Anti-patterns and Code Smells:**\n    *   **Large, monolithic `Jenkinsfile`s:**  Difficult to read, maintain, and debug.\n    *   **Hardcoding sensitive information:**  Compromises security and makes pipelines inflexible.\n    *   **Lack of error handling:**  Pipelines fail without clear error messages or recovery mechanisms.\n    *   **Excessive Groovy scripting:**  Can impact performance and increase complexity. Delegate tasks to external tools where possible.\n    *   **Ignoring security vulnerabilities:**  Exposes systems to potential attacks.\n    *   **Duplicated code across pipelines:** Indicates a need for shared libraries.\n*   **State Management:**\n    *   Use environment variables to store pipeline state.\n    *   Persist state to external systems (e.g., databases, artifact repositories) for long-running pipelines.\n    *   Avoid relying on global variables or mutable shared state.\n*   **Error Handling:**\n    *   Use `try...catch` blocks to handle exceptions and prevent pipeline failures.\n    *   Log error messages with sufficient detail to facilitate debugging.\n    *   Implement retry mechanisms for transient errors.\n    *   Use the `error` step to explicitly fail the pipeline with a custom message.\n    *   Consider using `unstash` with error handling to clean up temporary files.\n\n## 3. Performance Considerations\n\n*   **Optimization Techniques:**\n    *   Parallelize build and test stages to reduce overall execution time.\n    *   Use caching to avoid redundant downloads and computations.\n    *   Optimize Groovy code for performance (e.g., avoid unnecessary iterations).\n    *   Use lightweight agents with sufficient resources to handle the workload.\n    *   Leverage build accelerators and distributed build systems.\n*   **Memory Management:**\n    *   Avoid loading large files into memory using `JsonSlurper` or `XmlSlurper`. Use `sh` step with tools like `jq` or `xmllint` instead.\n    *   Limit the use of global variables and shared state to reduce memory consumption.\n    *   Monitor agent memory usage and adjust agent resources accordingly.\n*   **Bundle Size Optimization:** (Not directly applicable to Jenkins pipelines but relevant to applications built by Jenkins)\n    *   Minimize dependencies and remove unused code.\n    *   Use code splitting to load only the necessary code modules.\n    *   Compress artifacts before archiving or deploying them.\n*   **Lazy Loading:** (Not directly applicable to Jenkins pipelines themselves, but is related to web applications that are built using Jenkins).\n    *   Load resources on demand instead of upfront to reduce initial load time.\n    *   Defer the execution of non-critical tasks until they are needed.\n    *   Utilize asynchronous operations to avoid blocking the pipeline execution.\n\n## 4. Security Best Practices\n\n*   **Common Vulnerabilities:**\n    *   **Cross-Site Scripting (XSS):**  Sanitize user input to prevent malicious code injection.\n    *   **Cross-Site Request Forgery (CSRF):**  Enable CSRF protection to prevent unauthorized requests.\n    *   **Remote Code Execution (RCE):**  Avoid executing untrusted code within the pipeline.\n    *   **Credential Theft:**  Protect sensitive credentials using Jenkins' credential management system.\n    *   **Unauthorized Access:**  Implement role-based access control to restrict access to sensitive resources.\n*   **Input Validation:**\n    *   Validate all user inputs to prevent malicious code injection and data corruption.\n    *   Use parameterized builds with predefined choices to limit user input.\n    *   Encode or escape special characters to prevent interpretation as code.\n*   **Authentication and Authorization:**\n    *   Enable security and configure authentication using Jenkins' built-in user database or an external identity provider (e.g., LDAP, Active Directory).\n    *   Implement role-based access control (RBAC) to restrict access to sensitive resources and operations.\n    *   Use the principle of least privilege to grant only the necessary permissions to users and groups.\n    *   Regularly audit user permissions and remove unnecessary accounts.\n*   **Data Protection:**\n    *   Use Jenkins' credential management system to securely store passwords, API keys, and other sensitive information.\n    *   Encrypt sensitive data at rest and in transit.\n    *   Mask sensitive information in build logs to prevent exposure.\n    *   Rotate credentials regularly to minimize the impact of potential breaches.\n*   **Secure API Communication:**\n    *   Use HTTPS to encrypt communication between Jenkins and other systems.\n    *   Authenticate all API requests using secure tokens or credentials.\n    *   Limit API access to authorized users or systems.\n    *   Rate-limit API requests to prevent denial-of-service attacks.\n\n## 5. Testing Approaches\n\n*   **Unit Testing:**\n    *   Test individual functions or modules in isolation.\n    *   Use mocking and stubbing to isolate dependencies.\n    *   Write unit tests for shared libraries to ensure they function correctly.\n*   **Integration Testing:**\n    *   Test the interaction between different components or services.\n    *   Verify that shared libraries integrate correctly with the pipeline.\n    *   Use containerization to create isolated test environments.\n*   **End-to-End Testing:**\n    *   Test the entire pipeline workflow from start to finish.\n    *   Simulate real-world scenarios and user interactions.\n    *   Use automated testing tools to execute end-to-end tests.\n*   **Test Organization:**\n    *   Organize tests into logical suites based on functionality or component.\n    *   Use descriptive names for test cases to indicate their purpose.\n    *   Run tests automatically as part of the pipeline.\n    *   Generate test reports and track test results over time.\n*   **Mocking and Stubbing:**\n    *   Use mocking frameworks to create mock objects that simulate the behavior of dependencies.\n    *   Stub external services or APIs to isolate the system under test.\n    *   Use environment variables to configure mocking behavior.\n\n## 6. Common Pitfalls and Gotchas\n\n*   **Frequent Mistakes:**\n    *   Failing to secure Jenkins instance.\n    *   Overusing Groovy scripting leading to performance degradation.\n    *   Not using shared libraries for reusable code.\n    *   Hardcoding credentials and other secrets.\n    *   Lack of proper error handling.\n    *   Ignoring pipeline performance monitoring.\n*   **Edge Cases:**\n    *   Handling concurrent builds and resource contention.\n    *   Dealing with flaky tests and intermittent failures.\n    *   Managing large files and artifacts within the pipeline.\n    *   Supporting different operating systems and environments.\n*   **Version-Specific Issues:**\n    *   Compatibility issues between Jenkins versions and plugins.\n    *   Deprecated APIs and features.\n    *   Security vulnerabilities in older versions.\n*   **Compatibility Concerns:**\n    *   Ensure compatibility between Jenkins and the tools and technologies used in the pipeline (e.g., Docker, Kubernetes, AWS).\n    *   Test pipelines on different platforms to ensure cross-platform compatibility.\n*   **Debugging Strategies:**\n    *   Use build logs and console output to diagnose pipeline failures.\n    *   Add debug statements to Groovy code to trace execution flow.\n    *   Use remote debugging tools to step through pipeline execution.\n    *   Reproduce pipeline failures locally to isolate the cause.\n    *   Utilize the `script` step with caution for complex logic, ensuring proper error handling.\n    *   Review plugin documentation for common issues and troubleshooting tips.\n\n## 7. Tooling and Environment\n\n*   **Recommended Development Tools:**\n    *   IDE with Groovy support (e.g., IntelliJ IDEA, Eclipse).\n    *   Version control system (e.g., Git).\n    *   Build automation tools (e.g., Maven, Gradle).\n    *   Testing frameworks (e.g., JUnit, TestNG).\n    *   Containerization tools (e.g., Docker).\n*   **Build Configuration:**\n    *   Use parameterized builds to allow users to customize build behavior.\n    *   Define build triggers to automatically start builds on code changes or schedule.\n    *   Configure post-build actions to archive artifacts, send notifications, or deploy the application.\n    *   Use the `buildDiscarder` directive to clean up old builds and save disk space.\n*   **Linting and Formatting:**\n    *   Use a Groovy linter to enforce coding standards and identify potential errors.\n    *   Format Groovy code consistently to improve readability.\n    *   Use tools like `groovy-lint` or IDE plugins for linting and formatting.\n*   **Deployment:**\n    *   Use deployment plugins to automate the deployment process.\n    *   Implement blue-green deployments or rolling deployments to minimize downtime.\n    *   Use feature flags to decouple deployment from release.\n    *   Use a cloud-native deployment strategy (e.g., Kubernetes) for scalable and resilient deployments.\n*   **CI/CD Integration:**\n    *   Integrate Jenkins with other CI/CD tools (e.g., SonarQube, Artifactory).\n    *   Use webhooks to trigger builds from version control systems.\n    *   Monitor pipeline performance and identify areas for improvement.\n    *   Implement continuous feedback loops to improve the quality of the application and the pipeline.\n    *   Leverage Infrastructure as Code (IaC) tools such as Terraform to create ephemeral testing and build environments\n\nBy following these best practices, developers can create robust, maintainable, and secure Jenkins pipelines and configurations that streamline the software development process and improve the quality of the application.",
    "metadata": {
      "globs": "Jenkinsfile,*.jenkins,*.groovy",
      "format": "mdc",
      "originalFile": "jenkins.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "jenkins",
      "comprehensive",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "security",
      "performance",
      "testing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "jenkins",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-jest",
    "description": "This rule provides guidelines for writing clean, maintainable, and effective tests using Jest. It covers code organization, performance, common pitfalls, and best practices for testing JavaScript and TypeScript projects.",
    "author": "sanjeed5",
    "tags": [
      "jest",
      "typescript",
      "javascript",
      "types",
      "testing",
      "cursor",
      "cursor-rule",
      "mdc",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "quality-testing",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/jest.mdc",
    "content": "- **Organize tests by feature or module:**\n  - Group tests into files or directories that correspond to the features or modules they are testing. This makes it easier to locate and maintain tests.\n  - Create a `__tests__` directory alongside your source code files. This is a common convention that Jest recognizes.\n\n- **Use descriptive test names:**\n  - Write test names that clearly describe what the test is verifying. This makes it easier to understand the purpose of each test and to diagnose failures.\n  - Use the `describe` and `it` blocks to structure your tests and provide context.\n  - Example: `describe('User authentication', () => { it('should log in a user with valid credentials', () => { /* ... */ }); });`\n\n- **Keep tests isolated and independent:**\n  - Each test should be independent of other tests. Avoid sharing state or dependencies between tests.\n  - Use `beforeEach` and `afterEach` hooks to set up and tear down the environment for each test.\n\n- **Avoid testing implementation details:**\n  - Focus on testing the public API of your code, rather than the internal implementation details.\n  - This makes your tests more resilient to changes in the implementation.\n  - Test the \"what\", not the \"how\".\n\n- **Use setup and teardown methods:**\n  - Use `beforeAll`, `afterAll`, `beforeEach`, and `afterEach` hooks to set up and tear down the environment for your tests.\n  - `beforeAll` and `afterAll` run once before and after all tests in a `describe` block.\n  - `beforeEach` and `afterEach` run before and after each test in a `describe` block.\n\n- **Mock external dependencies:**\n  - Use mocking to isolate your code from external dependencies, such as network requests or database connections.\n  - Jest provides built-in mocking capabilities with `jest.mock` and `jest.spyOn`.\n  - Consider using a library like `axios-mock-adapter` for mocking HTTP requests.\n\n- **Write tests that are easy to read and maintain:**\n  - Keep your tests concise and focused.\n  - Use clear and consistent formatting.\n  - Add comments to explain complex logic.\n  - Refactor your tests regularly to keep them up to date.\n\n- **Aim for high test coverage, but prioritize meaningful tests over quantity:**\n  - Aim for high test coverage to ensure that your code is well-tested.\n  - However, prioritize writing meaningful tests that verify the core functionality of your code.\n  - Don't just aim for 100% coverage without considering the value of each test.\n\n- **Use Jest's built-in matchers effectively:**\n  - Jest provides a rich set of matchers for asserting different conditions.\n  - Use matchers like `toBe`, `toEqual`, `toBeGreaterThan`, `toContain`, `toHaveBeenCalled`, etc.\n  - Explore the Jest documentation for the full list of matchers.\n\n- **Handle asynchronous code correctly:**\n  - Use `async/await` or Promises to handle asynchronous code in your tests.\n  - Use the `resolves` and `rejects` matchers to assert that a Promise resolves or rejects.\n  - Example: `expect(myAsyncFunction()).resolves.toBe(expectedValue);`\n\n- **Test error handling:**\n  - Write tests to verify that your code handles errors correctly.\n  - Use the `toThrow` matcher to assert that a function throws an error.\n  - Example: `expect(() => myDangerousFunction()).toThrow(Error);`\n\n- **Use snapshots sparingly:**\n  - Snapshots can be useful for verifying the output of a component or function.\n  - However, they can also be brittle and difficult to maintain if used excessively.\n  - Use snapshots strategically and review them carefully when they change.\n\n- **Configure Jest correctly:**\n  - Configure Jest using the `jest.config.js` or `jest.config.ts` file.\n  - Configure settings such as test environment, module file extensions, and coverage thresholds.\n  - Consider using presets like `ts-jest` or `babel-jest` for TypeScript or Babel support.\n\n- **Leverage code coverage reports:**\n  - Use Jest's code coverage reports to identify areas of your code that are not well-tested.\n  - Aim to increase coverage in critical areas of your codebase.\n  - Use the `--coverage` flag to generate coverage reports.\n\n- **Keep test data separate from test logic:**\n  - Externalize test data to improve readability and maintainability.\n  - Use fixtures or factories to generate test data.\n  - Avoid hardcoding data directly in your tests.\n\n- **Consider using test-driven development (TDD):**\n  - Write tests before you write code to drive the development process.\n  - This can help you write more testable and well-designed code.\n\n- **Run tests frequently:**\n  - Run your tests frequently to catch errors early.\n  - Use Jest's watch mode to automatically run tests when files change.\n  - Integrate tests into your CI/CD pipeline.\n\n- **Document your tests:**\n  - Add comments to explain the purpose of each test and the expected behavior.\n  - This will make it easier for others to understand and maintain your tests.\n\n- **Code Organization and Structure:**\n  - **Directory structure best practices:** Organize test files alongside the component/module they test (e.g., `src/components/MyComponent/MyComponent.test.js`)\n  - **File naming conventions:** Use `.test.js` or `.spec.js` suffixes for test files (e.g., `MyComponent.test.js`, `MyModule.spec.ts`).\n  - **Module organization:** Keep test files close to the modules they are testing. Use a consistent naming convention for test files.\n  - **Component architecture:** Test components in isolation, mocking dependencies where necessary.\n  - **Code splitting strategies:** Ensure tests cover all code paths in dynamically imported modules.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design patterns specific to Jest:** Use Page Object Model (POM) for UI tests, Factory pattern for test data generation.\n  - **Recommended approaches for common tasks:** Use `jest.mock` for mocking modules, `jest.spyOn` for spying on methods, and `fakeTimers` for controlling time-dependent behavior.\n  - **Anti-patterns and code smells to avoid:** Avoid testing implementation details, relying on global state, and creating brittle snapshots.\n  - **State management best practices:** Mock external state dependencies and verify state changes using `expect` assertions.\n  - **Error handling patterns:** Test for specific error messages and ensure error boundaries are properly tested.\n\n- **Performance Considerations:**\n  - **Optimization techniques:** Use `jest.clearAllMocks` and `jest.resetAllMocks` in `beforeEach` blocks to prevent state leakage and improve test performance.\n  - **Memory management:** Avoid creating large data structures in tests that are not necessary. Manually trigger garbage collection in tests where large objects are created and released.\n  - **Rendering optimization:** Mock expensive rendering logic to speed up tests that involve React components.\n  - **Bundle size optimization:** Not applicable, as Jest primarily tests individual modules or components.\n  - **Lazy loading strategies:** Ensure tests cover all code paths in dynamically imported modules.\n\n- **Security Best Practices:**\n  - **Common vulnerabilities and how to prevent them:** Avoid using sensitive data in test snapshots. Sanitize test data to prevent potential injection attacks.\n  - **Input validation:** Test input validation logic and ensure that invalid inputs are handled correctly.\n  - **Authentication and authorization patterns:** Mock authentication and authorization logic to test different user roles and permissions.\n  - **Data protection strategies:** Not directly applicable, as Jest primarily focuses on functional testing.\n  - **Secure API communication:** Mock API calls and verify that data is transmitted securely.\n\n- **Testing Approaches:**\n  - **Unit testing strategies:** Test individual functions, classes, or components in isolation.\n  - **Integration testing:** Test interactions between different modules or components.\n  - **End-to-end testing:** Use tools like Cypress or Playwright for end-to-end tests.\n  - **Test organization:** Group tests into logical suites based on functionality or module.\n  - **Mocking and stubbing:** Use `jest.mock` and `jest.spyOn` to create mocks and stubs for dependencies.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent mistakes developers make:** Forgetting to mock dependencies, testing implementation details, and creating brittle snapshots.\n  - **Edge cases to be aware of:** Testing asynchronous code correctly, handling errors, and testing different input types.\n  - **Version-specific issues:** Be aware of breaking changes in Jest updates and update your tests accordingly.\n  - **Compatibility concerns:** Ensure tests are compatible with different browsers or environments.\n  - **Debugging strategies:** Use `console.log` statements, debuggers, or Jest's interactive mode to debug tests.\n\n- **Tooling and Environment:**\n  - **Recommended development tools:** VS Code, WebStorm, Jest Runner extension.\n  - **Build configuration:** Configure Jest using `jest.config.js` or `package.json`.\n  - **Linting and formatting:** Use ESLint and Prettier to enforce code style and prevent errors.\n  - **Deployment best practices:** Integrate tests into your CI/CD pipeline to ensure code quality.\n  - **CI/CD integration:** Use tools like GitHub Actions, Jenkins, or CircleCI to automate testing and deployment.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.mjs,*.cjs,*.mts,*.cts",
      "format": "mdc",
      "originalFile": "jest.mdc"
    },
    "subcategory": "testing",
    "keywords": [
      "cursor",
      "jest",
      "this",
      "rule",
      "provides",
      "guidelines",
      "writing",
      "clean",
      "maintainable",
      "effective",
      "tests",
      "using",
      "typescript",
      "javascript",
      "types",
      "testing",
      "cursor-rule",
      "mdc",
      "type-safety",
      "quality-testing"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "jest",
        "typescript",
        "javascript",
        "types",
        "testing",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "quality-testing"
    }
  },
  {
    "name": "cursor-jetpack-compose",
    "description": "Enforces Jetpack Compose best practices for code organization, performance, and maintainability. This rule provides guidelines for writing efficient and idiomatic Compose code.",
    "author": "sanjeed5",
    "tags": [
      "jetpack-compose",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/jetpack-compose.mdc",
    "content": "- **Code Organization and Structure**\n  - **Directory Structure:**\n    - Organize composables by feature or screen. Each feature should have its own directory.\n    - Example:\n      \n      app/\n        src/\n          main/\n            java/\n              com/example/app/\n                feature_a/\n                  FeatureAScreen.kt\n                  FeatureAViewModel.kt\n                  components/\n                    FeatureAButton.kt\n                    FeatureATextField.kt\n                feature_b/\n                  ...\n      \n  - **File Naming Conventions:**\n    - Use PascalCase for composable function names (e.g., `MyComposable`).\n    - Use descriptive names that clearly indicate the composable's purpose.\n    - Name files after the primary composable they contain (e.g., `MyComposable.kt`).\n  - **Module Organization:**\n    - Separate UI code (composables) from business logic (ViewModels, repositories).  Use modules to enforce this separation.\n    - Consider using feature modules for large applications to improve build times and maintainability.\n  - **Component Architecture:**\n    - Design composables as small, reusable components.\n    - Follow the single responsibility principle: each composable should have a single, well-defined purpose.\n    - Use a hierarchical component structure to build complex UIs from smaller, simpler components.\n  - **Code Splitting Strategies:**\n    - Break down large composables into smaller, more manageable parts.\n    - Use inline functions judiciously.  Overuse can hurt performance.\n    - Consider using `derivedStateOf` to only recompose when necessary based on derived state.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - **State Hoisting:** Move state as high as possible in the composable tree to maximize reusability and testability.  Pass state down as parameters.\n    - **Unidirectional Data Flow:**  Data flows down the composable tree, and events flow up. This makes it easier to reason about the state of the UI.\n    - **Composition Local:** Use sparingly to provide implicit dependencies to composables.  Avoid overusing as it can make dependencies less explicit.\n    - **ViewModel:** Use a ViewModel to hold UI state and handle business logic. This separates the UI from the data layer and makes the UI easier to test.\n  - **Recommended Approaches:**\n    - Use `remember` to cache expensive calculations and avoid unnecessary recompositions.\n    - Use `mutableStateOf` or `rememberSaveable` to store UI state.\n    - Use `LaunchedEffect` or `rememberCoroutineScope` for side effects (e.g., network requests, database access).\n    - Use `animate*AsState` functions for smooth animations.\n  - **Anti-patterns and Code Smells:**\n    - **Reading State from Too High a Scope:** Avoid reading state too high in the composition tree, as this can cause unnecessary recompositions.\n    - **Mutable State in Composables without remember:** If you're not using remember, every recomposition will create a new state, leading to unexpected behavior.\n    - **Long Composable Functions:** Break large composables into smaller, more manageable parts.\n    - **Hardcoded Values:** Avoid hardcoding values directly in composables. Use resources or constants instead.\n    - **Unnecessary Recomposition:**  Profile your code to identify and eliminate unnecessary recompositions.  Tools like the Layout Inspector can help.\n  - **State Management Best Practices:**\n    - Choose the right state management solution for your needs (e.g., `remember`, `mutableStateOf`, `StateFlow`, `LiveData`).\n    - Keep state as immutable as possible.  Use `copy()` to create new state objects instead of modifying existing ones.\n    - Use `derivedStateOf` to derive state from other state objects.\n  - **Error Handling Patterns:**\n    - Use `try-catch` blocks to handle exceptions in composables.\n    - Display error messages to the user in a clear and informative way.\n    - Use a central error handling mechanism to log errors and prevent crashes.  Consider using a `Snackbar` or a dedicated error display composable.\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - **`remember`:** Cache expensive calculations and resources.\n    - **`derivedStateOf`:** Only recompose when derived state changes.\n    - **`SnapshotFlow`:** Collect data from mutable state without recomposing.\n    - **`CompositionLocalProvider`:** Provides an alternative way to pass data if recomposition is a bottleneck.  Use with caution as it can make dependencies implicit.\n    - **`Skippable Composable Functions`:** Compose Compiler performs the best optimization for functions that are skippable. To allow skipping, a composable must meet the following criteria:\n      - All parameters passed to the composable are stable.\n      - The composable's result is the same given the same parameters.\n    - **Inline Functions (with care):** Useful for small functions but can increase bytecode size if overused.\n  - **Memory Management:**\n    - Avoid creating large objects in composables.\n    - Release resources when they are no longer needed.\n    - Use `WeakReference` to avoid memory leaks.\n  - **Rendering Optimization:**\n    - Use `Modifier.drawBehind` and `Modifier.drawWithContent` for custom drawing.\n    - Avoid overdraw by using `Modifier.clip` and `Modifier.background`.\n    - Use `Spacer` to control layout instead of adding padding to multiple elements.\n  - **Bundle Size Optimization:**\n    - Use R8 to shrink and obfuscate your code.\n    - Remove unused resources.\n    - Use dynamic feature modules to deliver features on demand.\n  - **Lazy Loading Strategies:**\n    - Use `LazyColumn` and `LazyRow` to display large lists of data.\n    - Use `rememberLazyListState` to persist the scroll position of lazy lists.\n\n- **Security Best Practices**\n  - **Common Vulnerabilities:**\n    - **Input Validation:**  Sanitize user input to prevent injection attacks.\n    - **Data Protection:**  Encrypt sensitive data at rest and in transit.\n    - **Secure API Communication:**  Use HTTPS to encrypt communication between the app and the server.\n  - **Input Validation:**\n    - Validate user input to prevent injection attacks and other security vulnerabilities.\n    - Use regular expressions or other validation techniques to ensure that input is in the expected format.\n  - **Authentication and Authorization Patterns:**\n    - Use a secure authentication and authorization mechanism to protect sensitive data and functionality.\n    - Use OAuth 2.0 or OpenID Connect for authentication.\n    - Use role-based access control (RBAC) for authorization.\n  - **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use a strong encryption algorithm.\n    - Store encryption keys securely.\n  - **Secure API Communication:**\n    - Use HTTPS to encrypt communication between the app and the server.\n    - Use certificate pinning to prevent man-in-the-middle attacks.\n\n- **Testing Approaches**\n  - **Unit Testing Strategies:**\n    - Test composables in isolation using `ComposeTestRule`.\n    - Verify that composables render correctly and handle user input as expected.\n    - Use `composeTestRule.setContent { ... }` to set the content of the test.\n    - Use `composeTestRule.onNodeWithText(\"...\").performClick()` to simulate user interactions.\n  - **Integration Testing:**\n    - Test the interaction between different composables and ViewModels.\n    - Use `Hilt` or `Koin` to inject dependencies into tests.\n  - **End-to-end Testing:**\n    - Test the entire application flow from the user's perspective.\n    - Use `UIAutomator` or `Espresso` for end-to-end testing.\n  - **Test Organization:**\n    - Organize tests by feature or screen.\n    - Create a separate test module for each feature module.\n  - **Mocking and Stubbing:**\n    - Use `Mockito` or `Mockk` to mock dependencies in unit tests.\n    - Use `Fake` implementations for integration tests.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - Forgetting to use `remember` for state.\n    - Reading state from too high a scope.\n    - Not handling errors properly.\n    - Not optimizing performance.\n  - **Edge Cases:**\n    - Handling different screen sizes and orientations.\n    - Handling different locales and languages.\n    - Handling different accessibility requirements.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes in new versions of Jetpack Compose.\n    - Use the latest version of Jetpack Compose to take advantage of new features and bug fixes.\n  - **Compatibility Concerns:**\n    - Ensure that your app is compatible with different Android versions.\n    - Use Jetpack Compose libraries that are compatible with your target Android version.\n  - **Debugging Strategies:**\n    - Use the Android Studio debugger to step through your code and inspect variables.\n    - Use the Layout Inspector to inspect the composable tree and identify performance bottlenecks.\n    - Use the Profiler to measure the performance of your app.\n\n- **Tooling and Environment**\n  - **Recommended Development Tools:**\n    - Android Studio\n    - Kotlin Compiler\n    - Jetpack Compose Libraries\n  - **Build Configuration:**\n    - Use Gradle to manage dependencies and build your app.\n    - Configure the Kotlin compiler to use the latest version of Jetpack Compose.\n  - **Linting and Formatting:**\n    - Use `ktlint` or `detekt` to enforce code style guidelines.\n    - Use `Prettier` to format your code automatically.\n  - **Deployment Best Practices:**\n    - Use the Google Play Store to distribute your app.\n    - Use a staged rollout to gradually release your app to users.\n  - **CI/CD Integration:**\n    - Use a CI/CD system to automate the build, test, and deployment process.\n    - Use `GitHub Actions` or `CircleCI` for CI/CD.",
    "metadata": {
      "globs": "*.kt",
      "format": "mdc",
      "originalFile": "jetpack-compose.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "jetpack",
      "compose",
      "enforces",
      "best",
      "practices",
      "code",
      "organization",
      "performance",
      "maintainability",
      "this",
      "jetpack-compose",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "jetpack-compose",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-jquery",
    "description": "This rule file provides guidelines for jQuery development, covering code organization, performance, security, and testing. It helps developers write maintainable, efficient, and secure jQuery code.",
    "author": "sanjeed5",
    "tags": [
      "jquery",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/jquery.mdc",
    "content": "# jQuery Best Practices: A Comprehensive Guide\n\nThis document outlines best practices for jQuery development to ensure code quality, performance, security, and maintainability.\n\n## Library Information:\n\n- Name: jQuery\n- Tags: javascript, dom, library, frontend\n\n## 1. Code Organization and Structure\n\nA well-structured project improves maintainability, collaboration, and scalability.\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a clear and consistent directory structure:\n\n\nproject-root/\n├── css/\n│   ├── style.css\n│   └── components/\n│       └── component.css\n├── js/\n│   ├── jquery.min.js  # jQuery library (ideally from a CDN)\n│   ├── app.js         # Main application file\n│   ├── modules/\n│   │   ├── module1.js\n│   │   └── module2.js\n│   ├── components/\n│   │   ├── component1.js\n│   │   └── component2.js\n│   └── utils/\n│       ├── helperFunctions.js\n│       └── ajaxUtils.js\n├── img/\n│   └── ...\n├── index.html\n├── .eslintrc.js      # ESLint configuration (see linting section)\n└── package.json      # Project dependencies and scripts\n\n\n**Explanation:**\n\n-   `css/`: Contains all CSS files, potentially organized into components.\n-   `js/`:  Contains all JavaScript files, including the main application script, modules, components, and utility functions.\n-   `img/`: Contains images.\n-   `index.html`: The main HTML file.\n-   `.eslintrc.js`: Configuration file for ESLint (JavaScript linter).\n-   `package.json`:  Defines project dependencies and scripts.\n\n### 1.2. File Naming Conventions\n\nUse descriptive and consistent file names:\n\n-   JavaScript files: `[componentName].js`, `[moduleName].js`, `[utilityName].js` (e.g., `navigation.js`, `userAuthentication.js`, `dateFormatter.js`).\n-   CSS files: `[componentName].css`, `style.css`.\n-   jQuery plugins: `jquery.[pluginName].js`.\n\n### 1.3. Module Organization Best Practices\n\nOrganize code into logical modules:\n\n-   **Encapsulation:** Each module should encapsulate a specific functionality or feature.\n-   **Loose Coupling:** Modules should be loosely coupled to minimize dependencies and promote reusability.\n-   **Revealing Module Pattern:** Use the revealing module pattern to expose only the necessary functions and variables.\n\njavascript\n// js/modules/userAuthentication.js\nconst userAuthentication = (function() {\n  let isAuthenticated = false;\n\n  function login(username, password) {\n    // Authentication logic (e.g., AJAX call)\n    // ...\n    isAuthenticated = true;\n  }\n\n  function logout() {\n    // Logout logic\n    //...\n    isAuthenticated = false;\n  }\n\n  function isLoggedIn() {\n    return isAuthenticated;\n  }\n\n  return {\n    login: login,\n    logout: logout,\n    isLoggedIn: isLoggedIn\n  };\n})();\n\n// In app.js\n$(document).ready(function() {\n  if (userAuthentication.isLoggedIn()) {\n    // Update UI for logged-in user\n  }\n});\n\n\n### 1.4. Component Architecture Recommendations\n\nBreak down the UI into reusable components:\n\n-   **Modularity:** Components should be self-contained and independent.\n-   **Reusability:** Components should be designed for reuse across the application.\n-   **Maintainability:** Component-based architecture simplifies code updates and maintenance.\n\njavascript\n// js/components/navigation.js\nfunction Navigation(elementId, options) {\n  this.element = $('#' + elementId);\n  this.options = $.extend({}, { /* Default options */ }, options);\n\n  this.init = function() {\n    // Component initialization\n    this.element.on('click', '.nav-item', this.handleNavigation.bind(this));\n  };\n\n  this.handleNavigation = function(event) {\n    event.preventDefault();\n    // Navigation logic\n    console.log('Navigating to:', $(event.target).attr('href'));\n  };\n\n  this.init();\n}\n\n// In app.js\n$(document).ready(function() {\n  const nav = new Navigation('main-nav', {\n    // Custom options\n  });\n});\n\n\n### 1.5. Code Splitting Strategies\n\nImprove initial load time by splitting code into smaller chunks:\n\n-   **On-Demand Loading:** Load modules or components only when they are needed.\n-   **Route-Based Splitting:** Load code specific to a particular route or page.\n-   **Conditional Loading:** Load code based on user interactions or device capabilities.\n\njavascript\n// Example: Loading a module on button click\n$('#load-module-button').on('click', function() {\n  $.getScript('js/modules/heavyModule.js', function() {\n    // Module loaded and executed\n    heavyModule.init();\n  });\n});\n\n\n## 2. Common Patterns and Anti-patterns\n\nEmploy established design patterns to improve code quality and avoid common mistakes.\n\n### 2.1. Design Patterns Specific to jQuery\n\n-   **Module Pattern:** (See section 1.3).  Encapsulates code and prevents global scope pollution.\n-   **Observer Pattern:**  Facilitates communication between components without tight coupling. jQuery's event system is essentially an implementation of the observer pattern.\n-   **Facade Pattern:** Provides a simplified interface to a complex system (e.g., jQuery's `$`).\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **DOM Manipulation:** Minimize direct DOM manipulation. Use document fragments for batch updates.\n-   **Event Handling:** Implement event delegation for dynamically added elements.\n-   **AJAX:** Use `$.ajax()` for flexible AJAX requests. Use promises for asynchronous operations.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Global Variables:** Avoid using global variables to prevent naming conflicts and unexpected behavior.\n-   **Chaining Overuse:**  Long chains can be difficult to read. Break them into smaller, more manageable chunks.\n-   **Excessive DOM Traversal:** Minimize DOM traversal by caching selectors.\n-   **Ignoring Performance:**  Avoid complex selectors and inefficient DOM manipulation.\n-   **Inconsistent Coding Style:** Adhere to a consistent coding style to improve readability.\n-   **Mixing Concerns:** Separate HTML structure, CSS styling, and JavaScript behavior.\n-   **Deprecated Methods**: Avoid using deprecated methods.\n\n### 2.4. State Management Best Practices\n\n-   **Keep it Simple:** For small applications, simple variables or data attributes may be sufficient.\n-   **Centralized Store:** For larger applications, consider a centralized state management solution (though jQuery is rarely used on its own for complex single page apps that require advanced state management).\n-   **Data Attributes:** Use data attributes (`data-*`) to store component-specific data.\n\n### 2.5. Error Handling Patterns\n\n-   **Try-Catch Blocks:** Use `try-catch` blocks to handle exceptions gracefully.\n-   **AJAX Error Handling:** Implement error handling for AJAX requests using the `error` callback or `$.Deferred`'s `fail` method.\n-   **Global Error Handler:** Set up a global error handler to catch unhandled exceptions.\n\njavascript\n$.ajax({\n  url: 'api/data',\n  dataType: 'json',\n  success: function(data) {\n    // Process data\n  },\n  error: function(jqXHR, textStatus, errorThrown) {\n    console.error('AJAX error:', textStatus, errorThrown);\n    // Display error message to the user\n  }\n});\n\n\n## 3. Performance Considerations\n\nOptimize code for speed and efficiency.\n\n### 3.1. Optimization Techniques\n\n-   **Selector Optimization:** Use ID selectors whenever possible. Be specific on the right-hand side of your selector and less specific on the left. Give your Selectors a Context.\n-   **Caching Selectors:** Cache jQuery selector returned objects in variables for reuse.\n-   **Minimize DOM Manipulations:** Batch updates, use document fragments, and detach elements before manipulation.\n-   **Event Delegation:** Use event delegation to reduce the number of event listeners.\n-   **Debouncing and Throttling:** Limit the rate at which a function is executed.\n\n### 3.2. Memory Management Considerations\n\n-   **Avoid Memory Leaks:** Remove event listeners and data when elements are removed from the DOM.\n-   **Release References:** Set variables to `null` to release memory when they are no longer needed.\n-   **Garbage Collection:** Understand how JavaScript garbage collection works and avoid creating unnecessary objects.\n\n### 3.3. Rendering Optimization\n\n-   **Minimize Reflows and Repaints:** Reduce the number of DOM manipulations that cause reflows and repaints.\n-   **Use CSS Transitions and Animations:** Use CSS transitions and animations instead of jQuery animations for better performance.\n-   **Hardware Acceleration:** Leverage hardware acceleration for smooth animations.\n\n### 3.4. Bundle Size Optimization\n\n-   **Minification:** Use minification to reduce file sizes.\n-   **Gzip Compression:** Enable Gzip compression on the server to reduce the size of transferred files.\n-   **Code Splitting:** Split code into smaller chunks to improve initial load time (see section 1.5).\n\n### 3.5. Lazy Loading Strategies\n\n-   **Lazy Load Images:** Load images only when they are visible in the viewport.\n-   **Lazy Load Modules:** Load modules or components only when they are needed (see section 1.5).\n-   **Use a Lazy Loading Library:**  Consider using a library like `lozad.js` for easy lazy loading.\n\n## 4. Security Best Practices\n\nProtect your application against common vulnerabilities.\n\n### 4.1. Common Vulnerabilities and Prevention\n\n-   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks. Use jQuery's `text()` method to set text content instead of `html()` to prevent injecting HTML code.\n-   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection tokens.\n-   **SQL Injection:**  Never directly use client-side data in database queries.  Use parameterized queries or ORMs.\n-   **Open Redirects:** Validate and sanitize redirect URLs to prevent open redirects.\n-   **Dependency Vulnerabilities:** Keep jQuery and all dependencies up to date to patch security vulnerabilities.\n\n### 4.2. Input Validation Best Practices\n\n-   **Client-Side Validation:** Implement client-side validation to provide immediate feedback to the user.\n-   **Server-Side Validation:** Always perform server-side validation to ensure data integrity.\n-   **Sanitize Input:** Sanitize user input to remove potentially harmful characters.\n\n### 4.3. Authentication and Authorization Patterns\n\n-   **Use HTTPS:** Always use HTTPS to encrypt data in transit.\n-   **Secure Cookies:**  Set the `secure` and `httpOnly` flags for cookies.\n-   **Authentication Tokens:** Use authentication tokens (e.g., JWT) for secure authentication.\n-   **Role-Based Access Control (RBAC):** Implement RBAC to restrict access to sensitive resources.\n\n### 4.4. Data Protection Strategies\n\n-   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n-   **Data Masking:** Mask sensitive data in the UI to prevent unauthorized access.\n-   **Regular Backups:** Perform regular backups of your data.\n\n### 4.5. Secure API Communication\n\n-   **Use HTTPS:** Always use HTTPS for API communication.\n-   **API Keys:** Use API keys to authenticate requests.\n-   **Rate Limiting:** Implement rate limiting to prevent abuse.\n-   **Input Validation:** Validate all input data on the server-side.\n\n## 5. Testing Approaches\n\nWrite tests to ensure code quality and prevent regressions.\n\n### 5.1. Unit Testing Strategies\n\n-   **Test Individual Components:**  Write unit tests for individual components and modules.\n-   **Use a Testing Framework:** Use a JavaScript testing framework like QUnit or Jasmine.\n-   **Mock Dependencies:**  Mock dependencies to isolate the component being tested.\n\n### 5.2. Integration Testing Approaches\n\n-   **Test Interactions:** Write integration tests to test the interactions between components.\n-   **Use a Testing Framework:**  Use a testing framework like Mocha or Jest.\n-   **Test API Integrations:** Test the integration with external APIs.\n\n### 5.3. End-to-End Testing Recommendations\n\n-   **Simulate User Interactions:**  Write end-to-end tests to simulate user interactions.\n-   **Use a Testing Framework:**  Use a testing framework like Cypress or Puppeteer.\n-   **Test Critical Paths:**  Test the critical paths through the application.\n\n### 5.4. Test Organization\n\n-   **Separate Test Files:**  Create separate test files for each component or module.\n-   **Use Descriptive Names:**  Use descriptive names for test cases.\n-   **Organize Tests:** Organize tests into logical groups.\n\n### 5.5. Mocking and Stubbing Techniques\n\n-   **Mock AJAX Requests:** Mock AJAX requests to isolate the component being tested.\n-   **Stub Functions:** Stub functions to control their behavior.\n-   **Use a Mocking Library:** Use a mocking library like Sinon.js.\n\njavascript\n// Example using QUnit and Sinon.js\nQUnit.module('User Authentication Module', function(hooks) {\n  hooks.beforeEach(function() {\n    this.ajax = sinon.stub($, 'ajax');\n  });\n\n  hooks.afterEach(function() {\n    this.ajax.restore();\n  });\n\n  QUnit.test('login() should make an AJAX request', function(assert) {\n    this.ajax.resolves({ success: true });\n    userAuthentication.login('testuser', 'password');\n    assert.ok(this.ajax.calledOnce, 'AJAX request was made');\n  });\n});\n\n\n## 6. Common Pitfalls and Gotchas\n\nBe aware of common mistakes and edge cases.\n\n### 6.1. Frequent Mistakes\n\n-   **Not Caching Selectors:**  Re-querying the DOM for the same element repeatedly.\n-   **Using Incorrect Scope (`this`):**  Understanding the scope of `this` in event handlers and callbacks.\n-   **Ignoring Errors:**  Not handling errors properly in AJAX requests and other asynchronous operations.\n-   **Overusing jQuery:**  Using jQuery for tasks that can be done more efficiently with native JavaScript.\n\n### 6.2. Edge Cases\n\n-   **Browser Compatibility:**  Testing your code in different browsers and versions.\n-   **Mobile Devices:**  Optimizing your code for mobile devices.\n-   **Accessibility:** Ensuring your code is accessible to users with disabilities.\n\n### 6.3. Version-Specific Issues\n\n-   **Deprecated Methods:**  Being aware of deprecated methods in newer versions of jQuery.\n-   **API Changes:**  Understanding API changes between different versions of jQuery.\n\n### 6.4. Compatibility Concerns\n\n-   **Conflicting Libraries:**  Avoiding conflicts with other JavaScript libraries (e.g., Prototype, MooTools) using `$.noConflict()`.\n-   **Plugin Compatibility:** Ensuring that jQuery plugins are compatible with the version of jQuery being used.\n\n### 6.5. Debugging Strategies\n\n-   **Use Browser Developer Tools:**  Use browser developer tools to inspect elements, debug JavaScript code, and profile performance.\n-   **Console Logging:**  Use `console.log()` to debug your code.\n-   **Breakpoints:**  Set breakpoints in your code to pause execution and inspect variables.\n\n## 7. Tooling and Environment\n\nUse the right tools to improve productivity and code quality.\n\n### 7.1. Recommended Development Tools\n\n-   **Text Editor/IDE:** Visual Studio Code, Sublime Text, Atom.\n-   **Browser:** Chrome, Firefox, Safari.\n-   **Debugging Tools:** Chrome DevTools, Firefox Developer Tools.\n-   **Build Tools:**  Webpack, Parcel, Gulp.\n-   **Testing Frameworks:** QUnit, Jasmine, Mocha, Jest.\n\n### 7.2. Build Configuration\n\n-   **Use a Build Tool:** Use a build tool like Webpack or Parcel to bundle and optimize your code.\n-   **Configure Loaders:** Configure loaders to handle different file types (e.g., JavaScript, CSS, images).\n-   **Optimize Output:** Optimize the output of the build process for production.\n\n### 7.3. Linting and Formatting\n\n-   **Use a Linter:** Use a linter like ESLint to enforce coding standards and catch errors.\n-   **Configure Rules:** Configure linting rules to match your project's coding style.\n-   **Use a Formatter:** Use a code formatter like Prettier to automatically format your code.\n\n### 7.4. Deployment\n\n-   **Minify and Gzip:** Minify and Gzip your code before deploying it.\n-   **Use a CDN:** Use a CDN to host static assets.\n-   **Cache Control Headers:** Set appropriate cache control headers.\n\n### 7.5. CI/CD Integration\n\n-   **Automated Builds:** Automate the build process using a CI/CD tool like Jenkins, Travis CI, or GitHub Actions.\n-   **Automated Testing:** Automate the testing process using a CI/CD tool.\n-   **Automated Deployment:** Automate the deployment process using a CI/CD tool.\n\nBy following these best practices, developers can write high-quality, performant, and secure jQuery code that is easy to maintain and scale.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "jquery.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "jquery",
      "this",
      "rule",
      "file",
      "provides",
      "guidelines",
      "development",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "jquery",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-junit",
    "description": "Comprehensive guidelines and best practices for writing effective, maintainable, and performant JUnit tests in Java projects. This rule file covers code organization, patterns, performance, security, testing strategies, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "junit",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/junit.mdc",
    "content": "# JUnit Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive guide to JUnit best practices, covering code organization, patterns, performance considerations, security, testing approaches, common pitfalls, and tooling. Following these guidelines will help you write effective, maintainable, and performant unit tests.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n- **Standard Maven/Gradle Project Structure:** Maintain the standard Maven/Gradle project structure to separate test code from production code.\n  - Production code: `src/main/java/com/example/app/...`\n  - Test code: `src/test/java/com/example/app/...`\n- **Mirror Production Structure:** Mirror the production code structure in the test directory to improve discoverability and maintainability.\n  - Example:\n    - Production: `src/main/java/com/example/app/service/UserService.java`\n    - Test: `src/test/java/com/example/app/service/UserServiceTest.java`\n- **Test Resources:** Place test resources (e.g., configuration files, data files, mock response files) in the `src/test/resources` directory.\n\n### 1.2. File Naming Conventions\n\n- **Test Class Names:** Use the `*Test.java` or `*Tests.java` suffix for test class names to clearly identify them.\n  - Example: `UserServiceTest.java`, `StringUtilsTests.java`\n- **Test Method Names:** Use descriptive test method names that clearly indicate the scenario and expected outcome.\n  - Follow a naming convention like `given_condition_when_action_then_expectedResult`.\n  - Example: `givenValidInput_whenCalculateSum_thenReturnsCorrectSum`\n\n### 1.3. Module Organization\n\n- **Modular Testing:** Organize tests by module or component to improve maintainability and reduce dependencies.\n- **Test Suites:** Use JUnit test suites to group related tests and run them together. This is especially useful for integration tests.\n- **Separate Test Configuration:** Keep test-specific configurations separate from production configurations.\n\n### 1.4. Component Architecture\n\n- **Testable Components:** Design components to be easily testable by following the SOLID principles (especially Dependency Inversion).\n- **Loose Coupling:** Minimize dependencies between components to facilitate isolated unit testing.\n- **Dependency Injection:** Use dependency injection to provide mock implementations of dependencies during testing.\n\n### 1.5. Code Splitting Strategies\n\n- **Small Test Methods:** Keep test methods small and focused on testing a single behavior.\n- **Helper Methods:** Use helper methods to avoid code duplication in test setup and assertions.\n- **Parameterized Tests:** Utilize JUnit's parameterized tests to test the same logic with different input values.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Arrange-Act-Assert (AAA):** Structure tests using the AAA pattern to clearly separate setup (arrange), execution (act), and verification (assert) phases.\n- **Test Fixture:** Use `@BeforeEach` and `@AfterEach` annotations to set up and tear down test data and resources.\n- **Mock Object:**  Utilize mocking frameworks (Mockito, EasyMock, PowerMock) to isolate the unit under test by simulating dependencies.\n- **Page Object Model (POM):** Employ POM for UI testing to create reusable representations of web pages, making tests more readable and robust.\n\n### 2.2. Recommended Approaches\n\n- **Test-Driven Development (TDD):** Write tests before implementing the code to drive development and ensure testability.\n- **Behavior-Driven Development (BDD):** Use BDD frameworks (e.g., Cucumber) to write tests in a natural language format, improving collaboration and understanding.\n- **Code Coverage:** Aim for high code coverage (around 80%) to ensure most of the code is tested, but remember that coverage alone doesn't guarantee quality.\n- **Continuous Integration:** Integrate unit tests into the CI/CD pipeline to automatically run tests on every code commit and provide immediate feedback.\n\n### 2.3. Anti-patterns and Code Smells\n\n- **Testing Implementation Details:** Avoid testing implementation details that might change, leading to brittle tests. Focus on testing behavior and outcomes.\n- **Hard-coded Values:** Avoid hard-coding values in tests. Use constants or test data to make tests more maintainable.\n- **Complex Test Logic:** Keep test logic simple and avoid complex calculations or conditional statements within tests.\n- **Ignoring Edge Cases:** Don't ignore edge cases or boundary conditions. Ensure tests cover a wide range of inputs, including invalid or unexpected values.\n- **Slow Tests:** Avoid slow tests that discourage developers from running them frequently.\n- **Over-reliance on Mocks:** Mock judiciously; too many mocks can obscure the actual behavior and make tests less reliable.\n- **Ignoring Test Failures:** Never ignore failing tests. Investigate and fix them promptly.\n\n### 2.4. State Management\n\n- **Isolated State:** Ensure each test has its own isolated state to avoid interference between tests. Use `@BeforeEach` to reset the state before each test.\n- **Immutable Objects:** Prefer immutable objects to simplify state management and avoid unexpected side effects.\n- **Stateless Components:** Design stateless components whenever possible to reduce the need for state management in tests.\n\n### 2.5. Error Handling\n\n- **Expected Exceptions:** Use `assertThrows` to verify that a method throws the expected exception under specific conditions.\n- **Exception Messages:** Assert the exception message to ensure the correct error is being thrown with helpful context.\n- **Graceful Degradation:** Test how the application handles errors and gracefully degrades when dependencies are unavailable.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Fast Execution:** Keep tests fast to encourage frequent execution.  Aim for millisecond execution times.\n- **Parallel Execution:** Utilize JUnit's parallel execution feature to run tests concurrently and reduce overall test execution time.\n- **Data Setup Optimization:** Optimize data setup by using in-memory databases or test data builders to avoid costly database interactions.\n- **Mocking Optimization:** Optimize mocking by using lightweight mocks and avoiding unnecessary stubbing.\n\n### 3.2. Memory Management\n\n- **Resource Management:** Ensure tests properly release resources (e.g., database connections, file streams) to avoid memory leaks.\n- **Large Data Sets:** Avoid loading large data sets into memory during testing. Use smaller, representative data sets.\n- **Garbage Collection:** Be mindful of garbage collection. Create and destroy objects efficiently within your tests.\n\n### 3.3 Rendering Optimization (if applicable)\n\n- **Headless Testing:**  If UI tests are involved, consider using headless browsers to minimize resource consumption.\n- **Optimized Locators:** Use efficient locators (e.g., IDs, CSS selectors) to quickly find elements during UI testing.\n\n### 3.4 Bundle Size Optimization (if applicable)\n\n- **Code Splitting:** Utilize code splitting techniques to minimize the bundle size of the test code. Ensure only the necessary code is included in each test bundle.\n- **Tree Shaking:** Enable tree shaking to remove unused code from test dependencies.\n\n### 3.5 Lazy Loading\n\n- **On-Demand Initialization:** Initialize test data and mocks only when they are needed to reduce startup time and resource consumption.\n- **Lazy Evaluation:** Use lazy evaluation techniques to defer the execution of expensive operations until they are actually required.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n- **Injection Attacks:** Prevent injection attacks (SQL injection, command injection) by using parameterized queries and input validation.\n- **Cross-Site Scripting (XSS):** Protect against XSS attacks by encoding user inputs before rendering them in the UI.\n- **Authentication and Authorization Bypass:** Ensure proper authentication and authorization mechanisms are in place to prevent unauthorized access.\n- **Data Exposure:** Avoid storing sensitive data in plain text. Use encryption and secure storage mechanisms.\n\n### 4.2. Input Validation\n\n- **Validate All Inputs:** Validate all inputs to ensure they conform to the expected format and range. Use regular expressions, data type validation, and range checks.\n- **Sanitize User Inputs:** Sanitize user inputs to remove potentially harmful characters or code. Use appropriate encoding and escaping techniques.\n\n### 4.3. Authentication and Authorization\n\n- **Secure Authentication:** Implement secure authentication using strong passwords, multi-factor authentication, and token-based authentication.\n- **Role-Based Access Control:** Use role-based access control to restrict access to sensitive resources based on user roles.\n- **Least Privilege Principle:** Grant users only the minimum privileges required to perform their tasks.\n\n### 4.4. Data Protection\n\n- **Encryption:** Use encryption to protect sensitive data at rest and in transit. Use strong encryption algorithms and secure key management practices.\n- **Data Masking:** Mask sensitive data to prevent unauthorized access. Use appropriate masking techniques to protect personally identifiable information (PII).\n- **Secure Storage:** Store sensitive data in secure storage locations with proper access controls.\n\n### 4.5. Secure API Communication\n\n- **HTTPS:** Use HTTPS to encrypt communication between the client and server. Obtain and install a valid SSL certificate.\n- **API Authentication:** Implement API authentication using API keys, tokens, or OAuth 2.0 to verify the identity of the client.\n- **Rate Limiting:** Implement rate limiting to prevent denial-of-service (DoS) attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- **Isolated Testing:** Test individual units of code in isolation from dependencies.\n- **Mocking:** Use mocking frameworks (Mockito, EasyMock) to simulate dependencies.\n- **Test Coverage:** Aim for high code coverage to ensure most of the code is tested.\n- **Edge Cases:** Test edge cases and boundary conditions to ensure code handles unexpected inputs correctly.\n- **Assertion Libraries:** Leverage assertion libraries (AssertJ, Hamcrest) for more expressive and readable assertions.\n\n### 5.2. Integration Testing\n\n- **Component Interactions:** Test interactions between different components or modules.\n- **External Systems:** Test integration with external systems (databases, APIs) using integration tests.\n- **Real Dependencies:** Use real dependencies or in-memory substitutes for integration tests.\n- **Data Consistency:** Verify data consistency and integrity across different components.\n\n### 5.3. End-to-End Testing\n\n- **Full System Testing:** Test the entire system from end to end to ensure it functions correctly.\n- **UI Testing:** Use UI testing frameworks (Selenium, Cypress) to test the user interface.\n- **User Scenarios:** Simulate real user scenarios to verify the system meets user requirements.\n- **Environment Parity:** Test in an environment that closely resembles the production environment.\n\n### 5.4. Test Organization\n\n- **Test Suites:** Organize tests into suites based on functionality or component.\n- **Test Categories:** Use JUnit categories to group tests and run them selectively.\n- **Test Runners:** Use test runners to execute tests and generate reports.\n\n### 5.5. Mocking and Stubbing\n\n- **Mocking Frameworks:** Use mocking frameworks (Mockito, EasyMock) to create mock objects that simulate dependencies.\n- **Stubbing:** Stub methods to return specific values or throw exceptions during testing.\n- **Verification:** Verify that methods are called with the expected arguments during testing.\n- **Avoid Over-Mocking:** Mock only the necessary dependencies to avoid over-complicating tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Ignoring Test Failures:** Ignoring failing tests and not fixing them promptly.\n- **Writing Brittle Tests:** Writing tests that are tightly coupled to implementation details.\n- **Not Testing Edge Cases:** Neglecting to test edge cases and boundary conditions.\n- **Writing Slow Tests:** Writing tests that take a long time to run, discouraging frequent execution.\n- **Not Using Mocking Frameworks:** Failing to use mocking frameworks to isolate units under test.\n\n### 6.2. Edge Cases\n\n- **Null Values:** Handle null values gracefully in tests and production code.\n- **Empty Collections:** Test how code handles empty collections.\n- **Invalid Inputs:** Test how code handles invalid inputs (e.g., negative numbers, invalid dates).\n- **Boundary Conditions:** Test boundary conditions to ensure code behaves correctly at the limits of its input range.\n\n### 6.3. Version-Specific Issues\n\n- **API Changes:** Be aware of API changes in different JUnit versions and update tests accordingly.\n- **Dependency Conflicts:** Resolve dependency conflicts between JUnit and other libraries.\n- **Compatibility Issues:** Ensure compatibility between JUnit and the Java version being used.\n\n### 6.4. Compatibility Concerns\n\n- **Third-Party Libraries:** Ensure compatibility between JUnit and third-party libraries being used.\n- **IDE Support:** Choose an IDE that provides good support for JUnit testing.\n- **Build Tools:** Integrate JUnit with build tools (Maven, Gradle) for automated testing.\n\n### 6.5. Debugging Strategies\n\n- **Debugging Mode:** Run tests in debugging mode to step through the code and inspect variables.\n- **Logging:** Add logging statements to tests to track execution flow and identify issues.\n- **Remote Debugging:** Use remote debugging to debug tests running on remote servers.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **Integrated Development Environment (IDE):** IntelliJ IDEA, Eclipse, NetBeans\n- **Build Tools:** Maven, Gradle\n- **Mocking Frameworks:** Mockito, EasyMock\n- **Assertion Libraries:** AssertJ, Hamcrest\n- **Code Coverage Tools:** JaCoCo, Cobertura\n- **Static Analysis Tools:** SonarQube, FindBugs\n\n### 7.2. Build Configuration\n\n- **Dependency Management:** Use Maven or Gradle to manage JUnit dependencies.\n- **Test Configuration:** Configure test execution options (e.g., parallel execution, code coverage) in the build file.\n- **Plugin Integration:** Integrate JUnit plugins with build tools for automated testing and reporting.\n\n### 7.3. Linting and Formatting\n\n- **Code Style:** Follow a consistent code style (e.g., Google Java Style, Checkstyle) to improve code readability and maintainability.\n- **Linting:** Use linting tools (e.g., Checkstyle, PMD) to enforce code style rules and identify potential issues.\n- **Formatting:** Use code formatting tools (e.g., IntelliJ IDEA formatter, Eclipse formatter) to automatically format code according to the configured style.\n\n### 7.4. Deployment\n\n- **Test Environment:** Deploy applications to a test environment that closely resembles the production environment.\n- **Automated Testing:** Run automated tests in the deployment pipeline to verify the application functions correctly.\n- **Rollback Strategy:** Implement a rollback strategy to quickly revert to a previous version if issues are detected after deployment.\n\n### 7.5. CI/CD Integration\n\n- **Continuous Integration:** Integrate JUnit tests into the CI/CD pipeline to automatically run tests on every code commit.\n- **Automated Testing:** Automate the execution of JUnit tests as part of the build process.\n- **Reporting:** Generate test reports and publish them to the CI/CD system.\n- **Failure Notifications:** Configure failure notifications to alert developers when tests fail.\n\nBy following these best practices, you can write more effective, maintainable, and performant JUnit tests, leading to higher-quality software and faster development cycles.",
    "metadata": {
      "globs": "*Test.java",
      "format": "mdc",
      "originalFile": "junit.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "junit",
      "comprehensive",
      "guidelines",
      "best",
      "practices",
      "writing",
      "effective",
      "maintainable",
      "performant",
      "tests",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "junit",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-keras",
    "description": "This rule enforces Keras library best practices, focusing on code clarity, modularity, performance optimization, and security considerations. It provides actionable guidance for developers to improve the quality and maintainability of Keras-based machine learning projects.",
    "author": "sanjeed5",
    "tags": [
      "keras",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/keras.mdc",
    "content": "# Keras Development Best Practices\n\nThis document outlines best practices for developing Keras applications. It covers various aspects of software engineering, including code organization, common patterns, performance, security, testing, and tooling.\n\nLibrary Information:\n- Name: keras\n- Tags: ai, ml, machine-learning, python, deep-learning\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a well-defined directory structure to enhance maintainability and collaboration.\n\n\nproject_root/\n├── data/                      # Contains datasets (raw, processed)\n├── models/                    # Saved models (weights, architectures)\n├── src/                       # Source code\n│   ├── layers/                # Custom Keras layers\n│   ├── models/                # Model definitions\n│   ├── utils/                 # Utility functions\n│   ├── callbacks/            # Custom Keras Callbacks\n│   ├── preprocessing/        # Data preprocessing scripts\n│   └── __init__.py          # Makes 'src' a Python package\n├── notebooks/                 # Jupyter notebooks for experimentation\n├── tests/                     # Unit and integration tests\n├── requirements.txt           # Project dependencies\n├── README.md                  # Project overview\n└── .gitignore                 # Specifies intentionally untracked files that Git should ignore\n\n\n### 1.2. File Naming Conventions\n\nUse descriptive and consistent file names.\n\n-   `model_name.py`:  For defining Keras models.\n-   `layer_name.py`: For custom Keras layers.\n-   `utils.py`: For utility functions.\n-   `data_preprocessing.py`: For data preprocessing scripts.\n-   `training_script.py`: Main training script.\n\n### 1.3. Module Organization\n\n-   **Single Responsibility Principle:** Each module should have a clear and specific purpose.\n-   **Loose Coupling:** Minimize dependencies between modules.\n-   **High Cohesion:**  Keep related functions and classes within the same module.\n\npython\n# src/models/my_model.py\n\nimport keras\nfrom keras import layers\n\ndef create_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n    x = layers.MaxPooling2D((2, 2))(x)\n    x = layers.Flatten()(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    model = keras.Model(inputs, outputs)\n    return model\n\n\n### 1.4. Component Architecture\n\n-   **Layers:** Encapsulate reusable blocks of computation (e.g., custom convolutional layers, attention mechanisms).\n-   **Models:** Define the overall architecture by combining layers.\n-   **Callbacks:** Implement custom training behaviors (e.g., early stopping, learning rate scheduling).\n-   **Preprocessing:** Separate data loading, cleaning, and transformation logic.\n\n### 1.5. Code Splitting\n\n-   **Functions:** Break down complex logic into smaller, well-named functions.\n-   **Classes:** Use classes to represent stateful components (e.g., custom layers with trainable parameters).\n-   **Packages:** Organize modules into packages for larger projects.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Functional API:** Use the Keras Functional API for building complex, multi-input/output models.\n\n    python\n    input_tensor = keras.Input(shape=(784,))\n    hidden_layer = layers.Dense(units=64, activation='relu')(input_tensor)\n    output_tensor = layers.Dense(units=10, activation='softmax')(hidden_layer)\n    model = keras.Model(inputs=input_tensor, outputs=output_tensor)\n    \n\n-   **Subclassing:**  Subclass `keras.Model` or `keras.layers.Layer` for maximum customization.\n\n    python\n    class MyLayer(layers.Layer):\n        def __init__(self, units=32, **kwargs):\n            super(MyLayer, self).__init__(**kwargs)\n            self.units = units\n\n        def build(self, input_shape):\n            self.w = self.add_weight(shape=(input_shape[-1], self.units),\n                                      initializer='random_normal',\n                                      trainable=True)\n            self.b = self.add_weight(shape=(self.units,),\n                                      initializer='zeros',\n                                      trainable=True)\n\n        def call(self, inputs):\n            return keras.activations.relu(tf.matmul(inputs, self.w) + self.b)\n    \n\n-   **Callbacks:** Implement custom training behaviors (e.g., custom logging, model checkpointing).\n\n    python\n    class CustomCallback(keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs=None):\n            print(f'Epoch {epoch}: Loss = {logs['loss']}')\n    \n\n### 2.2. Recommended Approaches\n\n-   **Data Input Pipelines:** Use `tf.data.Dataset` for efficient data loading and preprocessing.\n-   **Model Checkpointing:**  Save model weights during training to prevent data loss and allow for resuming training.\n-   **Early Stopping:**  Monitor validation loss and stop training when it plateaus to prevent overfitting.\n-   **Learning Rate Scheduling:**  Adjust the learning rate during training to improve convergence.\n\n### 2.3. Anti-Patterns\n\n-   **Hardcoding:** Avoid hardcoding values directly into your code. Use variables and configuration files instead.\n-   **Global Variables:** Minimize the use of global variables to prevent namespace pollution and unexpected side effects.\n-   **Over-Engineering:**  Don't overcomplicate your code with unnecessary abstractions or complex patterns.\n-   **Ignoring Warnings:** Pay attention to warnings and deprecation messages, as they often indicate potential problems.\n-   **Training on the entire dataset without validation:** Always split your data into training, validation and testing sets to avoid overfitting.\n\n### 2.4. State Management\n\n-   **Stateless Operations:**  Prefer stateless operations whenever possible to simplify testing and debugging.\n-   **Model Weights:**  Store model weights separately from the model architecture.\n-   **Configuration Files:**  Use configuration files (e.g., JSON, YAML) to manage hyperparameters and other settings.\n\n### 2.5. Error Handling\n\n-   **Exception Handling:**  Use `try...except` blocks to handle potential exceptions gracefully.\n-   **Logging:**  Log errors and warnings to help diagnose problems.\n-   **Validation:** Validate input data to prevent unexpected errors.\n-   **Assertions:** Use `assert` statements to check for conditions that should always be true.\n\npython\ntry:\n    model = keras.models.load_model('my_model.h5')\nexcept FileNotFoundError:\n    logging.error('Model file not found.')\n    raise\n\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **GPU Acceleration:**  Utilize GPUs for faster training and inference.\n-   **Data Preprocessing:**  Optimize data preprocessing pipelines to reduce overhead.\n-   **Batch Size:**  Adjust the batch size to maximize GPU utilization.\n-   **Model Pruning:**  Remove unnecessary weights from the model to reduce its size and improve its speed.\n-   **Quantization:**  Reduce the precision of model weights to reduce memory consumption and improve inference speed.\n-   **Mixed Precision Training:** Use `tf.keras.mixed_precision.Policy` to enable mixed precision training for faster training on modern GPUs.\n\n### 3.2. Memory Management\n\n-   **Garbage Collection:**  Be mindful of memory leaks and use garbage collection to reclaim unused memory.\n-   **Data Types:**  Use appropriate data types to minimize memory consumption (e.g., `tf.float16` instead of `tf.float32`).\n-   **Generators:**  Use generators to load data in batches, reducing memory usage.\n\n### 3.3. Rendering Optimization (If applicable)\n\nNot directly applicable to Keras itself, but relevant when visualizing model outputs or training progress.  Use libraries like `matplotlib` or `seaborn` efficiently and consider downsampling large datasets before plotting.\n\n### 3.4. Bundle Size Optimization\n\n-   **Model Pruning and Quantization:** as above. \n-   **Selectively Import Keras Modules**: Only import the specific Keras modules needed to reduce the overall bundle size, e.g., `from keras.layers import Dense, Conv2D` instead of `import keras.layers`.\n\n### 3.5. Lazy Loading\n\n-   **Lazy Initialization:**  Defer the initialization of resources until they are actually needed.\n-   **Data Loading:** Load data on demand rather than loading the entire dataset into memory.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n-   **Adversarial Attacks:**  Protect against adversarial attacks that can fool models into making incorrect predictions.\n-   **Data Poisoning:**  Ensure the integrity of training data to prevent data poisoning attacks.\n-   **Model Extraction:** Protect against model extraction attacks that can steal intellectual property.\n\n### 4.2. Input Validation\n\n-   **Sanitize Input:**  Sanitize input data to prevent injection attacks.\n-   **Validate Input:**  Validate input data to ensure that it conforms to the expected format and range.\n\npython\ndef predict(model, input_data):\n    if not isinstance(input_data, np.ndarray):\n        raise TypeError('Input data must be a NumPy array.')\n    if input_data.shape != (1, 784):\n        raise ValueError('Input data must have shape (1, 784).')\n    return model.predict(input_data)\n\n\n### 4.3. Authentication and Authorization\n\n-   **Secure API:**  Implement secure API communication using HTTPS.\n-   **Authentication:**  Require authentication for access to sensitive data and functionality.\n-   **Authorization:**  Enforce authorization policies to control access to resources.\n\n### 4.4. Data Protection\n\n-   **Encryption:**  Encrypt sensitive data at rest and in transit.\n-   **Anonymization:** Anonymize data to protect privacy.\n-   **Data Governance:** Implement data governance policies to ensure data quality and security.\n\n### 4.5. Secure API Communication\n\n-   **HTTPS:**  Use HTTPS for all API communication to encrypt data in transit.\n-   **API Keys:**  Use API keys to authenticate requests.\n-   **Rate Limiting:**  Implement rate limiting to prevent denial-of-service attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   **Test-Driven Development:** Write unit tests before writing code to ensure that the code meets the requirements.\n-   **Test Cases:**  Create test cases for different scenarios, including edge cases and error conditions.\n-   **Assertions:** Use assertions to verify that the code behaves as expected.\n\n### 5.2. Integration Testing\n\n-   **Component Interaction:**  Test the interaction between different components of the application.\n-   **Data Flow:**  Test the flow of data through the application.\n-   **System Integration:** Test the integration of the application with other systems.\n\n### 5.3. End-to-End Testing\n\n-   **User Interface:**  Test the user interface to ensure that it is functional and user-friendly.\n-   **Workflow:**  Test the entire workflow from start to finish.\n-   **Real-World Scenarios:** Test the application in real-world scenarios to ensure that it meets the needs of the users.\n\n### 5.4. Test Organization\n\n-   **Test Directory:** Create a dedicated `tests` directory to store test files.\n-   **Test Modules:** Organize tests into modules based on the components they test.\n-   **Test Naming Conventions:**  Use clear and consistent naming conventions for test files and functions.\n\n### 5.5. Mocking and Stubbing\n\n-   **Mock Objects:** Use mock objects to simulate the behavior of external dependencies.\n-   **Stub Functions:** Use stub functions to replace complex or time-consuming operations with simple, predictable results.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Incorrect Input Shapes:**  Ensure that the input shapes match the expected dimensions.\n-   **Data Type Mismatches:** Use consistent data types throughout the application.\n-   **Gradient Vanishing/Exploding:**  Use appropriate activation functions and weight initialization techniques to prevent gradient problems.\n-   **Overfitting:**  Use regularization techniques (e.g., dropout, L1/L2 regularization) to prevent overfitting.\n\n### 6.2. Edge Cases\n\n-   **Empty Datasets:**  Handle empty datasets gracefully.\n-   **Missing Values:**  Handle missing values appropriately (e.g., imputation, deletion).\n-   **Outliers:**  Identify and handle outliers in the data.\n\n### 6.3. Version-Specific Issues\n\n-   **API Changes:** Be aware of API changes between different versions of Keras and TensorFlow.\n-   **Compatibility:**  Ensure that your code is compatible with the versions of Keras and TensorFlow that you are using.\n\n### 6.4. Compatibility Concerns\n\n-   **TensorFlow Compatibility:** Verify the compatibility between Keras and TensorFlow versions. Keras 3 can run on TensorFlow 2.16 onwards but there can be backwards compatibility issues.\n-   **Hardware Compatibility:** Ensure compatibility with different hardware platforms (e.g., CPU, GPU, TPU).\n\n### 6.5. Debugging Strategies\n\n-   **Logging:** Use logging to track the execution of the code and identify potential problems.\n-   **Debugging Tools:** Use debugging tools (e.g., `pdb`, `TensorBoard`) to inspect the state of the application.\n-   **Print Statements:** Use print statements to display intermediate values and debug the code.\n-   **TensorBoard:** Use TensorBoard to visualize the model architecture, training progress, and performance metrics.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **IDE:**  Use an IDE (e.g., VS Code, PyCharm) with Keras and TensorFlow support.\n-   **Virtual Environment:** Use a virtual environment (e.g., `venv`, `conda`) to isolate project dependencies.\n-   **Jupyter Notebook:** Use Jupyter notebooks for experimentation and prototyping.\n\n### 7.2. Build Configuration\n\n-   **Requirements File:**  Use a `requirements.txt` file to specify project dependencies.\n-   **Setup Script:**  Use a `setup.py` script to define the project metadata and installation instructions.\n\n### 7.3. Linting and Formatting\n\n-   **PEP 8:** Adhere to PEP 8 style guidelines for Python code.\n-   **Linters:** Use linters (e.g., `flake8`, `pylint`) to enforce code style and identify potential problems.\n-   **Formatters:** Use formatters (e.g., `black`, `autopep8`) to automatically format code.\n\n### 7.4. Deployment\n\n-   **Containerization:**  Use containerization (e.g., Docker) to package the application and its dependencies.\n-   **Cloud Platforms:** Deploy the application to a cloud platform (e.g., AWS, Google Cloud, Azure).\n-   **Serving Frameworks:** Use serving frameworks (e.g., TensorFlow Serving, KServe) to deploy models for inference.\n\n### 7.5. CI/CD Integration\n\n-   **Continuous Integration:**  Automate the build, test, and integration process using CI tools (e.g., Jenkins, Travis CI, GitHub Actions).\n-   **Continuous Deployment:**  Automate the deployment process using CD tools (e.g., AWS CodePipeline, Google Cloud Build, Azure DevOps).\n\nThis comprehensive guide provides a strong foundation for developing high-quality, maintainable, and secure Keras applications. By following these best practices, developers can improve their productivity, reduce the risk of errors, and build robust machine learning systems.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "keras.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "keras",
      "this",
      "rule",
      "enforces",
      "library",
      "best",
      "practices",
      "focusing",
      "code",
      "clarity",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "keras",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-kivy",
    "description": "This rule file outlines best practices for Kivy UI development, including code organization, performance, security, and testing. Adhering to these guidelines ensures maintainable, efficient, and secure Kivy applications.",
    "author": "sanjeed5",
    "tags": [
      "kivy",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/kivy.mdc",
    "content": "# Kivy Development Best Practices\n\nThis document provides a comprehensive guide to Kivy development best practices, covering various aspects from code organization to security and testing.\n\n## 1. Code Organization and Structure\n\nProper code organization is crucial for maintainability, scalability, and collaboration in Kivy projects.\n\n### 1.1 Directory Structure\n\nA well-defined directory structure helps organize your Kivy project. Here's a suggested structure:\n\n\nmy_kivy_app/\n├── app.py          # Main application file\n├── main.kv         # Root KV file\n├── screens/        # Directory for screen definitions\n│   ├── __init__.py # Initialize screens package\n│   ├── main_screen.py\n│   ├── main_screen.kv\n│   ├── settings_screen.py\n│   └── settings_screen.kv\n├── components/     # Directory for reusable UI components\n│   ├── __init__.py # Initialize components package\n│   ├── custom_button.py\n│   └── custom_button.kv\n├── utils/          # Utility modules\n│   ├── __init__.py\n│   └── helpers.py\n├── data/           # Data files (JSON, images, fonts, etc.)\n│   ├── images/\n│   ├── fonts/\n│   └── settings.json\n├── tests/          # Unit and integration tests\n│   ├── __init__.py\n│   ├── test_main_screen.py\n│   └── test_helpers.py\n├── .gitignore      # Git ignore file\n├── README.md       # Project README\n└── requirements.txt # Project dependencies\n\n\n*   `app.py`: The main application file where you define your `App` subclass and run the application.\n*   `main.kv`:  The root KV file that typically handles overall layout structure and screen management.  It is loaded automatically if named appropriately (e.g., `myapp.kv` for a `MyApp` class).\n*   `screens/`: Contains individual screen definitions. Each screen can have a Python file for logic and a KV file for layout.\n*   `components/`:  Holds reusable UI components, like custom buttons, labels, or layouts. This promotes code reuse and consistency.\n*   `utils/`:  Includes helper functions and utility modules that provide common functionalities across the application.\n*   `data/`: Stores application data like images, fonts, and configuration files.\n*   `tests/`: Contains unit and integration tests to ensure code quality and prevent regressions.\n*   `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n*   `README.md`: Provides a project overview, setup instructions, and other relevant information.\n*   `requirements.txt`: Lists the Python packages required to run the application.  Use `pip freeze > requirements.txt` to generate this.\n\n### 1.2 File Naming Conventions\n\n*   **Python files:** Use lowercase with underscores (snake_case), e.g., `main_screen.py`, `custom_button.py`.\n*   **KV files:** Use the same name as the corresponding Python file, but with the `.kv` extension, e.g., `main_screen.kv`, `custom_button.kv`.\n*   **Class names:** Use CamelCase, e.g., `MainScreen`, `CustomButton`.\n*   **Variables and functions:** Use snake_case, e.g., `screen_width`, `calculate_layout()`.\n\nConsistent naming conventions improve code readability and maintainability.\n\n### 1.3 Module Organization\n\n*   **Separate concerns:** Divide your application into logical modules based on functionality.  For example, a module for data access, a module for UI components, and a module for business logic.\n*   **Use packages:** Group related modules into packages using `__init__.py` files. This helps organize your project and prevent naming conflicts.\n*   **Keep modules small:** Avoid creating overly large modules.  Smaller modules are easier to understand, test, and reuse.\n*   **Use relative imports:** Within a package, use relative imports (e.g., `from . import helpers`) to refer to other modules in the same package.  This makes your code more portable and less prone to errors.\n\n### 1.4 Component Architecture\n\n*   **Create reusable components:** Design your UI with reusable components. This promotes code reuse, reduces redundancy, and makes it easier to maintain your application.  Kivy's KV language and custom widget creation are ideal for this.\n*   **Use custom widgets:** Create custom widgets by subclassing Kivy's existing widgets or combining multiple widgets.  This allows you to encapsulate complex UI elements and behavior into reusable components.\n*   **Follow the DRY principle (Don't Repeat Yourself):** Abstract common functionalities into reusable components or utility functions. This reduces code duplication and makes your code more maintainable.\n\n### 1.5 Code Splitting\n\n*   **Break down large screens:** If a screen becomes too complex, break it down into smaller, manageable sub-components.\n*   **Lazy loading:** Load parts of the UI or data only when they are needed. This can improve startup time and reduce memory usage.\n*   **Dynamic loading of KV files:**  Load KV files dynamically using `Builder.load_file()` when a screen or component is needed.  This allows you to split your UI definition into multiple files and load them on demand.\n\n## 2. Common Patterns and Anti-patterns\n\nUnderstanding common design patterns and anti-patterns helps you write better Kivy code.\n\n### 2.1 Design Patterns\n\n*   **Model-View-Controller (MVC) / Model-View-Presenter (MVP) / Model-View-ViewModel (MVVM):** Consider using these patterns to separate data (model), UI (view), and logic (controller/presenter/viewmodel). Kivy does not enforce a specific architecture, but these patterns can help organize your code and improve testability.  MVVM is often considered more suitable due to Kivy's declarative nature.\n*   **Observer:**  Kivy's properties and event dispatching mechanism are based on the Observer pattern.  Use properties to observe changes in data and trigger UI updates accordingly.\n*   **Factory:**  Use the Factory pattern to create different types of widgets or objects based on certain conditions or data. This can be useful for dynamically generating UI elements.\n*   **Singleton:** While often debated, Singletons can be useful for global configuration or access to shared resources.  Use with caution and consider alternatives like dependency injection.\n\n### 2.2 Recommended Approaches\n\n*   **Use KV language for UI definition:** Separate your UI definition from your Python code using the KV language. This improves code readability and maintainability.\n*   **Bind properties to UI elements:** Use Kivy's property binding mechanism to automatically update UI elements when data changes. This simplifies UI updates and reduces boilerplate code.\n*   **Use events for user interaction:** Use Kivy's event system to handle user interactions, such as button clicks and text input. This allows you to react to user actions and update the UI accordingly.\n*   **Asynchronous operations:** Use asynchronous operations (e.g., `Clock.schedule_once()`, `Clock.schedule_interval()`, or `async/await`) for long-running tasks to avoid blocking the UI thread.  This ensures that your application remains responsive.\n*   **Data binding with properties:**  Leverage Kivy properties (StringProperty, NumericProperty, ObjectProperty, etc.) for data binding between UI elements and your application's data model. This enables automatic updates of UI elements when the underlying data changes, and vice versa.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Tight coupling:** Avoid tight coupling between UI elements and business logic. Separate your UI definition from your logic using the KV language and appropriate design patterns.\n*   **God object:** Avoid creating overly large and complex classes that handle too many responsibilities. Break down large classes into smaller, more manageable classes.\n*   **Code duplication:** Avoid duplicating code. Abstract common functionalities into reusable components or utility functions.\n*   **Ignoring errors:** Don't ignore errors. Handle errors gracefully and provide meaningful feedback to the user.\n*   **Blocking the UI thread:** Avoid performing long-running tasks on the UI thread. Use asynchronous operations to prevent the UI from freezing.\n*   **Excessive use of `eval()` or `exec()`:** Avoid using `eval()` or `exec()` to execute arbitrary code, as this can introduce security vulnerabilities. Prefer safer alternatives like data binding or function calls.\n*   **Over-reliance on global variables:** Minimize the use of global variables, as they can make your code harder to understand and maintain. Prefer passing data explicitly between components.\n\n### 2.4 State Management\n\n*   **Kivy Properties:** For simple state management within a widget or screen, Kivy Properties are often sufficient.  They offer automatic notification when their value changes, making them easy to bind to UI elements.\n*   **ScreenManager:** The `ScreenManager` widget can store state associated with each screen. This is useful for managing the overall application state and passing data between screens.\n*   **External state management libraries:** For more complex state management requirements, consider using external libraries like: `RxPY`, `KivyMD`, or even integrating with more comprehensive frameworks like Flask for the backend.\n*   **Minimize mutable state:**  Prefer immutable data structures to reduce the risk of unexpected side effects and improve code predictability.\n*   **Centralized State:** Implement a centralized state management system to ensure data consistency across different parts of the application.\n\n### 2.5 Error Handling\n\n*   **Use `try...except` blocks:** Use `try...except` blocks to handle potential exceptions. Provide specific exception handling for different types of errors.\n*   **Log errors:** Log errors to a file or console for debugging purposes. Include relevant information, such as the error message, stack trace, and timestamp.\n*   **Provide user-friendly error messages:** Display user-friendly error messages to the user. Avoid displaying technical details that the user may not understand.\n*   **Handle unhandled exceptions:** Implement a global exception handler to catch unhandled exceptions and prevent the application from crashing. Log the error and display a generic error message to the user.\n*   **Retry mechanism:** Implement a retry mechanism for operations that may fail due to transient errors, such as network connectivity issues.\n\n## 3. Performance Considerations\n\nOptimizing performance is crucial for creating smooth and responsive Kivy applications.\n\n### 3.1 Optimization Techniques\n\n*   **Use the right layout:** Choose the most efficient layout for your UI. `RelativeLayout` and `FloatLayout` can be more expensive than `BoxLayout` or `GridLayout`.\n*   **Minimize widget count:** Reduce the number of widgets in your UI.  Consider using custom drawing or more efficient layouts to achieve the same visual effect with fewer widgets.\n*   **Use textures efficiently:** Load images and textures at the correct size.  Avoid scaling large images down in the UI, as this can be inefficient.  Use texture atlases to combine multiple small images into a single texture, reducing the number of texture swaps.\n*   **Use `AsyncImage` for loading images:** Load images asynchronously using `AsyncImage` to avoid blocking the UI thread.\n*   **Optimize drawing:**  Use Kivy's drawing instructions efficiently.  Batch drawing operations to reduce the number of OpenGL calls.\n*   **Freeze layouts:** Use `Widget.size_hint` with fixed values to help Kivy optimize layout calculations.\n*   **Use appropriate property types:** Use specific Kivy property types (StringProperty, NumericProperty, etc.) instead of generic ObjectProperty to improve performance.\n*   **Avoid complex calculations in property callbacks:**  Keep property callback functions short and simple.  Move complex calculations to separate functions and call them from the callbacks.\n\n### 3.2 Memory Management\n\n*   **Release unused resources:** Release unused resources, such as images and textures, when they are no longer needed.  Use `Widget.clear()` to remove all children from a widget and release their resources.\n*   **Use weak references:** Use weak references to avoid creating circular dependencies that can prevent objects from being garbage collected.\n*   **Avoid creating large lists or dictionaries:** If you need to store large amounts of data, consider using more efficient data structures, such as NumPy arrays or SQLite databases.\n*   **Use generators:** Use generators to process large data sets lazily, reducing memory consumption.\n*   **Profile your application:** Use a memory profiler to identify memory leaks and optimize memory usage.\n\n### 3.3 Rendering Optimization\n\n*   **Use the correct OpenGL context:** Ensure that you are using the correct OpenGL context for your platform.  Kivy supports both OpenGL and OpenGL ES.\n*   **Reduce overdraw:** Reduce overdraw by minimizing the number of overlapping UI elements.\n*   **Use shaders:** Use shaders to perform complex rendering effects efficiently.\n*   **Optimize texture loading:** Optimize texture loading by using compressed textures and mipmaps.\n*   **Use the `kivy.graphics` module efficiently:** Minimize the number of drawing calls and state changes. Batch drawing operations together.\n\n### 3.4 Bundle Size Optimization\n\n*   **Remove unused code:** Remove unused code from your application to reduce the bundle size.\n*   **Compress images:** Compress images to reduce their file size. Use lossless compression for images that require high quality and lossy compression for images where some quality loss is acceptable.\n*   **Use efficient audio formats:** Use efficient audio formats, such as MP3 or Opus, to reduce the size of your audio files.\n*   **Obfuscate your code:** Obfuscate your code to make it harder to reverse engineer and reduce the bundle size.\n*   **Use code minification:** Minify your code to remove unnecessary whitespace and comments, reducing the bundle size.\n*   **Use code splitting:** Split your code into multiple modules and load them on demand to reduce the initial bundle size.\n\n### 3.5 Lazy Loading\n\n*   **Load screens on demand:** Load screens only when they are needed.  This can improve startup time and reduce memory usage. Use `ScreenManager.add_widget()` and `ScreenManager.remove_widget()` to manage screens dynamically.\n*   **Load data on demand:** Load data only when it is needed.  Use asynchronous operations to load data in the background without blocking the UI thread.\n*   **Load images on demand:** Load images only when they are needed.  Use `AsyncImage` to load images asynchronously.\n*   **Virtualization for lists:** When displaying long lists, use virtualization techniques to only render the visible items.  This can significantly improve performance and reduce memory usage.\n\n## 4. Security Best Practices\n\nSecurity should be a primary concern when developing Kivy applications, especially those that handle sensitive data or interact with external services.\n\n### 4.1 Common Vulnerabilities\n\n*   **Code injection:**  Avoid using `eval()` or `exec()` to execute arbitrary code, as this can allow attackers to inject malicious code into your application.\n*   **Cross-site scripting (XSS):**  Be careful when displaying user-generated content in your UI.  Sanitize the content to prevent attackers from injecting malicious scripts.\n*   **SQL injection:**  When interacting with databases, use parameterized queries or object-relational mappers (ORMs) to prevent SQL injection attacks.\n*   **Man-in-the-middle (MITM) attacks:**  Use HTTPS to encrypt communication between your application and external services, preventing attackers from intercepting sensitive data.\n*   **Data leakage:**  Be careful not to leak sensitive data in your application's logs or error messages. Disable debug mode in production builds.\n*   **Insecure storage:**  Avoid storing sensitive data in plain text.  Encrypt sensitive data before storing it locally or in the cloud.\n\n### 4.2 Input Validation\n\n*   **Validate all user input:**  Validate all user input to ensure that it conforms to the expected format and range.  Use regular expressions or custom validation functions to validate input.\n*   **Sanitize user input:**  Sanitize user input to remove potentially harmful characters or code.  Use Kivy's built-in functions or external libraries to sanitize input.\n*   **Limit input length:**  Limit the length of input fields to prevent buffer overflows and other security vulnerabilities.\n*   **Escape output:** Escape output to prevent cross-site scripting (XSS) attacks. Use Kivy's built-in functions or external libraries to escape output.\n*   **Use whitelisting:** Use whitelisting to allow only specific characters or patterns in input fields.  This can be more secure than blacklisting, which attempts to block specific harmful characters or patterns.\n\n### 4.3 Authentication and Authorization\n\n*   **Use secure authentication protocols:** Use secure authentication protocols, such as OAuth 2.0 or JWT, to authenticate users.  Avoid storing passwords in plain text.\n*   **Implement multi-factor authentication (MFA):** Implement multi-factor authentication (MFA) to add an extra layer of security to user accounts.\n*   **Use role-based access control (RBAC):** Use role-based access control (RBAC) to restrict access to sensitive data and functionalities based on user roles.\n*   **Regularly audit your authentication and authorization system:** Regularly audit your authentication and authorization system to identify and fix any vulnerabilities.\n*   **Use password hashing:** Always hash passwords using a strong hashing algorithm (e.g., bcrypt or Argon2) before storing them. Never store passwords in plain text.\n\n### 4.4 Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data before storing it locally or in the cloud.  Use strong encryption algorithms, such as AES.\n*   **Use secure storage:** Store sensitive data in secure storage locations, such as the Android Keystore or iOS Keychain.\n*   **Protect data in transit:** Use HTTPS to encrypt communication between your application and external services.\n*   **Comply with data privacy regulations:** Comply with data privacy regulations, such as GDPR and CCPA.\n*   **Implement data masking:** Mask sensitive data when displaying it in the UI or logs.  This can prevent unauthorized access to sensitive information.\n\n### 4.5 Secure API Communication\n\n*   **Use HTTPS:** Always use HTTPS to communicate with APIs. This encrypts the data transmitted between your application and the API server, preventing eavesdropping.\n*   **Validate API responses:** Validate API responses to ensure that they are in the expected format and do not contain any malicious data.\n*   **Use API keys or tokens:** Use API keys or tokens to authenticate your application with the API server. Store API keys and tokens securely.\n*   **Rate limiting:** Implement rate limiting to prevent denial-of-service attacks. This limits the number of requests that a client can make to the API server within a given time period.\n*   **Input validation on the server-side:** Validate all input data on the server-side, even if you have already validated it on the client-side. This prevents attackers from bypassing client-side validation and injecting malicious data.\n\n## 5. Testing Approaches\n\nTesting is essential for ensuring the quality and reliability of Kivy applications.\n\n### 5.1 Unit Testing\n\n*   **Test individual components:** Unit tests should focus on testing individual components, such as widgets, functions, and classes, in isolation.\n*   **Use a testing framework:** Use a testing framework, such as `unittest` or `pytest`, to organize and run your unit tests.\n*   **Write clear and concise tests:** Write clear and concise tests that are easy to understand and maintain.\n*   **Test edge cases:** Test edge cases to ensure that your code handles unexpected input or conditions correctly.\n*   **Use mock objects:** Use mock objects to isolate components from external dependencies, such as databases or network services.\n*   **Aim for high test coverage:** Aim for high test coverage to ensure that most of your code is tested.\n*   **Test Kivy properties:** Ensure your tests check for proper updates to Kivy Properties, including bindings and event triggering.\n\n### 5.2 Integration Testing\n\n*   **Test interactions between components:** Integration tests should focus on testing the interactions between different components, such as screens, widgets, and data models.\n*   **Test the application as a whole:** Integration tests should also test the application as a whole to ensure that all components work together correctly.\n*   **Use a testing framework:** Use a testing framework, such as `unittest` or `pytest`, to organize and run your integration tests.\n*   **Use a GUI testing framework:** If you need to test the GUI directly, consider using a GUI testing framework, such as `kivy.tests` or `pytest-kivy`.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate user interactions:** End-to-end tests should simulate user interactions to test the application from the user's perspective.\n*   **Test the entire application flow:** End-to-end tests should test the entire application flow to ensure that all steps work correctly.\n*   **Use a testing framework:** Use a testing framework, such as `Selenium` or `Appium`, to automate your end-to-end tests.\n*   **Run tests on different platforms:** Run your end-to-end tests on different platforms to ensure that your application works correctly on all supported platforms.\n\n### 5.4 Test Organization\n\n*   **Create a dedicated `tests` directory:** Create a dedicated `tests` directory to store your tests.\n*   **Organize tests by module:** Organize your tests by module to make it easier to find and run tests.\n*   **Use descriptive test names:** Use descriptive test names to make it clear what each test is testing.\n*   **Write test documentation:** Write test documentation to explain the purpose of each test and how it works.\n*   **Run tests automatically:** Run your tests automatically whenever you make changes to your code. Use a continuous integration system to automate this process.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use mock objects to isolate components:** Use mock objects to isolate components from external dependencies, such as databases or network services.\n*   **Use stub objects to simulate external dependencies:** Use stub objects to simulate external dependencies, such as APIs or hardware devices.\n*   **Use a mocking framework:** Use a mocking framework, such as `unittest.mock` or `mockito`, to create mock and stub objects easily.\n*   **Avoid over-mocking:** Avoid over-mocking, as this can make your tests less effective. Only mock dependencies that are truly external to the component being tested.\n\n## 6. Common Pitfalls and Gotchas\n\nBe aware of common pitfalls and gotchas when developing Kivy applications to avoid wasting time and effort.\n\n### 6.1 Frequent Mistakes\n\n*   **Forgetting to call `super()`:** When subclassing Kivy widgets or classes, remember to call the `super()` method to initialize the parent class properly.\n*   **Not understanding Kivy's property system:** Kivy's property system is powerful but can be confusing at first. Make sure you understand how properties work and how to use them effectively.\n*   **Blocking the UI thread:** Avoid performing long-running tasks on the UI thread, as this can cause the application to freeze.\n*   **Not handling events correctly:** Handle events correctly to ensure that your application responds to user interactions as expected.\n*   **Not using the KV language effectively:** The KV language is a powerful tool for defining UI layouts and styles. Use it effectively to separate your UI definition from your Python code.\n*   **Incorrect file paths in deployment:** When packaging your app, ensure that file paths to assets and other dependencies are correct relative to the packaged application.\n\n### 6.2 Edge Cases\n\n*   **Different screen resolutions:** Test your application on different screen resolutions to ensure that the UI scales correctly.\n*   **Different operating systems:** Test your application on different operating systems to ensure that it works correctly on all supported platforms.\n*   **Different hardware devices:** Test your application on different hardware devices to ensure that it works correctly on all target devices.\n*   **Handling orientation changes:** Implement proper handling of orientation changes (portrait/landscape) in your layouts.\n*   **Input from different devices:** Be aware of differences in input from touchscreens vs. mouse/keyboard, especially when designing interactions.\n\n### 6.3 Version-Specific Issues\n\n*   **Kivy API changes:** Be aware of API changes between different versions of Kivy. Consult the Kivy documentation for migration guides.\n*   **Dependency compatibility:** Ensure that your dependencies are compatible with the version of Kivy you are using.\n*   **Deprecated features:** Be aware of deprecated features and avoid using them in new code. Migrate existing code to use the recommended alternatives.\n\n### 6.4 Compatibility Concerns\n\n*   **Operating system dependencies:** Be aware of operating system dependencies and ensure that your application works correctly on all supported platforms.\n*   **Hardware dependencies:** Be aware of hardware dependencies and ensure that your application works correctly on all target devices.\n*   **Python version compatibility:** Ensure your code is compatible with supported Python versions. Kivy officially supports certain Python versions, so check the Kivy documentation for details.\n\n### 6.5 Debugging Strategies\n\n*   **Use the Kivy console:** Use the Kivy console to inspect the state of your application and execute commands dynamically.\n*   **Use logging:** Use logging to record information about your application's behavior. This can be helpful for debugging issues that occur in production.\n*   **Use a debugger:** Use a debugger, such as `pdb` or `pycharm`, to step through your code and inspect variables.\n*   **Use Kivy's interactive mode:** Use Kivy's interactive mode to test UI layouts and styles without running the entire application.\n*   **Read Kivy's error messages carefully:** Kivy's error messages often provide valuable information about the cause of the error. Read them carefully and try to understand what they mean.\n*   **Search the Kivy documentation and online forums:** Search the Kivy documentation and online forums for solutions to common problems. The Kivy community is very active and helpful.\n\n## 7. Tooling and Environment\n\nUsing the right tools and environment can significantly improve your Kivy development experience.\n\n### 7.1 Recommended Development Tools\n\n*   **Text editor/IDE:** Use a good text editor or IDE, such as VS Code, PyCharm, or Sublime Text. These tools provide features such as syntax highlighting, code completion, and debugging.\n*   **Kivy Designer:** Kivy Designer is a visual UI designer that allows you to create UI layouts visually. It can be helpful for prototyping and experimenting with different UI designs.\n*   **Buildozer:** Buildozer is a tool for packaging Kivy applications for Android, iOS, and other platforms. It simplifies the process of creating deployment packages.\n*   **Python virtual environment manager:**  Use virtualenv, venv (Python 3.3+), or conda to create isolated Python environments for your Kivy projects. This helps manage dependencies and avoid conflicts.\n\n### 7.2 Build Configuration\n\n*   **Use a build system:** Use a build system, such as Make or CMake, to automate the build process.\n*   **Create a build script:** Create a build script to automate the build process. The build script should handle tasks such as installing dependencies, compiling code, and packaging the application.\n*   **Use environment variables:** Use environment variables to configure the build process. This allows you to customize the build process without modifying the code.\n*   **Use a configuration file:** Use a configuration file to store application settings. This allows you to change application settings without modifying the code.\n\n### 7.3 Linting and Formatting\n\n*   **Use a linter:** Use a linter, such as `flake8` or `pylint`, to check your code for style errors and potential problems.\n*   **Use a code formatter:** Use a code formatter, such as `black` or `autopep8`, to automatically format your code according to PEP 8 guidelines.\n*   **Configure your editor/IDE:** Configure your editor/IDE to run the linter and code formatter automatically whenever you save a file. This helps ensure that your code is always clean and consistent.\n\n### 7.4 Deployment\n\n*   **Choose the right deployment method:** Choose the right deployment method for your target platform. For Android, you can use Buildozer to create an APK. For desktop platforms, you can use PyInstaller or cx_Freeze to create executable files.\n*   **Create a deployment script:** Create a deployment script to automate the deployment process. The deployment script should handle tasks such as building the application, packaging it, and uploading it to the target platform.\n*   **Test your application thoroughly:** Test your application thoroughly on the target platform before deploying it to users.\n*   **Follow platform-specific guidelines:** Adhere to platform-specific guidelines for packaging and distributing applications (e.g., Google Play Store guidelines, Apple App Store guidelines).\n\n### 7.5 CI/CD Integration\n\n*   **Use a CI/CD system:** Use a continuous integration/continuous delivery (CI/CD) system, such as Jenkins, Travis CI, GitHub Actions, or GitLab CI, to automate the build, test, and deployment process.\n*   **Create a CI/CD pipeline:** Create a CI/CD pipeline to automate the build, test, and deployment process. The pipeline should handle tasks such as checking out the code, installing dependencies, running tests, building the application, and deploying it to the target platform.\n*   **Use automated testing:** Use automated testing to ensure that your code is always working correctly. The CI/CD pipeline should run your tests automatically whenever you make changes to your code.\n*   **Automate deployment:** Automate deployment to the target platform. The CI/CD pipeline should deploy your application automatically whenever it passes all tests.\n*   **Integration with code review:** Integrate your CI/CD pipeline with your code review process. The CI/CD pipeline should run tests and linters automatically whenever a new pull request is created.\n\nBy following these best practices, you can create maintainable, efficient, secure, and testable Kivy applications.",
    "metadata": {
      "globs": "*.py,*.kv",
      "format": "mdc",
      "originalFile": "kivy.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "kivy",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "development",
      "including",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "kivy",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-kubernetes",
    "description": "This rule provides comprehensive best practices for developing and maintaining Kubernetes applications and infrastructure, covering coding standards, security, performance, testing, and deployment.",
    "author": "sanjeed5",
    "tags": [
      "kubernetes",
      "k8s",
      "devops",
      "infrastructure",
      "cursor",
      "cursor-rule",
      "mdc",
      "containers",
      "orchestration",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/kubernetes.mdc",
    "content": "# Kubernetes Development and Operations Best Practices\n\nThis document outlines a collection of guidelines, style suggestions, and tips for writing code and managing infrastructure within the Kubernetes ecosystem. It emphasizes clarity, maintainability, security, and performance.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n- **Root Level:**\n  - `cmd/`:  Main application entry points. Each subdirectory represents a separate command-line tool or service.\n  - `pkg/`: Reusable libraries and components that can be imported by other projects.\n  - `internal/`: Private code that should not be imported by external projects.  Enforces encapsulation.\n  - `api/`:  API definitions, including protobuf files and OpenAPI specifications.\n  - `config/`: Configuration files, such as YAML manifests, Kustomize configurations, and Helm charts.\n  - `scripts/`: Utility scripts for building, testing, and deploying the application.\n  - `docs/`: Documentation for the project.\n  - `examples/`: Example usage of the library or application.\n  - `vendor/`: (If using `go modules` without external dependency management) Contains vendored dependencies.  Generally discouraged in modern Go with `go modules`.\n- **Component-Specific Directories:** Inside `pkg/` or `internal/`, organize code by component or module. Each component should have its own directory with clear separation of concerns.\n\nExample:\n\n\nmy-kubernetes-project/\n├── cmd/\n│   └── controller/\n│       └── main.go\n├── pkg/\n│   └── api/\n│       ├── types.go\n│   └── controller/\n│       ├── controller.go\n│       ├── reconciler.go\n│   └── util/\n│       └── util.go\n├── internal/\n│   └── admission/\n│       └── webhook.go\n├── config/\n│   ├── deploy/\n│   │   └── deployment.yaml\n│   └── kustomize/\n│       ├── base/\n│       │   ├── kustomization.yaml\n│       │   └── ...\n│       └── overlays/\n│           ├── dev/\n│           │   ├── kustomization.yaml\n│           │   └── ...\n│           └── prod/\n│               ├── kustomization.yaml\n│               └── ...\n├── scripts/\n│   └── build.sh\n├── docs/\n│   └── architecture.md\n└── go.mod\n\n\n### 1.2 File Naming Conventions\n\n- **Go Files:** Use lowercase with underscores (e.g., `my_controller.go`).\n- **YAML Files:** Use lowercase with dashes (e.g., `deployment.yaml`).\n- **Configuration Files:** Be descriptive and consistent (e.g., `config.yaml`, `kustomization.yaml`).\n- **Test Files:** Follow the standard Go convention: `*_test.go` (e.g., `my_controller_test.go`).\n\n### 1.3 Module Organization (Go)\n\n- **Packages:**  Organize code into meaningful packages that represent logical units of functionality.\n- **Internal Packages:** Use `internal/` directories to create packages that are only visible within the project.\n- **Interfaces:** Define interfaces to abstract dependencies and promote testability.\n\n### 1.4 Component Architecture\n\n- **Microservices:** Design applications as a collection of loosely coupled microservices.\n- **Separation of Concerns:** Each component should have a single responsibility and well-defined interfaces.\n- **API Gateway:** Use an API gateway to handle routing, authentication, and rate limiting for external requests.\n- **Service Mesh:** Consider using a service mesh (e.g., Istio, Linkerd) to manage inter-service communication, observability, and security.\n\n### 1.5 Code Splitting Strategies\n\n- **Feature-Based Splitting:** Group code by feature or functionality.\n- **Layer-Based Splitting:** Separate code into layers, such as data access, business logic, and presentation.\n- **Component-Based Splitting:** Divide code into reusable components that can be shared across multiple projects.\n\n## 2. Common Patterns and Anti-Patterns\n\n### 2.1 Design Patterns\n\n- **Controller Pattern:** Implement controllers to reconcile the desired state of Kubernetes resources with the actual state.\n- **Operator Pattern:** Extend the Kubernetes API with custom resources and controllers to automate complex application management tasks.\n- **Sidecar Pattern:** Deploy a sidecar container alongside the main application container to provide supporting functionality, such as logging, monitoring, or security.\n- **Ambassador Pattern:**  Use an ambassador container to proxy network traffic to the main application container, providing features such as load balancing, routing, and authentication.\n- **Adapter Pattern:** Translate requests from one interface to another, allowing different components to work together.\n- **Singleton Pattern:** Implement a singleton pattern for managing global resources, such as database connections or configuration settings. Be extremely cautious, as this can hurt testability and introduce implicit dependencies.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Resource Management:** Use Kubernetes resource requests and limits to ensure that applications have sufficient resources and prevent resource contention.\n- **Configuration Management:** Use ConfigMaps and Secrets to manage configuration data and sensitive information separately from the application code.\n- **Service Discovery:** Use Kubernetes services to provide a stable endpoint for accessing applications, even when pods are scaled up or down.\n- **Health Checks:** Implement liveness and readiness probes to monitor the health of applications and automatically restart unhealthy pods.\n- **Logging and Monitoring:** Use a centralized logging and monitoring system to collect and analyze application logs and metrics.\n- **Rolling Updates:** Use Kubernetes deployments to perform rolling updates of applications with zero downtime.\n\n### 2.3 Anti-Patterns and Code Smells\n\n- **Naked Pods:** Avoid creating pods directly without a deployment or replica set, as they will not be automatically rescheduled if a node fails.\n- **Hardcoded Configuration:** Avoid hardcoding configuration data in the application code. Use ConfigMaps and Secrets instead.\n- **Ignoring Resource Limits:** Failing to set resource requests and limits can lead to resource contention and performance issues.\n- **Oversized Containers:**  Keep container images small and focused to improve startup time and reduce security risks.\n- **Privileged Containers:** Avoid running containers in privileged mode, as it can create security vulnerabilities.\n- **Long-Lived Branches:** Avoid creating long-lived branches, and prefer small, frequent merges to the main branch.\n- **God Classes:** Avoid creating classes that are too large and complex.  Break them down into smaller, more manageable classes.\n- **Shotgun Surgery:**  Avoid making changes to multiple classes when a single feature is modified. This suggests poor class design and coupling.\n- **Feature Envy:**  Avoid methods that access the data of another object more than their own.  This suggests that the method might be in the wrong class.\n\n### 2.4 State Management Best Practices\n\n- **Stateless Applications:** Prefer stateless applications whenever possible, as they are easier to scale and manage.\n- **Persistent Volumes:** Use Persistent Volumes to store persistent data for stateful applications.\n- **External Databases:** Consider using external databases for managing application state, such as databases hosted on cloud providers.\n- **Kubernetes Operators:** Implement Kubernetes operators to automate the management of stateful applications.\n- **Etcd:** Understand the importance of etcd as Kubernetes' data store and protect it accordingly.\n\n### 2.5 Error Handling Patterns\n\n- **Centralized Error Handling:** Implement a centralized error handling mechanism to handle exceptions and log errors consistently.\n- **Retry Mechanism:** Implement a retry mechanism to automatically retry failed operations.\n- **Circuit Breaker Pattern:** Use a circuit breaker pattern to prevent cascading failures in distributed systems.\n- **Logging Error Details:** Log detailed error messages, including stack traces and relevant context, to help with debugging.\n- **Graceful Degradation:** Design applications to gracefully degrade functionality when errors occur.\n- **Alerting on Critical Errors:** Set up alerts to notify administrators when critical errors occur.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Caching:** Implement caching to reduce latency and improve performance.\n- **Load Balancing:** Use load balancing to distribute traffic across multiple instances of an application.\n- **Connection Pooling:** Use connection pooling to reuse database connections and reduce overhead.\n- **Compression:** Use compression to reduce the size of data transmitted over the network.\n- **Gzip:** Enable Gzip compression in web servers to reduce the size of HTTP responses.\n\n### 3.2 Memory Management\n\n- **Memory Profiling:** Use memory profiling tools to identify memory leaks and optimize memory usage.\n- **Garbage Collection:** Understand how garbage collection works in the programming language used for the application.\n- **Resource Limits:** Set memory resource limits for containers to prevent them from consuming excessive memory.\n- **Monitor Memory Usage:** Monitor memory usage regularly to identify potential issues.\n\n### 3.3 Rendering Optimization\n\n- **Minimize DOM Manipulation:** Reduce the number of DOM manipulations to improve rendering performance in web applications.\n- **Virtual DOM:** Use a virtual DOM to optimize rendering updates in web applications.\n- **Lazy Loading:** Use lazy loading to load images and other resources only when they are needed.\n\n### 3.4 Bundle Size Optimization\n\n- **Code Minification:** Use code minification to reduce the size of JavaScript and CSS files.\n- **Tree Shaking:** Use tree shaking to remove unused code from JavaScript bundles.\n- **Image Optimization:** Optimize images to reduce their file size without sacrificing quality.\n- **Code Splitting:** Split the application code into smaller bundles that can be loaded on demand.\n\n### 3.5 Lazy Loading Strategies\n\n- **On-Demand Loading:** Load resources only when they are needed by the application.\n- **Intersection Observer:** Use the Intersection Observer API to detect when elements are visible in the viewport and load them accordingly.\n- **Placeholder Images:** Use placeholder images while loading the actual images to improve the user experience.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n- **Injection Attacks:** Prevent injection attacks by validating and sanitizing all user input.\n- **Cross-Site Scripting (XSS):** Prevent XSS attacks by escaping all user-generated content before rendering it in the browser.\n- **Cross-Site Request Forgery (CSRF):** Prevent CSRF attacks by using anti-CSRF tokens.\n- **Authentication and Authorization Flaws:** Implement robust authentication and authorization mechanisms to protect sensitive data and resources.\n- **Security Misconfiguration:** Avoid using default configurations and ensure that all components are properly configured with security in mind.\n- **Using Components with Known Vulnerabilities:** Keep all dependencies up to date to patch known vulnerabilities.\n- **Insufficient Logging and Monitoring:** Implement comprehensive logging and monitoring to detect and respond to security incidents.\n- **Container Security:** Follow best practices for securing containers, such as using minimal images, running as non-root, and limiting capabilities.\n- **Network Policies:** Use network policies to restrict network traffic between pods.\n- **RBAC (Role-Based Access Control):** Implement RBAC to control access to Kubernetes resources.\n- **Secrets Management:** Use Kubernetes Secrets to store sensitive information, and encrypt secrets at rest.\n- **Pod Security Policies/Pod Security Standards:** Enforce Pod Security Standards to restrict the capabilities of pods.\n\n### 4.2 Input Validation\n\n- **Validate All Input:** Validate all input, including user input, API requests, and configuration data.\n- **Use Strong Data Types:** Use strong data types to enforce data integrity.\n- **Sanitize Input:** Sanitize input to remove potentially harmful characters and prevent injection attacks.\n- **Whitelist Input:** Use a whitelist approach to only allow known good input.\n- **Blacklist Input:** Avoid using a blacklist approach, as it can be easily bypassed.\n\n### 4.3 Authentication and Authorization Patterns\n\n- **Multi-Factor Authentication (MFA):** Use MFA to enhance authentication security.\n- **OAuth 2.0:** Use OAuth 2.0 for authorization and delegation of access.\n- **JSON Web Tokens (JWT):** Use JWTs for securely transmitting claims between parties.\n- **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on roles.\n- **Least Privilege Principle:** Grant users and applications only the minimum necessary permissions.\n\n### 4.4 Data Protection Strategies\n\n- **Encryption at Rest:** Encrypt sensitive data at rest to protect it from unauthorized access.\n- **Encryption in Transit:** Encrypt sensitive data in transit using HTTPS or other secure protocols.\n- **Data Masking:** Mask sensitive data to prevent it from being exposed to unauthorized users.\n- **Data Anonymization:** Anonymize data to remove personally identifiable information (PII).\n- **Data Loss Prevention (DLP):** Implement DLP measures to prevent sensitive data from leaving the organization.\n\n### 4.5 Secure API Communication\n\n- **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n- **API Authentication:** Implement API authentication to verify the identity of clients.\n- **API Authorization:** Implement API authorization to control access to API endpoints.\n- **Rate Limiting:** Implement rate limiting to prevent abuse and denial-of-service attacks.\n- **Input Validation:** Validate all API requests to prevent injection attacks and other vulnerabilities.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n- **Test-Driven Development (TDD):** Write unit tests before writing the application code.\n- **Mock Dependencies:** Use mocks to isolate the unit being tested from its dependencies.\n- **Test Boundary Conditions:** Test boundary conditions and edge cases to ensure that the code handles them correctly.\n- **Test Error Conditions:** Test error conditions to ensure that the code handles errors gracefully.\n- **Code Coverage:** Aim for high code coverage to ensure that all parts of the code are tested.\n- **Table-Driven Tests:**  Use table-driven tests to easily test multiple inputs and outputs.\n\n### 5.2 Integration Testing\n\n- **Test Interactions Between Components:** Test the interactions between different components of the application.\n- **Test with Real Dependencies:** Use real dependencies or integration mocks for integration tests.\n- **Test Data Flows:** Test the data flows through the application to ensure that data is processed correctly.\n- **Contract Tests:**  Use contract tests to ensure that services adhere to a defined contract.\n\n### 5.3 End-to-End Testing\n\n- **Test the Entire System:** Test the entire system from end to end to ensure that all components work together correctly.\n- **Automate End-to-End Tests:** Automate end-to-end tests to ensure that they are run regularly.\n- **Use Realistic Test Data:** Use realistic test data to simulate real-world scenarios.\n- **CI/CD Integration:** Integrate end-to-end tests into the CI/CD pipeline.\n\n### 5.4 Test Organization\n\n- **Keep Tests Separate from Code:** Keep tests separate from the application code in a dedicated `test/` directory.\n- **Organize Tests by Component:** Organize tests by component or module to make them easier to find and maintain.\n- **Use Clear Naming Conventions:** Use clear naming conventions for test files and test functions.\n\n### 5.5 Mocking and Stubbing\n\n- **Use Mocking Frameworks:** Use mocking frameworks to simplify the creation of mocks and stubs.\n- **Mock External Dependencies:** Mock external dependencies, such as databases and APIs, to isolate the unit being tested.\n- **Stub Responses:** Use stubs to provide predefined responses for external dependencies.\n- **Verify Interactions:** Verify that the code under test interacts with dependencies as expected.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n- **Ignoring Error Handling:** Failing to handle errors properly can lead to unexpected behavior and crashes.\n- **Not Using Version Control:** Not using version control can lead to lost code and conflicts.\n- **Hardcoding Configuration:** Hardcoding configuration data can make it difficult to deploy the application in different environments.\n- **Not Securing Sensitive Data:** Not securing sensitive data can lead to security breaches.\n- **Not Testing Thoroughly:** Not testing thoroughly can lead to bugs and performance issues.\n- **Over-Engineering:** Adding unnecessary complexity to the code can make it difficult to understand and maintain.\n- **Premature Optimization:** Optimizing code before it is necessary can waste time and make the code harder to read.\n- **Not Documenting Code:** Not documenting code can make it difficult for others to understand and maintain it.\n\n### 6.2 Edge Cases to Be Aware Of\n\n- **Network Connectivity Issues:** Handle network connectivity issues gracefully.\n- **Resource Exhaustion:** Handle resource exhaustion gracefully.\n- **Concurrency Issues:** Avoid concurrency issues by using proper synchronization mechanisms.\n- **Data Corruption:** Protect against data corruption by using checksums and other data integrity techniques.\n- **Time Zone Issues:** Be aware of time zone issues when working with dates and times.\n\n### 6.3 Version-Specific Issues\n\n- **API Version Compatibility:** Be aware of API version compatibility issues when upgrading Kubernetes or other dependencies.\n- **Feature Deprecation:** Be aware of feature deprecation when upgrading Kubernetes or other dependencies.\n- **Configuration Changes:** Be aware of configuration changes when upgrading Kubernetes or other dependencies.\n\n### 6.4 Compatibility Concerns\n\n- **Operating System Compatibility:** Ensure that the application is compatible with the target operating systems.\n- **Architecture Compatibility:** Ensure that the application is compatible with the target architectures (e.g., x86, ARM).\n- **Browser Compatibility:** Ensure that web applications are compatible with the target browsers.\n\n### 6.5 Debugging Strategies\n\n- **Logging:** Use detailed logging to help identify the root cause of issues.\n- **Debugging Tools:** Use debugging tools, such as debuggers and profilers, to analyze the code and identify performance bottlenecks.\n- **Remote Debugging:** Use remote debugging to debug applications running in Kubernetes.\n- **Log Aggregation:**  Use log aggregation tools (e.g., Elasticsearch, Loki) to centralize and analyze logs.\n- **Metrics Monitoring:** Use metrics monitoring tools (e.g., Prometheus, Grafana) to track application performance.\n- **Tracing:** Implement distributed tracing (e.g., Jaeger, Zipkin) to track requests across multiple services.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE:** Use a modern IDE with support for the programming language used for the application (e.g., VS Code, IntelliJ IDEA, GoLand).\n- **Kubectl:** Use `kubectl` for interacting with Kubernetes clusters.\n- **Minikube/Kind:** Use Minikube or Kind for local Kubernetes development.\n- **Helm:** Use Helm for managing Kubernetes packages.\n- **Kustomize:** Use Kustomize for customizing Kubernetes configurations.\n- **Docker:** Use Docker for building and managing container images.\n- **Tilt:** Use Tilt for fast, local Kubernetes development.\n- **Skaffold:** Use Skaffold for automated build, push, and deploy workflows.\n- **Telepresence:** Use Telepresence to debug applications running in Kubernetes from your local machine.\n\n### 7.2 Build Configuration\n\n- **Makefile:** Use a Makefile to automate common build tasks.\n- **CI/CD Pipeline:** Integrate the build process into a CI/CD pipeline.\n- **Dependency Management:** Use a dependency management tool, such as `go modules`, to manage dependencies.\n- **Version Control:** Use version control to track changes to the build configuration.\n\n### 7.3 Linting and Formatting\n\n- **Linters:** Use linters to enforce code style and best practices (e.g., `golangci-lint`, `eslint`, `stylelint`).\n- **Formatters:** Use formatters to automatically format code according to a predefined style (e.g., `go fmt`, `prettier`).\n- **Pre-Commit Hooks:** Use pre-commit hooks to run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n- **Infrastructure as Code (IaC):** Use IaC tools, such as Terraform or CloudFormation, to manage infrastructure.\n- **Immutable Infrastructure:** Deploy immutable infrastructure to ensure consistency and repeatability.\n- **Blue-Green Deployments:** Use blue-green deployments to minimize downtime during deployments.\n- **Canary Deployments:** Use canary deployments to test new versions of the application with a small subset of users.\n- **Rolling Updates:** Use rolling updates to gradually update the application with zero downtime.\n- **Automated Rollbacks:** Implement automated rollbacks to quickly revert to a previous version of the application if something goes wrong.\n\n### 7.5 CI/CD Integration\n\n- **Automated Testing:** Automate all tests in the CI/CD pipeline.\n- **Automated Deployment:** Automate the deployment process in the CI/CD pipeline.\n- **Continuous Integration:** Use continuous integration to automatically build and test the application whenever code is committed.\n- **Continuous Delivery:** Use continuous delivery to automatically deploy the application to production whenever a new version is released.\n- **Pipeline Security:** Secure the CI/CD pipeline to prevent unauthorized access and code injection.\n\n## Bibliography\n\n- Kubernetes documentation: [https://kubernetes.io/docs/](https://kubernetes.io/docs/)\n- Kubernetes Best Practices: [https://kubernetes.io/docs/concepts/configuration/overview/](https://kubernetes.io/docs/concepts/configuration/overview/)\n- Application Security Checklist: [https://kubernetes.io/docs/concepts/security/application-security-checklist/](https://kubernetes.io/docs/concepts/security/application-security-checklist/)\n- Kubernetes coding conventions: [https://www.kubernetes.dev/docs/guide/coding-convention/](https://www.kubernetes.dev/docs/guide/coding-convention/)",
    "metadata": {
      "globs": "*.go,*.yaml,*.yml,*.sh,*.tf,*.tfvars,*.json",
      "format": "mdc",
      "originalFile": "kubernetes.mdc"
    },
    "subcategory": "containers",
    "keywords": [
      "cursor",
      "kubernetes",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "maintaining",
      "applications",
      "k8s",
      "devops",
      "infrastructure",
      "cursor-rule",
      "mdc",
      "containers",
      "orchestration"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "kubernetes",
        "k8s",
        "devops",
        "infrastructure",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-langchain-js",
    "description": "Comprehensive best practices and coding standards for developing applications using LangChain.js. Focuses on code organization, performance, security, testing, and common pitfalls to ensure robust and maintainable AI-driven solutions.",
    "author": "sanjeed5",
    "tags": [
      "langchain-js",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/langchain-js.mdc",
    "content": "- **Monitor and Evaluate LLM applications**: Utilize tools like LangSmith for monitoring application performance, including logging traces, analyzing latency, and evaluating LLM outputs against predefined metrics. This helps identify bottlenecks and ensures the application meets quality standards. Enable tracing by setting environment variables:\n\t`export LANGCHAIN_TRACING_V2=\"true\"`\n\t`export LANGCHAIN_API_KEY=\"...\"`\n\n- **Implement Stateful Agents**: Use LangGraph to build stateful agents, crucial for applications like chatbots where remembering past interactions enhances user experience. Model interactions as a graph with nodes (states) and edges (transitions).\n\n- **Maintain High Code Quality**: Enforce strict code quality through regular testing, ESLint, and Prettier for consistent code formatting and linting.\n\n- **Comprehensive Documentation**: Ensure all components and their interactions are well-documented for maintainability and scalability.\n\n- **Use LangChain Expression Language (LCEL)**: Employ LCEL for composing chains in a declarative way, supporting production deployment without code changes.\n\n- **Explore Trade-offs in Deployment**: Choose between using external LLM providers or self-hosting open-source models based on cost, latency, and privacy considerations.\n\n- **Secure Coding Practices**: Read up on our Security best practices to make sure you're developing safely with LangChain.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure**: Organize code into logical modules based on functionality (e.g., `chains`, `agents`, `tools`, `memory`).\n  \n  src/\n  ├── chains/\n  │   ├── conversationalChain.ts\n  │   └── summarizationChain.ts\n  ├── agents/\n  │   ├── agent.ts\n  │   └── agentExecutor.ts\n  ├── tools/\n  │   ├── searchTool.ts\n  │   └── calculatorTool.ts\n  ├── memory/\n  │   ├── bufferMemory.ts\n  │   └── conversationBufferMemory.ts\n  ├── utils/\n  │   ├── api.ts\n  │   └── helpers.ts\n  ├── index.ts\n  └── types.ts\n  \n\n- **File Naming Conventions**: Use descriptive names, typically in `camelCase` for variables and functions, and `PascalCase` for classes and interfaces.  Consider prefixes or suffixes to denote the type of module e.g., `*_chain.ts` or `*_agent.ts`\n\n- **Module Organization**: Group related functionalities into modules with clear interfaces. Use `index.ts` files to export module members for cleaner imports.\n  typescript\n  // chains/index.ts\n  export * from './conversationalChain';\n  export * from './summarizationChain';\n  \n  // Usage:\n  import { ConversationalChain, SummarizationChain } from '@/chains';\n  \n\n- **Component Architecture**: Design modular components for reusability. Implement interfaces to define contracts between components.\n  typescript\n  // Define an interface for a Tool\n  interface ToolInterface {\n      name: string;\n      description: string;\n      execute(input: string): Promise<string>;\n  }\n\n  // Implement the interface in a specific Tool\n  class SearchTool implements ToolInterface {\n      name = 'search';\n      description = 'Useful for searching the internet.';\n      async execute(input: string): Promise<string> {\n          // Implementation\n      }\n  }\n  \n\n- **Code Splitting**: Implement code splitting using dynamic imports to reduce initial load time, especially for large applications.\n  typescript\n  async function loadLargeModule() {\n      const largeModule = await import('./largeModule');\n      largeModule.initialize();\n  }\n  \n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns**: Use the Factory pattern for creating different types of chains or agents, and the Strategy pattern for choosing different LLMs.\n  typescript\n  // Factory Pattern for creating chains\n  class ChainFactory {\n      static createChain(type: 'conversational' | 'summarization', llm: LLM) {\n          if (type === 'conversational') {\n              return new ConversationalChain(llm);\n          } else if (type === 'summarization') {\n              return new SummarizationChain(llm);\n          } else {\n              throw new Error('Invalid chain type');\n          }\n      }\n  }\n\n  const chain = ChainFactory.createChain('conversational', new OpenAIChat());\n  \n\n- **Recommended Approaches**: Leverage LangChain's built-in modules and chains when possible, and customize them as needed. Prioritize asynchronous operations to prevent blocking the main thread.\n\n- **Anti-patterns**: Avoid deeply nested callbacks, which can lead to callback hell. Use `async/await` and promises for cleaner asynchronous code.\n\n- **State Management**: For simple applications, manage state with React's `useState` or similar. For complex applications, consider state management libraries like Zustand or Redux.\n\n- **Error Handling**: Implement robust error handling with `try/catch` blocks and global error handlers. Log errors with context for debugging.\n  typescript\n  async function processData() {\n      try {\n          const result = await fetchData();\n          // Process result\n      } catch (error) {\n          console.error('Error processing data:', error);\n          // Handle error (e.g., display error message to user)\n      }\n  }\n  \n\n## 3. Performance Considerations\n\n- **Optimization Techniques**: Use caching to store and reuse LLM responses. Optimize prompts to reduce token usage. Debounce computationally expensive operations.\n\n- **Memory Management**: Be mindful of memory leaks, especially when using streams or subscriptions. Properly clean up resources when components unmount.\n\n- **Bundle Size Optimization**: Use tools like Webpack Bundle Analyzer to identify large dependencies. Use tree shaking to remove unused code.\n\n- **Lazy Loading**: Implement lazy loading for components and modules that are not immediately needed to improve initial load time.\n\n## 4. Security Best Practices\n\n- **Vulnerabilities**: Prevent prompt injection attacks by carefully validating user inputs and using sandboxed execution environments.\n\n- **Input Validation**: Sanitize user inputs to prevent malicious code execution. Limit the length of inputs to prevent denial-of-service attacks.\n\n- **Authentication/Authorization**: Use secure authentication and authorization mechanisms to protect sensitive data and prevent unauthorized access.\n\n- **Data Protection**: Encrypt sensitive data at rest and in transit. Comply with data privacy regulations like GDPR and CCPA.\n\n- **Secure API Communication**: Use HTTPS for all API communication. Validate API responses to prevent data corruption.\n\n## 5. Testing Approaches\n\n- **Unit Testing**: Test individual components in isolation using Jest or Mocha. Mock dependencies to control test environments.\n\n- **Integration Testing**: Test interactions between components to ensure they work together correctly. Use in-memory databases or mock APIs for integration tests.\n\n- **End-to-end Testing**: Test the entire application flow using tools like Cypress or Puppeteer. Simulate user interactions to verify functionality.\n\n- **Test Organization**: Organize tests into separate directories based on component or module. Use clear and descriptive test names.\n\n- **Mocking/Stubbing**: Use mocking libraries like Jest's `jest.mock()` or Sinon.js to replace dependencies with controlled test doubles.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes**: Incorrectly configuring API keys, not handling errors properly, and overlooking prompt injection vulnerabilities.\n\n- **Edge Cases**: Handling unexpected input formats, dealing with rate limits from LLM providers, and managing long-running operations.\n\n- **Version-Specific Issues**: Check release notes for breaking changes when upgrading LangChain.js versions.\n\n- **Compatibility Concerns**: Ensure compatibility between LangChain.js and other libraries, especially those related to data processing or UI frameworks.\n\n- **Debugging Strategies**: Use console logging, debuggers, and monitoring tools like LangSmith to diagnose issues.\n\n## 7. Tooling and Environment\n\n- **Recommended Tools**: VS Code with TypeScript support, ESLint, Prettier, and Jest.\n\n- **Build Configuration**: Use Webpack, Parcel, or Rollup for bundling and optimization. Configure TypeScript compiler options for strict type checking.\n\n- **Linting/Formatting**: Enforce consistent code style with ESLint and Prettier. Use linting rules to catch potential errors and enforce best practices.\n\n- **Deployment Best Practices**: Use serverless functions or containerization for deployment. Implement monitoring and alerting to detect issues in production.\n\n- **CI/CD Integration**: Automate testing, linting, and deployment with CI/CD pipelines using tools like GitHub Actions or Jenkins.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx",
      "format": "mdc",
      "originalFile": "langchain-js.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "langchain",
      "js",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "applications",
      "using",
      "focuses",
      "langchain-js",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "langchain-js",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-langchain",
    "description": "This rule provides best practices for developing LangChain applications, covering code organization, performance, security, testing, and common pitfalls. It aims to improve code quality, maintainability, and overall project success.",
    "author": "sanjeed5",
    "tags": [
      "langchain",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/langchain.mdc",
    "content": "# LangChain Development Best Practices\n\nThis document outlines the best practices for developing LangChain applications to ensure code quality, maintainability, performance, security, and overall project success. These guidelines cover various aspects of development, from code organization to testing and deployment.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a clear and consistent directory structure to improve code discoverability and maintainability. A recommended structure is:\n\n\nproject_root/\n├── data/                   # Raw data, processed data, and datasets\n├── src/                    # Source code directory\n│   ├── components/          # Reusable LangChain components (e.g., custom chains, tools)\n│   ├── chains/              # Definitions of LangChain chains\n│   ├── agents/              # Agent implementations\n│   ├── memory/              # Memory implementations\n│   ├── utils/               # Utility functions and modules\n│   ├── models/              # Custom model definitions or wrappers\n│   ├── callbacks/           # Custom callback handlers\n│   ├── vectorstores/        # Vectorstore configurations and connections\n│   ├── document_loaders/  # Custom document loaders\n│   ├── prompts/             # Prompt templates and management\n│   ├── config/              # Configuration files\n│   └── main.py              # Entry point of the application\n├── tests/                  # Unit and integration tests\n├── notebooks/              # Jupyter notebooks for experimentation and documentation\n├── docs/                   # Project documentation\n├── requirements.txt        # Project dependencies\n├── pyproject.toml          # Project metadata and build configuration\n└── README.md               # Project README file\n\n\n### 1.2 File Naming Conventions\n\nUse descriptive and consistent file names:\n\n-   `module_name.py`: For general modules.\n-   `component_name.py`: For LangChain components (e.g., `custom_chain.py`).\n-   `test_module_name.py`: For test files.\n-   Use lowercase and underscores for file names (snake_case).\n\n### 1.3 Module Organization\n\nOrganize code into logical modules based on functionality. Each module should have a clear purpose and minimal dependencies.\n\n-   **Cohesion**: Modules should have high cohesion, meaning their elements are closely related.\n-   **Coupling**: Modules should have low coupling, meaning they are independent of each other as much as possible.\n\n### 1.4 Component Architecture\n\nDesign LangChain applications using a component-based architecture. Components should be reusable, testable, and well-defined.\n\n-   **Chains**: Define chains as reusable components that encapsulate specific workflows.\n-   **Agents**: Implement agents as modular entities that interact with the environment using tools.\n-   **Memory**: Manage conversation history and state using memory components.\n-   **Tools**: Create tools as independent units that perform specific actions.\n-   **Callbacks**: Utilize callbacks for logging, monitoring, and custom event handling.\n\n### 1.5 Code Splitting Strategies\n\nSplit large files into smaller, manageable chunks to improve readability and maintainability.\n\n-   **Function-level splitting**: Break down large functions into smaller, single-purpose functions.\n-   **Class-level splitting**: Divide large classes into smaller, more focused classes.\n-   **Module-level splitting**: Separate modules based on functionality to reduce complexity.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to LangChain\n\n-   **Chain of Responsibility**: Implement chains of operations where each component handles a specific task, passing the result to the next component.\n-   **Strategy Pattern**: Use strategy patterns to encapsulate different algorithms or behaviors within interchangeable strategy objects.\n-   **Template Method**: Define the skeleton of an algorithm in a base class, allowing subclasses to override specific steps without changing the algorithm's structure.\n-   **Factory Pattern**: Use factory patterns to create instances of LangChain components dynamically, based on configuration or runtime conditions.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Prompt Engineering**: Use prompt templates to manage and reuse prompts. Optimize prompts for clarity, context, and desired output.\n-   **Data Loading**: Implement custom data loaders to handle various data sources and formats. Use text splitters to chunk large documents into smaller pieces for retrieval.\n-   **Vector Storage**: Use vector stores to store and retrieve embeddings efficiently. Choose the appropriate vector store based on performance, scalability, and cost.\n-   **Agent Design**: Design agents with clear objectives, tools, and decision-making logic. Use observation logs to track agent actions and outcomes.\n-   **Memory Management**: Implement memory components to maintain conversation history and context. Use sliding window or summarization techniques to manage long conversations.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **God Classes**: Avoid creating large classes that handle too many responsibilities.\n-   **Long Methods**: Avoid creating long methods that are difficult to understand and maintain.\n-   **Duplicated Code**: Avoid duplicating code across multiple modules. Extract common code into reusable functions or components.\n-   **Magic Numbers**: Avoid using magic numbers or hardcoded values. Define constants or configuration variables instead.\n-   **Tight Coupling**: Avoid creating tight coupling between modules. Use interfaces and dependency injection to promote loose coupling.\n\n### 2.4 State Management Best Practices\n\n-   **Stateless Components**: Design components to be stateless whenever possible. This improves testability and scalability.\n-   **Centralized State**: Manage application state in a centralized location (e.g., a state management class or library).\n-   **Immutable State**: Use immutable data structures to prevent unintended side effects and improve predictability.\n-   **Explicit State Transitions**: Define explicit state transitions to make state changes clear and traceable.\n\n### 2.5 Error Handling Patterns\n\n-   **Try-Except Blocks**: Use try-except blocks to handle exceptions and prevent application crashes.\n-   **Logging**: Log errors and exceptions to facilitate debugging and monitoring.\n-   **Custom Exceptions**: Define custom exceptions to represent specific error conditions.\n-   **Retry Logic**: Implement retry logic for transient errors (e.g., network timeouts).\n-   **Fallback Strategies**: Implement fallback strategies for critical operations to ensure application resilience.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Caching**: Implement caching mechanisms to store frequently accessed data and results.\n-   **Batch Processing**: Process data in batches to reduce overhead and improve throughput.\n-   **Asynchronous Operations**: Use asynchronous operations to perform non-blocking I/O and improve responsiveness.\n-   **Connection Pooling**: Use connection pooling to reuse database connections and reduce latency.\n-   **Data Compression**: Compress data to reduce storage space and network bandwidth.\n-   **Vectorstore Optimization**: Use efficient vectorstore implementations (e.g., FAISS, Annoy) and optimize indexing parameters for fast retrieval.\n\n### 3.2 Memory Management\n\n-   **Object Pooling**: Use object pooling to reuse objects and reduce memory allocation overhead.\n-   **Garbage Collection**: Monitor garbage collection performance and tune parameters to minimize pauses.\n-   **Memory Profiling**: Use memory profiling tools to identify memory leaks and optimize memory usage.\n-   **Lazy Loading**: Load data on demand to reduce initial memory footprint.\n-   **Chunking Large Documents**: Process large documents in smaller chunks to avoid memory overflow.\n\n### 3.3 Rendering Optimization (if applicable for UI components)\n\n-   **Virtualization**: Use virtualization techniques to render large lists efficiently.\n-   **Debouncing and Throttling**: Use debouncing and throttling to reduce the frequency of UI updates.\n-   **Memoization**: Use memoization to cache expensive rendering calculations.\n\n### 3.4 Bundle Size Optimization (if applicable for web apps)\n\n-   **Code Splitting**: Split code into smaller chunks to reduce initial load time.\n-   **Tree Shaking**: Use tree shaking to remove unused code from bundles.\n-   **Minification and Compression**: Minify and compress code to reduce bundle size.\n-   **Lazy Loading**: Load components and modules on demand.\n\n### 3.5 Lazy Loading Strategies\n\n-   **On-Demand Loading**: Load data or components only when they are needed.\n-   **Intersection Observer**: Use the Intersection Observer API to load components when they become visible in the viewport.\n-   **Dynamic Imports**: Use dynamic imports to load modules asynchronously.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **Prompt Injection**: Prevent prompt injection by validating and sanitizing user inputs. Use prompt templates and parameterized queries to avoid direct injection of malicious code.\n-   **Data Exfiltration**: Prevent data exfiltration by restricting access to sensitive data and implementing data masking techniques.\n-   **Code Execution**: Prevent arbitrary code execution by avoiding the use of `eval()` or similar functions. Use safe alternatives for dynamic code generation.\n-   **Denial of Service (DoS)**: Prevent DoS attacks by implementing rate limiting, input validation, and resource quotas.\n\n### 4.2 Input Validation\n\n-   **Whitelisting**: Validate inputs against a whitelist of allowed values or patterns.\n-   **Sanitization**: Sanitize inputs to remove or escape potentially harmful characters or code.\n-   **Type Checking**: Enforce type checking to ensure that inputs conform to expected data types.\n-   **Length Limits**: Enforce length limits to prevent buffer overflows or excessive memory usage.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **Authentication**: Use strong authentication mechanisms (e.g., multi-factor authentication) to verify user identities.\n-   **Authorization**: Implement role-based access control (RBAC) to restrict access to resources based on user roles.\n-   **Least Privilege**: Grant users the minimum necessary privileges to perform their tasks.\n-   **Secure Storage**: Store sensitive credentials (e.g., API keys) securely using encryption or secret management tools.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption**: Encrypt sensitive data at rest and in transit.\n-   **Data Masking**: Mask sensitive data to protect it from unauthorized access.\n-   **Data Anonymization**: Anonymize data to remove personally identifiable information (PII).\n-   **Access Logging**: Log all data access events to track and monitor usage.\n-   **Data Retention**: Define and enforce data retention policies to minimize the risk of data breaches.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS**: Use HTTPS to encrypt communication between clients and servers.\n-   **API Keys**: Protect API keys and other sensitive credentials.\n-   **Rate Limiting**: Implement rate limiting to prevent abuse and DoS attacks.\n-   **Input Validation**: Validate all API inputs to prevent injection attacks.\n-   **Output Encoding**: Encode API outputs to prevent cross-site scripting (XSS) attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test-Driven Development (TDD)**: Write unit tests before writing the code to be tested.\n-   **Mocking**: Use mocking to isolate components and test them independently.\n-   **Assertion**: Use assertions to verify that the code behaves as expected.\n-   **Coverage**: Aim for high code coverage to ensure that all code paths are tested.\n-   **Parameterized Tests**: Use parameterized tests to test multiple scenarios with different inputs.\n\n### 5.2 Integration Testing\n\n-   **Component Integration**: Test the integration between components to ensure that they work together correctly.\n-   **API Integration**: Test the integration with external APIs to ensure that data is exchanged correctly.\n-   **Database Integration**: Test the integration with databases to ensure that data is stored and retrieved correctly.\n-   **End-to-End Flows**: Test end-to-end flows to ensure that the application works as a whole.\n\n### 5.3 End-to-End Testing\n\n-   **UI Testing**: Test the user interface to ensure that it is functional and user-friendly.\n-   **Functional Testing**: Test the functional requirements of the application to ensure that it meets the specifications.\n-   **Performance Testing**: Test the performance of the application to ensure that it is responsive and scalable.\n-   **Security Testing**: Test the security of the application to identify and mitigate vulnerabilities.\n-   **Accessibility Testing**: Test the accessibility of the application to ensure that it is usable by people with disabilities.\n\n### 5.4 Test Organization\n\n-   **Test Suites**: Organize tests into test suites based on functionality or component.\n-   **Test Naming**: Use descriptive test names to make it clear what each test is testing.\n-   **Test Data**: Use realistic test data to simulate real-world scenarios.\n-   **Test Environment**: Set up a dedicated test environment to isolate tests from production data.\n\n### 5.5 Mocking and Stubbing\n\n-   **Mocking**: Use mocking to replace external dependencies with controlled substitutes.\n-   **Stubbing**: Use stubbing to provide predefined responses to external dependencies.\n-   **Dependency Injection**: Use dependency injection to make it easier to mock and stub dependencies.\n-   **Mocking Frameworks**: Use mocking frameworks (e.g., `unittest.mock`) to simplify the mocking process.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Hardcoding API Keys**: Storing API keys directly in the code instead of using environment variables.\n-   **Ignoring Rate Limits**: Failing to handle API rate limits, leading to errors and service disruptions.\n-   **Lack of Input Validation**: Not validating user inputs, making the application vulnerable to prompt injection attacks.\n-   **Insufficient Error Handling**: Not handling errors properly, leading to application crashes and data loss.\n-   **Over-Reliance on Default Settings**: Using default settings without considering their impact on performance and security.\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **Empty Inputs**: Handling empty inputs gracefully to prevent errors.\n-   **Long Inputs**: Handling long inputs efficiently to avoid performance issues.\n-   **Special Characters**: Handling special characters correctly to prevent injection attacks.\n-   **Unicode Support**: Ensuring proper Unicode support to handle different languages and character sets.\n-   **Network Errors**: Handling network errors gracefully to ensure application resilience.\n\n### 6.3 Version-Specific Issues\n\n-   **API Changes**: Being aware of API changes in different LangChain versions and updating code accordingly.\n-   **Compatibility**: Ensuring compatibility between different LangChain components and versions.\n-   **Deprecated Features**: Avoiding the use of deprecated features and migrating to their replacements.\n\n### 6.4 Compatibility Concerns\n\n-   **Python Versions**: Ensuring compatibility with different Python versions.\n-   **Operating Systems**: Ensuring compatibility with different operating systems (e.g., Windows, macOS, Linux).\n-   **Dependency Conflicts**: Resolving dependency conflicts between different libraries.\n\n### 6.5 Debugging Strategies\n\n-   **Logging**: Use logging to track the execution flow and identify errors.\n-   **Debugging Tools**: Use debugging tools (e.g., `pdb`) to step through code and inspect variables.\n-   **Print Statements**: Use print statements strategically to output debugging information.\n-   **Error Messages**: Pay attention to error messages and stack traces to understand the root cause of errors.\n-   **Remote Debugging**: Use remote debugging to debug applications running on remote servers.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **IDE**: Use a powerful IDE (e.g., VS Code, PyCharm) with support for Python and LangChain.\n-   **Linters**: Use linters (e.g., `flake8`, `pylint`) to enforce code style and identify potential errors.\n-   **Formatters**: Use formatters (e.g., `black`, `autopep8`) to automatically format code according to PEP 8 standards.\n-   **Debuggers**: Use debuggers (e.g., `pdb`, `ipdb`) to step through code and inspect variables.\n-   **Version Control**: Use Git for version control and collaboration.\n\n### 7.2 Build Configuration\n\n-   **`pyproject.toml`**: Use `pyproject.toml` file to manage project metadata, dependencies, and build configuration.\n-   **`requirements.txt`**: Generate and update the `requirements.txt` file to specify project dependencies.\n-   **Virtual Environments**: Use virtual environments (`venv`, `conda`) to isolate project dependencies.\n\n### 7.3 Linting and Formatting\n\n-   **Linting**: Configure linters to enforce code style and identify potential errors automatically.\n-   **Formatting**: Configure formatters to automatically format code according to PEP 8 standards.\n-   **Pre-commit Hooks**: Use pre-commit hooks to run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n-   **Containerization**: Use containerization (e.g., Docker) to package the application and its dependencies.\n-   **Orchestration**: Use orchestration tools (e.g., Kubernetes) to manage and scale the application.\n-   **Infrastructure as Code (IaC)**: Use IaC tools (e.g., Terraform, CloudFormation) to provision and manage infrastructure.\n-   **Monitoring**: Implement monitoring and logging to track application performance and identify issues.\n-   **Continuous Deployment**: Implement continuous deployment to automate the deployment process.\n\n### 7.5 CI/CD Integration\n\n-   **Continuous Integration (CI)**: Use CI tools (e.g., GitHub Actions, GitLab CI, Jenkins) to automatically build, test, and analyze code.\n-   **Continuous Delivery (CD)**: Use CD tools to automatically deploy code to staging or production environments.\n-   **Automated Testing**: Integrate automated testing into the CI/CD pipeline to ensure code quality.\n-   **Rollback Strategies**: Implement rollback strategies to quickly revert to previous versions in case of deployment failures.\n\nBy following these best practices, developers can build robust, scalable, and maintainable LangChain applications that meet the needs of their users and stakeholders.\n\nThis comprehensive guide is designed to help developers create high-quality LangChain applications by adhering to industry-standard coding practices and principles.\n\n\n@file best_practices_python.mdc\n@file best_practices_langchain_specific.mdc",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "langchain.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "langchain",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "developing",
      "applications",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "langchain",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-langgraph",
    "description": "This rule file provides comprehensive best practices for developing with LangGraph, covering code organization, performance, security, testing, and common pitfalls. It offers actionable guidance for developers to build robust and maintainable LangGraph applications.",
    "author": "sanjeed5",
    "tags": [
      "langgraph",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/langgraph.mdc",
    "content": "# LangGraph Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing with LangGraph. It aims to provide clear, actionable guidance for developers to build robust, maintainable, and scalable LangGraph applications. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, and common pitfalls.\n\n## Library Information:\n\n- Name: langgraph\n- Tags: ai, ml, llm, python, agent-framework, workflow\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n\nmy_langgraph_project/\n├── data/                      # Datasets, knowledge bases, or other data files.\n├── src/                       # Source code.\n│   ├── components/             # Reusable components (e.g., custom nodes, tools).\n│   │   ├── __init__.py\n│   │   ├── retrieval.py        # Retrieval-related nodes\n│   │   ├── tool_selector.py    # Logic for selecting which tool to use\n│   │   └── ...\n│   ├── graphs/                 # Graph definitions.\n│   │   ├── __init__.py\n│   │   ├── customer_support.py  # Example: Customer support graph.\n│   │   ├── rag_pipeline.py     # Example: RAG pipeline graph.\n│   │   └── ...\n│   ├── utils/                  # Utility functions and helpers.\n│   │   ├── __init__.py\n│   │   ├── config.py           # Configuration loading\n│   │   ├── logging.py          # Logging setup\n│   │   └── ...\n│   ├── schemas/                # Data schemas and type definitions.\n│   │   ├── __init__.py\n│   │   ├── agent_state.py      # Definition of agent state\n│   │   └── ...\n│   ├── main.py                 # Entry point of the application.\n│   └── ...\n├── tests/                     # Unit and integration tests.\n│   ├── __init__.py\n│   ├── components/             # Tests for custom components.\n│   ├── graphs/                 # Tests for graph definitions.\n│   ├── utils/                  # Tests for utility functions.\n│   └── ...\n├── .env                       # Environment variables.\n├── requirements.txt           # Project dependencies.\n├── pyproject.toml            # Project metadata and build settings\n└── README.md                  # Project documentation.\n\n\n### 1.2. File Naming Conventions\n\n-   Python files: `snake_case.py` (e.g., `customer_support.py`, `retrieval_node.py`).\n-   Class names: `PascalCase` (e.g., `CustomerSupportGraph`, `RetrievalNode`).\n-   Variables and functions: `snake_case` (e.g., `user_query`, `process_message`).\n-   Configuration files: `config.yaml` or `config.json`\n\n### 1.3. Module Organization Best Practices\n\n-   Group related functionalities into modules (e.g., `components`, `graphs`, `utils`).\n-   Use `__init__.py` files to make directories packages.\n-   Keep modules focused and avoid overly large files.\n-   Use relative imports within modules to avoid naming conflicts.\n\n### 1.4. Component Architecture Recommendations\n\n-   Design reusable components for common tasks (e.g., data retrieval, text summarization, tool selection).\n-   Create abstract base classes or interfaces for components to promote code reuse and modularity.\n-   Use dependency injection to configure components and their dependencies.\n-   Adhere to the Single Responsibility Principle (SRP) when designing components.\n\n### 1.5. Code Splitting Strategies\n\n-   Split large graph definitions into smaller, more manageable files.\n-   Use lazy loading for components that are not immediately needed.\n-   Consider using a module bundler (e.g., esbuild via a plugin) to optimize bundle size for deployment.\n-   Break the system down into microservices if warranted by scale and complexity of the overall system. Communicate between microservices using REST or message queues.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **State Management Pattern**: Encapsulate the agent state in a dedicated class or data structure to ensure consistency and maintainability. Use LangGraph's `StateGraph` to clearly define the state transitions.\n-   **Node Pattern**: Define reusable nodes for common tasks such as information retrieval, tool selection, and response generation.\n-   **Conditional Edge Pattern**: Use conditional edges to implement branching logic based on the agent state or external factors. This makes the graph more dynamic and responsive.\n-   **Retry Pattern:** Implement retry logic within nodes or edges to handle transient errors or API rate limits.  Use exponential backoff to avoid overwhelming failing services.\n-   **Orchestration Pattern**: Use LangGraph as the orchestrator for complex agentic workflows, delegating specific tasks to specialized components or services.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Information Retrieval**: Use LangChain's retrieval chain or custom nodes to fetch relevant information from external sources.\n-   **Tool Selection**: Implement a tool selection node that dynamically chooses the appropriate tool based on the user query and agent state.\n-   **Response Generation**: Use LangChain's LLMChain or custom nodes to generate responses based on the retrieved information and agent state.\n-   **Error Handling:** Implement robust error handling within nodes and edges to gracefully handle exceptions and prevent application crashes. Log all errors and implement monitoring to quickly detect and resolve issues.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Monolithic Graphs**: Avoid creating overly complex graphs with too many nodes and edges. Break them down into smaller, more manageable subgraphs.\n-   **Hardcoded Values**: Avoid hardcoding values directly into the graph definition. Use configuration files or environment variables to manage configurable parameters.\n-   **Ignoring Errors**: Always handle exceptions and log errors appropriately. Ignoring errors can lead to unexpected behavior and difficult-to-debug issues.\n-   **Over-Reliance on Global State**: Minimize the use of global state to avoid unintended side effects and make the application more testable.\n-   **Lack of Testing**: Thoroughly test all components and graph definitions to ensure they function correctly and handle edge cases.\n-   **Infinite Loops:** Ensure the conditional edges within the graph are well-defined to avoid infinite loops.\n\n### 2.4. State Management Best Practices\n\n-   Define a clear and concise agent state schema.\n-   Use immutable data structures for the agent state to avoid accidental modifications.\n-   Persist the agent state to a database or other storage medium to support long-running conversations or task executions.  Consider using vector databases for efficient retrieval.\n-   Implement versioning for the agent state schema to support schema migrations.\n-   Use LangGraph's checkpointing feature to save and restore the agent state.\n\n### 2.5. Error Handling Patterns\n\n-   Use try-except blocks to catch exceptions within nodes and edges.\n-   Log all errors and warnings with relevant context information.\n-   Implement retry logic for transient errors or API rate limits.\n-   Use fallback mechanisms to gracefully handle unrecoverable errors.\n-   Centralize error handling logic in a dedicated module or class.\n-   Implement circuit breaker pattern to prevent cascading failures.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Caching**: Implement caching for frequently accessed data or LLM responses.\n-   **Batching**: Batch multiple requests to external APIs to reduce latency.\n-   **Asynchronous Operations**: Use asynchronous operations to perform non-blocking I/O and improve responsiveness.\n-   **Parallel Processing**: Use multi-threading or multi-processing to parallelize computationally intensive tasks.\n-   **Graph Optimization**: Optimize the graph structure to minimize the number of nodes and edges.\n-   **Prompt Optimization**: Carefully design prompts to reduce the number of tokens and improve LLM performance.\n-   **Reduce LLM calls**: Cache LLM responses when possible. Fine-tune smaller models for specific tasks to reduce latency and cost.\n\n### 3.2. Memory Management Considerations\n\n-   Monitor memory usage to detect memory leaks or excessive memory consumption.\n-   Use garbage collection to reclaim unused memory.\n-   Avoid storing large objects in the agent state.\n-   Use streaming or lazy loading for large data sets.\n\n### 3.3. (Not applicable, as LangGraph doesn't directly handle rendering)\n\n### 3.4. Bundle Size Optimization\n\n-   Use a module bundler (e.g., esbuild) to optimize bundle size.\n-   Remove unused code and dependencies.\n-   Use code splitting to load only the necessary code for each route or component.\n-   Compress the bundle using gzip or Brotli.\n\n### 3.5. Lazy Loading Strategies\n\n-   Use lazy loading for components that are not immediately needed.\n-   Load large data sets or models on demand.\n-   Implement code splitting to load only the necessary code for each graph or component.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n-   **Prompt Injection**: Prevent prompt injection by carefully validating user inputs and sanitizing prompts.\n-   **Data Leaks**: Protect sensitive data by encrypting it at rest and in transit.\n-   **Unauthorized Access**: Implement strong authentication and authorization mechanisms to control access to the application and its data.\n-   **Denial of Service (DoS)**: Implement rate limiting and request filtering to prevent DoS attacks.\n-   **Code Injection**: Avoid executing arbitrary code based on user inputs to prevent code injection vulnerabilities.\n-   **API Key Exposure**: Store API keys securely using environment variables or a secrets management system and avoid committing them to version control.\n\n### 4.2. Input Validation\n\n-   Validate all user inputs to prevent prompt injection and other vulnerabilities.\n-   Use regular expressions or other validation techniques to ensure that inputs conform to the expected format.\n-   Sanitize inputs to remove potentially harmful characters or code.\n-   Enforce input length limits to prevent buffer overflows.\n\n### 4.3. Authentication and Authorization\n\n-   Use strong authentication mechanisms (e.g., multi-factor authentication) to verify user identities.\n-   Implement role-based access control (RBAC) to restrict access to sensitive data and functionality.\n-   Use secure session management to protect user sessions from hijacking.\n-   Store passwords securely using hashing and salting.\n\n### 4.4. Data Protection\n\n-   Encrypt sensitive data at rest and in transit.\n-   Use secure protocols (e.g., HTTPS) for all API communication.\n-   Implement data masking to protect sensitive data from unauthorized access.\n-   Regularly back up data to prevent data loss.\n-   Comply with relevant data privacy regulations (e.g., GDPR, CCPA).\n\n### 4.5. Secure API Communication\n\n-   Use HTTPS for all API communication.\n-   Implement API authentication and authorization.\n-   Validate API requests and responses.\n-   Use rate limiting to prevent API abuse.\n-   Monitor API traffic for suspicious activity.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   Write unit tests for all components and utility functions.\n-   Use mocking and stubbing to isolate components during testing.\n-   Test edge cases and error conditions.\n-   Aim for high test coverage.\n\n### 5.2. Integration Testing\n\n-   Write integration tests to verify the interactions between different components.\n-   Test the integration with external APIs and services.\n-   Use a test environment that closely resembles the production environment.\n\n### 5.3. End-to-End Testing\n\n-   Write end-to-end tests to verify the entire application flow.\n-   Use a testing framework such as Playwright or Selenium to automate end-to-end tests.\n-   Test the application from the user's perspective.\n\n### 5.4. Test Organization\n\n-   Organize tests into separate directories for unit tests, integration tests, and end-to-end tests.\n-   Use descriptive names for test files and test functions.\n-   Follow a consistent naming convention for test files and test functions.\n-   Use test suites to group related tests.\n\n### 5.5. Mocking and Stubbing\n\n-   Use mocking to replace external dependencies with mock objects.\n-   Use stubbing to replace complex components with simplified versions.\n-   Use a mocking framework such as pytest-mock to simplify mocking and stubbing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Incorrect State Management**: Failing to properly manage the agent state can lead to inconsistent behavior and incorrect results.\n-   **Ignoring Edge Cases**: Neglecting to handle edge cases can cause unexpected errors and application crashes.\n-   **Over-Engineering**: Over-complicating the graph definition can make it difficult to understand and maintain.\n-   **Insufficient Testing**: Lack of thorough testing can lead to undetected bugs and application failures.\n-   **Not Handling Asynchronous Operations Correctly:** LangGraph, and LLMs generally, use async operations, and failing to await these operations will cause unpredictable results.\n\n### 6.2. Edge Cases\n\n-   **Empty User Inputs**: Handle cases where the user provides empty or invalid inputs.\n-   **API Rate Limits**: Implement retry logic and rate limiting to handle API rate limits.\n-   **Unexpected API Responses**: Handle cases where external APIs return unexpected responses.\n-   **Large Data Sets**: Use streaming or lazy loading to handle large data sets.\n\n### 6.3. Version-Specific Issues\n\n-   Be aware of compatibility issues between different versions of LangGraph and LangChain.\n-   Consult the documentation and release notes for any version-specific issues.\n-   Pin dependencies to specific versions to avoid unexpected behavior.\n\n### 6.4. Compatibility Concerns\n\n-   Ensure compatibility between LangGraph and other technologies used in the application.\n-   Test the integration with external APIs and services.\n-   Use a consistent set of libraries and dependencies.\n\n### 6.5. Debugging Strategies\n\n-   Use logging to track the execution flow and identify errors.\n-   Use a debugger to step through the code and inspect variables.\n-   Use a testing framework to write unit tests and integration tests.\n-   Use monitoring tools to track performance and identify bottlenecks.\n-   Visualize the graph structure to understand the flow of execution.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n-   **IDE**: PyCharm, Visual Studio Code with Python extension.\n-   **Virtual Environment Manager**: venv, conda.\n-   **Testing Framework**: pytest.\n-   **Mocking Framework**: pytest-mock.\n-   **Linting and Formatting**: pylint, black.\n-   **Module Bundler**: esbuild via a plugin.\n-   **CI/CD**: GitHub Actions, GitLab CI.\n-   **Secrets Management**: HashiCorp Vault, AWS Secrets Manager, Azure Key Vault.\n-   **Monitoring**: LangSmith, Prometheus, Grafana.\n\n### 7.2. Build Configuration\n\n-   Use a build system such as `poetry` or `pip` to manage dependencies.\n-   Use a configuration file such as `pyproject.toml` or `setup.py` to define project metadata and build settings.\n\n### 7.3. Linting and Formatting\n\n-   Use a linter such as `pylint` or `flake8` to enforce code style and identify potential errors.\n-   Use a code formatter such as `black` or `autopep8` to automatically format the code.\n-   Configure the linter and formatter to use a consistent set of rules and settings.\n\n### 7.4. Deployment\n\n-   Containerize the application using Docker.\n-   Deploy the application to a cloud platform such as AWS, Azure, or Google Cloud.\n-   Use a deployment tool such as Terraform or Ansible to automate the deployment process.\n-   Implement a blue-green deployment strategy to minimize downtime.\n\n### 7.5. CI/CD\n\n-   Use a CI/CD tool such as GitHub Actions or GitLab CI to automate the testing, building, and deployment processes.\n-   Configure the CI/CD pipeline to run tests, linters, and formatters.\n-   Use a code review process to ensure code quality and security.\n\n## Conclusion\n\nBy following these best practices and coding standards, developers can build robust, maintainable, and scalable LangGraph applications. This will also help with collaboration amongst team members working in the same codebase.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "langgraph.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "langgraph",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "langgraph",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-laravel",
    "description": "This rule outlines comprehensive best practices for Laravel development, covering coding standards, security, performance, and testing to ensure maintainable, efficient, and secure applications. It provides guidelines for code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "laravel",
      "php",
      "backend",
      "web",
      "cursor",
      "cursor-rule",
      "mdc",
      "mvc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/laravel.mdc",
    "content": "- Adhere to PSR coding standards (PSR-1, PSR-2, PSR-12).\n- Use meaningful and descriptive variable, function, and class names.\n- Organize routes effectively, leveraging resource controllers and route groups.\n- Use Eloquent ORM for database interactions; avoid raw SQL queries where possible (unless necessary for performance).\n- Implement caching strategies using Laravel's caching system for frequently accessed data.\n- Maintain a clear and consistent project structure following Laravel's conventions (app, config, database, public, resources, routes, storage).\n- Ensure code simplicity and readability to enhance maintainability.  Follow the single responsibility principle.\n- Keep Laravel and its packages up-to-date to mitigate security vulnerabilities and leverage new features.\n\n### 1. Code Organization and Structure:\n\n   - **Directory Structure Best Practices:**\n     - Follow Laravel's default directory structure: `app` (core application logic), `config` (configuration files), `database` (migrations and seeds), `public` (static assets), `resources` (views and assets), `routes` (route definitions), `storage` (file storage).\n     - Organize `app` directory using subdirectories like `Models`, `Controllers`, `Services`, `Repositories`, `Exceptions`, `Policies`, `Providers`, and `Http/Middleware`.\n     - Consider using modules for larger applications to encapsulate features.\n\n   - **File Naming Conventions:**\n     - Use PascalCase for class names (e.g., `UserController`).\n     - Use camelCase for variable and function names (e.g., `$userName`, `getUserName()`).\n     - Use snake_case for database table names and column names (e.g., `users`, `user_id`).\n     - Use kebab-case for route names (e.g., `user.profile`).\n     - Use descriptive names that clearly indicate the purpose of the file or class.\n\n   - **Module Organization:**\n     - For larger applications, use packages or modules to organize code into reusable components.\n     - Implement module-specific service providers, routes, and configurations.\n     - Isolate module dependencies to prevent conflicts.\n\n   - **Component Architecture:**\n     - Use Blade components for reusable UI elements.\n     - Create custom components for complex logic and rendering.\n     - Pass data to components using attributes and slots.\n     - Encapsulate component logic in dedicated classes.\n\n   - **Code Splitting Strategies:**\n     - Use lazy loading for non-critical features.\n     - Split large controllers into smaller, more manageable classes.\n     - Extract complex logic into service classes or repositories.\n\n### 2. Common Patterns and Anti-patterns:\n\n   - **Design Patterns Specific to Laravel:**\n     - **Repository Pattern:** Abstract data access logic from controllers.\n     - **Service Pattern:** Encapsulate business logic into reusable classes.\n     - **Observer Pattern:** Implement event-driven behavior for model changes.\n     - **Factory Pattern:** Create test data and seed databases.\n     - **Strategy Pattern:**  Define a family of algorithms and make them interchangeable.\n\n   - **Recommended Approaches for Common Tasks:**\n     - Use Eloquent ORM for database interactions, including relationships and aggregations.\n     - Use Laravel's validation system for request data validation.\n     - Use middleware for authentication, authorization, and request modification.\n     - Use queues for background processing and asynchronous tasks.\n     - Use events and listeners for decoupling components.\n\n   - **Anti-patterns and Code Smells to Avoid:**\n     - **God Classes:** Avoid creating large classes with too many responsibilities.\n     - **Spaghetti Code:** Avoid complex and unstructured code that is difficult to understand and maintain.\n     - **Copy-Paste Programming:** Avoid duplicating code; instead, create reusable components or functions.\n     - **Ignoring Exceptions:** Always handle exceptions properly to prevent unexpected behavior.\n     - **Over-Engineering:** Don't overcomplicate solutions with unnecessary complexity.\n     - **Mass Assignment Vulnerability:** Use guarded or fillable attributes to protect against mass assignment vulnerabilities.\n\n   - **State Management Best Practices:**\n     - Use sessions for storing user-specific data.\n     - Use cookies for storing client-side data.\n     - Use the cache for storing frequently accessed data.\n     - Use databases for persistent data storage.\n     - Consider using Laravel's broadcasting feature for real-time updates.\n\n   - **Error Handling Patterns:**\n     - Use try-catch blocks to handle exceptions gracefully.\n     - Use Laravel's exception handler to log and report errors.\n     - Implement custom exception classes for specific error scenarios.\n     - Provide informative error messages to users.\n\n### 3. Performance Considerations:\n\n   - **Optimization Techniques:**\n     - Use caching to reduce database queries and improve response times.\n     - Use eager loading to reduce N+1 query problems.\n     - Use queues for background processing.\n     - Optimize database queries with indexes and query optimization techniques.\n     - Minimize the use of loops and conditional statements in performance-critical code.\n\n   - **Memory Management:**\n     - Avoid storing large amounts of data in memory.\n     - Use garbage collection to free up memory.\n     - Use streams for processing large files.\n\n   - **Rendering Optimization:**\n     - Use Blade's caching features to cache rendered views.\n     - Use CSS and JavaScript minification to reduce file sizes.\n     - Use image optimization techniques to reduce image sizes.\n\n   - **Bundle Size Optimization:**\n     - Use Laravel Mix to bundle and minify assets.\n     - Remove unused CSS and JavaScript code.\n     - Use code splitting to load only the necessary code for each page.\n\n   - **Lazy Loading Strategies:**\n     - Use lazy loading for images and other non-critical assets.\n     - Use route model binding with eager loading to reduce database queries.\n\n### 4. Security Best Practices:\n\n   - **Common Vulnerabilities and How to Prevent Them:**\n     - **SQL Injection:** Use Eloquent ORM and prepared statements to prevent SQL injection attacks.\n     - **Cross-Site Scripting (XSS):** Sanitize user input and escape output to prevent XSS attacks.\n     - **Cross-Site Request Forgery (CSRF):** Use CSRF protection tokens to prevent CSRF attacks.\n     - **Mass Assignment:** Use guarded or fillable attributes to protect against mass assignment vulnerabilities.\n     - **Authentication and Authorization:** Use Laravel's built-in authentication and authorization features.\n\n   - **Input Validation:**\n     - Use Laravel's validation system to validate all user input.\n     - Sanitize user input to remove potentially harmful characters.\n     - Validate file uploads to prevent malicious files from being uploaded.\n\n   - **Authentication and Authorization Patterns:**\n     - Use Laravel's built-in authentication system for user authentication.\n     - Use policies to define authorization rules.\n     - Use gates to authorize access to specific resources.\n     - Implement two-factor authentication for enhanced security.\n\n   - **Data Protection Strategies:**\n     - Encrypt sensitive data using Laravel's encryption features.\n     - Store passwords using bcrypt hashing.\n     - Protect API keys and other sensitive configuration data.\n\n   - **Secure API Communication:**\n     - Use HTTPS for all API communication.\n     - Use API tokens for authentication.\n     - Implement rate limiting to prevent abuse.\n     - Validate API requests and responses.\n\n### 5. Testing Approaches:\n\n   - **Unit Testing Strategies:**\n     - Test individual units of code in isolation.\n     - Use mock objects to isolate dependencies.\n     - Write tests for all critical code paths.\n\n   - **Integration Testing:**\n     - Test the interaction between different components of the application.\n     - Test database interactions and external API calls.\n\n   - **End-to-End Testing:**\n     - Test the entire application from end to end.\n     - Use browser automation tools to simulate user interactions.\n\n   - **Test Organization:**\n     - Organize tests into logical groups.\n     - Use descriptive test names.\n     - Follow the arrange-act-assert pattern.\n\n   - **Mocking and Stubbing:**\n     - Use mock objects to isolate dependencies.\n     - Use stubbing to replace complex dependencies with simpler implementations.\n\n### 6. Common Pitfalls and Gotchas:\n\n   - **Frequent Mistakes Developers Make:**\n     - Not using dependency injection properly.\n     - Writing complex logic in views.\n     - Not using caching effectively.\n     - Ignoring security vulnerabilities.\n     - Not writing tests.\n\n   - **Edge Cases to Be Aware Of:**\n     - Handling large file uploads.\n     - Dealing with concurrent requests.\n     - Handling database connection errors.\n     - Handling time zone conversions.\n\n   - **Version-Specific Issues:**\n     - Be aware of breaking changes between Laravel versions.\n     - Consult the Laravel upgrade guide when upgrading to a new version.\n\n   - **Compatibility Concerns:**\n     - Ensure compatibility with different PHP versions and extensions.\n     - Ensure compatibility with different database systems.\n\n   - **Debugging Strategies:**\n     - Use Laravel's debugging tools (e.g., debugbar, telescope).\n     - Use logging to track application behavior.\n     - Use Xdebug for step-by-step debugging.\n\n### 7. Tooling and Environment:\n\n   - **Recommended Development Tools:**\n     - PHPStorm or VS Code with PHP extensions.\n     - Composer for dependency management.\n     - MySQL or PostgreSQL for database management.\n     - Docker for containerization.\n\n   - **Build Configuration:**\n     - Use Laravel Mix to compile assets.\n     - Use environment variables to configure the application.\n     - Use a build script to automate the build process.\n\n   - **Linting and Formatting:**\n     - Use PHP CS Fixer to enforce coding standards.\n     - Use ESLint and Prettier for JavaScript and CSS linting and formatting.\n\n   - **Deployment Best Practices:**\n     - Use a deployment tool like Envoyer or Deployer.\n     - Use zero-downtime deployment strategies.\n     - Use a CDN for static assets.\n\n   - **CI/CD Integration:**\n     - Use a CI/CD pipeline to automate testing and deployment.\n     - Use tools like Jenkins, GitLab CI, or GitHub Actions.",
    "metadata": {
      "globs": "*.php",
      "format": "mdc",
      "originalFile": "laravel.mdc"
    },
    "subcategory": "php",
    "keywords": [
      "cursor",
      "laravel",
      "this",
      "rule",
      "outlines",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "coding",
      "php",
      "backend",
      "web",
      "cursor-rule",
      "mdc",
      "mvc",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "laravel",
        "php",
        "backend",
        "web",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-lightgbm",
    "description": "This rule file provides comprehensive best practices for LightGBM, covering code organization, performance, security, testing, and common pitfalls to avoid. Adhering to these guidelines will improve the efficiency, reliability, and maintainability of your LightGBM projects.",
    "author": "sanjeed5",
    "tags": [
      "lightgbm",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/lightgbm.mdc",
    "content": "# LightGBM Best Practices\n\nThis document outlines best practices for developing and maintaining LightGBM-based machine learning projects. It covers various aspects, from code organization to performance optimization and security considerations.\n\n## Library Information:\n\n- Name: LightGBM\n- Tags: ai, ml, machine-learning, python, gradient-boosting\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n\nproject_root/\n├── data/\n│   ├── raw/\n│   ├── processed/\n│   └── external/\n├── notebooks/\n│   ├── exploratory_data_analysis.ipynb\n│   └── model_evaluation.ipynb\n├── src/\n│   ├── __init__.py\n│   ├── data/\n│   │   ├── __init__.py\n│   │   ├── dataset.py  # Data loading and preprocessing logic\n│   │   └── features.py # Feature engineering functions\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── train.py    # Model training script\n│   │   ├── predict.py  # Prediction script\n│   │   └── model.py    # Model definition (if applicable)\n│   ├── utils/\n│   │   ├── __init__.py\n│   │   ├── logger.py   # Logging utilities\n│   │   └── helper.py   # General helper functions\n│   └── visualization/\n│       ├── __init__.py\n│       └── plots.py  # Custom plotting functions\n├── tests/\n│   ├── __init__.py\n│   ├── data/\n│   ├── models/\n│   └── utils/\n├── configs/\n│   └── config.yaml\n├── reports/\n│   └── figures/\n├── .gitignore\n├── README.md\n├── pyproject.toml\n└── requirements.txt\n\n\n*   **data/**: Contains raw, processed, and external data.\n*   **notebooks/**: Jupyter notebooks for exploration and experimentation.\n*   **src/**: Source code for data loading, feature engineering, model training, and prediction.\n*   **tests/**: Unit and integration tests.\n*   **configs/**: Configuration files (e.g., YAML).\n*   **reports/**: Generated reports and figures.\n\n### 1.2 File Naming Conventions\n\n*   Python files: `lowercase_with_underscores.py`\n*   Jupyter notebooks: `descriptive_name.ipynb`\n*   Configuration files: `config.yaml` or `config.json`\n*   Data files: `data_description.csv` or `data_description.parquet`\n\n### 1.3 Module Organization\n\n*   Group related functions and classes into modules.\n*   Use clear and descriptive module names.\n*   Minimize dependencies between modules.\n\n### 1.4 Component Architecture\n\n*   **Data Layer:** Handles data loading, preprocessing, and feature engineering.\n*   **Model Layer:** Encapsulates model training, evaluation, and prediction.\n*   **Service Layer:** Exposes model functionality through an API or interface.\n*   **Configuration Layer:** Manages configuration parameters and settings.\n\n### 1.5 Code Splitting\n\n*   Break down complex tasks into smaller, more manageable functions.\n*   Use classes to encapsulate related data and behavior.\n*   Avoid long functions and deeply nested code blocks.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Factory Pattern:** To create different LightGBM models based on configuration.\n*   **Strategy Pattern:** To implement different feature engineering techniques.\n*   **Observer Pattern:** To monitor training progress and log metrics.\n\n### 2.2 Recommended Approaches\n\n*   **Data Preparation:** Utilize LightGBM's native support for missing values and categorical features. Convert categorical features to the `categorical` data type in pandas before splitting the data.\n*   **Hyperparameter Tuning:** Use techniques like grid search, random search, or Bayesian optimization (e.g., Optuna) to optimize hyperparameters. Implement early stopping to prevent overfitting.\n*   **Model Monitoring:** Track training and validation performance metrics to detect overfitting and adjust model complexity.\n*   **Feature Selection:** Use feature importance to identify and select relevant features.\n*   **Cross-Validation:** Use k-fold cross-validation for robust model evaluation.  The `cv` function provides mean metrics and standard deviations across folds.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Hardcoding hyperparameters:**  Avoid hardcoding; use configuration files.\n*   **Ignoring missing values:** LightGBM handles missing values, so explicitly using them is fine, but ensure you understand their impact.\n*   **Overfitting:**  Monitor training vs. validation performance and use regularization.\n*   **Large, monolithic functions:**  Break down into smaller, testable units.\n*   **Ignoring feature importances:** Use feature importance to help drive feature selection and understand your model.\n\n### 2.4 State Management\n\n*   Use configuration files to manage model parameters and training settings.\n*   Store model artifacts (e.g., trained models, scalers) in a designated directory.\n*   Use version control to track changes to code and data.\n\n### 2.5 Error Handling\n\n*   Use `try-except` blocks to handle potential exceptions.\n*   Log errors and warnings using a logging library (e.g., `logging`).\n*   Provide informative error messages to the user.\n*   Implement retry mechanisms for transient errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Hyperparameter Tuning:** Optimize hyperparameters such as learning rate, number of leaves, and tree depth.\n*   **Early Stopping:** Implement early stopping to prevent overfitting and reduce training time.\n*   **Parallel Training:** Enable parallel training for faster computations (data/feature/voting parallel).\n*   **GPU Acceleration:**  Enable GPU usage for accelerated training when possible.\n*   **Feature Selection:** Remove irrelevant or redundant features to improve performance.\n*   **Reduce data size:** Consider downcasting numerical types (e.g., float64 to float32) if precision loss is acceptable.\n*   **Histogram-based algorithms:**  LightGBM uses histogram-based algorithms for faster training on large datasets. \n\n### 3.2 Memory Management\n\n*   **`max_bin` Parameter:** Reduce `max_bin` to decrease memory usage (may impact accuracy).\n*   **`save_binary` Parameter:** Use `save_binary` to save data in a binary format for faster loading and reduced memory usage.\n*   **Data Types:** Use appropriate data types to minimize memory footprint (e.g., `int32` instead of `int64`).\n*   **Garbage Collection:**  Explicitly call `gc.collect()` to free up unused memory.\n\n### 3.3 Bundle Size Optimization (If applicable for deployment)\n\n*   Remove unnecessary dependencies.\n*   Use code minification and compression techniques.\n*   Optimize image assets.\n\n### 3.4 Lazy Loading\n\n*   Load data and models only when needed.\n*   Use generators to process large datasets in chunks.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Untrusted Input:** Vulnerable to injection attacks if model is used directly on user-provided data without sanitization.\n*   **Model Poisoning:** If training data is sourced from untrusted sources, the model can be poisoned.\n*   **Denial of Service (DoS):**  Malicious input crafted to consume excessive resources.\n\n### 4.2 Input Validation\n\n*   Validate input data to ensure it conforms to expected types and ranges.\n*   Sanitize input data to prevent injection attacks.\n*   Use a schema validation library (e.g., `cerberus`, `jsonschema`).\n\n### 4.3 Authentication and Authorization\n\n*   Implement authentication to verify the identity of users.\n*   Use authorization to control access to resources and functionality.\n*   Use secure protocols (e.g., HTTPS) for API communication.\n\n### 4.4 Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use data masking to protect sensitive information.\n*   Implement access controls to restrict access to data.\n\n### 4.5 Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Implement input validation and sanitization.\n*   Use rate limiting to prevent abuse.\n*   Monitor API traffic for suspicious activity.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   Test individual functions and classes in isolation.\n*   Use mocking and stubbing to isolate dependencies.\n*   Write tests for different input scenarios and edge cases.\n*   Verify expected outputs and side effects.\n\n### 5.2 Integration Testing\n\n*   Test interactions between different components.\n*   Verify data flow and consistency.\n*   Test API endpoints and data pipelines.\n\n### 5.3 End-to-End Testing\n\n*   Test the entire application flow from start to finish.\n*   Simulate real-world user scenarios.\n*   Verify that the application meets all requirements.\n\n### 5.4 Test Organization\n\n*   Organize tests into separate directories based on component.\n*   Use clear and descriptive test names.\n*   Follow a consistent testing style.\n\n### 5.5 Mocking and Stubbing\n\n*   Use mocking to replace external dependencies with controlled substitutes.\n*   Use stubbing to provide predefined responses for function calls.\n*   Use a mocking library (e.g., `unittest.mock`, `pytest-mock`).\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Data Leakage:** Accidentally using future information during training.\n*   **Incorrect Feature Scaling:** Using inappropriate scaling methods.\n*   **Ignoring Categorical Features:**  Not treating categorical features correctly.\n*   **Not tuning for imbalanced classes:** Ignoring the need to adjust for imbalanced datasets.\n*   **Improper Cross-Validation:** Setting up cross-validation incorrectly.\n\n### 6.2 Edge Cases\n\n*   **Rare Categories:** Handling infrequent categorical values.\n*   **Missing Data Patterns:** Understanding the nature and impact of missing data.\n*   **Outliers:** Detecting and handling extreme values in your dataset.\n\n### 6.3 Version-Specific Issues\n\n*   Refer to the LightGBM release notes for known issues and bug fixes.\n*   Stay up-to-date with the latest version of LightGBM.\n\n### 6.4 Compatibility Concerns\n\n*   Ensure compatibility between LightGBM and other libraries (e.g., scikit-learn, pandas).\n*   Address potential conflicts between different versions of dependencies.\n\n### 6.5 Debugging Strategies\n\n*   Use a debugger (e.g., `pdb`) to step through code and inspect variables.\n*   Log intermediate values and execution paths.\n*   Use assertions to verify expected behavior.\n*   Simplify the problem by isolating components.\n*   Consult the LightGBM documentation and community forums.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n*   **Python:** The primary language for LightGBM development.\n*   **pandas:** For data manipulation and analysis.\n*   **NumPy:** For numerical computations.\n*   **scikit-learn:** For machine learning algorithms and tools.\n*   **Jupyter Notebook:** For interactive development and experimentation.\n*   **IDE:** VSCode, PyCharm, or similar.\n*   **Optuna/Hyperopt:** For hyperparameter optimization.\n\n### 7.2 Build Configuration\n\n*   Use a build system (e.g., `setuptools`, `poetry`) to manage dependencies and build packages.\n*   Create a `requirements.txt` file to list project dependencies.\n*   Use a virtual environment to isolate project dependencies.\n\n### 7.3 Linting and Formatting\n\n*   Use a linter (e.g., `flake8`, `pylint`) to enforce code style and identify potential errors.\n*   Use a formatter (e.g., `black`, `autopep8`) to automatically format code.\n*   Configure the IDE to automatically run linters and formatters.\n\n### 7.4 Deployment Best Practices\n\n*   Containerize the application using Docker.\n*   Deploy the application to a cloud platform (e.g., AWS, Azure, GCP).\n*   Use a deployment tool (e.g., Kubernetes, Docker Compose).\n*   Monitor the application for performance and errors.\n\n### 7.5 CI/CD Integration\n\n*   Use a CI/CD pipeline (e.g., Jenkins, GitLab CI, GitHub Actions) to automate testing and deployment.\n*   Run unit and integration tests in the CI/CD pipeline.\n*   Deploy code to staging and production environments.\n\nBy adhering to these best practices, you can develop robust, efficient, and maintainable LightGBM-based machine learning projects.",
    "metadata": {
      "globs": "*.py,*.ipynb",
      "format": "mdc",
      "originalFile": "lightgbm.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "lightgbm",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "lightgbm",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-llama-index",
    "description": "This rule outlines best practices and coding standards for developing with LlamaIndex, covering code organization, performance, security, testing, and common pitfalls. It aims to ensure maintainable, efficient, and secure LlamaIndex applications.",
    "author": "sanjeed5",
    "tags": [
      "llama-index",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/llama-index.mdc",
    "content": "# LlamaIndex Best Practices and Coding Standards\n\nThis document provides comprehensive guidance on developing high-quality applications using LlamaIndex. It covers various aspects of development, including code organization, performance optimization, security considerations, and testing strategies.\n\n## 1. Code Organization and Structure\n\n*   **Directory Structure Best Practices:**\n    *   `data/`: Store data sources (e.g., documents, PDFs) used by LlamaIndex.\n    *   `indices/`: Contains index definitions and configurations.\n    *   `queries/`: Defines query engines and query logic.\n    *   `models/`: Place custom LLM or embedding model configurations.\n    *   `utils/`: Utility functions and helper classes.\n    *   `tests/`: Unit, integration, and end-to-end tests.\n    *   `scripts/`: Scripts for data ingestion, index building, or other automation tasks.\n*   **File Naming Conventions:**\n    *   Data loaders: `*_loader.py` (e.g., `pdf_loader.py`)\n    *   Index definitions: `*_index.py` (e.g., `vector_index.py`)\n    *   Query engines: `*_query_engine.py` (e.g., `knowledge_graph_query_engine.py`)\n    *   Models: `*_model.py` (e.g., `custom_llm_model.py`)\n    *   Utilities: `*_utils.py` (e.g., `text_processing_utils.py`)\n    *   Tests: `test_*.py` (e.g., `test_vector_index.py`)\n*   **Module Organization:**\n    *   Group related functionalities into modules (e.g., `data_ingestion`, `indexing`, `querying`).\n    *   Use clear and descriptive module names.\n    *   Minimize dependencies between modules to improve maintainability.\n*   **Component Architecture:**\n    *   **Data Connectors:** Abstract data loading logic into reusable connectors.\n    *   **Index Structures:** Use appropriate index structures (e.g., `VectorStoreIndex`, `KnowledgeGraphIndex`) based on data characteristics and query requirements.\n    *   **Query Engines:** Decouple query logic from index structures.\n    *   **LLM Abstraction:** Abstract LLM calls using interfaces for flexibility and testability.\n*   **Code Splitting:**\n    *   Break down large functions into smaller, well-defined functions.\n    *   Use classes to encapsulate related data and behavior.\n    *   Extract reusable code into separate modules or packages.\n\n## 2. Common Patterns and Anti-patterns\n\n*   **Design Patterns:**\n    *   **Factory Pattern:** For creating different types of indexes or query engines.\n    *   **Strategy Pattern:** For choosing different retrieval or ranking algorithms.\n    *   **Decorator Pattern:** For adding pre-processing or post-processing steps to queries.\n*   **Recommended Approaches:**\n    *   **Data Ingestion:** Use `SimpleDirectoryReader` or custom data connectors to load data.\n    *   **Indexing:** Choose the appropriate index type based on your data and query needs. Consider `VectorStoreIndex` for semantic search, `KnowledgeGraphIndex` for knowledge graph-based queries, and `ComposableGraph` for combining multiple indexes.\n    *   **Querying:** Use `as_query_engine()` to create a query engine from an index. Customize the query engine with different retrieval and response synthesis modules.\n    *   **Evaluation:** Use LlamaIndex's evaluation modules to measure the performance of your LLM application (e.g., retrieval and LLM response quality).\n*   **Anti-patterns and Code Smells:**\n    *   **Tight Coupling:** Avoid tight coupling between components. Use interfaces and dependency injection to promote loose coupling.\n    *   **God Classes:** Avoid creating large classes that do too much. Break them down into smaller, more focused classes.\n    *   **Code Duplication:** Avoid duplicating code. Extract common code into reusable functions or classes.\n    *   **Ignoring Errors:** Don't ignore errors. Handle them gracefully or raise exceptions.\n*   **State Management:**\n    *   Use LlamaIndex's `StorageContext` to persist indexes to disk.\n    *   Consider using a database to store application state.\n*   **Error Handling:**\n    *   Use `try-except` blocks to handle exceptions.\n    *   Log errors for debugging purposes.\n    *   Provide informative error messages to the user.\n\n## 3. Performance Considerations\n\n*   **Optimization Techniques:**\n    *   **Indexing:** Optimize index construction by using appropriate chunk sizes and overlap.\n    *   **Querying:** Optimize query performance by using appropriate retrieval and ranking algorithms.\n    *   **Caching:** Cache query results to improve performance.\n    *   **Parallelization:** Parallelize data loading and indexing tasks.\n*   **Memory Management:**\n    *   Use generators to process large datasets in chunks.\n    *   Release memory when it is no longer needed.\n*   **Bundle Size Optimization:** (Not directly applicable to LlamaIndex as it is a backend library, but relevant if building a web UI on top)\n    *   Remove unused code.\n    *   Use code splitting to load only the code that is needed.\n*   **Lazy Loading:**\n    *   Load data and models only when they are needed.\n    *   Use lazy initialization to defer the creation of objects until they are first used.\n\n## 4. Security Best Practices\n\n*   **Common Vulnerabilities:**\n    *   **Prompt Injection:** Prevent prompt injection attacks by carefully sanitizing user input and using appropriate prompt engineering techniques.\n    *   **Data Leaks:** Protect sensitive data by using appropriate access control and encryption.\n    *   **API Key Exposure:** Avoid exposing API keys in your code. Use environment variables or a secure configuration management system to store API keys.\n*   **Input Validation:**\n    *   Validate all user input to prevent injection attacks.\n    *   Sanitize input to remove potentially harmful characters.\n*   **Authentication and Authorization:**\n    *   Implement authentication and authorization to control access to your application.\n    *   Use strong passwords and multi-factor authentication.\n*   **Data Protection:**\n    *   Encrypt sensitive data at rest and in transit.\n    *   Use appropriate access control to protect data.\n*   **Secure API Communication:**\n    *   Use HTTPS to encrypt communication between your application and the LlamaIndex API.\n    *   Validate the server certificate to prevent man-in-the-middle attacks.\n\n## 5. Testing Approaches\n\n*   **Unit Testing:**\n    *   Write unit tests for all core components, including data connectors, index structures, and query engines.\n    *   Use mocking and stubbing to isolate components during testing.\n*   **Integration Testing:**\n    *   Write integration tests to verify that different components work together correctly.\n    *   Test the integration between LlamaIndex and other libraries or frameworks.\n*   **End-to-end Testing:**\n    *   Write end-to-end tests to verify that the entire application works as expected.\n    *   Test the application with real data and user scenarios.\n*   **Test Organization:**\n    *   Organize tests into separate directories for unit, integration, and end-to-end tests.\n    *   Use clear and descriptive test names.\n*   **Mocking and Stubbing:**\n    *   Use mocking and stubbing to isolate components during testing.\n    *   Use a mocking framework such as `unittest.mock` or `pytest-mock`.\n\n## 6. Common Pitfalls and Gotchas\n\n*   **Frequent Mistakes:**\n    *   Using the wrong index type for the data.\n    *   Not optimizing query performance.\n    *   Not handling errors gracefully.\n    *   Exposing API keys.\n    *   Not validating user input.\n*   **Edge Cases:**\n    *   Handling large documents.\n    *   Handling noisy or incomplete data.\n    *   Handling complex queries.\n*   **Version-Specific Issues:**\n    *   Be aware of breaking changes in LlamaIndex releases.\n    *   Refer to the LlamaIndex documentation for version-specific information.\n*   **Compatibility Concerns:**\n    *   Ensure that LlamaIndex is compatible with the other libraries and frameworks that you are using.\n    *   Test your application thoroughly to identify any compatibility issues.\n*   **Debugging Strategies:**\n    *   Use logging to track the execution of your application.\n    *   Use a debugger to step through your code and inspect variables.\n    *   Use LlamaIndex's debugging tools to diagnose issues.\n\n## 7. Tooling and Environment\n\n*   **Recommended Development Tools:**\n    *   **IDE:** VS Code, PyCharm\n    *   **Package Manager:** Poetry, pip\n    *   **Testing Framework:** pytest\n    *   **Linting and Formatting:** flake8, black\n*   **Build Configuration:**\n    *   Use a build system such as `poetry` to manage dependencies.\n    *   Create a `requirements.txt` file to list dependencies.\n*   **Linting and Formatting:**\n    *   Use a linter such as `flake8` to enforce code style.\n    *   Use a formatter such as `black` to automatically format code.\n*   **Deployment Best Practices:**\n    *   Use a containerization technology such as Docker to package your application.\n    *   Use a cloud platform such as AWS, Azure, or GCP to deploy your application.\n*   **CI/CD Integration:**\n    *   Use a CI/CD system such as GitHub Actions or Jenkins to automate the build, test, and deployment process.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "llama-index.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "llama",
      "index",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "llamaindex",
      "llama-index",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "llama-index",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-llamaindex-js",
    "description": "This rule provides comprehensive guidelines for developing AI applications with LlamaIndex-JS, covering code organization, performance, security, and testing best practices. It aims to ensure robust, efficient, and secure LLM-powered applications.",
    "author": "sanjeed5",
    "tags": [
      "llamaindex-js",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/llamaindex-js.mdc",
    "content": "# LlamaIndex-JS Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing AI and ML applications using the LlamaIndex-JS library. Following these guidelines will help you build robust, efficient, secure, and maintainable applications.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a modular directory structure to organize your LlamaIndex-JS project. Here’s a recommended structure:\n\n\nmy-llamaindex-app/\n├── src/\n│   ├── components/          # Reusable UI components (if applicable)\n│   │   ├── MyComponent.tsx\n│   │   └── ...\n│   ├── services/           # API services and data fetching logic\n│   │   ├── llamaIndexService.ts  # LlamaIndex specific functionalities\n│   │   └── ...\n│   ├── utils/              # Utility functions and helpers\n│   │   ├── dataProcessing.ts\n│   │   └── ...\n│   ├── index/                # Index management\n│   │   ├── documentLoaders.ts  # Custom document loaders\n│   │   ├── indexBuilders.ts    # Logic for building indices\n│   │   └── ...\n│   ├── prompts/            # Custom prompt templates\n│   │   ├── summarizationPrompt.ts\n│   │   └── ...\n│   ├── models/             # Data models and interfaces\n│   │   ├── document.ts\n│   │   └── ...\n│   ├── app.ts               # Main application entry point\n│   └── ...\n├── tests/\n│   ├── unit/\n│   │   └── ...\n│   ├── integration/\n│   │   └── ...\n│   └── ...\n├── .env                   # Environment variables\n├── package.json\n├── tsconfig.json          # TypeScript configuration\n├── README.md\n└── ...\n\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   For components, use PascalCase (e.g., `MyComponent.tsx`).\n*   For utility functions and services, use camelCase (e.g., `llamaIndexService.ts`, `dataProcessing.ts`).\n*   For configuration files, use kebab-case (e.g., `tsconfig.json`).\n\n### 1.3. Module Organization\n\n*   **Encapsulation:** Group related functions, classes, and interfaces into modules.\n*   **Single Responsibility Principle:** Each module should have a clear and specific purpose.\n*   **Explicit Exports:** Use explicit `export` statements to define the public API of each module.\n*   **Avoid Circular Dependencies:** Be mindful of circular dependencies between modules, as they can lead to runtime errors and make code harder to understand.\n\n### 1.4. Component Architecture (If Applicable)\n\n*   If your LlamaIndex-JS application includes a user interface (e.g., using React), follow a component-based architecture.\n*   **Presentational Components:** Focus on rendering UI elements and receiving data as props.\n*   **Container Components:** Handle data fetching, state management, and logic.\n*   **Component Composition:** Build complex UIs by composing smaller, reusable components.\n\n### 1.5. Code Splitting\n\n*   Use dynamic imports (`import()`) to split your code into smaller chunks.\n*   Lazy-load components or modules that are not immediately needed.\n*   This can significantly improve initial load time and reduce the overall bundle size.\n\ntypescript\n// Example of lazy loading a module\nasync function loadMyModule() {\n  const myModule = await import('./myModule');\n  myModule.doSomething();\n}\n\n\n## 2. Common Patterns and Anti-Patterns\n\n### 2.1. Design Patterns\n\n*   **Retrieval-Augmented Generation (RAG):** Implement RAG to enhance LLM responses by retrieving relevant data from external sources.\n*   **Factory Pattern:** Use factory functions to create instances of LlamaIndex objects, abstracting the creation logic.\n*   **Strategy Pattern:** Employ different indexing or query strategies based on the specific use case.\n*   **Observer Pattern:** Use this to react to changes in the underlying data or model.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Loading:** Use `Document` objects and `BaseReader` classes for loading data from various sources.\n*   **Indexing:** Choose appropriate index types (e.g., `VectorStoreIndex`, `SummaryIndex`) based on your data and query requirements.\n*   **Querying:** Use `QueryEngine` to orchestrate complex queries and retrieve relevant information.\n*   **Evaluation:** Implement evaluation metrics to measure the performance of your RAG pipeline.\n\n### 2.3. Anti-Patterns and Code Smells\n\n*   **Tight Coupling:** Avoid tight coupling between LlamaIndex-JS components and other parts of your application.\n*   **Global State:** Minimize the use of global state, as it can make your application harder to reason about.\n*   **Ignoring Errors:** Always handle errors gracefully and provide informative error messages.\n*   **Over-Complicating Queries:** Keep queries simple and focused on retrieving the most relevant information.\n*   **Not using `async/await`:** Use `async/await` when dealing with asynchronous operations to avoid callback hell.\n\n### 2.4. State Management\n\n*   Choose a state management library or pattern that fits your application's needs (e.g., React Context, Redux, Zustand).\n*   Keep state minimal and derive values as needed.\n*   Use immutable data structures to simplify state updates.\n\n### 2.5. Error Handling\n\n*   Use `try...catch` blocks to handle exceptions.\n*   Provide informative error messages to the user.\n*   Log errors for debugging purposes.\n*   Consider using a centralized error handling mechanism.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Efficient Indexing:** Optimize indexing by selecting appropriate chunk sizes and embedding models. Experiment to find optimal values.\n*   **Caching:** Cache frequently accessed data to reduce latency.\n*   **Asynchronous Operations:** Use asynchronous operations to avoid blocking the main thread.\n*   **Vector Store Selection:** Choose vector stores that support efficient similarity search (e.g., FAISS, Annoy, Qdrant).\n\n### 3.2. Memory Management\n\n*   Be mindful of memory usage, especially when dealing with large datasets.\n*   Use garbage collection effectively.\n*   Avoid creating unnecessary objects.\n*   Use streams for processing large files.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   Use virtualization techniques to render large lists efficiently.\n*   Memoize components to prevent unnecessary re-renders.\n*   Optimize images and other assets.\n\n### 3.4. Bundle Size Optimization\n\n*   Use tree shaking to remove unused code.\n*   Minify and compress your code.\n*   Use code splitting to load only the code that is needed for each page.\n*   Analyze bundle size using tools like Webpack Bundle Analyzer.\n\n### 3.5. Lazy Loading\n\n*   Implement lazy loading for non-critical components or modules.\n*   This can improve initial load time and reduce the overall bundle size.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Prompt Injection:** Protect against prompt injection attacks by sanitizing user input and validating LLM responses. Consider using libraries such as LLM Guard by Protect AI.\n*   **Data Leakage:** Prevent data leakage by carefully controlling access to sensitive information.\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks (if applicable, in UI components).\n*   **API Key Exposure:** Protect API keys and other sensitive credentials by storing them securely and avoiding hardcoding them in your code.\n\n### 4.2. Input Validation\n\n*   Validate all user input to prevent malicious data from entering your application.\n*   Use appropriate validation techniques for each type of input.\n*   Sanitize input to remove potentially harmful characters.\n\n### 4.3. Authentication and Authorization\n\n*   Implement authentication to verify the identity of users.\n*   Implement authorization to control access to resources.\n*   Use strong passwords and encryption.\n*   Follow the principle of least privilege.\n\n### 4.4. Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use secure storage mechanisms.\n*   Implement data loss prevention (DLP) measures.\n*   Regularly back up your data.\n\n### 4.5. Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Validate API responses to ensure data integrity.\n*   Implement rate limiting to prevent abuse.\n*   Use API keys or other authentication mechanisms.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   Write unit tests to verify the functionality of individual components and functions.\n*   Use mocking and stubbing to isolate units of code.\n*   Aim for high code coverage.\n\n### 5.2. Integration Testing\n\n*   Write integration tests to verify the interaction between different components and modules.\n*   Test the integration with external services and APIs.\n\n### 5.3. End-to-End Testing\n\n*   Write end-to-end tests to verify the overall functionality of the application.\n*   Simulate user interactions and verify the expected behavior.\n\n### 5.4. Test Organization\n\n*   Organize your tests into separate directories for unit, integration, and end-to-end tests.\n*   Use descriptive test names.\n*   Keep tests concise and focused.\n\n### 5.5. Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate units of code during testing.\n*   Use a mocking library such as Jest or Sinon.\n*   Avoid over-mocking, as it can make your tests less effective.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   Incorrectly configuring the LlamaIndex-JS client.\n*   Using the wrong index type for your data.\n*   Not handling errors properly.\n*   Ignoring performance considerations.\n*   Not securing your application against vulnerabilities.\n\n### 6.2. Edge Cases\n\n*   Handling large documents or datasets.\n*   Dealing with complex queries.\n*   Handling different data formats.\n*   Dealing with rate limits from external APIs.\n\n### 6.3. Version-Specific Issues\n\n*   Be aware of breaking changes between LlamaIndex-JS versions.\n*   Consult the release notes and migration guides when upgrading.\n*   Test your application thoroughly after upgrading.\n\n### 6.4. Compatibility Concerns\n\n*   Ensure compatibility between LlamaIndex-JS and other libraries or frameworks that you are using.\n*   Test your application in different environments.\n\n### 6.5. Debugging Strategies\n\n*   Use a debugger to step through your code and inspect variables.\n*   Log messages to the console to track the execution flow.\n*   Use error monitoring tools to track errors in production.\n*   Use the LlamaIndex-JS documentation and community forums to find solutions to common problems.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   Node.js\n*   npm or yarn\n*   TypeScript (recommended)\n*   VS Code or other IDE\n*   LlamaIndex Studio for visualization\n*   Postman or Insomnia for testing APIs\n\n### 7.2. Build Configuration\n\n*   Use a build tool such as Webpack or Parcel to bundle your code.\n*   Configure your build tool to optimize your code for production.\n*   Use environment variables to configure your application.\n\n### 7.3. Linting and Formatting\n\n*   Use a linter such as ESLint to enforce coding standards.\n*   Use a formatter such as Prettier to format your code consistently.\n*   Configure your IDE to automatically lint and format your code.\n\n### 7.4. Deployment\n\n*   Choose a deployment platform that meets your needs (e.g., Vercel, Netlify, AWS).\n*   Configure your deployment environment to use environment variables.\n*   Set up monitoring and logging to track the performance of your application.\n\n### 7.5. CI/CD Integration\n\n*   Use a CI/CD platform such as GitHub Actions or Jenkins to automate your build, test, and deployment processes.\n*   Configure your CI/CD pipeline to run your tests automatically.\n*   Use automated deployment to deploy your application to production.\n\nBy following these best practices, you can build robust, efficient, secure, and maintainable AI applications using LlamaIndex-JS.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx",
      "format": "mdc",
      "originalFile": "llamaindex-js.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "llamaindex",
      "js",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "developing",
      "applications",
      "with",
      "covering",
      "llamaindex-js",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "llamaindex-js",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-llvm",
    "description": "This rule enforces LLVM's coding standards and promotes best practices for writing efficient, maintainable, and robust code within the LLVM ecosystem. It covers style, language usage, optimization strategies, and more.",
    "author": "sanjeed5",
    "tags": [
      "llvm",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/llvm.mdc",
    "content": "- Adhere to LLVM's coding standards to ensure code consistency, readability, and maintainability.\n- Always follow the [LLVM Coding Standards](https://llvm.org/docs/CodingStandards.html) and [LLVM Developer Policy](https://llvm.org/docs/DeveloperPolicy.html).\n\n## Languages, Libraries, and Standards\n\n- Use modern, standard-conforming, and portable C++ code (C++17 or later, as supported by major toolchains).\n- Prefer LLVM's own libraries (e.g., `llvm::DenseMap`, `llvm::SmallVector`) over the C++ standard library when appropriate for performance or integration benefits.  Consult the LLVM Programmer's Manual for details.\n- Use Python (with the minimum version specified in the Getting Started documentation) for automation, build systems, and utility scripts.\n- Format Python code with `black` and `darker` to adhere to PEP 8 standards.\n\n## Mechanical Source Issues\n\n- Write clear diagnostic messages using succinct and correct English.\n- Follow the recommended `#include` style: Main module header first, followed by LLVM project headers (most specific to least specific), then system headers.\n- Limit source code width to 80 columns.\n- Prefer spaces to tabs in source files.\n- Avoid trailing whitespace.\n- Format multi-line lambdas like blocks of code.\n- Use braced initializer lists as if the braces were parentheses in a function call.\n\n## Language and Compiler Issues\n\n- Treat compiler warnings as errors.\n- Write portable code, encapsulating non-portable code behind well-defined interfaces.\n- Do not use RTTI or exceptions.\n- Prefer C++-style casts (`static_cast`, `reinterpret_cast`, `const_cast`) over C-style casts, except when casting to `void` to suppress unused variable warnings or between integral types.\n- Do not use static constructors (global variables with constructors or destructors).\n- Use `struct` when all members are public, and `class` otherwise.\n- Avoid using braced initializer lists to call constructors with non-trivial logic.\n- Use `auto` type deduction to make code more readable, but be mindful of unnecessary copies.\n- Beware of non-determinism due to the ordering of pointers in unordered containers.\n- Beware of non-deterministic sorting order of equal elements; use `llvm::sort` instead of `std::sort`.\n\n## Style Issues\n\n- Layer libraries correctly to avoid circular dependencies. Use Unix linker principles to enforce this.\n- `#include` as little as possible, especially in header files. Use forward declarations when possible.\n- Use namespace qualifiers to implement previously declared functions in source files; avoid opening namespace blocks.\n- Use early exits and `continue` statements to simplify code and reduce indentation.\n- Don't use `else` or `else if` after control flow interrupting statements like `return`, `break`, `continue`, or `goto`.\n- Turn predicate loops into predicate functions.\n\n## The Low-Level Issues\n\n- Name types, functions, variables, and enumerators properly, using descriptive and consistent names.\n- Assert liberally to check preconditions and assumptions.  Include informative error messages in assertions. Use `llvm_unreachable` to mark code that should never be reached. Avoid `assert(false)`. When assertions produce “unused value” warnings, move the call into the assert or cast the value to void.\n- Do not use `using namespace std`. Explicitly qualify identifiers from the standard namespace.\n- Don't use default labels in fully covered switches over enumerations to catch new enumeration values. Use `llvm_unreachable` after the switch to suppress GCC warnings about reaching the end of a non-void function.\n- Use range-based for loops wherever possible.\n- Don’t evaluate `end()` every time through a loop; evaluate it once before the loop starts.\n- `#include <iostream>` is forbidden. Use `raw_ostream` instead.\n- Avoid `std::endl`; use `\\n` instead.\n- Don’t use `inline` when defining a function in a class definition; it's implicit.\n\n## Microscopic Details\n\n- Put a space before an open parenthesis only in control flow statements, but not in normal function call expressions and function-like macros.\n- Prefer preincrement (`++X`) over postincrement (`X++`).\n- Don't indent namespaces; add comments indicating which namespace is being closed when helpful.\n\n## Code Organization and Structure\n\n- **Directory Structure:** Follow the existing LLVM directory structure conventions.  New components should typically reside in a subdirectory within an existing high-level category (e.g., `lib/Transforms`, `include/llvm/Analysis`).  Consider the intended audience (end-user tool vs. internal library) when choosing a location.\n- **File Naming:** Use descriptive names for files, matching the class or functionality they contain.  Header files should have a `.h` or `.hpp` extension, and implementation files should have a `.cpp`, `.cc`, or `.c` extension (depending on whether they are C or C++). MLIR files should have `.mlir` extension.\n- **Module Organization:** Break down large components into smaller, more manageable modules. Each module should have a well-defined purpose and interface. Minimize dependencies between modules.\n- **Component Architecture:** Design components with clear separation of concerns.  Use interfaces and abstract classes to promote loose coupling and enable polymorphism.  Follow the principle of least privilege.\n- **Code Splitting:** Decompose large functions into smaller, well-named helper functions. Use namespaces to group related functions and classes.\n\n## Common Patterns and Anti-patterns\n\n- **Visitor Pattern:** LLVM frequently uses the Visitor pattern for traversing and manipulating data structures (e.g., the LLVM IR).  Implement visitor classes for custom analysis or transformations.\n- **Pass Infrastructure:** Leverage LLVM's pass infrastructure for implementing optimization and analysis passes.  Create new pass types (e.g., analysis pass, transformation pass) as needed.\n- **Factory Pattern:** Use the Factory pattern to create instances of classes based on runtime parameters or configuration settings.\n- **Singleton Pattern (Avoid):** Minimize the use of the Singleton pattern, as it can lead to tight coupling and make testing difficult.  Consider dependency injection instead.\n- **Global Variables (Avoid):** Avoid global variables whenever possible, as they can introduce unexpected side effects and make code harder to reason about. Use configuration objects or dependency injection instead.\n\n## Performance Considerations\n\n- **Inline Hints:** Use `inline` judiciously to guide the compiler to inline frequently called functions.  Avoid inlining large or complex functions.\n- **Profile-Guided Optimization (PGO):** Use PGO to optimize code based on runtime profiles.  This can significantly improve performance for frequently executed code paths.\n- **LTO (Link-Time Optimization):** Enable LTO to allow the compiler to optimize code across module boundaries.\n- **Memory Management:** Use LLVM's memory management facilities (e.g., `BumpPtrAllocator`, `ScopedHashTable`) for efficient memory allocation.  Avoid excessive memory allocation and deallocation.\n- **Avoid Unnecessary Copies:** Pass objects by reference or pointer to avoid unnecessary copying.\n- **Use `SmallVector`:** Use `llvm::SmallVector` for small, fixed-size vectors to avoid dynamic memory allocation.\n- **Cache Locality:** Consider cache locality when designing data structures and algorithms.\n\n## Security Best Practices\n\n- **Input Validation:** Validate all external inputs to prevent vulnerabilities such as buffer overflows and code injection. Use LLVM's API for parsing various file formats.\n- **Sanitizers:** Use AddressSanitizer (ASan), MemorySanitizer (MSan), and UndefinedBehaviorSanitizer (UBSan) during development and testing to detect memory errors and undefined behavior.\n- **Avoid Code Injection:** Do not construct code by concatenating strings or using other techniques that could lead to code injection vulnerabilities.\n- **Data Validation:** Make sure to validate any data being retrieved from memory or other storage locations. Use `llvm::isSafeToLoadUnconditionally` to check if data is safe to load.\n\n## Testing Approaches\n\n- **Unit Tests:** Write unit tests for individual components and functions. Use the LLVM testing framework (e.g., `lit`) to automate test execution.\n- **Integration Tests:** Write integration tests to verify the interaction between different components. Create realistic test cases that exercise common use scenarios.\n- **Regression Tests:** Add regression tests for any bug fixes to prevent regressions in future versions.\n- **Fuzzing:** Use fuzzing techniques to identify corner cases and potential vulnerabilities.  Integrate fuzzing into the CI/CD pipeline.\n- **Code Coverage:** Measure code coverage to ensure that tests exercise all important code paths. Use `llvm-cov` to generate code coverage reports.\n\n## Common Pitfalls and Gotchas\n\n- **Incorrect Use of APIs:** Carefully read the documentation for LLVM APIs and ensure they are used correctly.  Pay attention to preconditions and postconditions.\n- **Memory Leaks:** Ensure that all allocated memory is properly deallocated. Use memory leak detection tools to identify memory leaks.\n- **Dangling Pointers:** Avoid dangling pointers by ensuring that objects are not deleted while they are still being referenced.\n- **Undefined Behavior:** Avoid undefined behavior, as it can lead to unpredictable results. Use sanitizers to detect undefined behavior.\n- **Version Compatibility:** Be aware of version compatibility issues when using LLVM with other libraries or tools.  Test your code with different versions of LLVM.\n\n## Tooling and Environment\n\n- **Clang:** Use Clang as the primary compiler for LLVM projects. Clang provides excellent support for C++ standards and LLVM extensions.\n- **CMake:** Use CMake to manage the build process for LLVM projects.  CMake is a cross-platform build system generator that is well-supported by LLVM.\n- **LLVM Tools:** Utilize the LLVM tools (e.g., `llvm-as`, `llvm-dis`, `opt`, `lli`) for various tasks such as assembling and disassembling LLVM IR, optimizing code, and executing LLVM bitcode.\n- **Git:** Use Git for version control.  Follow the LLVM Git commit message conventions.\n- **CI/CD:** Integrate CI/CD pipelines into LLVM development. Use test suites as part of your development cycle.\n\n## Additional Notes\n\n- When extending or modifying existing code, adhere to the style already in use.\n- Document your code clearly and concisely.  Provide comments explaining the purpose of functions, classes, and variables.\n- Keep pull requests small and focused.  This makes it easier for reviewers to understand and approve your changes.\n- Be responsive to feedback from reviewers and address any issues promptly.\n- Engage with the LLVM community to ask questions, share knowledge, and contribute to the project.\n- Refer to existing documentation and examples in the LLVM codebase for guidance on how to implement new features and functionality.\n\nBy following these guidelines, you can write high-quality LLVM code that is efficient, maintainable, and robust. This ensures consistent code quality and facilitates collaboration within the LLVM community.",
    "metadata": {
      "globs": "*.h,*.hpp,*.c,*.cc,*.cpp,*.ll,*.mlir",
      "format": "mdc",
      "originalFile": "llvm.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "llvm",
      "this",
      "rule",
      "enforces",
      "coding",
      "standards",
      "promotes",
      "best",
      "practices",
      "writing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "llvm",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-material-ui",
    "description": "Comprehensive guide to best practices when developing with Material-UI/MUI, covering code organization, performance, security, testing, and common pitfalls. It focuses on creating maintainable, scalable, and performant React applications using MUI components.",
    "author": "sanjeed5",
    "tags": [
      "material-ui",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/material-ui.mdc",
    "content": "# Material-UI/MUI Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing React applications using Material-UI (MUI). Following these guidelines will help you create maintainable, scalable, performant, and secure applications.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a clear and consistent directory structure to improve code maintainability and collaboration. A common approach is to organize code by feature or domain.\n\n\nsrc/\n  components/\n    [ComponentName]/\n      [ComponentName].jsx  # Component implementation\n      [ComponentName].module.css # Component-specific styles (CSS Modules)\n      [ComponentName].test.jsx # Unit tests\n      index.js           # (Optional) Export the component\n  pages/\n    [PageName]/\n      [PageName].jsx      # Page component\n      index.js           # (Optional) Export the page component\n  styles/\n    theme.js           # MUI theme configuration\n    global.css        # Global styles\n  utils/\n    api.js             # API client\n    helpers.js         # Utility functions\n  App.jsx              # Main application component\n  index.jsx            # Entry point\n\n\n### 1.2 File Naming Conventions\n\n-   **Components:** Use PascalCase for component file names (e.g., `MyButton.jsx`).\n-   **Styles:** Use camelCase or kebab-case for style file names (e.g., `myButton.module.css` or `my-button.module.css`).  Prefer CSS modules.\n-   **Utilities:** Use camelCase for utility file names (e.g., `api.js`, `helpers.js`).\n-   **Tests:** Use the `.test.jsx` or `.spec.jsx` suffix for test files (e.g., `MyComponent.test.jsx`).\n-   **Indexes**: `index.js` should export the main entity contained within its parent folder.\n\n### 1.3 Module Organization\n\n-   **Component-Specific Modules:** Encapsulate styles, logic, and tests within a component's directory to promote modularity and reusability.\n-   **Theme Module:** Centralize MUI theme customization in a dedicated module (`theme.js`).\n-   **Utility Modules:** Group related utility functions into separate modules (e.g., `api.js` for API calls, `helpers.js` for data manipulation). Import selectively only the parts you need from larger modules.\n\n### 1.4 Component Architecture\n\n-   **Presentational and Container Components:** Separate concerns by creating presentational (UI-focused) and container (data-fetching and state management) components.  Consider using hooks for simpler components.\n-   **Composition over Inheritance:** Favor component composition over inheritance to create flexible and reusable UI elements.\n-   **Controlled Components:** Use controlled components with explicit state management for better control and predictability.\n-   **Small Components:**  Create smaller, focused components that do one thing well.  This promotes reuse and testability.\n\n### 1.5 Code Splitting Strategies\n\n-   **Route-Based Splitting:** Use React.lazy and Suspense to split your application into smaller chunks that are loaded on demand based on the current route.\n-   **Component-Based Splitting:**  Lazy-load less critical components to reduce the initial bundle size. Useful for complex dialogs, or infrequently used features.\n-   **Library Splitting:** If certain libraries are used only in specific parts of your application, consider splitting them into separate chunks.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Material-UI/MUI\n\n-   **Theming:** Use the `ThemeProvider` to customize the MUI theme globally. Define your color palette, typography, and other theme values in `theme.js`. Use `createTheme` function to extend the default theme.\n-   **Styling with `sx` prop:** Employ the `sx` prop for simple, one-off style customizations.\n-   **Styling with `styled` API:** Use the `styled` API for creating reusable, theme-aware components.  This is the recommended approach for component styling in MUI v5 and above.\n-   **Grid System:** Leverage the `Grid` component for creating responsive layouts.\n-   **Hooks**: Use React hooks extensively for state management and side effects.  MUI components work seamlessly with hooks.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Form Handling:** Use `TextField` components with proper validation and state management libraries like Formik or React Hook Form.\n-   **Data Display:** Use `Table`, `List`, and `Card` components to display data in a structured and visually appealing manner.\n-   **Navigation:** Use `AppBar`, `Drawer`, and `BottomNavigation` components for application navigation.\n-   **Notifications:** Implement notifications using the `Snackbar` component.\n-   **Dialogs/Modals**: Use the `Dialog` component to display modal content.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Inline Styles:** Avoid inline styles as they are difficult to maintain and do not support theming. Use the `sx` prop or `styled` API instead. While the `sx` prop is quick, prefer `styled` components for reusability.\n-   **Direct DOM Manipulation:** Avoid directly manipulating the DOM. Use React's state management and component lifecycle methods to update the UI.\n-   **Over-nesting Components:** Avoid deeply nested component structures as they can impact performance and readability.  Refactor into smaller, more focused components.\n-   **Mutating Theme Directly**:  Don't directly mutate the theme object. Use `createTheme` and `ThemeProvider` to apply changes.\n-   **Ignoring Accessibility:** Ensure your components are accessible by providing proper ARIA attributes and keyboard navigation support.\n\n### 2.4 State Management Best Practices\n\n-   **Local Component State:** Use `useState` and `useReducer` for managing component-specific state.\n-   **Global Application State:**  Use Context API, Redux, Zustand, or Jotai for managing global application state.\n-   **Lifting State Up:** Lift state up to the nearest common ancestor component when multiple components need to share state.\n-   **Immutable Data:** Treat state as immutable and use immutable data structures to prevent unexpected side effects.  Libraries like Immer can help.\n\n### 2.5 Error Handling Patterns\n\n-   **Error Boundaries:** Use error boundaries to catch JavaScript errors in components and prevent the entire application from crashing.\n-   **Centralized Error Handling:** Implement a centralized error handling mechanism to log errors and display user-friendly error messages.\n-   **Try-Catch Blocks:** Use try-catch blocks to handle potential errors in asynchronous operations or API calls.\n-   **Defensive Programming**: Validate props, check for null/undefined values, and handle potential edge cases.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Memoization:** Use `React.memo` to memoize functional components and prevent unnecessary re-renders.  Use `useMemo` and `useCallback` hooks to memoize expensive computations and function references.\n-   **Virtualization:** Use virtualization libraries like `react-window` or `react-virtualized` to efficiently render large lists or tables.\n-   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of expensive operations like API calls or event handlers.\n-   **Code Splitting:** Implement code splitting to reduce the initial bundle size and improve load times.\n-   **Image Optimization:** Optimize images by compressing them and using appropriate formats (e.g., WebP).  Use lazy loading for images below the fold.\n-   **CDN**: Host static assets on a CDN.\n\n### 3.2 Memory Management\n\n-   **Avoid Memory Leaks:** Be mindful of memory leaks, especially in event listeners and subscriptions.  Clean up resources in the `useEffect` hook's cleanup function.\n-   **Garbage Collection:** Understand how JavaScript's garbage collection works and avoid creating unnecessary objects or closures that can lead to memory leaks.\n\n### 3.3 Rendering Optimization\n\n-   **ShouldComponentUpdate (Class Components):** Implement `shouldComponentUpdate` (or `React.memo` in functional components) to prevent unnecessary re-renders when the props or state have not changed.\n-   **PureComponent (Class Components):**  Extend `PureComponent` for components that rely solely on props for rendering, as it provides a shallow prop comparison.\n-   **Key Prop:**  Always provide a unique `key` prop when rendering lists of components. This helps React efficiently update the DOM.\n-   **Minimize DOM Updates:** Reduce the number of DOM updates by batching state updates and using techniques like requestAnimationFrame.\n\n### 3.4 Bundle Size Optimization\n\n-   **Tree Shaking:** Ensure your build process supports tree shaking to remove unused code from your bundle.\n-   **Minification:** Minify your code to reduce the bundle size.\n-   **Compression:** Use gzip or Brotli compression to reduce the size of your assets during transmission.\n-   **Dependency Analysis:** Analyze your dependencies to identify and remove unnecessary libraries.\n\n### 3.5 Lazy Loading Strategies\n\n-   **React.lazy and Suspense:** Use `React.lazy` and `Suspense` to lazy load components and improve initial load times.\n-   **Intersection Observer API:**  Use the Intersection Observer API to lazy load components when they become visible in the viewport.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.  Use libraries like DOMPurify to sanitize HTML.\n-   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection by using anti-CSRF tokens.\n-   **SQL Injection:**  Use parameterized queries or ORMs to prevent SQL injection attacks.\n-   **Authentication and Authorization Issues:** Implement secure authentication and authorization mechanisms to protect sensitive data and resources.\n-   **Denial of Service (DoS):** Implement rate limiting and other security measures to prevent DoS attacks.\n\n### 4.2 Input Validation\n\n-   **Client-Side Validation:** Implement client-side validation to provide immediate feedback to the user.\n-   **Server-Side Validation:**  Always validate user input on the server-side to prevent malicious data from being stored in your database.\n-   **Sanitization:** Sanitize user input to remove or encode potentially harmful characters or code.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **JSON Web Tokens (JWT):** Use JWTs for authentication and authorization.\n-   **OAuth 2.0:**  Use OAuth 2.0 for delegating authorization to third-party applications.\n-   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption:** Encrypt sensitive data at rest and in transit.\n-   **Data Masking:** Mask sensitive data to protect it from unauthorized access.\n-   **Data Minimization:** Collect only the necessary data to minimize the risk of data breaches.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS:**  Use HTTPS to encrypt communication between the client and the server.\n-   **API Keys:**  Use API keys to authenticate API requests.\n-   **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n-   **Input Validation**: Perform extensive input validation on API endpoints.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test Driven Development (TDD):** Consider using TDD to write tests before implementing the code.\n-   **Component Testing:** Unit test individual components in isolation to ensure they function correctly.\n-   **Mocking Dependencies:** Mock external dependencies like API calls or third-party libraries to isolate the component under test.\n-   **Test Coverage:** Aim for high test coverage to ensure that most of your code is tested.\n\n### 5.2 Integration Testing\n\n-   **Test Component Interactions:** Integration tests verify the interactions between different components.\n-   **Test Data Flow:** Test the flow of data between components to ensure that data is passed correctly.\n-   **Mock API Endpoints:** Mock API endpoints to simulate real-world scenarios.\n\n### 5.3 End-to-End Testing\n\n-   **Simulate User Interactions:** End-to-end tests simulate user interactions to verify that the application functions correctly from the user's perspective.\n-   **Test Critical User Flows:**  Focus on testing critical user flows like login, registration, and checkout.\n-   **Use Testing Frameworks:** Use testing frameworks like Cypress or Playwright to automate end-to-end tests.\n\n### 5.4 Test Organization\n\n-   **Colocate Tests with Components:** Place test files in the same directory as the component they test.\n-   **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what the test is verifying.\n-   **Organize Tests by Feature:** Organize tests by feature to improve maintainability.\n\n### 5.5 Mocking and Stubbing\n\n-   **Mock API Calls:** Mock API calls to isolate components during testing.\n-   **Stub External Dependencies:** Stub external dependencies to control their behavior during testing.\n-   **Use Mocking Libraries:** Use mocking libraries like Jest or Sinon to create mocks and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Not Using the ThemeProvider:** Neglecting to use the `ThemeProvider` for consistent styling.\n-   **Overriding Styles Incorrectly:**  Incorrectly overriding MUI component styles (e.g., using CSS specificity issues).\n-   **Ignoring Responsiveness:**  Failing to design responsive layouts using the `Grid` component.\n-   **Not Using the Latest Version:** Using older versions of MUI that may have known bugs or security vulnerabilities.\n-   **Over-reliance on `any` type in Typescript**: Not defining accurate types can lead to runtime errors.\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **Server-Side Rendering (SSR):**  MUI requires special configuration for SSR to prevent CSS hydration issues.\n-   **Accessibility (a11y):**  Ensure components are accessible by providing proper ARIA attributes and keyboard navigation support.\n-   **Browser Compatibility:** Test your application in different browsers to ensure compatibility.\n-   **Internationalization (i18n):**  Consider internationalization when designing your application.\n\n### 6.3 Version-Specific Issues\n\n-   **Breaking Changes:**  Be aware of breaking changes when upgrading MUI versions.  Refer to the migration guide for each version.\n-   **Deprecated Features:**  Avoid using deprecated features as they may be removed in future versions.\n\n### 6.4 Compatibility Concerns\n\n-   **React Version:**  Ensure that your MUI version is compatible with your React version.\n-   **Third-Party Libraries:**  Be aware of compatibility issues between MUI and other third-party libraries.\n\n### 6.5 Debugging Strategies\n\n-   **Use Browser Developer Tools:** Use browser developer tools to inspect the DOM, debug JavaScript code, and profile performance.\n-   **Use React Developer Tools:** Use the React Developer Tools to inspect the component tree, view component props and state, and profile performance.\n-   **Use Logging Statements:** Use logging statements to trace the execution of your code and identify potential issues.\n-   **Use a Debugger:** Use a debugger to step through your code and inspect variables.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **IDE:** Visual Studio Code (VS Code) with extensions like ESLint, Prettier, and React Developer Tools.\n-   **Package Manager:** npm, yarn, or pnpm.\n-   **Build Tool:** Webpack, Parcel, or Rollup.\n-   **Testing Framework:** Jest or Mocha.\n-   **Linting and Formatting:** ESLint and Prettier.\n\n### 7.2 Build Configuration\n\n-   **Webpack Configuration:** Configure Webpack to optimize your bundle size, enable code splitting, and handle assets.\n-   **Babel Configuration:** Configure Babel to transpile your code to older versions of JavaScript for browser compatibility.\n\n### 7.3 Linting and Formatting\n\n-   **ESLint:** Configure ESLint to enforce code style and prevent common errors.  Use a shared ESLint configuration like Airbnb or Standard.\n-   **Prettier:** Configure Prettier to automatically format your code.\n-   **Husky and Lint-Staged:** Use Husky and Lint-Staged to run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n-   **Choose a Hosting Provider:** Choose a reliable hosting provider like Netlify, Vercel, or AWS.\n-   **Configure Environment Variables:** Configure environment variables for different environments (e.g., development, staging, production).\n-   **Optimize Assets:** Optimize assets like images and fonts before deploying your application.\n-   **Use a CDN:** Use a CDN to serve static assets.\n\n### 7.5 CI/CD Integration\n\n-   **Choose a CI/CD Tool:** Choose a CI/CD tool like GitHub Actions, Jenkins, or CircleCI.\n-   **Automate Tests:** Automate tests to run automatically on every commit or pull request.\n-   **Automate Deployment:** Automate deployment to automatically deploy your application to different environments.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "material-ui.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "material",
      "ui",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "when",
      "developing",
      "with",
      "covering",
      "code",
      "material-ui",
      "react",
      "frontend",
      "javascript",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "material-ui",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-matplotlib",
    "description": "This rule provides guidelines and best practices for developing robust, maintainable, and performant data visualizations using Matplotlib in Python. It covers aspects from code organization to testing and security considerations.",
    "author": "sanjeed5",
    "tags": [
      "matplotlib",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/matplotlib.mdc",
    "content": "# Matplotlib Best Practices\n\nThis document outlines best practices for using Matplotlib, a powerful Python library for creating static, interactive, and animated visualizations. Adhering to these guidelines will help you write cleaner, more maintainable, and performant code for your data visualization projects.\n\nLibrary Information:\n- Name: matplotlib\n- Tags: ai, ml, data-science, python, data-visualization\n\n## 1. Code Organization and Structure\n\nProper code organization is essential for maintainability and collaboration.  For visualization projects using Matplotlib, the organization becomes crucial due to the complexity that can arise from numerous plotting options and data manipulation.\n\n### 1.1 Directory Structure\n\nAdopt a structured directory layout to separate source code, data, and output. A typical project structure might look like this:\n\n\nproject_name/\n├── src/\n│   ├── __init__.py\n│   ├── data_processing.py  # Data loading, cleaning, and transformation functions\n│   ├── plotting_functions.py # Reusable plotting functions using Matplotlib\n│   ├── main.py            # Main script to orchestrate the visualization\n├── data/\n│   ├── raw/            # Original, unmodified data\n│   ├── processed/      # Data that has been cleaned and transformed\n├── output/\n│   ├── images/          # Saved plot images\n│   ├── reports/         # Generated reports or summaries\n├── notebooks/         # Jupyter notebooks for exploration\n├── tests/            # Testing directory\n│   ├── __init__.py\n│   ├── test_data_processing.py\n│   ├── test_plotting_functions.py\n├── README.md\n├── requirements.txt\n├── .gitignore\n\n\n### 1.2 File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   Python files: `snake_case.py` (e.g., `data_processing.py`, `plotting_functions.py`).\n*   Image files: `descriptive_name.png`, `descriptive_name.jpg`, or `descriptive_name.svg`.\n*   Data files: `descriptive_name.csv`, `descriptive_name.json`.\n\n### 1.3 Module Organization\n\n*   Group related functions and classes into modules.\n*   Use meaningful module names that reflect their purpose (e.g., `data_processing`, `plotting_utils`).\n*   Import modules using explicit relative imports when working within the same package (e.g., `from . import data_processing`).\n*   Avoid circular dependencies between modules.\n\n### 1.4 Component Architecture\n\n*   **Data Abstraction Layer:** Create modules dedicated to data loading, cleaning, and transformation. This isolates the visualization logic from the data source.\n*   **Plotting Abstraction Layer:**  Develop reusable plotting functions that encapsulate common Matplotlib configurations.  This promotes code reuse and consistency.\n*   **Configuration Management:** Store plot configurations (colors, styles, labels) in a separate configuration file (e.g., a JSON or YAML file). This allows for easy modification of plot aesthetics without changing the code.\n*   **Orchestration Layer:** A main script responsible for calling the data loading, processing and plotting functions and assembling the final visualization, like `main.py` in the example structure above.\n\n### 1.5 Code Splitting Strategies\n\n*   **Functional Decomposition:** Break down complex plotting tasks into smaller, manageable functions.\n*   **Class-Based Organization:** Use classes to represent complex plot structures (e.g., a custom chart type) or to manage plot state (see section on State Management below).\n*   **Separate Data Handling:** Ensure functions which load and clean data are distinct from plotting functionalities.\n*   **Configuration Driven:** Define plot styles and settings in external configuration files (JSON, YAML) which are then read by plotting functions, allowing easy style modifications.\n\n## 2. Common Patterns and Anti-patterns\n\nRecognizing and applying appropriate design patterns can significantly improve the quality of your Matplotlib code. Similarly, awareness of anti-patterns can help you avoid common pitfalls.\n\n### 2.1 Design Patterns\n\n*   **Object-Oriented API:**  Prioritize using Matplotlib's object-oriented API (`fig, ax = plt.subplots()`) over the stateful `pyplot` interface. The object-oriented API provides greater flexibility and control, especially for complex plots.\n*   **Template Method:** Create a base class for common plot types with abstract methods for data loading and customization. Subclasses can then implement these methods to create specific plots.\n*   **Strategy Pattern:** Define different plotting strategies as separate classes.  The main plotting function can then dynamically choose the appropriate strategy based on the data or user input.\n*   **Observer Pattern:** Useful in interactive plots where changes in one element (e.g., a slider) trigger updates in other elements of the plot. Matplotlib's event handling system can be leveraged for this pattern.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Creating Subplots:**  Use `plt.subplots()` to create figures with multiple subplots. Specify the number of rows and columns, and unpack the returned figure and axes objects for individual manipulation.\n*   **Customizing Plots:**  Use the `ax.set()` method to set plot titles, axis labels, legends, and other properties.  For more fine-grained control, use methods like `ax.set_xlabel()`, `ax.set_ylabel()`, `ax.set_title()`, etc.\n*   **Adding Legends:** Use `ax.legend()` to add a legend to the plot. Customize the legend appearance and location as needed.\n*   **Saving Plots:**  Use `fig.savefig()` to save plots to files.  Specify the desired file format, resolution (dpi), and other options.\n*   **Working with Color Maps:**  Use `cmap` argument in plotting functions to apply color maps to your data. Consider using perceptually uniform color maps to avoid visual distortions.\n*   **Handling Date Data:** Matplotlib provides excellent support for date data.  Use `matplotlib.dates` module to format and manipulate dates on the axes. Use `dateutil.parser` for flexible date parsing.\n*   **Interactive plots:** Utilize Matplotlib's interactive capabilities with `plt.ion()` and `plt.ioff()` to update plots dynamically in a loop. Use widgets such as sliders and buttons for user interaction.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Excessive Use of `pyplot` Interface:** Relying heavily on the `pyplot` interface can lead to tightly coupled and less maintainable code.  Embrace the object-oriented API for better structure and flexibility.\n*   **Hardcoding Plot Configurations:**  Avoid hardcoding plot configurations (colors, styles, labels) directly in the code.  Use configuration files or dictionaries to manage these settings.\n*   **Copy-Pasting Plotting Code:**  Duplicating plotting code across multiple scripts leads to redundancy and makes it difficult to maintain consistency.  Create reusable plotting functions instead.\n*   **Ignoring Performance Considerations:** Creating very complex plots with huge amount of data without considering optimization can result in slow rendering and high memory usage.\n*   **Not Handling Exceptions:** Failure to handle potential exceptions (e.g., file not found, invalid data) can lead to unexpected program termination.\n*   **Overplotting:** In scatter plots, overlapping data points can obscure the underlying distribution.  Use techniques like transparency (`alpha`) or jitter to mitigate overplotting.\n\n### 2.4 State Management\n\n*   **Encapsulate Plot State:** Use classes or functions to encapsulate the state of a plot.  This makes it easier to manage complex plot configurations and ensures that plots are rendered consistently.\n*   **Avoid Global State:** Minimize the use of global variables to store plot state.  This can lead to unexpected side effects and make it difficult to reason about the code.\n*   **Use Configuration Objects:**  Create configuration objects to store plot settings.  This allows you to easily modify the appearance of your plots without changing the code.\n\n### 2.5 Error Handling\n\n*   **Use `try...except` Blocks:**  Wrap potentially problematic code (e.g., file I/O, data processing) in `try...except` blocks to handle exceptions gracefully.\n*   **Log Errors:**  Use the `logging` module to log errors and warnings. This helps you identify and diagnose problems in your code.\n*   **Provide Informative Error Messages:**  When raising exceptions, provide informative error messages that help the user understand the cause of the problem.\n*   **Validate Inputs:** Before using data in your plots, validate the data to ensure it is in the expected format and range. Handle invalid data appropriately.\n*   **Custom Exceptions:** Create custom exception classes for specific error conditions in your plotting code. This improves code readability and makes it easier to handle errors.\n\n## 3. Performance Considerations\n\nPerformance is a crucial aspect when dealing with large datasets or complex visualizations. Optimizing your code can significantly improve rendering speed and reduce memory consumption.\n\n### 3.1 Optimization Techniques\n\n*   **Vectorization:** Use NumPy's vectorized operations to perform calculations on entire arrays instead of looping through individual elements. This can significantly improve performance.\n*   **Data Aggregation:**  Aggregate data before plotting it to reduce the number of data points. This can be especially helpful for large datasets.\n*   **Use Efficient Plot Types:**  Choose plot types that are appropriate for the data and the visualization goal. For example, use histograms to visualize distributions instead of scatter plots.\n*   **Limit Data Points:** Plot only the necessary data points. Avoid plotting unnecessary details that do not contribute to the visualization.\n*   **Caching:** Cache intermediate results to avoid redundant calculations. This can be helpful for computationally intensive tasks.\n*   **Simplify Complex Geometries:** Reduce the complexity of plot elements by simplifying geometries or using approximations.\n\n### 3.2 Memory Management\n\n*   **Release Unused Memory:** Explicitly release memory occupied by large data structures when they are no longer needed. Use `del` statement to remove references to objects.\n*   **Use Generators:** Use generators to process large datasets in chunks instead of loading the entire dataset into memory. This can significantly reduce memory consumption.\n*   **Avoid Creating Copies:** Avoid creating unnecessary copies of data. Use in-place operations whenever possible.\n*   **Sparse Data Structures:**  For sparse datasets, consider using sparse data structures to reduce memory consumption.\n\n### 3.3 Rendering Optimization\n\n*   **Use Blitting:** Use blitting to redraw only the parts of the plot that have changed. This can significantly improve rendering speed for interactive plots.\n*   **Reduce Figure Size:** Reduce the size of the figure to improve rendering speed. Smaller figures require less memory and processing power.\n*   **Rasterize Vector Graphics:** For very complex plots, consider rasterizing vector graphics to reduce rendering time. Use the `rasterized=True` option in plotting functions.\n*   **Use Hardware Acceleration:** Ensure that Matplotlib is using hardware acceleration if available. This can significantly improve rendering speed.\n\n### 3.4 Bundle Size Optimization\n\n*   This is generally less relevant for Matplotlib as it's a backend library, not typically bundled for frontend use.\n*   However, if integrating Matplotlib plots into web applications, pre-render the images on the server-side and serve static images to the client.\n\n### 3.5 Lazy Loading\n\n*   Delay loading large datasets until they are needed. This can improve the startup time of your application.\n*   Load only the data that is visible in the plot. As the user zooms or pans, load additional data as needed.\n*   Use lazy loading techniques to create thumbnails or previews of plots without rendering the full plot.\n\n## 4. Security Best Practices\n\nWhile Matplotlib is primarily a visualization library, security considerations are important when dealing with untrusted data or integrating Matplotlib into web applications.\n\n### 4.1 Common Vulnerabilities\n\n*   **Code Injection:** If user-provided data is used to construct plot commands, it could lead to code injection vulnerabilities. Always sanitize user input before using it in plot commands.\n*   **Denial of Service (DoS):**  Creating extremely complex plots with large datasets can consume excessive resources and lead to DoS attacks. Implement resource limits and input validation to prevent this.\n*   **Cross-Site Scripting (XSS):** If integrating Matplotlib plots into web applications, be careful about how the plots are displayed.  Sanitize any user-provided data that is displayed in the plot to prevent XSS attacks.\n*   **Data Leakage:** Be cautious about displaying sensitive data in plots. Ensure that the data is properly anonymized or obfuscated before plotting it.\n\n### 4.2 Input Validation\n\n*   **Validate Data Types:** Ensure that the data used for plotting is of the expected type (e.g., numeric, date).\n*   **Validate Data Ranges:** Ensure that the data falls within the expected range. This can prevent unexpected behavior and potential errors.\n*   **Sanitize User Input:**  If user input is used to generate plot commands, sanitize the input to prevent code injection vulnerabilities.\n*   **Limit Input Size:** Limit the size of the input data to prevent DoS attacks.\n\n### 4.3 Authentication and Authorization\n\n*   This section is generally less relevant for Matplotlib, as it doesn't typically handle user authentication directly.\n*   If the visualizations are part of a larger application that has authentication, ensure that the correct users are authenticated before showing the plots.\n*   Implement authorization to control which users have access to specific plots or data.\n\n### 4.4 Data Protection\n\n*   **Anonymize Sensitive Data:**  Before plotting sensitive data, anonymize or obfuscate it to protect user privacy.\n*   **Use Secure Storage:** Store sensitive data securely, using encryption and access controls.\n*   **Comply with Regulations:** Ensure that your data handling practices comply with relevant regulations (e.g., GDPR, HIPAA).\n\n### 4.5 Secure API Communication\n\n*   If integrating Matplotlib plots into web applications, use secure API communication protocols (e.g., HTTPS).\n*   Validate and sanitize data received from APIs before using it in plots.\n*   Implement rate limiting to prevent API abuse.\n\n## 5. Testing Approaches\n\nThorough testing is essential to ensure the quality and reliability of your Matplotlib code. Unit tests, integration tests, and end-to-end tests all play a role in validating different aspects of your code.\n\n### 5.1 Unit Testing\n\n*   **Test Individual Functions and Classes:**  Write unit tests to verify the behavior of individual functions and classes in your plotting code.\n*   **Use Assertions:** Use assertions to check that the output of your functions is as expected.\n*   **Test Edge Cases:**  Test edge cases and boundary conditions to ensure that your code handles unexpected input gracefully.\n*   **Test Error Handling:**  Test that your code handles exceptions correctly.\n*   **Use Mocking:**  Use mocking to isolate units of code from their dependencies. This makes it easier to test units of code in isolation.\n*   **Parameterize Tests:** Write parameterized tests to test the same function with different inputs and expected outputs. This reduces code duplication and improves test coverage.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Modules:**  Write integration tests to verify that different modules in your plotting code work together correctly.\n*   **Test Data Flow:**  Test the flow of data through your plotting pipeline to ensure that data is processed correctly.\n*   **Test Plot Rendering:**  Test that plots are rendered correctly and that they contain the expected elements.\n*   **Test Data Integration:** Test the integration with data sources, ensuring that the data is loaded correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Plotting Workflow:** Write end-to-end tests to verify that the entire plotting workflow works correctly, from data loading to plot rendering.\n*   **Simulate User Interactions:** Simulate user interactions (e.g., zooming, panning, clicking) to test the behavior of interactive plots.\n*   **Verify Visual Output:**  Use visual testing tools to compare the rendered plots against baseline images. This can help you detect visual regressions.\n\n### 5.4 Test Organization\n\n*   **Create a Separate Test Directory:** Create a separate directory for your tests.\n*   **Use Descriptive Test Names:** Use descriptive test names that indicate what the test is verifying.\n*   **Organize Tests by Module:** Organize your tests by module to make it easier to find and run tests.\n*   **Use Test Runners:** Use test runners (e.g., `pytest`, `unittest`) to run your tests and generate reports.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock External Dependencies:** Mock external dependencies (e.g., data sources, APIs) to isolate units of code from their dependencies.\n*   **Stub Function Calls:** Stub function calls to control the behavior of functions that are called by the code under test.\n*   **Use Mocking Libraries:** Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to simplify the process of creating mocks and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\nKnowing common pitfalls and gotchas can save you a lot of time and frustration when working with Matplotlib.\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect Axis Limits:** Forgetting to set the correct axis limits can result in plots that are difficult to interpret.\n*   **Missing Labels and Titles:** Forgetting to add labels and titles to plots makes them less informative and harder to understand.\n*   **Overlapping Labels:** Overlapping labels can make plots difficult to read. Use techniques like rotation or alignment to avoid overlapping labels.\n*   **Incorrect Color Maps:** Using inappropriate color maps can distort the data and make it difficult to interpret the plots.\n*   **Not Handling Missing Data:** Not handling missing data can result in unexpected errors or incorrect plots. Use appropriate techniques to handle missing data (e.g., imputation, filtering).\n*   **Ignoring Aspect Ratio:** Ignoring the aspect ratio of the plot can result in distorted visualizations. Use `ax.set_aspect('equal')` to ensure that the aspect ratio is correct.\n\n### 6.2 Edge Cases\n\n*   **Empty Datasets:** Handle the case where the dataset is empty gracefully.\n*   **Non-Numeric Data:** Handle the case where the data contains non-numeric values.\n*   **Infinite Values:** Handle the case where the data contains infinite values.\n*   **NaN Values:** Handle the case where the data contains NaN (Not a Number) values.\n*   **Large Datasets:** Handle the case where the dataset is very large. Use techniques like data aggregation and lazy loading to improve performance.\n\n### 6.3 Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of Matplotlib. Consult the documentation for the specific version you are using.\n*   **Compatibility Issues:** Be aware of compatibility issues between Matplotlib and other libraries (e.g., NumPy, Pandas).\n*   **Bug Fixes:** Be aware of bug fixes in newer versions of Matplotlib. Upgrading to the latest version may resolve known issues.\n\n### 6.4 Compatibility Concerns\n\n*   **NumPy Version:** Ensure that your NumPy version is compatible with your Matplotlib version.\n*   **Pandas Version:** Ensure that your Pandas version is compatible with your Matplotlib version.\n*   **Operating System:** Be aware of potential compatibility issues between Matplotlib and different operating systems (e.g., Windows, macOS, Linux).\n*   **Backend Rendering Engine:** Be aware of potential compatibility issues between Matplotlib and different backend rendering engines (e.g., Agg, TkAgg, WebAgg).\n\n### 6.5 Debugging Strategies\n\n*   **Use Print Statements:** Use print statements to inspect the values of variables and data structures.\n*   **Use Debuggers:** Use debuggers (e.g., `pdb`, `ipdb`) to step through your code and examine the state of the program.\n*   **Use Logging:** Use logging to record events and errors in your code. This can help you identify and diagnose problems.\n*   **Simplify the Plot:** Simplify the plot to isolate the source of the problem. Remove unnecessary elements or reduce the amount of data being plotted.\n*   **Check the Documentation:** Consult the Matplotlib documentation for information about specific functions and methods.\n*   **Search Online:** Search online for solutions to common problems. Stack Overflow and other online forums can be valuable resources.\n*   **Isolate the issue**: Comment out portions of the plotting routine to isolate which sections are causing unexpected behavior.\n\n## 7. Tooling and Environment\n\nUsing the right tools and environment can significantly improve your productivity and the quality of your Matplotlib code.\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Use an Integrated Development Environment (IDE) such as VS Code, PyCharm, or Spyder. These tools provide features such as code completion, debugging, and testing.\n*   **Jupyter Notebooks:** Use Jupyter Notebooks for interactive exploration and development.\n*   **Virtual Environments:** Use virtual environments to isolate project dependencies.\n*   **Version Control:** Use version control systems (e.g., Git) to track changes to your code.\n\n### 7.2 Build Configuration\n\n*   **Use `requirements.txt`:** Create a `requirements.txt` file to specify project dependencies. Use `pip freeze > requirements.txt` to generate the file.\n*   **Use `setup.py`:** Create a `setup.py` file to package your plotting code into a reusable library. This file defines the metadata about the library (name, version, author, etc.) and the dependencies required to install it.\n*   **Use `pyproject.toml`:** For modern projects, consider using `pyproject.toml` to manage build dependencies and configurations. It offers a more standardized and flexible approach compared to `setup.py`.\n\n### 7.3 Linting and Formatting\n\n*   **Use Linters:** Use linters (e.g., `flake8`, `pylint`) to identify potential errors and style violations in your code.\n*   **Use Formatters:** Use formatters (e.g., `black`, `autopep8`) to automatically format your code according to PEP 8 style guidelines.\n*   **Configure IDE:** Configure your IDE to automatically run linters and formatters when you save your code.\n\n### 7.4 Deployment Best Practices\n\n*   **Containerization:** Use containerization technologies (e.g., Docker) to create portable and reproducible deployment environments. This ensures that your plotting code runs consistently across different platforms.\n*   **Cloud Platforms:** Deploy your plotting code to cloud platforms (e.g., AWS, Azure, Google Cloud) for scalability and reliability.\n*   **Serverless Functions:**  Consider using serverless functions to deploy individual plotting tasks as independent units. This can be a cost-effective way to run plotting code on demand.\n\n### 7.5 CI/CD Integration\n\n*   **Use CI/CD Pipelines:** Set up Continuous Integration/Continuous Deployment (CI/CD) pipelines to automate the build, test, and deployment process. This helps ensure that your code is always in a releasable state.\n*   **Run Tests Automatically:** Configure your CI/CD pipeline to automatically run tests whenever you commit code. This helps you catch errors early.\n*   **Deploy Automatically:** Configure your CI/CD pipeline to automatically deploy your code to production environments after it has passed all tests.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "matplotlib.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "matplotlib",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "developing",
      "robust",
      "maintainable",
      "performant",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "matplotlib",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-maven",
    "description": "Comprehensive guidelines for effective Maven project management, covering code organization, dependency management, performance optimization, and security best practices. This rule provides actionable advice to avoid common pitfalls and promote maintainable, scalable Maven projects.",
    "author": "sanjeed5",
    "tags": [
      "maven",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/maven.mdc",
    "content": "---\n- **Introduction**\n  This guide provides comprehensive best practices for effectively using Maven in Java development, focusing on code organization, dependency management, performance, security, testing, and tooling. Adhering to these guidelines will result in more maintainable, scalable, and robust Maven projects.\n\n- **Code Organization and Structure**\n\n  - **Standard Directory Structure:**\n    - Follow the standard Maven directory structure for consistency and ease of understanding:\n      \n      project-root/\n      ├── src/\n      │   ├── main/\n      │   │   ├── java/      # Source code\n      │   │   ├── resources/ # Resources (e.g., properties files)\n      │   ├── test/\n      │   │   ├── java/      # Test code\n      │   │   ├── resources/ # Test resources\n      ├── pom.xml            # Maven project definition\n      \n  - **File Naming Conventions:**\n    - Java source files: `YourClass.java`\n    - Resource files: `application.properties`, `log4j2.xml`\n    - POM files: `pom.xml`\n  - **Module Organization (Multi-Module Projects):**\n    - For larger projects, consider using a multi-module structure:\n      \n      parent-project/\n      ├── pom.xml            # Parent POM (defines dependencies, plugins, versions)\n      ├── module1/\n      │   └── pom.xml        # Module-specific POM\n      ├── module2/\n      │   └── pom.xml\n      └── ...\n      \n    - Parent POM handles shared configurations.\n    - Each module has its specific functionality and dependencies.\n  - **Component Architecture:**\n    - Organize code into logical components (e.g., data access, business logic, UI).\n    - Use interfaces to define contracts between components.\n    - Employ dependency injection to manage component dependencies.\n  - **Code Splitting Strategies:**\n    - Split large classes into smaller, more manageable units based on functionality.\n    - Create utility classes for reusable code.\n    - Break down complex processes into separate methods.\n\n- **Common Patterns and Anti-patterns**\n\n  - **Design Patterns:**\n    - **Factory Pattern:**  Use factories to create instances of objects, especially when the exact type of object needed is not known at compile time.\n    - **Singleton Pattern:** Ensure only one instance of a class exists (use with caution).\n    - **Strategy Pattern:** Define a family of algorithms, encapsulate each one, and make them interchangeable.\n  - **Recommended Approaches:**\n    - **Dependency Injection:** Use frameworks like Spring to manage dependencies and improve testability.\n    - **Configuration Management:** Externalize configuration using properties files or environment variables.\n    - **Logging:**  Use a logging framework like Log4j 2 or SLF4J for consistent logging practices.\n  - **Anti-Patterns:**\n    - **God Classes:** Avoid large, monolithic classes that handle too many responsibilities.\n    - **Copy-Paste Programming:**  Extract common code into reusable methods or classes.\n    - **Ignoring Exceptions:**  Always handle exceptions properly; don't just catch and ignore them.\n    - **Hardcoding Values:**  Externalize configuration values to avoid hardcoding.\n  - **State Management:**\n    - For web applications, use session management carefully.\n    - Avoid storing sensitive data in sessions.\n    - Use appropriate scoping for managed beans (e.g., request, session, application).\n  - **Error Handling:**\n    - Use try-catch blocks to handle exceptions gracefully.\n    - Log exceptions with sufficient context.\n    - Provide user-friendly error messages.\n    - Use custom exception classes to represent specific error conditions.\n\n- **Performance Considerations**\n\n  - **Optimization Techniques:**\n    - **Profiling:** Use profiling tools (e.g., VisualVM, YourKit) to identify performance bottlenecks.\n    - **Caching:** Implement caching (e.g., using Ehcache or Redis) to reduce database load and improve response times.\n    - **Connection Pooling:** Use connection pooling to manage database connections efficiently.\n    - **Efficient Data Structures:**  Choose appropriate data structures for your specific needs (e.g., HashMap, ArrayList).\n    - **Optimize Database Queries:** Use indexes, avoid full table scans, and optimize SQL queries.\n  - **Memory Management:**\n    - **Garbage Collection:** Understand how garbage collection works and tune JVM settings if necessary.\n    - **Object Pooling:**  Use object pooling for frequently created and destroyed objects.\n    - **Avoid Memory Leaks:**  Ensure resources are properly released to prevent memory leaks.\n  - **Bundle Size Optimization:**\n    - Use ProGuard or other code shrinking tools to reduce the size of JAR files.\n    - Remove unused dependencies.\n    - Optimize resource files (e.g., compress images).\n  - **Lazy Loading:**\n    - Use lazy loading for resources or data that are not immediately needed.\n    - Implement pagination for large datasets.\n\n- **Security Best Practices**\n\n  - **Common Vulnerabilities:**\n    - **Dependency Vulnerabilities:** Regularly scan dependencies for known vulnerabilities (using Snyk, OWASP Dependency-Check).\n    - **SQL Injection:**  Use parameterized queries or ORM frameworks to prevent SQL injection.\n    - **Cross-Site Scripting (XSS):**  Encode user input properly to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):**  Implement CSRF protection mechanisms.\n    - **Authentication and Authorization Flaws:** Use strong authentication and authorization mechanisms.\n  - **Input Validation:**\n    - Validate all user input to prevent malicious data from entering the system.\n    - Use whitelisting to define allowed values.\n    - Sanitize input to remove potentially harmful characters.\n  - **Authentication and Authorization:**\n    - Use a secure authentication mechanism (e.g., OAuth 2.0, OpenID Connect).\n    - Implement role-based access control (RBAC) to restrict access to resources.\n    - Use strong password policies.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication.\n    - Store passwords securely using hashing algorithms (e.g., bcrypt).\n  - **Secure API Communication:**\n    - Use API keys or OAuth 2.0 to authenticate API requests.\n    - Validate API requests to prevent malicious input.\n    - Limit the rate of API requests to prevent abuse.\n\n- **Testing Approaches**\n\n  - **Unit Testing:**\n    - Use JUnit or TestNG for unit testing.\n    - Write tests for all critical components and methods.\n    - Use mocking frameworks (e.g., Mockito, EasyMock) to isolate units under test.\n    - Aim for high code coverage.\n  - **Integration Testing:**\n    - Test the interaction between different components or services.\n    - Use embedded databases or mock services for testing.\n    - Test data access layers, API endpoints, and message queues.\n  - **End-to-End Testing:**\n    - Simulate real user scenarios to test the entire application flow.\n    - Use testing frameworks like Selenium or Cypress.\n    - Test the user interface, business logic, and data access layers.\n  - **Test Organization:**\n    - Place test code in the `src/test/java` directory.\n    - Organize tests into packages that mirror the source code structure.\n    - Use descriptive test names.\n  - **Mocking and Stubbing:**\n    - Use mocking frameworks to create mock objects for dependencies.\n    - Use stubs to provide predefined responses for method calls.\n    - Avoid over-mocking; test the actual behavior when possible.\n\n- **Common Pitfalls and Gotchas**\n\n  - **Dependency Conflicts:**  Use `mvn dependency:tree` to identify and resolve dependency conflicts. Use `<dependencyManagement>` to control versions.\n  - **Version Mismatches:** Ensure all modules in a multi-module project use compatible versions of dependencies.\n  - **Transitive Dependencies:** Be aware of transitive dependencies and their potential impact on your project.\n  - **Incorrect Scopes:** Use the correct dependency scopes (e.g., compile, runtime, test, provided) to avoid including unnecessary dependencies in the final artifact.\n  - **Snapshot Dependencies:** Avoid using snapshot dependencies in production environments.\n\n- **Tooling and Environment**\n\n  - **Recommended Development Tools:**\n    - **IDE:** IntelliJ IDEA, Eclipse, NetBeans\n    - **Build Tool:** Apache Maven\n    - **Version Control:** Git\n    - **Dependency Scanning:** Snyk, OWASP Dependency-Check\n    - **Static Analysis:** SonarQube, FindBugs\n  - **Build Configuration:**\n    - Use properties to define reusable values (e.g., versions, file paths).\n    - Configure plugins properly and use appropriate versions.\n    - Use profiles to manage different build configurations (e.g., development, production).\n  - **Linting and Formatting:**\n    - Use code formatters (e.g., IntelliJ IDEA code style, Eclipse code formatter) to ensure consistent code formatting.\n    - Use static analysis tools to identify potential issues.\n  - **Deployment:**\n    - Use Maven plugins (e.g., `maven-deploy-plugin`) to deploy artifacts to a repository.\n    - Use configuration management tools (e.g., Ansible, Chef, Puppet) to automate deployment.\n    - Follow best practices for deploying Java applications (e.g., using application servers, containers).\n  - **CI/CD Integration:**\n    - Integrate Maven builds with CI/CD pipelines (e.g., Jenkins, GitLab CI, GitHub Actions).\n    - Automate testing, code analysis, and deployment.\n    - Use build automation tools to manage the build process.\n\n- **Conclusion**\n  By adhering to these best practices, you can build robust, maintainable, and secure Maven projects. Regular code reviews, continuous integration, and proactive dependency management will further enhance the quality and reliability of your software.",
    "metadata": {
      "globs": "**/pom.xml",
      "format": "mdc",
      "originalFile": "maven.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "maven",
      "comprehensive",
      "guidelines",
      "effective",
      "project",
      "management",
      "covering",
      "code",
      "organization",
      "dependency",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "maven",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-microsoft-teams",
    "description": "This rule provides best practices for developing with Microsoft Teams, covering code organization, performance, security, testing, and common pitfalls. Adhering to these guidelines will ensure robust, maintainable, and secure Teams applications.",
    "author": "sanjeed5",
    "tags": [
      "microsoft-teams",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/microsoft-teams.mdc",
    "content": "- # Code Organization and Structure\n  - Effective code organization is critical for maintainability and scalability in Microsoft Teams application development.\n\n  - ## Directory Structure Best Practices\n    - **src/**: Contains all source code.\n      - **components/**: Reusable UI components.\n      - **modules/**: Independent, reusable modules with specific functionalities (e.g., authentication, data fetching).\n      - **pages/** or **views/**: Top-level components representing different application views/pages.\n      - **services/**: Code interacting with Microsoft Teams APIs or other external services.\n      - **utils/** or **helpers/**: Utility functions, constants, and helper classes.\n      - **styles/**: CSS, SCSS, or other styling-related files.\n      - **types/**: TypeScript type definitions (if using TypeScript).\n    - **public/**: Static assets (images, fonts, etc.).\n    - **tests/**: Unit, integration, and end-to-end tests.\n    - **.cursor/**: Stores Cursor-specific project rules.\n\n  - ## File Naming Conventions\n    - **Components:** PascalCase (e.g., `MyTeamsComponent.tsx`).\n    - **Modules:** camelCase (e.g., `teamsAuthentication.ts`).\n    - **Styles:** kebab-case (e.g., `my-teams-component.scss`).\n    - **Tests:** `<filename>.test.ts` or `<filename>.spec.ts` (e.g., `MyTeamsComponent.test.tsx`).\n    - **Interfaces/Types:** Capitalized with a leading `I` if an interface (e.g., `IUser.ts`).\n\n  - ## Module Organization\n    - Favor small, focused modules with clear responsibilities.\n    - Use dependency injection to manage dependencies between modules.\n    - Consider using an inversion of control (IoC) container for more complex applications.\n\n  - ## Component Architecture\n    - **Presentational Components:** Responsible for rendering UI; receive data and callbacks as props.\n    - **Container Components:** Fetch data, manage state, and pass data to presentational components.\n    - Consider using a state management library like Redux, Zustand, or Jotai for complex applications.\n\n  - ## Code Splitting\n    - Use dynamic imports to lazy-load modules and components.\n    - Implement route-based code splitting to reduce the initial bundle size.\n    - Analyze bundle size using tools like Webpack Bundle Analyzer to identify large dependencies.\n\n- # Common Patterns and Anti-patterns\n  - Employing established design patterns and avoiding anti-patterns are crucial for writing clean, maintainable code in Microsoft Teams development.\n\n  - ## Design Patterns\n    - **Observer Pattern:** Useful for subscribing components to changes in Teams state (e.g., user presence, channel messages).\n    - **Factory Pattern:** Abstract component creation to simplify management of different Teams context variables or user settings.\n    - **Strategy Pattern:** To handle different API authentication approaches and use appropriate logic depending on where code is run (webpage or Teams client)\n    - **Facade Pattern:** Simplify complex Teams API interactions by providing a higher-level interface.\n\n  - ## Recommended Approaches\n    - Use the Microsoft Teams Client SDK for interacting with the Teams client.\n    - Prefer asynchronous operations to avoid blocking the UI thread.\n    - Implement proper error handling for API calls and user input.\n    - Adopt responsive design principles to ensure your application works well on different screen sizes.\n\n  - ## Anti-patterns and Code Smells\n    - **Deeply Nested Components:** Leads to performance issues and difficulty in understanding the component hierarchy.\n    - **God Objects:** Modules or components with too many responsibilities.\n    - **Copy-Pasted Code:** Indicates a lack of proper abstraction and code reuse.\n    - **Ignoring Errors:** Can lead to unexpected behavior and difficult-to-debug issues.\n    - **Over-reliance on `any` Type (TypeScript):** Reduces the benefits of TypeScript's type safety.\n\n  - ## State Management\n    - For simple components, use React's built-in `useState` hook.\n    - For complex applications, consider using a state management library:\n      - **Redux:** Predictable state container with a centralized store and unidirectional data flow.\n      - **Zustand:** Small, fast, and scalable bearbones state-management solution.\n      - **Jotai:** Primitive and flexible state management with an atomic model.\n    - Avoid mutating state directly; use immutability techniques.\n\n  - ## Error Handling\n    - Use `try...catch` blocks to handle exceptions gracefully.\n    - Implement global error handling to catch unhandled exceptions.\n    - Log errors to a central location for monitoring and debugging.\n    - Provide informative error messages to the user.\n\n- # Performance Considerations\n  - Optimizing performance is crucial for providing a smooth user experience in Microsoft Teams applications.\n\n  - ## Optimization Techniques\n    - **Memoization:** Cache the results of expensive function calls to avoid redundant computations.\n    - **Debouncing and Throttling:** Limit the rate at which functions are executed in response to user input.\n    - **Virtualization:** Render only the visible portion of large lists or tables.\n    - **Code Splitting:** As mentioned earlier, divide code into smaller chunks to reduce initial load time.\n    - **Efficient Data Structures:** Use appropriate data structures for optimal performance (e.g., Maps instead of Objects for frequent lookups).\n\n  - ## Memory Management\n    - Avoid memory leaks by properly cleaning up resources (e.g., event listeners, timers).\n    - Use weak references when necessary to avoid preventing garbage collection.\n    - Monitor memory usage using browser developer tools to identify potential issues.\n\n  - ## Rendering Optimization\n    - Use React.memo or similar techniques to prevent unnecessary re-renders.\n    - Optimize images and other assets to reduce file size.\n    - Minimize DOM manipulations.\n\n  - ## Bundle Size Optimization\n    - Use tree shaking to remove unused code from dependencies.\n    - Minify and compress code using tools like Terser and Gzip.\n    - Analyze bundle size to identify large dependencies and consider alternatives.\n\n  - ## Lazy Loading\n    - Lazy-load images and other assets that are not immediately visible.\n    - Use Intersection Observer API to detect when elements are visible.\n    - Lazy load modules by incorporating `React.lazy` and `Suspense`.\n\n- # Security Best Practices\n  - Security is paramount when developing Microsoft Teams applications to protect user data and prevent vulnerabilities.\n\n  - ## Common Vulnerabilities\n    - **Cross-Site Scripting (XSS):** Injecting malicious scripts into the application.\n    - **Cross-Site Request Forgery (CSRF):** Attacking users into performing actions without their consent.\n    - **Authentication and Authorization Flaws:** Improperly securing user authentication and authorization mechanisms.\n    - **Data Injection:** SQL injection, LDAP injection, etc.\n\n  - ## Prevention Strategies\n    - **Input Validation:** Sanitize and validate all user input to prevent injection attacks.\n    - **Output Encoding:** Escape output to prevent XSS attacks.\n    - **Content Security Policy (CSP):** Configure CSP to restrict the sources of content that the browser is allowed to load.\n    - **Regular Security Audits:** Conduct regular security audits to identify and address vulnerabilities.\n\n  - ## Authentication and Authorization\n    - Use OAuth 2.0 for secure authentication and authorization.\n    - Implement proper role-based access control (RBAC) to restrict access to sensitive data and functionality.\n    - Store credentials securely using appropriate encryption and hashing techniques.\n\n  - ## Data Protection\n    - Encrypt sensitive data at rest and in transit.\n    - Implement data loss prevention (DLP) policies to prevent sensitive information from being shared inappropriately.\n    - Follow privacy best practices to protect user data.\n\n  - ## Secure API Communication\n    - Use HTTPS for all API communication.\n    - Validate server-side certificate.\n    - Implement proper authentication and authorization for API endpoints.\n    - Use rate limiting to prevent denial-of-service attacks.\n\n- # Testing Approaches\n  - Comprehensive testing is essential for ensuring the quality and reliability of Microsoft Teams applications.\n\n  - ## Unit Testing\n    - Test individual components and modules in isolation.\n    - Use mocking and stubbing to isolate dependencies.\n    - Aim for high code coverage to ensure that all parts of the code are tested.\n\n  - ## Integration Testing\n    - Test the interaction between different components and modules.\n    - Verify that data flows correctly between different parts of the application.\n    - Test integrations with Microsoft Teams APIs and other external services.\n\n  - ## End-to-End Testing\n    - Test the entire application flow from the user's perspective.\n    - Simulate real-world user scenarios.\n    - Use tools like Cypress or Playwright to automate end-to-end tests.\n\n  - ## Test Organization\n    - Organize tests into logical groups based on functionality or component.\n    - Use clear and descriptive test names.\n    - Keep tests small and focused.\n\n  - ## Mocking and Stubbing\n    - Use mocking libraries like Jest or Sinon.js to create mocks and stubs.\n    - Mock external dependencies to isolate the code under test.\n    - Use stubs to provide controlled responses from dependencies.\n\n- # Common Pitfalls and Gotchas\n  - Being aware of common pitfalls and gotchas can save developers time and effort when developing Microsoft Teams applications.\n\n  - ## Frequent Mistakes\n    - Improperly handling asynchronous operations.\n    - Not validating user input.\n    - Exposing sensitive data in the client-side code.\n    - Failing to handle errors gracefully.\n    - Neglecting performance optimization.\n    - Not localizing application for different locales\n\n  - ## Edge Cases\n    - Handling different Teams client versions and platforms.\n    - Dealing with network connectivity issues.\n    - Handling unexpected API responses.\n    - Managing different user roles and permissions.\n    - Handling large data sets.\n\n  - ## Version-Specific Issues\n    - Be aware of breaking changes in Microsoft Teams API updates.\n    - Test your application with different Teams client versions.\n    - Use feature detection to adapt to different API capabilities.\n\n  - ## Compatibility Concerns\n    - Ensure that your application is compatible with different browsers and devices.\n    - Test your application with different operating systems.\n    - Use polyfills to support older browsers.\n\n  - ## Debugging Strategies\n    - Use browser developer tools to debug client-side code.\n    - Use logging to track application flow and identify errors.\n    - Use remote debugging to debug server-side code.\n    - Use a debugger to step through code and inspect variables.\n\n- # Tooling and Environment\n  - Choosing the right tools and environment can significantly improve the development experience for Microsoft Teams applications.\n\n  - ## Recommended Development Tools\n    - **Visual Studio Code:** Code editor with excellent TypeScript support and debugging capabilities.\n    - **Microsoft Teams Toolkit:** Provides templates and tools for creating and deploying Teams applications.\n    - **Node.js:** JavaScript runtime environment for server-side development.\n    - **NPM or Yarn:** Package managers for managing dependencies.\n    - **Webpack or Parcel:** Module bundlers for bundling code and assets.\n    - **React Developer Tools:** Browser extension for debugging React components.\n\n  - ## Build Configuration\n    - Use a build system like Webpack or Parcel to automate the build process.\n    - Configure the build system to optimize code for production (e.g., minification, compression).\n    - Use environment variables to manage different configuration settings for different environments.\n\n  - ## Linting and Formatting\n    - Use ESLint or TSLint to enforce coding style and prevent errors.\n    - Use Prettier to automatically format code.\n    - Configure the code editor to automatically format code on save.\n\n  - ## Deployment\n    - Deploy your application to Azure or another cloud provider.\n    - Use Microsoft Teams App Studio to create and manage your Teams app package.\n    - Submit your app to the Microsoft Teams app store for wider distribution.\n\n  - ## CI/CD Integration\n    - Use a CI/CD system like Azure DevOps, GitHub Actions, or Jenkins to automate the build, test, and deployment process.\n    - Configure the CI/CD system to run tests and linters automatically.\n    - Use automated deployments to deploy changes to production quickly and reliably.\n\n- # Additional Best Practices\n    - **Accessibility:** Ensure your application is accessible to users with disabilities.\n    - **Localization:** Localize your application for different languages and regions.\n    - **Documentation:** Write clear and concise documentation for your code.\n    - **Collaboration:** Use a version control system like Git to collaborate with other developers.\n    - **Stay Up-to-Date:** Keep up with the latest Microsoft Teams API updates and best practices.\n\n\nBy adhering to these best practices, developers can create robust, maintainable, secure, and high-performing Microsoft Teams applications that provide a great user experience.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "microsoft-teams.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "microsoft",
      "teams",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "microsoft-teams",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "microsoft-teams",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-mkdocs",
    "description": "Comprehensive guidelines for mkdocs development, covering code organization, best practices, performance, security, testing, common pitfalls, and tooling. This rule aims to ensure maintainable, performant, and secure documentation using mkdocs.",
    "author": "sanjeed5",
    "tags": [
      "mkdocs",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mkdocs.mdc",
    "content": "# mkdocs Best Practices\n\nThis document provides comprehensive guidelines for developing documentation using mkdocs. It covers various aspects including code organization, common patterns, performance, security, testing, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n-   **docs/**: All documentation source files should reside within this directory. This is the default and recommended location for mkdocs.\n    -   `index.md`: The project homepage.\n    -   `about.md`: An example of another page.\n    -   `user-guide/`: A subdirectory for a section of documentation.\n        -   `getting-started.md`: A sub-page within the user guide.\n        -   `configuration-options.md`: Another sub-page.\n    -   `img/`: A directory to store images used in the documentation. Store your images as close as possible to the document that references it.\n        -   `screenshot.png`\n-   **mkdocs.yml**: The main configuration file for mkdocs, located at the root of the project alongside the `docs/` directory.\n\nExample:\n\n\nmkdocs.yml\ndocs/\n  index.md\n  about.md\n  license.md\n  img/\n    screenshot.png\nuser-guide/\n    getting-started.md\n    configuration-options.md\n\n\n### 1.2. File Naming Conventions\n\n-   Use `.md` as the extension for Markdown files.\n-   Name the homepage `index.md` or `README.md`.\n-   Use descriptive names for other pages (e.g., `getting-started.md`, `configuration-options.md`).\n-   Use lowercase and hyphens for file names to create clean URLs.\n\n### 1.3. Module Organization\n\n-   mkdocs itself doesn't have modules in the traditional programming sense. Structure your documentation content logically into sections and sub-sections using directories and files.\n-   Use the `nav` configuration in `mkdocs.yml` to define the structure of the navigation menu.\n\nExample:\n\n\nnav:\n  - Home: index.md\n  - User Guide:\n    - Getting Started: user-guide/getting-started.md\n    - Configuration Options: user-guide/configuration-options.md\n  - About: about.md\n  - License: license.md\n\n\n### 1.4. Component Architecture\n\n-   mkdocs is not a component-based system like React or Vue.js.\n-   Instead, think of each Markdown file as a page or section of your documentation.\n-   Use includes or macros (via plugins) to reuse content across multiple pages (see Snippets and Includes section).\n\n### 1.5. Code Splitting Strategies\n\n-   Divide your documentation into logical sections and sub-sections.\n-   Create separate Markdown files for each section.\n-   Use the `nav` configuration to structure the navigation menu.\n-   Use `include-markdown` plugin to avoid repeating content in multiple pages.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to mkdocs\n\n-   **Navigation as Code**: Managing the navigation structure directly within `mkdocs.yml` is a fundamental pattern. It allows for centralized control over the site's hierarchy.\n-   **Content Reusability**: Utilizing plugins like `include-markdown` to reuse common elements like disclaimers, notices, or standard procedures.\n-   **Theming Customization**: Overriding the default theme templates to tailor the look and feel of the documentation to match branding or specific aesthetic requirements.\n-   **Plugin Extension**: Extending the functionality of mkdocs by using and customizing existing plugins or creating custom ones to fulfill specific documentation needs, such as generating API documentation or integrating with external tools.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Linking to Pages**: Use relative paths for internal links to avoid issues when deploying (e.g., `[link to about](about.md)`).\n-   **Linking to Sections**: Use anchor links to link to specific sections within a page (e.g., `[link to license](about.md#license)`).\n-   **Including Images**: Place images in the `docs/img/` directory and link to them using relative paths (e.g., `![Screenshot](img/screenshot.png)`).\n-   **Adding Meta-Data**: Add YAML or MultiMarkdown style meta-data to the beginning of Markdown files to control page templates or add information such as authors or descriptions.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n-   **Absolute Paths in Links**: Avoid using absolute paths for internal links. Use relative paths instead.\n-   **Large Markdown Files**: Avoid creating very large Markdown files. Break them into smaller, more manageable files and use the `nav` configuration to link them.\n-   **Ignoring the `nav` Configuration**: Relying on the automatic navigation generation instead of explicitly defining it in `mkdocs.yml` can lead to a disorganized navigation menu.\n-   **Over-Customization**: Excessively customizing the theme or adding too many plugins can make the documentation difficult to maintain and update.\n-   **Lack of a Clear File Structure**: An unstructured or inconsistent file structure makes it difficult to navigate and understand the documentation.\n\n### 2.4. State Management Best Practices\n\n-   mkdocs is a static site generator, so it doesn't have a traditional concept of state management.\n-   However, you can use plugins to add dynamic content or interact with external data sources.\n\n### 2.5. Error Handling Patterns\n\n-   mkdocs doesn't have runtime error handling in the traditional sense.\n-   Errors typically occur during the build process (e.g., invalid configuration, broken links).\n-   Use a CI/CD pipeline to automatically build and test the documentation and catch errors early.\n-   Utilize linters and validators (plugins) to ensure the integrity of your Markdown and configuration files.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Optimize Images**: Use optimized images to reduce file sizes and improve loading times.\n-   **Minify HTML, CSS, and JavaScript**: Use the `mkdocs-minify-plugin` to minify the generated HTML, CSS, and JavaScript files.\n-   **Lazy Loading Images**: Lazy load images below the fold to improve initial page load time.\n-   **Use a CDN**: Use a CDN (Content Delivery Network) to serve static assets (images, CSS, JavaScript) from multiple locations around the world.\n\n### 3.2. Memory Management\n\n-   mkdocs itself doesn't have specific memory management considerations.\n-   However, if you're using plugins that generate dynamic content, be mindful of memory usage.\n\n### 3.3. Rendering Optimization\n\n-   mkdocs generates static HTML files, so rendering performance is generally not a concern.\n-   However, complex Markdown structures can slow down the build process. Keep your Markdown files as simple as possible.\n\n### 3.4. Bundle Size Optimization\n\n-   Optimize the size of your images and other static assets.\n-   Use the `mkdocs-minify-plugin` to minify the generated HTML, CSS, and JavaScript files.\n-   Avoid including unnecessary CSS or JavaScript in your theme.\n\n### 3.5. Lazy Loading Strategies\n\n-   Implement lazy loading for images using JavaScript.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n-   **Cross-Site Scripting (XSS)**: Since mkdocs generates static sites, the risk of XSS is minimal, but if you incorporate user-generated content or external data, sanitize inputs properly.\n-   **Injection Attacks**: Avoid using untrusted data to generate content. If you must use untrusted data, sanitize it properly.\n\n### 4.2. Input Validation\n\n-   If your mkdocs site incorporates forms or user input via plugins, validate all inputs to prevent injection attacks.\n\n### 4.3. Authentication and Authorization Patterns\n\n-   mkdocs doesn't provide built-in authentication or authorization.\n-   If you need to protect certain pages, you can implement authentication at the web server level or use a plugin.\n\n### 4.4. Data Protection Strategies\n\n-   Since mkdocs generates static sites, there is no sensitive data stored on the server.\n-   However, be careful not to include sensitive information in your documentation source files.\n\n### 4.5. Secure API Communication\n\n-   If your mkdocs site communicates with external APIs, use HTTPS to encrypt the communication.\n-   Verify the API server's SSL certificate.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n-   mkdocs itself doesn't have unit tests in the traditional programming sense.\n-   However, if you create custom plugins, you should write unit tests for them.\n\n### 5.2. Integration Testing\n\n-   Create integration tests to verify that your mkdocs site is built correctly and that all links are working.\n-   Use a tool like `htmlproofer` to validate URLs in the rendered HTML files.\n\n### 5.3. End-to-end Testing\n\n-   Use an end-to-end testing framework to verify that your mkdocs site is working as expected in a browser.\n\n### 5.4. Test Organization\n\n-   Organize your tests into separate directories (e.g., `tests/`).\n-   Use descriptive names for your test files and test functions.\n\n### 5.5. Mocking and Stubbing\n\n-   If you're testing custom plugins that interact with external APIs, use mocking and stubbing to isolate your tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n-   **Incorrect File Paths**: Using incorrect file paths in links or image references.\n-   **Ignoring the `nav` Configuration**: Relying on the automatic navigation generation instead of explicitly defining it in `mkdocs.yml`.\n-   **Over-Customization**: Customizing the theme too much can make the documentation difficult to maintain and update.\n-   **Not Keeping Documentation Up-to-Date**: Forgetting to update the documentation when the codebase changes.\n\n### 6.2. Edge Cases to Be Aware Of\n\n-   **Long File Paths**: Long file paths can cause issues on some operating systems.\n-   **Special Characters in File Names**: Avoid using special characters in file names.\n-   **Conflicting Plugin Options**: Some plugins may have conflicting options.\n\n### 6.3. Version-Specific Issues\n\n-   mkdocs is constantly evolving, so be aware of version-specific issues.\n-   Always test your documentation with the latest version of mkdocs before deploying.\n\n### 6.4. Compatibility Concerns\n\n-   Ensure that your documentation is compatible with different browsers and devices.\n-   Test your documentation on different platforms to ensure that it looks good everywhere.\n\n### 6.5. Debugging Strategies\n\n-   **Check the mkdocs Build Log**: The mkdocs build log contains valuable information about errors and warnings.\n-   **Use a Debugger**: Use a debugger to step through the mkdocs build process and identify issues.\n-   **Simplify Your Configuration**: Simplify your `mkdocs.yml` file to isolate the issue.\n-   **Disable Plugins**: Disable plugins one by one to identify the plugin causing the issue.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **Text Editor**: VS Code, Sublime Text, Atom\n-   **Markdown Editor**: Typora, Mark Text\n-   **Web Browser**: Chrome, Firefox, Safari\n-   **mkdocs CLI**: The mkdocs command-line interface.\n\n### 7.2. Build Configuration\n\n-   Use a `mkdocs.yml` file to configure your mkdocs site.\n-   The `mkdocs.yml` file should be located at the root of your project.\n-   The `mkdocs.yml` file should contain the following information:\n    -   `site_name`: The name of your site.\n    -   `site_description`: A description of your site.\n    -   `site_author`: The author of your site.\n    -   `docs_dir`: The directory containing your documentation source files.\n    -   `theme`: The theme to use for your site.\n    -   `nav`: The navigation menu for your site.\n    -   `markdown_extensions`: A list of Markdown extensions to enable.\n    -   `plugins`: A list of plugins to enable.\n\n### 7.3. Linting and Formatting\n\n-   Use a linter to enforce code style and identify potential issues.\n-   Use a formatter to automatically format your Markdown files.\n\n### 7.4. Deployment Best Practices\n\n-   **Use a CI/CD Pipeline**: Use a CI/CD pipeline to automatically build and deploy your mkdocs site.\n-   **Deploy to a CDN**: Deploy your mkdocs site to a CDN to improve performance.\n-   **Use HTTPS**: Use HTTPS to encrypt communication with your site.\n-   **Configure a Custom Domain**: Configure a custom domain for your site.\n\n### 7.5. CI/CD Integration\n\n-   Use a CI/CD tool like GitHub Actions, GitLab CI, or Travis CI to automatically build and deploy your mkdocs site.\n-   Configure your CI/CD pipeline to run tests and linters.\n-   Configure your CI/CD pipeline to deploy your site to a CDN.\n\n## Additional Notes\n\n-   Always refer to the official mkdocs documentation for the most up-to-date information.\n-   Consider contributing to the mkdocs community by creating plugins or themes.\n-   Stay informed about the latest best practices and security vulnerabilities.\n\nThis comprehensive guide should help you create maintainable, performant, and secure documentation using mkdocs.",
    "metadata": {
      "globs": "*.md",
      "format": "mdc",
      "originalFile": "mkdocs.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "mkdocs",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "organization",
      "best",
      "practices",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mkdocs",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-mlx",
    "description": "This rule provides comprehensive best practices for the MLX library, covering code organization, performance, security, testing, and common pitfalls. It aims to promote consistent, efficient, and maintainable code when working with MLX on Apple platforms.",
    "author": "sanjeed5",
    "tags": [
      "mlx",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mlx.mdc",
    "content": "# MLX Library Best Practices\n\nThis document outlines the recommended best practices and coding standards for developing applications using the MLX library on Apple platforms, primarily using Swift. Following these guidelines will help ensure code quality, maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\nA well-structured project is crucial for scalability and maintainability. Here's how to organize your MLX projects effectively:\n\n### 1.1. Directory Structure\n\nAdopt a modular directory structure that separates concerns and promotes reusability. A typical project structure might look like this:\n\n\nMyMLXProject/\n├── Data/\n│   ├── Datasets.swift         # Classes/structs for handling datasets\n│   ├── Preprocessing.swift    # Data preprocessing utilities\n├── Models/\n│   ├── ModelDefinitions.swift # MLX Model Definitions (structs/classes)\n│   ├── Layers.swift           # Custom layers for your models\n│   ├── LossFunctions.swift    # Loss functions for training\n├── Training/\n│   ├── Trainer.swift          # Training loop and optimization logic\n│   ├── Metrics.swift          # Evaluation metrics\n├── Inference/\n│   ├── InferenceEngine.swift  # Model inference and prediction code\n├── Utilities/\n│   ├── Helpers.swift          # Helper functions and extensions\n│   ├── Configuration.swift   # Project configuration settings\n├── UI/\n│   ├── ViewControllers.swift  # UI-related code (if applicable)\n│   ├── Views.swift           # Custom UI views\n├── Tests/\n│   ├── UnitTests.swift        # Unit tests for individual components\n│   ├── IntegrationTests.swift # Integration tests for the application\n├── MyMLXProject.xcodeproj   # Xcode project file\n├── Podfile                   # CocoaPods dependencies (if using)\n├── Package.swift             # Swift Package Manager manifest (if using)\n\n\n### 1.2. File Naming Conventions\n\n- Use descriptive and consistent names for your files.\n- Follow the `PascalCase` convention for Swift files (e.g., `ModelDefinitions.swift`).\n- Name files according to the primary type or functionality they contain.\n- Use suffixes like `View`, `Controller`, `Model`, `Helper`, `Manager` to clearly indicate the role of the file.\n\n### 1.3. Module Organization\n\n- Organize your code into logical modules or Swift packages using Swift Package Manager (SPM).\n- Each module should encapsulate a specific set of functionalities, such as data processing, model definitions, or training logic.\n- Modules should have well-defined interfaces and minimize dependencies between them to promote reusability and testability.\n\n### 1.4. Component Architecture\n\nConsider using established architectural patterns like MVVM (Model-View-ViewModel) or VIPER (View-Interactor-Presenter-Entity-Router), especially for applications with a UI. However, even in non-UI projects:\n\n- **Data Layer**: Responsible for data loading, preprocessing, and storage.  This could interface with Core Data, files, or network resources.\n- **Model Layer**:  Holds the MLX model definitions, custom layers, and any associated logic.  Focus on making these types lightweight and easily serializable (if needed).\n- **Service Layer**:  Manages model training, inference, and evaluation. This layer orchestrates the interaction between the data and model layers.\n- **Utility Layer**: Contains helper functions, extensions, and common utilities used throughout the project.\n\n### 1.5. Code Splitting Strategies\n\n- Break down large files into smaller, more manageable units based on functionality or responsibility.\n- Use extensions to logically group related methods within a class or struct (e.g., `// MARK: - Data Loading`).\n- Employ protocols to define clear interfaces between components and enable loose coupling.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Factory Pattern**: Use factory methods or classes to create instances of MLX models, layers, or optimizers, especially when dealing with complex configurations or dependencies.\n- **Strategy Pattern**: Implement different optimization algorithms or loss functions as strategies that can be swapped in and out during training.\n- **Observer Pattern**: Employ the observer pattern to notify components about training progress or model updates.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n- **Data Loading**: Use `MLXData` or custom data loaders to efficiently load and preprocess your training data. Consider using memory mapping for large datasets.\n- **Model Definition**: Define your models using `MLX` layers and sequential models. Leverage functional programming techniques for building complex model architectures.\n- **Training Loop**: Implement a well-structured training loop that iterates over the data, performs forward and backward passes, updates model parameters, and evaluates performance.\n- **Inference**: Use `MLXModel.predict` or custom inference engines to make predictions on new data.\n- **Evaluation**:  Implement robust evaluation metrics and visualizations to monitor model performance and identify potential issues.\n\n### 2.3. Anti-Patterns and Code Smells\n\n- **Massive View Controllers**: Avoid placing all MLX-related logic directly within view controllers. Delegate tasks to service layers or dedicated MLX components.\n- **Global State**: Minimize the use of global variables or singletons to manage MLX model instances or training data.  Instead, pass these objects as dependencies.\n- **Hardcoded Values**: Avoid hardcoding model hyperparameters or data paths. Use configuration files or dependency injection to manage these values.\n- **Ignoring Errors**:  Handle potential errors during data loading, model training, or inference gracefully, rather than ignoring or suppressing them.\n- **Synchronous Operations on the Main Thread**: Offload time-consuming operations like model training or inference to background threads to prevent blocking the main thread and freezing the UI.\n\n### 2.4. State Management\n\n- For simple applications, pass state directly between components or use a simple state container object.\n- For more complex applications, consider using state management frameworks like Combine or SwiftUI's `@StateObject` and `@EnvironmentObject`. Or a dedicated state management framework for ML models.\n- Store model parameters and training progress in a dedicated state object and update it during the training loop.\n- Make sure MLX-related state is properly handled and persisted across application lifecycle events (e.g., app termination, backgrounding).\n\n### 2.5. Error Handling\n\n- Use Swift's `Error` protocol and `do-catch` blocks to handle potential errors during data loading, model training, or inference.\n- Create custom error types to represent specific MLX-related errors.\n- Log error messages with sufficient context to aid debugging.\n- Provide user-friendly error messages or feedback to the user when appropriate.\n\n## 3. Performance Considerations\n\nML workloads are inherently performance-sensitive. Optimize your MLX code for speed and efficiency:\n\n### 3.1. Optimization Techniques\n\n- **Vectorization**: Leverage `MLX`'s vectorized operations to perform computations on entire arrays or matrices rather than iterating over individual elements.\n- **Data Type Optimization**: Use the appropriate data types for your model parameters and training data (e.g., `Float16` or `Float32` instead of `Float64`).\n- **Memory Optimization**: Minimize memory allocations and deallocations during the training loop. Re-use buffers and avoid unnecessary data copies.\n- **Graph Compilation**:  If MLX supports it, compile your model graph to optimize its execution. This can significantly improve inference speed.\n- **GPU Acceleration**: Ensure your MLX code is running on the GPU for faster computations (if available).  Verify GPU usage using system monitoring tools.\n\n### 3.2. Memory Management\n\n- Be mindful of memory usage, especially when dealing with large datasets or complex models.\n- Use memory profiling tools to identify memory leaks or excessive memory allocations.\n- Release unused memory explicitly when possible.\n- Consider using techniques like data streaming or batch processing to reduce memory footprint.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n-  MLX is focused on numerical computation, but if you are visualizing outputs, use techniques like Metal shaders to optimize rendering if you are drawing visualizations of ML data.\n\n### 3.4. Bundle Size Optimization\n\n- If using dependencies, consider the impact of external dependencies on the application bundle size.\n- Use code stripping and dead code elimination to remove unused code and resources.\n- Compress images, models, and other assets to reduce their size.\n\n### 3.5. Lazy Loading\n\n- Lazy load large models or datasets only when they are needed to reduce startup time and memory footprint.\n- Use placeholder data or loading indicators while lazy-loading data in the background.\n\n## 4. Security Best Practices\n\nEven though MLX focuses on numerical computation, security is still important:\n\n### 4.1. Common Vulnerabilities and Prevention\n\n- **Model Poisoning**: Prevent malicious actors from injecting adversarial data into your training set to degrade model performance or inject biases.\n  - **Mitigation**: Implement data validation and sanitization techniques. Monitor data sources and investigate anomalies.\n- **Model Extraction**: Protect your trained models from being stolen or reverse-engineered by unauthorized parties.\n  - **Mitigation**: Use model encryption or obfuscation techniques. Implement access controls and authentication mechanisms.\n- **Adversarial Attacks**: Defend against adversarial attacks that can trick your models into making incorrect predictions.\n  - **Mitigation**: Implement adversarial training techniques or input validation mechanisms.\n\n### 4.2. Input Validation\n\n- Validate all external inputs, including user data, API responses, and configuration files, to prevent malicious data from compromising your application or models.\n- Sanitize input data to remove or escape potentially harmful characters or code.\n- Use type checking and data validation libraries to ensure data conforms to expected formats and ranges.\n\n### 4.3. Authentication and Authorization\n\n- Implement robust authentication and authorization mechanisms to protect access to your models, training data, and API endpoints.\n- Use secure password storage techniques like hashing and salting.\n- Implement role-based access control (RBAC) to restrict access to sensitive resources based on user roles.\n\n### 4.4. Data Protection\n\n- Encrypt sensitive data at rest and in transit to prevent unauthorized access.\n- Use secure storage options like the iOS Keychain to store sensitive information like API keys or passwords.\n- Implement data masking or anonymization techniques to protect user privacy.\n\n### 4.5. Secure API Communication\n\n- Use HTTPS to encrypt communication between your application and external APIs or services.\n- Implement certificate pinning to prevent man-in-the-middle attacks.\n- Validate API responses to ensure data integrity and prevent data injection attacks.\n\n## 5. Testing Approaches\n\nThorough testing is essential for ensuring the reliability and correctness of your MLX code:\n\n### 5.1. Unit Testing\n\n- Write unit tests to verify the functionality of individual components, such as model layers, loss functions, or data preprocessing utilities.\n- Use mocking and stubbing techniques to isolate components and simulate dependencies.\n- Test edge cases and boundary conditions to ensure robust behavior.\n\n### 5.2. Integration Testing\n\n- Write integration tests to verify the interaction between different components or modules.\n- Test the data flow through the application pipeline, from data loading to model inference.\n- Verify that the application integrates correctly with external APIs or services.\n\n### 5.3. End-to-End Testing\n\n- Write end-to-end tests to simulate user interactions and verify the overall application functionality.\n- Test the user interface (if applicable) to ensure it behaves as expected.\n- Verify that the application meets the specified performance and security requirements.\n\n### 5.4. Test Organization\n\n- Organize your tests into separate test suites or folders based on the component or functionality being tested.\n- Use descriptive names for your test methods to clearly indicate their purpose.\n- Follow a consistent naming convention for your test files (e.g., `MyComponentTests.swift`).\n\n### 5.5. Mocking and Stubbing\n\n- Use mocking frameworks to create mock objects that simulate the behavior of dependencies during unit testing.\n- Use stubbing techniques to provide pre-defined responses or values for dependencies during testing.\n- Avoid over-mocking or stubbing, as it can make tests brittle and less reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Incorrect Data Shapes**: Ensure that your input data and model parameters have the correct shapes and dimensions. Incorrect shapes can lead to errors or unexpected behavior.\n- **Gradient Vanishing/Exploding**: Be aware of gradient vanishing or exploding problems during training. Use techniques like gradient clipping or batch normalization to mitigate these issues.\n- **Overfitting**: Monitor your model's performance on a validation set to prevent overfitting. Use regularization techniques or dropout to reduce overfitting.\n- **Not Freezing the graph before production**: After training and validation, ensure that MLX is not attempting to recalculate the graph each time inference is called.  Freeze the graph before deploying to production.\n\n### 6.2. Edge Cases\n\n- **Handling Missing Data**: Implement strategies for handling missing data in your datasets. Consider using imputation techniques or creating custom data loaders.\n- **Dealing with Imbalanced Datasets**: Address imbalanced datasets by using techniques like oversampling, undersampling, or weighted loss functions.\n- **Handling Out-of-Memory Errors**: Be prepared to handle out-of-memory errors when dealing with large models or datasets. Reduce batch sizes, use memory mapping, or distribute training across multiple GPUs.\n\n### 6.3. Version-Specific Issues\n\n- Be aware of potential compatibility issues between different versions of MLX and other dependencies.\n- Consult the MLX documentation and release notes for information on known issues or breaking changes.\n- Use dependency management tools like CocoaPods or SPM to manage dependencies and ensure compatibility.\n\n### 6.4. Compatibility Concerns\n\n- Consider compatibility between MLX and other technologies used in your project, such as Core ML or Metal.\n- Use feature detection or conditional compilation to handle different platform versions or hardware capabilities.\n\n### 6.5. Debugging Strategies\n\n- Use Xcode's debugger to step through your code and inspect variables.\n- Use logging statements to track the execution flow and data values.\n- Use visualization tools to inspect model architectures, data distributions, and training progress.\n- Leverage MLX's error messages and stack traces to identify and resolve issues.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **Xcode**: Use Xcode as your primary IDE for developing MLX applications on Apple platforms.\n- **Metal Performance Shaders**: Use Metal Performance Shaders (MPS) to optimize performance on Apple GPUs.\n- **Instruments**: Use Instruments to profile your application's performance and identify bottlenecks.\n- **TensorBoard**: Use TensorBoard to visualize model architectures, training progress, and evaluation metrics.\n\n### 7.2. Build Configuration\n\n- Configure your Xcode project to optimize build settings for performance (e.g., enable optimization levels, disable debugging symbols).\n- Use build configurations (e.g., Debug, Release) to manage different build settings for development and production environments.\n- Use environment variables to configure application behavior based on the environment.\n\n### 7.3. Linting and Formatting\n\n- Use SwiftLint to enforce coding style guidelines and identify potential code quality issues.\n- Use SwiftFormat to automatically format your code according to a consistent style.\n- Configure Xcode to automatically run SwiftLint and SwiftFormat during the build process.\n\n### 7.4. Deployment\n\n- Prepare your MLX models and data for deployment. Convert models to efficient formats (e.g., Core ML) if necessary.\n- Use code signing and provisioning profiles to ensure secure application distribution.\n- Deploy your application to the App Store or distribute it using enterprise deployment mechanisms.\n\n### 7.5. CI/CD Integration\n\n- Integrate your MLX project with a continuous integration and continuous delivery (CI/CD) system like Jenkins, Travis CI, or GitHub Actions.\n- Configure CI/CD pipelines to automatically build, test, and deploy your application on every code change.\n- Use automated testing frameworks to verify the correctness of your MLX code and models.\n\nBy following these best practices, you can develop robust, efficient, and secure MLX applications that leverage the power of machine learning on Apple platforms.",
    "metadata": {
      "globs": "*.swift",
      "format": "mdc",
      "originalFile": "mlx.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "mlx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "library",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mlx",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-mobx",
    "description": "This rule provides comprehensive guidance for using MobX effectively, covering best practices for code organization, performance, testing, and common pitfalls. It aims to ensure efficient and maintainable state management in React and other JavaScript applications using MobX.",
    "author": "sanjeed5",
    "tags": [
      "mobx",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mobx.mdc",
    "content": "# MobX Best Practices and Coding Standards\n\nThis document outlines the best practices for using MobX in your projects. Following these guidelines will help you write more maintainable, performant, and robust code.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n*   **Feature-Based Organization:** Organize your code by feature rather than by file type (e.g., components, stores, utils). This promotes better modularity and easier navigation.\n\n    \n    src/\n    ├── features/\n    │   ├── user-profile/\n    │   │   ├── components/\n    │   │   │   ├── UserProfile.jsx\n    │   │   │   └── UserDetails.jsx\n    │   │   ├── stores/\n    │   │   │   ├── userStore.js\n    │   │   ├── api/\n    │   │   │   └── userApi.js\n    │   │   └── utils/\n    │   │       └── userUtils.js\n    │   ├── product-listing/\n    │   │   └── ...\n    ├── app.js\n    └── ...\n    \n\n*   **Dedicated `stores` Directory:** Place all your MobX stores in a dedicated `stores` directory to clearly separate state management logic from the rest of your application.\n\n*   **Shared Utilities:** Create a `utils` directory for reusable utility functions.\n\n### 1.2 File Naming Conventions\n\n*   **Descriptive Names:** Use descriptive names for files and modules that clearly indicate their purpose.\n*   **Consistent Case:** Maintain a consistent naming convention (e.g., camelCase for JavaScript files, PascalCase for React components).\n\n### 1.3 Module Organization\n\n*   **Single Responsibility Principle:** Each module should have a single, well-defined responsibility.\n*   **Clear Exports:** Clearly define the exports of each module (e.g., named exports for individual functions, default export for the main component or store).\n*   **Avoid Circular Dependencies:** Ensure that modules do not have circular dependencies to prevent runtime errors and improve code maintainability. Use dependency injection if necessary.\n\n### 1.4 Component Architecture\n\n*   **Presentational and Container Components:** Separate presentational (UI-focused) components from container (data-fetching and logic-handling) components.  Presentational components receive data via props, while container components connect to MobX stores and pass data down.\n\n    jsx\n    // Container component\n    import React from 'react';\n    import { observer } from 'mobx-react-lite';\n    import { useUserStore } from './stores/userStore';\n    import UserProfile from './UserProfile';\n\n    const UserProfileContainer = observer(() => {\n      const userStore = useUserStore();\n\n      return <UserProfile user={userStore.user} />; // Pass data as props\n    });\n\n    export default UserProfileContainer;\n\n    // Presentational component\n    import React from 'react';\n\n    const UserProfile = ({ user }) => {\n      return (\n        <div>\n          <h1>{user.name}</h1>\n          <p>{user.email}</p>\n        </div>\n      );\n    };\n\n    export default UserProfile;\n    \n\n*   **Functional Components with Hooks:** Use functional components with the `useObserver` hook (or `observer` from `mobx-react-lite`) for better performance and readability.\n\n    jsx\n    import React from 'react';\n    import { observer } from 'mobx-react-lite';\n    import { useUserStore } from './stores/userStore';\n\n    const UserProfile = observer(() => {\n      const userStore = useUserStore();\n\n      return (\n        <div>\n          <h1>{userStore.user.name}</h1>\n          <p>{userStore.user.email}</p>\n        </div>\n      );\n    });\n\n    export default UserProfile;\n    \n\n*   **Component Composition:** Favor component composition over deep inheritance to create reusable and flexible components.\n\n### 1.5 Code Splitting Strategies\n\n*   **Route-Based Splitting:** Split your application into chunks based on routes or pages. This allows users to download only the code they need for the current view.\n*   **Component-Based Splitting:** Split large components into smaller chunks that can be loaded on demand.  Use `React.lazy` and `Suspense` for lazy loading components.\n*   **Vendor Splitting:** Separate your vendor dependencies (e.g., libraries) into a separate chunk. This allows browsers to cache vendor code separately from your application code.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to MobX\n\n*   **Observable State:** Use `@observable` to define the state that MobX should track for changes.  Ensure that only necessary data is made observable to optimize performance.\n*   **Computed Properties:** Use `@computed` to derive values from observable state. Computed properties are automatically updated when their dependencies change and are cached for performance.\n\n    javascript\n    import { makeObservable, observable, computed } from 'mobx';\n\n    class Cart {\n      items = [];\n\n      constructor() {\n        makeObservable(this, {\n          items: observable,\n          totalPrice: computed\n        });\n      }\n\n      get totalPrice() {\n        return this.items.reduce((sum, item) => sum + item.price, 0);\n      }\n    }\n    \n\n*   **Actions:** Use `@action` to modify the state. Actions ensure that state changes are batched and tracked by MobX.  All state modifications should happen within actions to maintain predictability.\n\n    javascript\n    import { makeObservable, observable, computed, action } from 'mobx';\n\n    class Cart {\n      items = [];\n\n      constructor() {\n        makeObservable(this, {\n          items: observable,\n          totalPrice: computed,\n          addItem: action\n        });\n      }\n\n      get totalPrice() {\n        return this.items.reduce((sum, item) => sum + item.price, 0);\n      }\n\n      addItem(item) {\n        this.items.push(item);\n      }\n    }\n    \n\n*   **Reactions:** Use `reaction`, `autorun`, and `when` to react to state changes.  Use `reaction` for side effects that depend on specific observable values, `autorun` for side effects that depend on any observable value, and `when` for one-time side effects.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Form Handling:** Use MobX to manage form state. Create observable properties for each form field and use actions to update them.\n\n    jsx\n    import React from 'react';\n    import { observer } from 'mobx-react-lite';\n    import { makeObservable, observable, action } from 'mobx';\n\n    class FormStore {\n      name = '';\n      email = '';\n\n      constructor() {\n        makeObservable(this, {\n          name: observable,\n          email: observable,\n          setName: action,\n          setEmail: action\n        });\n      }\n\n      setName(value) {\n        this.name = value;\n      }\n\n      setEmail(value) {\n        this.email = value;\n      }\n    }\n\n    const formStore = new FormStore();\n\n    const Form = observer(() => {\n      return (\n        <form>\n          <input type=\"text\" value={formStore.name} onChange={e => formStore.setName(e.target.value)} />\n          <input type=\"email\" value={formStore.email} onChange={e => formStore.setEmail(e.target.value)} />\n        </form>\n      );\n    });\n\n    export default Form;\n    \n\n*   **Asynchronous Operations:** Use actions to handle asynchronous operations such as API calls. Use `async/await` syntax to simplify asynchronous code.\n\n    javascript\n    import { makeObservable, observable, action } from 'mobx';\n\n    class UserStore {\n      user = null;\n      loading = false;\n\n      constructor() {\n        makeObservable(this, {\n          user: observable,\n          loading: observable,\n          fetchUser: action\n        });\n      }\n\n      async fetchUser(id) {\n        this.loading = true;\n        try {\n          const response = await fetch(`/api/users/${id}`);\n          this.user = await response.json();\n        } finally {\n          this.loading = false;\n        }\n      }\n    }\n    \n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Mutating Observables Directly:** Avoid directly mutating observable values outside of actions. This can lead to unexpected behavior and make it difficult to track state changes. Always use actions to modify observable state.\n*   **Over-Observing:** Avoid making everything observable. Only observe the data that needs to be tracked for changes. Over-observing can lead to performance issues.\n*   **Complex Computed Properties:** Keep computed properties simple and focused. Avoid complex logic in computed properties, as this can make your code harder to understand and debug.\n*   **Using `autorun` Excessively:** Be careful when using `autorun`, as it can easily lead to performance issues if not used correctly. Prefer `reaction` when you need to react to specific observable values.\n*   **Forgetting to Dispose Reactions:** Always dispose of reactions when they are no longer needed to prevent memory leaks. Use the `dispose` function returned by `autorun` and `reaction`.\n\n### 2.4 State Management Best Practices\n\n*   **Single Source of Truth:** Maintain a single source of truth for your application's state. Avoid duplicating state across multiple stores.\n*   **Normalized State:** Normalize your state to reduce redundancy and improve performance. Store data in a flat, relational structure.\n*   **Immutability (with MobX's Mutability):** While MobX embraces mutability for performance, try to treat your data as immutable as possible, especially when working with arrays and objects.  Instead of directly modifying arrays, use methods like `concat`, `slice`, and `filter` to create new arrays.\n*   **Centralized State Management:** Use MobX to manage all your application's state in a centralized location. This makes it easier to reason about and debug your code.\n\n### 2.5 Error Handling Patterns\n\n*   **Try-Catch Blocks:** Use `try-catch` blocks to handle errors in asynchronous operations and other code that might throw exceptions.\n*   **Error Stores:** Create dedicated error stores to manage application-wide errors.  This allows you to display error messages to the user and log errors for debugging.\n*   **Global Error Handling:** Implement global error handling to catch unhandled exceptions and prevent your application from crashing.  Use `window.onerror` or `React Error Boundaries`.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Use `mobx-react-lite`:** Use `mobx-react-lite` instead of `mobx-react` for smaller bundle size and improved performance. `mobx-react-lite` provides hooks-based integration with React.\n*   **`useMemo` and `useCallback`:** Use `useMemo` and `useCallback` to optimize rendering performance by memoizing expensive calculations and preventing unnecessary re-renders.\n\n    jsx\n    import React, { useMemo } from 'react';\n    import { observer } from 'mobx-react-lite';\n\n    const MyComponent = observer(() => {\n      const expensiveValue = useMemo(() => {\n        // Perform expensive calculation\n        return computeExpensiveValue();\n      }, []);\n\n      return <div>{expensiveValue}</div>;\n    });\n\n    export default MyComponent;\n    \n\n*   **`shouldComponentUpdate` (Class Components):**  If you are using class components, implement `shouldComponentUpdate` to prevent unnecessary re-renders.  Compare the previous and current props and state to determine if a re-render is necessary. Consider using `PureComponent`.\n*   **Minimize Re-renders:** Minimize the number of re-renders by optimizing your component structure and using techniques like `useMemo` and `useCallback`.\n\n### 3.2 Memory Management\n\n*   **Dispose Reactions:** Always dispose of reactions when they are no longer needed to prevent memory leaks. Use the `dispose` function returned by `autorun` and `reaction`.\n*   **Avoid Creating Unnecessary Objects:** Avoid creating unnecessary objects, especially in computed properties and reactions. This can lead to memory leaks and performance issues.\n*   **Garbage Collection:** Be aware of JavaScript's garbage collection mechanism and avoid creating circular references that can prevent garbage collection.\n\n### 3.3 Rendering Optimization\n\n*   **Virtualization:** Use virtualization techniques to render large lists efficiently. Virtualization renders only the visible items in the list, which can significantly improve performance.\n*   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of updates to the UI. This can improve performance by preventing excessive re-renders.\n\n### 3.4 Bundle Size Optimization\n\n*   **Code Splitting:** Use code splitting to reduce the initial bundle size of your application. This allows users to download only the code they need for the current view.\n*   **Tree Shaking:** Use tree shaking to remove dead code from your bundle. Tree shaking is a technique that removes unused code from your bundle, which can significantly reduce its size.\n*   **Minification:** Use minification to reduce the size of your code. Minification removes whitespace and comments from your code, which can reduce its size.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Loading Components:** Use `React.lazy` and `Suspense` to lazy load components. This allows you to load components on demand, which can improve the initial load time of your application.\n*   **Lazy Loading Images:** Use lazy loading for images to improve the initial load time of your application. This can be done using the `loading` attribute on the `img` element or using a library like `react-lazyload`.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and escaping output. Use libraries like `DOMPurify` to sanitize HTML.\n*   **Cross-Site Request Forgery (CSRF):** Prevent CSRF attacks by using CSRF tokens. CSRF tokens are unique, secret values that are included in requests to prevent attackers from forging requests on behalf of users.\n*   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or an ORM (Object-Relational Mapper). Parameterized queries escape user input, which prevents attackers from injecting malicious SQL code.\n\n### 4.2 Input Validation\n\n*   **Server-Side Validation:** Validate user input on the server-side to prevent malicious data from being stored in your database.\n*   **Client-Side Validation:** Validate user input on the client-side to provide immediate feedback to the user and improve the user experience. However, always validate on the server-side as well, since client-side validation can be bypassed.\n*   **Regular Expressions:** Use regular expressions to validate user input. Regular expressions are a powerful tool for validating data against specific patterns.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **Authentication:** Use a secure authentication mechanism to verify the identity of users. Use libraries like `Passport.js` or `Auth0` to simplify the authentication process.\n*   **Authorization:** Implement authorization to control access to resources based on the user's role. Use role-based access control (RBAC) or attribute-based access control (ABAC) to manage access permissions.\n*   **JSON Web Tokens (JWT):** Use JWTs to securely transmit user information between the client and the server. JWTs are digitally signed, which makes them tamper-proof.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit. Use HTTPS to encrypt data in transit and libraries like `bcrypt` to encrypt passwords.\n*   **Data Masking:** Mask sensitive data to protect it from unauthorized access. Data masking replaces sensitive data with fictitious data, which allows developers to work with the data without exposing the actual sensitive information.\n*   **Data Anonymization:** Anonymize data to remove personally identifiable information (PII). Data anonymization is a technique that removes or modifies PII to prevent it from being linked to a specific individual.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Always use HTTPS to encrypt communication between the client and the server. HTTPS uses TLS/SSL to encrypt data in transit, which prevents eavesdropping.\n*   **API Keys:** Use API keys to authenticate requests to your API. API keys are unique, secret values that are used to identify the client making the request.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API. Rate limiting limits the number of requests that a client can make within a given time period.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Stores in Isolation:** Unit test MobX stores in isolation to verify that their state and actions behave as expected. Use mocking and stubbing to isolate the stores from external dependencies.\n*   **Test Computed Properties:** Test computed properties to ensure that they correctly derive values from observable state.\n*   **Test Actions:** Test actions to ensure that they correctly modify the state.\n\n### 5.2 Integration Testing\n\n*   **Test Components with Stores:** Integration test components with MobX stores to verify that they interact correctly. Use a testing library like `React Testing Library` to render the components and simulate user interactions.\n*   **Test API Interactions:** Test API interactions to ensure that data is correctly fetched from and sent to the server. Use mocking to isolate the components from the actual API.\n\n### 5.3 End-to-End Testing\n\n*   **Automated Browser Tests:** Use end-to-end testing frameworks like Cypress or Selenium to automate browser tests. End-to-end tests verify that the entire application works correctly from the user's perspective.\n\n### 5.4 Test Organization\n\n*   **Separate Test Files:** Create separate test files for each module or component. This makes it easier to find and run the tests.\n*   **Descriptive Test Names:** Use descriptive names for your tests that clearly indicate what they are testing.\n*   **Test Suites:** Organize your tests into test suites based on functionality or module.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock Dependencies:** Use mocking to replace external dependencies with mock objects. This allows you to isolate the code being tested and control its behavior.\n*   **Stub Functions:** Use stubbing to replace functions with predefined return values or behavior. This allows you to control the behavior of the code being tested without actually executing it.\n*   **Mock API Calls:** Mock API calls to avoid making real API requests during testing. This makes your tests faster and more reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Forgetting to Wrap Components with `observer`:** Forgetting to wrap React components with `observer` (or using `useObserver`) prevents them from reacting to changes in the MobX store.\n*   **Directly Modifying Observable Arrays/Objects:** Directly modifying observable arrays or objects (e.g., `myArray[0] = 'new value'`) won't trigger reactivity. Always use the methods provided by MobX (e.g., `myArray.splice(0, 1, 'new value')` or `myObject.set('key', 'value')`).\n*   **Not Using `useLocalObservable` in Components:**  Using `useLocalObservable` is crucial for creating isolated, component-specific stores, preventing unintended state sharing.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **React Strict Mode:** Be aware that React Strict Mode can cause MobX to re-run reactions multiple times. This can be useful for debugging, but it can also lead to performance issues.\n*   **Large Datasets:** Be careful when working with large datasets in MobX. Consider using virtualization techniques to improve performance.\n\n### 6.3 Version-Specific Issues\n\n*   **MobX 5 vs. MobX 6:** Be aware of the differences between MobX 5 and MobX 6. MobX 6 introduced several breaking changes, including the removal of implicit observability. Make sure your code is compatible with the version of MobX you are using.\n*   **React Compatibility:** Ensure that your version of `mobx-react` or `mobx-react-lite` is compatible with your version of React.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:** Ensure that your code is compatible with the browsers you are targeting. Use polyfills to support older browsers.\n*   **Node.js Compatibility:** Ensure that your code is compatible with the version of Node.js you are using. Use a tool like `nvm` to manage multiple Node.js versions.\n\n### 6.5 Debugging Strategies\n\n*   **MobX DevTools:** Use the MobX DevTools to inspect your application's state and track changes. The MobX DevTools is a browser extension that allows you to visualize your MobX stores and track changes in real-time.\n*   **Logging:** Use logging to track the execution of your code and identify errors. Use a logging library like `debug` to simplify the logging process.\n*   **Breakpoints:** Use breakpoints to pause the execution of your code and inspect its state. Breakpoints are a powerful tool for debugging complex code.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code:** Use VS Code as your IDE. VS Code has excellent support for JavaScript, TypeScript, and React, and it has a wide range of extensions that can improve your development workflow.\n*   **ESLint:** Use ESLint to enforce coding standards and identify potential errors. ESLint is a linter that can be configured to enforce a wide range of coding standards.\n*   **Prettier:** Use Prettier to automatically format your code. Prettier is a code formatter that can be configured to automatically format your code according to a set of rules.\n\n### 7.2 Build Configuration\n\n*   **Webpack:** Use Webpack to bundle your code. Webpack is a module bundler that can be used to bundle your code and its dependencies into a single file.\n*   **Babel:** Use Babel to transpile your code to older versions of JavaScript. Babel is a transpiler that can be used to convert your code to older versions of JavaScript, which allows it to run on older browsers.\n*   **TypeScript:** Use TypeScript to add static typing to your code. TypeScript is a superset of JavaScript that adds static typing to the language. This can help you catch errors early and improve the maintainability of your code.\n\n### 7.3 Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce coding standards and identify potential errors. Configure ESLint to use the recommended rules for React and MobX.\n*   **Prettier:** Use Prettier to automatically format your code. Configure Prettier to use a consistent code style.\n*   **Husky:** Use Husky to run linters and formatters before committing code. This ensures that all code committed to the repository meets the required standards.\n\n### 7.4 Deployment Best Practices\n\n*   **Continuous Integration/Continuous Deployment (CI/CD):** Implement a CI/CD pipeline to automate the deployment process. This ensures that your code is automatically tested and deployed whenever changes are made.\n*   **Caching:** Use caching to improve the performance of your application. Cache static assets like images and JavaScript files to reduce the load on your server.\n*   **Content Delivery Network (CDN):** Use a CDN to distribute your static assets across multiple servers. This improves the performance of your application by serving assets from the server closest to the user.\n\n### 7.5 CI/CD Integration\n\n*   **GitHub Actions:** Use GitHub Actions to automate your CI/CD pipeline. GitHub Actions is a CI/CD service that is integrated with GitHub. Use Jenkins, CircleCI, or other CI/CD tools.\n*   **Automated Testing:** Automate your testing process to ensure that your code is thoroughly tested before it is deployed. Use a testing framework like Jest or Mocha to write automated tests.\n*   **Automated Deployment:** Automate your deployment process to ensure that your code is deployed quickly and reliably. Use a deployment tool like `Capistrano` or `Deployer` to automate the deployment process.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "mobx.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "mobx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "using",
      "effectively",
      "covering",
      "best",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mobx",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-mockito",
    "description": "This rule provides comprehensive best practices and coding standards for using the Mockito library in Java projects. It covers code organization, patterns, performance, security, testing, and common pitfalls to enhance test reliability and maintainability.",
    "author": "sanjeed5",
    "tags": [
      "mockito",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mockito.mdc",
    "content": "# Mockito Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for using the Mockito library effectively in Java projects. It covers various aspects, including code organization, common patterns, performance considerations, security, testing, and common pitfalls.\n\n## Library Information:\n\n- Name: Mockito\n- Tags: testing, java, mocking, unit-testing\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n- **Standard Maven/Gradle Structure:** Follow the standard Maven or Gradle project structure.\n    - `src/main/java`: Production code.\n    - `src/test/java`: Test code.\n    - `src/test/resources`: Test resources (e.g., data files).\n- **Package Structure:** Mirror the package structure of your production code in your test code.\n    - Example: If your production code is in `com.example.service`, your test code should be in `com.example.service` (or a subpackage like `com.example.service.tests`).\n\n### 1.2 File Naming Conventions\n\n- **Test Class Naming:**\n    - Use the same name as the class being tested, followed by `Test` or `IT` (for integration tests).\n    - Examples: `UserServiceTest`, `ProductRepositoryIT`.\n- **Test Method Naming:**\n    - Use descriptive names that clearly indicate what is being tested.\n    - Consider using the pattern `should_[expectedBehavior]_when_[condition]`.\n    - Example: `should_returnUser_when_userExists()`.\n\n### 1.3 Module Organization\n\n- **Single Module:** For small projects, a single module is usually sufficient.\n- **Multi-Module Projects:** For larger projects, consider breaking down the project into modules based on functionality.\n    - Example: `core`, `service`, `repository`, `api`.\n    - Ensure that test code for each module resides within that module.\n\n### 1.4 Component Architecture\n\n- **Layered Architecture:** A common and effective architecture is layered architecture (e.g., presentation, service, data access).\n- **Test Each Layer:** Write unit tests for each layer in isolation using Mockito to mock dependencies.\n- **Integration Tests:** Write integration tests to verify the interactions between layers.\n\n### 1.5 Code Splitting Strategies\n\n- **Test-Driven Development (TDD):** Write tests before writing production code. This naturally leads to smaller, testable units of code.\n- **Refactoring:** Regularly refactor your code to improve its structure and testability.\n- **Extract Methods:** If a method is too complex to test easily, extract smaller, more focused methods.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Mockito\n\n- **Mock Object:** The core pattern in Mockito is the Mock Object pattern, where dependencies are replaced with controlled test doubles.\n- **Dependency Injection:**  Use dependency injection to make your code testable. Mockito is most effective when dependencies are easily replaceable with mocks.\n\n### 2.2 Recommended Approaches for Common Tasks with Mockito\n\n- **Mocking Dependencies:**  Use `@Mock` annotation for cleaner mock creation.\n- **Injecting Mocks:** Use `@InjectMocks` to automatically inject mocks into the class under test.\n- **Verifying Interactions:** Use `verify()` to ensure that expected method calls occurred.\n- **Stubbing Method Calls:**  Use `when(...).thenReturn(...)` to define the return values of mocked method calls.\n- **Capturing Arguments:** Use `ArgumentCaptor` to capture and assert arguments passed to mocked methods.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n- **Over-mocking:** Avoid mocking classes that are easy to instantiate and use directly (e.g., value objects, simple data structures).\n- **Testing Implementation Details:** Focus on testing behavior rather than implementation details.  Tests should not break when you refactor code internally.\n- **Ignoring Test Failures:** Investigate and fix test failures promptly. Don't ignore failing tests.\n- **Writing Untestable Code:** Design code with testability in mind. Avoid tightly coupled code and dependencies.\n- **Misusing Spies:** Use spies sparingly.  If you need to spy on a class, it might be a sign that the class has too many responsibilities.\n- **Chaining `when()` calls excessively:**  If you have long chains of `when()` calls, it might indicate that your class under test is doing too much.\n- **Using `reset()` frequently:**  Frequent use of `reset()` might suggest that your tests are not properly isolated or that your mocks are holding too much state.\n\n### 2.4 State Management Best Practices\n\n- **Isolated Tests:** Each test should be independent of other tests. Avoid sharing state between tests.\n- **Fresh Mocks:** Create fresh mock objects for each test using `@BeforeEach` or `@Before` (JUnit 4).\n- **Avoid Static State:** Minimize the use of static variables or shared mutable state that could affect test results.\n\n### 2.5 Error Handling Patterns\n\n- **Expected Exceptions:** Use `@Test(expected = Exception.class)` (JUnit 4) or `assertThrows()` (JUnit 5) to verify that expected exceptions are thrown.\n- **Exception Handling in Mocks:** Use `when(...).thenThrow(...)` to simulate exceptions thrown by mocked dependencies.\n- **Verification of Exception Handling:** If the code under test catches exceptions, verify that appropriate error handling logic is executed (e.g., logging, retries).\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Lazy Initialization:** Initialize mocks only when they are needed to reduce startup time.\n- **Efficient Stubbing:** Stub only the methods that are actually used in the test case.\n- **Avoid Excessive Verification:** Verify only the interactions that are relevant to the test case.\n\n### 3.2 Memory Management\n\n- **Limited Mock Scope:** Keep the scope of mock objects as narrow as possible (e.g., within a method). This allows them to be garbage collected sooner.\n- **Avoid Large Mocks:** Avoid creating mocks that consume large amounts of memory (e.g., mocks with many fields or methods).\n\n### 3.3 Rendering Optimization (N/A)\n\n- Mockito is primarily a testing framework and does not directly involve rendering.\n\n### 3.4 Bundle Size Optimization (N/A)\n\n- Mockito is a testing dependency and is not included in the production bundle.\n\n### 3.5 Lazy Loading Strategies (Not Directly Applicable)\n\n- Lazy loading is typically used for loading data or resources.  Mockito doesn't directly use lazy loading patterns, although you can lazily initialize mocks if necessary.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n- **Unintended Side Effects:** Ensure that mocked methods do not introduce unintended side effects that could compromise security.\n- **Sensitive Data Exposure:** Avoid logging or storing sensitive data in mock objects.\n\n### 4.2 Input Validation Best Practices\n\n- **Validate Inputs in Production Code:** Mockito tests should verify that input validation is performed correctly in the production code.\n- **Simulate Invalid Inputs:** Use Mockito to simulate invalid inputs and verify that the code handles them appropriately.\n\n### 4.3 Authentication and Authorization Patterns\n\n- **Mock Authentication/Authorization Services:** Mock authentication and authorization services to test different security scenarios (e.g., authorized vs. unauthorized users).\n- **Verify Access Control:** Use Mockito to verify that access control checks are performed correctly in the production code.\n\n### 4.4 Data Protection Strategies\n\n- **Encryption:** If sensitive data is used in mock objects, ensure that it is encrypted.\n- **Data Masking:** Use data masking techniques to protect sensitive data in mock objects.\n\n### 4.5 Secure API Communication\n\n- **Mock API Clients:** Mock API clients to simulate different API responses, including error conditions.\n- **Verify Secure Communication:** Use Mockito to verify that secure communication protocols (e.g., HTTPS) are used when interacting with APIs.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n- **Test Individual Units:** Unit tests should focus on testing individual units of code (e.g., classes, methods) in isolation.\n- **Mock Dependencies:** Use Mockito to mock dependencies and control their behavior.\n- **Test All Scenarios:** Write tests for all possible scenarios, including normal cases, edge cases, and error conditions.\n\n### 5.2 Integration Testing Approaches\n\n- **Test Interactions Between Units:** Integration tests should focus on testing the interactions between different units of code.\n- **Use Real Dependencies (If Possible):** Use real dependencies whenever possible to ensure that the integration works correctly.\n- **Mock External Systems:** Mock external systems (e.g., databases, APIs) to control their behavior and simulate different scenarios.\n\n### 5.3 End-to-End Testing Recommendations (Beyond Mockito)\n\n- **Use UI Testing Frameworks:** Use UI testing frameworks (e.g., Selenium, Cypress) to test the entire application flow.\n- **Test User Interactions:** End-to-end tests should simulate real user interactions to ensure that the application works as expected.\n\n### 5.4 Test Organization Best Practices\n\n- **Separate Test Classes:** Create separate test classes for each class being tested.\n- **Descriptive Test Names:** Use descriptive test names that clearly indicate what is being tested.\n- **Arrange, Act, Assert:** Follow the Arrange, Act, Assert (AAA) pattern in your tests.\n- **Keep Tests Short and Focused:** Keep tests short and focused on testing a single aspect of the code.\n\n### 5.5 Mocking and Stubbing Techniques\n\n- **`@Mock` Annotation:** Use `@Mock` to create mock objects.\n- **`@InjectMocks` Annotation:** Use `@InjectMocks` to automatically inject mock objects into the class under test.\n- **`when(...).thenReturn(...)`:** Use `when(...).thenReturn(...)` to stub method calls.\n- **`verify(...)`:** Use `verify(...)` to verify that method calls occurred.\n- **`ArgumentCaptor`:** Use `ArgumentCaptor` to capture and assert arguments passed to mocked methods.\n- **`doReturn(...).when(...)`:** Use `doReturn(...).when(...)` when stubbing void methods or methods that are called multiple times.\n- **`thenAnswer(...)`:** Use `thenAnswer(...)` to provide custom logic for stubbing method calls.\n- **`thenThrow(...)`:** Use `thenThrow(...)` to simulate exceptions thrown by mocked methods.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n- **Mocking Everything:** Mocking simple classes can lead to brittle tests. Use real objects when possible.\n- **Testing Implementation Details:** Focus on testing behavior, not implementation.\n- **Ignoring Test Failures:** Always investigate and fix test failures promptly.\n- **Not Using Argument Matchers Properly:** When using argument matchers, ensure that all arguments are either exact values or matchers.\n- **Forgetting to Initialize Mocks:** Ensure that mocks are initialized using `MockitoAnnotations.initMocks(this)` or `@ExtendWith(MockitoExtension.class)` (JUnit 5).\n\n### 6.2 Edge Cases to Be Aware Of\n\n- **Final Classes and Methods:** Mockito cannot mock final classes or methods by default. Consider using the Mockito inline mock maker or PowerMock (though PowerMock should be used as a last resort due to complexity).\n- **Static Methods:** Mockito cannot mock static methods by default. Consider using the Mockito inline mock maker or PowerMock.\n- **Equals and HashCode:** Mockito can have issues with `equals()` and `hashCode()` methods, especially when using argument matchers. Be careful when mocking classes that rely heavily on these methods.\n- **Order of Interactions:**  Mockito verifies interactions in the order they occur. Be mindful of the order of method calls when writing tests.\n\n### 6.3 Version-Specific Issues\n\n- **Mockito 2 vs. Mockito 3 vs. Mockito 4/5:** Be aware of the differences between Mockito versions.  Some features may be deprecated or added in newer versions.\n- **Java Version Compatibility:** Ensure that your Mockito version is compatible with your Java version.\n\n### 6.4 Compatibility Concerns\n\n- **JUnit Version:** Ensure that your Mockito version is compatible with your JUnit version.\n- **Other Testing Frameworks:** Mockito can be used with other testing frameworks, but ensure that there are no compatibility issues.\n- **IDE Integration:** Ensure that your IDE has proper support for Mockito and JUnit.\n\n### 6.5 Debugging Strategies\n\n- **Print Statements:** Use print statements to debug the code and verify that the mock objects are behaving as expected.\n- **IDE Debugger:** Use the IDE debugger to step through the code and inspect the mock objects.\n- **Mockito Spy:** Use a Mockito spy to partially mock a class and observe its behavior.\n- **Verbose Logging:** Use verbose logging to see all method calls and their return values.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE:** IntelliJ IDEA, Eclipse, or Visual Studio Code.\n- **Build Tool:** Maven or Gradle.\n- **Testing Framework:** JUnit 4 or JUnit 5.\n- **Code Coverage Tool:** JaCoCo or SonarQube.\n\n### 7.2 Build Configuration Best Practices\n\n- **Dependency Management:** Use Maven or Gradle to manage Mockito dependencies.\n- **Test Dependencies:** Declare Mockito as a test dependency to ensure that it is not included in the production code.\n- **Plugin Configuration:** Configure Maven or Gradle plugins to run tests and generate code coverage reports.\n\n### 7.3 Linting and Formatting\n\n- **Code Style:** Follow a consistent code style (e.g., Google Java Style, Checkstyle).\n- **Linting Rules:** Use linting tools (e.g., PMD, SpotBugs) to enforce coding standards and identify potential issues.\n- **Formatting:** Use code formatters (e.g., IntelliJ IDEA formatter, Eclipse formatter) to automatically format your code.\n\n### 7.4 Deployment Best Practices (N/A)\n\n- Mockito is a testing dependency and is not deployed with the production code.\n\n### 7.5 CI/CD Integration\n\n- **Automated Builds:** Configure your CI/CD system (e.g., Jenkins, CircleCI, GitHub Actions) to automatically build and test your code.\n- **Test Execution:** Run unit tests and integration tests as part of the CI/CD pipeline.\n- **Code Coverage:** Generate code coverage reports as part of the CI/CD pipeline and set thresholds for code coverage.\n- **Static Analysis:** Perform static analysis as part of the CI/CD pipeline to identify potential issues.\n\n## Conclusion\n\nBy following these best practices, you can write more effective and maintainable tests using Mockito. Remember to focus on testing behavior, avoid over-mocking, and keep your tests short and focused.",
    "metadata": {
      "globs": "*.java",
      "format": "mdc",
      "originalFile": "mockito.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "mockito",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "using",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mockito",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-modal",
    "description": "This rule outlines best practices for developing and maintaining the Modal library, covering code organization, performance, security, and testing. It aims to ensure high-quality, maintainable, and scalable cloud deployment solutions.",
    "author": "sanjeed5",
    "tags": [
      "modal",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/modal.mdc",
    "content": "# Modal Library Best Practices\n\nThis document outlines the best practices for developing and maintaining the Modal library. These guidelines cover various aspects of the library, including code organization, performance, security, testing, and deployment.  Following these guidelines will ensure the Modal library remains a high-quality, maintainable, and scalable cloud deployment solution.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure Best Practices:**\n    - Adopt a modular directory structure based on functionality or component type.\n    - Use clear and descriptive directory names.\n    - Example:\n        \n        modal/\n        ├── api/\n        │   ├── __init__.py\n        │   ├── routes.py\n        │   └── models.py\n        ├── config/\n        │   ├── __init__.py\n        │   └── settings.py\n        ├── deployment/\n        │   ├── __init__.py\n        │   ├── deploy.py\n        │   └── utils.py\n        ├── exceptions/\n        │   ├── __init__.py\n        │   └── custom_exceptions.py\n        ├── security/\n        │   ├── __init__.py\n        │   ├── auth.py\n        │   └── permissions.py\n        ├── testing/\n        │   ├── __init__.py\n        │   ├── unit/\n        │   └── integration/\n        ├── utils/\n        │   ├── __init__.py\n        │   └── helpers.py\n        ├── __init__.py\n        └── core.py\n        \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - Follow a consistent naming convention (e.g., `snake_case` for Python).\n    - Example: `user_authentication.py`, `database_connection.py`\n\n- **Module Organization:**\n    - Group related functions, classes, and data into modules.\n    - Use `__init__.py` files to define package structure.\n    - Ensure clear separation of concerns between modules.\n    - Each module should have a clearly defined purpose.\n\n- **Component Architecture:**\n    - Design the library using a component-based architecture.\n    - Each component should be self-contained and reusable.\n    - Components should have well-defined interfaces.\n    - Use dependency injection to manage component dependencies.\n\n- **Code Splitting Strategies:**\n    - Divide large modules into smaller, more manageable files.\n    - Split code based on functionality or feature.\n    - Consider using lazy loading for infrequently used modules.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns Specific to Modal:**\n    - **Singleton:**  For managing global resources (e.g., configuration).\n    - **Factory:**  For creating Modal clients with different configurations.\n    - **Observer:** For notifying subscribers of Modal state changes.\n    - **Strategy:** For different deployment strategies (e.g., different cloud providers).\n\n- **Recommended Approaches for Common Tasks:**\n    - **Configuration Management:** Use a dedicated configuration module to manage settings.\n    - **Logging:** Implement a robust logging system for debugging and monitoring.\n    - **Error Handling:**  Use exception handling to gracefully handle errors.\n    - **Asynchronous Operations:** Use `asyncio` or similar libraries for handling asynchronous tasks.\n    - **Resource Management:** Use context managers (`with` statement) to ensure proper resource cleanup.\n\n- **Anti-patterns and Code Smells to Avoid:**\n    - **God Classes:** Avoid creating classes that are too large and complex.\n    - **Spaghetti Code:**  Maintain a clear and well-structured codebase.\n    - **Magic Numbers:**  Use constants instead of hardcoded values.\n    - **Duplicated Code:**  Refactor duplicated code into reusable functions or classes.\n    - **Ignoring Errors:**  Always handle exceptions appropriately.\n\n- **State Management Best Practices:**\n    - Prefer immutable data structures to avoid unintended side effects.\n    - Use a centralized state management system (if needed) for complex state.\n    - Consider using libraries like `attrs` or `dataclasses` for managing data objects.\n\n- **Error Handling Patterns:**\n    - Use try-except blocks to handle potential exceptions.\n    - Define custom exception classes for specific error conditions.\n    - Log exceptions with relevant information for debugging.\n    - Implement retry mechanisms for transient errors.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - Profile code to identify performance bottlenecks.\n    - Optimize database queries and data access patterns.\n    - Use caching to reduce the load on external services.\n    - Avoid unnecessary computations and memory allocations.\n\n- **Memory Management:**\n    - Use generators and iterators to process large datasets efficiently.\n    - Avoid creating large objects in memory unnecessarily.\n    - Use memory profiling tools to identify memory leaks.\n\n- **Rendering Optimization (if applicable):**\n    - N/A (Modal library is primarily backend-focused).\n\n- **Bundle Size Optimization (if applicable):**\n    - N/A (Modal library is primarily backend-focused).\n\n- **Lazy Loading Strategies:**\n    - Use lazy loading to load modules and resources only when they are needed.\n    - This can reduce startup time and memory usage.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - **Injection Attacks:**  Sanitize user inputs to prevent SQL injection, command injection, etc.\n    - **Cross-Site Scripting (XSS):** N/A (Modal library is primarily backend-focused).\n    - **Cross-Site Request Forgery (CSRF):** N/A (Modal library is primarily backend-focused).\n    - **Authentication and Authorization Flaws:** Implement secure authentication and authorization mechanisms.\n    - **Data Exposure:**  Protect sensitive data by encrypting it at rest and in transit.\n\n- **Input Validation:**\n    - Validate all user inputs to prevent malicious data from entering the system.\n    - Use data validation libraries (e.g., `marshmallow`, `pydantic`) to enforce data types and constraints.\n\n- **Authentication and Authorization Patterns:**\n    - Use a strong authentication mechanism (e.g., OAuth 2.0, JWT).\n    - Implement role-based access control (RBAC) to restrict access to sensitive resources.\n    - Avoid storing passwords in plain text; use password hashing algorithms (e.g., bcrypt, Argon2).\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between clients and servers.\n    - Implement data masking and anonymization techniques to protect sensitive data.\n\n- **Secure API Communication:**\n    - Use API keys or tokens to authenticate API requests.\n    - Implement rate limiting to prevent abuse.\n    - Use input validation to prevent malicious data from entering the system.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Write unit tests for all critical functions and classes.\n    - Use mocking and stubbing to isolate units of code.\n    - Aim for high test coverage.\n\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between different components.\n    - Test the integration with external services (e.g., databases, APIs).\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the entire system functionality.\n    - Simulate real-world scenarios.\n\n- **Test Organization:**\n    - Organize tests into separate directories based on functionality or component.\n    - Use a consistent naming convention for test files and functions.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to isolate units of code.\n    - Create stubs for external dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes Developers Make:**\n    - Improper error handling.\n    - Lack of input validation.\n    - Security vulnerabilities.\n    - Performance bottlenecks.\n    - Inadequate testing.\n\n- **Edge Cases to Be Aware Of:**\n    - Handling of large datasets.\n    - Concurrent access to shared resources.\n    - Network failures and timeouts.\n    - Unexpected input values.\n\n- **Version-Specific Issues:**\n    - Be aware of compatibility issues between different versions of the library and its dependencies.\n    - Test the library with different versions of Python and other dependencies.\n\n- **Compatibility Concerns:**\n    - Ensure the library is compatible with different operating systems and environments.\n\n- **Debugging Strategies:**\n    - Use logging to trace the execution flow and identify errors.\n    - Use debuggers to step through the code and inspect variables.\n    - Use profiling tools to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - IDE: VS Code, PyCharm\n    - Debugger: pdb, ipdb\n    - Profiler: cProfile, line_profiler\n    - Testing Framework: pytest, unittest\n    - Mocking Library: unittest.mock, pytest-mock\n    - Linting and Formatting: pylint, flake8, black\n\n- **Build Configuration:**\n    - Use a build system (e.g., `setuptools`, `poetry`) to manage dependencies and build the library.\n    - Define a clear build process.\n\n- **Linting and Formatting:**\n    - Use linters (e.g., `pylint`, `flake8`) to enforce code style and identify potential errors.\n    - Use formatters (e.g., `black`) to automatically format the code.\n\n- **Deployment Best Practices:**\n    - Use a deployment automation tool (e.g., Ansible, Terraform) to automate the deployment process.\n    - Use infrastructure-as-code (IaC) to manage infrastructure.\n    - Monitor the deployment process for errors.\n\n- **CI/CD Integration:**\n    - Integrate the library with a CI/CD pipeline to automate testing and deployment.\n    - Use tools like Jenkins, GitLab CI, or GitHub Actions.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "modal.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "modal",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "developing",
      "maintaining",
      "library",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "modal",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-mongodb",
    "description": "Comprehensive best practices for developing with MongoDB, covering schema design, code organization, performance optimization, security considerations, and testing strategies. This rule provides actionable guidance to help developers build robust and scalable MongoDB applications.",
    "author": "sanjeed5",
    "tags": [
      "mongodb",
      "go",
      "backend",
      "performance",
      "database",
      "nosql",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mongodb.mdc",
    "content": "- **Understand Schema Differences Between Relational and Document-based Databases:**  Recognize that MongoDB's document-oriented model differs significantly from relational databases. Design schemas that reflect the relationships within the data itself, rather than relying on joins.\n- **Embed Your Data Instead of Relying on Joins:** Favor embedding related data within a single document to minimize the need for costly join operations. This approach can significantly improve read performance.\n- **Use Indexes For Frequent Operations:**  Create indexes on fields that are frequently queried to optimize performance. Carefully consider the types of queries your application will perform and create indexes accordingly. Compound indexes are beneficial for queries involving multiple fields.\n- **Properly Size Your Servers:** Ensure that your MongoDB server resources are adequately sized for your workload. Monitor resource utilization and scale as needed to maintain optimal performance. Consider CPU, memory, and disk I/O.\n- **Use Replication or Sharding:** Implement replication or sharding to enhance scalability and reliability. Replication provides data redundancy and high availability, while sharding distributes data across multiple servers to handle larger datasets and higher traffic volumes.\n\n### 1. Code Organization and Structure:\n\n- **Directory Structure Best Practices:**\n    - `config/`: Contains configuration files for database connections, authentication, and other settings.\n    - `models/`: Defines data models using Mongoose or other ODM libraries. Each model represents a MongoDB collection.\n    - `routes/`: Handles API endpoints and routes for interacting with the database.\n    - `controllers/`: Implements the logic for handling requests, interacting with models, and returning responses.\n    - `services/`: Contains reusable business logic related to data access and manipulation.\n    - `utils/`: Provides utility functions for common tasks such as validation, formatting, and error handling.\n    - `tests/`: Includes unit, integration, and end-to-end tests.\n- **File Naming Conventions:**\n    - Use descriptive names that reflect the purpose of the file (e.g., `user.model.js`, `auth.controller.ts`, `product.service.js`).\n    - Follow a consistent naming convention across the project (e.g., camelCase or snake_case).\n- **Module Organization:**\n    - Organize code into modules based on functionality or domain (e.g., `user` module, `product` module).\n    - Use ES modules or CommonJS modules to encapsulate code and manage dependencies.\n- **Component Architecture:**\n    - Design reusable components for common tasks such as data validation, error handling, and authentication.\n    - Follow the principles of separation of concerns and single responsibility.\n- **Code Splitting Strategies:**\n    - Implement lazy loading of modules or components to improve initial load time.\n    - Use code splitting to break down large bundles into smaller chunks.\n\n### 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns Specific to MongoDB:**\n    - **Embedded Document Pattern:** Embed related data within a single document to minimize the need for joins.\n    - **Polymorphic Pattern:** Store different types of documents in the same collection using a common base schema and discriminator fields.\n    - **Bucket Pattern:** Group data into buckets based on time or other criteria for efficient querying and aggregation.\n- **Recommended Approaches for Common Tasks:**\n    - Use Mongoose or other ODM libraries to simplify data modeling and validation.\n    - Implement pagination for large result sets.\n    - Use aggregation pipelines for complex queries and data transformations.\n- **Anti-patterns and Code Smells to Avoid:**\n    - **Over-indexing:** Creating too many indexes can degrade write performance.\n    - **Ignoring Performance:** Neglecting to analyze query performance can lead to slow response times.\n    - **Schema Violations:** Allowing inconsistent data to be stored in collections can cause unexpected errors.\n- **State Management Best Practices:**\n    - Use a state management library such as Redux or Zustand to manage application state.\n    - Store state in a centralized store to ensure consistency and predictability.\n- **Error Handling Patterns:**\n    - Implement robust error handling to catch and handle exceptions gracefully.\n    - Use try-catch blocks to handle potential errors.\n    - Log errors for debugging and monitoring.\n\n### 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - Use indexes to optimize query performance.\n    - Avoid using `$where` operator, as it can be slow.\n    - Use projection to retrieve only the necessary fields.\n- **Memory Management:**\n    - Monitor memory usage and identify potential memory leaks.\n    - Use connection pooling to reuse database connections.\n- **Rendering Optimization:** (If applicable for UI-based apps using MongoDB data)\n    - Implement virtualization for large lists.\n    - Use memoization to avoid unnecessary re-renders.\n- **Bundle Size Optimization:** (If applicable)\n    - Minify and compress JavaScript and CSS files.\n    - Remove unused code.\n- **Lazy Loading Strategies:** (If applicable)\n    - Lazy load images and other resources.\n    - Use code splitting to load modules on demand.\n\n### 4. Security Best Practices:\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - **NoSQL Injection:** Sanitize user inputs to prevent injection attacks.\n    - **Authentication Bypass:** Implement strong authentication and authorization mechanisms.\n    - **Data Exposure:** Protect sensitive data by encrypting it and controlling access.\n- **Input Validation:**\n    - Validate all user inputs to prevent malicious data from being stored in the database.\n    - Use a validation library such as Joi or Yup to define validation schemas.\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication protocol such as OAuth 2.0 or JWT.\n    - Implement role-based access control (RBAC) to restrict access to sensitive data and functionality.\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use data masking to protect personally identifiable information (PII).\n- **Secure API Communication:**\n    - Use HTTPS to encrypt communication between the client and server.\n    - Implement rate limiting to prevent abuse.\n\n### 5. Testing Approaches:\n\n- **Unit Testing Strategies:**\n    - Write unit tests to verify the functionality of individual modules and components.\n    - Use a testing framework such as Jest or Mocha.\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between different modules and components.\n    - Test the integration between the application and the database.\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the functionality of the entire application.\n    - Use a testing framework such as Cypress or Playwright.\n- **Test Organization:**\n    - Organize tests into separate directories based on functionality or module.\n    - Use descriptive names for test files and test cases.\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate units of code during testing.\n    - Use a mocking library such as Sinon or Jest's built-in mocking.\n\n### 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes Developers Make:**\n    - **Not Understanding MongoDB's Query Language:**  Failing to grasp the nuances of MongoDB's query language can lead to inefficient queries.\n    - **Ignoring Indexes:**  Neglecting to create indexes on frequently queried fields can significantly impact performance.\n    - **Not Handling Errors Properly:**  Failing to handle errors gracefully can lead to unexpected application behavior.\n- **Edge Cases to Be Aware Of:**\n    - **Data Type Mismatches:** Ensure that data types are consistent across the application and the database.\n    - **Concurrency Issues:**  Handle concurrency issues carefully to prevent data corruption.\n- **Version-Specific Issues:**\n    - Be aware of compatibility issues between different versions of MongoDB and related libraries.\n    - Consult the documentation for the specific version you are using.\n- **Compatibility Concerns:**\n    - Ensure that the application is compatible with different operating systems and browsers.\n    - Test the application on different devices and screen sizes.\n- **Debugging Strategies:**\n    - Use logging to track the execution flow and identify potential issues.\n    - Use a debugger to step through the code and inspect variables.\n\n### 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - **MongoDB Compass:** A GUI tool for exploring and managing MongoDB databases.\n    - **MongoDB Shell:** A command-line interface for interacting with MongoDB.\n    - **VS Code Extension for MongoDB:** Provides syntax highlighting, code completion, and other features for MongoDB development.\n- **Build Configuration:**\n    - Use a build tool such as Webpack or Parcel to bundle and optimize the application.\n    - Configure the build tool to minify and compress JavaScript and CSS files.\n- **Linting and Formatting:**\n    - Use a linter such as ESLint to enforce coding standards.\n    - Use a formatter such as Prettier to automatically format code.\n- **Deployment Best Practices:**\n    - Use a containerization technology such as Docker to package the application and its dependencies.\n    - Deploy the application to a cloud platform such as AWS, Azure, or Google Cloud.\n- **CI/CD Integration:**\n    - Integrate the application with a CI/CD pipeline to automate the build, test, and deployment process.\n    - Use a CI/CD tool such as Jenkins, Travis CI, or CircleCI.",
    "metadata": {
      "globs": "*.js,*.ts,*.mongodb",
      "format": "mdc",
      "originalFile": "mongodb.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "mongodb",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "schema",
      "design",
      "code",
      "go",
      "backend",
      "performance",
      "database",
      "nosql",
      "cursor-rule",
      "mdc",
      "data-ai"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mongodb",
        "go",
        "golang",
        "backend",
        "performance",
        "database",
        "nosql",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "data-ai"
    }
  },
  {
    "name": "cursor-mypy",
    "description": "This rule file outlines best practices for using mypy in Python projects, emphasizing gradual adoption, consistent configuration, and leveraging advanced features for improved code quality and maintainability. It covers code organization, performance, security, testing, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "mypy",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/mypy.mdc",
    "content": "# Mypy Best Practices and Coding Standards\n\nThis document outlines the recommended best practices for using Mypy in Python projects. Following these guidelines can lead to more maintainable, robust, and understandable code.\n\n## 1. Gradual Typing and Adoption\n\n- **Start Small:** When introducing Mypy to an existing codebase, focus on a manageable subset of the code first. Choose modules or files that are relatively isolated or self-contained.\n- **Iterative Annotation:** Gradually increase the coverage by adding type hints as you modify or add new code. Avoid large-scale refactoring solely for the purpose of adding type hints.\n- **`# type: ignore` Strategically:** Use `# type: ignore` comments sparingly to temporarily suppress errors in code that is not yet fully typed. Always include a specific error code when using `# type: ignore` to avoid unintentionally ignoring other errors.  Review these regularly.\n- **Prioritize Widely Imported Modules:** Focus on annotating modules that are imported by many other modules. This will provide the greatest benefit in terms of type checking and error detection.\n\n## 2. Consistent Configuration and Integration\n\n- **Standardized Configuration:** Ensure that all developers use the same Mypy configuration and version. Use a `mypy.ini` file or a `pyproject.toml` file to define the project's Mypy settings. This file should be version-controlled.\n- **CI Integration:** Integrate Mypy checks into your Continuous Integration (CI) pipeline to catch type errors early in the development process. Use a pre-commit hook to run Mypy before committing code.\n- **Editor Integration:** Encourage developers to use Mypy integration in their code editors to get real-time feedback on type errors. Most popular Python editors, such as VS Code, PyCharm, and Sublime Text, have Mypy plugins or extensions.\n- **Version Pinning:** Pin the version of mypy in your project's dependencies to ensure consistent behavior across different environments.\n\n## 3. Leveraging Advanced Features\n\n- **Strict Mode:** Utilize Mypy's strict mode (enabled with the `--strict` flag) to catch more potential errors. Strict mode enables a collection of stricter type checking options.\n- **`--warn-unused-ignores`:** Use this flag to identify `# type: ignore` comments that are no longer necessary because the corresponding errors have been fixed.\n- **`--disallow-untyped-defs`:** Use this flag to require type annotations for all function definitions.\n- **`--disallow-incomplete-defs`:** Use this flag to disallow function definitions with incomplete type annotations.\n- **`--check-untyped-defs`:** Use this flag to type check function bodies even if the signature lacks type annotations.\n- **Protocols and Structural Subtyping:** Take advantage of Mypy's support for protocols and structural subtyping to define flexible interfaces and improve code reusability.\n- **Generics:** Use generics to write type-safe code that can work with different types of data.\n- **TypedDict:** Use `TypedDict` to define the types of dictionaries with known keys and values. This can help to prevent errors when working with data structures.\n\n## 4. Code Organization and Structure\n\n- **Directory Structure:** Use a well-defined directory structure to organize your code. A common pattern is the `src` layout, where the project's source code is located in a `src` directory.\n- **File Naming Conventions:** Follow consistent file naming conventions. Use lowercase letters and underscores for module names (e.g., `my_module.py`).\n- **Module Organization:** Organize your code into logical modules. Each module should have a clear purpose and a well-defined interface.\n- **Component Architecture:** Design your application using a component-based architecture. Each component should be responsible for a specific task and should have well-defined inputs and outputs.\n- **Code Splitting:** Split large modules into smaller, more manageable files. This can improve code readability and maintainability.\n\n## 5. Common Patterns and Anti-patterns\n\n- **Dependency Injection:** Use dependency injection to decouple components and improve testability.\n- **Abstract Factories:** Use abstract factories to create families of related objects without specifying their concrete classes.\n- **Singletons:** Avoid using singletons excessively. They can make code harder to test and reason about.\n- **Global State:** Minimize the use of global state. It can make code harder to understand and debug.\n- **Exception Handling:** Use exception handling to gracefully handle errors and prevent the application from crashing. Avoid catching generic exceptions (e.g., `except Exception:`). Catch specific exceptions and handle them appropriately.\n\n## 6. Performance Considerations\n\n- **Profiling:** Use profiling tools to identify performance bottlenecks in your code.\n- **Caching:** Use caching to store frequently accessed data and reduce the number of expensive operations.\n- **Lazy Loading:** Use lazy loading to defer the loading of resources until they are actually needed.\n- **Efficient Data Structures:** Choose appropriate data structures for your data. For example, use sets for membership testing and dictionaries for key-value lookups.\n- **Avoid Unnecessary Copying:** Avoid making unnecessary copies of data. This can consume memory and slow down your code.\n\n## 7. Security Best Practices\n\n- **Input Validation:** Validate all user inputs to prevent injection attacks and other security vulnerabilities. Use type annotations to enforce type constraints on function arguments.\n- **Authentication and Authorization:** Implement robust authentication and authorization mechanisms to protect your application from unauthorized access.\n- **Data Protection:** Protect sensitive data by encrypting it and storing it securely.\n- **Secure API Communication:** Use HTTPS to encrypt communication between your application and external APIs.\n- **Dependency Management:** Regularly audit your project's dependencies for security vulnerabilities and update them to the latest versions.\n\n## 8. Testing Approaches\n\n- **Unit Testing:** Write unit tests for all components in your application. Unit tests should verify that each component behaves as expected in isolation.\n- **Integration Testing:** Write integration tests to verify that different components in your application work together correctly.\n- **End-to-End Testing:** Write end-to-end tests to verify that the entire application works as expected from the user's perspective.\n- **Test Organization:** Organize your tests into a clear and logical structure. Use separate directories for unit tests, integration tests, and end-to-end tests.\n- **Mocking and Stubbing:** Use mocking and stubbing to isolate components during testing and to simulate external dependencies.\n\n## 9. Common Pitfalls and Gotchas\n\n- **`Any` Type:** Avoid using the `Any` type excessively. It effectively disables type checking for the corresponding code.\n- **Inconsistent Type Annotations:** Ensure that type annotations are consistent throughout your codebase. Inconsistent type annotations can lead to unexpected errors.\n- **Ignoring Errors:** Avoid ignoring Mypy errors without a good reason. Mypy errors usually indicate a real problem in your code.\n- **Version Compatibility:** Be aware of compatibility issues between different versions of Mypy and other libraries.\n- **Circular Dependencies:** Avoid circular dependencies between modules. They can make code harder to understand and test.\n\n## 10. Tooling and Environment\n\n- **Development Tools:** Use a good code editor with Mypy integration, such as VS Code, PyCharm, or Sublime Text.\n- **Build Configuration:** Use a build system, such as `setuptools` or `poetry`, to manage your project's dependencies and build process.\n- **Linting and Formatting:** Use a linter, such as `flake8` or `ruff`, to enforce code style and detect potential errors. Use a code formatter, such as `black` or `ruff`, to automatically format your code.\n- **Deployment:** Deploy your application to a production environment using a container system, such as Docker, or a cloud platform, such as AWS or Google Cloud.\n- **CI/CD:** Integrate Mypy into your CI/CD pipeline to automatically check your code for type errors before deploying it to production.\n\n## 11. Additional Best Practices\n\n- **Use type hints for all function arguments and return values.** This makes it easier to understand what types of data the function expects and returns.\n- **Use type aliases to simplify complex type annotations.** This can make your code more readable and maintainable.\n- **Use the `typing` module to access advanced type features.** The `typing` module provides a number of useful type-related classes and functions, such as `List`, `Dict`, `Union`, and `Optional`.\n- **Use the `reveal_type()` function to inspect the type of an expression.** This can be helpful for debugging type-related issues.\n- **Keep your code clean and well-organized.** This makes it easier to understand and maintain.\n- **Write clear and concise comments.** This helps others understand your code and how it works.\n- **Follow the PEP 8 style guide.** This ensures that your code is consistent and readable.\n- **Use a version control system.** This allows you to track changes to your code and collaborate with others.\n\nBy following these best practices, you can improve the quality, maintainability, and robustness of your Python code that uses mypy and other Python tools.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "mypy.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "mypy",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "using",
      "python",
      "projects",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "mypy",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-neo4j",
    "description": "This rule provides guidelines for best practices and coding standards when developing applications with Neo4j. It covers aspects from code organization and performance to security and testing.",
    "author": "sanjeed5",
    "tags": [
      "neo4j",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/neo4j.mdc",
    "content": "# Neo4j Development Best Practices\n\nThis document outlines best practices and coding standards for developing applications using Neo4j. These guidelines are designed to promote maintainability, performance, and security.\n\nLibrary Information:\n- Name: neo4j\n- Tags: database, graph, nosql, relationships\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nOrganize your project with a clear directory structure that separates concerns. A recommended structure is as follows:\n\n\nproject_root/\n├── data/                  # Contains data files for import/export\n├── queries/               # Stores Cypher queries\n├── src/                    # Source code for the application\n│   ├── models/           # Defines data models and graph schemas\n│   ├── services/          # Contains business logic and Neo4j interactions\n│   ├── utils/             # Utility functions and helper classes\n│   ├── config/            # Configuration files\n│   └── app.js            # Main application file\n├── tests/                 # Unit, integration, and end-to-end tests\n├── .env                    # Environment variables\n├── package.json          # Node.js project configuration\n├── requirements.txt      # Python project dependencies\n└── README.md\n\n\n### 1.2 File Naming Conventions\n\n*   **Cypher Queries:** Use descriptive names (e.g., `get_user_friends.cypher`).\n*   **Models:** Name files according to the entity they represent (e.g., `user.js`, `movie.py`).\n*   **Services:** Use a service-based naming convention (e.g., `user_service.js`, `movie_service.py`).\n*   **Tests:** Match test file names to the source file names (e.g., `user_service.test.js`).\n\n### 1.3 Module Organization\n\nBreak down your application into modules based on functionality. Use well-defined interfaces and avoid circular dependencies.\n\n*   **Node.js:** Use ES modules (`import`, `export`) or CommonJS (`require`, `module.exports`).\n*   **Python:** Utilize packages and modules for organizing code.\n\n### 1.4 Component Architecture\n\nDesign a component architecture that promotes reusability and maintainability. Consider using patterns like Model-View-Controller (MVC) or a layered architecture.\n\n*   **Models:** Define data structures and interact with the Neo4j database.\n*   **Services:** Implement business logic and handle data manipulation.\n*   **Controllers (or equivalent):** Handle user requests and orchestrate interactions between models and services.\n\n### 1.5 Code Splitting\n\nFor large applications, use code splitting to improve initial load times. Load modules and components on demand when they are needed.\n\n*   **Node.js:** Use dynamic imports (`import()`) for on-demand loading.\n*   **Frontend Frameworks (if applicable):** Use framework-specific code-splitting techniques (e.g., React.lazy, Vue.js's async components).\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Repository Pattern:** Abstract data access logic behind a repository interface.  This makes it easier to switch database implementations or mock data access for testing.\n*   **Unit of Work:** Group multiple database operations into a single transaction to ensure atomicity.\n*   **Data Mapper:** Transfer data between domain objects and the database.\n*   **Graph Traversal Pattern:** Encapsulate common graph traversal logic into reusable functions or classes.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Creating Nodes and Relationships:** Use Cypher queries with parameters to avoid SQL injection and improve performance.\n*   **Querying Data:** Use Cypher's `MATCH` clause for efficient graph traversal. Leverage indexes and constraints for optimal query performance.\n*   **Data Validation:** Validate data before inserting it into the database. Use constraints to enforce data integrity at the database level.\n*   **Error Handling:** Implement robust error handling to gracefully handle database errors and prevent application crashes.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Over-fetching Data:** Avoid retrieving unnecessary data from the database. Use projections in Cypher queries to select only the required properties.\n*   **Long Cypher Queries:** Break down complex Cypher queries into smaller, more manageable queries.\n*   **Lack of Indexing:** Ensure that frequently queried properties are indexed to improve query performance.\n*   **Ignoring Constraints:** Define and enforce constraints to maintain data integrity and consistency.\n*   **Hardcoding Values:** Avoid hardcoding values in Cypher queries. Use parameters instead.\n*   **Excessive Relationship Traversal in Application Code:** Prefer to execute complex relationship traversals within Cypher rather than in application code which reduces the amount of data transported and is significantly faster.\n\n### 2.4 State Management\n\n*   **Stateless Services:** Design services to be stateless to improve scalability and testability.\n*   **Session Management:** Use appropriate session management techniques for web applications.\n*   **Caching:** Implement caching to reduce database load and improve response times.\n\n### 2.5 Error Handling\n\n*   **Centralized Error Handling:** Implement a centralized error handling mechanism to handle exceptions consistently.\n*   **Logging:** Log errors and warnings to help with debugging and monitoring.\n*   **Retry Logic:** Implement retry logic for transient database errors.\n*   **Custom Exceptions:** Define custom exceptions for specific error conditions.\n*   **Graceful Degradation:** Design the application to degrade gracefully in case of database failures.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Indexing:** Create indexes on frequently queried properties.\n*   **Constraints:** Use constraints to enforce data integrity and improve query performance.\n*   **Query Optimization:** Analyze Cypher query execution plans and optimize queries for performance.\n*   **Connection Pooling:** Use connection pooling to reuse database connections and reduce connection overhead.\n*   **Batch Operations:** Use batch operations to insert or update multiple nodes and relationships in a single transaction.\n*   **Profile Queries:** Use `PROFILE` or `EXPLAIN` to understand query performance.\n*   **Use `apoc.periodic.iterate` for batch processing** When dealing with large datasets, `apoc.periodic.iterate` allows for batch processing and avoids exceeding memory limits.\n\n### 3.2 Memory Management\n\n*   **Limit Result Set Size:** Use `LIMIT` in Cypher queries to restrict the number of returned results.\n*   **Stream Data:** Stream data from the database to avoid loading large amounts of data into memory.\n*   **Garbage Collection:** Monitor garbage collection and tune JVM settings for optimal performance (Java-based implementations).\n\n### 3.3 Bundle Size Optimization\n\n*   **Tree shaking** remove unused code\n*   **Minification:** Minify code to reduce bundle size.\n*   **Compression:** Compress bundles to reduce transfer size.\n\n### 3.4 Lazy Loading\n\n*   **On-Demand Loading:** Load data and components on demand when they are needed.\n*   **Pagination:** Use pagination to load data in smaller chunks.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Cypher Injection:** Prevent Cypher injection by using parameterized queries.\n*   **Authentication Bypass:** Secure authentication mechanisms and avoid relying on client-side authentication.\n*   **Data Exposure:** Protect sensitive data by encrypting it at rest and in transit.\n*   **Authorization Flaws:** Implement robust authorization mechanisms to control access to resources.\n\n### 4.2 Input Validation\n\n*   **Sanitize Inputs:** Sanitize user inputs to prevent Cross-Site Scripting (XSS) attacks.\n*   **Validate Inputs:** Validate user inputs to ensure they conform to expected formats and values.\n*   **Parameterize Queries:** Always use parameterized queries to prevent Cypher injection.\n\n### 4.3 Authentication and Authorization\n\n*   **Secure Authentication:** Use strong authentication mechanisms such as OAuth 2.0 or JWT.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Least Privilege Principle:** Grant users only the minimum necessary permissions.\n*   **Neo4j's built-in security:** Utilize Neo4j's built-in authentication and authorization mechanisms for database access.\n\n### 4.4 Data Protection\n\n*   **Encryption at Rest:** Encrypt sensitive data at rest using Neo4j's encryption features or third-party encryption solutions.\n*   **Encryption in Transit:** Use HTTPS to encrypt data in transit.\n*   **Data Masking:** Mask sensitive data in logs and reports.\n*   **Regular Backups:** Perform regular backups to protect against data loss.\n*   **Database Auditing:** Enable database auditing to track access and modifications to data.\n*   **Avoid Storing Sensitive Data:** Only store necessary sensitive data. Consider tokenization or anonymization where applicable.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Keys:** Use API keys to authenticate API requests.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Validation:** Validate API requests to prevent malicious input.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Individual Components:** Unit test individual components in isolation.\n*   **Mock Dependencies:** Use mocking to isolate components from external dependencies.\n*   **Test Edge Cases:** Test edge cases and boundary conditions.\n*   **Test Data Validation** Unit tests should cover data validation logic.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions:** Test the interactions between different components.\n*   **Test Database Interactions:** Test the interactions between the application and the Neo4j database.\n*   **Use Test Databases:** Use separate test databases for integration tests.\n\n### 5.3 End-to-End Testing\n\n*   **Test Full Workflows:** Test the complete end-to-end workflows of the application.\n*   **Automate Tests:** Automate end-to-end tests to ensure consistent results.\n\n### 5.4 Test Organization\n\n*   **Organize Tests:** Organize tests in a clear and logical manner.\n*   **Use Test Suites:** Use test suites to group related tests together.\n*   **Naming Convention:** Follow a clear naming convention for test files and test methods.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock Neo4j Driver:** Mock the Neo4j driver to isolate components from the database.\n*   **Stub Responses:** Stub database responses to control the data returned by the database.\n*   **Verify Interactions:** Verify that components interact with the database as expected.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Lack of Planning:** Failing to properly plan the graph schema and data model.\n*   **Ignoring Performance:** Neglecting to optimize Cypher queries and database configuration.\n*   **Poor Security:** Failing to implement proper security measures.\n*   **Insufficient Testing:** Insufficient testing leading to bugs and regressions.\n*   **Not Utilizing Indexes:** Neglecting to create indexes on frequently queried properties.\n\n### 6.2 Edge Cases\n\n*   **Large Graphs:** Handling very large graphs with millions or billions of nodes and relationships.\n*   **Concurrent Access:** Managing concurrent access to the database.\n*   **Transaction Management:** Properly managing transactions to ensure data consistency.\n*   **Handling Null Values:** Understanding how Neo4j handles null values and handling them appropriately.\n\n### 6.3 Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of the Neo4j driver and database.\n*   **Cypher Syntax:** Be aware of changes to the Cypher syntax in different versions of Neo4j.\n*   **Deprecated Features:** Avoid using deprecated features.\n\n### 6.4 Compatibility Concerns\n\n*   **Driver Compatibility:** Ensure that the Neo4j driver is compatible with the version of the Neo4j database.\n*   **Operating System Compatibility:** Ensure that the application is compatible with the target operating system.\n*   **Java Version Compatibility:** Ensure the Java version is compatible (if using Java-based drivers).\n\n### 6.5 Debugging Strategies\n\n*   **Logging:** Use logging to track the execution of the application and identify errors.\n*   **Debuggers:** Use debuggers to step through the code and inspect variables.\n*   **Neo4j Browser:** Use the Neo4j Browser to visualize the graph and execute Cypher queries.\n*   **Cypher Profiler:** Use the Cypher profiler to analyze the performance of Cypher queries.\n*   **APOC Procedures:** Use APOC Procedures to aid with debugging and monitoring.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Neo4j Browser:** A web-based interface for interacting with the Neo4j database.\n*   **Neo4j Desktop:** A desktop application for managing Neo4j databases.\n*   **IntelliJ IDEA/PyCharm:** IDEs with excellent support for Neo4j development.\n*   **VS Code:** Popular code editor with Neo4j extensions.\n*   **APOC Library:** Provides many helpful stored procedures.\n\n### 7.2 Build Configuration\n\n*   **Dependency Management:** Use a dependency management tool (e.g., npm, pip) to manage project dependencies.\n*   **Environment Variables:** Use environment variables to configure the application for different environments.\n*   **Build Scripts:** Use build scripts to automate the build process.\n\n### 7.3 Linting and Formatting\n\n*   **ESLint/Pylint:** Use linters to enforce coding standards and identify potential errors.\n*   **Prettier/Black:** Use formatters to automatically format code.\n*   **Consistent Style:** Maintain a consistent coding style throughout the project.\n\n### 7.4 Deployment Best Practices\n\n*   **Containerization:** Use containerization (e.g., Docker) to package the application and its dependencies.\n*   **Cloud Deployment:** Deploy the application to a cloud platform (e.g., AWS, Azure, GCP).\n*   **Load Balancing:** Use load balancing to distribute traffic across multiple instances of the application.\n*   **Monitoring:** Monitor the application to detect and respond to issues.\n*   **Immutable Infrastructure:** Treat servers as immutable; rebuild instead of modifying.\n\n### 7.5 CI/CD Integration\n\n*   **Automated Builds:** Automate the build process using a CI/CD pipeline.\n*   **Automated Tests:** Run automated tests as part of the CI/CD pipeline.\n*   **Automated Deployments:** Automate the deployment process using a CI/CD pipeline.\n*   **Version Control:** Use version control (e.g., Git) to manage the codebase.\n*   **Trunk-Based Development:** Consider trunk-based development for faster feedback cycles.\n\nBy following these best practices, developers can build robust, scalable, and secure Neo4j applications.",
    "metadata": {
      "globs": "*.cypher",
      "format": "mdc",
      "originalFile": "neo4j.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "neo4j",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "coding",
      "standards",
      "when",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "neo4j",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-nestjs",
    "description": "This rule provides comprehensive guidance on NestJS best practices, coding standards, and architectural patterns. It aims to help developers build scalable, maintainable, and performant NestJS applications by covering code organization, security, testing, and other essential aspects.",
    "author": "sanjeed5",
    "tags": [
      "nestjs",
      "nodejs",
      "backend",
      "typescript",
      "cursor",
      "cursor-rule",
      "mdc",
      "api",
      "javascript",
      "types",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/nestjs.mdc",
    "content": "- **Code Organization and Structure:**\n  - **Directory Structure:**\n    - Adopt a modular structure that reflects the application's domain or features. A common approach includes organizing code into modules, services, controllers, DTOs, and entities, each in their own directory.\n    - Example:\n      \n      src/\n      ├── app.module.ts\n      ├── auth/\n      │   ├── auth.module.ts\n      │   ├── auth.controller.ts\n      │   ├── auth.service.ts\n      │   ├── strategies/\n      │   │   └── jwt.strategy.ts\n      │   ├── dtos/\n      │   │   └── create-user.dto.ts\n      │   └── entities/\n      │       └── user.entity.ts\n      ├── users/\n      │   ├── users.module.ts\n      │   ├── users.controller.ts\n      │   ├── users.service.ts\n      │   └── ...\n      ├── core/\n      │   ├── filters/\n      │   │   └── http-exception.filter.ts\n      │   ├── interceptors/\n      │   │   └── logging.interceptor.ts\n      │   └── ...\n      └── main.ts\n      \n  - **File Naming Conventions:**\n    - Use descriptive and consistent naming conventions.  Prefix files based on their role (e.g., `user.controller.ts`, `auth.service.ts`, `create-user.dto.ts`).\n    - Use PascalCase for classes and interfaces (e.g., `UserService`, `CreateUserDto`).\n    - Use camelCase for instances and variables (e.g., `userService`, `createUserDto`).\n  - **Module Organization:**\n    - Encapsulate features within modules. Each module should represent a distinct part of the application and handle related functionality.\n    - Modules should import necessary dependencies and export components that other modules need.\n    - Use the `forRoot` and `forFeature` methods for configuration and feature modules, respectively, especially when dealing with database connections or other shared resources.\n  - **Component Architecture:**\n    - Follow the SOLID principles for designing components.  Each component (controller, service, etc.) should have a single responsibility.\n    - Use dependency injection to manage dependencies between components, making them more testable and maintainable.\n    - Controllers should handle request routing and validation, services should implement business logic, and entities should represent data models.\n  - **Code Splitting Strategies:**\n    - For large applications, consider splitting modules into smaller, more manageable chunks using feature modules or lazy-loaded modules.\n    - Use dynamic imports and lazy loading to improve initial load times and reduce bundle size.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Dependency Injection:** Use NestJS's built-in dependency injection container to manage dependencies and promote loose coupling.\n    - **Repository Pattern:** Abstract data access logic into repositories to decouple services from specific database implementations.\n    - **Unit of Work:**  Use a Unit of Work pattern for managing transactions across multiple repositories.\n    - **CQRS (Command Query Responsibility Segregation):** For complex applications, consider using CQRS to separate read and write operations, improving performance and scalability.\n  - **Recommended Approaches:**\n    - Use DTOs (Data Transfer Objects) for data validation and transformation between layers.\n    - Implement global exception filters to handle errors consistently across the application.\n    - Use interceptors for logging, caching, and other cross-cutting concerns.\n    - Utilize pipes for request validation and data transformation.\n    - Use asynchronous operations (`async/await`) for non-blocking I/O operations.\n  - **Anti-patterns:**\n    - **Tight Coupling:** Avoid creating tightly coupled components that are difficult to test and maintain. Use dependency injection and interfaces to promote loose coupling.\n    - **God Classes:** Avoid creating classes with too many responsibilities. Break down large classes into smaller, more manageable components.\n    - **Ignoring Errors:** Always handle errors properly using try-catch blocks, exception filters, and logging. Never ignore errors or swallow exceptions.\n    - **Hardcoding Configuration:** Avoid hardcoding configuration values directly in the code. Use environment variables or configuration files to manage settings.\n  - **State Management:**\n    - For simple applications, use services to manage application state.\n    - For more complex applications, consider using a state management library like Redux or NgRx (although this is less common on the backend).\n    - Avoid storing sensitive data in the client-side state. Store it securely on the server.\n  - **Error Handling:**\n    - Implement a global exception filter to catch unhandled exceptions and return appropriate error responses to the client.\n    - Use custom exceptions to represent specific error conditions in the application.\n    - Log errors with sufficient detail to facilitate debugging.\n    - Return consistent error responses with appropriate HTTP status codes.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use caching to reduce database load and improve response times.  NestJS provides built-in support for caching using interceptors.\n    - Optimize database queries by using indexes, avoiding N+1 queries, and using efficient data retrieval methods.\n    - Use connection pooling to reduce the overhead of establishing database connections.\n    - Profile the application to identify performance bottlenecks and optimize accordingly.\n  - **Memory Management:**\n    - Avoid memory leaks by properly managing resources and releasing unused objects.\n    - Use streams for handling large files or data streams.\n    - Use object pooling to reuse frequently created objects.\n  - **Rendering Optimization (Server-Side Rendering):**\n    - Not directly applicable to NestJS, as it's primarily a backend framework. However, if using SSR, optimize rendering performance by caching rendered pages and using efficient templating engines.\n  - **Bundle Size Optimization:**\n    - Use tree shaking to remove unused code from the bundle.\n    - Minify and compress code to reduce bundle size.\n    - Use code splitting to load only the necessary code for each route or module.\n  - **Lazy Loading:**\n    - Use lazy loading to load modules or features on demand, improving initial load times.\n    - Implement code splitting to create smaller bundles that can be loaded independently.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM that automatically escapes user inputs.\n    - **Cross-Site Scripting (XSS):** Protect against XSS by sanitizing user inputs and encoding outputs.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection using tokens or other mechanisms.\n    - **Authentication and Authorization Flaws:** Secure authentication and authorization by using strong passwords, multi-factor authentication, and role-based access control.\n    - **Insecure Direct Object References (IDOR):** Prevent IDOR by validating user access to resources before granting access.\n  - **Input Validation:**\n    - Validate all user inputs to prevent malicious data from entering the system. Use DTOs and validation pipes to enforce input constraints.\n    - Sanitize user inputs to remove or escape potentially harmful characters.\n    - Validate file uploads to prevent malicious files from being uploaded.\n  - **Authentication and Authorization:**\n    - Use JWT (JSON Web Tokens) for authentication and authorization.\n    - Implement role-based access control (RBAC) to restrict access to resources based on user roles.\n    - Use secure password hashing algorithms (e.g., bcrypt) to store passwords securely.\n    - Implement rate limiting to prevent brute-force attacks.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to encrypt communication between the client and server.\n    - Store secrets securely using environment variables or a secrets management system.\n  - **Secure API Communication:**\n    - Use API keys or OAuth 2.0 for API authentication and authorization.\n    - Implement request validation and rate limiting to protect APIs from abuse.\n    - Use a secure API gateway to manage API traffic and enforce security policies.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Write unit tests for individual components (services, controllers, etc.) to verify their functionality in isolation.\n    - Use mocking and stubbing to isolate components from their dependencies.\n    - Follow the Arrange-Act-Assert pattern for writing clear and concise unit tests.\n  - **Integration Testing:**\n    - Write integration tests to verify the interaction between multiple components or modules.\n    - Test the integration between the application and external systems (e.g., databases, APIs).\n  - **End-to-End Testing:**\n    - Write end-to-end tests to verify the application's functionality from a user's perspective.\n    - Use tools like Puppeteer or Cypress to automate end-to-end tests.\n  - **Test Organization:**\n    - Organize tests into separate directories that mirror the application's directory structure.\n    - Use descriptive names for test files and test cases.\n  - **Mocking and Stubbing:**\n    - Use mocking frameworks (e.g., Jest, Sinon.js) to create mock objects and stub methods.\n    - Use dependency injection to make components easily testable.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - **Not using DTOs for validation:** Always use DTOs and validation pipes to ensure data integrity.\n    - **Ignoring environment variables:** Use environment variables for configuration to avoid hardcoding values.\n    - **Not handling exceptions properly:** Implement global exception filters to catch unhandled exceptions and return appropriate error responses.\n    - **Overlooking security vulnerabilities:** Be aware of common security vulnerabilities and take steps to mitigate them.\n  - **Edge Cases:**\n    - **Handling large file uploads:** Use streams and appropriate buffering techniques to handle large file uploads efficiently.\n    - **Dealing with concurrent requests:** Use appropriate locking mechanisms or transaction management to handle concurrent requests safely.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between NestJS versions and update code accordingly.\n    - Consult the NestJS documentation for migration guides and compatibility information.\n  - **Compatibility Concerns:**\n    - Ensure compatibility with different Node.js versions and operating systems.\n    - Test the application on different browsers and devices to ensure cross-platform compatibility.\n  - **Debugging Strategies:**\n    - Use the NestJS debugger to step through code and inspect variables.\n    - Use logging to track the flow of execution and identify errors.\n    - Use profiling tools to identify performance bottlenecks.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:**\n    - **IDE:** Visual Studio Code with NestJS extensions.\n    - **CLI:** Nest CLI for generating and managing NestJS projects.\n    - **Database:** PostgreSQL, MySQL, MongoDB, or other compatible database.\n    - **Testing:** Jest, Supertest.\n  - **Build Configuration:**\n    - Use `tsconfig.json` to configure the TypeScript compiler.\n    - Use Webpack or Parcel to bundle and optimize the application.\n  - **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce code style and formatting rules.\n    - Configure pre-commit hooks to automatically lint and format code before committing.\n  - **Deployment:**\n    - Deploy to platforms like Heroku, AWS, Google Cloud, or Azure.\n    - Use Docker to containerize the application and simplify deployment.\n  - **CI/CD Integration:**\n    - Integrate with CI/CD pipelines (e.g., Jenkins, Travis CI, GitHub Actions) to automate testing and deployment.\n    - Use environment-specific configuration files for different environments (development, staging, production).",
    "metadata": {
      "globs": "*.ts",
      "format": "mdc",
      "originalFile": "nestjs.mdc"
    },
    "subcategory": "nodejs",
    "keywords": [
      "cursor",
      "nestjs",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "coding",
      "standards",
      "nodejs",
      "backend",
      "typescript",
      "cursor-rule",
      "mdc",
      "api",
      "javascript",
      "types",
      "type-safety",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "nestjs",
        "nodejs",
        "backend",
        "typescript",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-netlify",
    "description": "This rule file outlines best practices for Netlify development, covering code structure, performance, security, testing, and deployment. It aims to provide a comprehensive guide for building robust and scalable applications on Netlify.",
    "author": "sanjeed5",
    "tags": [
      "netlify",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/netlify.mdc",
    "content": "# Netlify Library Best Practices and Coding Standards\n\nThis document outlines best practices for developing applications using Netlify, encompassing code organization, performance considerations, security measures, testing strategies, and deployment procedures. Adhering to these guidelines will ensure the creation of robust, scalable, and maintainable applications on the Netlify platform.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nA well-defined directory structure is crucial for maintainability and collaboration.  Here's a recommended structure:\n\n\nproject-root/\n├── .netlify/          # Netlify-specific configuration (auto-generated)\n├── functions/        # Serverless functions\n│   └── api/          # API endpoint functions\n│       └── hello.js\n├── src/              # Source code\n│   ├── components/   # Reusable UI components\n│   │   ├── Button.jsx\n│   │   └── Header.jsx\n│   ├── pages/        # Pages for different routes\n│   │   ├── index.jsx\n│   │   └── about.jsx\n│   ├── styles/       # CSS, SCSS, or other styling\n│   │   ├── global.css\n│   │   └── components/\n│   ├── utils/        # Utility functions\n│   │   └── api.js\n│   ├── App.jsx       # Main application component\n│   ├── index.jsx     # Entry point for React\n│   └── routes.js     # Routing configuration\n├── static/           # Static assets (images, fonts, etc.)\n│   ├── img/\n│   └── fonts/\n├── public/           # Public files to be deployed\n│   └── index.html\n├── tests/            # Tests\n│   ├── unit/\n│   └── integration/\n├── netlify.toml      # Netlify configuration file\n├── package.json      # Node.js dependencies\n└── README.md\n\n\n### 1.2 File Naming Conventions\n\n*   **Components:** Use PascalCase for component file names (e.g., `MyComponent.jsx`).\n*   **Styles:** Use kebab-case for style file names (e.g., `my-component.css`).\n*   **Functions:** Use camelCase or kebab-case for function file names (e.g., `helloWorld.js` or `hello-world.js`).\n*   **Images:** Use descriptive names (e.g., `product-image.jpg`).\n\n### 1.3 Module Organization\n\n*   **Group Related Code:**  Place related functions, components, and styles into separate modules/directories.\n*   **Single Responsibility Principle:** Each module should have a clear and single purpose.\n*   **Avoid Circular Dependencies:**  Carefully manage dependencies between modules to prevent circular dependencies.\n*   **Use ES Modules:** Utilize ES modules (`import/export`) for better code organization and tree shaking.\n\n### 1.4 Component Architecture\n\n*   **Component-Based Approach:** Build your UI using reusable components.\n*   **Presentational and Container Components:** Separate concerns by using presentational components (UI only) and container components (data fetching and logic).\n*   **Atomic Design:**  Consider using atomic design principles (atoms, molecules, organisms, templates, pages) for a scalable component architecture.\n\n### 1.5 Code Splitting\n\n*   **Dynamic Imports:**  Use dynamic imports (`import()`) to load modules on demand.\n*   **Route-Based Splitting:** Split your application based on routes so that only the necessary code is loaded for a given route. This will improve the initial loading time for the end user.\n*   **Component-Based Splitting:** Use React.lazy or similar mechanisms to load components only when they are needed.\n*   **Webpack or Parcel Bundler Configuration:** Configure your bundler (Webpack, Parcel, etc.) for optimal code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **JAMstack Architecture:**  Embrace the JAMstack architecture (JavaScript, APIs, Markup) for faster and more secure websites.\n*   **Serverless Functions:** Utilize Netlify Functions for backend logic (API endpoints, background tasks).  Follow the function handler structure and consider using middleware for common tasks like authentication.\n*   **Git-Based Workflow:** Use Git for version control and continuous deployment with Netlify.\n*   **Environment Variables:** Store sensitive information (API keys, database credentials) in environment variables, and access them from your serverless functions. Ensure you configure these in Netlify's UI and use `process.env.VARIABLE_NAME`.\n\n### 2.2 Recommended Approaches\n\n*   **Form Handling:** Use libraries like Formik or React Hook Form for form handling.\n*   **State Management:**  Choose a state management solution appropriate for the complexity of your application (e.g., Context API, Redux, Zustand).\n*   **API Calls:** Use `fetch` or libraries like Axios for making API calls.  Implement error handling and loading states.\n*   **Image Optimization:** Optimize images before deployment to improve performance.  Consider using Netlify Large Media for automatic image optimization.\n\n### 2.3 Anti-patterns\n\n*   **Committing Secrets:** Avoid committing API keys or other secrets to your Git repository.\n*   **Over-reliance on Client-Side Rendering:**  Minimize client-side rendering for better SEO and initial load time. Use static site generation (SSG) or server-side rendering (SSR) where appropriate.\n*   **Ignoring Performance Budgets:**  Establish performance budgets and monitor your application's performance regularly. Use tools such as Lighthouse, WebPageTest, and Chrome DevTools.\n*   **Unnecessary Dependencies:**  Avoid including unnecessary dependencies in your project.\n*   **Direct DOM Manipulation:** Avoid direct DOM manipulation in React components; let React handle the updates.\n\n### 2.4 State Management\n\n*   **Context API:**  Use React's Context API for simple state management.\n*   **Redux:**  Use Redux for more complex state management requirements.\n*   **Zustand:** Consider Zustand for a simple and unopinionated state management solution.\n*   **Avoid Global State:** Minimize the use of global state to avoid performance issues and make code easier to reason about.\n*   **Immutable Updates:** Use immutable updates when updating state to improve performance and prevent unexpected side effects.\n\n### 2.5 Error Handling\n\n*   **Try-Catch Blocks:**  Use try-catch blocks in your serverless functions to handle errors gracefully.\n*   **Centralized Error Handling:**  Implement a centralized error handling mechanism to log errors and display user-friendly messages.\n*   **ErrorBoundary:**  Use React's `ErrorBoundary` component to catch errors in your UI.\n*   **Logging:** Log errors to a service like Sentry, Rollbar, or Netlify's built-in logging for monitoring and debugging.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Code Splitting:**  Implement code splitting to reduce initial load time.\n*   **Lazy Loading:** Lazy load images and other assets to improve performance.\n*   **Image Optimization:** Optimize images using tools like ImageOptim, TinyPNG, or Netlify Large Media.\n*   **Caching:**  Utilize browser caching and CDN caching to reduce server load and improve response times. Netlify automatically handles CDN caching.\n*   **Minification:**  Minify your CSS and JavaScript files to reduce their size.\n*   **Compression:** Use Gzip or Brotli compression to reduce the size of your files.\n\n### 3.2 Memory Management\n\n*   **Avoid Memory Leaks:**  Be careful to avoid memory leaks in your JavaScript code. Properly clean up event listeners and timers.\n*   **Use Efficient Data Structures:** Use appropriate data structures for your data to optimize memory usage.\n*   **Limit Large Data Sets:**  Avoid loading large datasets into memory if possible.\n\n### 3.3 Rendering Optimization (if applicable)\n\n*   **Virtual DOM:** React's Virtual DOM provides significant rendering optimization. Ensure you are using React efficiently, minimizing unnecessary re-renders.\n*   **Memoization:** Use `React.memo` to prevent re-rendering components unless their props change.\n*   **Pure Components:**  Use `PureComponent` or implement `shouldComponentUpdate` for class components to prevent unnecessary re-renders.\n\n### 3.4 Bundle Size Optimization\n\n*   **Analyze Bundle Size:** Use tools like Webpack Bundle Analyzer or Parcel Size Analyzer to identify large dependencies.\n*   **Tree Shaking:**  Enable tree shaking in your bundler to remove unused code.\n*   **Code Minimization:** Utilize code minification in your build process.\n*   **Remove Unused Dependencies:** Review your dependencies and remove any unused ones.\n\n### 3.5 Lazy Loading\n\n*   **Intersection Observer:**  Use the Intersection Observer API to lazy load images and other assets when they come into view.\n*   **React Lazy:** Use React.lazy for component-level lazy loading.\n*   **Dynamic Imports:**  Use dynamic imports for modules that are not needed immediately.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user inputs and escaping output.\n*   **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using CSRF tokens.\n*   **Injection Attacks:**  Prevent SQL injection and other injection attacks by using parameterized queries and validating user inputs.\n*   **Authentication and Authorization:**  Implement secure authentication and authorization mechanisms to protect sensitive data.\n*   **Exposed API Keys:** Avoid exposing API keys in client-side code. Store them in environment variables and access them from your serverless functions.\n\n### 4.2 Input Validation\n\n*   **Client-Side Validation:** Use client-side validation to provide immediate feedback to users.\n*   **Server-Side Validation:**  Always perform server-side validation to ensure data integrity and prevent malicious inputs.\n*   **Sanitization:** Sanitize user inputs to remove potentially harmful characters.\n*   **Escaping:** Escape output to prevent XSS attacks.\n\n### 4.3 Authentication and Authorization\n\n*   **Netlify Identity:** Use Netlify Identity for simple authentication and authorization.\n*   **Third-Party Authentication:**  Use third-party authentication providers like Auth0, Firebase Authentication, or AWS Cognito.\n*   **JSON Web Tokens (JWT):** Use JWTs to securely transmit user information between the client and server.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n\n### 4.4 Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Secure Storage:** Store sensitive data in secure storage locations.\n*   **Regular Backups:** Perform regular backups of your data.\n*   **Data Minimization:** Only collect and store the data that is necessary.\n*   **Compliance:** Ensure your application complies with relevant data protection regulations (e.g., GDPR, CCPA).\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Keys:** Use API keys to authenticate requests to your API.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n*   **CORS:** Configure CORS (Cross-Origin Resource Sharing) to allow only authorized domains to access your API.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components in isolation.\n*   **Mock Dependencies:** Mock dependencies to isolate the component being tested.\n*   **Test All Code Paths:** Test all code paths, including error handling.\n*   **Use a Testing Framework:** Use a testing framework like Jest, Mocha, or Jasmine.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions:** Integration tests should focus on testing the interactions between different components and modules.\n*   **Test API Calls:** Test the integration with your API endpoints.\n*   **Use a Testing Framework:** Use a testing framework like Cypress, Puppeteer, or Selenium.\n\n### 5.3 End-to-End Testing\n\n*   **Test User Flows:** End-to-end tests should focus on testing complete user flows.\n*   **Simulate User Interactions:** Simulate user interactions, such as clicking buttons and filling out forms.\n*   **Use a Testing Framework:** Use a testing framework like Cypress, Puppeteer, or Selenium.\n\n### 5.4 Test Organization\n\n*   **Separate Test Files:** Create separate test files for each component or module.\n*   **Organize Tests by Type:** Organize tests by type (unit, integration, end-to-end).\n*   **Use Descriptive Test Names:** Use descriptive test names to make it easier to understand what each test is testing.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock API Calls:** Mock API calls to avoid making real API calls during testing.\n*   **Stub Dependencies:** Stub dependencies to isolate the component being tested.\n*   **Use a Mocking Library:** Use a mocking library like Jest's `jest.mock` or Sinon.js.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Not Using Environment Variables:**  Failing to use environment variables for sensitive information.\n*   **Over-complicating Serverless Functions:** Creating serverless functions that are too large and complex.\n*   **Not Handling Errors:**  Failing to handle errors gracefully in serverless functions.\n*   **Ignoring Performance:**  Ignoring performance considerations and creating slow-loading applications.\n*   **Not Testing:**  Failing to test your application thoroughly.\n\n### 6.2 Edge Cases\n\n*   **Long Build Times:**  Long build times can be a problem for large applications. Optimize your build process to reduce build times.\n*   **Function Cold Starts:**  Serverless functions can experience cold starts, which can increase response times. Use techniques like keep-alive to reduce cold start times.\n*   **CDN Invalidation:**  Ensure your CDN invalidates cache correctly when you deploy new versions of your application.\n\n### 6.3 Version-Specific Issues\n\n*   **Netlify CLI Updates:** Stay up-to-date with the latest Netlify CLI to avoid compatibility issues.\n*   **Node.js Versions:**  Ensure your Node.js version is compatible with Netlify Functions.\n*   **Dependency Updates:**  Regularly update your dependencies to address security vulnerabilities and bug fixes.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:**  Test your application in different browsers to ensure compatibility.\n*   **Device Compatibility:**  Test your application on different devices (desktop, mobile, tablet) to ensure compatibility.\n*   **Accessibility:** Ensure your application is accessible to users with disabilities by following accessibility guidelines (WCAG).\n\n### 6.5 Debugging Strategies\n\n*   **Netlify Logs:** Use Netlify's built-in logging to debug issues.\n*   **Console Logging:**  Use `console.log` statements to debug your code.\n*   **Debugging Tools:** Use browser debugging tools like Chrome DevTools or Firefox Developer Tools.\n*   **Remote Debugging:**  Use remote debugging tools to debug serverless functions.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n*   **VS Code:** VS Code with extensions like ESLint, Prettier, and Netlify.\n*   **Netlify CLI:** Netlify Command Line Interface for local development and deployment.\n*   **Git:** Git for version control.\n*   **npm or Yarn:** npm or Yarn for package management.\n*   **Webpack, Parcel, or Rollup:**  Webpack, Parcel, or Rollup for bundling your code.\n\n### 7.2 Build Configuration\n\n*   **Netlify TOML:** Use the `netlify.toml` file to configure your build process. Set environment variables, build commands, and deploy contexts.\n*   **Build Commands:**  Define build commands to transpile your code, optimize assets, and generate static files.\n*   **Deploy Contexts:** Use deploy contexts to create different environments (e.g., production, staging, development).\n\n### 7.3 Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce code style and prevent errors.\n*   **Prettier:**  Use Prettier to automatically format your code.\n*   **Husky and lint-staged:** Use Husky and lint-staged to run linters and formatters before committing code.\n\n### 7.4 Deployment\n\n*   **Git-Based Deployment:**  Deploy your application by pushing your code to a Git repository connected to Netlify.\n*   **Netlify CLI Deployment:**  Deploy your application using the Netlify CLI.\n*   **Atomic Deploys:** Netlify provides atomic deploys, ensuring that your site is always in a consistent state during updates.\n*   **Rollbacks:** Easily roll back to previous deployments if necessary.\n\n### 7.5 CI/CD Integration\n\n*   **GitHub Actions:**  Integrate with GitHub Actions for automated testing and deployment.\n*   **CircleCI:** Integrate with CircleCI for continuous integration and continuous deployment.\n*   **Travis CI:** Integrate with Travis CI for continuous integration and continuous deployment.\n\nBy following these best practices, you can create robust, scalable, secure, and maintainable applications using Netlify.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.html,*.css,*.scss,*.md",
      "format": "mdc",
      "originalFile": "netlify.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "netlify",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "netlify",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-next-js",
    "description": "This rule provides comprehensive guidance for Next.js development, covering code organization, performance, security, testing, and common pitfalls. It helps developers build robust, scalable, and maintainable Next.js applications by adhering to community-accepted best practices and coding standards.",
    "author": "sanjeed5",
    "tags": [
      "next-js",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/next-js.mdc",
    "content": "# Next.js Best Practices\n\nThis document outlines best practices for developing Next.js applications, focusing on code organization, performance optimization, security, testing strategies, and common pitfalls to avoid. Adhering to these guidelines will help you build robust, scalable, and maintainable applications.\n\n## 1. Code Organization and Structure\n\n### Directory Structure\n\n*   **`app/`**: (Recommended - Next.js 13+) Contains route handlers, server components, and client components.\n    *   `page.tsx`: Represents the UI for a route.\n    *   `layout.tsx`: Defines the layout for a route and its children.\n    *   `loading.tsx`: Displays a loading UI while a route segment is loading.\n    *   `error.tsx`: Handles errors within a route segment.\n    *   `head.tsx`: Manages the `<head>` metadata for a route.\n    *   `route.ts`: Defines server-side route handlers (API routes).\n    *   `[dynamic-segment]`: Dynamic route segments, using brackets.\n    *   `@folder-name`:  Route Groups to organize routes without affecting URL structure.\n*   **`pages/`**: (Legacy - Before Next.js 13) Contains page components.\n    *   `api/`: Serverless functions (API routes).\n    *   `_app.js/tsx`: Custom App component (wraps all pages).\n    *   `_document.js/tsx`: Custom Document component (control the entire HTML document).\n*   **`components/`**: Reusable UI components.\n*   **`lib/`**: Utility functions, helper functions, and third-party integrations.\n*   **`hooks/`**: Custom React hooks.\n*   **`styles/`**: Global styles and CSS modules.\n*   **`public/`**: Static assets (images, fonts, etc.).\n*   **`types/`**: TypeScript type definitions and interfaces.\n*   **`utils/`**: Contains utilities and helper functions, along with any API-related logic.\n\n**Recommendation:**  Prefer the `app/` directory structure for new projects as it aligns with the latest Next.js features and best practices.  When using `pages/`, keep it simple and migrate to `app/` when feasible.\n\n### File Naming Conventions\n\n*   **Components:** `ComponentName.jsx` or `ComponentName.tsx`\n*   **Pages:** `page.js`, `page.jsx`, `page.ts`, `page.tsx` (within the `app` or `pages` directory)\n*   **Layouts:** `layout.js`, `layout.jsx`, `layout.ts`, `layout.tsx` (within the `app` directory)\n*   **API Routes:** `route.js`, `route.ts` (within the `app/api` directory or `pages/api` directory)\n*   **Hooks:** `useHookName.js` or `useHookName.ts`\n*   **Styles:** `ComponentName.module.css` or `ComponentName.module.scss`\n*   **Types:** `types.ts` or `interfaces.ts`\n\n### Module Organization\n\n*   **Co-location:** Keep related components, styles, and tests in the same directory.\n*   **Feature-based modules:** Group files by feature rather than type (e.g., `components/user-profile/`, not `components/button`, `components/form`).\n*   **Avoid deeply nested directories:** Keep the directory structure relatively flat to improve navigation.\n\n### Component Architecture\n\n*   **Presentational vs. Container Components:** Separate components that handle data fetching and state management (container components) from those that only render UI (presentational components).\n*   **Atomic Design:** Organize components into atoms, molecules, organisms, templates, and pages for better reusability and maintainability.\n*   **Composition over inheritance:** Favor composition to create flexible and reusable components.\n*   **Server Components (app directory):**  Use server components by default for improved performance.  Only use client components when interactivity (event handlers, useState, useEffect) is required.\n\n### Code Splitting\n\n*   **Dynamic imports:** Use `next/dynamic` to load components only when they are needed, improving initial load time.  Example: `dynamic(() => import('../components/MyComponent'))`.\n*   **Route-level code splitting:** Next.js automatically splits code based on routes, so each page only loads the necessary JavaScript.\n*   **Granular code splitting:** Break down large components into smaller chunks that can be loaded independently.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Higher-Order Components (HOCs):** Reusable component logic.\n*   **Render Props:** Sharing code between React components using a prop whose value is a function.\n*   **Hooks:** Extracting stateful logic into reusable functions.\n*   **Context API:** Managing global state.\n*   **Compound Components:** Combining multiple components that work together implicitly.\n\n### Recommended Approaches\n\n*   **Data fetching:** Use `getServerSideProps` or `getStaticProps` or server components for fetching data on the server-side. Use `SWR` or `React Query` for client-side data fetching and caching.\n*   **Styling:** Use CSS Modules, Styled Components, or Tailwind CSS for component-level styling.  Prefer Tailwind CSS for rapid development.\n*   **State Management:** Use React Context, Zustand, Jotai, or Recoil for managing global state.  Redux is an option, but often overkill for smaller Next.js projects.\n*   **Form Handling:** Use `react-hook-form` for managing forms and validation.\n*   **API Routes:** Use Next.js API routes for serverless functions.\n\n### Anti-patterns and Code Smells\n\n*   **Over-fetching data:** Only fetch the data that is needed by the component.\n*   **Blocking the main thread:** Avoid long-running synchronous operations in the main thread.\n*   **Mutating state directly:** Always use `setState` or hooks to update state.\n*   **Not memoizing components:** Use `React.memo` to prevent unnecessary re-renders.\n*   **Using `useEffect` without a dependency array:** Ensure the dependency array is complete to prevent unexpected behavior.\n*   **Writing server side code in client components:** Can expose secrets or cause unexpected behavior.\n\n### State Management\n\n*   **Local State:** Use `useState` for component-specific state.\n*   **Context API:** Use `useContext` for application-wide state that doesn't change often.\n*   **Third-party libraries:** Use `Zustand`, `Jotai`, or `Recoil` for more complex state management needs. These are simpler and more performant alternatives to Redux for many Next.js use cases.\n\n### Error Handling\n\n*   **`try...catch`:** Use `try...catch` blocks for handling errors in asynchronous operations.\n*   **Error Boundary Components:** Create reusable error boundary components to catch errors in child components. Implement `getDerivedStateFromError` or `componentDidCatch` lifecycle methods.\n*   **Centralized error logging:** Log errors to a central service like Sentry or Bugsnag.\n*   **Custom Error Pages:** Use `_error.js` or `_error.tsx` to create custom error pages.\n*   **Route-level error handling (app directory):** Use `error.tsx` within route segments to handle errors specific to that route.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Image optimization:** Use `next/image` component for automatic image optimization, including lazy loading and responsive images.\n*   **Font optimization:**  Use `next/font` to optimize font loading and prevent layout shift.\n*   **Code splitting:** Use dynamic imports and route-level code splitting to reduce initial load time.\n*   **Caching:** Use caching strategies (e.g., `Cache-Control` headers, `SWR`, `React Query`) to reduce data fetching overhead.\n*   **Memoization:** Use `React.memo` to prevent unnecessary re-renders of components.\n*   **Prefetching:** Use the `<Link prefetch>` tag to prefetch pages that are likely to be visited.\n*   **SSR/SSG:** Use Static Site Generation (SSG) for content that doesn't change often and Server-Side Rendering (SSR) for dynamic content.\n*   **Incremental Static Regeneration (ISR):** Use ISR to update statically generated pages on a regular interval.\n\n### Memory Management\n\n*   **Avoid memory leaks:** Clean up event listeners and timers in `useEffect` hooks.\n*   **Minimize re-renders:** Only update state when necessary to reduce the number of re-renders.\n*   **Use immutable data structures:** Avoid mutating data directly to prevent unexpected side effects.\n\n### Rendering Optimization\n\n*   **Server Components (app directory):**  Render as much as possible on the server to reduce client-side JavaScript.\n*   **Client Components (app directory):** Only use client components when interactivity is required. Defer rendering of non-critical client components using `React.lazy`.\n\n### Bundle Size Optimization\n\n*   **Analyze bundle size:** Use tools like `webpack-bundle-analyzer` to identify large dependencies.\n*   **Remove unused code:** Use tree shaking to remove unused code from your bundles.\n*   **Use smaller dependencies:** Replace large dependencies with smaller, more lightweight alternatives.\n*   **Compression:** Enable Gzip or Brotli compression on your server to reduce the size of the transferred files.\n\n### Lazy Loading\n\n*   **Images:** Use `next/image` for automatic lazy loading of images.\n*   **Components:** Use `next/dynamic` for lazy loading of components.\n*   **Intersection Observer:** Use the Intersection Observer API for manual lazy loading of content.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.  Be especially careful when rendering HTML directly from user input.\n*   **Cross-Site Request Forgery (CSRF):** Use CSRF tokens to protect against CSRF attacks.\n*   **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n*   **Authentication and Authorization vulnerabilities:** Implement secure authentication and authorization mechanisms.  Avoid storing secrets in client-side code.\n*   **Exposing sensitive data:** Protect API keys and other sensitive data by storing them in environment variables and accessing them on the server-side.\n\n### Input Validation\n\n*   **Server-side validation:** Always validate user input on the server-side.\n*   **Client-side validation:** Use client-side validation for immediate feedback, but don't rely on it for security.\n*   **Sanitize input:** Sanitize user input to remove potentially malicious code.\n*   **Use a validation library:** Use a library like `zod` or `yup` for validating user input.\n\n### Authentication and Authorization\n\n*   **Use a secure authentication provider:** Use a service like Auth0, NextAuth.js, or Firebase Authentication for secure authentication.\n*   **Store tokens securely:** Store tokens in HTTP-only cookies or local storage.\n*   **Implement role-based access control:** Use role-based access control to restrict access to sensitive resources.\n*   **Protect API endpoints:** Use authentication middleware to protect API endpoints.\n\n### Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **Regularly update dependencies:** Keep your dependencies up to date to patch security vulnerabilities.\n*   **Secure environment variables:**  Never commit environment variables to your repository.  Use a secrets management tool if necessary.\n\n### Secure API Communication\n\n*   **Use HTTPS:** Use HTTPS for all API communication.\n*   **Authenticate API requests:** Use API keys or tokens to authenticate API requests.\n*   **Rate limiting:** Implement rate limiting to prevent abuse of your API.\n*   **Input validation:** Validate all API request parameters.\n*   **Output encoding:** Properly encode API responses to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   **Test individual components:** Write unit tests for individual components to ensure they are working correctly.\n*   **Use a testing framework:** Use a testing framework like Jest or Mocha.\n*   **Mock dependencies:** Mock external dependencies to isolate components during testing.\n*   **Test edge cases:** Test edge cases and error conditions to ensure the component is robust.\n*   **Use React Testing Library:** Prefer React Testing Library for component testing as it encourages testing from a user perspective, promoting better accessibility and more robust tests.\n\n### Integration Testing\n\n*   **Test interactions between components:** Write integration tests to ensure that components are working together correctly.\n*   **Test API calls:** Test API calls to ensure that data is being fetched and saved correctly.\n*   **Use a testing framework:** Use a testing framework like Jest or Mocha with libraries like `msw` (Mock Service Worker) to intercept and mock API calls.\n\n### End-to-End Testing\n\n*   **Test the entire application:** Write end-to-end tests to ensure that the entire application is working correctly.\n*   **Use a testing framework:** Use a testing framework like Cypress or Playwright.\n*   **Test user flows:** Test common user flows to ensure that the application is providing a good user experience.\n*   **Focus on critical paths:**  Prioritize end-to-end tests for critical user flows to ensure application stability.\n\n### Test Organization\n\n*   **Co-locate tests with components:** Keep tests in the same directory as the components they are testing.\n*   **Use a consistent naming convention:** Use a consistent naming convention for test files (e.g., `ComponentName.test.js`).\n*   **Organize tests by feature:** Organize tests by feature to improve maintainability.\n\n### Mocking and Stubbing\n\n*   **Mock external dependencies:** Mock external dependencies to isolate components during testing.\n*   **Stub API calls:** Stub API calls to prevent network requests during testing.\n*   **Use a mocking library:** Use a mocking library like Jest's built-in mocking capabilities or `msw`.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   **Not understanding server-side rendering:**  Failing to utilize SSR effectively can impact SEO and initial load performance.\n*   **Over-complicating state management:** Using Redux for simple state management needs can add unnecessary complexity.\n*   **Not optimizing images:** Not using `next/image` can result in large image sizes and slow loading times.\n*   **Ignoring security best practices:** Neglecting security can lead to vulnerabilities.\n*   **Not testing the application thoroughly:** Insufficient testing can result in bugs and regressions.\n*   **Accidentally exposing API keys or secrets in client-side code.**\n\n### Edge Cases\n\n*   **Handling errors gracefully:** Implement proper error handling to prevent the application from crashing.\n*   **Dealing with different screen sizes:** Ensure the application is responsive and works well on different screen sizes.\n*   **Supporting different browsers:** Test the application in different browsers to ensure compatibility.\n*   **Managing complex data structures:** Use appropriate data structures and algorithms to efficiently manage complex data.\n\n### Version-Specific Issues\n\n*   **Breaking changes:** Be aware of breaking changes when upgrading Next.js versions.\n*   **Deprecated features:** Avoid using deprecated features.\n*   **Compatibility with third-party libraries:** Ensure that third-party libraries are compatible with the Next.js version being used.\n\n### Compatibility Concerns\n\n*   **Browser compatibility:** Ensure that the application is compatible with the target browsers.\n*   **Third-party library compatibility:** Ensure that third-party libraries are compatible with Next.js.\n\n### Debugging Strategies\n\n*   **Use the browser developer tools:** Use the browser developer tools to inspect the DOM, debug JavaScript, and analyze network requests.\n*   **Use console.log statements:** Use `console.log` statements to debug code.\n*   **Use a debugger:** Use a debugger to step through code and inspect variables.\n*   **Use error logging:** Log errors to a central service to track and analyze issues.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n*   **VS Code:** Code editor with excellent support for JavaScript, TypeScript, and React.\n*   **ESLint:** Linter for identifying and fixing code style issues.\n*   **Prettier:** Code formatter for automatically formatting code.\n*   **Chrome Developer Tools:** Browser developer tools for debugging and profiling.\n*   **React Developer Tools:** Browser extension for inspecting React components.\n*   **Webpack Bundle Analyzer:** Tool for analyzing the size of the Webpack bundle.\n\n### Build Configuration\n\n*   **Use environment variables:** Store configuration values in environment variables.\n*   **Use a build script:** Use a build script to automate the build process.\n*   **Optimize build settings:** Optimize build settings for production (e.g., enable minification, tree shaking).\n\n### Linting and Formatting\n\n*   **Use ESLint with recommended rules:** Configure ESLint with a set of recommended rules for JavaScript and React.\n*   **Use Prettier for automatic formatting:** Configure Prettier to automatically format code on save.\n*   **Integrate linting and formatting into the build process:** Integrate linting and formatting into the build process to ensure that code is always consistent.\n*   **Use a shared configuration:** Ensure that all developers are using the same linting and formatting configuration.\n\n### Deployment\n\n*   **Use Vercel for easy deployment:** Vercel is the recommended platform for deploying Next.js applications.\n*   **Use a CDN for static assets:** Use a CDN to serve static assets from a location that is geographically close to the user.\n*   **Configure caching:** Configure caching to improve performance and reduce server load.\n*   **Monitor application health:** Monitor application health to detect and resolve issues quickly.\n\n### CI/CD Integration\n\n*   **Use a CI/CD pipeline:** Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Run tests in the CI/CD pipeline:** Run tests in the CI/CD pipeline to ensure that code is working correctly before it is deployed.\n*   **Automate deployments:** Automate deployments to reduce the risk of human error.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "next-js.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "next",
      "js",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "development",
      "covering",
      "code",
      "organization",
      "next-js",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "next-js",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-nginx",
    "description": "This rule provides a comprehensive guide to nginx configuration best practices, covering code organization, common patterns, performance, security, testing, pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "nginx",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/nginx.mdc",
    "content": "# nginx Configuration Best Practices\n\nThis document outlines best practices for configuring nginx as a web server, reverse proxy, and load balancer. Adhering to these guidelines promotes maintainability, security, and performance.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nMaintain a well-organized directory structure to manage configuration files efficiently.\n\n\n/etc/nginx/\n├── nginx.conf        # Main nginx configuration file\n├── conf.d/           # Site-specific configurations (symlinks preferred)\n│   ├── default.conf    # Default configuration\n│   ├── example.com.conf# Site-specific configuration\n│   └── ...\n├── snippets/         # Reusable configuration snippets\n│   ├── ssl-params.conf # SSL parameters\n│   ├── proxy-params.conf # Reverse proxy parameters\n│   └── ...\n└── modules-enabled/  # Enabled modules (usually managed by package manager)\n\n\n**Explanation:**\n\n*   `/etc/nginx/nginx.conf`:  The main configuration file that includes other configurations.\n*   `/etc/nginx/conf.d/`: Contains site-specific configurations.  Symlinking from `/etc/nginx/sites-available/` to `/etc/nginx/sites-enabled/` is a common, more manageable pattern.\n*   `/etc/nginx/snippets/`: Stores reusable configuration snippets, promoting modularity and reducing duplication.\n\n### 1.2 File Naming Conventions\n\nAdopt consistent file naming conventions for clarity.\n\n*   Site-specific configurations: `domain.com.conf` or `application-name.conf`.\n*   Snippets: `description.conf` (e.g., `ssl-params.conf`, `proxy-params.conf`).\n\n### 1.3 Modular Configuration\n\nBreak down complex configurations into smaller, reusable modules (snippets).\n\n**Example: `snippets/ssl-params.conf`**\n\nnginx\nssl_protocols TLSv1.2 TLSv1.3;\nssl_prefer_server_ciphers on;\nssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384;\nssl_ecdh_curve prime256v1;\nssl_session_timeout  10m;\nssl_session_cache shared:SSL:10m;\nssl_session_tickets off;\n\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\nadd_header X-Frame-Options SAMEORIGIN;\nadd_header X-Content-Type-Options nosniff;\nadd_header X-XSS-Protection \"1; mode=block\";\n\nssl_stapling on;\nssl_stapling_verify on;\nresolver 8.8.8.8 8.8.4.4 valid=300s;\nresolver_timeout 5s;\n\n\n**Usage in site configuration:**\n\nnginx\nserver \n    listen 443 ssl;\n    server_name example.com;\n\n    include snippets/ssl-params.conf;\n\n    ssl_certificate /etc/nginx/ssl/example.com.crt;\n    ssl_certificate_key /etc/nginx/ssl/example.com.key;\n\n    location / {\n        # ...\n    \n}\n\n\n### 1.4 Component Architecture\n\nDesign your nginx configurations with a clear separation of concerns:\n\n*   **Global Settings**: Core directives in `nginx.conf` affecting all virtual hosts.\n*   **Virtual Host Configuration**:  Separate files for each site/application in `conf.d/`.\n*   **Reusable Blocks**: Snippets for common settings like SSL, reverse proxy configurations, or access control.\n\n### 1.5 Code Splitting\n\nFor large and complex configurations, split files by functionality (e.g., routing rules, security policies, caching configurations).  Use `include` directives to assemble the complete configuration.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Reverse Proxy**:  Forward requests to backend servers. Useful for load balancing, caching, and security.\n*   **Load Balancer**: Distribute traffic across multiple backend servers for high availability and scalability. Use `upstream` blocks.\n*   **Static Content Server**:  Efficiently serve static files like images, CSS, and JavaScript.\n*   **Cache**: Reduce latency and server load by caching frequently accessed content.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Serving Static Content:**\n\n    nginx\n    location /static/ {\n        alias /var/www/example.com/static/;\n        expires 30d;\n        access_log off;\n    }\n    \n\n*   **Reverse Proxy to a Backend Server:**\n\n    nginx\n    location / {\n        proxy_pass http://backend_server;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    upstream backend_server {\n        server backend1.example.com;\n        server backend2.example.com;\n    }\n    \n\n*   **Implementing Basic Authentication:**\n\n    nginx\n    location /protected/ {\n        auth_basic \"Restricted Area\";\n        auth_basic_user_file /etc/nginx/.htpasswd;\n    }\n    \n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Large, Monolithic Configuration Files**: Difficult to manage and debug. Break them into smaller, modular files using `include`.\n*   **Duplicated Configuration Blocks**:  Create snippets to reuse common configurations.\n*   **Using `if` Statements Excessively**: `if` statements can have performance implications.  Prefer using `try_files` or other more efficient directives.\n*   **Insecure Configuration**: Exposing sensitive information, using weak ciphers, or not implementing proper access controls.\n*   **Ignoring Error Logs**: Neglecting to monitor and analyze error logs can lead to undetected issues.\n\n### 2.4 State Management\n\nNginx itself is generally stateless. State management is typically handled by backend applications.  However, Nginx Plus offers features like session persistence (sticky sessions) for load balancing.\n\n*   **Session Persistence (Nginx Plus):**\n\n    nginx\n    upstream backend {\n        server backend1.example.com;\n        server backend2.example.com;\n        sticky cookie srv_id expires=1h;\n    }\n    \n\n### 2.5 Error Handling\n\n*   **Custom Error Pages**: Configure custom error pages for a better user experience.\n\n    nginx\n    error_page 404 /404.html;\n    location = /404.html {\n        root /var/www/example.com/html;\n        internal;\n    }\n    \n\n*   **Logging**:  Use comprehensive logging to capture errors and warnings for troubleshooting.\n*   **Retry Logic**: Implement retry logic in your application or use Nginx's `proxy_next_upstream` directive to retry failed requests on different backend servers.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Enable Gzip Compression**: Compress text-based responses to reduce bandwidth usage.\n\n    nginx\ngzip on;\ngzip_disable \"msie6\";\ngzip_vary on;\ngzip_proxied any;\ngzip_comp_level 6;\ngzip_buffers 16 8k;\ngzip_http_version 1.1;\ngzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n    \n\n*   **Enable Caching**: Cache static content and dynamic responses to reduce server load and improve response times. Use `proxy_cache_path` and `proxy_cache` directives.\n\n    nginx\nproxy_cache_path /tmp/nginx_cache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;\n\nserver {\n    location / {\n        proxy_pass http://backend_server;\n        proxy_cache my_cache;\n        proxy_cache_valid 200 302 1h;\n        proxy_cache_valid 404 10m;\n        proxy_cache_use_stale error timeout updating invalid_header http_500 http_502 http_503 http_504;\n        add_header X-Cache-Status $upstream_cache_status;\n    }\n}\n    \n\n*   **Tune Worker Processes and Connections**: Adjust `worker_processes` and `worker_connections` based on your server's resources.\n\n    nginx\nworker_processes auto;\nevents {\n    worker_connections 1024;\n}\n    \n\n*   **HTTP/2 or HTTP/3**: Enable HTTP/2 or HTTP/3 for improved performance.\n*   **Keep-Alive Connections**: Enable keep-alive connections to reduce latency by reusing existing connections.\n\n    nginx\nkeepalive_timeout 65;\n    \n\n### 3.2 Memory Management\n\n*   **Optimize Buffer Sizes**: Tune buffer sizes (e.g., `proxy_buffer_size`, `proxy_buffers`) to match your application's needs and avoid memory fragmentation.\n*   **Monitor Memory Usage**: Use tools like `top` or `htop` to monitor nginx's memory usage and identify potential memory leaks.\n\n### 3.3 Rendering Optimization (If applicable)\n\nNginx primarily serves content; rendering optimization is typically handled by the backend application.\n\n*   **Content Delivery Network (CDN)**: Offload static content delivery to a CDN.\n\n### 3.4 Bundle Size Optimization (If applicable)\n\nThis primarily applies to serving static assets.\n\n*   **Minify and Compress**: Minify and compress CSS and JavaScript files before serving them.\n*   **Use Brotli**: Consider using Brotli compression, which offers better compression ratios than Gzip.\n\n### 3.5 Lazy Loading (If applicable)\n\nThis is typically implemented at the application level.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **SQL Injection**: Prevent SQL injection by validating and sanitizing user inputs at the application level.\n*   **Cross-Site Scripting (XSS)**: Implement proper output encoding and use HTTP headers like `X-XSS-Protection` and `Content-Security-Policy`.\n\n    nginx\nadd_header X-XSS-Protection \"1; mode=block\";\nadd_header Content-Security-Policy \"default-src 'self'\";\n    \n\n*   **Clickjacking**: Prevent clickjacking by setting the `X-Frame-Options` header.\n\n    nginx\nadd_header X-Frame-Options \"SAMEORIGIN\";\n    \n\n*   **Buffer Overflow**: Keep Nginx up to date to patch vulnerabilities related to buffer overflows.\n*   **Denial of Service (DoS)**: Implement rate limiting to prevent DoS attacks.\n\n    nginx\nlimit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;\n\nlocation / {\n    limit_req zone=mylimit burst=5 nodelay;\n    # ...\n}\n    \n\n### 4.2 Input Validation\n\n*   **Validate User Inputs**: Validate all user inputs at the application level to prevent malicious data from reaching backend servers.\n*   **Limit Request Size**: Limit the size of incoming requests to prevent buffer overflows and DoS attacks.\n\n    nginx\nclient_max_body_size 2m;\n    \n\n### 4.3 Authentication and Authorization\n\n*   **Basic Authentication**: Use basic authentication for simple access control. However, it's not secure over HTTP; always use HTTPS.\n*   **JWT (JSON Web Tokens)**: Implement JWT-based authentication for APIs.\n*   **OAuth 2.0**: Use OAuth 2.0 for delegated authorization.\n*   **Access Control Lists (ACLs)**: Use ACLs to control access to specific resources based on IP addresses or other criteria.\n\n    nginx\nallow 192.168.1.0/24;\ndeny all;\n    \n\n### 4.4 Data Protection\n\n*   **HTTPS**: Use HTTPS to encrypt all traffic between clients and the server. Obtain and configure SSL/TLS certificates.\n*   **Secure Storage**: Store sensitive data (e.g., passwords, API keys) securely using encryption and access controls.\n\n### 4.5 Secure API Communication\n\n*   **API Keys**: Require API keys for all API requests.\n*   **Rate Limiting**: Implement rate limiting to prevent abuse and DoS attacks.\n*   **Input Validation**: Validate all API request parameters.\n*   **Output Encoding**: Encode API responses to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\nNginx configuration files are difficult to unit test directly.  Unit testing is more relevant for custom Nginx modules written in C.\n\n### 5.2 Integration Testing\n\n*   **Test Configuration Syntax**: Use `nginx -t` to test the syntax of your configuration files.\n*   **Test with Docker**: Use Docker containers to create isolated test environments.\n*   **Test with Real Traffic**: Use tools like `ab` (Apache Bench) or `wrk` to simulate real traffic and measure performance.\n\n### 5.3 End-to-End Testing\n\nUse tools like Selenium or Cypress to automate end-to-end tests of your application.\n\n### 5.4 Test Organization\n\n*   **Separate Test Environment**: Create a separate test environment that mirrors your production environment.\n*   **Automated Testing**: Automate your testing process using CI/CD pipelines.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock Backend Services**: Mock backend services to isolate your Nginx configuration and test different scenarios.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect Syntax**: Nginx configuration syntax can be tricky. Always test your configuration files using `nginx -t`.\n*   **Missing Semicolons**: Forgetting semicolons at the end of directives.\n*   **Incorrect File Permissions**: Ensure that Nginx has the necessary permissions to read configuration files and access static content.\n*   **Not Reloading Configuration**: Forgetting to reload Nginx after making changes to the configuration files (e.g., `nginx -s reload`).\n*   **Using `if` Statements Inappropriately**: Overusing `if` can lead to unexpected behavior and performance issues.  Prefer `try_files` or other alternatives.\n\n### 6.2 Edge Cases\n\n*   **Handling Large Files**: Tune buffer sizes and timeouts when handling large file uploads or downloads.\n*   **WebSockets**: Configure Nginx to properly proxy WebSocket connections.\n*   **Long URIs**: Configure `client_header_buffer_size` and `large_client_header_buffers` to handle long URIs.\n\n### 6.3 Version-Specific Issues\n\n*   **Check Release Notes**: Review the release notes for each Nginx version to identify any breaking changes or known issues.\n*   **Test Upgrades**: Test Nginx upgrades in a staging environment before deploying to production.\n\n### 6.4 Compatibility Concerns\n\n*   **Backend Application Compatibility**: Ensure that your Nginx configuration is compatible with the backend applications you are using.\n*   **TLS Versions and Ciphers**: Choose TLS versions and ciphers that are compatible with your clients and backend servers.\n\n### 6.5 Debugging Strategies\n\n*   **Error Logs**: Check Nginx error logs (`/var/log/nginx/error.log`) for errors and warnings.\n*   **Access Logs**: Analyze Nginx access logs (`/var/log/nginx/access.log`) to understand traffic patterns and identify potential issues.\n*   **`nginx -t`**: Use `nginx -t` to test the syntax of your configuration files.\n*   **Verbose Logging**: Enable verbose logging to capture more detailed information about requests and responses.\n*   **tcpdump/Wireshark**: Use `tcpdump` or Wireshark to capture and analyze network traffic.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Text Editor**: Use a text editor with syntax highlighting and autocompletion for Nginx configuration files (e.g., VS Code with Nginx configuration extension).\n*   **Command-Line Tools**: Use command-line tools like `nginx`, `curl`, `ab`, and `tcpdump` for testing and debugging.\n*   **Docker**: Use Docker for creating isolated test environments.\n\n### 7.2 Build Configuration\n\n*   **Version Control**: Store your Nginx configuration files in a version control system (e.g., Git).\n*   **Configuration Management**: Use configuration management tools like Ansible or Chef to automate the deployment and management of your Nginx configuration.\n\n### 7.3 Linting and Formatting\n\n*   **Nginx Linter**: Use an Nginx linter to check your configuration files for syntax errors and best practices violations (e.g., `nginx -t`).\n*   **Code Formatting**: Use a code formatter to ensure consistent formatting of your configuration files.\n\n### 7.4 Deployment Best Practices\n\n*   **Blue-Green Deployment**: Use blue-green deployment to minimize downtime during deployments.\n*   **Canary Deployment**: Use canary deployment to test new Nginx configurations with a small subset of users before rolling them out to the entire user base.\n*   **Rollback Strategy**: Have a rollback strategy in place in case of deployment failures.\n\n### 7.5 CI/CD Integration\n\n*   **Automated Testing**: Integrate automated testing into your CI/CD pipeline.\n*   **Configuration Validation**: Validate Nginx configuration files as part of your CI/CD pipeline.\n*   **Automated Deployment**: Automate the deployment of Nginx configuration files using CI/CD tools like Jenkins, GitLab CI, or CircleCI.\n\nBy following these best practices, you can create a robust, secure, and performant Nginx configuration that meets the needs of your web applications.",
    "metadata": {
      "globs": "nginx.conf",
      "format": "mdc",
      "originalFile": "nginx.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "nginx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guide",
      "configuration",
      "best",
      "practices",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "nginx",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-nltk",
    "description": "Provides comprehensive guidance on best practices for coding standards, performance, security, and testing in NLTK projects. This rule helps developers write clean, maintainable, and efficient NLP code using NLTK.",
    "author": "sanjeed5",
    "tags": [
      "nltk",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/nltk.mdc",
    "content": "- Follow these guidelines for consistency and maintainability of your code.\n\n# NLTK Coding Standards and Best Practices\n\nThis document outlines coding standards and best practices for developing applications using the Natural Language Toolkit (NLTK) in Python.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a clear and logical directory structure to organize your NLTK project. A typical structure might look like this:\n\n\nmy_nltk_project/\n├── data/              # Raw data files\n├── processed_data/    # Processed data files (e.g., tokenized, stemmed)\n├── models/            # Trained models (e.g., sentiment analysis models)\n├── scripts/           # Python scripts for data processing, training, etc.\n│   ├── __init__.py  # Make the scripts directory a Python package\n│   ├── data_processing.py\n│   ├── model_training.py\n│   └── utils.py\n├── tests/             # Unit and integration tests\n│   ├── __init__.py\n│   ├── test_data_processing.py\n│   └── test_model_training.py\n├── notebooks/         # Jupyter notebooks for experimentation\n├── requirements.txt  # Project dependencies\n├── README.md\n└── .gitignore\n\n\n*   `data/`: Stores raw data used for training and analysis.  Keep this separate and under version control if the dataset is small.  For larger datasets, use DVC (Data Version Control) or similar.\n*   `processed_data/`: Save intermediate and final processed data here.  This avoids recomputing the same steps repeatedly.  Consider using Parquet or Feather format for efficient storage and retrieval of processed dataframes.\n*   `models/`: Stores trained NLTK models.  Use a consistent naming convention (e.g., `sentiment_model_v1.pkl`) and consider using a model registry (e.g., MLflow, Weights & Biases) for managing model versions and metadata.\n*   `scripts/`: Contains reusable Python modules for data processing, model training, and utility functions.  Structure this directory into submodules if the project becomes complex.\n*   `tests/`: Holds unit tests and integration tests to ensure code correctness.  Aim for high test coverage.\n*   `notebooks/`: Jupyter notebooks are useful for exploring data and prototyping code.  Keep notebooks clean and well-documented, and consider refactoring useful code into the `scripts/` directory.\n*   `requirements.txt`: Lists all project dependencies, allowing for easy installation via `pip install -r requirements.txt`.  Use `pip freeze > requirements.txt` to generate this file.\n\n### 1.2 File Naming Conventions\n\nFollow consistent file naming conventions to improve readability and maintainability:\n\n*   Python scripts: Use snake_case (e.g., `data_processing.py`).\n*   Data files: Use descriptive names that indicate the contents (e.g., `raw_text_data.csv`, `processed_data.parquet`).\n*   Model files: Include versioning and relevant information in the name (e.g., `sentiment_model_v1.pkl`).\n*   Test files: Prefix with `test_` and mirror the naming of the modules they test (e.g., `test_data_processing.py`).\n\n### 1.3 Module Organization Best Practices\n\nOrganize your code into logical modules within the `scripts/` directory.  Each module should focus on a specific task or set of related functionalities.  Here's an example:\n\npython\n# scripts/data_processing.py\n\nimport nltk\n\ndef tokenize_text(text):\n    # Tokenize text using NLTK\n    tokens = nltk.word_tokenize(text)\n    return tokens\n\ndef remove_stopwords(tokens):\n    # Remove stopwords using NLTK\n    stopwords = nltk.corpus.stopwords.words('english')\n    filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n    return filtered_tokens\n\n# scripts/model_training.py\n\nimport nltk\nimport pickle\n\ndef train_sentiment_model(data):\n    # Train a sentiment analysis model using NLTK\n    # ...\n    model = ...\n    return model\n\ndef save_model(model, filepath):\n    # Save the trained model to a file\n    with open(filepath, 'wb') as f:\n        pickle.dump(model, f)\n\n\n### 1.4 Component Architecture Recommendations\n\nDesign your application with a clear component architecture.  Consider using a layered architecture:\n\n*   **Data Layer:** Handles data loading, cleaning, and preprocessing.  Responsible for interacting with data sources (e.g., files, databases, APIs).\n*   **Processing Layer:** Implements NLP tasks such as tokenization, stemming, lemmatization, POS tagging, and parsing.  This layer relies heavily on NLTK functionalities.\n*   **Model Layer:** Trains and evaluates NLP models.  Includes code for feature extraction, model selection, and hyperparameter tuning.\n*   **Application Layer:** Provides the user interface or API for interacting with the NLP application.  Handles user input and presents results.\n\n### 1.5 Code Splitting Strategies\n\nBreak down large code files into smaller, more manageable chunks.  Use functions, classes, and modules to improve code organization and reusability.\n\n*   **Functions:**  Encapsulate specific tasks into well-defined functions with clear inputs and outputs.  Use docstrings to document function purpose, arguments, and return values.\n*   **Classes:**  Group related data and functions into classes.  Use inheritance and polymorphism to create reusable and extensible code.  For example, you could create a base `TextProcessor` class and subclasses for different text processing tasks (e.g., `SentimentAnalyzer`, `TopicModeler`).\n*   **Modules:**  Organize code into modules based on functionality.  Use relative imports to access modules within the same package.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Strategy Pattern:** Use this pattern to implement different text processing algorithms (e.g., stemming algorithms).  Define a common interface for all algorithms and allow the client to choose the desired algorithm at runtime.\n*   **Factory Pattern:** Use this pattern to create different types of NLTK objects (e.g., different types of tokenizers or stemmers).  This promotes loose coupling and makes it easier to switch between different implementations.\n*   **Observer Pattern:** Use this pattern to notify interested components when data changes (e.g., when a new document is added to a corpus).  This can be useful for real-time NLP applications.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Text Preprocessing:** Create a reusable pipeline for text preprocessing.  This pipeline should include tokenization, lowercasing, punctuation removal, stopword removal, stemming/lemmatization, and any other necessary steps.\n*   **Feature Extraction:** Use NLTK's feature extraction capabilities (e.g., bag-of-words, TF-IDF) to convert text data into numerical features suitable for machine learning models.\n*   **Model Training:** Use scikit-learn or other machine learning libraries in conjunction with NLTK to train and evaluate NLP models.  Use cross-validation to estimate model performance and hyperparameter tuning to optimize model parameters.\n*   **Sentiment Analysis:**  Use pre-trained sentiment analysis models (e.g., VADER) or train your own model using NLTK and scikit-learn.\n*   **Topic Modeling:** Use NLTK and Gensim to perform topic modeling on text data.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Global Variables:** Avoid using global variables, as they can lead to unexpected side effects and make code difficult to debug.  Use dependency injection or other techniques to pass data between components.\n*   **Hardcoded Values:** Avoid hardcoding values in your code.  Use configuration files or environment variables to store configurable parameters.\n*   **Long Functions:**  Avoid writing long, complex functions.  Break down large functions into smaller, more manageable chunks.\n*   **Code Duplication:**  Avoid duplicating code.  Create reusable functions or classes to encapsulate common functionality.\n*   **Ignoring Errors:**  Don't ignore errors.  Implement proper error handling to prevent unexpected crashes and provide informative error messages.\n*   **Over-commenting/Under-commenting:** Strike a balance. Comments should explain *why* you're doing something, not *what* the code is already clearly showing. Conversely, don't under-comment complex logic.\n\n### 2.4 State Management Best Practices\n\n*   **Stateless Functions:**  Prefer stateless functions whenever possible.  Stateless functions are easier to test and reason about.\n*   **Immutable Data Structures:**  Use immutable data structures whenever possible.  Immutable data structures prevent accidental modification of data and make code more robust.\n*   **Configuration Management:**  Use a configuration management library (e.g., `configparser`) to store application settings and parameters.  This makes it easier to change settings without modifying code.\n\n### 2.5 Error Handling Patterns\n\n*   **Try-Except Blocks:** Use `try-except` blocks to handle potential exceptions.  Catch specific exceptions rather than using a generic `except` block. Log exceptions for debugging purposes.\n*   **Logging:** Use the `logging` module to log events, errors, and warnings.  Configure logging levels to control the amount of information that is logged.  Use a consistent logging format.\n*   **Custom Exceptions:** Define custom exceptions for specific error conditions in your application.  This makes it easier to handle errors in a consistent and informative way.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Profiling:** Use profiling tools (e.g., `cProfile`) to identify performance bottlenecks in your code.\n*   **Vectorization:** Use NumPy's vectorized operations to perform calculations on arrays of data. Vectorization is significantly faster than looping over individual elements.\n*   **Caching:** Use caching to store frequently accessed data and avoid redundant calculations.  Use the `functools.lru_cache` decorator for simple caching.\n*   **Parallelization:** Use multiprocessing or threading to parallelize computationally intensive tasks.\n*   **Efficient Data Structures:** Choose appropriate data structures for your needs.  Use sets for fast membership testing and dictionaries for fast key-value lookups.\n*   **Lazy Loading:** Defer the loading of large datasets or models until they are actually needed. This can significantly reduce startup time.\n\n### 3.2 Memory Management\n\n*   **Generators:** Use generators to process large datasets in chunks.  Generators produce data on demand, which reduces memory consumption.\n*   **Data Type Optimization:** Use the most appropriate data types for your data.  For example, use `int8` instead of `int64` if your integers are within the range of `int8`.\n*   **Garbage Collection:** Be aware of Python's garbage collection mechanism.  Avoid creating circular references that can prevent objects from being garbage collected.\n*   **Del Statements:** Use `del` statements to explicitly release memory when objects are no longer needed.\n\n### 3.3 Rendering Optimization (If Applicable)\n\nNLTK itself doesn't typically involve direct rendering like a UI framework, but visualization of NLTK outputs (e.g., parse trees) might. In such cases, libraries like Matplotlib or Graphviz might be used. Follow their respective optimization guides.\n\n### 3.4 Bundle Size Optimization\n\nThis is more relevant for web applications using NLTK in the backend. For such cases:\n\n*   **Dependency Management:** Only include the NLTK modules that are actually needed by your application. Avoid importing entire modules if you only need a few functions.\n*   **Code Minification:** Minify your Python code to reduce its size. This can be done using tools like `pyminify`.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Delayed Imports:** Import NLTK modules only when they are needed. This can reduce startup time if your application doesn't use all of NLTK's functionalities.\n*   **Conditional Loading:** Load different NLTK modules based on the application's configuration. This allows you to only load the modules that are relevant to the current task.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **Arbitrary Code Execution:** Be careful when loading data from untrusted sources. Avoid using `eval()` or `pickle.load()` on untrusted data, as these can be exploited to execute arbitrary code. Use safer alternatives such as JSON or CSV.\n*   **Denial of Service (DoS):** Protect your application from DoS attacks by limiting the size of input data and using appropriate timeouts. Avoid unbounded loops or recursive functions that can consume excessive resources.\n*   **Regular Expression Denial of Service (ReDoS):** Be careful when using regular expressions, as complex regular expressions can be exploited to cause ReDoS attacks. Use simple and efficient regular expressions, and limit the backtracking depth.\n\n### 4.2 Input Validation\n\n*   **Data Type Validation:** Validate the data type of input values to prevent type errors and unexpected behavior.\n*   **Range Validation:** Validate that input values are within acceptable ranges.\n*   **Format Validation:** Validate that input data is in the expected format (e.g., using regular expressions).\n*   **Sanitization:** Sanitize input data to remove potentially harmful characters or code.  Use appropriate escaping techniques to prevent injection attacks.\n\n### 4.3 Authentication and Authorization\n\n*   **Authentication:** Implement authentication to verify the identity of users. Use strong passwords and multi-factor authentication.\n*   **Authorization:** Implement authorization to control access to resources. Use role-based access control (RBAC) to assign permissions to users based on their roles.\n\n### 4.4 Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit. Use strong encryption algorithms and manage keys securely.\n*   **Data Masking:** Mask sensitive data when displaying it to users. This can prevent unauthorized access to sensitive information.\n*   **Access Control:** Implement strict access control policies to limit access to sensitive data. Only grant access to users who need it.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS to encrypt communication between your application and the API. This prevents eavesdropping and man-in-the-middle attacks.\n*   **API Keys:** Use API keys to authenticate your application with the API. Protect your API keys and do not embed them in your code.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your API. This can protect your API from DoS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test-Driven Development (TDD):** Write unit tests before writing code. This helps you to design your code in a testable way and ensures that your code meets the requirements.\n*   **Test Coverage:** Aim for high test coverage. Use a test coverage tool to measure the percentage of code that is covered by tests.\n*   **Assertions:** Use assertions to verify that your code is behaving as expected. Use informative error messages to help you debug your code.\n\n### 5.2 Integration Testing\n\n*   **Test Dependencies:** Test the integration of your code with external dependencies (e.g., databases, APIs). Use mock objects or test doubles to isolate your code from external dependencies during unit testing.\n*   **Test Scenarios:** Test different scenarios to ensure that your code handles different inputs and edge cases correctly.\n\n### 5.3 End-to-End Testing\n\n*   **User Interface Testing:** Test the user interface of your application to ensure that it is working as expected. Use automated testing tools to automate UI testing.\n*   **System Testing:** Test the entire system to ensure that all components are working together correctly.\n\n### 5.4 Test Organization\n\n*   **Test Directory:** Create a separate `tests/` directory to store your tests.\n*   **Test Modules:** Create separate test modules for each module in your application. Use the same naming conventions as your application modules.\n*   **Test Classes:** Group related tests into test classes. Use descriptive names for your test classes.\n*   **Test Functions:** Create separate test functions for each test case. Use descriptive names for your test functions.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock Objects:** Use mock objects to replace external dependencies during unit testing. This allows you to isolate your code from external dependencies and test it in a controlled environment.\n*   **Stubbing:** Use stubbing to replace complex or time-consuming operations with simple or fast operations during testing. This can improve the speed and reliability of your tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect Data Preparation:** Failing to properly clean and prepare data can lead to inaccurate results.\n*   **Overfitting:** Training a model that is too complex for the data can lead to overfitting. Use regularization techniques and cross-validation to prevent overfitting.\n*   **Ignoring Rare Words:** Ignoring rare words can lead to a loss of information. Use techniques such as stemming or lemmatization to group related words together.\n*   **Using Default Parameters:** Relying on default parameters without understanding their implications can lead to unexpected behavior.\n*   **Not Documenting Code:** Failing to document code makes it difficult to understand and maintain.\n\n### 6.2 Edge Cases\n\n*   **Empty Strings:** Handle empty strings gracefully.\n*   **Special Characters:** Handle special characters correctly.\n*   **Unicode:** Handle Unicode characters correctly.  Use UTF-8 encoding for all text files.\n*   **Missing Data:** Handle missing data appropriately.\n\n### 6.3 Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of NLTK.  Check the NLTK documentation for migration guides.\n*   **Dependency Conflicts:** Be aware of potential dependency conflicts between NLTK and other libraries.  Use a virtual environment to isolate your project's dependencies.\n\n### 6.4 Compatibility Concerns\n\n*   **Python Version:** Ensure that your code is compatible with the desired version of Python.\n*   **Operating System:** Be aware of potential compatibility issues between different operating systems.\n\n### 6.5 Debugging Strategies\n\n*   **Print Statements:** Use `print` statements to debug your code. Print the values of variables and the results of calculations.\n*   **Debuggers:** Use a debugger to step through your code and inspect the values of variables.\n*   **Logging:** Use the `logging` module to log events, errors, and warnings. Review the logs to identify the cause of problems.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Use an IDE such as Visual Studio Code, PyCharm, or Spyder. These IDEs provide features such as code completion, debugging, and refactoring.\n*   **Virtual Environment Manager:** Use a virtual environment manager such as `venv` or `conda` to isolate your project's dependencies.\n*   **Package Manager:** Use a package manager such as `pip` or `conda` to install and manage your project's dependencies.\n*   **Version Control System:** Use a version control system such as Git to track changes to your code.\n*   **Data Version Control (DVC):** For larger datasets that are under version control use DVC.\n\n### 7.2 Build Configuration\n\n*   **Makefile:** Use a `Makefile` to automate common tasks such as building, testing, and deploying your application.\n*   **Setup Script:** Use a `setup.py` script to package your application for distribution.\n\n### 7.3 Linting and Formatting\n\n*   **Linting:** Use a linter such as `pylint` or `flake8` to check your code for style errors and potential problems.\n*   **Formatting:** Use a code formatter such as `black` or `autopep8` to automatically format your code according to a consistent style guide.\n\n### 7.4 Deployment\n\n*   **Containerization:** Use containerization technologies such as Docker to package your application and its dependencies into a self-contained unit. This makes it easier to deploy your application to different environments.\n*   **Cloud Platform:** Deploy your application to a cloud platform such as AWS, Google Cloud, or Azure.\n\n### 7.5 CI/CD Integration\n\n*   **Continuous Integration:** Use a continuous integration (CI) system such as Jenkins, Travis CI, or CircleCI to automatically build and test your code whenever changes are pushed to your version control system.\n*   **Continuous Deployment:** Use a continuous deployment (CD) system to automatically deploy your application to production after it has passed all tests.\n\nBy adhering to these coding standards and best practices, you can develop NLTK applications that are clean, maintainable, efficient, and secure.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "nltk.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "nltk",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "coding",
      "standards",
      "performance",
      "security",
      "testing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "nltk",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-nose2",
    "description": "Comprehensive best practices and coding standards for Python projects using the nose2 testing framework. Covers code organization, common patterns, performance, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "nose2",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/nose2.mdc",
    "content": "# nose2 Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to best practices and coding standards for Python projects using the nose2 testing framework. Following these guidelines will help you write clean, maintainable, and efficient testing code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n-   **Dedicated Test Directory:** Maintain a dedicated directory (e.g., `tests/`) at the project root to house all test files. This keeps test code separate from the application code.\n-   **Mirror Application Structure:**  Mirror the structure of your application code within the test directory. For example, if your application has modules in `myapp/module1/` and `myapp/module2/`, create corresponding directories `tests/module1/` and `tests/module2/`.\n-   **Test Modules:** Each application module should have a corresponding test module.  For `myapp/module.py`, the test module should be named `tests/test_module.py` or `tests/module_test.py`\n\nExample:\n\n\nmyproject/\n├── myapp/\n│   ├── __init__.py\n│   ├── module1.py\n│   ├── module2.py\n│   └── ...\n├── tests/\n│   ├── __init__.py\n│   ├── test_module1.py\n│   ├── test_module2.py\n│   └── ...\n├── ...\n\n\n### 1.2. File Naming Conventions\n\n-   **Test File Prefix:**  Name test files with a prefix like `test_` or a suffix `_test` (e.g., `test_module.py` or `module_test.py`).  nose2 automatically discovers files that follow this convention.\n-   **Descriptive Names:** Use descriptive file names that clearly indicate the module or component being tested.  For example, `test_user_authentication.py` for tests related to user authentication.\n\n### 1.3. Module Organization\n\n-   **Single Responsibility:** Each test module should focus on testing a single application module or a closely related set of functionalities.\n-   **Test Classes:** Organize tests within a module into test classes. Each class should test a specific aspect or component of the module. Inherit from `unittest.TestCase`.\n-   **Test Functions/Methods:** Each test case should be a separate function (starting with `test_`) within a test class.  These methods should be small, focused, and test a single condition or scenario.\n\nExample:\n\npython\n# tests/test_user.py\nimport unittest\nfrom myapp import user\n\nclass TestUser(unittest.TestCase):\n\n    def setUp(self):\n        # Setup code to run before each test\n        self.user = user.User(\"testuser\", \"password\")\n\n    def tearDown(self):\n        # Teardown code to run after each test\n        pass\n\n    def test_user_creation(self):\n        self.assertEqual(self.user.username, \"testuser\")\n        self.assertTrue(self.user.check_password(\"password\"))\n\n    def test_invalid_password(self):\n        self.assertFalse(self.user.check_password(\"wrong_password\"))\n\n\n\n### 1.4. Component Architecture\n\n-   **Isolate Components:** Design your application to isolate components, making them easier to test independently. Use dependency injection or other techniques to decouple modules.\n-   **Testable Interfaces:** Define clear and testable interfaces between components. This allows you to mock or stub dependencies during testing.\n\n### 1.5. Code Splitting Strategies\n\n-   **Functional Decomposition:** Split large test functions into smaller, more manageable functions that focus on specific aspects of the test.\n-   **Parameterization:** Use parameterized tests (e.g., with `nose2.tools.params`) to test the same code with different inputs and expected outputs. This avoids code duplication and improves test coverage.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Arrange-Act-Assert (AAA):** Follow the AAA pattern in each test: _Arrange_ the test environment (set up data, mock dependencies), _Act_ (execute the code under test), and _Assert_ (verify the expected outcome).\n-   **Test Fixtures:** Use `setUp` and `tearDown` methods in `unittest.TestCase` to create and clean up test fixtures (e.g., database connections, temporary files) before and after each test.\n-   **Mocking:** Use mocking libraries like `unittest.mock` or `mock` to replace real dependencies with controlled substitutes during testing. This allows you to isolate the code under test and simulate various scenarios.\n\n### 2.2. Recommended Approaches\n\n-   **Test-Driven Development (TDD):** Write tests before writing the application code. This helps you define clear requirements and ensure that the code is testable.\n-   **Behavior-Driven Development (BDD):** Use BDD frameworks like `behave` to write tests in a human-readable format that describes the expected behavior of the system.\n-   **Focus on Edge Cases:**  Don't only test the happy path. Dedicate tests to verify edge cases, boundary conditions, and error handling.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Over-testing:** Avoid testing implementation details that are likely to change. Focus on testing the behavior and expected outputs of the code.\n-   **Fragile Tests:** Tests that break frequently due to minor code changes are fragile.  Strive for tests that are resilient to refactoring and implementation changes.\n-   **Slow Tests:**  Slow tests can significantly slow down the development process. Optimize your tests to run quickly.  Use techniques like mocking and in-memory databases to speed up testing.\n-   **Ignoring Test Failures:** Always investigate and fix failing tests. Don't ignore them or disable them without a proper reason.\n-   **Redundant Assertions:** Avoid having more than one assertion per test case unless absolutely necessary.  Multiple assertions make it hard to pinpoint what failed.\n\n### 2.4. State Management\n\n-   **Isolate Test State:** Each test should be independent and not rely on the state left by previous tests. Use `setUp` and `tearDown` to ensure a clean state for each test.\n-   **Avoid Global State:** Minimize the use of global variables or shared state in your application, as they can make tests harder to write and maintain.\n\n### 2.5. Error Handling\n\n-   **Test Exception Handling:** Write tests to verify that your code raises the correct exceptions in error scenarios.\n-   **Use `assertRaises`:** Use `self.assertRaises(ExceptionType, callable, *args, **kwargs)` to assert that a specific exception is raised when calling a function or method.\n-   **Context Managers for Asserting Exceptions:** Use context managers when checking for exceptions in more complex scenarios.\n\nExample:\n\npython\nimport unittest\n\nclass MyClass:\n    def divide(self, a, b):\n        if b == 0:\n            raise ValueError(\"Cannot divide by zero\")\n        return a / b\n\nclass TestMyClass(unittest.TestCase):\n\n    def setUp(self):\n        self.my_class = MyClass()\n\n    def test_divide_valid(self):\n        self.assertEqual(self.my_class.divide(10, 2), 5)\n\n    def test_divide_by_zero(self):\n        with self.assertRaises(ValueError) as context:\n            self.my_class.divide(10, 0)\n        self.assertEqual(str(context.exception), \"Cannot divide by zero\")\n\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Profiling:** Use profiling tools to identify performance bottlenecks in your tests. Optimize the slowest tests first.\n-   **Mocking Expensive Operations:** Mock out slow operations (e.g., database queries, network requests) during testing to reduce test execution time.\n-   **Caching Test Data:** Cache frequently used test data to avoid redundant calculations or data retrieval.\n\n### 3.2. Memory Management\n\n-   **Clean Up Resources:**  Ensure that tests properly clean up any resources they allocate (e.g., files, database connections) to avoid memory leaks.\n-   **Limit Test Data Size:**  Use realistic but minimal test data to reduce memory consumption during testing.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n-   This is generally not applicable to `nose2` testing itself, but if testing code involves UI rendering, strategies like reducing render frequency and complexity should be considered.\n\n### 3.4. Bundle Size Optimization (If Applicable)\n\n- This is generally not applicable to `nose2` testing itself.\n\n### 3.5. Lazy Loading\n\n-   **Lazy Initialization of Test Data:**  Defer the initialization of test data until it is actually needed by a test case. This can reduce test setup time and memory consumption.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n-   **Insecure Dependencies:** Use dependency scanning tools to identify and address vulnerabilities in third-party libraries used by your application or tests.\n-   **Hardcoded Secrets:** Avoid hardcoding secrets (e.g., passwords, API keys) in your tests. Use environment variables or configuration files to store sensitive information.\n-   **Insufficient Input Validation:**  Test that your application properly validates user inputs to prevent injection attacks and other security vulnerabilities.\n\n### 4.2. Input Validation\n\n-   **Test Boundary Conditions:**  Test that your application handles invalid or unexpected inputs gracefully, including boundary conditions, edge cases, and malicious inputs.\n\n### 4.3. Authentication and Authorization\n\n-   **Test Authentication Flows:** Write tests to verify that your application correctly authenticates users and grants access to authorized resources.\n-   **Role-Based Access Control (RBAC):**  If your application uses RBAC, test that users with different roles have the appropriate permissions.\n\n### 4.4. Data Protection\n\n-   **Test Data Encryption:** If your application encrypts sensitive data, test that the encryption and decryption processes are working correctly.\n-   **Secure Storage:**  Test that sensitive data is stored securely (e.g., using hashed passwords, encrypted databases).\n\n### 4.5. Secure API Communication\n\n-   **Test HTTPS:** If your application communicates with external APIs, test that it uses HTTPS to encrypt the communication.\n-   **API Key Security:**  Protect API keys and other credentials used for API communication.  Don't store them directly in the code, and use appropriate access controls.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   **Focus on Individual Units:** Unit tests should focus on testing individual functions, methods, or classes in isolation.\n-   **Mock Dependencies:** Use mocking to isolate the unit under test from its dependencies.\n-   **Test All Code Paths:** Aim for high code coverage by testing all possible code paths and branches.\n\n### 5.2. Integration Testing\n\n-   **Test Interactions Between Components:** Integration tests verify that different components of the application work together correctly.\n-   **Use Real Dependencies (Where Possible):**  Unlike unit tests, integration tests should use real dependencies (e.g., databases, external APIs) where feasible, or integration-specific lightweight replacements.\n\n### 5.3. End-to-End (E2E) Testing\n\n-   **Test the Entire System:** E2E tests simulate real user scenarios and test the entire application from end to end.\n-   **Use Automated Testing Tools:** Use automated testing tools like Selenium or Cypress to automate E2E tests.\n\n### 5.4. Test Organization\n\n-   **Test Suites:**  Use test suites to group related tests together. This makes it easier to run specific sets of tests.\n-   **Test Runners:** Use test runners (e.g., `nose2`, `pytest`) to discover and execute tests automatically.\n\n### 5.5. Mocking and Stubbing\n\n-   **`unittest.mock`:** Use the `unittest.mock` library (or the older `mock` library for Python 2) to create mock objects and stub out dependencies.\n-   **`patch` Decorator:** Use the `patch` decorator to replace objects or attributes with mock objects during testing.\n-   **`side_effect`:**  Use the `side_effect` attribute of mock objects to simulate different behaviors or raise exceptions when the mock object is called.\n\nExample:\n\npython\nimport unittest\nfrom unittest.mock import patch\n\nclass MyClass:\n    def get_data(self):\n        # This method might make an external API call\n        return \"Real data\"\n\n    def process_data(self):\n        data = self.get_data()\n        return data.upper()\n\nclass TestMyClass(unittest.TestCase):\n\n    @patch('__main__.MyClass.get_data')  # Patch the get_data method\n    def test_process_data(self, mock_get_data):\n        # Configure the mock to return a specific value\n        mock_get_data.return_value = \"Mock data\"\n\n        my_class = MyClass()\n        result = my_class.process_data()\n\n        self.assertEqual(result, \"MOCK DATA\")\n        mock_get_data.assert_called_once() # Verify that the mock was called\n\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Not Using `setUp` and `tearDown` Correctly:** Failing to properly set up test conditions or clean up resources after each test can lead to inconsistent test results.\n-   **Ignoring Dependencies:** Forgetting to mock out dependencies can make tests slow, unreliable, and prone to external factors.\n-   **Asserting Too Much in One Test:** Trying to test too many things in a single test case makes it difficult to identify the source of failures and maintain the tests.\n-   **Writing Tests That Are Too Specific:** Writing tests that are tightly coupled to the implementation details can make them brittle and difficult to maintain.\n\n### 6.2. Edge Cases\n\n-   **Null Values:** Test how your application handles null or missing values.\n-   **Empty Collections:** Test how your application handles empty lists, dictionaries, or sets.\n-   **Large Data Sets:** Test how your application performs with large amounts of data.\n-   **Special Characters:** Test how your application handles special characters in user inputs.\n-   **Date and Time Zones:** Test how your application handles different date and time zones.\n\n### 6.3. Version-Specific Issues\n\n-   **Python Version Compatibility:** nose2 requires Python 3. Ensure compatibility across different minor versions of Python 3.\n-   **Dependency Versions:** Be aware of compatibility issues between nose2 and its dependencies. Specify version constraints in your project's requirements file.\n\n### 6.4. Compatibility Concerns\n\n-   **`unittest` Compatibility:** nose2 extends `unittest`, so understanding `unittest` is fundamental. Be aware of any differences in behavior between standard `unittest` and nose2.\n\n### 6.5. Debugging Strategies\n\n-   **Use a Debugger:** Use a debugger (e.g., `pdb`, `ipdb`) to step through your tests and examine the state of the application.\n-   **Print Statements:** Use `print` statements to output debugging information to the console.\n-   **Logging:** Use the `logging` module to record debugging information to a file. This is useful for debugging tests that run in a CI/CD environment.\n-   **Isolate the Problem:**  When a test fails, try to isolate the problem by running the test in isolation or by commenting out parts of the test.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **IDE:** PyCharm, VS Code with Python extension, or other Python-friendly IDE.\n-   **Text Editor:**  Sublime Text, Atom, or other text editor.\n-   **Debugger:**  `pdb` (Python Debugger) or `ipdb` (IPython Debugger).\n-   **Mocking Library:** `unittest.mock` (built-in) or `mock` (for older Python versions).\n\n### 7.2. Build Configuration\n\n-   **`setup.py` or `pyproject.toml`:** Use `setup.py` or `pyproject.toml` to define your project's dependencies and build configuration.\n-   **`requirements.txt`:** Use `requirements.txt` to list the project's dependencies. Generate this file using `pip freeze > requirements.txt`.\n-   **Virtual Environments:** Use virtual environments (e.g., `venv`, `virtualenv`) to isolate the project's dependencies from the system's Python environment.\n\n### 7.3. Linting and Formatting\n\n-   **Pylint:** Use Pylint to enforce coding standards and detect potential errors in your code.  Configure Pylint with a `.pylintrc` file.\n-   **pycodestyle (formerly pep8):** Use pycodestyle to check your code for compliance with PEP 8.\n-   **Flake8:**  Use Flake8 as a wrapper around pycodestyle, pyflakes, and McCabe complexity checker.\n-   **Black:**  Use Black to automatically format your code according to a consistent style.\n-   **isort:** Use isort to automatically sort your imports.\n\n### 7.4. Deployment Best Practices\n\n-   This is generally out of scope of `nose2` itself, but automated testing as part of the deployment pipeline ensures high quality code.\n\n### 7.5. CI/CD Integration\n\n-   **GitHub Actions, GitLab CI, Jenkins:** Integrate nose2 into your CI/CD pipeline to automatically run tests whenever code is pushed or merged.\n-   **Test Reporting:**  Configure your CI/CD system to generate test reports and display test results.\n-   **Code Coverage Reporting:**  Integrate code coverage tools (e.g., `coverage.py`) into your CI/CD pipeline to track code coverage and identify areas that need more testing.\n-   **Fail Fast:**  Configure your CI/CD pipeline to fail immediately if any tests fail. This prevents broken code from being deployed to production.\n\nBy following these best practices and coding standards, you can create robust and reliable Python testing code using nose2.",
    "metadata": {
      "globs": "*test*.py",
      "format": "mdc",
      "originalFile": "nose2.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "nose2",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "python",
      "projects",
      "using",
      "testing",
      "framework",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "nose2",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-notion-api",
    "description": "This rule provides comprehensive best practices for developing applications using the notion-api library, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "notion-api",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/notion-api.mdc",
    "content": "# Notion API Library Best Practices\n\nThis document outlines the recommended best practices for developing applications using the `notion-api` library. Following these guidelines will help you create maintainable, performant, secure, and testable Notion integrations.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a clear and consistent directory structure to improve code maintainability and collaboration. Here's a suggested structure for projects using `notion-api`:\n\n\nproject-root/\n ├── src/\n │   ├── components/        # Reusable UI components (if applicable)\n │   ├── pages/             # Page-specific components/logic (if applicable)\n │   ├── services/          # Notion API interaction logic\n │   │   ├── notion-client.js  # or notion-client.ts: Initializes the Notion client\n │   │   ├── database-service.js # or database-service.ts: Handles database interactions\n │   │   ├── page-service.js     # or page-service.ts: Handles page interactions\n │   │   └── utils.js          # or utils.ts: Utility functions for API calls, data formatting\n │   ├── models/             # Data models for Notion objects\n │   ├── utils/              # General utility functions\n │   ├── config/             # Configuration files\n │   └── app.js              # or app.ts: Main application entry point\n ├── tests/              # Unit and integration tests\n ├── .env                 # Environment variables\n ├── package.json          # Project dependencies\n └── README.md            # Project documentation\n\n\n### 1.2. File Naming Conventions\n\nUse descriptive and consistent file names:\n\n*   **Components:** `ComponentName.jsx` or `ComponentName.tsx`\n*   **Services:** `service-name.js` or `service-name.ts`\n*   **Models:** `model-name.js` or `model-name.ts`\n*   **Utility functions:** `utility-name.js` or `utility-name.ts`\n*   **Configuration files:** `config-name.js` or `config-name.ts`\n\n### 1.3. Module Organization\n\nOrganize your code into logical modules based on functionality.  For `notion-api`, this commonly involves separating:\n\n*   **Notion Client Initialization:**  A module responsible for initializing the Notion client with your API key. This should handle authentication.\n*   **Data Access Layer (Services):** Modules that encapsulate all interactions with the Notion API. These modules should provide functions for common operations like creating pages, querying databases, and updating content.  Use separate modules for database and page-related operations.\n*   **Data Models:**  Define TypeScript interfaces or JavaScript classes to represent Notion objects (e.g., Page, Database, Block). This improves type safety and code readability.\n*   **Utility Functions:**  Create utility functions for tasks such as formatting data for the Notion API, handling pagination, and error handling.\n\n### 1.4. Component Architecture (If Applicable)\n\nIf you're building a UI that interacts with the Notion API, consider using a component-based architecture (e.g., React, Vue, Angular).  Separate concerns by creating reusable components for displaying and interacting with Notion data.\n\n### 1.5. Code Splitting\n\nFor larger applications, use code splitting to improve initial load times.  Lazy-load components and modules that are not immediately needed. This is particularly useful for components that display large amounts of Notion data or perform complex API operations.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Repository Pattern:** Use the repository pattern to abstract data access logic.  This makes it easier to switch data sources in the future (e.g., using a mock API for testing).\n*   **Adapter Pattern:**  Adapt the data returned by the Notion API to your application's specific needs. This helps decouple your application from the API's data structure.\n*   **Singleton Pattern (for Notion Client):** Use the singleton pattern to ensure only one instance of the Notion client is created. This can improve performance and avoid rate limiting issues.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Fetching Data:** Use asynchronous functions (`async/await`) to fetch data from the Notion API. Implement proper error handling (see below).\n*   **Creating Pages:**  Use the `pages.create` method to create new pages. Ensure you provide the required properties for the parent (database or page).\n*   **Querying Databases:** Use the `databases.query` method to query databases.  Learn how to use filters, sorts, and pagination to retrieve the data you need efficiently.\n*   **Updating Content:**  Use the `blocks.update` and `pages.update` method to update content. Understand how to update different types of blocks and page properties.\n*   **Handling Pagination:** Implement proper pagination to handle large datasets.  Use the `has_more` and `next_cursor` properties returned by the API to iterate through all pages of data.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Directly calling the Notion API in UI components:** This violates separation of concerns and makes testing difficult.  Use a service layer to handle API interactions.\n*   **Hardcoding API keys:** Store API keys in environment variables and never commit them to your repository.\n*   **Ignoring errors:** Always handle errors and log them appropriately.  Do not swallow exceptions.\n*   **Over-fetching data:** Only request the data you need. Use filters and projections to reduce the amount of data transferred.\n*   **Creating too many Notion client instances:**  Re-use existing client instances to optimize performance and avoid rate limiting.\n*   **Lack of Pagination:** Neglecting to handle pagination when fetching large datasets from Notion databases.\n\n### 2.4. State Management (If Applicable)\n\nIf you're building a UI, choose a state management solution that fits your application's complexity (e.g., React Context, Redux, Zustand).  Store Notion data in a normalized format to improve performance and avoid unnecessary re-renders.  Use selectors to efficiently retrieve data from the state.\n\n### 2.5. Error Handling Patterns\n\nImplement robust error handling to gracefully handle API errors and unexpected situations.\n\n*   **Try-Catch Blocks:** Use `try-catch` blocks to wrap API calls and handle potential errors.\n*   **Error Logging:** Log errors with sufficient detail to facilitate debugging.\n*   **User Feedback:** Provide informative error messages to the user.\n*   **Retry Mechanism:** Implement a retry mechanism for transient errors (e.g., network errors, rate limiting).\n*   **Centralized Error Handling:** Create a centralized error handling function or middleware to handle errors consistently across your application.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Caching:** Implement caching to reduce the number of API calls. Cache frequently accessed data in memory or in a persistent store.\n*   **Batching:** Batch multiple API requests into a single request to reduce network overhead (where supported by the API.  Currently, Notion's API offers limited batching capabilities.\n*   **Minimize Data Transfer:** Only request the data you need.  Use filters and projections to reduce the amount of data transferred.\n*   **Compression:** Enable compression (e.g., gzip) to reduce the size of API responses.\n*   **Optimize Database Queries:** Carefully design your database queries to retrieve data efficiently. Use indexes to improve query performance.\n\n### 3.2. Memory Management\n\n*   **Avoid Memory Leaks:**  Be mindful of memory leaks, especially in long-running applications.  Release resources when they are no longer needed.\n*   **Use Efficient Data Structures:**  Use efficient data structures to store Notion data. Avoid creating unnecessary copies of data.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   **Virtualization:** Use virtualization to efficiently render large lists of Notion blocks.\n*   **Memoization:** Use memoization to avoid re-rendering components that haven't changed.\n*   **Code Splitting:** As described above.\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from your bundles.\n*   **Minification:** Minify your code to reduce bundle size.\n*   **Code Splitting:** As described above.\n*   **Use a CDN:** Serve static assets from a CDN to improve loading times.\n\n### 3.5. Lazy Loading\n\n*   **Lazy Load Images:** Lazy load images to improve initial load times.\n*   **Lazy Load Components:** As described above.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **API Key Exposure:** Never commit API keys to your repository. Store them in environment variables and access them securely.\n*   **Injection Attacks:**  Sanitize user input to prevent injection attacks (e.g., SQL injection, XSS).\n*   **Cross-Site Scripting (XSS):** If your application renders user-generated content from Notion, sanitize it to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection to prevent malicious websites from making requests on behalf of authenticated users.\n*   **Man-in-the-Middle Attacks:** Ensure that all communication with the Notion API is encrypted using HTTPS.\n\n### 4.2. Input Validation\n\n*   **Validate All User Input:**  Validate all user input before sending it to the Notion API. This includes checking data types, formats, and ranges.\n*   **Sanitize User Input:** Sanitize user input to remove potentially harmful characters.\n\n### 4.3. Authentication and Authorization\n\n*   **Use OAuth 2.0:** Use OAuth 2.0 for authentication and authorization. This allows users to grant your application access to their Notion data without sharing their passwords.\n*   **Store Tokens Securely:** Store access tokens securely.  Use encryption or a secure storage mechanism (e.g., Keychain).\n*   **Follow the Principle of Least Privilege:** Only request the permissions you need.\n\n### 4.4. Data Protection\n\n*   **Encrypt Sensitive Data:**  Encrypt sensitive data at rest and in transit.\n*   **Follow Data Privacy Regulations:**  Comply with all applicable data privacy regulations (e.g., GDPR, CCPA).\n*   **Regularly Audit Security Practices:** Regularly audit your security practices to identify and address potential vulnerabilities.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Ensure that all communication with the Notion API is encrypted using HTTPS.\n*   **Validate SSL Certificates:** Validate SSL certificates to prevent man-in-the-middle attacks.\n*   **Use a Secure API Client:** Use a secure API client that supports encryption and certificate validation.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Unit test individual components and modules to ensure they function correctly in isolation.\n*   **Mock External Dependencies:** Mock external dependencies (e.g., the Notion API) to isolate your code and make tests more predictable.\n*   **Use a Testing Framework:** Use a testing framework like Jest or Mocha to write and run your unit tests.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Integration test the interactions between different components and modules to ensure they work together correctly.\n*   **Use a Test Database:** Use a test database to avoid affecting your production data.\n*   **Seed the Test Database:** Seed the test database with sample data to make tests more realistic.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Application Flow:** End-to-end test the entire application flow to ensure that everything works correctly from start to finish.\n*   **Use a Testing Framework:** Use a testing framework like Cypress or Puppeteer to write and run your end-to-end tests.\n*   **Run Tests in a CI/CD Pipeline:** Run your tests in a CI/CD pipeline to ensure that changes don't break existing functionality.\n\n### 5.4. Test Organization\n\n*   **Create a Dedicated Test Directory:** Create a dedicated test directory to store your tests.\n*   **Follow a Consistent Naming Convention:** Follow a consistent naming convention for your test files.\n*   **Organize Tests by Feature:** Organize tests by feature to make them easier to find and maintain.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mocking Libraries:** Use mocking libraries like Jest or Sinon to create mocks and stubs.\n*   **Mock the Notion API:** Mock the Notion API to isolate your code and make tests more predictable.\n*   **Stub API Responses:** Stub API responses to control the data returned by the API.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not Understanding the Notion API Data Model:**  Failing to understand the Notion API data model can lead to incorrect API calls and unexpected results. Study the documentation thoroughly.\n*   **Misunderstanding Rate Limits:**  Exceeding rate limits can lead to temporary blocking. Implement proper rate limiting handling and retry mechanisms.\n*   **Improperly Handling Errors:**  Ignoring errors can lead to silent failures and difficult debugging. Always handle errors and log them appropriately.\n*   **Not Using Pagination:**  Failing to use pagination can lead to incomplete data retrieval. Implement proper pagination to handle large datasets.\n\n### 6.2. Edge Cases\n\n*   **Empty Databases:** Handle the case where a database is empty or doesn't contain the expected properties.\n*   **Deleted Pages:** Handle the case where a page has been deleted or moved.\n*   **Permission Errors:**  Handle the case where the application doesn't have the required permissions to access a page or database.\n*   **API Downtime:** Handle the case where the Notion API is temporarily unavailable.\n\n### 6.3. Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes in new versions of the Notion API. Test your application thoroughly after upgrading.\n*   **Deprecated Features:** Avoid using deprecated features, as they may be removed in future versions.\n\n### 6.4. Compatibility Concerns\n\n*   **Library Conflicts:** Be aware of potential library conflicts between `notion-api` and other libraries in your project.\n*   **Browser Compatibility:** Ensure that your application is compatible with the target browsers.\n\n### 6.5. Debugging Strategies\n\n*   **Use Debugging Tools:** Use debugging tools to inspect your code and identify errors.\n*   **Log API Requests and Responses:** Log API requests and responses to help diagnose issues.\n*   **Use a Network Monitor:** Use a network monitor to inspect network traffic and identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE:** Visual Studio Code, IntelliJ IDEA, or WebStorm\n*   **Node.js:**  A JavaScript runtime environment\n*   **npm or Yarn:** Package managers\n*   **Git:** Version control system\n*   **Postman or Insomnia:** API testing tools\n\n### 7.2. Build Configuration\n\n*   **Use a Build Tool:** Use a build tool like Webpack or Parcel to bundle your code.\n*   **Configure Environment Variables:** Configure environment variables to store API keys and other sensitive information.\n*   **Use a .gitignore File:** Use a `.gitignore` file to exclude sensitive files from your repository.\n\n### 7.3. Linting and Formatting\n\n*   **Use a Linter:** Use a linter like ESLint or JSHint to enforce coding standards.\n*   **Use a Formatter:** Use a formatter like Prettier to automatically format your code.\n*   **Configure CI/CD:** Configure CI/CD to automatically lint and format your code.\n\n### 7.4. Deployment\n\n*   **Choose a Deployment Platform:** Choose a deployment platform that fits your application's needs (e.g., Vercel, Netlify, AWS).\n*   **Configure Environment Variables:** Configure environment variables on your deployment platform to store API keys and other sensitive information.\n*   **Monitor Your Application:** Monitor your application to identify and address performance issues and errors.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD Platform:** Use a CI/CD platform like GitHub Actions or GitLab CI/CD to automate your build, test, and deployment processes.\n*   **Run Tests in CI/CD:** Run your tests in your CI/CD pipeline to ensure that changes don't break existing functionality.\n*   **Automate Deployment:** Automate deployment to reduce the risk of human error.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx",
      "format": "mdc",
      "originalFile": "notion-api.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "notion",
      "api",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "using",
      "notion-api",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "notion-api",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-numba",
    "description": "This rule provides comprehensive best practices and coding standards for the Numba library, covering code organization, performance optimization, security, testing, and common pitfalls. It aims to help developers write efficient, maintainable, and secure Numba code.",
    "author": "sanjeed5",
    "tags": [
      "numba",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/numba.mdc",
    "content": "# Numba Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for the Numba library to help developers write efficient, maintainable, and secure code.\n\n## Library Information:\n\n- Name: numba\n- Tags: ai, ml, gpu-computing, python, jit-compiler\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n- **`src/`:** Contains the main source code. Subdivide into modules or packages based on functionality (e.g., `src/core`, `src/cuda`, `src/npyimpl`).\n- **`tests/`:** Contains unit, integration, and end-to-end tests.  Mirror the `src/` structure to easily locate corresponding tests.\n- **`examples/`:** Provides example scripts and notebooks demonstrating how to use numba features.\n- **`docs/`:** Stores documentation in reStructuredText or Markdown format.\n- **`benchmarks/`:** Contains benchmark scripts for performance evaluation.\n- **`scripts/`:**  Utilities and helper scripts for development, testing, or deployment.\n- **`.cursor/rules/`:** Store custom rules for AI-assisted code generation (e.g., this file).\n\nExample:\n\n\nmy_project/\n├── src/\n│   ├── __init__.py\n│   ├── core/\n│   │   ├── __init__.py\n│   │   ├── functions.py\n│   │   ├── types.py\n│   ├── cuda/\n│   │   ├── __init__.py\n│   │   ├── kernels.py\n│   │   ├── device.py\n│   ├── npyimpl/\n│   │   ├── __init__.py\n│   │   ├── array_methods.py\n│   │   ├── reductions.py\n├── tests/\n│   ├── __init__.py\n│   ├── core/\n│   │   ├── test_functions.py\n│   │   ├── test_types.py\n│   ├── cuda/\n│   │   ├── test_kernels.py\n│   │   ├── test_device.py\n│   ├── npyimpl/\n│   │   ├── test_array_methods.py\n│   │   ├── test_reductions.py\n├── examples/\n│   ├── mandelbrot.py\n│   ├── gaussian_blur.ipynb\n├── docs/\n│   ├── source/\n│   │   ├── conf.py\n│   │   ├── index.rst\n│   ├── Makefile\n├── benchmarks/\n│   ├── bench_matmul.py\n├── scripts/\n│   ├── build_extensions.py\n├── .cursor/\n│   ├── rules/\n│   │   ├── numba_rules.mdc\n├── setup.py\n├── README.md\n├── LICENSE\n\n\n### 1.2. File Naming Conventions\n\n- Python files: Use descriptive lowercase names with underscores (e.g., `array_methods.py`, `type_inference.py`).\n- Test files: Prefix with `test_` and mirror the module/file being tested (e.g., `test_array_methods.py`).\n- Class names: Use PascalCase (e.g., `NumbaTypeManager`, `CUDADeviceContext`).\n- Function and variable names: Use lowercase with underscores (e.g., `jit_compile`, `input_array`).\n- Constants: Use uppercase with underscores (e.g., `DEFAULT_NUM_THREADS`, `MAX_ARRAY_SIZE`).\n\n### 1.3. Module Organization\n\n- Group related functionality into modules. For example, put all type-related code in a `types` module.\n- Use `__init__.py` files to define packages and control namespace imports.\n- Keep modules focused and avoid large, monolithic modules.\n- Use relative imports within packages (e.g., `from . import functions`).\n\n### 1.4. Component Architecture\n\n- Design with clear separation of concerns (e.g., type inference, code generation, runtime execution).\n- Employ interfaces or abstract base classes for loose coupling between components.\n- Use dependency injection to manage component dependencies.\n- Favor composition over inheritance to promote code reuse and flexibility.\n\n### 1.5. Code Splitting\n\n- Break down large functions into smaller, more manageable functions.\n- Group related functions into classes or modules.\n- Use decorators to add functionality without modifying the original code (e.g., `@jit`, `@vectorize`).\n- Extract common code into reusable utility functions.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Decorator Pattern:** Used extensively in Numba via the `@jit`, `@njit`, `@vectorize`, and `@cuda.jit` decorators for applying transformations and optimizations to functions.\n- **Factory Pattern:** Can be used to create different types of compiled functions based on runtime conditions or configurations.\n- **Strategy Pattern:** Employ different compilation strategies based on target architecture or optimization level.\n\n### 2.2. Recommended Approaches\n\n- **Use `@njit` whenever possible:**  This enforces no-python mode, maximizing performance.  Only fall back to `@jit` if no-python mode is not feasible.\n- **Explicitly specify types:** When possible, define input and output types using Numba's type system for increased performance and type safety.\n- **Utilize `prange` for parallel loops:** When using `parallel=True`, use `numba.prange` instead of `range` for loops that can be executed in parallel.\n- **Minimize data transfer between CPU and GPU:** When using CUDA, keep data on the GPU as much as possible and pre-allocate output arrays.\n- **Use structured array when possible:** When working with complex data, leverage the power of structured arrays to improve data access times and readability.\n\n### 2.3. Anti-patterns\n\n- **Relying on object mode:**  Object mode is significantly slower than no-python mode. Avoid it by ensuring your code is compatible with no-python mode.\n- **Excessive use of global variables:** Global variables can hinder type inference and optimization.  Pass data as function arguments instead.\n- **Unnecessary data copying:** Avoid copying data between CPU and GPU or within memory unless absolutely necessary.\n- **Ignoring profiling results:**  Don't guess where performance bottlenecks are.  Use profiling tools to identify and address them.\n- **Using Python data structures like dictionaries and lists directly inside `@njit` decorated code:** These data structures usually trigger object mode and hinder performance. Opt for `typed-list` and `typed-dict` when possible.\n\n### 2.4. State Management\n\n- Avoid mutable global state within Numba-compiled functions. Mutating global state can lead to unpredictable behavior and make debugging difficult.\n- If state needs to be maintained, consider using a class with methods decorated with `@njit` to encapsulate the state and operations.\n- When working with CUDA, manage device memory explicitly to avoid memory leaks and ensure efficient resource utilization.\n\n### 2.5. Error Handling\n\n- Use `try...except` blocks to handle potential exceptions within Numba-compiled functions.\n- Propagate errors gracefully and provide informative error messages.\n- Consider using Numba's error reporting mechanisms for custom error handling.\n- Handle CUDA errors properly when working with GPU code.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Just-In-Time (JIT) Compilation:** Leverage `@jit` and `@njit` decorators for automatic code optimization.\n- **Vectorization:** Utilize `@vectorize` decorator for element-wise operations on arrays.\n- **Parallelization:** Employ `parallel=True` and `prange` for parallel loop execution on multi-core CPUs.\n- **CUDA Acceleration:** Use `@cuda.jit` decorator to compile and execute code on NVIDIA GPUs.\n- **`fastmath`:** Use `fastmath=True` when strict IEEE 754 compliance is not required to enable aggressive optimizations.\n- **Loop Unrolling:** Manually unroll loops to reduce loop overhead when appropriate.\n- **Memory Alignment:** Ensure data is properly aligned in memory for efficient access.\n- **Kernel Fusion:** Combine multiple operations into a single kernel to reduce memory access and improve performance.\n- **Use Intel SVML:** If possible, install and use the Intel Short Vector Math Library (SVML) for optimized transcendental functions.\n\n### 3.2. Memory Management\n\n- **Minimize data transfer between CPU and GPU:** Keep data on the GPU as much as possible.\n- **Pre-allocate output arrays:** Use `cuda.device_array` or `np.empty` to pre-allocate memory.\n- **Use CUDA Device Arrays:** Operate directly on device arrays to avoid implicit data transfers.\n- **Use `del` keyword to free unused arrays:** Use the `del` keyword to release large arrays or variables and free up memory after they're no longer needed.\n\n### 3.3. Bundle Size Optimization\n\n- Numba itself doesn't directly impact front-end bundle sizes (as it operates on the backend Python code).  However, minimizing dependencies and using efficient numerical algorithms can indirectly reduce the overall application size.\n\n### 3.4. Lazy Loading\n\n- Numba JIT compilation performs lazy loading by default. Functions are compiled only when they are first called.\n- This can be beneficial for large applications where not all functions need to be compiled immediately.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n- **Code Injection:** Avoid using `eval()` or `exec()` with user-supplied input, as this can lead to arbitrary code execution.\n- **Integer Overflow:** Be mindful of potential integer overflows when performing arithmetic operations.\n- **Buffer Overflow:** Prevent buffer overflows by validating array dimensions and sizes before performing operations.\n- **Denial of Service (DoS):** Limit resource usage (e.g., memory, CPU time) to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n- Validate all user-supplied input before passing it to Numba-compiled functions.\n- Check data types, ranges, and sizes to prevent unexpected behavior or errors.\n- Sanitize input to remove potentially malicious characters or code.\n\n### 4.3. Data Protection\n\n- Avoid storing sensitive data in plain text. Encrypt sensitive data at rest and in transit.\n- Implement access controls to restrict access to sensitive data to authorized users only.\n\n### 4.4. Secure API Communication\n\n- Use HTTPS for all API communication to encrypt data in transit.\n- Implement authentication and authorization mechanisms to verify the identity of clients and restrict access to resources.\n- Protect against Cross-Site Scripting (XSS) and Cross-Site Request Forgery (CSRF) attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- Write unit tests for individual functions and classes to verify their correctness.\n- Use the `unittest` or `pytest` frameworks for writing and running tests.\n- Mock external dependencies to isolate the code being tested.\n- Test different input values and edge cases to ensure robustness.\n\n### 5.2. Integration Testing\n\n- Write integration tests to verify the interaction between different components or modules.\n- Test the integration between Numba-compiled functions and other parts of the application.\n- Use realistic test data to simulate real-world scenarios.\n\n### 5.3. End-to-End Testing\n\n- Write end-to-end tests to verify the overall functionality of the application.\n- Test the entire workflow from user input to output to ensure that all components are working correctly.\n- Use automated testing tools to run tests regularly.\n\n### 5.4. Test Organization\n\n- Organize tests in a directory structure that mirrors the source code.\n- Use descriptive test names to indicate the functionality being tested.\n- Write clear and concise test cases that are easy to understand and maintain.\n\n### 5.5. Mocking and Stubbing\n\n- Use mocking and stubbing to replace external dependencies with controlled substitutes during testing.\n- This allows you to isolate the code being tested and simulate different scenarios.\n- Use libraries like `unittest.mock` or `pytest-mock` for mocking and stubbing.\n- Make sure mocks respect type constraints used within the tested code.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Incorrect data types:**  Numba relies on type inference, so providing incorrect data types can lead to unexpected results or errors. Explicitly specify types when possible.\n- **Unsupported Python features:**  Numba does not support all Python features. Be aware of the limitations and use supported alternatives.\n- **Not using no-python mode:** Forgetting to use `@njit` or `nopython=True` can result in significantly slower performance due to object mode compilation.\n- **Ignoring performance profiling:**  Failing to profile your code can lead to inefficient optimizations or missed opportunities for performance improvements.\n- **Over-optimizing too early:** Focus on writing correct and readable code first, then optimize only when necessary.\n- **Incompatible NumPy versions:** Make sure you are using a compatible NumPy version that Numba supports.\n\n### 6.2. Edge Cases\n\n- **Division by zero:** Handle potential division by zero errors gracefully.\n- **NaN and Inf values:** Be aware of how NaN and Inf values can propagate through calculations.\n- **Large arrays:**  Be mindful of memory usage when working with large arrays, especially on GPUs.\n- **Multithreading issues:** When using `parallel=True`, be aware of potential race conditions and data synchronization issues.\n\n### 6.3. Version-Specific Issues\n\n- Consult the Numba documentation and release notes for any version-specific issues or compatibility concerns.\n- Pay attention to deprecation warnings and update your code accordingly.\n\n### 6.4. Compatibility Concerns\n\n- Ensure compatibility between Numba and other libraries you are using, such as NumPy, SciPy, and CUDA.\n- Be aware of potential conflicts between different versions of these libraries.\n\n### 6.5. Debugging Strategies\n\n- Use the `print()` function or a debugger to inspect variables and execution flow.\n- Check the Numba documentation and community forums for troubleshooting tips.\n- Use the `numba.errors.DEBUG` environment variable to enable debug output from Numba.\n- Use `numba --sysinfo` to get details about your system for inclusion in bug reports or when seeking help.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **IDE:** VS Code with the Python extension, PyCharm, or Jupyter Notebook.\n- **Profiler:** `cProfile` or `line_profiler` for identifying performance bottlenecks.\n- **Debugger:** `pdb` or an IDE-integrated debugger for stepping through code and inspecting variables.\n- **Linter:** `flake8` or `pylint` for enforcing code style and identifying potential errors.\n- **Formatter:** `black` or `autopep8` for automatically formatting code according to PEP 8.\n\n### 7.2. Build Configuration\n\n- Use `setup.py` or `pyproject.toml` for managing project dependencies and build configuration.\n- Specify Numba as a dependency in your project's configuration file.\n- Consider using a virtual environment (e.g., `venv` or `conda`) to isolate project dependencies.\n\n### 7.3. Linting and Formatting\n\n- Use `flake8` or `pylint` to enforce code style and identify potential errors.\n- Configure the linter to check for Numba-specific best practices, such as using `@njit` whenever possible.\n- Use `black` or `autopep8` to automatically format code according to PEP 8.\n\n### 7.4. Deployment Best Practices\n\n- Package your application and its dependencies into a self-contained executable or container.\n- Use a deployment platform that supports Numba and its dependencies (e.g., AWS Lambda, Google Cloud Functions, Docker).\n- Optimize your application for the target deployment environment.\n\n### 7.5. CI/CD Integration\n\n- Integrate Numba into your Continuous Integration/Continuous Delivery (CI/CD) pipeline.\n- Run unit tests, integration tests, and end-to-end tests automatically on every commit.\n- Use a CI/CD tool like GitHub Actions, GitLab CI, or Jenkins to automate the build, test, and deployment process.\n- Perform performance testing as part of the CI/CD pipeline to detect regressions.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "numba.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "numba",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "library",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "numba",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-numpy",
    "description": "This rule provides best practices for using NumPy in Python, covering coding standards, performance optimization, security, and testing strategies to enhance code quality and maintainability.",
    "author": "sanjeed5",
    "tags": [
      "numpy",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/numpy.mdc",
    "content": "# NumPy Library Best Practices and Coding Standards\n\nThis document outlines best practices for using the NumPy library in Python for scientific computing, data science, machine learning, and AI development. Adhering to these guidelines will improve code readability, maintainability, performance, security, and overall project success.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **`root_directory/`**: The project's root directory.\n    *   **`data/`**: Stores datasets (e.g., CSV files, NumPy arrays in `.npy` format).  Consider using subdirectories within `data/` to categorize datasets (e.g., `raw/`, `processed/`).  Use version control (e.g., DVC) for larger datasets.\n    *   **`notebooks/`**: Jupyter notebooks for exploration, prototyping, and EDA. Number notebooks sequentially (e.g., `01_data_loading.ipynb`, `02_feature_engineering.ipynb`).  Keep notebooks clean and well-documented; move reusable code to modules.\n    *   **`src/`** (or `package_name/`): Contains the Python source code.\n        *   **`package_name/`**:  The main package directory.  Use your project's name as the package name.\n            *   **`__init__.py`**: Marks the directory as a Python package.  Can be empty or contain package-level initialization code.\n            *   **`utils/`**: Utility functions and helper classes.  Split into submodules if necessary (e.g., `utils/data_handling.py`, `utils/math_functions.py`).\n            *   **`models/`**:  Model definitions and training scripts (if applicable).  Subdirectories can organize models further (e.g., `models/regression/`, `models/classification/`).\n            *   **`preprocessing/`**:  Data preprocessing functions and classes.\n            *   **`visualization/`**: Functions for creating plots and visualizations.\n            *   **`config.py`**:  Configuration settings (e.g., file paths, hyperparameters). Use a library like `python-box` or `dynaconf` to manage configurations.\n            *   **`main.py`**:  The main entry point for the application (if applicable).  Use `if __name__ == \"__main__\":` to control execution.\n    *   **`tests/`**: Unit and integration tests.  Mirror the `src/` structure.  Use `pytest` or `unittest`.\n        *   **`tests/utils/`**: Tests for the `utils/` module.\n        *   **`tests/models/`**: Tests for the `models/` module.\n        *   **`conftest.py`**:  Configuration file for `pytest`.  Can contain fixtures and hooks.\n    *   **`docs/`**: Documentation for the project (e.g., using Sphinx).\n    *   **`scripts/`**:  Scripts for data downloading, processing, or model deployment.\n    *   **`requirements.txt`**:  Lists Python dependencies.  Use `pip freeze > requirements.txt` to generate.\n    *   **`.gitignore`**:  Specifies files and directories to ignore in Git (e.g., `data/`, `notebooks/`, `__pycache__/`).\n    *   **`README.md`**:  Provides a high-level overview of the project.\n    *   **`LICENSE`**:  Specifies the license for the project.\n    *   **`setup.py`** or **`pyproject.toml`**: Used for packaging and distribution.\n\n### 1.2. File Naming Conventions\n\n*   **Python files**: Use lowercase with underscores (snake_case): `data_loader.py`, `feature_engineering.py`.\n*   **Class names**: Use CamelCase: `DataLoader`, `FeatureEngineer`.\n*   **Function and variable names**: Use snake_case: `load_data()`, `feature_names`.\n*   **Constants**: Use uppercase with underscores: `MAX_ITERATIONS`, `DEFAULT_LEARNING_RATE`.\n\n### 1.3. Module Organization\n\n*   **Separate concerns**: Each module should have a single, well-defined purpose.\n*   **Avoid circular dependencies**:  Design modules to minimize dependencies on each other.\n*   **Use relative imports**: Within a package, use relative imports to refer to other modules: `from . import utils`, `from ..models import BaseModel`.\n*   **Expose a clear API**: Each module should have a well-defined API (Application Programming Interface) of functions and classes that are intended for external use. Hide internal implementation details using leading underscores (e.g., `_helper_function()`).\n\n### 1.4. Component Architecture\n\n*   **Layered architecture**:  Divide the application into layers (e.g., data access, business logic, presentation) to promote separation of concerns.\n*   **Microservices**:  For larger applications, consider breaking them down into smaller, independent microservices.\n*   **Design patterns**: Implement relevant design patterns to enhance flexibility and maintainability.\n\n### 1.5. Code Splitting\n\n*   **Functions**: Break down large functions into smaller, more manageable functions.\n*   **Classes**: Use classes to encapsulate related data and behavior.\n*   **Modules**: Split code into multiple modules based on functionality.\n*   **Packages**: Organize modules into packages to create a hierarchical structure.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Strategy**: Use a Strategy pattern to encapsulate different algorithms or approaches for a specific task.\n*   **Factory**: Employ a Factory pattern to create objects without specifying their concrete classes.\n*   **Observer**: Use an Observer pattern to notify dependent objects when the state of an object changes.\n\n### 2.2. Recommended Approaches\n\n*   **Vectorization**:  Leverage NumPy's vectorized operations whenever possible to avoid explicit loops. Vectorization significantly improves performance.\n*   **Broadcasting**: Understand and utilize NumPy's broadcasting rules to perform operations on arrays with different shapes.\n*   **Ufuncs (Universal Functions)**: Use NumPy's built-in ufuncs (e.g., `np.sin`, `np.exp`, `np.add`) for element-wise operations. Ufuncs are highly optimized.\n*   **Masking**: Use boolean masks to select and modify specific elements in arrays.\n*   **Views vs. Copies**: Be aware of the difference between views and copies when slicing and manipulating arrays. Modifying a view affects the original array.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Explicit loops**: Avoid explicit loops for element-wise operations. Use vectorized operations instead.\n*   **Unnecessary copies**: Avoid creating unnecessary copies of arrays. Use views when possible.\n*   **Modifying arrays in place**: Be careful when modifying arrays in place, as it can lead to unexpected side effects.\n*   **Ignoring broadcasting rules**:  Not understanding broadcasting rules can lead to incorrect results or errors.\n*   **Hardcoding array shapes**:  Avoid hardcoding array shapes. Use `array.shape` to get the shape dynamically.\n*   **Relying on mutable default arguments**:  Avoid using mutable default arguments (e.g., lists, dictionaries) in function definitions.\n\n### 2.4. State Management\n\n*   **Immutable data structures**: When appropriate, use immutable data structures to prevent accidental modification of data.  Consider libraries like `namedtuple` or `dataclasses` (with `frozen=True`).\n*   **Encapsulation**: Encapsulate state within classes to control access and modification.\n*   **Dependency injection**: Use dependency injection to decouple components and make them more testable.\n\n### 2.5. Error Handling\n\n*   **Exceptions**: Use exceptions to handle errors and unexpected conditions. Raise specific exceptions (e.g., `ValueError`, `TypeError`) when appropriate.\n*   **Assertions**: Use assertions to check for conditions that should always be true. Assertions are helpful for debugging and validating data.\n*   **Logging**: Use logging to record errors, warnings, and informational messages. Configure logging to write to a file or stream.\n*   **`np.errstate`**: Use `np.errstate` context manager to handle floating-point exceptions (e.g., division by zero, overflow). You can configure how NumPy handles these exceptions (e.g., ignore, warn, raise).\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Vectorization**:  As mentioned earlier, prioritize vectorized operations over explicit loops.\n*   **Memory Alignment**: NumPy arrays are typically aligned in memory, which can improve performance. Ensure that your data is aligned correctly.\n*   **Data Types**: Choose the smallest possible data type that can represent your data. Using smaller data types reduces memory usage and improves performance. For example, use `np.int8` instead of `np.int64` if the values are within the range of `np.int8`.\n*   **`np.einsum`**: Use `np.einsum` (Einstein summation) for complex array operations. `np.einsum` can often be more efficient than explicit loops or other NumPy functions.\n*   **Numba**: Use Numba to JIT (Just-In-Time) compile NumPy code. Numba can significantly improve the performance of computationally intensive code.\n*   **Cython**: Use Cython to write NumPy code in C. Cython allows you to take advantage of C's performance while still using Python's syntax.\n*   **BLAS/LAPACK**: NumPy relies on BLAS (Basic Linear Algebra Subprograms) and LAPACK (Linear Algebra Package) libraries for linear algebra operations. Ensure that you are using an optimized BLAS/LAPACK implementation (e.g., OpenBLAS, MKL).\n*   **`np.fft`**: For FFT (Fast Fourier Transform) operations, use the functions provided in NumPy's `np.fft` module. They're usually highly optimized.\n\n### 3.2. Memory Management\n\n*   **Avoid creating large temporary arrays**:  Minimize the creation of large temporary arrays, especially within loops.  Use in-place operations when possible.\n*   **`np.empty`**: Use `np.empty` to create uninitialized arrays when you don't need to initialize the values immediately.  This can be faster than `np.zeros` or `np.ones`.\n*   **`np.memmap`**: Use `np.memmap` to create memory-mapped arrays. Memory-mapped arrays allow you to work with large datasets that don't fit in memory.\n*   **Garbage collection**: Be mindful of Python's garbage collection. Explicitly delete large arrays when they are no longer needed to free up memory: `del my_array`.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   This is mainly relevant when NumPy arrays are used for image processing or other visualization tasks. Libraries like Matplotlib, Seaborn, or specialized rendering engines may offer specific optimizations for handling NumPy arrays.\n\n### 3.4. Bundle Size Optimization (If Applicable)\n\n*   If you are deploying a web application or other application that includes NumPy, consider using tree shaking to remove unused code.  Tools like Webpack or Parcel can help with tree shaking.\n\n### 3.5. Lazy Loading\n\n*   If you are working with very large datasets, use lazy loading to load data only when it is needed. Libraries like Dask or Apache Arrow can help with lazy loading.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Arbitrary code execution**:  Avoid using `np.fromstring` or `np.frombuffer` with untrusted input, as this can lead to arbitrary code execution.\n*   **Denial of service**:  Be careful when using NumPy functions with user-supplied input, as this can lead to denial-of-service attacks. Validate input to prevent excessively large array allocations or computationally intensive operations.\n*   **Integer overflow**: Be aware of integer overflow issues when performing arithmetic operations on large arrays. Use appropriate data types to prevent overflow.\n\n### 4.2. Input Validation\n\n*   **Data type validation**:  Ensure that the input data has the expected data type.\n*   **Shape validation**:  Ensure that the input data has the expected shape.\n*   **Range validation**:  Ensure that the input data falls within the expected range.\n*   **Sanitize input**: Sanitize input data to prevent injection attacks.\n*   **Use `np.asarray`**: When receiving data from external sources, use `np.asarray` to convert it to a NumPy array. This ensures that you are working with a NumPy array and not some other type of object that might have unexpected behavior.\n\n### 4.3. Authentication and Authorization (If Applicable)\n\n*   NumPy itself doesn't handle authentication or authorization.  If your application requires these features, use appropriate authentication and authorization mechanisms (e.g., OAuth, JWT).\n\n### 4.4. Data Protection\n\n*   **Encryption**: Encrypt sensitive data at rest and in transit.\n*   **Access control**: Restrict access to data based on user roles and permissions.\n*   **Data masking**: Mask sensitive data to protect it from unauthorized access.\n*   **Regular Security Audits**: Conduct regular security audits to identify and address potential vulnerabilities.\n\n### 4.5. Secure API Communication (If Applicable)\n\n*   Use HTTPS for all API communication.\n*   Validate all API requests.\n*   Use rate limiting to prevent denial-of-service attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test individual functions and classes**: Unit tests should focus on testing individual functions and classes in isolation.\n*   **Use `pytest` or `unittest`**: Use a testing framework like `pytest` or `unittest` to write and run unit tests.\n*   **Test edge cases**: Test edge cases and boundary conditions to ensure that your code handles them correctly.\n*   **Test for exceptions**: Test that your code raises the correct exceptions when errors occur.\n*   **Use parametrization**: Use parametrization to run the same test with multiple sets of inputs.\n*   **Assert almost equal**: Use `np.testing.assert_allclose` instead of `assert a == b` when comparing floating-point numbers.  This accounts for potential floating-point precision errors.\n\n### 5.2. Integration Testing\n\n*   **Test interactions between components**: Integration tests should focus on testing the interactions between different components of your application.\n*   **Use mock objects**: Use mock objects to isolate components during integration testing.\n\n### 5.3. End-to-End Testing (If Applicable)\n\n*   **Test the entire application flow**: End-to-end tests should focus on testing the entire application flow from start to finish.\n\n### 5.4. Test Organization\n\n*   **Mirror the source code structure**: Organize your tests in a directory structure that mirrors the source code structure.\n*   **Use descriptive test names**: Use descriptive test names that clearly indicate what the test is testing.\n*   **Keep tests small and focused**: Keep tests small and focused to make them easier to understand and maintain.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use mock objects to isolate components**: Use mock objects to isolate components during testing.\n*   **Use `unittest.mock` or `pytest-mock`**: Use a mocking library like `unittest.mock` or `pytest-mock` to create mock objects.\n*   **Mock external dependencies**: Mock external dependencies (e.g., databases, APIs) to avoid relying on them during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Incorrect array indexing**: NumPy uses 0-based indexing, which can be confusing for developers who are used to other languages.\n*   **Incorrect array slicing**: Be careful when slicing arrays, as this can create views or copies depending on the slicing operation.\n*   **Incorrect broadcasting**: Not understanding broadcasting rules can lead to incorrect results or errors.\n*   **Modifying views**: Modifying a view affects the original array, which can lead to unexpected side effects.\n*   **Ignoring data types**:  Not specifying the correct data type can lead to integer overflow or other issues.\n\n### 6.2. Edge Cases\n\n*   **Empty arrays**: Be careful when working with empty arrays, as they can have unexpected behavior.\n*   **Arrays with NaN or Inf values**: Be aware that arrays can contain NaN (Not a Number) or Inf (Infinity) values, which can affect calculations.\n*   **Arrays with mixed data types**:  NumPy arrays should typically have a single data type.  Be cautious when working with arrays that have mixed data types (e.g., object arrays).\n\n### 6.3. Version-Specific Issues\n\n*   Consult the NumPy release notes for information on version-specific issues and changes.\n\n### 6.4. Compatibility Concerns\n\n*   **Python version**: Ensure that your code is compatible with the Python version you are using.\n*   **Other libraries**: Be aware of compatibility issues between NumPy and other libraries.\n*   **Operating system**:  Be aware of potential differences in behavior across different operating systems.\n\n### 6.5. Debugging Strategies\n\n*   **Print statements**: Use print statements to inspect the values of variables and arrays.\n*   **Debuggers**: Use a debugger (e.g., pdb, ipdb) to step through your code and inspect the state of the program.\n*   **Logging**: Use logging to record errors, warnings, and informational messages.\n*   **`np.seterr`**: Use `np.seterr` to configure how NumPy handles floating-point exceptions.\n*   **`np.info`**: Use `np.info` to get information about NumPy objects.\n*   **Visual Inspection**: Use visualization tools (Matplotlib, Seaborn, etc.) to visually inspect data and identify potential problems.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE**: Use an IDE (Integrated Development Environment) like VS Code, PyCharm, or Spyder.\n*   **Jupyter Notebook**: Use Jupyter Notebook for exploration, prototyping, and EDA.\n*   **IPython**: Use IPython for interactive computing.\n*   **Debugging Tools**: Utilize debuggers like pdb or IDE-integrated debuggers for stepping through code and inspecting variables.\n\n### 7.2. Build Configuration\n\n*   **`setup.py` or `pyproject.toml`**:  Use `setup.py` or `pyproject.toml` to configure the build process.\n*   **`requirements.txt`**:  Use `requirements.txt` to specify dependencies.\n*   **Virtual environments**:  Use virtual environments to isolate dependencies.\n*   **Conda**: Consider using Conda for environment and package management, particularly for scientific computing workflows.\n\n### 7.3. Linting and Formatting\n\n*   **PEP 8**: Follow PEP 8 style guidelines for Python code.\n*   **Linters**: Use a linter (e.g., pylint, flake8) to check for style violations and potential errors.\n*   **Formatters**: Use a formatter (e.g., black, autopep8) to automatically format your code.\n*   **Pre-commit hooks**: Use pre-commit hooks to run linters and formatters before committing code.\n\n### 7.4. Deployment\n\n*   **Containerization (Docker)**: Use Docker to create a containerized environment for your application. This helps ensure consistency across different environments.\n*   **Cloud platforms**: Deploy your application to a cloud platform (e.g., AWS, Azure, GCP).\n*   **Serverless functions**: Consider using serverless functions (e.g., AWS Lambda, Azure Functions, Google Cloud Functions) for simple applications.\n*   **Model serving frameworks**: If deploying machine learning models, use a model serving framework like TensorFlow Serving or TorchServe.\n\n### 7.5. CI/CD Integration\n\n*   **Continuous Integration (CI)**: Use a CI system (e.g., Jenkins, Travis CI, CircleCI, GitHub Actions) to automatically build and test your code when changes are made.\n*   **Continuous Delivery (CD)**: Use a CD system to automatically deploy your code to production after it has been tested.\n*   **Automated Testing**: Integrate automated tests into your CI/CD pipeline to ensure code quality and prevent regressions.\n*   **Infrastructure as Code (IaC)**: Define your infrastructure using code (e.g., Terraform, CloudFormation) to automate the provisioning and management of your environment.\n\nBy following these best practices, you can write high-quality, maintainable, and performant NumPy code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "numpy.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "numpy",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "using",
      "python",
      "covering",
      "coding",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "numpy",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-nuxt",
    "description": "This rule provides comprehensive best practices and coding standards for Nuxt.js projects, covering code organization, performance, security, testing, and common pitfalls. It aims to ensure maintainable, scalable, and secure Nuxt.js applications.",
    "author": "sanjeed5",
    "tags": [
      "nuxt",
      "vue",
      "frontend",
      "ssr",
      "cursor",
      "cursor-rule",
      "mdc",
      "ui",
      "javascript",
      "web",
      "fullstack",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/nuxt.mdc",
    "content": "- **Enable ESLint support:** Use the `@nuxt/eslint` module for project-aware ESLint configuration. This ensures code quality and consistency.\n  - `npx nuxi module add eslint` to add the module.\n  - Customize the generated `eslint.config.mjs` file as needed.\n- **Adopt Nuxt.js Modules:** Leverage Nuxt.js modules to encapsulate functionalities and maintain a clean codebase.  Explore existing modules before implementing custom solutions (e.g., `@nuxt/auth` for server-side authentication).\n- **Convention over Configuration:** Adhere to Nuxt.js conventions to simplify development and collaboration.  Avoid deviating from conventions unless absolutely necessary.\n- **Efficiently Utilize Nuxt Layouts:** Create reusable layouts for components shared across multiple pages to ensure consistency and save development time. Layouts are located in the `layouts/` directory.\n- **Manage State with Pinia:** Use Pinia for state management. Organize store modules based on features or functionalities for better maintainability.\n- **Divide Pages into Components:** Break down pages into small, reusable components to enhance maintainability, testability, and reusability. Each component should have a single responsibility.\n- **Leverage Nuxt Plugins Wisely:** Use Nuxt plugins to run code before Vue.js initializes or add global functionality.  Be mindful of plugin performance impact. Plugins are located in the `plugins/` directory.\n- **Optimize for SEO and Performance:** Utilize Nuxt.js's server-side rendering (SSR) for SEO.  Implement lazy loading for images and optimize assets to minimize initial load time.  Use tools like Lighthouse to identify performance bottlenecks.\n- **Implement Error Handling and Validation:** Implement robust error handling and validation mechanisms to provide a seamless user experience. Use Nuxt.js middleware to intercept requests and responses for error handling and data validation.\n- **Document Your Code:** Provide clear and concise documentation for components, modules, and custom functions using tools like JSDoc.\n- **Embrace Testing:** Write unit tests, integration tests, and end-to-end tests using tools like Jest, Vue Test Utils and Vitest.\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n  - `components/`: Reusable Vue components.\n  - `composables/`: Reusable composable functions.\n  - `layouts/`: Application layouts.\n  - `middleware/`: Route middleware.\n  - `pages/`: Application pages (route definitions).\n  - `plugins/`: Nuxt.js plugins.\n  - `server/`: API routes and server-side logic.\n  - `static/`: Static assets (e.g., images, fonts).\n  - `store/`: Pinia stores (optional, but recommended).\n  - `utils/`: Utility functions.\n- **File Naming Conventions:**\n  - Components: `PascalCase.vue` (e.g., `MyComponent.vue`)\n  - Composables: `usePascalCase.js` or `usePascalCase.ts` (e.g., `useCounter.js`)\n  - Layouts: `kebab-case.vue` (e.g., `default.vue` or `custom-layout.vue`)\n  - Pages: `kebab-case.vue` (e.g., `index.vue`, `about.vue`, `product-details.vue`)\n  - Plugins: `kebab-case.js` or `kebab-case.ts` (e.g., `analytics.js`)\n  - Stores: `kebab-case.js` or `kebab-case.ts` (e.g., `user-store.js`)\n  - Utility functions: `camelCase.js` or `camelCase.ts` (e.g., `formatDate.js`)\n- **Module Organization:**\n  - Group related functionalities into separate modules.\n  - Use the `@nuxt/modules` array in `nuxt.config.js` or `nuxt.config.ts` to register modules.\n  - Create custom modules to encapsulate complex logic.\n- **Component Architecture:**\n  - Favor composition over inheritance.\n  - Use functional components for simple UI elements.\n  - Design components for reusability and testability.\n  - Consider using slots for flexible component composition.\n- **Code Splitting:**\n  - Utilize dynamic imports for route-based code splitting.\n  - Split large components into smaller chunks using `import()`.\n  - Analyze bundle size with tools like Webpack Bundle Analyzer.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n  - **Composition API:** Use the Composition API for organizing component logic.\n  - **Store Pattern (Pinia):** Implement a centralized state management system with Pinia.\n  - **Middleware Pattern:** Use middleware for authentication, authorization, and data validation.\n  - **Plugin Pattern:** Create plugins for global functionality and third-party library integrations.\n- **Recommended Approaches:**\n  - **API Communication:** Use the `useFetch` or `useAsyncData` composables for API calls within components.\n  - **Form Handling:** Utilize Vue's built-in form handling features with `v-model` and validation libraries like VeeValidate.\n  - **Authentication:** Implement a secure authentication flow using a library like `@nuxt/auth` or a custom solution.\n  - **Authorization:** Implement role-based access control (RBAC) using middleware and Pinia stores.\n- **Anti-patterns:**\n  - **Mutating props directly:** Avoid modifying parent component data directly from child components. Use `emit` instead.\n  - **Overusing global state:** Limit the use of global state to essential application data.  Consider component-level state for local data.\n  - **Ignoring error handling:** Always handle potential errors in API calls and other asynchronous operations.\n  - **Writing overly complex components:** Break down large components into smaller, more manageable pieces.\n- **State Management Best Practices:**\n  - **Single Source of Truth:** Maintain a single, consistent source of truth for application state in Pinia stores.\n  - **Immutability:** Treat state as immutable. Use functions to update the store rather than directly manipulating data.\n  - **Clear Naming Conventions:** Use descriptive names for store modules, actions, and mutations.\n  - **Modularization:** Divide stores into modules based on features or functionalities.\n- **Error Handling Patterns:**\n  - **Centralized Error Handling:** Implement a global error handler to catch unhandled exceptions.\n  - **Error Boundaries:** Use error boundaries to isolate component failures and prevent cascading errors.\n  - **User-Friendly Error Messages:** Provide clear and helpful error messages to users.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n  - **Lazy Loading:** Implement lazy loading for images, components, and routes.\n  - **Code Splitting:** Split the application into smaller chunks for faster initial load times.\n  - **Tree Shaking:** Remove unused code during the build process.\n  - **Caching:** Cache API responses and static assets to reduce server load.\n  - **Image Optimization:** Optimize images using tools like `nuxt/image`. Use appropriate image formats (WebP). Resize the image to appropriate size. Consider using a CDN for image delivery.\n- **Memory Management:**\n  - **Avoid Memory Leaks:** Clean up event listeners and timers when components are unmounted.\n  - **Use Weak References:** Use weak references for DOM elements when possible.\n  - **Minimize Object Creation:** Avoid creating unnecessary objects and arrays.\n- **Rendering Optimization:**\n  - **Virtualization:** Use virtualization for large lists to improve rendering performance.\n  - **Memoization:** Memoize expensive calculations to avoid redundant computations. Use `computed` properties effectively to avoid unnecessary re-renders.\n  - **Debouncing and Throttling:** Use debouncing and throttling for event handlers to reduce the number of function calls.\n- **Bundle Size Optimization:**\n  - **Analyze Bundle Size:** Use Webpack Bundle Analyzer to identify large dependencies.\n  - **Remove Unused Dependencies:** Remove unused dependencies to reduce bundle size.\n  - **Use Smaller Alternatives:** Consider using smaller alternatives to large libraries.\n  - **Optimize Dependencies:** Review dependencies and ensure you're using the most efficient ones.\n- **Lazy Loading Strategies:**\n  - **Route-based Lazy Loading:** Load components only when the corresponding route is accessed.\n  - **Component-based Lazy Loading:** Load components only when they are visible in the viewport.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n  - **Cross-Site Scripting (XSS):** Prevent XSS attacks by properly sanitizing user input and using Vue's built-in HTML escaping.\n  - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by implementing CSRF tokens.\n  - **SQL Injection:** Avoid raw SQL queries. Use an ORM (Object-Relational Mapper) to prevent SQL injection.\n  - **Authentication and Authorization Flaws:** Implement secure authentication and authorization mechanisms.\n  - **Insecure Direct Object References (IDOR):** Implement proper access control to prevent unauthorized access to resources.\n- **Input Validation:**\n  - **Server-Side Validation:** Always validate user input on the server-side.\n  - **Client-Side Validation:** Provide client-side validation for a better user experience (but don't rely on it as the sole source of validation).\n  - **Sanitize Input:** Sanitize user input to remove potentially harmful characters.\n- **Authentication and Authorization Patterns:**\n  - **JWT (JSON Web Tokens):** Use JWT for authentication and authorization.\n  - **OAuth 2.0:** Implement OAuth 2.0 for third-party authentication.\n  - **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n- **Data Protection Strategies:**\n  - **Encryption:** Encrypt sensitive data at rest and in transit.\n  - **Hashing:** Hash passwords and other sensitive data using strong hashing algorithms.\n  - **Data Masking:** Mask sensitive data in logs and other non-production environments.\n- **Secure API Communication:**\n  - **HTTPS:** Always use HTTPS for API communication.\n  - **API Rate Limiting:** Implement API rate limiting to prevent abuse.\n  - **Authentication and Authorization:** Require authentication and authorization for all API endpoints.\n\n## 5. Testing Approaches:\n\n- **Unit Testing:**\n  - **Test Individual Components:** Test individual components in isolation.\n  - **Mock Dependencies:** Mock external dependencies to isolate components during testing.\n  - **Verify Component Behavior:** Verify that components render correctly and behave as expected.\n- **Integration Testing:**\n  - **Test Component Interactions:** Test the interactions between components.\n  - **Test Data Flow:** Test the data flow between components and stores.\n  - **Test API Integrations:** Test the integration with external APIs.\n- **End-to-End Testing:**\n  - **Simulate User Interactions:** Simulate user interactions to test the application's functionality.\n  - **Test the Entire Application Flow:** Test the entire application flow from start to finish.\n  - **Use a Browser Automation Tool:** Use a browser automation tool like Cypress or Playwright.\n- **Test Organization:**\n  - **Organize Tests by Feature:** Organize tests by feature or functionality.\n  - **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what each test is testing.\n  - **Keep Tests Isolated:** Keep tests isolated from each other to avoid interference.\n- **Mocking and Stubbing:**\n  - **Use Mock Objects:** Use mock objects to replace external dependencies during testing.\n  - **Use Stubs:** Use stubs to replace complex functions with simplified versions.\n  - **Avoid Over-Mocking:** Avoid mocking too much code, as this can make tests less effective.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n  - **Incorrect `this` Context:** Be mindful of the `this` context in Vue components and use arrow functions or `bind` to maintain the correct context.\n  - **Asynchronous Data Handling:** Properly handle asynchronous data loading with `async/await` or Promises.\n  - **Forgetting to Unsubscribe:** Unsubscribe from event listeners and timers when components are unmounted to prevent memory leaks.\n  - **Overusing `forceUpdate`:** Avoid using `forceUpdate` unless absolutely necessary, as it can negatively impact performance.\n- **Edge Cases:**\n  - **Server-Side Rendering (SSR):** Be aware of the differences between client-side and server-side rendering.\n  - **Browser Compatibility:** Test the application in different browsers to ensure compatibility.\n  - **Accessibility:** Consider accessibility when designing and developing the application.\n- **Version-Specific Issues:**\n  - **Nuxt 2 vs Nuxt 3:** Be aware of the differences between Nuxt 2 and Nuxt 3.\n  - **Vue 2 vs Vue 3:** Be aware of the differences between Vue 2 and Vue 3.\n  - **Dependency Updates:** Carefully review dependency updates for potential breaking changes.\n- **Compatibility Concerns:**\n  - **Browser Support:** Ensure compatibility with the target browsers.\n  - **Device Compatibility:** Test the application on different devices.\n  - **Operating System Compatibility:** Ensure compatibility with the target operating systems.\n- **Debugging Strategies:**\n  - **Use Browser Developer Tools:** Use browser developer tools to inspect the application's state and network activity.\n  - **Use Vue Devtools:** Use Vue Devtools to inspect Vue components and data.\n  - **Use Logging:** Use logging to track the application's behavior.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n  - **VS Code:** Visual Studio Code is a popular code editor with excellent Vue.js support.\n  - **Vue Devtools:** Vue Devtools is a browser extension that provides debugging tools for Vue.js applications.\n  - **ESLint:** ESLint is a linter that enforces coding standards.\n  - **Prettier:** Prettier is a code formatter that automatically formats code.\n- **Build Configuration:**\n  - **`nuxt.config.js` or `nuxt.config.ts`:** Configure the application's build settings in `nuxt.config.js` or `nuxt.config.ts`.\n  - **Webpack:** Nuxt uses Webpack to bundle the application.\n  - **Vite:** Nuxt 3 uses Vite to bundle the application by default, providing faster build and development times.\n- **Linting and Formatting:**\n  - **ESLint:** Use ESLint to enforce coding standards.\n  - **Prettier:** Use Prettier to automatically format code.\n  - **Husky:** Use Husky to run linters and formatters before commits.\n- **Deployment Best Practices:**\n  - **Server-Side Rendering (SSR):** Deploy the application to a server that supports SSR.\n  - **Static Site Generation (SSG):** Generate a static site for content-heavy applications.\n  - **CDN:** Use a CDN to deliver static assets.\n- **CI/CD Integration:**\n  - **Continuous Integration (CI):** Use a CI tool like Jenkins, GitLab CI, or GitHub Actions to automate the build and testing process.\n  - **Continuous Deployment (CD):** Use a CD tool to automate the deployment process.\n\nBy following these best practices, you can build robust, maintainable, and scalable Nuxt.js applications.",
    "metadata": {
      "globs": "*.vue,*.js,*.ts,*.mjs,*.mts,*.jsx,*.tsx,*.config.js,*.config.ts",
      "format": "mdc",
      "originalFile": "nuxt.mdc"
    },
    "subcategory": "vue-ecosystem",
    "keywords": [
      "cursor",
      "nuxt",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "vue",
      "frontend",
      "ssr",
      "cursor-rule",
      "mdc",
      "ui",
      "javascript",
      "web",
      "fullstack",
      "frontend-frameworks",
      "vue-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "nuxt",
        "vue",
        "frontend",
        "ssr",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-openai",
    "description": "Comprehensive best practices and coding standards for projects using the openai library, covering code structure, performance, security, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "openai",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/openai.mdc",
    "content": "# openai Library Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing applications using the `openai` library. Following these guidelines will lead to more maintainable, performant, and secure code.\n\n## Library Information:\n- Name: openai\n- Tags: ai, ml, llm, api\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a clear and consistent directory structure to improve code organization and maintainability. Here's a recommended structure for projects using the openai library:\n\n\nproject_root/\n├── src/                        # Source code directory\n│   ├── models/              # Definitions for your models (e.g., data classes, schemas)\n│   ├── services/             # Service layer for interacting with the OpenAI API\n│   │   ├── openai_service.py   # Encapsulates OpenAI API calls\n│   ├── utils/                # Utility functions\n│   ├── main.py               # Entry point of your application\n├── tests/                      # Tests directory\n│   ├── unit/                 # Unit tests\n│   ├── integration/          # Integration tests\n│   ├── conftest.py           # Pytest configuration file\n├── data/                       # Data storage (e.g., prompts, training data)\n├── docs/                       # Documentation\n├── .env                        # Environment variables\n├── requirements.txt            # Dependencies\n├── README.md                   # Project README\n\n\n### 1.2 File Naming Conventions\n\n-   Use descriptive and consistent file names.\n-   Python files should use snake_case (e.g., `openai_service.py`).\n-   Class names should use CamelCase (e.g., `OpenAIService`).\n-   Variable names should use snake_case (e.g., `api_key`).\n\n### 1.3 Module Organization\n\n-   Group related functionalities into modules.\n-   Avoid circular dependencies between modules.\n-   Use clear and concise module names.\n-   Use `__init__.py` files to define packages and control namespace.\n\n### 1.4 Component Architecture\n\nConsider using a layered architecture to separate concerns:\n\n-   **Presentation Layer:** Handles user interface or external API interactions.\n-   **Service Layer:** Encapsulates business logic and interacts with the OpenAI API.\n-   **Data Access Layer:** Handles data persistence and retrieval.\n\nThis separation makes testing and maintenance easier.\n\n### 1.5 Code Splitting Strategies\n\n-   Split large files into smaller, more manageable modules based on functionality.\n-   Use abstract base classes and interfaces to define contracts between components.\n-   Apply the Single Responsibility Principle (SRP) to classes and functions.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n-   **Factory Pattern:** Use a factory to create OpenAI API client instances with different configurations.\n-   **Strategy Pattern:** Implement different prompt strategies based on the task.\n-   **Decorator Pattern:** Add logging, caching, or rate limiting to OpenAI API calls.\n\n### 2.2 Recommended Approaches\n\n-   **Prompt Engineering:** Follow best practices for prompt design. Place clear instructions at the beginning of prompts, be specific, and use examples.\n-   **Configuration:** Store API keys and other sensitive information in environment variables using a library like `python-dotenv`.\n-   **Asynchronous Calls:** Use `asyncio` and `aiohttp` for non-blocking API calls to improve performance.\n-   **Retries and Exponential Backoff:** Implement retry mechanisms with exponential backoff to handle transient API errors.\n\n### 2.3 Anti-patterns\n\n-   **Hardcoding API Keys:** Never hardcode API keys directly into your code. Always use environment variables.\n-   **Ignoring Rate Limits:** Implement rate limiting to avoid exceeding OpenAI API limits.\n-   **Lack of Error Handling:** Always handle API errors gracefully and provide informative error messages.\n-   **Overly Complex Prompts:** Keep prompts simple and focused. Break down complex tasks into smaller steps.\n-   **Mixing Concerns:** Avoid mixing presentation, business logic, and data access in the same component.\n\n### 2.4 State Management\n\n-   Use appropriate data structures to manage the state of your OpenAI interactions.\n-   Consider using a state management library if your application has complex state requirements.\n-   Avoid storing sensitive information in application state.\n\n### 2.5 Error Handling\n\n-   Use `try-except` blocks to catch potential exceptions.\n-   Log errors with sufficient context for debugging.\n-   Implement custom exception classes for specific error conditions.\n-   Handle rate limit errors and implement retry logic.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Caching:** Cache API responses to reduce the number of API calls.\n-   **Batching:** Batch multiple API requests into a single request when possible.\n-   **Asynchronous Operations:** Use asynchronous programming to avoid blocking the main thread.\n-   **Token Optimization:** Reduce the number of tokens in your prompts to lower costs and improve response times.\n\n### 3.2 Memory Management\n\n-   Be mindful of the size of your prompts and responses, especially when working with large language models.\n-   Use generators to process large datasets in chunks.\n-   Clean up resources (e.g., file handles, network connections) promptly.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n-   If your application involves rendering OpenAI-generated content, optimize the rendering process to minimize latency.\n\n### 3.4 Bundle Size Optimization (If Applicable)\n\n-   For web applications, minimize bundle size by using tree shaking and code splitting.\n\n### 3.5 Lazy Loading\n\n-   Use lazy loading to load modules or data only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n-   **API Key Exposure:** Protect your OpenAI API key. Never commit it to version control or share it publicly.\n-   **Prompt Injection:** Validate and sanitize user inputs to prevent prompt injection attacks.\n-   **Data Leakage:** Avoid exposing sensitive data in prompts or API responses.\n\n### 4.2 Input Validation\n\n-   Validate all user inputs to prevent malicious or unexpected data from being sent to the OpenAI API.\n-   Sanitize inputs to remove potentially harmful characters or code.\n\n### 4.3 Authentication and Authorization\n\n-   Implement authentication and authorization mechanisms to protect your application and data.\n-   Use secure storage for API keys and other sensitive information.\n\n### 4.4 Data Protection\n\n-   Encrypt sensitive data at rest and in transit.\n-   Follow data privacy regulations (e.g., GDPR, CCPA).\n\n### 4.5 Secure API Communication\n\n-   Use HTTPS to encrypt communication with the OpenAI API.\n-   Verify the authenticity of the OpenAI API server using SSL certificates.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n-   Write unit tests for individual components to ensure they function correctly in isolation.\n-   Use mocking and stubbing to isolate components from external dependencies (e.g., the OpenAI API).\n\n### 5.2 Integration Testing\n\n-   Write integration tests to verify that different components work together correctly.\n-   Test the interaction between your application and the OpenAI API.\n\n### 5.3 End-to-End Testing\n\n-   Write end-to-end tests to simulate user interactions and verify that the entire application works as expected.\n\n### 5.4 Test Organization\n\n-   Organize your tests into a clear and consistent directory structure.\n-   Use descriptive test names.\n-   Follow a consistent testing style.\n\n### 5.5 Mocking and Stubbing\n\n-   Use mocking libraries like `unittest.mock` or `pytest-mock` to mock the OpenAI API.\n-   Create stubs for API responses to control the behavior of the API during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n-   **Not handling API errors:** Implement proper error handling for OpenAI API calls.\n-   **Exceeding rate limits:** Implement rate limiting and exponential backoff to avoid exceeding API limits.\n-   **Incorrect prompt formatting:** Follow OpenAI's prompt engineering guidelines to optimize model performance.\n-   **Not validating inputs:** Validate user inputs to prevent prompt injection attacks and unexpected behavior.\n\n### 6.2 Edge Cases\n\n-   **Handling very long prompts:** Be aware of token limits and consider splitting long prompts into smaller chunks.\n-   **Dealing with ambiguous or unclear instructions:** Craft prompts carefully to provide clear and specific instructions.\n-   **Handling unexpected API responses:** Implement robust error handling to deal with unexpected API responses.\n\n### 6.3 Version-Specific Issues\n\n-   Be aware of changes between different versions of the `openai` library.\n-   Consult the release notes and migration guides when upgrading to a new version.\n\n### 6.4 Compatibility Concerns\n\n-   Ensure compatibility between the `openai` library and other libraries used in your project.\n-   Test your application thoroughly after upgrading any dependencies.\n\n### 6.5 Debugging Strategies\n\n-   Use logging to track the flow of your application and identify potential issues.\n-   Use a debugger to step through your code and inspect variables.\n-   Use unit tests to isolate and debug individual components.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **IDE:** VS Code, PyCharm\n-   **Virtual Environment Manager:** venv, conda, pipenv\n-   **Package Manager:** pip, poetry\n-   **Testing Framework:** pytest, unittest\n-   **Linting and Formatting:** pylint, flake8, black\n\n### 7.2 Build Configuration\n\n-   Use a `requirements.txt` or `pyproject.toml` file to manage dependencies.\n-   Use a build system like `setuptools` or `poetry` to package your application.\n\n### 7.3 Linting and Formatting\n\n-   Use a linter like `pylint` or `flake8` to enforce coding style guidelines.\n-   Use a formatter like `black` to automatically format your code.\n\n### 7.4 Deployment Best Practices\n\n-   Use a containerization technology like Docker to package your application and its dependencies.\n-   Deploy your application to a cloud platform like AWS, Azure, or Google Cloud.\n-   Use a process manager like `systemd` or `supervisor` to manage your application.\n\n### 7.5 CI/CD Integration\n\n-   Use a CI/CD pipeline to automate the build, test, and deployment process.\n-   Integrate your tests into the CI/CD pipeline to ensure that all changes are thoroughly tested before being deployed.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "openai.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "openai",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "using",
      "library",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "openai",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-opencv-python",
    "description": "This rule outlines best practices for developing with the opencv-python library, focusing on code organization, performance, security, testing, and common pitfalls. It provides comprehensive guidelines for efficient and maintainable opencv-python projects.",
    "author": "sanjeed5",
    "tags": [
      "opencv-python",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/opencv-python.mdc",
    "content": "- Always use UV or Pipenv when installing dependencies for consistent environments.\n- Always specify Python 3.10 or higher, as older versions may lack feature parity and security updates.\n- Use type hints extensively for improved code readability and maintainability.\n\n# Library Information:\n- Name: opencv-python\n- Tags: python, image-processing, computer-vision, opencv\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - \n    project_root/\n    ├── data/           # Store image, video, and other data files.\n    ├── src/            # Source code directory.\n    │   ├── modules/     # Reusable modules and utility functions.\n    │   │   ├── image_processing/  # Specific image processing functions.\n    │   │   │   ├── __init__.py\n    │   │   │   ├── filters.py  # Implement filters as functions or classes\n    │   │   │   ├── transforms.py # Implement image transforms as functions or classes\n    │   │   ├── utils.py       # Utility functions for data loading, etc.\n    │   ├── main.py        # Entry point of your application.\n    ├── tests/          # Test suite.\n    │   ├── unit/        # Unit tests for individual components.\n    │   ├── integration/   # Integration tests for combined components.\n    ├── models/          # Saved model files\n    ├── notebooks/      # Jupyter notebooks for experimentation.\n    ├── requirements.txt # Project dependencies.\n    ├── pyproject.toml   # Project metadata and build configuration.\n    └── README.md        # Project documentation.\n    \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent naming.\n    - `module_name.py` (e.g., `image_utils.py`, `feature_extraction.py`).\n    - Class names: `PascalCase` (e.g., `ImageProcessor`, `FeatureDetector`).\n    - Function names: `snake_case` (e.g., `load_image`, `apply_filter`).\n\n- **Module Organization:**\n    - Group related functions and classes into modules within the `src/modules/` directory.\n    - Use `__init__.py` files to make directories packages.\n    - Employ clear and concise module names.\n\n- **Component Architecture:**\n    - Follow a layered architecture:\n        - **Data Access Layer:** Handles image loading, saving, and data source interactions.\n        - **Processing Layer:** Implements image processing algorithms and feature extraction.\n        - **Application Layer:** Orchestrates the processing and presents the results.\n\n- **Code Splitting:**\n    - Decompose complex functions into smaller, well-defined units.\n    - Create separate modules for distinct functionalities (e.g., filtering, feature detection, object tracking).\n    - Utilize classes to encapsulate related state and behavior.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Strategy Pattern:** To swap image processing algorithms at runtime.\n    - **Factory Pattern:** To create different image processing objects based on configuration.\n    - **Observer Pattern:** To notify subscribers of image processing events.\n\n- **Recommended Approaches:**\n    - **Image Loading:** Use `cv2.imread()` for loading images.  Handle potential file errors gracefully.\n    - **Image Display:** Use `cv2.imshow()` for displaying images, and remember to call `cv2.waitKey()` to prevent freezing.\n    - **Video Processing:** Use `cv2.VideoCapture()` to capture video from a file or camera.\n    - **Iterating Pixels:** Access pixel values directly using NumPy array indexing for performance.  Avoid slow Python loops when possible.\n\n- **Anti-patterns and Code Smells:**\n    - **Deeply Nested Loops:** Indicate inefficient pixel-level operations. Consider vectorization using NumPy.\n    - **Global Variables:** Lead to unpredictable state. Encapsulate state within classes.\n    - **Hardcoded Paths:** Make code inflexible. Use relative paths and configurable settings.\n    - **Ignoring Errors:** Can lead to unexpected crashes. Implement robust error handling.\n\n- **State Management:**\n    - Encapsulate state within classes.\n    - Minimize mutable state; favor immutable data structures where appropriate.\n    - Use dependency injection to manage external dependencies.\n\n- **Error Handling:**\n    - Use `try...except` blocks to handle potential exceptions (e.g., file not found, invalid image format).\n    - Log errors for debugging and monitoring.\n    - Raise exceptions to propagate errors up the call stack.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Vectorization:** Use NumPy's vectorized operations instead of loops for faster processing.\n    - **Pre-allocation:** Pre-allocate NumPy arrays instead of repeatedly resizing them.\n    - **Caching:** Cache frequently accessed data (e.g., lookup tables) to avoid recalculation.\n    - **Multiprocessing/Multithreading:** Use `multiprocessing` or `threading` to parallelize independent image processing tasks.\n    - **Cython:** Implement performance-critical sections in Cython for C-like speeds.\n    - **GPU Acceleration:** Leverage OpenCV's CUDA module for GPU-accelerated processing (if applicable).\n\n- **Memory Management:**\n    - Release unused memory by explicitly deleting large arrays or objects.\n    - Be mindful of memory copies. Use `view()` or `ascontiguousarray()` to avoid unnecessary copies.\n    - Use generators to process large images in chunks.\n\n- **Rendering Optimization:**\n    - Minimize the number of draw calls.\n    - Use efficient drawing functions (e.g., `cv2.polylines()` instead of individual `cv2.line()` calls).\n\n- **Bundle Size Optimization:**\n    - Not directly applicable to opencv-python. For applications that use opencv-python, dependencies should be managed effectively. \n\n- **Lazy Loading:**\n    - Load images only when needed.\n    - Use lazy initialization for computationally expensive objects.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Denial of Service (DoS):** Prevent processing extremely large or malformed images that can consume excessive resources.\n    - **Code Injection:** Avoid executing arbitrary code based on user input (e.g., constructing file paths dynamically without proper sanitization).\n    - **Buffer Overflows:** Check image dimensions and data types to prevent buffer overflows when accessing pixel data directly.\n\n- **Input Validation:**\n    - Validate image file extensions and formats.\n    - Check image dimensions and data types.\n    - Sanitize filenames to prevent path traversal attacks.\n\n- **Authentication and Authorization:**\n    - Not typically applicable to core opencv-python functionality. These are relevant for applications leveraging opencv-python for tasks like facial recognition or video surveillance, requiring access control mechanisms.\n\n- **Data Protection:**\n    - Encrypt sensitive image data at rest and in transit (if applicable).\n    - Implement access control mechanisms to restrict access to sensitive image data.\n    - Anonymize or redact personally identifiable information (PII) from images.\n\n- **Secure API Communication:**\n    - Enforce HTTPS for all API communication.\n    - Use secure authentication mechanisms (e.g., API keys, OAuth).\n    - Validate all API requests and responses.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - Test individual functions and classes in isolation.\n    - Use mocking to isolate components from external dependencies (e.g., file system, camera).\n    - Test edge cases and boundary conditions.\n    - Use libraries like `pytest` and `unittest`.\n\n- **Integration Testing:**\n    - Test the interaction between different components.\n    - Verify that data flows correctly between modules.\n    - Use realistic test data.\n\n- **End-to-End Testing:**\n    - Test the entire application workflow.\n    - Simulate user interactions.\n    - Verify that the application meets the requirements.\n\n- **Test Organization:**\n    - Structure tests to mirror the source code organization.\n    - Use descriptive test names.\n    - Keep tests concise and focused.\n\n- **Mocking and Stubbing:**\n    - Use `unittest.mock` or `pytest-mock` to create mock objects for external dependencies.\n    - Stub out functions that perform I/O operations or interact with hardware.\n\n## 6. Common Pitfalls and Gotchas\n\n- **BGR vs. RGB:** Be aware that OpenCV uses BGR color format by default, while other libraries (e.g., Matplotlib, PIL) use RGB. Convert between formats using `cv2.cvtColor()`.\n- **Image Data Types:** Understand the different image data types (e.g., `uint8`, `float32`) and their implications for processing.\n- **Memory Layout:** Be aware of the memory layout of NumPy arrays and use `ascontiguousarray()` when necessary.\n- **`cv2.waitKey()`:** Remember to call `cv2.waitKey()` after `cv2.imshow()` to display the image and allow the window to respond to events. A value of 0 will wait indefinitely for a key press.\n- **Incorrect File Paths:** Double-check file paths when loading images or videos.\n- **Version Compatibility:** Be aware of compatibility issues between different versions of opencv-python.\n- **Global Interpreter Lock (GIL):** Understand the implications of the GIL for multithreading in Python. Use multiprocessing for CPU-bound tasks.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **IDE:** VS Code, PyCharm, Jupyter Notebook.\n    - **Virtual Environment:** `venv`, `conda`.\n    - **Package Manager:** `pip`, `uv`.\n\n- **Build Configuration:**\n    - Use `pyproject.toml` for project metadata and build configuration.\n    - Specify dependencies in `requirements.txt` or `pyproject.toml`.\n    - Use a build system like `setuptools` or `poetry`.\n\n- **Linting and Formatting:**\n    - Use `flake8` for linting.\n    - Use `black` for formatting.\n    - Configure your IDE to automatically format code on save.\n\n- **Deployment:**\n    - Containerize your application using Docker.\n    - Use a deployment platform like AWS, Azure, or Google Cloud.\n\n- **CI/CD:**\n    - Integrate with a CI/CD system like Jenkins, GitLab CI, or GitHub Actions.\n    - Automate testing, linting, and deployment.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "opencv-python.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "opencv",
      "python",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "developing",
      "with",
      "library",
      "opencv-python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "opencv-python",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pandas",
    "description": "This rule outlines best practices for using the pandas library in Python, covering code style, performance, data handling, and testing. It aims to promote maintainable, efficient, and robust data analysis workflows.",
    "author": "sanjeed5",
    "tags": [
      "pandas",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pandas.mdc",
    "content": "# Pandas Best Practices\n\nThis document provides guidelines for writing high-quality pandas code, covering various aspects from code style to performance optimization.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - Organize your project with a clear directory structure.\n    - Use separate directories for data, scripts, modules, tests, and documentation.\n    - Example:\n        \n        project_root/\n        ├── data/\n        │   ├── raw/\n        │   └── processed/\n        ├── src/\n        │   ├── modules/\n        │   │   ├── data_cleaning.py\n        │   │   ├── feature_engineering.py\n        │   │   └── ...\n        │   ├── main.py\n        ├── tests/\n        │   ├── unit/\n        │   ├── integration/\n        │   └── ...\n        ├── docs/\n        ├── notebooks/\n        ├── requirements.txt\n        └── ...\n        \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - Use snake_case for Python files and variables.\n    - Example: `data_processing.py`, `load_data.py`\n\n- **Module Organization:**\n    - Break down your code into reusable modules.\n    - Each module should focus on a specific task or functionality.\n    - Use clear and concise function and class names within modules.\n    - Follow the Single Responsibility Principle (SRP).\n\n- **Component Architecture:**\n    - Design your pandas-based applications with a clear component architecture.\n    - Separate data loading, preprocessing, analysis, and visualization into distinct components.\n    - Use classes to encapsulate related functionality and data.\n\n- **Code Splitting Strategies:**\n    - Split large pandas operations into smaller, more manageable steps.\n    - Use functions or methods to encapsulate these steps.\n    - This improves readability and makes debugging easier.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns Specific to Pandas:**\n    - **Chain of Responsibility:** Use method chaining to perform a sequence of operations on a DataFrame.\n    - **Strategy Pattern:** Implement different data processing strategies based on input parameters.\n    - **Factory Pattern:** Use factory functions to create DataFrames or Series from various sources.\n\n- **Recommended Approaches for Common Tasks:**\n    - **Data Loading:** Use `pd.read_csv()`, `pd.read_excel()`, `pd.read_sql()` to load data from different sources.\n    - **Data Cleaning:** Use `dropna()`, `fillna()`, `replace()` to clean missing or incorrect data.\n    - **Data Transformation:** Use `apply()`, `map()`, `groupby()`, `pivot_table()` to transform data.\n    - **Data Aggregation:** Use `groupby()`, `agg()`, `transform()` to aggregate data.\n    - **Data Visualization:** Use `matplotlib`, `seaborn`, or `plotly` to visualize data.\n\n- **Anti-patterns and Code Smells to Avoid:**\n    - **Iterating over DataFrames with `iterrows()` or `itertuples()`:** These are slow; prefer vectorized operations.\n    - **Chained Indexing:** Avoid using chained indexing (e.g., `df['A']['B']`) as it can lead to unexpected behavior. Use `.loc` or `.iloc` instead.\n    - **Ignoring Data Types:** Always be aware of your data types and convert them appropriately using `astype()`.\n    - **Writing loops to filter/process the data:** Vectorize these operations to avoid performance issues.\n    - **Modifying DataFrame inplace:** Creating copies is a safer approach.\n\n- **State Management Best Practices:**\n    - Avoid modifying DataFrames in place unless absolutely necessary.\n    - Make copies of DataFrames using `.copy()` to avoid unintended side effects.\n    - Use functional programming principles where possible to minimize state changes.\n\n- **Error Handling Patterns:**\n    - Use `try-except` blocks to handle potential errors during data loading, processing, or analysis.\n    - Log errors and warnings using the `logging` module.\n    - Raise exceptions when necessary to signal errors to the calling code.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Vectorization:** Use vectorized operations instead of loops whenever possible. Pandas is optimized for vectorized operations.\n    - **Cython:** Consider using Cython to optimize performance-critical parts of your code.\n    - **Numba:** Use Numba to JIT-compile NumPy and pandas code for improved performance.\n    - **Dask:** Use Dask for parallel processing of large datasets that don't fit in memory.\n    - **Parquet or Feather:** Use Parquet or Feather file formats for efficient data storage and retrieval.\n    - **Categorical Data:** Use categorical data types for columns with a limited number of unique values.\n\n- **Memory Management:**\n    - **Data Types:** Choose appropriate data types to minimize memory usage (e.g., `int8`, `float32` instead of `int64`, `float64`).\n    - **Chunking:** Load large datasets in chunks to avoid memory errors.\n    - **Garbage Collection:** Use `gc.collect()` to explicitly release memory.\n    - **Sparse Data:** Use sparse data structures for data with many missing values.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - **SQL Injection:** When reading data from SQL databases, use parameterized queries or ORM frameworks to prevent SQL injection attacks.\n    - **CSV Injection:** Be cautious when loading CSV files from untrusted sources, as they may contain malicious formulas that can execute arbitrary code.\n    - **Arbitrary Code Execution:** Avoid using `eval()` or `exec()` on data loaded from untrusted sources, as this can lead to arbitrary code execution.\n\n- **Input Validation:**\n    - Validate user inputs to prevent malicious data from entering your pandas workflows.\n    - Use regular expressions or custom validation functions to check the format and content of inputs.\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use access control mechanisms to restrict access to sensitive data.\n    - Anonymize or pseudonymize data when possible to protect privacy.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual functions and classes.\n    - Use `pytest` or `unittest` for writing and running tests.\n    - Test edge cases and boundary conditions.\n    - Use assert statements to verify the correctness of your code.\n\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between different modules or components.\n    - Test the end-to-end functionality of your pandas-based applications.\n\n- **Test Organization:**\n    - Organize your tests in a separate `tests` directory.\n    - Use a clear naming convention for your test files and functions.\n    - Example: `test_data_cleaning.py`, `test_load_data()`\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate units of code during testing.\n    - Use the `unittest.mock` module or third-party libraries like `pytest-mock`.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes Developers Make:**\n    - **Forgetting to set the index properly:** This can lead to performance issues when joining or merging DataFrames.\n    - **Incorrectly handling missing data:** Be aware of how missing data is represented in your DataFrames and handle it appropriately.\n    - **Not understanding the difference between `.loc` and `.iloc`:** These methods are used for different types of indexing and can lead to unexpected results if used incorrectly.\n\n- **Edge Cases to Be Aware Of:**\n    - **Empty DataFrames:** Handle the case where a DataFrame is empty.\n    - **DataFrames with duplicate indices:** Be aware of how pandas handles DataFrames with duplicate indices.\n\n- **Debugging Strategies:**\n    - Use the `print()` function or the `logging` module to debug your code.\n    - Use a debugger to step through your code and inspect variables.\n    - Use the `pdb` module for interactive debugging.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **Jupyter Notebook/Lab:** For interactive data exploration and analysis.\n    - **VS Code with Python extension:** For code editing, debugging, and testing.\n    - **PyCharm:** A full-featured IDE for Python development.\n\n- **Linting and Formatting:**\n    - Use `flake8` to lint your code and identify potential issues.\n    - Use `black` to automatically format your code according to PEP 8.\n    - Use `isort` to automatically sort your imports.\n    - Integrate these tools into your pre-commit hooks to ensure consistent code style.\n\n- **CI/CD Integration:**\n    - Use CI/CD pipelines to automate the testing and deployment of your pandas-based applications.\n    - Integrate your CI/CD pipelines with your version control system (e.g., GitHub, GitLab, Bitbucket).\n    - Use Docker to containerize your applications for consistent deployment.\n\nThis comprehensive guide covers the key aspects of pandas best practices and coding standards. By following these guidelines, you can write more maintainable, efficient, and robust pandas code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pandas.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pandas",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "using",
      "library",
      "python",
      "covering",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pandas",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pdoc",
    "description": "Comprehensive best practices for using pdoc to generate and maintain Python project documentation. Covers code structure, performance, security, testing, and tooling to ensure high-quality documentation and maintainable projects.",
    "author": "sanjeed5",
    "tags": [
      "pdoc",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pdoc.mdc",
    "content": "# pdoc Best Practices: A Comprehensive Guide\n\nThis document outlines best practices for using `pdoc` to generate API documentation for Python projects. It covers code organization, performance considerations, security, testing, and common pitfalls, all tailored for effective documentation generation and maintainability.\n\n## Library Information:\n\n- Name: pdoc\n- Tags: development, documentation, python, auto-generation\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n- **Clear Module Grouping:** Organize your code into logical modules and sub-packages.  This makes it easier for `pdoc` to generate a navigable API.\n- **`__init__.py` Files:** Ensure that each package directory contains an `__init__.py` file. This file can be empty, or it can contain initialization code and, importantly, the package-level docstring which `pdoc` will use.\n- **Separate Concerns:**  Isolate different functionalities into separate modules. For example, separate data models, business logic, and utility functions into distinct files.\n\nExample:\n\n\nmy_project/\n├── my_package/\n│   ├── __init__.py  # Package-level docstring here\n│   ├── module_a.py  # Contains functions and classes\n│   ├── module_b.py  # Contains more functions and classes\n│   └── subpackage/\n│       ├── __init__.py  # Subpackage-level docstring here\n│       └── module_c.py # Contains functions and classes\n└── setup.py       # Installation script\n\n\n### 1.2 File Naming Conventions\n\n- **Descriptive Names:** Use descriptive names for modules and packages. For example, `database_utils.py` is much better than `db.py`.\n- **Lowercase with Underscores:** Follow the standard Python convention of using lowercase letters with underscores for module names (e.g., `my_module.py`).\n\n### 1.3 Module Organization\n\n- **Top-Level Docstrings:** Every module should have a top-level docstring that describes its purpose and lists the main classes, functions, and exceptions it defines.\n- **`__all__` Variable:** Use the `__all__` variable to explicitly define the public API of a module. This tells `pdoc` (and other tools) which names should be included in the generated documentation.\n\nExample:\n\npython\n# my_module.py\n\"\"\"This module provides utility functions for data processing.\n\nClasses:\n    DataProcessor: Processes data.\n\nFunctions:\n    clean_data: Cleans the data.\n\"\"\"\n\n__all__ = ['DataProcessor', 'clean_data']\n\nclass DataProcessor:\n    \"\"\"Processes data from various sources.\"\"\"\n    ...\n\ndef clean_data(data):\n    \"\"\"Cleans the input data.\"\"\"\n    ...\n\n\n### 1.4 Component Architecture\n\n- **Loose Coupling:** Design your components to be loosely coupled. This means that components should have minimal dependencies on each other.\n- **Clear Interfaces:** Define clear interfaces for your components. This makes it easier to test and document your code.\n- **Abstraction:** Use abstraction to hide the implementation details of your components. This makes your code more flexible and easier to maintain.\n\n### 1.5 Code Splitting\n\n- **Divide and Conquer:** Split large modules into smaller, more manageable files. This makes your code easier to understand and maintain.\n- **By Functionality:** Split code based on functionality. For example, if you have a module that contains both database access code and business logic, split it into two separate modules.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Factory Pattern:** Use the factory pattern to create objects. This makes it easier to switch between different implementations of a class.\n- **Strategy Pattern:** Use the strategy pattern to encapsulate different algorithms. This makes it easier to switch between different algorithms at runtime.\n- **Decorator Pattern:** Use the decorator pattern to add functionality to objects dynamically.\n\n### 2.2 Recommended Approaches\n\n- **Use Docstrings:** All modules, classes, functions, and methods must include docstrings. Docstrings are used by `pdoc` to create the API documentation.\n- **Follow PEP 257:** Adhere to PEP 257 for docstring conventions. This ensures consistency and readability.\n- **Choose a Style:** Consistently use a docstring style (Google, NumPy, reStructuredText) throughout your project.\n- **Include Examples:** Provide simple, executable examples in your docstrings. This helps users understand how to use your code.  These examples can be embedded directly within docstrings using the `doctest` module.\n\n### 2.3 Anti-patterns\n\n- **Missing Docstrings:** Failing to document modules, classes, functions, or methods.\n- **Incomplete Docstrings:** Providing docstrings that are too brief or lack essential information.\n- **Inconsistent Style:** Mixing different docstring styles within the same project.\n- **Redundant Documentation:** Repeating information that is already clear from the code itself. Focus on the *why* rather than the *how*.\n- **Ignoring `__all__`:**  Not defining `__all__` or defining it incorrectly can lead to undocumented or wrongly documented API surfaces.\n\n### 2.4 State Management\n\n- **Minimize Global State:** Avoid using global variables as much as possible. If you must use global variables, document them clearly.\n- **Use Classes to Encapsulate State:** Use classes to encapsulate state. This makes it easier to manage and reason about your code.\n\n### 2.5 Error Handling\n\n- **Raise Exceptions:** Raise exceptions when errors occur. This makes it easier to handle errors gracefully.\n- **Use Try-Except Blocks:** Use try-except blocks to catch exceptions. This prevents your program from crashing when errors occur.\n- **Document Exceptions:** Document the exceptions that your functions and methods can raise.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Profiling:** Use a profiler to identify performance bottlenecks in your code.\n- **Caching:** Use caching to store frequently accessed data.  Consider using `functools.lru_cache` for memoization.\n- **Vectorization:** Use vectorized operations when working with numerical data. This is often faster than using loops.\n\n### 3.2 Memory Management\n\n- **Avoid Memory Leaks:** Be careful to avoid memory leaks. Free up memory when it is no longer needed.\n- **Use Generators:** Use generators to process large amounts of data. This can reduce memory usage.\n- **Use Data Structures Efficiently:** Use the right data structures for the job. For example, use sets for membership testing and dictionaries for lookups.\n\n### 3.3 Rendering Optimization\n\n- Not generally applicable to `pdoc` itself, as it mainly generates static HTML.  However, the design of your code *can* affect how quickly `pdoc` can process it. Well-structured, easily-introspected code will be processed faster.\n\n### 3.4 Bundle Size\n\n- Not applicable to `pdoc` itself, as it is a documentation generator and not a web application framework.\n\n### 3.5 Lazy Loading\n\n- Not directly applicable to `pdoc`, but consider lazy loading modules within your own code to improve startup time if you have a large project that `pdoc` needs to process. This is done using `importlib.import_module`.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n- **Not Directly Applicable:** `pdoc` generates static documentation and does not execute arbitrary user-supplied code.  Therefore, it is less vulnerable than many other types of applications. However, be mindful of the dependencies you use and keep them up to date.\n\n### 4.2 Input Validation\n\n- **Not Directly Applicable:** `pdoc` does not take direct user input.\n\n### 4.3 Authentication and Authorization\n\n- **Not Applicable:** `pdoc` is a documentation generation tool and does not require authentication or authorization.\n\n### 4.4 Data Protection\n\n- **Not Applicable:** `pdoc` does not handle sensitive data.\n\n### 4.5 Secure API Communication\n\n- **Not Applicable:** `pdoc` does not communicate with external APIs.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- **Test Docstrings:** Use `doctest` to test examples embedded in your docstrings. This ensures that your examples are up-to-date and correct. `pdoc` renders these examples, making them executable directly from the documentation.\n- **Focus on Public API:** Write unit tests for the public API of your modules, classes, and functions.\n\n### 5.2 Integration Testing\n\n- **Test Interactions:** Test the interactions between different components of your system.\n\n### 5.3 End-to-End Testing\n\n- **Test Complete Workflows:** Test complete workflows to ensure that your system is working correctly.\n\n### 5.4 Test Organization\n\n- **Separate Test Files:** Keep your tests in separate files from your code. This makes it easier to find and run your tests.\n- **Organize by Module:** Organize your tests by module. This makes it easier to find the tests for a specific module.\n\n### 5.5 Mocking and Stubbing\n\n- **Use Mock Objects:** Use mock objects to isolate the code that you are testing from its dependencies. This makes it easier to test your code in isolation.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Incorrect Docstring Formatting:** Using the wrong docstring format or inconsistent formatting.\n- **Omitting Parameters:** Failing to document all parameters of a function or method.\n- **Not Updating Documentation:** Failing to update the documentation when the code changes.\n- **Circular Imports:**  Circular imports can confuse `pdoc`. Refactor your code to avoid them.\n\n### 6.2 Edge Cases\n\n- **Dynamic Code Generation:** If your code heavily uses dynamic code generation (`eval`, `exec`), `pdoc` may have difficulty introspecting it.\n- **Metaclasses:** Complex metaclasses can also make it harder for `pdoc` to generate accurate documentation.\n\n### 6.3 Version-Specific Issues\n\n- **Check Compatibility:** Always check the compatibility of `pdoc` with your Python version.  Refer to the official `pdoc` documentation for version-specific information.\n\n### 6.4 Compatibility Concerns\n\n- **Third-Party Libraries:** Ensure that `pdoc` is compatible with any third-party libraries that you are using.\n\n### 6.5 Debugging Strategies\n\n- **Verbose Mode:** Run `pdoc` in verbose mode to see more detailed output. This can help you identify errors.\n- **Check for Errors:** Check the output of `pdoc` for any errors or warnings.\n- **Inspect Generated HTML:** Inspect the generated HTML to see if the documentation looks correct.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n- **IDE:** Use a good IDE (e.g., VS Code, PyCharm) with Python support.\n- **Linting:** Use a linter (e.g., pylint, flake8) to catch errors and enforce coding standards.\n- **Formatting:** Use a code formatter (e.g., black, autopep8) to format your code.\n\n### 7.2 Build Configuration\n\n- **`setup.py` or `pyproject.toml`:** Use a `setup.py` file or `pyproject.toml` to define your project's dependencies and metadata.\n- **Include Documentation Files:** Make sure to include documentation files in your build configuration.\n\n### 7.3 Linting and Formatting\n\n- **Consistent Style:** Enforce a consistent coding style using a linter and code formatter.\n- **Follow PEP 8:** Follow the PEP 8 style guide for Python code.\n- **Use Docstring Checks:** Configure your linter to check for missing or incomplete docstrings.\n\n### 7.4 Deployment Best Practices\n\n- **Generate Documentation Automatically:** Automate the generation of documentation as part of your build process.\n- **Host Documentation:** Host the generated documentation on a web server or documentation hosting service (e.g., Read the Docs).\n\n### 7.5 CI/CD Integration\n\n- **Integrate with CI/CD:** Integrate `pdoc` with your CI/CD pipeline to automatically generate and deploy documentation on every commit.\n\nBy following these best practices, you can ensure that your Python projects have high-quality, well-maintained documentation that is easy for users to understand and use.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pdoc.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pdoc",
      "comprehensive",
      "best",
      "practices",
      "using",
      "generate",
      "maintain",
      "python",
      "project",
      "documentation",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pdoc",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-peewee",
    "description": "Comprehensive guide for Peewee ORM best practices, covering code organization, performance, security, testing, and common pitfalls. Provides actionable guidance for developers to write maintainable and efficient database-driven applications using Peewee.",
    "author": "sanjeed5",
    "tags": [
      "peewee",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/peewee.mdc",
    "content": "# Peewee ORM Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for using Peewee ORM in Python development. Following these guidelines will lead to more maintainable, efficient, and secure database-driven applications.\n\n## Library Information:\n\n- Name: peewee\n- Tags: database, orm, python, sql\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n\nproject_root/\n├── models/\n│   ├── __init__.py\n│   ├── user.py\n│   ├── product.py\n│   └── ...\n├── migrations/\n│   ├── 0001_initial.py\n│   ├── 0002_add_index.py\n│   └── ...\n├── utils/\n│   ├── db.py  # Database connection and initialization\n│   └── ...\n├── tests/\n│   ├── __init__.py\n│   ├── test_user.py\n│   ├── test_product.py\n│   └── ...\n├── main.py  # Application entry point\n└── requirements.txt\n\n\n- **models/:** Contains model definitions, each in a separate file.\n- **migrations/:** Stores database migration scripts.\n- **utils/:** Utility functions, including database connection management.\n- **tests/:** Unit and integration tests.\n- **main.py:** The main application file.\n\n### 1.2. File Naming Conventions\n\n- Model files: Use lowercase, singular nouns (e.g., `user.py`, `product.py`).\n- Migration files: Use a sequential numbering scheme (e.g., `0001_initial.py`, `0002_add_index.py`).\n- Test files: Prefix with `test_` (e.g., `test_user.py`).\n- Utility files: Use descriptive names (e.g., `db.py`).\n\n### 1.3. Module Organization\n\n- Group related models into the same module.  For example, models related to user management would reside in `models/user.py`.\n- Use `__init__.py` files to make directories importable as packages and to provide a convenient way to import all models from the `models` directory.  Example:\n\npython\n# models/__init__.py\nfrom .user import User\nfrom .product import Product\n\n\n### 1.4. Component Architecture\n\n- Separate database interactions from business logic. Create service layers or repositories that handle Peewee queries and data manipulation, keeping models thin and focused on schema definition.\n- Favor composition over inheritance where appropriate, using mixins for reusable model functionality.\n\n### 1.5. Code Splitting\n\n- Use separate files for different model definitions to improve readability and maintainability.\n- Decompose complex queries into smaller, reusable functions.\n- Consider using submodules within `models/` for logical groupings of models when projects grow large.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Repository Pattern:** Create a layer between the application and the database to abstract data access logic.  This makes it easier to switch databases or change ORM implementations later.\n- **Unit of Work:** Manage database transactions within a single unit of work, ensuring consistency and atomicity. Peewee's `atomic()` context manager facilitates this pattern.\n- **Data Mapper:** Maps data between domain objects and the database. Peewee models inherently implement this pattern.\n\n### 2.2. Recommended Approaches\n\n- **Explicit Database Connection Management:** Always open and close database connections explicitly, especially in web applications or concurrent environments. Use `with db:` or `@db.connection_context()` to ensure connections are properly handled.  Disable `autoconnect` when initializing the database:\n\npython\ndb = SqliteDatabase('my_app.db', autoconnect=False)\n\n\n- **Base Model Class:** Define a base model class that all other models inherit from. This centralizes database configuration and ensures consistency:\n\npython\nfrom peewee import * \n\ndb = SqliteDatabase('my_app.db')\n\nclass BaseModel(Model):\n    class Meta:\n        database = db\n\n\n- **Relationships and Joins:** Utilize Peewee's built-in support for relationships and joins to simplify complex queries:\n\npython\nclass User(BaseModel):\n    username = CharField()\n\nclass Tweet(BaseModel):\n    user = ForeignKeyField(User, backref='tweets')\n    content = TextField()\n\nquery = Tweet.select().join(User).where(User.username == 'john_doe')\n\n\n- **Migrations:** Use a migration library (like `peewee-migrate`) to manage schema changes effectively.  This ensures that database schemas can evolve smoothly over time.\n\n### 2.3. Anti-patterns and Code Smells\n\n- **Implicit Database Connections:** Relying on Peewee's `autoconnect` feature can lead to unpredictable behavior and connection leaks. Manage connections explicitly.\n- **Global Database Instance:** Avoid creating a single global database instance without proper connection management, especially in multi-threaded applications. Use connection pools or context managers to manage connections per request or thread.\n- **String Interpolation:** Never use string interpolation to construct SQL queries, as this can lead to SQL injection vulnerabilities. Always use parameterized queries.\n\npython\n# Anti-pattern (SQL injection vulnerability!)\nusername = input(\"Enter username:\")\nquery = User.select().where(SQL(\"username = '%s'\" % username))\n\n# Correct approach (parameterized query)\nquery = User.select().where(User.username == username)\n\n\n- **Over-fetching Data:** Avoid selecting all columns when only a subset is needed. Specify the required fields in the `select()` method.\n\n### 2.4. State Management\n\n- In web applications, manage database connections on a per-request basis. Open a connection at the beginning of the request and close it at the end. Framework integration examples are provided in the base documentation.\n- In asynchronous applications, utilize connection pools and context managers to manage connections concurrently.\n\n### 2.5. Error Handling\n\n- Use try-except blocks to handle database errors, such as `IntegrityError` (for unique constraint violations) and `DoesNotExist` (when a record is not found).\n- Implement logging to track database errors and diagnose issues.\n- Provide informative error messages to the user, without exposing sensitive database details.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Indexing:** Add indexes to frequently queried columns to improve query performance.  Use Peewee's indexing features when defining your models or use migrations to create them:\n\npython\nclass User(BaseModel):\n    username = CharField(index=True) # Simple index\n\n    class Meta:\n        indexes = (\n            (('email', 'is_active'), True),  # Composite index (unique=True)\n        )\n\n\n- **Caching:** Implement caching for frequently accessed data to reduce database load. Consider using a caching library like Redis or Memcached.\n- **Connection Pooling:** Use connection pooling to reduce the overhead of establishing new database connections for each request.  Peewee's `playhouse.pool` module provides pooled database classes:\n\npython\nfrom playhouse.pool import PooledSqliteDatabase\n\ndb = PooledSqliteDatabase('my_app.db', max_connections=16)\n\n\n- **Batch Inserts/Updates:** Use `insert_many()` and `update()` methods for bulk operations instead of iterating and executing individual queries.\n\npython\ndata = [\n    {'username': 'user1', 'email': 'user1@example.com'},\n    {'username': 'user2', 'email': 'user2@example.com'},\n]\n\nwith db.atomic(): # Transaction for atomicity\n    User.insert_many(data).execute()\n\n\n- **Query Optimization:**  Use `.prefetch()` to reduce N+1 query problems. Use `.defer()` to avoid fetching unnecessary columns. Profile your queries and analyze execution plans to identify bottlenecks.\n\n### 3.2. Memory Management\n\n- Limit the number of records returned by queries to avoid loading large amounts of data into memory. Use pagination or filtering to retrieve data in smaller chunks.\n- Close database connections promptly after use to release resources.\n- Be mindful of large data types (e.g., BLOBs) and handle them efficiently to avoid memory exhaustion.\n\n### 3.3. Bundle Size Optimization\n\n- Peewee is a lightweight library, so its direct impact on bundle size is minimal. However, be mindful of dependencies introduced by database drivers or extensions.\n- Use a minifier to reduce the size of your Python code before deployment.\n\n### 3.4. Lazy Loading\n\n-  Use `ForeignKeyField` with caution, understanding that accessing the related object will trigger a new database query if the related object is not prefetched. Utilize `.prefetch()` for efficient loading of related data.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n- **SQL Injection:**  Prevent SQL injection by using parameterized queries and avoiding string concatenation when constructing SQL statements.\n- **Cross-Site Scripting (XSS):**  If displaying data retrieved from the database in a web application, sanitize the data to prevent XSS attacks. (This is primarily a front-end concern, but relevant when handling user-generated content stored in the database).\n- **Sensitive Data Exposure:**  Avoid storing sensitive data (e.g., passwords, API keys) in plain text. Use proper encryption or hashing techniques. Peewee itself does not provide encryption; use appropriate Python libraries for this (like `bcrypt` for passwords).\n\n### 4.2. Input Validation\n\n- Validate all user inputs before using them in database queries or model fields. This prevents malicious data from being stored in the database or used to exploit vulnerabilities.\n- Use Peewee's field validation capabilities to enforce data types, lengths, and other constraints at the model level:\n\npython\nclass User(BaseModel):\n    username = CharField(max_length=50)\n    email = CharField(unique=True)\n    age = IntegerField(null=True, constraints=[Check('age > 0')]) #CHECK constraint\n\n\n\n### 4.3. Authentication and Authorization\n\n- Implement robust authentication and authorization mechanisms to protect sensitive data and restrict access to authorized users only. Peewee can integrate with authentication frameworks like Flask-Login or Django's authentication system.\n- Do not rely solely on client-side validation for security. Always perform server-side validation.\n\n### 4.4. Data Protection\n\n- Implement data encryption at rest and in transit to protect sensitive data from unauthorized access.  Consider using database-level encryption or encrypting sensitive fields at the application level.\n- Use HTTPS to secure communication between the client and the server.\n- Comply with relevant data privacy regulations (e.g., GDPR, CCPA).\n\n### 4.5. Secure API Communication\n\n- Use API keys or tokens to authenticate API requests.\n- Implement rate limiting to prevent abuse and denial-of-service attacks.\n- Validate API request data and sanitize API responses to prevent vulnerabilities.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- Unit test model methods, query logic, and other database-related functionality in isolation. Use mocking and stubbing to isolate units of code from external dependencies (e.g., the database itself).\n- Utilize an in-memory SQLite database for unit tests to avoid modifying the production database. Bind the models to the in-memory database during testing.\n\npython\nimport unittest\nfrom peewee import *\n\ndb = SqliteDatabase(':memory:')\n\nclass BaseModel(Model):\n    class Meta:\n        database = db\n\nclass User(BaseModel):\n    username = CharField()\n\nclass TestUser(unittest.TestCase):\n    def setUp(self):\n        db.bind([User])\n        db.create_tables([User])\n\n    def tearDown(self):\n        db.drop_tables([User])\n        db.close()\n\n    def test_user_creation(self):\n        user = User.create(username='test_user')\n        self.assertEqual(user.username, 'test_user')\n\nif __name__ == '__main__':\n    unittest.main()\n\n\n### 5.2. Integration Testing\n\n- Integration test the interaction between different components of the application, including database interactions.\n- Use a separate test database (e.g., a dedicated SQLite file or a testing instance of your production database) for integration tests.\n- Ensure that the test database is properly initialized and cleaned up before and after each test.\n\n### 5.3. End-to-End Testing\n\n- End-to-end tests verify the entire application workflow, including database interactions, from the user's perspective.\n- Use tools like Selenium or Cypress to automate end-to-end tests.\n- Ensure that the end-to-end tests cover critical business scenarios and data flows.\n\n### 5.4. Test Organization\n\n- Organize tests into separate modules or directories based on the component or functionality being tested.\n- Use descriptive test names to clearly indicate the purpose of each test.\n- Follow the Arrange-Act-Assert pattern to structure tests.\n\n### 5.5. Mocking and Stubbing\n\n- Use mocking and stubbing to isolate units of code during unit testing and to simulate database behavior.\n- Use libraries like `unittest.mock` or `pytest-mock` for mocking and stubbing.\n- Mock database connections, queries, and model methods as needed.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Forgetting to Handle Exceptions:** Neglecting to handle database exceptions can lead to application crashes or data corruption.\n- **Incorrect Data Types:** Using incorrect data types for model fields can result in data truncation or validation errors.\n- **Not Closing Connections:** Failing to close database connections can lead to connection leaks and performance issues.\n- **N+1 Query Problem:** Inefficiently fetching related data can result in the N+1 query problem, where a query is executed for each related record. Use `prefetch()` to mitigate this.\n\n### 6.2. Edge Cases\n\n- **Concurrency Issues:**  Be aware of concurrency issues when multiple threads or processes access the database simultaneously. Use transactions and locking mechanisms to ensure data consistency.\n- **Large Datasets:**  Handle large datasets efficiently by using pagination, streaming, or batch processing techniques.\n- **Database-Specific Features:**  Be aware of database-specific features and syntax differences when writing queries. Use Peewee's database-specific extensions when necessary.\n\n### 6.3. Version-Specific Issues\n\n- Consult the Peewee documentation and release notes for version-specific issues and compatibility concerns.\n- Test your application thoroughly after upgrading Peewee or your database driver.\n\n### 6.4. Compatibility Concerns\n\n- Ensure that the Peewee version is compatible with the Python version and the database driver being used.\n- Be aware of potential compatibility issues when integrating Peewee with other libraries or frameworks.\n\n### 6.5. Debugging Strategies\n\n- Enable logging to track database queries and errors.\n- Use a database profiler to analyze query performance.\n- Use a debugger to step through code and inspect variables.\n- Simplify complex queries to isolate the source of the problem.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **Integrated Development Environment (IDE):** VS Code, PyCharm, or other IDEs with Python support.\n- **Database Client:** DB Browser for SQLite, pgAdmin, MySQL Workbench, or other database clients for interacting with the database.\n- **Migration Tool:** Alembic or `peewee-migrate` for managing database schema changes.\n\n### 7.2. Build Configuration\n\n- Use `requirements.txt` or `pyproject.toml` to manage project dependencies.\n- Specify the Peewee version and database driver versions in the dependencies file.\n- Use a virtual environment to isolate project dependencies from the system environment.\n\n### 7.3. Linting and Formatting\n\n- Use a linter like Flake8 or Pylint to enforce code style and identify potential errors.\n- Use a code formatter like Black to automatically format your code according to a consistent style.\n- Configure the linter and formatter to adhere to the Peewee coding standards.\n\n### 7.4. Deployment\n\n- Use a deployment tool like Docker or Kubernetes to containerize and deploy your application.\n- Configure the application to connect to the production database using environment variables or configuration files.\n- Ensure that the database schema is up-to-date before deploying the application. Run database migrations as part of the deployment process.\n- Monitor the application and database for performance and security issues.\n\n### 7.5. CI/CD Integration\n\n- Integrate Peewee tests into your CI/CD pipeline to automatically run tests whenever code is committed or deployed.\n- Use a CI/CD tool like Jenkins, GitLab CI, or GitHub Actions to automate the build, test, and deployment process.\n- Configure the CI/CD pipeline to run database migrations and seed the database with test data.\n\nThis guide provides a comprehensive overview of Peewee ORM best practices. By following these guidelines, you can create robust, efficient, and maintainable database-driven applications.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "peewee.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "peewee",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "peewee",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-phoenix",
    "description": "This rule outlines the best practices and coding standards for developing Elixir applications with the Phoenix framework, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "phoenix",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/phoenix.mdc",
    "content": "- # Phoenix Framework Best Practices\n\n  This document outlines general best practices for developing Elixir applications with the Phoenix Framework. It aims to promote maintainable, scalable, and performant codebases.\n\n- ## 1. Code Organization and Structure\n\n  - ### 1.1. Directory Structure Best Practices\n\n    - **`lib/`**: Contains the core application logic, including contexts, schemas, and supporting modules.\n    - **`lib/<app_name>_web/`**: Holds the web-related components, such as controllers, views, templates, channels, and live views.\n    - **`lib/<app_name>/`**: Contains your application’s core domain logic. Favor placing most of your code here.\n    - **`test/`**: Contains all test-related files, including unit, integration, and acceptance tests.\n    - **`priv/repo/migrations/`**: Stores database migration files.\n    - **`config/`**: Contains configuration files for different environments (dev, test, prod).\n    - **`assets/`**: Contains static assets like JavaScript, CSS, and images. Managed by tools like esbuild or Webpack.\n    - **`deps/`**: Automatically generated folder containing project dependencies.\n    - **`rel/`**: Used for building releases with distillery or mix release. Contains configuration for releases.\n\n  - ### 1.2. File Naming Conventions\n\n    - Use `snake_case` for file names (e.g., `user_controller.ex`, `user_schema.ex`).\n    - Match the file name to the module name (e.g., `UserController` module should be in `user_controller.ex`).\n    - For LiveView components, use `_live` suffix (e.g., `user_live.ex`).\n    - For schema files, use `_schema` suffix(e.g. `user_schema.ex`).\n\n  - ### 1.3. Module Organization\n\n    - Organize modules into contexts, representing logical domains within the application (e.g., `Accounts`, `Blog`, `Payments`).\n    - Keep modules small and focused, adhering to the Single Responsibility Principle (SRP).\n    - Use namespaces to group related modules (e.g., `MyApp.Accounts.User`, `MyApp.Blog.Post`).\n    - Favor explicit dependencies between modules to promote clarity and reduce coupling.\n\n  - ### 1.4. Component Architecture (LiveView)\n\n    - Break down complex LiveView pages into smaller, reusable components.\n    - Use functional components (HEEx templates with function definitions) for simple UI elements.\n    - Use LiveComponent modules for more complex, stateful components with event handling.\n    - Organize components into directories based on their purpose or domain.\n    - Define attributes and slots for LiveView components to ensure type safety.\n    - Utilize PubSub for communication between LiveView components.\n\n  - ### 1.5. Code Splitting Strategies\n\n    - Separate concerns by using contexts. Controllers delegate to contexts, which handle the business logic, and contexts rely on schemas, which handle the data validations and structure.\n    - Utilize umbrella projects to divide a large application into smaller, independent applications.\n    - Consider code splitting at the LiveView level, using separate LiveView modules for different sections of a page.\n    - Use dynamic imports for JavaScript modules to load code on demand.\n\n- ## 2. Common Patterns and Anti-patterns\n\n  - ### 2.1. Design Patterns\n\n    - **MVC (Model-View-Controller)**: The core architectural pattern in Phoenix. Ensure proper separation of concerns between models (schemas), views (templates), and controllers.\n    - **Context Pattern**: Encapsulate business logic and data access within contexts to provide a clear API for controllers and other parts of the application.\n    - **Repository Pattern**: Abstract away database interactions behind a repository interface to allow for easier testing and potential database changes.  While contexts often serve this purpose in Phoenix, a dedicated repository layer can be useful for very complex data access logic.\n    - **PubSub**: Use `Phoenix.PubSub` for real-time communication between different parts of the application (e.g., LiveView components, channels).\n    - **Ecto Changesets**: Employ Ecto changesets for data validation and sanitization before persisting to the database.\n\n  - ### 2.2. Recommended Approaches for Common Tasks\n\n    - **Authentication**: Use a library like `Pow` or `Ueberauth` for handling user authentication and authorization.\n    - **Authorization**: Implement role-based access control (RBAC) or attribute-based access control (ABAC) using libraries like `Pomegranate` or custom logic.\n    - **Form Handling**: Use `Phoenix.HTML.Form` helpers and Ecto changesets for building and validating forms.\n    - **Real-time Updates**: Leverage Phoenix Channels or LiveView for real-time updates and interactive features.\n    - **Background Jobs**: Use `Oban` for reliable background job processing.\n\n  - ### 2.3. Anti-patterns and Code Smells\n\n    - **Fat Controllers**: Avoid putting too much logic in controllers. Delegate to contexts or services.\n    - **Direct Repo Access in Controllers**: Do not directly call `Repo` functions in controllers. Use contexts.\n    - **Ignoring Changeset Errors**: Always handle changeset errors and display appropriate messages to the user.\n    - **Over-Complicated Queries**: Keep Ecto queries simple and composable. Use views or functions in schema modules to build more complex queries.\n    - **Unnecessary Global State**: Minimize the use of global state. Prefer passing data explicitly between functions and components.\n\n  - ### 2.4. State Management Best Practices (LiveView)\n\n    - Store only the minimal required state in LiveView's `assigns`.\n    - Use `handle_params` to load data based on URL parameters.\n    - Employ `handle_info` for handling asynchronous events and updates.\n    - Implement proper state cleanup in `mount` and `terminate` callbacks.\n    - Consider using a global state management library like `global` only when truly necessary for cross-component communication.\n\n  - ### 2.5. Error Handling Patterns\n\n    - Use pattern matching to handle different error scenarios.\n    - Raise exceptions only for truly exceptional cases.  For expected errors, return `{:error, reason}` tuples.\n    - Implement error logging and monitoring using tools like `Sentry` or `Bugsnag`.\n    - Use `try...rescue` blocks for handling potential exceptions during external API calls or file operations.\n    - Define custom error types using atoms or structs to provide more context for error handling.\n\n- ## 3. Performance Considerations\n\n  - ### 3.1. Optimization Techniques\n\n    - **Database Queries**: Optimize Ecto queries by using indexes, preloading associations, and avoiding N+1 queries.\n    - **Caching**: Implement caching for frequently accessed data using `ETS` tables or a dedicated caching library like `Cachex`.\n    - **Concurrency**: Leverage Elixir's concurrency features (e.g., `Task`, `GenServer`) to handle concurrent requests and background tasks efficiently.\n    - **Code Profiling**: Use tools like `Erlang's observer` or `fprof` to identify performance bottlenecks in your code.\n    - **Connection Pooling**: Ensure proper database connection pooling to minimize connection overhead.\n\n  - ### 3.2. Memory Management\n\n    - **Avoid Memory Leaks**: Be mindful of memory leaks, especially in long-running processes like `GenServers`.\n    - **Use Streams**: Employ Elixir streams for processing large datasets in a memory-efficient manner.\n    - **Garbage Collection**: Understand Erlang's garbage collection behavior and optimize code to minimize garbage collection overhead.\n\n  - ### 3.3. Rendering Optimization (LiveView)\n\n    - **Minimize DOM Updates**: Reduce the number of DOM updates in LiveView by using `phx-update` attributes and smart diffing.\n    - **Use Static Content**: Serve static content (e.g., images, CSS, JavaScript) directly from the web server without involving LiveView.\n    - **Optimize Templates**: Optimize HEEx templates for efficient rendering.\n\n  - ### 3.4. Bundle Size Optimization\n\n    - **Code Splitting**: Use code splitting to reduce the initial bundle size and load code on demand.\n    - **Tree Shaking**: Enable tree shaking in esbuild or Webpack to remove unused code from the bundle.\n    - **Minification**: Minify CSS and JavaScript files to reduce their size.\n    - **Image Optimization**: Optimize images for web use by compressing them and using appropriate formats.\n\n  - ### 3.5. Lazy Loading\n\n    - **Lazy Load Images**: Implement lazy loading for images to improve initial page load time.\n    - **Lazy Load Components**: Use dynamic imports or conditional rendering to lazy load LiveView components.\n\n- ## 4. Security Best Practices\n\n  - ### 4.1. Common Vulnerabilities and Prevention\n\n    - **Cross-Site Scripting (XSS)**: Sanitize user input and use proper escaping in templates to prevent XSS attacks. Phoenix's HEEx templates automatically escape variables, but be careful when using `raw/1` or `safe/1`.\n    - **Cross-Site Request Forgery (CSRF)**: Protect against CSRF attacks by using Phoenix's built-in CSRF protection mechanisms. Include the CSRF token in forms and AJAX requests.\n    - **SQL Injection**: Use Ecto's parameterized queries to prevent SQL injection vulnerabilities.\n    - **Authentication and Authorization Issues**: Implement robust authentication and authorization mechanisms to protect sensitive data and functionality.\n\n  - ### 4.2. Input Validation\n\n    - **Use Ecto Changesets**: Always validate user input using Ecto changesets to ensure data integrity and prevent malicious input.\n    - **Whitelist Input**: Define a whitelist of allowed input values instead of a blacklist of disallowed values.\n    - **Sanitize Input**: Sanitize user input to remove potentially harmful characters or code.\n\n  - ### 4.3. Authentication and Authorization\n\n    - **Use Strong Passwords**: Enforce strong password policies and use proper hashing algorithms (e.g., `bcrypt`) to store passwords securely.\n    - **Implement Multi-Factor Authentication (MFA)**: Add an extra layer of security by requiring users to authenticate using multiple factors.\n    - **Use JWT (JSON Web Tokens)**: Use JWT for secure API authentication and authorization.\n    - **Implement Role-Based Access Control (RBAC)**: Define roles and permissions to control access to different parts of the application.\n\n  - ### 4.4. Data Protection\n\n    - **Encrypt Sensitive Data**: Encrypt sensitive data at rest and in transit using appropriate encryption algorithms.\n    - **Use HTTPS**: Always use HTTPS to encrypt communication between the client and the server.\n    - **Protect API Keys**: Store API keys securely and restrict access to them.\n\n  - ### 4.5. Secure API Communication\n\n    - **Use HTTPS**: Enforce HTTPS for all API communication.\n    - **Validate API Requests**: Validate API requests to prevent malicious input and unauthorized access.\n    - **Rate Limiting**: Implement rate limiting to prevent abuse and denial-of-service attacks.\n    - **API Versioning**: Use API versioning to ensure backward compatibility and allow for future API changes.\n\n- ## 5. Testing Approaches\n\n  - ### 5.1. Unit Testing\n\n    - **Test Contexts and Schemas**: Write unit tests for contexts and schemas to ensure that business logic and data validation work as expected.\n    - **Mock External Dependencies**: Use mocking libraries like `Mock` or `Meck` to isolate units under test and avoid dependencies on external services.\n    - **Test Edge Cases**: Test edge cases and boundary conditions to ensure that code handles unexpected input correctly.\n\n  - ### 5.2. Integration Testing\n\n    - **Test Controllers and Channels**: Write integration tests for controllers and channels to ensure that they interact correctly with contexts and other parts of the application.\n    - **Use a Test Database**: Use a dedicated test database to avoid affecting the production database.\n    - **Verify Database Interactions**: Verify that database interactions are performed correctly by inspecting the database state after running tests.\n\n  - ### 5.3. End-to-End Testing\n\n    - **Use Wallaby or Cypress**: Use end-to-end testing frameworks like Wallaby or Cypress to simulate user interactions and verify that the application works as expected from the user's perspective.\n    - **Test Critical User Flows**: Test critical user flows to ensure that the most important features of the application are working correctly.\n\n  - ### 5.4. Test Organization\n\n    - **Organize Tests by Module**: Organize tests into directories that mirror the application's module structure.\n    - **Use Descriptive Test Names**: Use descriptive test names to clearly indicate what each test is verifying.\n    - **Keep Tests Small and Focused**: Keep tests small and focused to make them easier to understand and maintain.\n\n  - ### 5.5. Mocking and Stubbing\n\n    - **Use Mock Libraries**: Use mocking libraries like `Mock` or `Meck` to create mock objects and stub function calls.\n    - **Avoid Over-Mocking**: Avoid over-mocking, as it can make tests less realistic and harder to maintain.\n    - **Use Stubs for External Dependencies**: Use stubs to replace external dependencies with simplified versions that are easier to control during testing.\n\n- ## 6. Common Pitfalls and Gotchas\n\n  - ### 6.1. Frequent Mistakes\n\n    - **Not Using Contexts**: Directly accessing the Repo in controllers or other modules, bypassing the business logic encapsulation provided by contexts.\n    - **Ignoring Changeset Validation Errors**: Neglecting to handle and display changeset validation errors to the user, leading to confusing behavior.\n    - **N+1 Queries**: Failing to preload associations in Ecto queries, resulting in performance bottlenecks.\n    - **Over-reliance on Global State**: Using global state when it's not necessary, making code harder to reason about and test.\n\n  - ### 6.2. Edge Cases\n\n    - **Handling Timezones**: Dealing with timezones correctly, especially when storing and displaying dates and times to users in different locations.\n    - **Concurrency Issues**: Avoiding race conditions and other concurrency issues when using Elixir's concurrency features.\n    - **Large File Uploads**: Handling large file uploads efficiently and securely.\n\n  - ### 6.3. Version-Specific Issues\n\n    - **LiveView Updates**: Staying up-to-date with LiveView updates and understanding potential breaking changes.\n    - **Ecto Version Compatibility**: Ensuring compatibility between Ecto and other dependencies.\n\n  - ### 6.4. Compatibility Concerns\n\n    - **JavaScript Framework Integration**: Integrating Phoenix with JavaScript frameworks like React or Vue.js can introduce compatibility issues.\n    - **Database Driver Compatibility**: Ensuring compatibility between Ecto and the chosen database driver.\n\n  - ### 6.5. Debugging Strategies\n\n    - **Use IEx.pry**: Use `IEx.pry` to pause execution and inspect variables.\n    - **Enable Debug Logging**: Enable debug logging to get more information about what's happening in the application.\n    - **Use Remote Debugging**: Use remote debugging tools to debug applications running in production environments.\n    - **Analyze Logs**: Analyze logs to identify errors and performance issues.\n\n- ## 7. Tooling and Environment\n\n  - ### 7.1. Recommended Development Tools\n\n    - **Visual Studio Code**: VS Code with the ElixirLS extension provides excellent Elixir support, including code completion, linting, and debugging.\n    - **IntelliJ IDEA**: IntelliJ IDEA with the Elixir plugin also provides excellent Elixir support.\n    - **Mix**: Elixir's build tool, used for creating, compiling, testing, and managing dependencies.\n    - **IEx**: Elixir's interactive shell, used for exploring code and debugging.\n    - **Erlang Observer**: Erlang's GUI tool for monitoring and debugging Erlang/Elixir applications.\n\n  - ### 7.2. Build Configuration\n\n    - **Use `mix.exs`**: Use `mix.exs` to manage project dependencies, compilation settings, and other build configurations.\n    - **Define Environments**: Define separate environments for development, testing, and production.\n    - **Use Configuration Files**: Use configuration files (`config/config.exs`, `config/dev.exs`, `config/test.exs`, `config/prod.exs`) to configure the application for different environments.\n    - **Secrets Management**: Use environment variables or dedicated secrets management tools to store sensitive information like API keys and database passwords.\n\n  - ### 7.3. Linting and Formatting\n\n    - **Use `mix format`**: Use `mix format` to automatically format Elixir code according to a consistent style.\n    - **Use Credo**: Use Credo to analyze Elixir code for style and potential issues.\n    - **Configure Editor**: Configure the editor to automatically format code on save.\n\n  - ### 7.4. Deployment\n\n    - **Use Mix Release**: Use `mix release` to build and deploy Elixir applications. Distillery is deprecated.\n    - **Use Docker**: Use Docker to containerize Elixir applications for easy deployment and scaling.\n    - **Deploy to Cloud Platforms**: Deploy Elixir applications to cloud platforms like Heroku, AWS, Google Cloud, or Azure.\n    - **Use a Process Manager**: Use a process manager like `systemd` or `pm2` to manage Elixir application processes.\n\n  - ### 7.5. CI/CD Integration\n\n    - **Use GitHub Actions, GitLab CI, or CircleCI**: Use CI/CD platforms to automate the build, test, and deployment processes.\n    - **Run Tests on CI**: Run tests on CI to ensure that code changes don't introduce regressions.\n    - **Automate Deployments**: Automate deployments to production environments after successful tests.\n\n- ## Additional Resources\n\n  - [Phoenix Framework Documentation](https://www.phoenixframework.org/docs)\n  - [Elixir Language Documentation](https://elixir-lang.org/docs.html)\n  - [Ecto Documentation](https://hexdocs.pm/ecto/Ecto.html)\n  - [Phoenix LiveView Documentation](https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html)\n  - [Oban Documentation](https://github.com/sorentwo/oban)\n  - [Credo Documentation](https://hexdocs.pm/credo/Credo.html)",
    "metadata": {
      "globs": "*.ex,*.exs,*.eex,*.leex,*.sface",
      "format": "mdc",
      "originalFile": "phoenix.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "phoenix",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "elixir",
      "applications",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "phoenix",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-php",
    "description": "This rule provides guidelines for PHP coding best practices, covering code structure, security, performance, and testing to improve code quality and maintainability.",
    "author": "sanjeed5",
    "tags": [
      "php",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/php.mdc",
    "content": "# PHP Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for PHP development to ensure code quality, maintainability, security, and performance.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n*   **`src/`:**  Contains the core source code of your application or library.\n*   **`public/`:**  The document root of your application, containing publicly accessible files like `index.php`, CSS, JavaScript, and images. All requests should be routed through this directory.\n*   **`config/`:** Stores configuration files for different environments (development, testing, production).\n*   **`tests/`:** Contains unit, integration, and functional tests.\n*   **`vendor/`:**  Managed by Composer, containing third-party libraries and dependencies.  Do not modify contents manually.\n*   **`cache/`:** Directory used for caching data.\n*   **`logs/`:** Directory for storing application logs.  Use descriptive names for log files.\n*   **`data/`:**  Stores data files (e.g., SQLite databases).\n*   **`resources/`:** Contains view templates, language files, and other resources.\n*   **`migrations/`:**  Database migration files for version control of your database schema.\n\n\nproject/\n├── src/\n│   ├── Controller/\n│   │   └── UserController.php\n│   ├── Model/\n│   │   └── User.php\n│   └── ...\n├── public/\n│   └── index.php\n├── config/\n│   └── config.php\n├── tests/\n│   ├── Unit/\n│   │   └── UserTest.php\n│   └── ...\n├── vendor/\n│   └── ...\n├── cache/\n│   └── ...\n├── logs/\n│   └── app.log\n├── data/\n│   └── database.sqlite\n├── resources/\n│   ├── views/\n│   │   └── user.php\n│   └── lang/\n│       └── en.php\n└── migrations/\n    └── 2024_01_01_create_users_table.php\n\n\n### 1.2. File Naming Conventions\n\n*   **Classes:** Use PascalCase (e.g., `UserController.php`). The filename should match the class name.\n*   **Functions and methods:** Use camelCase (e.g., `getUserById()`).\n*   **Variables:** Use camelCase (e.g., `$userName`).\n*   **Constants:** Use UPPER_SNAKE_CASE (e.g., `MAX_USER_AGE`).\n*   **Configuration files:** Use lowercase with underscores (e.g., `database_config.php`).\n*   **View files:** Use lowercase with hyphens (e.g., `user-profile.php`).\n\n### 1.3. Module Organization\n\n*   **Separate concerns:** Organize code into modules based on functionality (e.g., authentication, user management, payment processing).\n*   **Use namespaces:** Group related classes and interfaces within namespaces to avoid naming conflicts and improve code organization (e.g., `namespace App\\Controllers;`). Follow PSR-4 autoloading standards.\n*   **Dependency Injection:** Use dependency injection to decouple modules and make them easier to test and maintain.\n*   **Interfaces and Abstract Classes:** Define interfaces for modules to ensure loose coupling and allow for different implementations.\n\n### 1.4. Component Architecture\n\n*   **Components:** Independent, reusable pieces of functionality that can be composed to build larger applications.\n*   **Thin Controllers:**  Keep controllers light, delegate business logic to service classes or model layer. \n*   **Repositories:** Abstract data access logic from the rest of the application. This allows you to easily switch between different data sources (e.g., databases, APIs) without modifying the core application code.\n*   **Services:**  Encapsulate complex business logic.\n\n### 1.5. Code Splitting\n\n*   **Lazy loading:** Load modules or components only when they are needed to improve initial load time.\n*   **Composer autoloading:** Composer efficiently handles autoloading of classes based on namespaces, splitting code into separate files.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton:**  Ensures that a class has only one instance and provides a global point of access to it.  Use sparingly, as overuse can lead to tight coupling and make testing difficult.\n*   **Factory:**  Creates objects without specifying the exact class to create. Useful for abstracting object creation.\n*   **Observer:**  Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. Useful for event handling.\n*   **Strategy:**  Defines a family of algorithms, encapsulates each one, and makes them interchangeable.  Lets the algorithm vary independently from clients that use it.\n*   **Model-View-Controller (MVC):** Separates application logic (Model), user interface (View), and input handling (Controller). Most PHP frameworks are based on MVC.\n*   **Repository Pattern:** Abstract data access logic. Useful when you want to be able to easily switch data sources or when your data access logic is complex.\n\n### 2.2. Recommended Approaches\n\n*   **Database interactions:**  Use prepared statements with parameterized queries to prevent SQL injection.\n*   **Templating:** Use a templating engine like Twig or Blade to separate presentation logic from PHP code. Helps to maintain code clean and readable.\n*   **Routing:**  Use a routing component to map URLs to controllers and actions. Simplifies URL handling.\n*   **Error handling:** Implement a consistent error handling strategy using exceptions and logging.\n*   **Dependency Injection:** Use a dependency injection container to manage dependencies and promote loose coupling.  Frameworks often include DI containers.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Global state:** Avoid using global variables as they can lead to unpredictable behavior and make code difficult to test.\n*   **Tight coupling:** Minimize dependencies between classes and modules to improve reusability and maintainability.\n*   **Long methods/functions:** Break down large methods into smaller, more focused functions.\n*   **Copy-pasted code:**  Extract common functionality into reusable functions or classes.\n*   **Ignoring errors:**  Always handle exceptions and log errors appropriately.\n*   **Over-use of static methods:**  Limit the use of static methods, which can make testing more difficult.\n*   **Code duplication:** Follow the DRY (Don't Repeat Yourself) principle.\n\n### 2.4. State Management\n\n*   **Sessions:** Use PHP sessions for managing user authentication and temporary data. Configure session security settings (e.g., `session.cookie_httponly`, `session.cookie_secure`).\n*   **Cookies:**  Use cookies for storing small amounts of data on the client-side.  Be mindful of cookie size limits and security.\n*   **Caching:**  Use caching mechanisms (e.g., Memcached, Redis, file-based caching) to improve performance by storing frequently accessed data.\n*   **Database:**  Store persistent data in a database.  Use appropriate data types and indexes for optimal performance.\n*   **Statelessness:**  Design APIs to be stateless whenever possible to improve scalability.\n\n### 2.5. Error Handling\n\n*   **Exceptions:**  Use exceptions to handle errors and exceptional situations. Throw exceptions when something goes wrong.\n*   **Try-catch blocks:** Wrap code that might throw an exception in try-catch blocks to handle errors gracefully.\n*   **Custom exception classes:** Create custom exception classes to represent specific error conditions in your application.\n*   **Logging:**  Log errors, warnings, and informational messages using a logging library (e.g., Monolog).  Configure logging levels.\n*   **Error reporting:**  Configure PHP error reporting settings (`error_reporting`, `display_errors`) appropriately for different environments.  Disable displaying errors in production.\n*   **Global Exception Handler:** Set a global exception handler to catch uncaught exceptions and log them.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Opcode caching:** Use an opcode cache like OPcache (built into PHP) to store compiled PHP code in memory, reducing the need to recompile code on each request.\n*   **Caching:** Implement caching strategies at different levels (e.g., database caching, object caching, page caching).\n*   **Database optimization:** Optimize database queries, use indexes, and avoid N+1 query problems.\n*   **Code profiling:** Use a profiler (e.g., Xdebug) to identify performance bottlenecks in your code.\n*   **Minimize file I/O:**  Reduce the number of file read/write operations.\n*   **Use appropriate data structures:** Choose the right data structures for your needs (e.g., arrays, linked lists, hash tables).\n*   **Avoid resource-intensive operations:**  Minimize the use of functions that consume a lot of resources (e.g., regular expressions).\n*   **Use PHP 7.x/8.x features:**  Take advantage of performance improvements in newer versions of PHP.\n\n### 3.2. Memory Management\n\n*   **Unset variables:** Unset variables that are no longer needed to free up memory.\n*   **Avoid large arrays:**  Avoid storing large amounts of data in arrays.  Use iterators or generators if possible.\n*   **Garbage collection:**  PHP automatically manages memory using garbage collection.  Ensure that your code doesn't create memory leaks (e.g., circular references).\n*   **Limit session size:** Be mindful of the amount of data stored in sessions, as large sessions can consume a lot of memory.\n\n### 3.3. Rendering Optimization\n\n*   **Minimize HTTP requests:** Reduce the number of HTTP requests by combining CSS and JavaScript files, using CSS sprites, and inlining small images.\n*   **Optimize images:** Compress images and use appropriate image formats (e.g., JPEG, PNG, WebP).\n*   **Use browser caching:** Configure browser caching to store static assets (e.g., CSS, JavaScript, images) in the browser cache.\n*   **Content Delivery Network (CDN):**  Use a CDN to serve static assets from geographically distributed servers.\n*   **Gzip compression:** Enable Gzip compression to reduce the size of HTTP responses.\n*   **Minify HTML, CSS, and JavaScript:** Remove unnecessary characters from HTML, CSS, and JavaScript files.\n\n### 3.4. Bundle Size Optimization (Less relevant for traditional PHP, but important for frontend assets)\n\n*   **Code splitting:** Split frontend code into smaller chunks that can be loaded on demand. (Relevant if using a frontend framework like React, Vue, or Angular alongside PHP).\n*   **Tree shaking:** Remove unused code from your JavaScript bundles. (Relevant if using a frontend framework).\n\n### 3.5. Lazy Loading\n\n*   **Lazy-load images:** Load images only when they are visible in the viewport.\n*   **Lazy-load modules:** Load modules or components only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **SQL injection:**  Occurs when untrusted data is used to construct SQL queries. Prevent by using prepared statements with parameterized queries.\n*   **Cross-Site Scripting (XSS):**  Occurs when malicious scripts are injected into a website. Prevent by sanitizing user input and escaping output.\n*   **Cross-Site Request Forgery (CSRF):**  Occurs when a malicious website tricks a user into performing unwanted actions on another website. Prevent by using CSRF tokens.\n*   **Remote Code Execution (RCE):**  Occurs when an attacker can execute arbitrary code on the server. Prevent by avoiding dangerous functions (e.g., `eval()`, `system()`) and carefully validating user input.\n*   **File Inclusion:** Occurs when an attacker can include arbitrary files on the server. Prevent by carefully validating user input and restricting file access.\n*   **Session Hijacking:** Occurs when an attacker steals a user's session ID. Prevent by using secure session management practices.\n*   **Denial of Service (DoS):** Occurs when an attacker overwhelms a server with requests, making it unavailable to legitimate users. Prevent by implementing rate limiting and other security measures.\n\n### 4.2. Input Validation\n\n*   **Sanitize user input:**  Remove or encode potentially dangerous characters from user input.\n*   **Validate user input:**  Verify that user input conforms to expected formats and values.\n*   **Use whitelisting:**  Allow only known good values for user input.  Avoid blacklisting, which can be easily bypassed.\n*   **Escape output:**  Escape output to prevent XSS attacks.\n\n### 4.3. Authentication and Authorization\n\n*   **Use strong passwords:**  Enforce strong password policies and use a secure password hashing algorithm (e.g., bcrypt, Argon2).\n*   **Salt passwords:**  Add a unique salt to each password before hashing it.\n*   **Store passwords securely:** Store password hashes in a secure database.\n*   **Implement access control:** Restrict access to resources based on user roles and permissions.\n*   **Use multi-factor authentication (MFA):**  Add an extra layer of security by requiring users to provide multiple forms of authentication.\n*   **Secure cookies:**  Set the `HttpOnly` and `Secure` flags on cookies to prevent XSS and man-in-the-middle attacks.\n*   **Use HTTPS:**  Encrypt all communication between the client and server using HTTPS.\n\n### 4.4. Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use encryption keys securely:** Store encryption keys in a secure location and rotate them regularly.\n*   **Comply with data privacy regulations:** Comply with data privacy regulations like GDPR and CCPA.\n*   **Implement data masking:** Mask sensitive data when it is not needed for processing.\n*   **Regularly back up data:** Regularly back up data to protect against data loss.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Enforce HTTPS for all API endpoints.\n*   **Authenticate API requests:** Use API keys, OAuth 2.0, or other authentication mechanisms to verify the identity of API clients.\n*   **Authorize API requests:**  Restrict access to API endpoints based on user roles and permissions.\n*   **Rate limit API requests:** Implement rate limiting to prevent abuse.\n*   **Validate API input:** Validate all API input to prevent injection attacks.\n*   **Sanitize API output:** Sanitize all API output to prevent XSS attacks.\n*   **Log API requests:** Log all API requests for auditing and security monitoring.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test individual units of code:**  Focus on testing individual functions, methods, or classes in isolation.\n*   **Use a testing framework:**  Use a unit testing framework like PHPUnit or Codeception.\n*   **Write testable code:**  Design code to be easily testable (e.g., use dependency injection).\n*   **Follow the Arrange-Act-Assert pattern:** Arrange the test data, act on the code being tested, and assert the expected results.\n*   **Test edge cases:** Test edge cases and boundary conditions to ensure that code handles unexpected input correctly.\n\n### 5.2. Integration Testing\n\n*   **Test interactions between components:** Focus on testing how different components of the application interact with each other.\n*   **Use a testing framework:** Use an integration testing framework like PHPUnit or Codeception.\n*   **Test database interactions:** Test database interactions to ensure that data is stored and retrieved correctly.\n*   **Test API integrations:** Test API integrations to ensure that data is exchanged correctly.\n\n### 5.3. End-to-End Testing\n\n*   **Test the entire application flow:** Focus on testing the entire application flow from start to finish.\n*   **Use a testing framework:** Use an end-to-end testing framework like Selenium or Cypress.\n*   **Automate tests:**  Automate end-to-end tests to ensure that the application continues to work correctly as it evolves.\n\n### 5.4. Test Organization\n\n*   **Create a `tests/` directory:** Store all test files in a `tests/` directory.\n*   **Mirror the source code structure:**  Organize test files to mirror the source code structure (e.g., `tests/Unit/UserControllerTest.php`).\n*   **Use namespaces:**  Use namespaces to organize test classes.\n*   **Use descriptive test names:**  Use descriptive test names that clearly indicate what is being tested.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use mocks to isolate units of code:**  Use mocks to replace dependencies with controlled test doubles.\n*   **Use stubs to provide canned responses:** Use stubs to provide canned responses from dependencies.\n*   **Use a mocking framework:** Use a mocking framework like Mockery or Prophecy.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Not escaping output:**  Failing to escape output, leading to XSS vulnerabilities.\n*   **Using `mysql_*` functions:** Using deprecated `mysql_*` functions instead of `mysqli_*` or PDO.\n*   **Not using prepared statements:** Not using prepared statements with parameterized queries, leading to SQL injection vulnerabilities.\n*   **Ignoring errors:** Ignoring errors and warnings, making it difficult to debug problems.\n*   **Not using namespaces:** Not using namespaces, leading to naming conflicts.\n*   **Over-complicating code:**  Writing overly complex code that is difficult to understand and maintain.\n*   **Not following coding standards:** Not following coding standards, leading to inconsistent code.\n\n### 6.2. Edge Cases\n\n*   **Handling different character encodings:**  Handling different character encodings correctly.\n*   **Dealing with time zones:** Dealing with time zones correctly.\n*   **Handling large file uploads:** Handling large file uploads without running out of memory.\n*   **Dealing with concurrency:** Handling concurrency correctly in multi-threaded applications (less common in typical web applications).\n\n### 6.3. Version-Specific Issues\n\n*   **Deprecated features:**  Being aware of deprecated features and replacing them with their recommended alternatives.\n*   **Compatibility issues:**  Ensuring that code is compatible with different versions of PHP.\n\n### 6.4. Compatibility Concerns\n\n*   **Database drivers:**  Ensuring that the correct database drivers are installed and configured.\n*   **Web server configuration:** Configuring the web server (e.g., Apache, Nginx) correctly to serve PHP applications.\n*   **Operating system compatibility:**  Ensuring that the application works correctly on different operating systems.\n\n### 6.5. Debugging Strategies\n\n*   **Use a debugger:** Use a debugger (e.g., Xdebug) to step through code and inspect variables.\n*   **Log messages:**  Insert log messages to track the execution flow and identify problems.\n*   **Use `var_dump()` or `print_r()`:** Use `var_dump()` or `print_r()` to inspect variables and data structures (use with caution in production).\n*   **Read error messages:** Carefully read error messages and warnings to understand the cause of problems.\n*   **Use a linter:** Use a linter to identify potential errors and code style violations.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE:** PhpStorm, VS Code with PHP extensions.\n*   **Debugger:** Xdebug.\n*   **Package manager:** Composer.\n*   **Database client:** Dbeaver, phpMyAdmin.\n*   **Version control:** Git.\n*   **Virtualization:** Docker, Vagrant.\n*   **Profiler:** Xdebug, Blackfire.io\n\n### 7.2. Build Configuration\n\n*   **Use Composer:**  Use Composer to manage dependencies.\n*   **Define dependencies in `composer.json`:**  List all dependencies in the `composer.json` file.\n*   **Use semantic versioning:** Use semantic versioning to specify dependency versions.\n*   **Use a `composer.lock` file:**  Commit the `composer.lock` file to version control to ensure that everyone is using the same versions of dependencies.\n*   **Configure autoloading:**  Configure autoloading to automatically load classes.\n\n### 7.3. Linting and Formatting\n\n*   **Use a linter:** Use a linter (e.g., PHPStan, Psalm) to identify potential errors and code style violations.\n*   **Use a code formatter:** Use a code formatter (e.g., PHP CS Fixer) to automatically format code according to coding standards.\n*   **Configure linting and formatting rules:**  Configure linting and formatting rules to enforce coding standards.\n*   **Integrate linting and formatting into the development workflow:**  Integrate linting and formatting into the development workflow to automatically check code for errors and style violations.\n\n### 7.4. Deployment\n\n*   **Use version control:** Use version control to track changes to code.\n*   **Automate deployments:**  Automate deployments using a deployment tool (e.g., Deployer, Capistrano).\n*   **Use environment variables:**  Use environment variables to configure application settings for different environments.\n*   **Separate code and configuration:** Separate code and configuration to make it easier to deploy applications to different environments.\n*   **Use a build process:**  Use a build process to prepare code for deployment (e.g., run linters, formatters, and tests).\n*   **Test deployments:** Test deployments in a staging environment before deploying to production.\n\n### 7.5. CI/CD\n\n*   **Use a CI/CD platform:** Use a CI/CD platform (e.g., Jenkins, Travis CI, CircleCI, GitHub Actions) to automate the build, test, and deployment process.\n*   **Configure CI/CD pipelines:** Configure CI/CD pipelines to run tests, linters, and formatters automatically on every commit.\n*   **Automate deployments:**  Automate deployments using CI/CD pipelines.\n*   **Use infrastructure as code:**  Use infrastructure as code (e.g., Terraform, Ansible) to manage infrastructure.\n\nThis document aims to provide a comprehensive overview of PHP best practices and coding standards. By following these guidelines, developers can create high-quality, maintainable, secure, and performant PHP applications.",
    "metadata": {
      "globs": "*.php",
      "format": "mdc",
      "originalFile": "php.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "php",
      "this",
      "rule",
      "provides",
      "guidelines",
      "coding",
      "best",
      "practices",
      "covering",
      "code",
      "structure",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "php",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-pillow",
    "description": "This rule provides best practices for using the Pillow image processing library in Python, covering code organization, performance, security, testing, and common pitfalls. It aims to help developers write maintainable, efficient, and secure image processing applications.",
    "author": "sanjeed5",
    "tags": [
      "pillow",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pillow.mdc",
    "content": "# Pillow Library Best Practices and Coding Standards\n\nThis document outlines the recommended best practices and coding standards for effectively using the Pillow library in Python for image processing tasks. These guidelines aim to promote maintainable, efficient, and secure applications.\n\n## 1. Installation and Setup\n\n- **Use a Virtual Environment:** Always create a virtual environment for your Pillow projects to isolate dependencies and avoid conflicts. Use `python -m venv .venv` and activate it.\n- **Install with pip:** Install Pillow using `pip install Pillow`.  Consider using `pip install -U Pillow` for upgrades.\n- **Verify Installation:**  Verify the installation using `python -c \"from PIL import Image; print(Image.VERSION)\"`. This also serves as a smoke test for the library.\n- **Pin Dependencies:** Specify Pillow and other dependencies in a `requirements.txt` file, pinning the versions for reproducible builds. Use `pip freeze > requirements.txt`.\n- **Install dependencies with UV:** Use the uv package manager when installing dependencies: `pip install uv` then `uv pip install -r requirements.txt`.\n\n## 2. Code Organization and Structure\n\n- **Directory Structure:** Organize your project into logical directories. A typical structure might include:\n  \n  project_name/\n  ├── src/\n  │   ├── __init__.py\n  │   ├── image_processing.py  # Pillow-related functions\n  │   ├── utils.py            # Helper functions\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── test_image_processing.py\n  ├── data/                   # Input and output images\n  ├── notebooks/              # Jupyter notebooks for experimentation\n  ├── requirements.txt\n  ├── pyproject.toml         # Optional: For poetry or flit\n  ├── README.md\n  \n- **File Naming Conventions:** Use descriptive and consistent file names:\n  - Python modules: `image_utils.py`, `image_filters.py`\n  - Test files: `test_image_utils.py`, `test_image_filters.py`\n  - Image data: `input_image.jpg`, `output_image.png`\n- **Module Organization:** Group related functions and classes into modules. For example:\n  - `image_processing.py`: Contains functions for core image manipulations (resizing, cropping, color conversions).\n  - `image_filters.py`:  Contains functions for applying image filters (blur, sharpen, edge detection).\n  - `image_io.py`: Contains functions for image loading and saving.\n- **Component Architecture:** Consider using a component-based architecture for larger projects:\n  - **Data Access Layer:**  Handles image loading and saving.\n  - **Business Logic Layer:**  Implements image processing algorithms.\n  - **Presentation Layer:**  Provides a user interface (if applicable) or API endpoint.\n- **Code Splitting:** For large image processing pipelines, split the code into smaller, manageable functions. Use generators for lazy processing of large image datasets.\n\n## 3. Coding Standards and Best Practices\n\n- **Importing:** Always import Pillow using `from PIL import Image`. This is the standard and recommended way.\n- **Explicit Imports:** Use explicit imports (`from PIL import Image, ImageFilter`) rather than wildcard imports (`from PIL import *`). This improves code readability and avoids namespace pollution.\n- **Clear Naming:** Use descriptive variable and function names:\n  - `image = Image.open(\"input.jpg\")`\n  - `resized_image = image.resize((width, height))`\n- **Error Handling:** Use `try...except` blocks to handle potential errors, such as `FileNotFoundError` when opening images or `IOError` when saving images.\n- **Context Managers:** Use `with` statements to ensure proper resource management (especially file closing) when working with images:\n  python\n  try:\n    with Image.open(\"input.jpg\") as image:\n        # Process the image\n        image.save(\"output.png\")\n  except FileNotFoundError:\n      print(\"Error: Input image not found.\")\n  except IOError:\n      print(\"Error: Could not save the image.\")\n  \n- **Image Modes:** Be mindful of image modes (RGB, RGBA, L, CMYK) and convert images to the appropriate mode when necessary using `image.convert(\"RGB\")`.\n- **Resampling Filters:**  Choose appropriate resampling filters for resizing operations:\n  - `Image.LANCZOS`: High-quality resampling for downscaling.\n  - `Image.NEAREST`: Fastest resampling, but lowest quality.\n  - `Image.BILINEAR`, `Image.BICUBIC`: Intermediate quality and speed.\n  - Use `Image.Resampling.LANCZOS` (or `Image.Resampling.BOX`, `Image.Resampling.NEAREST`, etc.) if using Pillow 9.2.0 or newer.\n- **Saving Images:** Always specify the format when saving images, especially if the filename extension is ambiguous. Use `image.save(\"output.png\", format=\"PNG\")`.\n- **Documentation:** Write clear and concise docstrings for all functions and classes, explaining their purpose, arguments, and return values.\n- **Type Hints:** Use type hints to improve code readability and help catch errors early.\n  python\n  from PIL import Image\n\ndef resize_image(image_path: str, width: int, height: int) -> Image.Image:\n    \"\"\"Resizes an image to the specified dimensions.\"\"\"\n    with Image.open(image_path) as image:\n      resized_image = image.resize((width, height))\n      return resized_image\n  \n- **Linting and Formatting:** Use a linter (e.g., pylint, flake8) and a formatter (e.g., black, autopep8) to maintain consistent code style.\n\n## 4. Common Patterns and Anti-patterns\n\n- **Factory Pattern:** Use a factory pattern to create different types of image objects based on input data.\n- **Strategy Pattern:** Implement different image processing algorithms as strategies, allowing you to easily switch between them.\n- **Anti-pattern: Ignoring Errors:** Avoid ignoring exceptions without proper handling.  Always log errors or raise them appropriately.\n- **Anti-pattern: Excessive Memory Usage:** Avoid loading entire image datasets into memory at once. Use generators or iterators for large datasets.\n- **State Management:** For applications with image editing features, use a state management system to track changes and enable undo/redo functionality. Redux, Zustand, or custom state management are possibilities.\n- **Error Handling Patterns:** Use specific exception types (e.g., `FileNotFoundError`, `ValueError`) to handle different error scenarios. Provide informative error messages to the user or log them for debugging.\n\n## 5. Performance Considerations\n\n- **Optimize Image Formats:** Choose the appropriate image format for your needs. JPEG is good for photographs, PNG is good for images with transparency or sharp edges, and WebP offers good compression and quality.\n- **Image Optimization Libraries:** Utilize libraries like `optipng` or `jpegoptim` to further optimize images for web delivery. These tools can reduce file size without significant quality loss.\n- **Lazy Loading:** Load images only when they are needed, especially for web applications. Use placeholders or low-resolution previews while the full image is loading.\n- **Caching:** Cache frequently accessed images to reduce loading times. Use a memory-based cache (e.g., `functools.lru_cache`) or a disk-based cache (e.g., `diskcache`).\n- **Thumbnail Generation:** Generate thumbnails for large images to improve performance in image galleries or previews. Use `image.thumbnail()`.\n- **Efficient Resizing:**  Use `image.thumbnail()` when creating thumbnails as it preserves aspect ratio. If ignoring aspect ratio, use `image.resize()` but be mindful of performance implications.\n- **Memory Management:**\n  - **Use `del` to release memory:** Explicitly delete large image objects when they are no longer needed using `del image`.\n  - **Limit Image Size:** Avoid loading extremely large images that can consume excessive memory.  Consider resizing images to a reasonable size before processing.\n  - **Chunked Processing:** For very large images, process them in chunks to reduce memory usage.\n- **Rendering Optimization:**  When displaying images in a GUI application, use optimized rendering techniques to improve performance.  Consider using hardware acceleration if available.\n- **Asynchronous Processing:**  Offload image processing tasks to separate threads or processes to avoid blocking the main thread.  Use `threading` or `multiprocessing` modules.\n- **Numpy integration:** Convert Pillow images to NumPy arrays for faster calculations.\n\n## 6. Security Best Practices\n\n- **Input Validation:** Validate all image file names and paths to prevent directory traversal attacks and other security vulnerabilities. Use `os.path.abspath()` and `os.path.normpath()` to sanitize paths.\n- **File Extension Validation:** Verify that the file extension matches the actual image format.  Don't rely solely on the extension.\n- **Limit File Size:**  Limit the maximum file size of uploaded images to prevent denial-of-service attacks.\n- **Prevent Image Bomb Attacks:** Implement checks to prevent image bomb attacks, which involve maliciously crafted images designed to consume excessive resources.\n- **Use a Security Linter:**  Incorporate a security linter (e.g., bandit) into your CI/CD pipeline to identify potential security vulnerabilities in your code.\n- **Authentication and Authorization:**  Implement proper authentication and authorization mechanisms to protect access to image processing services.\n- **Data Protection:**  Encrypt sensitive image data at rest and in transit.\n- **Avoid Executing Untrusted Code:** Be cautious when using Pillow to process images from untrusted sources, as vulnerabilities in the library could be exploited. Regularly update Pillow to the latest version.\n- **Regularly Update Pillow:** Stay up-to-date with the latest Pillow releases to patch security vulnerabilities.\n- **Safe Image Handling:** Consider using a sandboxed environment to handle untrusted images, further isolating potential security risks.\n\n## 7. Testing Approaches\n\n- **Unit Testing:** Write unit tests for individual functions and classes in your Pillow-related code. Use a testing framework like `pytest` or `unittest`.\n  - **Test Image Transformations:** Verify that image transformations (resizing, cropping, color conversions) produce the expected results.\n  - **Test Error Handling:** Ensure that your code handles errors gracefully (e.g., invalid image files, incorrect parameters).\n- **Integration Testing:** Test the interaction between different components of your image processing pipeline.\n- **End-to-End Testing:** Verify that the entire application works as expected, including image loading, processing, and saving.\n- **Test Organization:** Organize your tests into logical directories that mirror your code structure.\n- **Mocking and Stubbing:** Use mocking and stubbing to isolate components during testing.  For example, mock the `Image.open()` function to avoid accessing real image files during unit tests.\n- **Property-based Testing:** Use property-based testing (e.g., Hypothesis) to automatically generate test cases and verify that your code satisfies certain properties.\n- **Golden Image Tests:** Compare the output of your image processing functions with known \"golden\" images to ensure that the results are consistent.\n\n## 8. Common Pitfalls and Gotchas\n\n- **Incorrect Image Mode:** Forgetting to convert images to the correct mode (e.g., RGB) before performing certain operations can lead to unexpected results.\n- **Integer Division:**  Be aware of integer division in Python 2. Use `from __future__ import division` to ensure that division always returns a float.\n- **File Closing:**  Forgetting to close image files after processing can lead to resource leaks. Use `with` statements to ensure that files are closed automatically.\n- **Out-of-Memory Errors:** Processing extremely large images can lead to out-of-memory errors.  Use techniques like chunked processing and lazy loading to avoid this.\n- **Color Profile Issues:** Be aware of color profile issues when working with images that have embedded color profiles.  Consider using `image.convert('RGB')` to strip color profiles or use a color management library like `littlecms`.\n- **Pillow Version Compatibility:** Be aware of compatibility issues between different Pillow versions.  Check the Pillow documentation for version-specific changes and bug fixes.\n- **Floating point errors:** Be aware of the loss of precision due to floating point math and how to properly fix it.\n\n## 9. Tooling and Environment\n\n- **Development Tools:**\n  - **IDE:** Use a powerful IDE like VS Code with the Python extension or PyCharm.\n  - **Debugging:** Use a debugger to step through your code and identify errors.\n  - **Profiling:** Use a profiler to identify performance bottlenecks.\n- **Build Configuration:**\n  - **`setup.py`:** Use `setup.py` or `pyproject.toml` to manage your project's dependencies and build process.\n  - **Virtual Environments:** Use virtual environments to isolate your project's dependencies.\n- **Linting and Formatting:**\n  - **Pylint:** Use Pylint to check your code for style errors and potential problems.\n  - **Black:** Use Black to automatically format your code to a consistent style.\n  - **Flake8:** Use Flake8 to check your code for style errors and potential problems.\n- **Deployment:**\n  - **Docker:** Use Docker to containerize your application and ensure consistent deployment across different environments.\n  - **Cloud Platforms:** Deploy your application to a cloud platform like AWS, Google Cloud, or Azure.\n- **CI/CD Integration:**\n  - **GitHub Actions:** Use GitHub Actions to automate your build, test, and deployment process.\n  - **Jenkins:** Use Jenkins for continuous integration and continuous delivery.\n  - **CircleCI:** Use CircleCI for continuous integration and continuous delivery.\n\nBy following these best practices and coding standards, you can create robust, efficient, and secure image processing applications using the Pillow library in Python.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pillow.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pillow",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "using",
      "image",
      "processing",
      "library",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pillow",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-playwright",
    "description": "This rule enforces best practices and coding standards for Playwright tests, including stable selectors, test isolation, user-centric testing, and performance considerations.",
    "author": "sanjeed5",
    "tags": [
      "playwright",
      "testing",
      "e2e",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "quality-testing",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/playwright.mdc",
    "content": "- **General Principles**\n  - **Test User-Visible Behavior:** Focus tests on how users interact with your application, not on internal implementation details.\n  - **Isolate Tests:** Ensure tests are independent of each other to prevent cascading failures and ensure predictable results.\n  - **Avoid Testing Third-Party Dependencies:** Mock or stub external services and APIs to isolate your application's behavior.\n\n- **Code Organization and Structure**\n  - **Directory Structure:**\n    - `tests/`: Contains all test files.\n    - `tests/e2e/`: End-to-end tests.\n    - `tests/unit/`: Unit tests (if applicable, though Playwright is primarily for E2E).\n    - `tests/utils/`: Helper functions and page object models.\n  - **File Naming Conventions:**\n    - Use `.spec.ts` or `.spec.js` for test files (e.g., `login.spec.ts`).\n    - Group related tests in the same file.\n  - **Module Organization:**\n    - Employ Page Object Model (POM) to encapsulate UI elements and interactions.\n  - **Component Architecture:**\n    - Structure tests around components or features of your application.\n  - **Code Splitting Strategies:**\n    - Not directly applicable to tests, but keep test files concise and focused.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - **Page Object Model (POM):** A common pattern where each page is represented as a class, with methods for interacting with the page's elements.  This improves reusability and maintainability. Example:\n      typescript\n      class LoginPage {\n        constructor(private readonly page: Page) {}\n\n        async goto() {\n          await this.page.goto('/login');\n        }\n\n        async login(username: string, password: string) {\n          await this.page.fill('#username', username);\n          await this.page.fill('#password', password);\n          await this.page.click('#login-button');\n        }\n\n        async getErrorMessage() {\n          return await this.page.textContent('#error-message');\n        }\n      }\n      \n    - **Fixture pattern:** Use Playwright's built-in fixtures to manage test setup and teardown. This ensures each test starts in a clean state.\n  - **Recommended Approaches:**\n    - Use `baseURL` in `playwright.config.ts` to avoid hardcoding URLs in tests.\n    - Utilize `expect` matchers for assertions (e.g., `expect(page.locator('#success')).toBeVisible()`).\n    - Use auto-waiting features for improved stability.\n  - **Anti-patterns:**\n    - Hardcoding URLs.\n    - Using brittle selectors (e.g., XPath based on DOM structure).\n    - Writing tests that depend on each other.\n  - **State Management:**\n    - Keep tests stateless. Reset the application state before each test.\n    - Use database transactions or API calls to seed data for tests.\n  - **Error Handling:**\n    - Use `try...catch` blocks to handle expected errors.\n    - Log errors and failures with descriptive messages.\n    - Use `expect.soft()` for non-critical assertions that shouldn't fail the test immediately.\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - Run tests in parallel to reduce overall test execution time.\n    - Use `reuseExistingServer: true` in `playwright.config.ts` during development to speed up debugging.\n    - Use `codegen` to generate selectors automatically.\n  - **Memory Management:**\n    - Close pages and browsers after each test or group of tests to release resources.\n  - **Rendering Optimization:**\n    - Not directly applicable but optimize your application's rendering for faster testing.\n  - **Bundle Size Optimization:**\n    - Not directly applicable, but optimize your application's bundle size for faster loading.\n  - **Lazy Loading Strategies:**\n    - Not directly applicable to tests.\n\n- **Security Best Practices**\n  - **Common Vulnerabilities:**\n    - Avoid exposing sensitive data (e.g., passwords, API keys) in test code or logs.\n  - **Input Validation:**\n    - Test input validation to ensure your application handles invalid data correctly.\n  - **Authentication and Authorization:**\n    - Test different user roles and permissions.\n  - **Data Protection:**\n    - Ensure sensitive data is encrypted in the database.\n  - **Secure API Communication:**\n    - Test that API calls are made over HTTPS.\n\n- **Testing Approaches**\n  - **Unit Testing:**\n    - While Playwright primarily focuses on E2E testing, unit tests can be written for utility functions or components.\n  - **Integration Testing:**\n    - Test the interaction between different parts of your application.\n  - **End-to-End Testing:**\n    - Simulate user flows to test the entire application.\n  - **Test Organization:**\n    - Group tests by feature or functionality.\n    - Use `describe` blocks to organize tests.\n  - **Mocking and Stubbing:**\n    - Use Playwright's `route` API to mock API responses.\n    - Use `locator.evaluate` to stub JavaScript functions.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - Using XPath instead of CSS selectors.\n    - Not using auto-waiting features.\n    - Writing flaky tests.\n  - **Edge Cases:**\n    - Handling different screen sizes and devices.\n    - Testing error conditions and edge cases.\n  - **Version-Specific Issues:**\n    - Stay up-to-date with Playwright's release notes and upgrade guides.\n  - **Compatibility Concerns:**\n    - Test on different browsers and operating systems.\n  - **Debugging Strategies:**\n    - Use Playwright Inspector to debug tests visually.\n    - Use `console.log` statements to log information during test execution.\n    - Use `pause()` to halt test execution and inspect the page.\n\n- **Tooling and Environment**\n  - **Recommended Development Tools:**\n    - VS Code with the Playwright extension.\n  - **Build Configuration:**\n    - Use TypeScript for type safety and autocompletion.\n  - **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce code style.\n  - **Deployment Best Practices:**\n    - Run tests in CI/CD pipeline before deploying to production.\n  - **CI/CD Integration:**\n    - Integrate Playwright with CI/CD tools like GitHub Actions, Jenkins, or GitLab CI.\n\n- **Specific Best Practices & Details**\n    - **Stable Selectors:** Prefer CSS selectors based on attributes like `data-testid` or `data-test-id` over XPath or fragile CSS classnames.\n    - **Leverage Auto-waiting:** Playwright automatically waits for elements to be actionable before performing actions.  Avoid explicit waits where possible. However, use explicit waits (e.g. `waitForSelector`) when necessary.\n    - **Web-First Assertions:** Use `expect` assertions, which retry and wait for conditions to be met. They help to avoid flakiness.\n    - **Configure Debugging Highlights:**  Configure `playwright.config.ts` to highlight actions performed by playwright in the browser during debugging to see what's happening step by step. Example:\n        typescript\n        use: {\n            /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */\n            trace: 'on-first-retry',\n            video: 'on',\n            screenshot: 'only-on-failure',\n        }\n        \n\n- **Additional Notes**\n    - Regularly review and update your test suite to reflect changes in your application.\n    - Document your tests to make them easier to understand and maintain.\n    - Use a consistent naming convention for your tests.",
    "metadata": {
      "globs": "*.spec.ts",
      "format": "mdc",
      "originalFile": "playwright.mdc"
    },
    "subcategory": "e2e-testing",
    "keywords": [
      "cursor",
      "playwright",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "tests",
      "including",
      "testing",
      "e2e",
      "cursor-rule",
      "mdc",
      "quality-testing",
      "e2e-testing"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "playwright",
        "testing",
        "e2e",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "quality-testing"
    }
  },
  {
    "name": "cursor-plotly",
    "description": "This rule file provides best practices and coding standards for using the Plotly library, focusing on code organization, performance, security, testing, and common pitfalls. It aims to guide developers in creating maintainable, efficient, and secure Plotly applications.",
    "author": "sanjeed5",
    "tags": [
      "plotly",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/plotly.mdc",
    "content": "# Plotly Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for using the Plotly library in Python for AI, ML, data science, and other development contexts. It covers various aspects, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nOrganizing your project with a clear and consistent directory structure enhances maintainability and collaboration. Here's a suggested structure:\n\n\nproject_root/\n├── data/\n│   ├── raw/\n│   ├── processed/\n│   └── external/\n├── src/\n│   ├── visualizations/\n│   │   ├── __init__.py\n│   │   ├── charts.py  # Contains functions for creating different charts\n│   │   ├── layouts.py # Defines layouts and themes\n│   │   └── utils.py   # Utility functions for visualizations\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── model_training.py\n│   │   └── model_evaluation.py\n│   ├── data_processing/\n│   │   ├── __init__.py\n│   │   ├── data_cleaning.py\n│   │   └── feature_engineering.py\n│   ├── utils/\n│   │   ├── __init__.py\n│   │   ├── config.py   # Configuration settings\n│   │   └── helpers.py  # General helper functions\n│   └── main.py         # Entry point of the application\n├── tests/\n│   ├── visualizations/\n│   ├── models/\n│   ├── data_processing/\n│   └── conftest.py    # Pytest configuration file\n├── notebooks/         # Jupyter notebooks for exploration\n├── requirements.txt   # Project dependencies\n├── pyproject.toml     # Configuration file for dependencies\n└── README.md\n\n\n*   `data/`: Stores data-related files.\n    *   `raw/`: Contains the original, untouched data.\n    *   `processed/`: Stores cleaned and transformed data.\n    *   `external/`: Includes data from external sources.\n*   `src/`: Houses the source code of your application.\n    *   `visualizations/`: Contains modules for creating Plotly charts and layouts.\n    *   `models/`: Includes modules for training and evaluating machine learning models.\n    *   `data_processing/`: Contains modules for data cleaning and feature engineering.\n    *   `utils/`: Contains utility modules, such as configuration settings and helper functions.\n    *   `main.py`: The entry point of your application.\n*   `tests/`: Stores unit tests for different modules.\n*   `notebooks/`: Contains Jupyter notebooks for data exploration and prototyping.\n*   `requirements.txt`: Lists project dependencies.\n*   `README.md`: Provides a high-level overview of the project.\n\n### 1.2. File Naming Conventions\n\nFollow consistent naming conventions for files and directories to improve readability and maintainability:\n\n*   Use lowercase letters for file names.\n*   Separate words with underscores (`_`).\n*   Be descriptive and concise.\n\nExample:\n\n*   `charts.py`\n*   `data_cleaning.py`\n*   `feature_engineering.py`\n*   `model_training.py`\n\n### 1.3. Module Organization Best Practices\n\nOrganize your code into modules based on functionality. For Plotly-specific code, consider the following modules:\n\n*   `charts.py`: Contains functions for creating different types of Plotly charts (e.g., scatter plots, bar charts, line charts).\n*   `layouts.py`: Defines layouts and themes for Plotly charts.\n*   `utils.py`: Includes utility functions for visualizations, such as data formatting and color palettes.\n\nExample `charts.py`:\n\npython\nimport plotly.express as px\n\ndef create_scatter_plot(df, x_col, y_col, color_col=None, title=\"Scatter Plot\"):\n    \"\"\"Creates a scatter plot using Plotly Express.\"\"\"\n    fig = px.scatter(df, x=x_col, y=y_col, color=color_col, title=title)\n    return fig\n\ndef create_bar_chart(df, x_col, y_col, color_col=None, title=\"Bar Chart\"):\n    \"\"\"Creates a bar chart using Plotly Express.\"\"\"\n    fig = px.bar(df, x=x_col, y=y_col, color=color_col, title=title)\n    return fig\n\n# Add other chart functions here\n\n\n### 1.4. Component Architecture Recommendations\n\nFor larger applications, consider a component-based architecture. This involves breaking down the application into reusable components. Components can be:\n\n*   Chart components: Reusable functions or classes for creating specific types of charts.\n*   Layout components: Reusable layouts and themes.\n*   Data components: Functions or classes for fetching and processing data.\n\nExample:\n\npython\n# visualizations/components.py\n\nimport plotly.graph_objects as go\n\nclass ScatterPlot:\n    def __init__(self, df, x_col, y_col, color_col=None, title=\"Scatter Plot\"):\n        self.df = df\n        self.x_col = x_col\n        self.y_col = y_col\n        self.color_col = color_col\n        self.title = title\n\n    def create_plot(self):\n        fig = go.Figure(data=go.Scatter(x=self.df[self.x_col], y=self.df[self.y_col], mode='markers', marker=dict(color=self.df[self.color_col] if self.color_col else None)))\n        fig.update_layout(title=self.title, xaxis_title=self.x_col, yaxis_title=self.y_col)\n        return fig\n\n\n### 1.5. Code Splitting Strategies\n\nFor web applications built with Dash, code splitting can improve performance by loading only the necessary code for each page or component. Strategies include:\n\n*   Using Dash's `dcc.Location` component to conditionally render different components based on the URL.\n*   Implementing lazy loading for large datasets or complex visualizations.\n*   Breaking down your Dash app into multiple files and importing only the necessary components.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Plotly\n\n*   **Factory Pattern:** Use a factory function to create different types of charts based on input parameters. This simplifies the creation of charts and promotes code reuse.\n*   **Template Method Pattern:** Define a base class for chart components with a template method that outlines the steps for creating a chart. Subclasses can then implement specific steps.\n*   **Observer Pattern:** In Dash applications, use the Observer pattern to update charts dynamically based on user interactions or data changes.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Creating Interactive Charts:** Use `plotly.express` for quick interactive charts. For more control, use `plotly.graph_objects`.\n*   **Updating Chart Layouts:** Use `fig.update_layout()` to modify chart titles, axes labels, legends, and annotations.\n*   **Handling Large Datasets:** Use techniques like data aggregation, sampling, or WebGL rendering to improve performance.\n*   **Creating Dashboards:** Use the Dash framework to build interactive web applications with Plotly charts.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Overloading Charts:** Avoid including too much information in a single chart, which can make it difficult to interpret.\n*   **Ignoring Performance:** Neglecting to optimize charts for large datasets can lead to slow rendering and poor user experience.\n*   **Hardcoding Values:** Avoid hardcoding values in your chart definitions. Use configuration files or environment variables instead.\n*   **Not Handling Errors:** Failing to handle errors can lead to unexpected behavior and poor user experience.\n*   **Inconsistent Styling:** Ensure consistent styling across all charts in your application.\n\n### 2.4. State Management Best Practices for Plotly Applications (Dash)\n\n*   **Use Dash's `dcc.Store` component:** Store application-wide state in `dcc.Store` components. This allows you to share state between different callbacks.\n*   **Avoid Storing Large Datasets in State:** Instead, load data on-demand or use a server-side caching mechanism.\n*   **Use Callbacks to Update State:** Only update state in response to user interactions or data changes.\n*   **Immutable State Updates:** Treat state as immutable and create new state objects instead of modifying existing ones.\n\n### 2.5. Error Handling Patterns\n\n*   **Use `try-except` Blocks:** Wrap Plotly code in `try-except` blocks to catch potential exceptions, such as data errors or rendering issues.\n*   **Log Errors:** Log error messages to a file or console for debugging purposes.\n*   **Display User-Friendly Error Messages:** Display informative error messages to the user instead of showing raw exceptions.\n*   **Implement Fallback Mechanisms:** Provide fallback mechanisms in case of chart rendering failures, such as displaying a static image or a placeholder message.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Data Aggregation:** Aggregate data to reduce the number of data points displayed in the chart.\n*   **Sampling:** Use sampling techniques to reduce the size of large datasets.\n*   **WebGL Rendering:** Utilize Plotly's WebGL backend for faster rendering of complex 3D and dense 2D plots. Add `renderer=\"webgl\"` argument in the `show()` function\n*   **Caching:** Implement caching mechanisms to store frequently accessed data and reduce the number of database queries or API calls.\n\n### 3.2. Memory Management Considerations\n\n*   **Release Unused Resources:** Ensure that you release any unused resources, such as large datasets or chart objects, to prevent memory leaks.\n*   **Use Generators:** Use generators to process large datasets in chunks instead of loading the entire dataset into memory.\n*   **Avoid Creating Unnecessary Copies:** Avoid creating unnecessary copies of data objects, as this can consume additional memory.\n\n### 3.3. Rendering Optimization\n\n*   **Reduce Chart Complexity:** Simplify your charts by reducing the number of traces, data points, or annotations.\n*   **Use Efficient Data Structures:** Use efficient data structures, such as NumPy arrays or Pandas DataFrames, to store and manipulate data.\n*   **Optimize Callback Logic:** Optimize the logic in your Dash callbacks to reduce the amount of time spent processing data or updating charts.\n\n### 3.4. Bundle Size Optimization Strategies\n\n*   **Use a Virtual Environment:** Create a virtual environment for your project to isolate dependencies and reduce the overall bundle size.\n*   **Remove Unused Dependencies:** Remove any unused dependencies from your project.\n*   **Minify JavaScript and CSS:** Minify JavaScript and CSS files to reduce their size.\n*   **Use Code Splitting:** Split your code into multiple bundles and load only the necessary code for each page or component.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Load Data On-Demand:** Load data only when it is needed, such as when a user interacts with a chart or navigates to a new page.\n*   **Use Asynchronous Loading:** Use asynchronous loading techniques to load data in the background without blocking the main thread.\n*   **Implement Placeholder Content:** Display placeholder content while data is loading to improve the user experience.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user inputs and escaping any data displayed in the charts.\n*   **Injection Attacks:** Prevent injection attacks by using parameterized queries or ORM frameworks to interact with databases.\n*   **Denial of Service (DoS):** Implement rate limiting and input validation to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n*   **Validate User Inputs:** Validate user inputs to ensure that they conform to the expected format and range.\n*   **Sanitize User Inputs:** Sanitize user inputs to remove any potentially malicious code or characters.\n*   **Use Whitelisting:** Use whitelisting to allow only specific characters or patterns in user inputs.\n\n### 4.3. Authentication and Authorization\n\n*   **Implement Authentication:** Implement authentication to verify the identity of users accessing your application.\n*   **Use Strong Passwords:** Enforce the use of strong passwords and implement password hashing and salting.\n*   **Implement Authorization:** Implement authorization to control access to different parts of your application based on user roles or permissions.\n\n### 4.4. Data Protection Strategies\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit to protect it from unauthorized access.\n*   **Use Secure Protocols:** Use secure protocols, such as HTTPS, to communicate with servers and APIs.\n*   **Implement Access Controls:** Implement access controls to restrict access to sensitive data based on user roles or permissions.\n\n### 4.5. Secure API Communication\n\n*   **Use API Keys:** Use API keys to authenticate requests to external APIs.\n*   **Validate API Responses:** Validate API responses to ensure that they are in the expected format and do not contain any malicious content.\n*   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of your APIs.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Write unit tests to test individual components of your Plotly code, such as chart functions or layout definitions.\n*   **Use Mock Data:** Use mock data to isolate components from external dependencies.\n*   **Verify Chart Properties:** Verify that the chart properties, such as titles, axes labels, and data values, are correct.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Write integration tests to test the interactions between different components of your application.\n*   **Use a Test Database:** Use a test database to isolate your tests from the production database.\n*   **Verify Data Flow:** Verify that data flows correctly between components.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Application:** Write end-to-end tests to test the entire application from the user's perspective.\n*   **Use a Testing Framework:** Use a testing framework, such as Selenium or Cypress, to automate end-to-end tests.\n*   **Verify User Interactions:** Verify that user interactions, such as clicking buttons or entering data, produce the expected results.\n\n### 5.4. Test Organization\n\n*   **Organize Tests by Module:** Organize your tests into directories that correspond to the modules in your application.\n*   **Use Descriptive Test Names:** Use descriptive test names that clearly indicate what the test is verifying.\n*   **Write Clear Assertions:** Write clear assertions that verify the expected results.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mock Objects:** Use mock objects to replace external dependencies, such as databases or APIs, with controlled test doubles.\n*   **Use Stub Functions:** Use stub functions to replace complex or time-consuming operations with simple, predictable implementations.\n*   **Verify Interactions with Mocks:** Verify that your code interacts with mock objects in the expected way.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Incorrect Data Formatting:** Ensure that your data is formatted correctly for Plotly charts. For example, ensure that dates are in the correct format and that numerical data is not stored as strings.\n*   **Missing Dependencies:** Ensure that all required dependencies are installed.\n*   **Incorrect Chart Types:** Choose the correct chart type for your data and the message you want to convey.\n*   **Ignoring Layout Customization:** Customize the chart layout to improve readability and visual appeal.\n\n### 6.2. Edge Cases\n\n*   **Handling Missing Data:** Handle missing data gracefully by either removing it from the chart or replacing it with a default value.\n*   **Dealing with Outliers:** Deal with outliers appropriately by either removing them from the chart or using a chart type that is less sensitive to outliers, such as a box plot.\n*   **Handling Large Numbers:** Handle large numbers by using appropriate formatting and scaling.\n\n### 6.3. Version-Specific Issues\n\n*   **Check Release Notes:** Check the release notes for each Plotly version to be aware of any breaking changes or bug fixes.\n*   **Test with Different Versions:** Test your code with different Plotly versions to ensure compatibility.\n\n### 6.4. Compatibility Concerns\n\n*   **Dash Version Compatibility:** Ensure that your Dash version is compatible with your Plotly version.\n*   **Browser Compatibility:** Test your charts in different browsers to ensure compatibility.\n\n### 6.5. Debugging Strategies\n\n*   **Use Debugging Tools:** Use debugging tools, such as print statements or a debugger, to identify and fix issues in your code.\n*   **Check Error Messages:** Check error messages for clues about what is going wrong.\n*   **Simplify the Chart:** Simplify the chart by removing traces or annotations to isolate the issue.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **VS Code:** A popular code editor with excellent support for Python and Plotly.\n*   **Jupyter Notebook:** An interactive environment for data exploration and prototyping.\n*   **PyCharm:** A full-featured IDE for Python development.\n*   **Dash Enterprise:** A platform for deploying and managing Dash applications.\n\n### 7.2. Build Configuration Best Practices\n\n*   **Use a Virtual Environment:** Create a virtual environment for your project to isolate dependencies.\n*   **Use a Dependency Manager:** Use a dependency manager, such as pip or poetry, to manage project dependencies.\n*   **Specify Dependencies:** Specify the exact versions of your dependencies in your `requirements.txt` or `pyproject.toml` file.\n\n### 7.3. Linting and Formatting\n\n*   **Use a Linter:** Use a linter, such as pylint or flake8, to identify and fix code style issues.\n*   **Use a Formatter:** Use a formatter, such as black or autopep8, to automatically format your code according to a consistent style.\n*   **Configure Your Editor:** Configure your editor to automatically run the linter and formatter when you save your code.\n\n### 7.4. Deployment Best Practices\n\n*   **Use a Production Environment:** Deploy your application to a production environment that is separate from your development environment.\n*   **Use a Web Server:** Use a web server, such as nginx or Apache, to serve your application.\n*   **Use a Process Manager:** Use a process manager, such as gunicorn or uwsgi, to manage your application processes.\n\n### 7.5. CI/CD Integration Strategies\n\n*   **Use a CI/CD Pipeline:** Use a CI/CD pipeline, such as Jenkins or GitHub Actions, to automate the build, test, and deployment process.\n*   **Run Tests Automatically:** Run tests automatically as part of the CI/CD pipeline.\n*   **Deploy Automatically:** Deploy your application automatically to the production environment when all tests pass.\n\nBy following these best practices and coding standards, you can create maintainable, efficient, and secure Plotly applications that meet the needs of your users and stakeholders.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "plotly.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "plotly",
      "this",
      "rule",
      "file",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "using",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "plotly",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-poetry",
    "description": "This rule set provides comprehensive guidance on best practices for using Poetry in Python projects, including dependency management, project structure, and coding standards. It covers various aspects such as code organization, performance considerations, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "poetry",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/poetry.mdc",
    "content": "# Poetry Python Library Best Practices\n\nThis document outlines best practices for utilizing Poetry, a dependency management and packaging tool for Python. Following these guidelines will result in more maintainable, scalable, and robust Python projects.\n\n## 1. Code Organization and Structure\n\nA well-organized project structure is critical for maintainability and collaboration. Poetry provides the tools to enforce a standardized structure.\n\n### 1.1 Directory Structure Best Practices\n\n*   **Root Directory:** The root directory contains the `pyproject.toml` file, `README.md`, and potentially other top-level configuration files (e.g., `.gitignore`, `mypy.ini`).\n*   **Source Directory:** The main source code should reside in a dedicated directory. The typical layout is to place your package in a top-level directory, e.g., `my_package/`, or within a `src/` directory (e.g., `src/my_package/`). Using `src/` allows for cleaner separation of concerns, facilitating testing and package building.\n    *   **Choosing Between Flat and `src` Layouts:**\n        *   **Flat Layout (default):** `my_project/my_package/__init__.py`\n        *   **`src` Layout:** `my_project/src/my_package/__init__.py`. The `src` layout avoids potential import ambiguity when running scripts from the project root and provides a clearer separation between project-level files and package code.\n*   **Tests Directory:** Tests should be in a `tests/` directory, mirroring the source structure. This helps in easily locating and running tests. Include an `__init__.py` in the directory to make it a package.\n*   **Docs Directory (Optional):** If the project requires extensive documentation, a `docs/` directory can be included to house documentation files.\n*   **Examples Directory (Optional):** Provides example usage scenarios to help end-users easily start using your library.\n\nExample directory structure (using the `src` layout):\n\n\nmy_project/\n├── src/\n│   └── my_package/\n│       ├── __init__.py\n│       ├── module1.py\n│       └── module2.py\n├── tests/\n│   ├── __init__.py\n│   ├── test_module1.py\n│   └── test_module2.py\n├── pyproject.toml\n├── poetry.lock\n├── README.md\n└── .gitignore\n\n\n### 1.2 File Naming Conventions\n\n*   **Python Files:** Use lowercase names with underscores (snake_case) for Python files (e.g., `my_module.py`, `data_processing.py`).\n*   **Test Files:**  Test files should mirror the module being tested, prefixed with `test_`.  For example, `test_my_module.py` tests `my_module.py`.\n*   **`__init__.py`:**  Use an empty `__init__.py` file or add initialization logic if needed. The presence of `__init__.py` makes the directory a Python package.\n*   **Configuration Files:**  Use descriptive names for configuration files (e.g., `config.py`, `settings.toml`).\n\n### 1.3 Module Organization\n\n*   **Grouping Functionality:** Group related functions and classes into modules. Each module should represent a specific functionality or component.\n*   **Avoiding Circular Dependencies:**  Design modules to minimize dependencies on each other. Circular dependencies can lead to import errors and make code harder to understand.\n*   **Explicit Imports:** Use explicit imports (e.g., `from my_package.module1 import function_x`) instead of wildcard imports (`from my_package.module1 import *`). Explicit imports improve code readability and reduce namespace pollution.\n*   **Relative Imports (Where Appropriate):** Within a package, use relative imports (e.g., `from . import module2` or `from .. import another_package`) to reference other modules in the same package. This makes the package more self-contained.\n\n### 1.4 Component Architecture\n\n*   **Layered Architecture:** For larger projects, consider a layered architecture (e.g., presentation layer, business logic layer, data access layer). This promotes separation of concerns and makes the codebase more modular.\n*   **Microservices (If Applicable):** If the project is complex, consider splitting it into microservices, each managed as a separate Poetry project.\n*   **Dependency Injection:**  Employ dependency injection to decouple components.  This enhances testability and flexibility.\n*   **Interfaces:** Define clear interfaces between components. This allows for easier swapping of implementations without affecting other parts of the system.\n\n### 1.5 Code Splitting Strategies\n\n*   **By Functionality:** Split code into modules based on functionality (e.g., `data_processing.py`, `api_client.py`, `ui_components.py`).\n*   **By Component:**  If using a component-based architecture, split code into modules representing individual components.\n*   **Lazy Loading:** Use lazy loading for modules that are not immediately required at startup. This can improve application startup time.\n*   **Dynamic Imports:** Use dynamic imports (e.g., `importlib.import_module`) for optional dependencies or features. Handle potential `ImportError` exceptions gracefully.\n\n## 2. Common Patterns and Anti-patterns\n\nUnderstanding common patterns and anti-patterns is essential for writing clean, efficient, and maintainable code.\n\n### 2.1 Design Patterns\n\n*   **Factory Pattern:** Use factory patterns to create objects without specifying their concrete classes. This promotes loose coupling and makes it easier to switch between different implementations.\n*   **Strategy Pattern:** Use strategy patterns to define a family of algorithms and make them interchangeable at runtime. This allows for flexible algorithm selection based on different conditions.\n*   **Observer Pattern:**  Implement the observer pattern for event handling and decoupled communication between components.\n*   **Singleton Pattern (Use Sparingly):** Avoid overuse of the singleton pattern.  If used, ensure thread safety.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Dependency Injection:** Using dependency injection to manage dependencies improves testability and flexibility.\n*   **Configuration Management:** Using configuration files (e.g., TOML, YAML) to store application settings simplifies management and deployment.\n*   **Logging:** Using a logging library (e.g., `logging`) for application logging enables easy debugging and monitoring.\n*   **Data Validation:** Use a data validation library (e.g., `pydantic`, `marshmallow`) to validate input data and ensure data integrity.\n*   **API Clients:** Encapsulate API interactions within dedicated modules, enabling reuse and reducing code duplication. Use libraries like `requests` or `httpx` for HTTP requests. Consider asynchronous clients with `asyncio` for enhanced performance in I/O bound scenarios.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Global State:** Avoid using global variables excessively. Global state makes code harder to reason about and test.\n*   **Magic Numbers:** Avoid using magic numbers in code. Define constants with descriptive names instead.\n*   **Duplicated Code:** Avoid code duplication. Extract common code into functions or classes.\n*   **Long Functions:** Avoid writing long functions. Break them down into smaller, more manageable functions.\n*   **Over-Engineering:** Don't over-engineer solutions. Keep the code simple and focused on the problem at hand.\n*   **Ignoring Exceptions:** Never leave `except:` blocks empty. Always handle exceptions appropriately.\n*   **Wildcard Imports:** Avoid wildcard imports (`from module import *`). They pollute the namespace and make it harder to understand where symbols come from.\n\n### 2.4 State Management\n\n*   **Stateless Components:** Prefer stateless components whenever possible. Stateless components are easier to test and reason about.\n*   **Immutable Data:** Use immutable data structures (e.g., `namedtuple`, `dataclasses` with `frozen=True`) to avoid accidental state modifications.\n*   **Explicit State:** Make state transitions explicit and well-defined. Use a state management library (e.g., `transitions`) for complex state machines.\n*   **Centralized State (If Needed):** For complex applications, consider using a centralized state management solution (e.g., Redux-like pattern). However, be mindful of the increased complexity.\n\n### 2.5 Error Handling\n\n*   **Specific Exceptions:** Catch specific exceptions instead of using a broad `except Exception:`.\n*   **Logging Errors:** Log error messages with relevant context (e.g., function name, input arguments).\n*   **Raising Exceptions:** Raise exceptions when errors occur to signal failures to the caller.\n*   **Context Managers:** Use context managers (`with` statement) to ensure proper resource management (e.g., closing files, releasing locks).\n*   **Retry Mechanism:**  Implement a retry mechanism for transient errors (e.g., network errors, API rate limits). Use libraries like `tenacity` to easily implement retry logic with customizable backoff strategies.\n*   **Error Boundaries:**  Design error boundaries in your application that prevent errors in one part of the system from crashing the entire application.  This can be achieved through exception handling at appropriate levels and the use of circuit breaker patterns.\n\n## 3. Performance Considerations\n\nOptimizing performance is crucial for providing a smooth user experience and reducing resource consumption.\n\n### 3.1 Optimization Techniques\n\n*   **Profiling:** Use profiling tools (e.g., `cProfile`, `line_profiler`) to identify performance bottlenecks.\n*   **Algorithm Optimization:** Choose efficient algorithms and data structures for critical tasks.\n*   **Caching:** Implement caching for frequently accessed data. Use libraries like `cachetools` or `diskcache` for caching.\n*   **Asynchronous Programming:** Use asynchronous programming (`asyncio`) for I/O-bound operations (e.g., network requests, file I/O). This can significantly improve concurrency and responsiveness.\n*   **Multiprocessing:** Use multiprocessing (`multiprocessing`) for CPU-bound operations to take advantage of multiple cores. However, be mindful of the increased complexity of inter-process communication.\n*   **Vectorization (NumPy):** Use NumPy for vectorized operations on arrays. Vectorization can significantly speed up numerical computations.\n*   **Just-In-Time (JIT) Compilation:** Consider using a JIT compiler (e.g., Numba) for computationally intensive functions. JIT compilation can significantly improve performance.\n\n### 3.2 Memory Management\n\n*   **Garbage Collection:** Understand how Python's garbage collection works. Avoid creating circular references that can prevent garbage collection.\n*   **Generators and Iterators:** Use generators and iterators for processing large datasets. Generators and iterators consume memory on demand, avoiding the need to load the entire dataset into memory.\n*   **Data Structure Efficiency:** Choose efficient data structures for storing data. Consider using specialized data structures (e.g., `collections.deque`, `heapq`) when appropriate.\n*   **Memory Profiling:** Use memory profiling tools (e.g., `memory_profiler`) to identify memory leaks and excessive memory consumption.\n*   **Object Reuse:**  Reuse objects when possible to minimize object creation and destruction overhead. This can be particularly relevant for long-running processes.\n\n### 3.3 Bundle Size Optimization (If Applicable)\n\n*   **Tree Shaking:** If using a bundler, enable tree shaking to remove unused code from the bundle.\n*   **Code Minification:**  Minify code to reduce the bundle size. Tools like `Terser` can be used for code minification.\n*   **Image Optimization:** Optimize images to reduce their size without compromising quality.\n*   **Dependency Optimization:**  Analyze dependencies to identify and remove unnecessary dependencies. Tools like `depcheck` can help with dependency optimization.\n*   **Compression:**  Use compression algorithms (e.g., gzip, Brotli) to compress the bundle before deployment. This reduces the download size and improves loading time.\n\n### 3.4 Lazy Loading\n\n*   **Module Lazy Loading:** Use dynamic imports to lazy load modules that are not immediately required.\n*   **Data Lazy Loading:** Use generators or iterators to lazy load data from databases or files.\n*   **Component Lazy Loading:**  Load UI components or application features on demand, improving initial startup time.\n\n## 4. Security Best Practices\n\nSecurity should be a top priority in any software project. Following security best practices can help protect your application from vulnerabilities.\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **Injection Attacks:** Prevent injection attacks (e.g., SQL injection, command injection) by validating and sanitizing user inputs. Use parameterized queries or ORMs to prevent SQL injection.\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by escaping user-generated content before displaying it in the browser.\n*   **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using anti-CSRF tokens.\n*   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms to protect sensitive resources.\n*   **Dependency Vulnerabilities:** Regularly scan dependencies for vulnerabilities and update them to the latest versions. Tools like `Safety` or Snyk can be used to detect and remediate dependency vulnerabilities.\n*   **Sensitive Data Exposure:** Avoid storing sensitive data (e.g., passwords, API keys) in plaintext. Encrypt sensitive data at rest and in transit.\n*   **Denial of Service (DoS):**  Implement rate limiting and input validation to prevent DoS attacks.\n\n### 4.2 Input Validation\n\n*   **Validate All Inputs:** Validate all user inputs, including form data, URL parameters, and API requests.\n*   **Use a Validation Library:** Use a validation library (e.g., `pydantic`, `marshmallow`) to define validation schemas and validate data against them.\n*   **Sanitize Inputs:** Sanitize inputs to remove potentially harmful characters or code.\n*   **Limit Input Length:** Limit the length of input fields to prevent buffer overflows.\n*   **Check Data Types:** Verify that input data is of the expected data type.\n\n### 4.3 Authentication and Authorization\n\n*   **Strong Passwords:** Enforce strong password policies (e.g., minimum length, complexity requirements).\n*   **Hashing Passwords:** Hash passwords using a strong hashing algorithm (e.g., bcrypt, Argon2) and store them securely.\n*   **Salting Passwords:** Salt passwords to prevent rainbow table attacks.\n*   **Two-Factor Authentication (2FA):** Implement two-factor authentication for increased security.\n*   **Role-Based Access Control (RBAC):** Use role-based access control to restrict access to sensitive resources based on user roles.\n*   **JSON Web Tokens (JWT):** Use JSON Web Tokens for stateless authentication and authorization.\n*   **OAuth 2.0:**  Use OAuth 2.0 for secure delegation of authorization.\n\n### 4.4 Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit using strong encryption algorithms (e.g., AES, TLS).\n*   **Data Masking:** Mask sensitive data when displaying it to users.\n*   **Data Anonymization:** Anonymize data when it is not necessary to identify individual users.\n*   **Regular Backups:** Perform regular backups of data to prevent data loss.\n*   **Secure Storage:** Store data in a secure location with appropriate access controls.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n*   **API Keys:** Protect API keys and store them securely. Rotate API keys regularly.\n*   **Rate Limiting:** Implement rate limiting to prevent API abuse.\n*   **Input Validation:** Validate all API requests to prevent injection attacks.\n*   **Output Sanitization:** Sanitize API responses to prevent XSS attacks.\n*   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms for API access.\n*   **CORS:** Configure Cross-Origin Resource Sharing (CORS) to restrict API access to authorized domains.\n\n## 5. Testing Approaches\n\nThorough testing is essential for ensuring the quality and reliability of software.\n\n### 5.1 Unit Testing\n\n*   **Test-Driven Development (TDD):** Consider using test-driven development (TDD) to write tests before writing code.\n*   **Test Coverage:** Aim for high test coverage to ensure that all parts of the code are tested.\n*   **Test Independence:** Write tests that are independent of each other. Avoid sharing state between tests.\n*   **Assertion Libraries:** Use assertion libraries (e.g., `unittest`, `pytest`) to write clear and concise assertions.\n*   **Edge Cases:** Test edge cases and boundary conditions to ensure that the code handles them correctly.\n\n### 5.2 Integration Testing\n\n*   **Component Integration:** Test the integration between different components of the system.\n*   **API Integration:** Test the integration with external APIs.\n*   **Database Integration:** Test the integration with databases.\n*   **Mock External Dependencies:** Use mocks or stubs to isolate the system under test from external dependencies.\n*   **Real-World Scenarios:** Design integration tests to simulate real-world usage scenarios.\n\n### 5.3 End-to-End Testing\n\n*   **User Interface Testing:** Test the user interface to ensure that it is working as expected.\n*   **User Flows:** Test complete user flows to ensure that the system is functioning correctly from start to finish.\n*   **Automated Testing:** Automate end-to-end tests to ensure that they are run regularly.\n*   **Browser Automation:** Use browser automation tools (e.g., Selenium, Playwright) to automate user interface tests.\n*   **Continuous Integration:** Integrate end-to-end tests into the continuous integration pipeline.\n\n### 5.4 Test Organization\n\n*   **Mirror Source Structure:** Organize tests in a directory structure that mirrors the source code structure.\n*   **Descriptive Test Names:** Use descriptive names for test functions and test classes.\n*   **Grouping Tests:** Group related tests into test classes or modules.\n*   **Test Suites:** Create test suites to group related tests together.\n*   **Test Runners:** Use test runners (e.g., `unittest`, `pytest`) to discover and run tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock External Dependencies:** Use mocks to simulate the behavior of external dependencies (e.g., databases, APIs).\n*   **Stub Internal Dependencies:** Use stubs to replace internal dependencies with simpler implementations.\n*   **Isolate the System Under Test:** Use mocks and stubs to isolate the system under test from external factors.\n*   **Verify Interactions:** Use mocks to verify that the system under test is interacting with its dependencies in the expected way.\n*   **Mocking Libraries:** Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to create mocks and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\nBeing aware of common pitfalls can save time and prevent headaches.\n\n### 6.1 Frequent Mistakes\n\n*   **Forgetting to Update `poetry.lock`:** Failing to update the `poetry.lock` file after adding or updating dependencies can lead to inconsistent environments.\n*   **Using Wildcard Dependencies:** Using wildcard dependencies can lead to unexpected updates that break the code.\n*   **Ignoring Virtual Environments:** Not using virtual environments can lead to conflicts between different projects.\n*   **Committing Virtual Environment Directories:** Committing the virtual environment directory to version control is unnecessary and can lead to problems.\n*   **Using Incompatible Python Versions:** Using incompatible Python versions can lead to errors.\n\n### 6.2 Edge Cases\n\n*   **Platform-Specific Dependencies:** Handling platform-specific dependencies requires careful consideration of package availability and compatibility.\n*   **Optional Dependencies:** Managing optional dependencies that may not be available on all systems.\n*   **Conflicting Dependencies:** Resolving conflicts between dependencies with overlapping requirements can be challenging.\n*   **Cyclic Dependencies:** Cyclic dependencies can lead to import errors and make code harder to understand.\n*   **Large Datasets:** Handling large datasets requires careful consideration of memory management and performance.\n\n### 6.3 Version-Specific Issues\n\n*   **Dependency Compatibility:** Ensuring that dependencies are compatible with the target Python version and each other.\n*   **Deprecated Features:** Handling deprecated features and migrating to newer versions of dependencies.\n*   **Security Updates:** Staying up-to-date with security updates for Poetry and its dependencies.\n\n### 6.4 Compatibility Concerns\n\n*   **Operating System Compatibility:** Ensuring that the code works correctly on different operating systems.\n*   **Python Interpreter Compatibility:** Ensuring that the code works correctly with different Python interpreters (e.g., CPython, PyPy).\n*   **Package Compatibility:** Ensuring that packages are compatible with each other.\n*   **Hardware Compatibility:** Considering hardware compatibility, especially when dealing with platform-specific dependencies or performance-critical code.\n*   **Backward Compatibility:** Striving to maintain backward compatibility to minimize disruption for existing users when introducing new features or changes.\n\n### 6.5 Debugging Strategies\n\n*   **Logging:** Using logging to track the flow of execution and identify errors.\n*   **Debuggers:** Using debuggers (e.g., `pdb`, `ipdb`) to step through code and inspect variables.\n*   **Unit Tests:** Writing unit tests to isolate and test individual components.\n*   **Print Statements (Use Sparingly):** Using print statements to display the values of variables (use sparingly and remove them before committing code).\n*   **Profiling:** Using profiling tools to identify performance bottlenecks.\n*   **Remote Debugging:**  Utilize remote debugging techniques to debug code running on remote servers or containers. This can be particularly helpful for cloud deployments.\n*   **Post-Mortem Debugging:**  Leverage Python's post-mortem debugging capabilities to analyze errors after they have occurred. This can provide valuable insights into the root cause of the problem.\n\n## 7. Tooling and Environment\n\nUsing the right tools and configuring the environment correctly can significantly improve developer productivity.\n\n### 7.1 Recommended Development Tools\n\n*   **Integrated Development Environment (IDE):** Use an IDE (e.g., VS Code, PyCharm) with Python support for code completion, syntax highlighting, and debugging.\n*   **Linters:** Use linters (e.g., `flake8`, `pylint`) to enforce code style and identify potential errors.\n*   **Formatters:** Use formatters (e.g., `black`, `autopep8`) to automatically format code according to style guidelines.\n*   **Type Checkers:** Use type checkers (e.g., `mypy`) to catch type errors early on.\n*   **Version Control System (VCS):** Use a version control system (e.g., Git) to track changes to the code.\n\n### 7.2 Build Configuration\n\n*   **`pyproject.toml`:**  The cornerstone of Poetry projects, this file defines project metadata, dependencies, and build configuration.\n*   **`.gitignore`:**  Excludes unnecessary files and directories (e.g., virtual environment directories, build artifacts) from version control.\n*   **`Makefile` (Optional):** Use a `Makefile` to automate common tasks (e.g., running tests, building documentation).\n*   **Dockerfiles:** Use Dockerfiles to create container images for deployment. This ensures consistent environments across different systems.\n*   **Configuration Files:** Use configuration files (e.g., TOML, YAML) to store application settings and environment variables.\n\n### 7.3 Linting and Formatting\n\n*   **`flake8` Configuration:** Configure `flake8` to enforce coding style guidelines and identify potential errors. Configure in `pyproject.toml` if the tool supports it, otherwise use a separate config file.\n*   **`black` Configuration:** Configure `black` to automatically format code according to style guidelines. Configure in `pyproject.toml`.\n*   **`isort` Configuration:** Configure `isort` to automatically sort imports according to style guidelines. Configure in `pyproject.toml`.\n*   **Pre-commit Hooks:** Use pre-commit hooks to automatically run linters and formatters before committing code. This helps to maintain code quality and consistency.\n\n### 7.4 Deployment\n\n*   **Containerization:** Containerize the application using Docker to ensure consistent environments across different systems.\n*   **Cloud Platforms:** Deploy the application to a cloud platform (e.g., AWS, Azure, Google Cloud) for scalability and reliability.\n*   **Continuous Delivery:** Use continuous delivery pipelines to automate the deployment process.\n*   **Configuration Management:** Use configuration management tools (e.g., Ansible, Chef, Puppet) to manage infrastructure configuration.\n*   **Monitoring:** Implement monitoring to track the performance and health of the application.\n\n### 7.5 CI/CD Integration\n\n*   **Continuous Integration (CI):** Integrate the code with a continuous integration system (e.g., Jenkins, GitLab CI, GitHub Actions) to automate testing and building.\n*   **Continuous Delivery (CD):** Integrate the CI system with a continuous delivery system to automate the deployment process.\n*   **Automated Testing:** Automate unit tests, integration tests, and end-to-end tests in the CI/CD pipeline.\n*   **Automated Code Analysis:** Integrate code analysis tools (e.g., linters, formatters, type checkers) into the CI/CD pipeline.\n*   **Automated Deployment:** Automate the deployment process to ensure that code is deployed consistently and reliably.\n\nBy adhering to these best practices, developers can create Python projects with Poetry that are more maintainable, scalable, secure, and reliable.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "poetry.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "poetry",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "using",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "poetry",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pony",
    "description": "Comprehensive guidelines for Pony ORM best practices, covering code organization, patterns, performance, security, testing, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "pony",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pony.mdc",
    "content": "# Pony ORM Best Practices\n\nThis document outlines best practices for developing Python applications using Pony ORM. Following these guidelines will improve code maintainability, readability, performance, and security.\n\n## 1. Code Organization and Structure\n\n### Directory Structure\n\nAdopt a logical directory structure to organize your project. A common pattern is to separate data access logic (Pony entities and queries) from business logic.\n\n\nproject/\n├── models/\n│   ├── __init__.py\n│   ├── entities.py  # Pony entity definitions\n│   └── queries.py   # Reusable queries\n├── services/\n│   ├── __init__.py\n│   ├── user_service.py  # Business logic for users\n│   └── product_service.py # Business logic for products\n├── utils/\n│   └── db.py        # Database connection and session management\n├── tests/\n│   ├── __init__.py\n│   ├── test_entities.py\n│   └── test_user_service.py\n├── main.py          # Application entry point\n└── requirements.txt\n\n\n### File Naming Conventions\n\n*   Use descriptive names for files and modules.\n*   `entities.py`: Contains Pony entity definitions.\n*   `queries.py`: Contains reusable database queries.\n*   `[module]_service.py`: Contains business logic for a specific module.\n*   `test_[module].py`: Contains unit tests for a specific module.\n\n### Module Organization\n\n*   Group related entities and queries into separate modules.\n*   Use `__init__.py` to define module interfaces and control imports.\n\n### Component Architecture\n\n*   **Entities Layer**: Contains database models and relationships. Entities should primarily define data structure and basic validation.\n*   **Data Access Layer**: Manages database interactions.  Implement CRUD operations (Create, Read, Update, Delete) within this layer. Avoid business logic in this layer, focusing solely on data retrieval and persistence.\n*   **Business Logic Layer**:  This layer contains the core application logic. It orchestrates data flow between the data access layer and the presentation layer.\n*   **Presentation Layer**: (If applicable) Handles user interaction and data display.  This could be a web framework, GUI application or CLI.\n\n### Code Splitting\n\n*   Break down large modules into smaller, more manageable files.\n*   Use subpackages to group related modules.\n*   Consider splitting modules based on functionality or entity type.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Repository Pattern**: Encapsulate data access logic behind a repository interface. This allows for easier testing and switching of data storage implementations.\n*   **Unit of Work Pattern**: Track changes to entities within a single unit of work (database transaction) and commit all changes at once.\n*   **Data Mapper Pattern**:  Map data between the database and the entity model.  Pony ORM inherently implements this pattern.\n*   **Factory Pattern**:  Use factories to create entity instances, especially when instantiation logic is complex or requires external dependencies.\n*   **Singleton Pattern**:  Ensure only one instance of the `Database` object exists for each database connection.  This is often used in conjunction with a dependency injection framework.\n\n### Recommended Approaches for Common Tasks\n\n*   **Fetching data efficiently**: Utilize Pony's query optimization features to minimize database round trips.\n*   **Handling relationships**:  Properly define relationships (One-to-many, Many-to-many) using `Set`, `Required`, and `Optional` attributes.\n*   **Performing complex queries**: Leverage Pony's Pythonic query syntax for readable and maintainable queries.\n*   **Managing transactions**: Always use the `db_session` decorator or context manager to wrap database interactions.\n*   **Implementing validation**: Define validation rules within entity classes or using separate validation functions.\n\n### Anti-patterns and Code Smells\n\n*   **Mixing business logic with entity definitions**: Keep entity classes focused on data representation, not application logic.\n*   **Performing database operations outside of a `db_session`**: This will lead to `TransactionError` exceptions.\n*   **Over-fetching data**:  Only select the data that is needed for a specific operation. Use projections in your queries.\n*   **Ignoring Pony's query optimization**:  Write inefficient queries that lead to performance bottlenecks.\n*   **Directly manipulating the database connection**:  Rely on Pony ORM for database interactions.\n*   **Not handling exceptions**: Lack of exception handling can lead to application instability and data corruption.\n*   **Using global database sessions without proper context management.** This can lead to concurrency issues.\n*   **Not using indexes where appropriate.** This will lead to slow query performance.\n\n### State Management\n\n*   Within a `db_session`, Pony ORM manages the state of entities automatically.\n*   For long-running processes, be mindful of memory usage and consider clearing the `db_session` cache periodically.\n*   Avoid passing entity instances outside of the `db_session` scope if you intend to modify them.  Consider extracting relevant data and passing simple data objects (dictionaries, data transfer objects) instead.\n\n### Error Handling\n\n*   Use `try...except` blocks to handle potential exceptions during database operations.\n*   Rollback transactions in case of errors using `db.rollback()` or let `db_session` handle it.\n*   Log errors for debugging and monitoring purposes.\n*   Define custom exceptions for specific error scenarios.\n*   Consider retrying transactions for recoverable errors.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Query optimization**:  Use Pony's query syntax effectively to generate optimized SQL queries. Analyze generated SQL queries to identify potential performance bottlenecks and optimize using indexes. Use `set_sql_debug(True)` to observe the queries.\n*   **Caching**: Pony ORM includes Identity Map, automatic caching of queries and objects. Understand its limitations and potential benefits.\n*   **Lazy loading**: Avoid loading unnecessary data by using lazy loading for related entities.\n*   **Eager loading**: For well-known queries where related entities are always required, use eager loading to reduce the number of database queries.\n*   **Batch operations**: Perform bulk inserts, updates, and deletes to minimize database round trips.\n*   **Indexing**: Add indexes to frequently queried columns to improve query performance.\n*   **Connection pooling**:  Pony ORM uses connection pooling. Configure connection pool size based on application needs.\n*   **Data Type Selection**: Choose the appropriate data types for your entities to minimize storage space and improve query performance.\n\n### Memory Management\n\n*   Be aware of the size of the `db_session` cache and clear it periodically for long-running processes.\n*   Avoid loading large datasets into memory at once.\n*   Use generators for processing large datasets in chunks.\n\n### Rendering Optimization\n\n*   If applicable, optimize rendering logic to minimize the amount of data that needs to be displayed.\n*   Use pagination for displaying large lists of data.\n*   Consider caching rendered output to reduce database load.\n\n### Bundle Size Optimization\n\n*   If applicable to your project, minimize the size of your application bundle by removing unused code and dependencies.\n*   Use code splitting to load only the code that is needed for a specific page or feature.\n\n### Lazy Loading\n\n*   Pony ORM supports lazy loading for related entities.\n*   Use lazy loading to avoid loading unnecessary data upfront.\n*   Be mindful of the N+1 problem when using lazy loading and consider eager loading for frequently accessed related entities.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and Prevention\n\n*   **SQL injection**: Prevent SQL injection by using Pony's parameterized queries.  Never construct SQL queries by concatenating strings directly. Pony ORM avoids SQL injection by using generator expressions or lambda functions.\n*   **Cross-site scripting (XSS)**:  If applicable to your project, sanitize user input to prevent XSS attacks.\n*   **Cross-site request forgery (CSRF)**: If applicable to your project, protect against CSRF attacks by using CSRF tokens.\n*   **Authentication and authorization vulnerabilities**: Implement secure authentication and authorization mechanisms to protect sensitive data.\n*   **Denial-of-service (DoS) attacks**:  Protect against DoS attacks by implementing rate limiting and other security measures.\n\n### Input Validation\n\n*   Validate all user input to prevent malicious data from being stored in the database.\n*   Use appropriate validation rules for each entity attribute.\n*   Sanitize input to remove potentially harmful characters.\n\n### Authentication and Authorization\n\n*   Use a secure authentication mechanism to verify user identities.\n*   Implement authorization rules to control access to sensitive data and functionality.\n*   Consider using a role-based access control (RBAC) system.\n\n### Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use strong passwords and store them securely.\n*   Implement data masking to protect sensitive data from unauthorized access.\n\n### Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Implement API authentication and authorization.\n*   Protect against API attacks, such as rate limiting and input validation.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   Write unit tests for individual components, such as entity classes, queries, and services.\n*   Use mocking and stubbing to isolate components from external dependencies.\n*   Test edge cases and error conditions.\n*   Use `in-memory` SQLite database for faster and isolated testing.\n\n### Integration Testing\n\n*   Write integration tests to verify the interaction between different components.\n*   Test the integration between Pony ORM and the database.\n*   Use a test database that is separate from the production database.\n\n### End-to-End Testing\n\n*   Write end-to-end tests to verify the entire application workflow.\n*   Test the application from the user's perspective.\n*   Use a testing framework such as Selenium or Cypress.\n\n### Test Organization\n\n*   Organize tests into separate modules based on the component or functionality being tested.\n*   Use a consistent naming convention for test files and functions.\n*   Keep tests small and focused.\n\n### Mocking and Stubbing\n\n*   Use mocking to replace external dependencies with controlled substitutes.\n*   Use stubbing to provide predefined responses for external dependencies.\n*   Use mocking frameworks such as `unittest.mock` or `pytest-mock`.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   Forgetting to use `db_session` for database interactions.\n*   Writing inefficient queries that lead to performance bottlenecks.\n*   Not handling exceptions properly.\n*   Ignoring security best practices.\n*   Using deprecated features or APIs.\n*   Incorrectly configuring database connections.\n*   Misunderstanding how the Identity Map cache works.\n\n### Edge Cases\n\n*   Handling concurrent database access.\n*   Dealing with large datasets.\n*   Managing database migrations.\n*   Handling database errors and exceptions.\n*   Working with different database vendors.\n\n### Version-Specific Issues\n\n*   Be aware of compatibility issues between different versions of Pony ORM.\n*   Consult the Pony ORM documentation for version-specific information.\n\n### Compatibility Concerns\n\n*   Be aware of compatibility issues between Pony ORM and other technologies, such as web frameworks and database drivers.\n*   Consult the Pony ORM documentation for compatibility information.\n\n### Debugging Strategies\n\n*   Use Pony's SQL debugging feature to inspect generated SQL queries.\n*   Use logging to track application behavior and identify errors.\n*   Use a debugger to step through code and inspect variables.\n*   Check the database logs for errors and warnings.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n*   Python IDE (e.g., PyCharm, VS Code).\n*   Database client (e.g., DBeaver, pgAdmin).\n*   Testing framework (e.g., pytest, unittest).\n*   Mocking framework (e.g., unittest.mock, pytest-mock).\n*   Linting and formatting tools (e.g., flake8, black).\n\n### Build Configuration\n\n*   Use a build system such as `setuptools` or `poetry` to manage project dependencies.\n*   Specify Pony ORM as a dependency in your project's `requirements.txt` or `pyproject.toml` file.\n\n### Linting and Formatting\n\n*   Use linting tools such as `flake8` to enforce code style guidelines.\n*   Use formatting tools such as `black` to automatically format code.\n*   Configure your IDE to run linting and formatting tools automatically.\n\n### Deployment\n\n*   Deploy your application to a production environment that is separate from the development environment.\n*   Configure your application to use a production database.\n*   Monitor your application for errors and performance issues.\n\n### CI/CD Integration\n\n*   Use a continuous integration and continuous delivery (CI/CD) system to automate the build, test, and deployment process.\n*   Integrate Pony ORM tests into your CI/CD pipeline.\n*   Automate database migrations as part of your CI/CD process.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pony.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "pony",
      "comprehensive",
      "guidelines",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "patterns",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pony",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-postgresql",
    "description": "Enforces PostgreSQL coding standards, best practices, and performance optimization techniques to ensure maintainable, efficient, and secure database interactions. This rule covers code formatting, data integrity, security, and performance considerations.",
    "author": "sanjeed5",
    "tags": [
      "postgresql",
      "database",
      "sql",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/postgresql.mdc",
    "content": "- **Code Formatting and Comments:**\n  - Maintain consistent code formatting using a tool like `pgformatter` or similar.\n  - Use clear and concise comments to explain complex logic and intentions. Update comments regularly to avoid confusion.\n  - Use inline comments sparingly; prefer block comments for detailed explanations.\n  - Write comments in plain, easy-to-follow English.\n  - Add a space after line comments (`-- a comment`); do not add a space for commented-out code (`--raise notice`).\n  - Keep comments up-to-date; incorrect comments are worse than no comments.\n\n- **Naming Conventions:**\n  - Use `snake_case` for identifiers (e.g., `user_id`, `customer_name`).\n  - Use plural nouns for table names (e.g., `customers`, `products`).\n  - Use consistent naming conventions for functions, procedures, and triggers.\n  - Choose descriptive and meaningful names for all database objects.\n\n- **Data Integrity and Data Types:**\n  - Use appropriate data types for columns to ensure data integrity (e.g., `INTEGER`, `VARCHAR`, `TIMESTAMP`).\n  - Use constraints (e.g., `NOT NULL`, `UNIQUE`, `CHECK`, `FOREIGN KEY`) to enforce data integrity.\n  - Define primary keys for all tables.\n  - Use foreign keys to establish relationships between tables.\n  - Utilize domains to enforce data type constraints reusable across multiple columns.\n\n- **SQL Injection Prevention:**\n  - Always use parameterized queries or prepared statements to prevent SQL injection attacks.\n  - Sanitize user inputs before using them in SQL queries.\n  - Avoid constructing SQL queries by concatenating strings directly.\n  - Use the `quote_literal()` and `quote_ident()` functions to properly escape strings and identifiers.\n\n- **Transaction Management:**\n  - Use explicit transactions to ensure data consistency and atomicity.\n  - Start transactions with `BEGIN;` and end them with `COMMIT;` or `ROLLBACK;`.\n  - Handle transaction errors properly to prevent data corruption.\n  - Use savepoints to allow partial rollbacks within a transaction.\n\n- **Indexing:**\n  - Create indexes on columns frequently used in `WHERE` clauses and `JOIN` conditions.\n  - Avoid over-indexing, as it can slow down write operations.\n  - Consider using partial indexes for specific query patterns.\n  - Use appropriate index types (e.g., `B-tree`, `Hash`, `GIN`, `GiST`) based on the data and query requirements.\n  - Regularly analyze and maintain indexes using `ANALYZE` and `VACUUM`.\n\n- **Query Optimization:**\n  - Use `EXPLAIN ANALYZE` to analyze query execution plans and identify performance bottlenecks.\n  - Avoid using `SELECT *` and specify only the necessary columns.\n  - Use `JOIN` operations instead of subqueries where possible.\n  - Optimize `WHERE` clauses to reduce the number of rows processed.\n  - Consider using materialized views for frequently executed, complex queries.\n  - Rewrite slow performing queries with more efficient alternatives.\n\n- **PL/pgSQL Best Practices:**\n  - Keep PL/pgSQL functions and procedures short and focused.\n  - Use exception handling to gracefully handle errors.\n  - Use `RAISE NOTICE`, `RAISE WARNING`, and `RAISE EXCEPTION` for logging and error reporting.\n  - Avoid using cursors unless absolutely necessary; prefer set-based operations.\n  - Use the `STRICT` attribute to ensure that a function returns a value.\n\n- **Security Best Practices:**\n  - Grant the least privileges necessary to database users.\n  - Use roles to manage permissions.\n  - Regularly audit database activity.\n  - Encrypt sensitive data at rest and in transit.\n  - Use the `SECURITY DEFINER` attribute for functions that require elevated privileges.\n  - Configure appropriate authentication mechanisms (e.g., `SCRAM-SHA-256`).\n\n- **Connection Management:**\n  - Use connection pooling to reduce the overhead of establishing new connections.\n  - Close connections when they are no longer needed.\n  - Configure connection timeouts to prevent idle connections from consuming resources.\n\n- **Backup and Recovery:**\n  - Implement a robust backup and recovery strategy.\n  - Regularly back up the database.\n  - Test the recovery process to ensure it works as expected.\n  - Consider using replication for high availability.\n\n- **Code Organization and Structure:**\n  - Organize database objects into schemas based on functionality or application modules.\n  - Use version control for database scripts and migrations.\n  - Follow a consistent directory structure for database-related files.\n\n- **Common Pitfalls and Gotchas:**\n  - Avoid using reserved keywords as identifiers.\n  - Be aware of the limitations of data types (e.g., maximum length of `VARCHAR` columns).\n  - Handle null values carefully.\n  - Test database changes thoroughly before deploying them to production.\n\n- **Tooling and Environment:**\n  - Use a code editor with SQL syntax highlighting and autocompletion.\n  - Use a database client tool for querying and managing the database (e.g., `pgAdmin`, `DBeaver`, `psql`).\n  - Use a version control system (e.g., Git) to manage database scripts and migrations.\n  - Use a CI/CD pipeline to automate database deployments.\n\n- **C Coding Standards (When Extending PostgreSQL):**\n  - Adhere to the C99 standard. Only use language features available in the C99 standard.\n  - Follow PostgreSQL's source code conventions ([PostgreSQL Documentation](https://www.postgresql.org/docs/current/source-conventions.html)).\n  - Manage memory carefully; avoid memory leaks.\n  - Properly handle errors and exceptions.\n  - Document code thoroughly.\n\n- **Use Case specific optimizations:**\n  - Time series data: Consider timescaledb extension\n  - Geospatial data: Consider postgis extension\n\n@file ./rules/postgresql_security_rules.mdc",
    "metadata": {
      "globs": "*.sql,*.plpgsql,*.c,*.h",
      "format": "mdc",
      "originalFile": "postgresql.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "postgresql",
      "enforces",
      "coding",
      "standards",
      "best",
      "practices",
      "performance",
      "optimization",
      "techniques",
      "ensure",
      "database",
      "sql",
      "cursor-rule",
      "mdc",
      "data-ai",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "postgresql",
        "database",
        "sql",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "data-ai"
    }
  },
  {
    "name": "cursor-postman",
    "description": "This rule provides best practices for effectively using Postman for API testing, covering code organization, common patterns, performance, security, testing, and tooling to ensure robust and maintainable API tests.",
    "author": "sanjeed5",
    "tags": [
      "postman",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/postman.mdc",
    "content": "# Postman API Testing Best Practices\n\nThis document outlines best practices for using Postman for API testing, covering aspects like project structure, common patterns, performance optimization, security considerations, testing strategies, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\nEffective organization is crucial for maintainability and collaboration. While Postman doesn't directly enforce code organization like a traditional codebase, the way you structure your collections and environments significantly impacts your workflow.\n\n- **Workspaces:** Utilize workspaces to separate projects and collections logically. Different workspaces can represent different projects, teams, or stages of development.\n- **Collections:** Group related API requests into collections. Each collection should represent a specific feature or API domain.\n- **Folders:** Organize requests within collections using folders. Folders can represent different workflows or API endpoints. For example:\n  \n  MyProject\n  └── Collections\n      └── User Authentication\n          ├── Register User\n          ├── Login User\n          ├── Forgot Password\n          └── Reset Password\n  \n- **Environment Variables:** Use environments to manage different configurations (development, staging, production) without hardcoding sensitive information.\n- **File Naming Conventions:** Use consistent and descriptive names for collections, folders, and requests.\n  - `Collection`: `[ProjectName] - [APIDomain] API Tests` (e.g., `ECommerce - User Authentication API Tests`)\n  - `Folder`: `[Endpoint]` or `[Workflow]` (e.g., `/users` or `Register User Workflow`)\n  - `Request`: `[HTTPMethod] [EndpointDescription]` (e.g., `POST Register User`)\n\n## 2. Common Patterns and Anti-patterns\n\n- **Environment-Specific Variables:** Use environment variables to store values that change based on the environment (e.g., API URLs, authentication tokens). Create separate environments for development, staging, and production.\n\n  - **Pattern:** Create environment variables for the base URL, API keys, and other environment-specific settings.\n  - **Anti-pattern:** Hardcoding URLs or API keys directly into requests.\n\n- **Data-Driven Testing:** Use data-driven testing to run the same request multiple times with different data sets. This can be achieved by importing data from CSV or JSON files.\n\n  - **Pattern:** Use the Collection Runner to iterate through data files and automatically populate request parameters.\n  - **Anti-pattern:** Manually creating multiple requests with slightly different data.\n\n- **Reusing Code with Pre-request Scripts and Tests:** Use pre-request scripts to dynamically generate request parameters or perform setup tasks. Use test scripts to validate API responses and set variables for subsequent requests.\n\n  - **Pattern:** Use pre-request scripts to generate authentication tokens or timestamps. Use test scripts to extract data from responses and store them in environment variables for use in other requests.\n  - **Anti-pattern:** Duplicating the same code in multiple requests.\n\n- **Error Handling:** Implement robust error handling to gracefully handle unexpected API responses or network issues.\n\n  - **Pattern:** Check for error status codes (e.g., 4xx, 5xx) in your test scripts and log detailed error messages.\n  - **Anti-pattern:** Ignoring error responses or assuming that all requests will succeed.\n\n## 3. Performance Considerations\n\n- **Minimize Request Size:** Reduce the size of your requests by sending only the necessary data. Avoid including unnecessary headers or body parameters.\n- **Optimize Test Scripts:** Write efficient test scripts to minimize execution time. Avoid using complex or unnecessary logic in your test scripts.\n- **Use Monitors:** Utilize Postman Monitors to schedule regular performance tests and track API response times.\n- **Parallel Execution:** The collection runner in Postman executes requests sequentially. If parallel execution is required (for load testing, for example), consider Newman and external load testing tools.\n\n## 4. Security Best Practices\n\n- **Input Validation:** While Postman itself doesn't directly handle server-side input validation, your tests should validate that the API responds appropriately to invalid input.\n  - **Pattern:** Send requests with invalid or malicious input and verify that the API returns appropriate error messages and status codes.\n\n- **Authentication and Authorization:** Implement secure authentication and authorization mechanisms to protect your APIs.\n  - **Pattern:** Use environment variables to store API keys, tokens, and other credentials. Implement authentication flows (e.g., OAuth 2.0) in your collections.\n  - **Anti-pattern:** Hardcoding credentials directly into requests or storing them in plain text.\n\n- **Data Protection:** Ensure that sensitive data is encrypted in transit and at rest.\n  - **Pattern:** Use HTTPS to encrypt communication between Postman and your APIs. Implement data masking or redaction in your test scripts to prevent sensitive data from being exposed.\n\n## 5. Testing Approaches\n\n- **Unit Testing:** While traditional unit testing is not directly applicable to Postman, you can create individual requests to test specific API endpoints in isolation. This verifies the individual endpoint is returning expected data.\n- **Integration Testing:** Use collections to test the integration between different API endpoints. This verifies that data is passed correctly between different parts of your application.\n- **End-to-End Testing:** Create workflows to test the entire user experience, from start to finish. This verifies that all parts of your application are working together correctly.\n- **Test Organization:**\n  - Group tests by functionality.\n  - Use descriptive names for tests.\n  - Keep tests small and focused.\n\n- **Mocking and Stubbing:**\n  - Use Postman's mock server feature to create mock APIs for testing purposes. This allows you to test your application without relying on a live API.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Hardcoding Values:** Avoid hardcoding values directly into requests. Use environment variables instead.\n- **Ignoring Error Responses:** Always check for error responses and handle them appropriately.\n- **Not Versioning Collections:** Version your collections to track changes and ensure that your tests are up to date.\n- **Not Documenting Tests:** Document your tests to make them easier to understand and maintain.\n- **Misunderstanding Scope of Variables**: Be mindful of variable scope (global, collection, environment, local) and how it affects test execution.\n\n## 7. Tooling and Environment\n\n- **Postman CLI (Newman):** Use Newman to run Postman collections from the command line. This is essential for CI/CD integration.\n- **Version Control (Git):** Store your Postman collections in a Git repository to track changes and collaborate with team members.\n- **Linting and Formatting:** While Postman doesn't have built-in linting, ensure consistency in request structures and test scripts.\n\n  - **Build Configuration:** Use Newman with CI/CD tools (Jenkins, GitLab CI, GitHub Actions) to automate API testing.\n  - **Deployment:**  Deploy API specifications and Postman collections alongside your API for easier testing and documentation.",
    "metadata": {
      "globs": "*.postman_collection.json",
      "format": "mdc",
      "originalFile": "postman.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "postman",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "effectively",
      "using",
      "testing",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "postman",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-prisma",
    "description": "Enforces Prisma best practices for schema design, data access, and application security. Provides guidelines for writing efficient, secure, and maintainable Prisma applications.",
    "author": "sanjeed5",
    "tags": [
      "prisma",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/prisma.mdc",
    "content": "- **General Principles:**\n  - **Never expose the raw Prisma client directly in APIs.** Instead, create abstraction layers (e.g., repositories or services) to handle data access logic. This protects you from accidentally exposing sensitive database details and allows you to easily change your data access implementation in the future.\n  - **Always use input validation** before performing any database operations. Use a validation library like Zod or Yup to ensure that user input conforms to your expected schema and data types.  This helps prevent injection attacks and data corruption.\n  - **Implement row-level security (RLS) where applicable.** If your application handles sensitive data, use Prisma policies or database-level RLS to restrict data access based on user roles or permissions.  Carefully design your policies to prevent unauthorized data access.\n  - **Sanitize and validate all user inputs** to prevent injection attacks, such as SQL injection. Use Prisma's built-in features to escape user input and prevent it from being interpreted as code.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:**\n    - `prisma/`: Contains the `schema.prisma` file and any seed scripts or migrations.\n    - `src/`: Contains the main application code.\n    - `src/lib/prisma.ts`: A single module that exports an instance of the Prisma client. This promotes reuse and simplifies dependency injection.\n    - `src/models/`: Database model definitions as classes, abstracting Prisma calls.\n    - `src/repositories/`: Contains data access logic, abstracting Prisma queries.\n    - `src/services/`: Contains business logic, orchestrating data access through repositories.\n  - **File Naming Conventions:**\n    - Use descriptive names for files and directories that reflect their purpose.\n    - Use consistent naming conventions (e.g., camelCase for variables, PascalCase for components).\n  - **Module Organization:**\n    - Organize code into logical modules with clear responsibilities.\n    - Use dependency injection to decouple modules and improve testability.\n  - **Component Architecture:**\n    - Design components that are reusable, testable, and maintainable.\n    - Follow the single responsibility principle for each component.\n  - **Code Splitting Strategies:**\n    - Use dynamic imports to load code on demand and reduce initial bundle size.\n    - Split code based on routes, features, or user roles.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Repository Pattern:** Abstract data access logic behind repositories.\n    - **Service Layer Pattern:** Encapsulate business logic in service classes.\n    - **Unit of Work Pattern:** Manage transactions across multiple repositories.\n  - **Recommended Approaches:**\n    - Use Prisma's relation features to model complex relationships between entities.\n    - Use Prisma's transaction features to ensure data consistency.\n    - Use Prisma's filtering and sorting options to optimize queries.\n  - **Anti-patterns:**\n    - **Exposing the Prisma client directly to the client-side.** This is a major security risk.\n    - **Writing complex queries directly in components.** Move query logic to repositories or services.\n    - **Ignoring error handling.** Always handle potential errors when interacting with the database.\n  - **State Management:**\n    - Consider using a state management library like Redux, Zustand, or Jotai for complex applications.\n    - Use server-side data fetching for initial data loading and hydration.\n  - **Error Handling:**\n    - Use try-catch blocks to handle potential errors when interacting with the database.\n    - Log errors to a centralized logging system for monitoring and debugging.\n    - Return meaningful error messages to the client-side.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use Prisma's connection pooling to reduce database connection overhead.\n    - Use Prisma's batching features to reduce the number of database roundtrips.\n    - Optimize database queries by using indexes and filtering data on the server-side.\n  - **Memory Management:**\n    - Avoid loading large amounts of data into memory at once. Use pagination or streaming to process data in smaller chunks.\n    - Clean up resources after use, such as database connections and file handles.\n  - **Rendering Optimization:**\n    - Use virtualization for large lists or tables.\n    - Optimize images and other assets.\n  - **Bundle Size Optimization:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused code and dependencies.\n  - **Lazy Loading Strategies:**\n    - Load data on demand when it is needed.\n    - Use placeholders or skeletons to improve the user experience during loading.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - SQL injection: Prevented by using Prisma's prepared statements and escaping user input.\n    - Cross-site scripting (XSS): Prevented by sanitizing user input and output.\n    - Cross-site request forgery (CSRF): Prevented by using CSRF tokens.\n  - **Input Validation:**\n    - Use a validation library to validate all user input.\n    - Validate data types, lengths, and formats.\n  - **Authentication and Authorization:**\n    - Use a secure authentication library like NextAuth.js or Clerk.\n    - Implement role-based access control (RBAC) to restrict access to sensitive data and functionality.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between the client and server.\n  - **Secure API Communication:**\n    - Use API keys or tokens to authenticate API requests.\n    - Rate limit API requests to prevent abuse.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Test individual components and functions in isolation.\n    - Use mocking and stubbing to isolate components from external dependencies.\n  - **Integration Testing:**\n    - Test the interaction between different components and modules.\n    - Test database interactions using a test database.\n  - **End-to-End Testing:**\n    - Test the entire application from end to end.\n    - Use a testing framework like Cypress or Playwright.\n  - **Test Organization:**\n    - Organize tests into logical suites based on functionality.\n    - Use descriptive names for tests.\n  - **Mocking and Stubbing:**\n    - Use mocking to replace external dependencies with test doubles.\n    - Use stubbing to control the behavior of dependencies.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Forgetting to handle errors when interacting with the database.\n    - Exposing the Prisma client directly to the client-side.\n    - Writing complex queries directly in components.\n  - **Edge Cases:**\n    - Handling large datasets.\n    - Dealing with concurrency issues.\n    - Managing database migrations.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between Prisma versions.\n    - Use version control to manage dependencies.\n  - **Compatibility Concerns:**\n    - Ensure that your code is compatible with different browsers and devices.\n    - Test your application on different environments.\n  - **Debugging Strategies:**\n    - Use logging to track down errors.\n    - Use a debugger to step through code.\n    - Use Prisma's query logging feature to inspect database queries.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:**\n    - VS Code with the Prisma extension.\n    - Prisma Studio for visualizing and managing data.\n    - Docker for containerizing the application.\n  - **Build Configuration:**\n    - Use a build tool like Webpack, Parcel, or esbuild to bundle and optimize code.\n    - Configure the build tool to generate production-ready code.\n  - **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce code style and prevent errors.\n    - Configure the linter and formatter to use consistent settings across the project.\n  - **Deployment Best Practices:**\n    - Use a CI/CD pipeline to automate deployments.\n    - Deploy to a cloud platform like Vercel, Netlify, or AWS.\n  - **CI/CD Integration:**\n    - Integrate with CI/CD tools like GitHub Actions, GitLab CI, or CircleCI.\n    - Run tests and linters as part of the CI/CD pipeline.\n\n- **Specific Prisma Configuration:**\n  - **Schema Design:**\n    - Use clear and concise names for models and fields.\n    - Define relationships between models using Prisma's relation features.\n    - Use indexes to optimize query performance.\n    - Consider using enums for fields with a limited set of values.\n    - Properly use `@id`, `@unique`, and `@relation` directives for optimal schema design.\n  - **Data Types:**\n    - Use the appropriate data types for each field.\n    - Use `DateTime` for storing timestamps.\n    - Use `Json` for storing complex data structures.\n  - **Prisma Client Generation:**\n    - Ensure your `.env` file is correctly configured for database connection.\n    - Regularly update the Prisma client to the latest version.\n    - Use `prisma generate` to generate the client after schema changes.\n\n- **Query Optimization:**\n    - **Select only the necessary fields** to reduce the amount of data transferred from the database.\n    - **Use `include` and `select` carefully** to optimize the query shape.\n    - **Avoid N+1 queries** by using Prisma's `include` or `join` features.\n    - **Use pagination** to limit the number of results returned by a query.\n    - **Use `take` and `skip`** for efficient pagination.\n\n- **Transaction Management:**\n    - **Use Prisma's `prisma.$transaction` method** to ensure atomicity of database operations.\n    - **Handle potential errors** within the transaction to prevent data inconsistency.\n    - **Keep transactions short** to minimize the impact on database performance.\n\n- **Seed Data Management:**\n    - **Create a seed script** to populate the database with initial data.\n    - **Use Prisma's `prisma.create` method** to create seed data.\n    - **Use environment variables** to configure seed data for different environments.\n\n- **Migration Management:**\n    - **Use Prisma Migrate** to manage database schema changes.\n    - **Create migrations** for each schema change.\n    - **Apply migrations** to the database using `prisma migrate deploy`.\n    - **Use shadow database** to test migrations before deploying them to production.\n\n- **Monitoring and Logging:**\n    - **Use Prisma's query logging feature** to monitor database queries.\n    - **Log errors and warnings** to a centralized logging system.\n    - **Monitor database performance** using tools like Prometheus or Grafana.\n\n- **Further Study:**\n  - Always refer to the [official Prisma documentation](https://www.prisma.io/docs/) for the most up-to-date information.\n  - Consider taking an [official Prisma course](https://www.prisma.io/learn/).",
    "metadata": {
      "globs": "*.prisma",
      "format": "mdc",
      "originalFile": "prisma.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "prisma",
      "enforces",
      "best",
      "practices",
      "schema",
      "design",
      "data",
      "access",
      "application",
      "security",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "prisma",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-puppeteer",
    "description": "This rule file outlines best practices for Puppeteer, covering code organization, performance, security, testing, and common pitfalls. It aims to guide developers in building robust and maintainable Puppeteer applications.",
    "author": "sanjeed5",
    "tags": [
      "puppeteer",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/puppeteer.mdc",
    "content": "# Puppeteer Best Practices\n\nThis document outlines best practices for using Puppeteer, covering code organization, common patterns, performance, security, testing, and common pitfalls. Following these guidelines will help you write more robust, maintainable, and efficient Puppeteer applications.\n\n## 1. Code Organization and Structure\n\n### Directory Structure\n\nConsistent directory structure is crucial for maintainability. Here's a recommended structure:\n\n\nproject-root/\n├── src/\n│   ├── scrapers/       # Directory for specific scraping logic\n│   │   ├── product_scraper.js\n│   │   ├── news_scraper.js\n│   │   └── ...\n│   ├── utils/          # Utility functions (e.g., CSV export, error handling)\n│   │   ├── csv_utils.js\n│   │   ├── error_handler.js\n│   │   └── ...\n│   ├── config/         # Configuration files (e.g., URLs, selectors)\n│   │   ├── urls.js\n│   │   ├── selectors.js\n│   │   └── ...\n│   ├── models/         # Data models (e.g., Product, Article)\n│   │   ├── product.js\n│   │   ├── article.js\n│   │   └── ...\n│   ├── core/            # Core puppeteer setup and helper functions\n│   │   ├── browser_manager.js # Browser launch and closing\n│   │   ├── page_actions.js   # Reusable page interaction functions\n│   │   └── ...\n│   └── index.js        # Main entry point\n├── tests/\n│   ├── unit/\n│   ├── integration/\n│   └── e2e/\n├── .eslintrc.js        # ESLint configuration\n├── .prettierrc.js      # Prettier configuration\n├── package.json\n└── README.md\n\n\n### File Naming Conventions\n\n*   **Scrapers:** `[target_site]_scraper.js` (e.g., `amazon_scraper.js`, `twitter_scraper.js`)\n*   **Utility functions:** `[utility_name]_utils.js` (e.g., `csv_utils.js`, `string_utils.js`)\n*   **Configuration files:**  Use descriptive names like `urls.js`, `selectors.js`, `api_keys.js`.\n*   **Data models:** Singular nouns in PascalCase (e.g., `Product.js`, `Article.js`).\n*   **Core Files:**  `browser_manager.js`, `page_actions.js`, `request_interceptor.js`\n\n### Module Organization\n\n*   **Separate concerns:** Each module should have a single responsibility.  For example, one module handles browser launching, another handles navigation, and another handles data extraction.\n*   **Use ES modules:** Use `import` and `export` for better readability and maintainability.\n*   **Avoid circular dependencies:** Ensure modules don't depend on each other in a circular manner.\n\n### Component Architecture\n\n*   **Reusable components:** Create reusable components for common tasks like navigating to a page, filling out a form, or waiting for an element to load.  These can be organized into functions within the `core` directory and reused across multiple scrapers.\n*   **Configuration-driven:** Design components to be configurable via parameters or configuration files. This allows for easy adaptation to different websites or scraping scenarios.\n\n### Code Splitting\n\n*   **Scraper-specific bundles:** If you have multiple scrapers with significant code differences, consider creating separate bundles for each scraper to reduce initial load time.\n*   **Dynamic imports:** Use dynamic imports (`import()`) to load modules only when they are needed.  This can be useful for loading scraper-specific configurations or utility functions.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Strategy Pattern:** Use the strategy pattern to handle different scraping strategies for different websites or content types. Create an interface for scraping, and implement concrete strategies for each website.  This promotes code reusability and flexibility.\n*   **Factory Pattern:** Employ the factory pattern to create browser instances with specific configurations. This is especially useful when dealing with different browser profiles or proxy settings.\n*   **Page Object Model (POM):** Encapsulate page elements and interactions into separate page objects. This makes tests more readable and maintainable.\n*   **Observer Pattern:** Implement an observer pattern to monitor browser events (e.g., network requests, console messages) and react accordingly. This can be helpful for debugging and error handling.\n\n### Recommended Approaches\n\n*   **Resource Blocking:** Block unnecessary resources (images, CSS, fonts) to improve scraping speed and reduce bandwidth usage. Use `page.route()` to intercept requests and abort those that are not needed.\n*   **Dynamic Content Handling:** Use `page.waitForSelector()`, `page.waitForResponse()`, or `page.waitForFunction()` instead of fixed delays to ensure elements are loaded before interacting with them.  Always use try/catch blocks around these to gracefully handle timeouts.\n*   **Error Handling:** Implement robust error handling with `try...catch` blocks and logging.  Ensure browser instances are properly closed even if errors occur.\n*   **User-Agent Spoofing:** Set the `User-Agent` header to mimic real user behavior and avoid detection by anti-bot systems.\n*   **Proxy Rotation:** Use a proxy server and rotate it periodically to avoid IP bans.\n*   **Headless Mode vs. Headed Mode:** Use headless mode for faster execution but switch to headed mode for debugging when necessary. Consider `slowMo` to slow down execution in headed mode for better visibility.\n\n### Anti-patterns and Code Smells\n\n*   **Hardcoding selectors:** Avoid hardcoding CSS selectors or XPath expressions directly in your code.  Instead, store them in a configuration file or a separate module and reuse them.\n*   **Using fixed timeouts:** Avoid using `setTimeout` or `sleep` for waiting. Use `waitForSelector`, `waitForResponse`, or `waitForFunction` instead.\n*   **Ignoring errors:** Never ignore errors.  Always log errors and handle them gracefully.\n*   **Overly complex XPath expressions:** Avoid using overly complex XPath expressions that are prone to breaking when the page structure changes.  Use CSS selectors whenever possible.\n*   **Direct DOM scraping:** Try to extract data directly from API responses instead of scraping the DOM whenever possible. This is more efficient and stable.\n*   **Not closing the browser:** Failing to close the browser instance after the scraping task is complete leads to memory leaks and resource exhaustion.\n*   **Parallel scraping without control:** Launching too many parallel scrapers can overload the target server and lead to IP bans or performance issues. Implement rate limiting and concurrency control.\n\n### State Management\n\n*   **Stateless components:**  Design your scrapers to be as stateless as possible.  Pass all necessary data as arguments to functions or components.\n*   **Centralized configuration:** Store global configurations (e.g., API keys, URLs, proxy settings) in a centralized configuration file or environment variables.\n\n### Error Handling Patterns\n\n*   **Try-Catch Blocks:** Wrap Puppeteer operations within `try...catch` blocks to catch potential errors. Log the errors and handle them appropriately (e.g., retry the request, skip the item, or stop the scraper).\n*   **Global Error Handling:** Implement a global error handler to catch unhandled exceptions and prevent the application from crashing.\n*   **Retry Mechanism:** Implement a retry mechanism to automatically retry failed requests. Use exponential backoff to avoid overloading the target server.\n*   **Circuit Breaker:** Implement a circuit breaker pattern to prevent repeated failures from cascading and bringing down the scraper.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Resource Blocking:** Block unnecessary resources (images, CSS, fonts) using `page.route()`.\n*   **Viewport Optimization:** Set the viewport to a smaller size to reduce rendering time and memory usage.\n*   **JavaScript Optimization:** Minimize the amount of JavaScript that needs to be executed on the page. Use `evaluateHandle` for extracting complex data structures.\n*   **Caching:** Cache frequently accessed data to reduce the number of requests to the target server.\n*   **Concurrency Control:** Limit the number of concurrent browser instances or pages to avoid overloading the system or the target server. Use libraries like `p-queue` or `async` for managing concurrency.\n*   **Disable JavaScript if possible**: `await page.setJavaScriptEnabled(false)` can drastically improve performance if the target site doesn't require JavaScript for the data you need.\n*   **EvaluateHandle instead of evaluate**:  For returning complex objects use `evaluateHandle` rather than `evaluate`.  `evaluateHandle` returns a reference to the object in the browser, avoiding serialization overhead.\n\n### Memory Management\n\n*   **Close Browser Instances:** Always close browser instances and pages when they are no longer needed.  Use `browser.close()` and `page.close()`.\n*   **Avoid Memory Leaks:** Be mindful of memory leaks in your code, especially when using closures or event listeners.  Remove event listeners when they are no longer needed.\n*   **Garbage Collection:**  Force garbage collection periodically to release unused memory. This can be done using `await page.evaluate(() => gc());`. However, use this sparingly as it can impact performance.\n\n### Rendering Optimization\n\n*   **Disable GPU:** Disable GPU acceleration for headless browsers to reduce memory usage. Use the `--disable-gpu` flag when launching the browser.\n*   **Set Viewport:** `await page.setViewport({ width: 800, height: 600 });` Avoid very high resolutions when not needed.\n\n### Bundle Size Optimization\n\n*   **Tree Shaking:** Use a bundler like Webpack or Rollup with tree shaking enabled to remove unused code.\n*   **Code Minification:** Minify your JavaScript code to reduce its size.\n*   **Dependency Optimization:** Analyze your dependencies and remove any that are not needed.  Consider using smaller alternatives for large libraries.\n\n### Lazy Loading\n\n*   **Lazy Loading of Images:** If you are scraping images, consider lazy loading them to reduce initial page load time. Implement this on the scraped site side if applicable.\n*   **On-Demand Scraping:** Only scrape data that is currently needed. Defer scraping of less important data until it is requested.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and Prevention\n\n*   **Code Injection:** Prevent code injection by carefully validating any user-supplied input that is used in `evaluate()` or other code execution contexts. Avoid using `eval()` altogether.\n*   **Cross-Site Scripting (XSS):** Be aware of XSS vulnerabilities when scraping data from untrusted sources. Sanitize data before displaying it to users.\n*   **Denial of Service (DoS):** Implement rate limiting and concurrency control to prevent your scraper from overloading the target server and causing a denial of service.\n*   **IP Bans:** Use proxy servers and rotate them periodically to avoid IP bans.  Also, respect the target website's `robots.txt` file.\n\n### Input Validation\n\n*   **Sanitize User Input:** Sanitize any user-supplied input before using it in selectors or other code that interacts with the browser. Use libraries like `DOMPurify` to sanitize HTML.\n*   **Validate URLs:** Validate URLs before navigating to them using `page.goto()`.  Ensure that the URLs are safe and trusted.\n\n### Authentication and Authorization\n\n*   **Secure Credentials:** Store API keys, passwords, and other sensitive credentials securely using environment variables or a dedicated secrets management tool.  Never hardcode credentials in your code.\n*   **Session Management:** If you need to maintain a session with the target website, use cookies and store them securely.  Consider using the `page.cookies()` method to manage cookies.\n\n### Data Protection\n\n*   **Encryption:** Encrypt sensitive data before storing it.  Use libraries like `crypto` to encrypt data.\n*   **Data Masking:** Mask sensitive data (e.g., credit card numbers, social security numbers) before displaying it to users or storing it in logs.\n\n### Secure API Communication\n\n*   **HTTPS:** Always use HTTPS for API communication.  Verify that the server's SSL certificate is valid.\n*   **API Rate Limiting:** Implement rate limiting on your API endpoints to prevent abuse.\n*   **Authentication:** Use authentication to protect your API endpoints.  Consider using API keys or JWT tokens.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   **Mock Puppeteer Objects:** Mock Puppeteer objects (e.g., `browser`, `page`) to isolate units of code during testing. Use libraries like `jest-puppeteer` or `mock-puppeteer` for mocking.\n*   **Test Utility Functions:** Unit test utility functions (e.g., CSV export, error handling) to ensure they are working correctly.\n*   **Verify Logic:** Write unit tests to verify the logic of your scraping algorithms.\n\n### Integration Testing\n\n*   **Test Interactions:** Write integration tests to verify the interactions between different components of your scraper (e.g., browser launching, page navigation, data extraction).\n*   **Use Test Servers:** Use a test server or mock API to simulate the target website during integration testing. Libraries like `nock` can be helpful.\n*   **Verify Data Flow:** Write integration tests to verify that data is flowing correctly through your scraper.\n\n### End-to-End Testing\n\n*   **Simulate User Flows:** Write end-to-end tests to simulate real user flows and verify that the scraper is working as expected from start to finish.\n*   **Test Real Websites:** Test your scraper against real websites to ensure that it is robust and reliable.\n*   **Use Headless Mode:** Run end-to-end tests in headless mode for faster execution.\n*   **Screenshot Comparison**: Integrate screenshot comparison tools to detect visual regressions in your scraped data. This is particularly useful when target website layouts change frequently.\n\n### Test Organization\n\n*   **Separate Test Files:** Create separate test files for unit tests, integration tests, and end-to-end tests.\n*   **Use Descriptive Names:** Use descriptive names for your test files and test cases.\n*   **Organize Tests by Feature:** Organize your tests by feature or functionality.\n\n### Mocking and Stubbing\n\n*   **Mock Network Requests:** Mock network requests to avoid making real requests to the target server during testing. Use libraries like `nock` for mocking.\n*   **Stub Puppeteer Methods:** Stub Puppeteer methods (e.g., `page.goto()`, `page.$()`) to control the behavior of your scraper during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   **Not Handling Dynamic Content:** Failing to handle dynamic content and relying on fixed delays.\n*   **Using Brittle Selectors:** Using overly complex or fragile CSS selectors or XPath expressions.\n*   **Ignoring Errors:** Not handling errors gracefully and letting the scraper crash.\n*   **Not Closing Browser Instances:** Forgetting to close browser instances and leaking memory.\n*   **Not Respecting `robots.txt`:** Ignoring the `robots.txt` file and scraping restricted areas of the website.\n*   **Missing Rate Limiting:** Not implementing rate limiting and overloading the target server.\n*   **Incorrectly Handling Async Operations**: Forgetting to `await` asynchronous calls, leading to race conditions or unexpected behavior.\n\n### Edge Cases\n\n*   **Website Layout Changes:** Websites frequently change their layout, which can break your scraper. Implement robust selector strategies and monitor your scraper for errors.\n*   **Anti-Bot Measures:** Websites implement anti-bot measures to detect and block scrapers. Use techniques like user-agent spoofing, proxy rotation, and CAPTCHA solving to avoid detection.\n*   **Infinite Scroll:** Handling infinite scroll pages requires special attention to avoid scraping the same data multiple times. Use techniques like pagination or scroll-to-bottom with debouncing.\n*   **Frames and Iframes:** Dealing with content inside frames or iframes requires switching to the frame context before scraping.  Use `page.frame()` to get a frame and then interact with it.\n*   **Shadow DOM:** Accessing elements inside shadow DOM requires using `shadowRoot` property or special selectors.\n\n### Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of Puppeteer.  Consult the release notes for each version.\n*   **Chromium Updates:** Puppeteer is tied to specific versions of Chromium.  Chromium updates can sometimes break your scraper.  Test your scraper regularly after Chromium updates.\n\n### Compatibility Concerns\n\n*   **Node.js Version:** Ensure that you are using a compatible version of Node.js.  Refer to the Puppeteer documentation for compatibility information.\n*   **Operating System:** Puppeteer may behave differently on different operating systems.  Test your scraper on all target operating systems.\n\n### Debugging Strategies\n\n*   **Headless Mode:** Switch to headed mode for debugging to visually inspect the browser.  Use `headless: false` when launching the browser.\n*   **Console Logging:** Use `console.log()` to log debugging information to the console.  Capture console output from the page using `page.on('console', msg => console.log('PAGE LOG:', msg.text()));`\n*   **`slowMo` Option:** Use the `slowMo` option when launching the browser to slow down the execution and make it easier to follow along.  `const browser = await puppeteer.launch({ headless: false, slowMo: 50 });`\n*   **Debugger Statement:** Add `debugger;` statements to your code to pause execution and inspect variables in the Chrome DevTools.\n*   **Screenshot Debugging:**  Take screenshots at key points in the script execution to visually debug the page state.  `await page.screenshot({path: 'screenshot.png'});`\n*   **Performance Tracing:** Use Chrome DevTools to record a performance trace and identify performance bottlenecks.  `await page.tracing.start({path: 'trace.json'});` and `await page.tracing.stop();`\n*   **Browser DevTools:** Use `devtools: true` when launching puppeteer to directly show the Browser DevTools. `const browser = await puppeteer.launch({ devtools: true });`\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n*   **IDE:** Visual Studio Code (VS Code) is a popular choice for Puppeteer development due to its excellent JavaScript support, debugging capabilities, and extensions.\n*   **Debugger:** The Chrome DevTools debugger is essential for debugging Puppeteer code.  Use the debugger statement or launch the browser in headed mode to use the DevTools.\n*   **Linter:** ESLint helps enforce coding standards and identify potential errors. Configure ESLint with appropriate rules for Puppeteer code.\n*   **Formatter:** Prettier automatically formats your code to ensure consistency. Configure Prettier with appropriate settings for JavaScript code.\n\n### Build Configuration\n\n*   **Bundler:** Use a bundler like Webpack or Rollup to bundle your code and dependencies into a single file.  This simplifies deployment and improves performance.\n*   **Transpiler:** Use a transpiler like Babel to convert your code to a compatible version of JavaScript.\n*   **Environment Variables:** Use environment variables to configure your application for different environments (e.g., development, staging, production).\n\n### Linting and Formatting\n\n*   **ESLint:** Configure ESLint with recommended rules for Puppeteer code.  Use the `eslint:recommended` preset and customize it to fit your needs.\n*   **Prettier:** Configure Prettier with consistent settings for JavaScript code.  Use the `prettier` command to automatically format your code.\n*   **.editorconfig**: Use .editorconfig to enforce consistent coding styles across different editors.\n\n### Deployment Best Practices\n\n*   **Docker:** Use Docker to containerize your application and ensure consistency across different environments.  Create a Dockerfile that specifies the dependencies and configuration for your application.\n*   **Serverless Functions:** Deploy your scraper as a serverless function (e.g., AWS Lambda, Google Cloud Functions) to avoid managing servers.\n*   **Environment Variables:** Use environment variables to configure your application in the deployment environment.\n*   **CI/CD Pipeline:** Automate the deployment process using a CI/CD pipeline.  Use tools like Jenkins, GitLab CI, or GitHub Actions to build, test, and deploy your application.\n\n### CI/CD Integration\n\n*   **Automated Testing:** Integrate automated testing into your CI/CD pipeline to ensure that your scraper is working correctly before deploying it to production.  Run unit tests, integration tests, and end-to-end tests as part of the pipeline.\n*   **Code Quality Checks:** Integrate code quality checks into your CI/CD pipeline to ensure that your code meets coding standards and best practices.  Use ESLint and Prettier to check code quality.\n*   **Deployment Automation:** Automate the deployment process to ensure that your application is deployed consistently and reliably.  Use tools like Ansible or Terraform to automate deployment.\n*   **Monitor Deploys:** Integrate monitoring to immediately notify you of any broken deploys.\n\nBy following these best practices, you can develop robust, scalable, and maintainable Puppeteer applications.",
    "metadata": {
      "globs": "*.js",
      "format": "mdc",
      "originalFile": "puppeteer.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "puppeteer",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "puppeteer",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-pydantic",
    "description": "Comprehensive best practices and coding standards for utilizing Pydantic effectively in Python projects, covering code organization, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "pydantic",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pydantic.mdc",
    "content": "- **Model Definition:**\n  - Use `BaseModel` to define data schemas with type annotations for clarity and automatic validation.\n  - Prefer simple models that encapsulate a single concept to maintain readability and manageability.\n  - Use nested models for complex data structures while ensuring each model has clear validation rules.\n  - Always define a `Config` class within your model to control model behavior.\n\n- **Validation and Error Handling:**\n  - Implement built-in and custom validators to enforce data integrity.\n  - Utilize `@field_validator` for field-specific rules and `@root_validator` for cross-field validation.\n  - Ensure that validation errors are user-friendly and logged for debugging purposes.\n  - Custom error messages should be informative and guide the user on how to correct the data.\n  - Use `ValidationError` to catch and handle validation errors.\n\n- **Performance Optimization:**\n  - Consider using lazy initialization and avoid redundant validation where data is already trusted.\n  - Use Pydantic's configuration options to control when validation occurs, which can significantly enhance performance in high-throughput applications.\n  - Use `model_rebuild` to dynamically rebuild models when related schema change.\n  - Consider using `__slots__` in the `Config` class to reduce memory footprint.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:**\n    - Adopt a modular structure: `src/`, `tests/`, `docs/`.\n    - Models can reside in `src/models/`.\n    - Validators in `src/validators/`.\n    - Example:\n      \n      project_root/\n      ├── src/\n      │   ├── __init__.py\n      │   ├── models/\n      │   │   ├── __init__.py\n      │   │   ├── user.py\n      │   │   ├── item.py\n      │   ├── validators/\n      │   │   ├── __init__.py\n      │   │   ├── user_validators.py\n      │   ├── main.py  # Application entry point\n      ├── tests/\n      │   ├── __init__.py\n      │   ├── test_user.py\n      │   ├── test_item.py\n      ├── docs/\n      │   ├── ...\n      ├── .env\n      ├── pyproject.toml\n      ├── README.md\n      \n  - **File Naming:**\n    - Use snake_case for file names (e.g., `user_model.py`).\n    - Name model files after the primary model they define (e.g., `user.py` for `UserModel`).\n  - **Module Organization:**\n    - Group related models and validators into separate modules.\n    - Utilize `__init__.py` to make modules importable.\n  - **Component Architecture:**\n    - Employ a layered architecture (e.g., data access, business logic, presentation).\n    - Pydantic models are primarily used in the data access layer.\n  - **Code Splitting:**\n    - Split large models into smaller, manageable components using composition.\n    - Leverage inheritance judiciously.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Data Transfer Object (DTO):** Pydantic models serve as DTOs.\n    - **Factory Pattern:** Create model instances using factory functions for complex initialization.\n    - **Repository Pattern:** Use repositories to abstract data access and validation logic.\n  - **Recommended Approaches:**\n    - Centralize validation logic in dedicated validator functions.\n    - Utilize nested models for complex data structures.\n    - Use `BaseSettings` for managing application settings.\n  - **Anti-patterns:**\n    - Embedding business logic directly into models.\n    - Overly complex inheritance hierarchies.\n    - Ignoring validation errors.\n    - Performing I/O operations within validator functions.\n  - **State Management:**\n    - Use immutable models whenever possible to simplify state management.\n    - Consider using state management libraries like `attrs` or `dataclasses` in conjunction with Pydantic for complex applications.\n  - **Error Handling:**\n    - Raise `ValidationError` exceptions when validation fails.\n    - Provide informative error messages.\n    - Log validation errors for debugging.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use `model_rebuild` to recompile models when their schema changes.\n    - Leverage `__slots__` in the `Config` class to reduce memory footprint.\n    - Use the `@cached_property` decorator to cache expensive computations.\n  - **Memory Management:**\n    - Be mindful of large lists or dictionaries within models, as they can consume significant memory.\n    - Use generators or iterators for processing large datasets.\n  - **Efficient Data Parsing:**\n   -  Utilize `model_validate_json` and `model_validate` for efficient data parsing.\n  - **Controlling Validation:**\n    -  Use `validate_default` and `validate_assignment` options in the `Config` class to control validation occurrence.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - Injection attacks (e.g., SQL injection) if model data is used directly in database queries.\n    - Cross-site scripting (XSS) if model data is displayed in web pages without proper escaping.\n    - Deserialization vulnerabilities if models are deserialized from untrusted sources.\n  - **Input Validation:**\n    - Always validate all incoming data using Pydantic models.\n    - Use appropriate type annotations and constraints to restrict input values.\n    - Sanitize input data to remove potentially harmful characters or sequences.\n  - **Authentication and Authorization:**\n    - Use authentication and authorization mechanisms to restrict access to sensitive data.\n    - Implement role-based access control (RBAC) to grant different levels of access to different users.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms for storing API keys and other secrets.\n    - Mask sensitive data in logs and error messages.\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement API rate limiting to prevent denial-of-service attacks.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Test individual models and validators in isolation.\n    - Use parameterized tests to cover different input values and scenarios.\n    - Verify that validation errors are raised correctly.\n  - **Integration Testing:**\n    - Test the interaction between models and other components of the application.\n    - Use mock objects to simulate external dependencies.\n  - **End-to-End Testing:**\n    - Test the entire application flow from end to end.\n    - Use automated testing tools to simulate user interactions.\n  - **Test Organization:**\n    - Organize tests into separate modules based on the component being tested.\n    - Use descriptive test names to indicate the purpose of each test.\n  - **Mocking and Stubbing:**\n    - Use mock objects to simulate external dependencies such as databases or APIs.\n    - Use stub objects to provide predefined responses for certain functions or methods.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Misusing Union Types: Using `Union` incorrectly can complicate type validation and handling.\n    - Optional Fields without Default Values: Forgetting to provide a default value for optional fields can lead to `None` values causing errors in your application.\n    - Incorrect Type Annotations: Assigning incorrect types to fields can cause validation to fail. For example, using `str` for a field that should be an `int`.\n  - **Edge Cases:**\n    - Handling complex validation logic with dependencies between fields.\n    - Dealing with large or deeply nested data structures.\n    - Handling different input formats (e.g., JSON, CSV).\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between Pydantic versions.\n    - Consult the Pydantic documentation for migration guides.\n  - **Compatibility Concerns:**\n    - Ensure compatibility between Pydantic and other libraries used in your project.\n    - Be mindful of potential conflicts with other validation libraries.\n\n- **Tooling and Environment:**\n  - **Development Tools:**\n    - Use a code editor or IDE with Pydantic support (e.g., VS Code with the Pylance extension).\n    - Use a static type checker like MyPy to catch type errors.\n    - Use a linter like Flake8 or Pylint to enforce code style.\n  - **Build Configuration:**\n    - Use a build tool like Poetry or Pipenv to manage dependencies.\n    - Specify Pydantic as a dependency in your project's configuration file.\n  - **Linting and Formatting:**\n    - Configure a linter and formatter to enforce consistent code style.\n    - Use pre-commit hooks to automatically run linters and formatters before committing code.\n  - **Deployment:**\n    - Use a deployment platform that supports Python applications (e.g., Heroku, AWS Elastic Beanstalk, Docker).\n    - Configure your deployment environment to install Pydantic and its dependencies.\n  - **CI/CD:**\n    - Integrate Pydantic tests into your CI/CD pipeline.\n    - Automatically run tests and linters on every commit.\n\n- **Getting Started with Pydantic:**\n  - Install Pydantic with `pip install pydantic`\n  - Define your data models using `BaseModel` and type hints\n  - Validate your data by instantiating the data models\n  - Handle validation errors using `try...except ValidationError`\n\n- **Example:**\n  python\n  from pydantic import BaseModel, ValidationError\n  from typing import List, Optional\n\n  class Address(BaseModel):\n    street: str\n    city: str\n    zip_code: Optional[str] = None\n\n  class User(BaseModel):\n    id: int\n    name: str\n    email: str\n    addresses: List[Address]\n\n  try:\n    user_data = {\n        \"id\": 1,\n        \"name\": \"John Doe\",\n        \"email\": \"invalid-email\",\n        \"addresses\": [{\n            \"street\": \"123 Main St\",\n            \"city\": \"Anytown\"\n        }]\n    }\n    user = User(**user_data)\n    print(user)\n  except ValidationError as e:\n    print(e.json())",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pydantic.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pydantic",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "utilizing",
      "effectively",
      "python",
      "projects",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pydantic",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pygame",
    "description": "This rule provides comprehensive guidelines for pygame development, covering code organization, performance, security, testing, and common pitfalls. It aims to establish best practices and coding standards for building maintainable, efficient, and secure pygame applications.",
    "author": "sanjeed5",
    "tags": [
      "pygame",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pygame.mdc",
    "content": "---\n\n# Pygame Development Best Practices\n\nThis document outlines best practices and coding standards for developing games and multimedia applications using the Pygame library in Python. Adhering to these guidelines will result in more maintainable, efficient, and secure code.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nA well-organized directory structure is crucial for project maintainability. Consider the following structure:\n\n\nproject_name/\n├── assets/          # Images, sounds, fonts, etc.\n│   ├── images/\n│   ├── sounds/\n│   ├── fonts/\n│   └── ...\n├── src/             # Source code\n│   ├── main.py      # Entry point\n│   ├── modules/     # Custom modules\n│   │   ├── game.py  # Game logic\n│   │   ├── player.py # Player class\n│   │   ├── enemy.py  # Enemy class\n│   │   ├── ui.py     # UI elements\n│   │   └── ...\n│   └── ...\n├── tests/           # Unit and integration tests\n│   ├── test_game.py\n│   ├── test_player.py\n│   └── ...\n├── data/            # Game data (levels, configurations, etc.)\n├── docs/            # Documentation\n├── README.md        # Project description and instructions\n├── LICENSE          # License information\n├── requirements.txt # Dependencies\n└── .gitignore       # Files to ignore in Git\n\n\n### 1.2 File Naming Conventions\n\n*   **Python files:** Use lowercase with underscores (e.g., `player.py`, `game_state.py`).\n*   **Image files:** Use descriptive names (e.g., `player_idle.png`, `enemy_attack.png`).\n*   **Sound files:** Use descriptive names (e.g., `explosion.wav`, `jump.ogg`).\n*   **Font files:** Use the font name (e.g., `arial.ttf`).\n\n### 1.3 Module Organization\n\n*   **Modular design:** Break down your game into logical modules (e.g., `game`, `player`, `enemy`, `ui`).\n*   **Clear dependencies:** Avoid circular dependencies between modules.\n*   **Single responsibility principle:** Each module should have a clear and well-defined purpose.\n\n### 1.4 Component Architecture\n\nFor complex games, consider using a component-based architecture. This involves creating reusable components that can be attached to game objects to provide specific functionality.\n\nExample:\n\npython\nclass Component:\n    def __init__(self, owner):\n        self.owner = owner\n\n    def update(self, dt):\n        pass\n\nclass MovementComponent(Component):\n    def __init__(self, owner, speed):\n        super().__init__(owner)\n        self.speed = speed\n\n    def update(self, dt):\n        # Update movement logic based on input\n        ...\n\nclass Player(pygame.sprite.Sprite):\n    def __init__(self, x, y):\n        super().__init__()\n        self.image = pygame.Surface([32, 32])\n        self.image.fill((255, 0, 0))\n        self.rect = self.image.get_rect()\n        self.rect.x = x\n        self.rect.y = y\n        self.movement = MovementComponent(self, 200)\n\n    def update(self, dt):\n        self.movement.update(dt)\n        # Other update logic\n\n\n### 1.5 Code Splitting Strategies\n\n*   **Large files:** Split large files into smaller, more manageable modules.\n*   **Functional grouping:** Group related functions and classes into modules based on their functionality.\n*   **Layered architecture:** Separate your code into layers (e.g., presentation layer, logic layer, data access layer) to improve maintainability and testability.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Model-View-Controller (MVC):** Separate game data (model), UI (view), and input handling (controller).\n*   **Observer:** Implement event handling and communication between objects.\n*   **Factory:** Create objects without specifying their concrete classes.\n*   **Singleton:** Ensure that a class has only one instance.\n*   **State:** Encapsulate different states of a game object.\n*   **Command:** Encapsulate actions as objects to allow for undo/redo functionality.\n\n### 2.2 Recommended Approaches\n\n*   **Game loop:** Use a well-defined game loop for updating game state and rendering.\n*   **Event handling:** Implement a clear event handling loop to process user input and other events.\n*   **Surface management:** Use `Surface.convert()` when loading images to optimize rendering speed. Also ensure image types are optimized for the use case (e.g., .png for transparency, .jpg for photos).\n*   **Sprite groups:** Use sprite groups for managing and rendering multiple sprites.\n*   **Timers:** Use `pygame.time.Clock()` to control the frame rate and create timers for game events. Use `pygame.time.set_timer()` for creating custom events on a timer.  This avoids blocking the main thread.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **God classes:** Avoid creating classes that are too large and complex.\n*   **Spaghetti code:** Avoid writing code that is difficult to understand and maintain.\n*   **Tight coupling:** Avoid tight dependencies between modules.\n*   **Duplicated code:** Avoid repeating the same code in multiple places.\n*   **Premature optimization:** Avoid optimizing code before identifying performance bottlenecks.\n*   **Hardcoding values:** Avoid hardcoding values in your code; use constants or configuration files instead.\n\n### 2.4 State Management\n\n*   **State machines:** Use state machines to manage different game states (e.g., menu, playing, paused).\n*   **Centralized game state:** Store game state in a central location to make it accessible to all parts of the game.\n*   **Avoid global variables:** Minimize the use of global variables to reduce the risk of naming conflicts and improve code maintainability.\n\n### 2.5 Error Handling\n\n*   **Try-except blocks:** Use `try-except` blocks to handle exceptions gracefully.\n*   **Logging:** Use the `logging` module to log errors and other important events.\n*   **Custom exceptions:** Define custom exceptions for specific error conditions in your game.\n*   **Avoid bare except clauses:** Always specify the exception type you are catching to avoid masking unexpected errors.\n*   **Reraise exceptions when appropriate:** If you catch an exception but cannot handle it, reraise it to allow a higher-level handler to deal with it.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Surface.convert():** As mentioned, use `Surface.convert()` to optimize blitting speed.\n*   **Rect collision detection:** Use `Rect.colliderect()` for fast collision detection.\n*   **Sprite groups:** Utilize sprite groups for efficient rendering and collision detection.\n*   **Profile your code:** Use profiling tools to identify performance bottlenecks.\n*   **Optimize loops:** Minimize the number of iterations in your game loop.\n*   **Limit surface creation:** Avoid creating surfaces in your game loop; create them once and reuse them.\n*   **Pre-calculate values:** Pre-calculate values that are used frequently in your game loop.\n*   **Use vector math:** `pygame.math.Vector2` is significantly faster than manual tuple based calculations.\n*   **Use hardware acceleration:** Ensure that hardware acceleration is enabled by using the appropriate display flags (e.g., `pygame.HWSURFACE`, `pygame.DOUBLEBUF`).  Note `HWSURFACE` is deprecated in Pygame 2.0.0+\n\n### 3.2 Memory Management\n\n*   **Release surfaces:** Release surfaces that are no longer needed by setting them to `None`.\n*   **Avoid memory leaks:** Be careful not to create memory leaks by holding references to objects that are no longer needed.\n*   **Use generators:** Use generators to process large datasets without loading them entirely into memory.\n\n### 3.3 Rendering Optimization\n\n*   **Blitting:** Use `Surface.blit()` for fast image rendering.\n*   **Dirty rects:** Use dirty rects (updating only changed portions of the screen) to improve rendering performance when the screen is not fully updating every frame. (Less important on modern hardware)\n*   **Minimize draw calls:** Reduce the number of draw calls by batching them together.\n*   **Use layers:** Render different parts of the game on different layers to improve performance.\n*   **Optimize image sizes:** Use appropriately sized images to reduce memory usage and improve rendering speed.\n*   **Avoid transparency when not needed:** Surfaces without transparency can blit faster. Use `.convert()` or `.convert_alpha()` as needed.\n\n### 3.4 Bundle Size Optimization\n\n*   **Compress assets:** Use compression techniques to reduce the size of your game assets (images, sounds, fonts).\n*   **Remove unused assets:** Remove any assets that are not used in your game.\n*   **Optimize image formats:** Choose the most efficient image format for each asset (e.g., PNG, JPG).\n*   **Use appropriate audio formats:** Use compressed audio formats like OGG or MP3.\n\n### 3.5 Lazy Loading\n\n*   **Load assets on demand:** Load assets only when they are needed, instead of loading them all at the beginning of the game.\n*   **Use loading screens:** Display loading screens while assets are being loaded to provide feedback to the user.\n*   **Asynchronous loading:** Load assets in the background to avoid blocking the main thread.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Code injection:** Prevent code injection by validating user input and avoiding the use of `eval()` or `exec()`.\n*   **Data tampering:** Protect game data from tampering by using checksums or encryption.\n*   **Denial of service (DoS):** Protect your game server from DoS attacks by implementing rate limiting and input validation.\n*   **Save game exploits:** Validate save game data, using encryption and/or checksums, to prevent save game exploits.\n\n### 4.2 Input Validation\n\n*   **Validate all user input:** Validate all user input to prevent code injection, data tampering, and other security vulnerabilities.\n*   **Use whitelists:** Use whitelists to specify the allowed characters and values for user input.\n*   **Sanitize user input:** Sanitize user input to remove potentially harmful characters and code.\n\n### 4.3 Authentication and Authorization\n\n*   **User authentication:** Implement user authentication to verify the identity of players.\n*   **Role-based access control:** Use role-based access control to restrict access to certain features and resources based on the player's role.\n*   **Secure communication:** Use HTTPS to encrypt communication between the game client and server.\n\n### 4.4 Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data, such as passwords and credit card numbers.\n*   **Store data securely:** Store data securely using appropriate storage mechanisms (e.g., databases, key-value stores).\n*   **Protect against data breaches:** Implement measures to protect against data breaches, such as regular backups and security audits.\n\n### 4.5 Secure API Communication\n\n*   **Use HTTPS:** Always use HTTPS for API communication to encrypt data in transit.\n*   **Authenticate requests:** Authenticate all API requests to prevent unauthorized access.\n*   **Authorize requests:** Authorize all API requests to ensure that users have the necessary permissions to access the requested resources.\n*   **Validate responses:** Validate API responses to prevent data injection and other security vulnerabilities.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test individual components:** Write unit tests for individual components to ensure that they function correctly.\n*   **Use a testing framework:** Use a testing framework like `unittest` or `pytest` to write and run unit tests.\n*   **Mock dependencies:** Use mocking to isolate components from their dependencies.\n*   **Test edge cases:** Test edge cases to ensure that your code handles unexpected input and conditions gracefully.\n*   **Aim for high test coverage:** Aim for high test coverage to ensure that most of your code is tested.\n\n### 5.2 Integration Testing\n\n*   **Test interactions between components:** Write integration tests to ensure that components work together correctly.\n*   **Test the game loop:** Test the game loop to ensure that it updates the game state and renders the screen correctly.\n*   **Test user input:** Test user input to ensure that it is handled correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Test the entire game:** Write end-to-end tests to test the entire game from start to finish.\n*   **Automate testing:** Automate testing using tools like Selenium or Appium.\n*   **Test on multiple platforms:** Test your game on multiple platforms to ensure that it works correctly on all of them.\n\n### 5.4 Test Organization\n\n*   **Separate test files:** Store test files in a separate directory from your source code.\n*   **Use descriptive test names:** Use descriptive test names to make it clear what each test is testing.\n*   **Organize tests by module:** Organize tests by module to make it easier to find and run tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock dependencies:** Use mocking to replace dependencies with mock objects that can be controlled and inspected during testing.\n*   **Stub out complex logic:** Use stubbing to replace complex logic with simpler implementations that return predefined values.\n*   **Use a mocking framework:** Use a mocking framework like `unittest.mock` or `pytest-mock` to create mock objects and stubs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Forgetting to call `pygame.init()`:** This is a common mistake that can lead to unexpected errors.\n*   **Not handling events:** Not handling events can cause the game to freeze or crash.\n*   **Not updating the display:** Not updating the display will cause the screen to remain blank.\n*   **Using the wrong color format:** Using the wrong color format can lead to incorrect colors being displayed.\n*   **Not releasing surfaces:** Not releasing surfaces can lead to memory leaks.\n*   **Inadequate collision detection:** Basic rectangle based collision, while fast, can lead to visually incorrect collisions.  Consider using circular collision or per pixel collision in these cases.\n\n### 6.2 Edge Cases\n\n*   **Window resizing:** Handle window resizing correctly to ensure that the game continues to work as expected.\n*   **Fullscreen mode:** Test your game in fullscreen mode to ensure that it works correctly.\n*   **Multiple monitors:** Test your game on systems with multiple monitors to ensure that it works correctly.\n*   **Different screen resolutions:** Test your game on different screen resolutions to ensure that it scales correctly.\n\n### 6.3 Version-Specific Issues\n\n*   **Pygame 1 vs Pygame 2:** Be aware of compatibility issues between Pygame 1 and Pygame 2. Some functions and classes have been deprecated or renamed in Pygame 2.\n\n### 6.4 Compatibility Concerns\n\n*   **Operating systems:** Test your game on different operating systems (Windows, macOS, Linux) to ensure that it works correctly on all of them.\n*   **Graphics drivers:** Be aware of potential compatibility issues with different graphics drivers.\n*   **Python versions:** Test your game with different Python versions to ensure compatibility.\n\n### 6.5 Debugging Strategies\n\n*   **Use print statements:** Use print statements to debug your code and track the values of variables.\n*   **Use a debugger:** Use a debugger to step through your code and inspect the state of your program.\n*   **Read error messages:** Pay attention to error messages and use them to identify the cause of the error.\n*   **Search for solutions:** Search online for solutions to common problems.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Text editor/IDE:** Use a text editor or IDE with Python support (e.g., VS Code, PyCharm).\n*   **Version control system:** Use a version control system like Git to track changes to your code.\n*   **Package manager:** Use a package manager like pip to manage dependencies.\n*   **Debugging tools:** Use debugging tools to step through your code and inspect the state of your program.\n*   **Profiling tools:** Use profiling tools to identify performance bottlenecks.\n\n### 7.2 Build Configuration\n\n*   **Use a build system:** Use a build system like Make or CMake to automate the build process.\n*   **Specify dependencies:** Specify dependencies in a `requirements.txt` file.\n*   **Use virtual environments:** Use virtual environments to isolate dependencies for each project.\n\n### 7.3 Linting and Formatting\n\n*   **Use a linter:** Use a linter like pylint or flake8 to identify potential errors and style issues.\n*   **Use a formatter:** Use a formatter like black or autopep8 to automatically format your code.\n*   **Follow PEP 8:** Follow the PEP 8 style guide for Python code.\n\n### 7.4 Deployment\n\n*   **Use a packaging tool:** Use a packaging tool like PyInstaller or cx_Freeze to create standalone executables of your game.\n*   **Create installers:** Create installers for different platforms to make it easy for users to install your game.\n*   **Consider using a game distribution platform:** Publish your game on a game distribution platform like Steam or Itch.io.\n\n### 7.5 CI/CD Integration\n\n*   **Use a CI/CD system:** Use a CI/CD system like Jenkins or GitHub Actions to automate the build, test, and deployment process.\n*   **Run tests automatically:** Run tests automatically on every commit to ensure that the code is always working correctly.\n*   **Deploy automatically:** Deploy your game automatically to staging or production environments.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pygame.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "pygame",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "organization",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pygame",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-pylint",
    "description": "This rule file provides comprehensive best practices for using Pylint to ensure high-quality, maintainable, and secure Python code. It covers code organization, common patterns, performance, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "pylint",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pylint.mdc",
    "content": "# Pylint Best Practices: A Comprehensive Guide\n\nThis document outlines the best practices for using Pylint, a widely used static code analysis tool for Python. Following these guidelines will help you write cleaner, more maintainable, and secure code.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n*   **Project Root:** Contains core project files (`README.md`, `LICENSE`, `.gitignore`, `setup.py` or `pyproject.toml`, `.pylintrc`).\n*   **Source Directory (`src/` or project_name/`):** Holds the main application code.\n    *   Organize code into modules and subpackages based on functionality (e.g., `src/models`, `src/views`, `src/controllers`, `src/utils`).\n    *   Use clear and descriptive names for modules and packages.\n*   **Tests Directory (`tests/`):** Contains unit, integration, and end-to-end tests.\n    *   Mirror the source directory structure for easier navigation (e.g., `tests/models`, `tests/views`).\n*   **Docs Directory (`docs/`):** Stores project documentation (using Sphinx, MkDocs, etc.).\n*   **Scripts Directory (`scripts/`):** Contains utility scripts for development, deployment, etc.\n*   **Configuration Directory (`config/`):** Stores configuration files for different environments (development, staging, production).\n\nExample:\n\n\nmy_project/\n├── .gitignore\n├── .pylintrc\n├── pyproject.toml\n├── README.md\n├── src/\n│   ├── __init__.py\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── user.py\n│   │   └── item.py\n│   ├── views/\n│   │   ├── __init__.py\n│   │   ├── user_view.py\n│   │   └── item_view.py\n│   └── utils/\n│       ├── __init__.py\n│       └── helper_functions.py\n├── tests/\n│   ├── __init__.py\n│   ├── models/\n│   │   ├── test_user.py\n│   │   └── test_item.py\n│   └── views/\n│       ├── __init__.py\n│       └── test_user_view.py\n└── docs/\n    └── ...\n\n\n### 1.2 File Naming Conventions\n\n*   Use lowercase with underscores for module and package names (e.g., `user_model.py`, `data_processing/`).\n*   Class names should use CamelCase (e.g., `UserModel`).\n*   Constants should be in uppercase with underscores (e.g., `MAX_USERS`).\n*   Test files should be named `test_*.py`.\n\n### 1.3 Module Organization\n\n*   Each module should have a single, well-defined responsibility.\n*   Avoid circular dependencies between modules.\n*   Use `__init__.py` files to define packages and control imports.\n*   Keep modules relatively small (e.g., less than 500 lines of code).\n*   Follow the \"Explicit is better than implicit\" principle. Use explicit imports rather than `from module import *`.\n\n### 1.4 Component Architecture\n\n*   **Layered Architecture:** Separate concerns into distinct layers (e.g., presentation, business logic, data access).\n*   **Microservices Architecture:** Decompose the application into small, independent services.\n*   **Hexagonal Architecture (Ports and Adapters):** Decouple the core logic from external dependencies.\n*   **MVC (Model-View-Controller):** A common pattern, separating data (Model), presentation (View), and user input handling (Controller).\n\nChoose an architecture that suits the complexity and scale of your project. Ensure that pylint can analyze each component effectively by providing clear interfaces and minimal inter-component dependencies.\n\n### 1.5 Code Splitting Strategies\n\n*   **Functional Decomposition:** Split code into functions based on specific tasks.\n*   **Class-Based Decomposition:** Group related functions and data into classes.\n*   **Module-Based Decomposition:** Organize classes and functions into modules based on their domain.\n*   **Package-Based Decomposition:** Group related modules into packages.\n*   **Vertical Slicing**: Create independent, deployable features from end-to-end (UI to database)\n\nApply these strategies iteratively as your codebase grows.  Keep pylint's static analysis capabilities in mind; avoid excessively complex functions or classes that can become difficult for pylint to analyze effectively.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Factory Pattern:** Use factory functions or classes to create objects, promoting loose coupling and testability.\n*   **Singleton Pattern:** Ensure that a class has only one instance, providing a global point of access.\n*   **Observer Pattern:** Define a one-to-many dependency between objects, so that when one object changes state, all its dependents are notified and updated automatically.\n*   **Strategy Pattern:** Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\n*   **Dependency Injection:** Provide dependencies to a component rather than having it create them internally, increasing flexibility and testability.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Configuration Management:** Use libraries like `ConfigParser`, `Dynaconf` or `pydantic-settings` to manage application configuration.\n*   **Logging:** Use the `logging` module for structured logging.\n*   **Data Validation:** Use libraries like `Pydantic` or `Marshmallow` to validate data.\n*   **API Requests:** Use the `requests` library for making HTTP requests.\n*   **Date and Time Handling:** Use the `datetime` module for date and time operations.\n*   **Use Context Managers (`with` statements) whenever working with external resources like files, network connections, etc. to ensure proper cleanup.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Long Methods/Functions:** Functions or methods exceeding a reasonable length (e.g., 50 lines) are hard to understand and maintain. Split them into smaller, more focused units.\n*   **Duplicate Code:** Avoid copy-pasting code. Extract common logic into reusable functions or classes.\n*   **Magic Numbers:** Use named constants instead of hardcoded values.\n*   **Feature Envy:** A method accesses the data of another object more than its own. Move the method to the object it uses the most.\n*   **God Class/Object:** A class that knows or does too much. Split it into smaller, more specialized classes.\n*   **Spaghetti Code:** Code with a complex and tangled control structure, making it difficult to follow the logic. Refactor it into a more structured design.\n*   **Shotgun Surgery:** Whenever you make one kind of change, you have to make many small changes to a lot of different classes. Consolidate changes into fewer classes.\n*   **Primitive Obsession:** Using primitive data types to represent domain concepts. Create dedicated classes instead.\n*   **Data Clumps:** Groups of variables that appear together in many places. Create a class to encapsulate them.\n\n### 2.4 State Management\n\n*   **Minimize Mutable State:** Favor immutable data structures to reduce complexity and potential errors.\n*   **Centralized State Management:** Use patterns like Redux or Context API (if applicable) to manage application state in a central location.\n*   **Clear State Transitions:** Define clear and predictable state transitions to avoid unexpected behavior.\n*   **Avoid Global State:** Global state can make code harder to reason about and test. Use dependency injection or other techniques to manage dependencies.\n\n### 2.5 Error Handling\n\n*   **Specific Exception Handling:** Catch specific exceptions rather than generic `Exception` to handle errors appropriately.\n*   **Use `try...except...finally`:** Ensure that resources are released properly, even if an exception occurs.\n*   **Avoid Bare `except` Clauses:**  Always specify the exception type you are catching.\n*   **Logging Exceptions:** Log detailed information about exceptions for debugging purposes.\n*   **Raise Exceptions Responsibly:** Raise exceptions when an error occurs that cannot be handled locally. Provide meaningful error messages.\n*   **Use Custom Exceptions:**  Create custom exception classes for specific error scenarios in your application, improving clarity and maintainability.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Profiling:** Use profiling tools like `cProfile` to identify performance bottlenecks.\n*   **Algorithmic Optimization:** Choose efficient algorithms and data structures for critical tasks.\n*   **Caching:** Use caching techniques to store frequently accessed data and reduce computation time (e.g., `functools.lru_cache`).\n*   **List Comprehensions and Generators:** Use list comprehensions and generators for concise and efficient code.\n*   **Avoid Premature Optimization:** Optimize code only after identifying actual performance bottlenecks.\n*   **Use vectorized operations with NumPy when dealing with numerical computations to leverage performance.\n\n### 3.2 Memory Management\n\n*   **Avoid Memory Leaks:** Ensure that objects are properly deallocated when they are no longer needed.\n*   **Use Generators:** Use generators to process large datasets in chunks, reducing memory usage.\n*   **Minimize Object Creation:** Avoid creating unnecessary objects to reduce memory overhead.\n*   **Use Data Structures Wisely:** Choose appropriate data structures based on memory usage and performance characteristics.\n*   **Use the `del` keyword when you are completely finished with a variable that is holding a large data structure, allowing the garbage collector to reclaim the memory.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n*   This is more relevant to UI applications or cases where Pylint is integrated into a tool with a visual output.\n*   **Virtualization/Windowing**: Only render what is visible on the screen, especially for long lists or tables.\n*   **Debouncing/Throttling**: Limit the frequency of updates to the display.\n\n### 3.4 Bundle Size Optimization (If Applicable)\n\n*   This mainly applies if you are building a web application or a desktop app where Pylint analysis is integrated as part of the build process.  Minimize dependencies, tree shake (remove unused code), and compress the output.\n\n### 3.5 Lazy Loading\n\n*   **Lazy Loading Modules:** Use lazy loading to load modules only when they are needed.\n*   **Lazy Loading Data:** Fetch data only when it is required by the user or the application.\n*   **Avoid Eager Loading:** Avoid loading large datasets or resources upfront.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Use CSRF tokens to protect against CSRF attacks.\n*   **Command Injection:** Avoid executing arbitrary commands based on user input.\n*   **Path Traversal:** Validate file paths to prevent path traversal attacks.\n*   **Regularly update your dependencies to patch security vulnerabilities.\n\n### 4.2 Input Validation\n\n*   **Validate All User Input:** Validate all user input to ensure that it is valid and safe.\n*   **Use Regular Expressions:** Use regular expressions to validate input patterns.\n*   **Sanitize Input:** Sanitize input to remove or escape potentially harmful characters.\n*   **Limit Input Length:** Limit the length of input fields to prevent buffer overflows.\n\n### 4.3 Authentication and Authorization\n\n*   **Use Strong Passwords:** Enforce strong password policies and use password hashing algorithms (e.g., bcrypt, Argon2).\n*   **Implement Role-Based Access Control (RBAC):** Define roles and permissions to control access to resources.\n*   **Use Multi-Factor Authentication (MFA):** Add an extra layer of security with MFA.\n*   **Secure Session Management:** Use secure session management techniques to protect user sessions.\n\n### 4.4 Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Use Secure Protocols:** Use secure protocols like HTTPS for communication.\n*   **Data Masking:** Mask sensitive data when it is not needed.\n*   **Data Anonymization:** Anonymize data to protect user privacy.\n\n### 4.5 Secure API Communication\n\n*   **Use Authentication Tokens:** Use authentication tokens to authenticate API requests (e.g., JWT).\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Validation:** Validate all input to API endpoints.\n*   **Output Sanitization:** Sanitize output from API endpoints to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Individual Components:** Write unit tests for individual functions, classes, and modules.\n*   **Use Assertions:** Use assertions to verify that the code behaves as expected.\n*   **Test Edge Cases:** Test edge cases and boundary conditions.\n*   **Test Exception Handling:** Test that exceptions are raised and handled correctly.\n*   **Isolate Tests:** Ensure that unit tests are isolated and do not depend on external resources.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions:** Write integration tests to verify that different components work together correctly.\n*   **Test API Endpoints:** Test API endpoints to ensure that they are functioning as expected.\n*   **Test Database Interactions:** Test database interactions to ensure that data is being stored and retrieved correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate User Flows:** Write end-to-end tests to simulate user flows and verify that the application behaves as expected from a user's perspective.\n*   **Test UI Interactions:** Test UI interactions to ensure that the UI is functioning correctly.\n*   **Test System Behavior:** Test overall system behavior and performance.\n\n### 5.4 Test Organization\n\n*   **Mirror Source Directory:** Organize tests in a directory structure that mirrors the source directory structure.\n*   **Use Descriptive Names:** Use descriptive names for test files and test functions.\n*   **Separate Test Files:** Separate unit tests, integration tests, and end-to-end tests into separate files.\n*   **Use a Test Runner:** Use a test runner like `pytest` or `unittest` to run tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocks:** Use mocks to replace external dependencies with controlled test doubles.\n*   **Use Stubs:** Use stubs to provide predefined responses for external dependencies.\n*   **Isolate Units Under Test:** Use mocking and stubbing to isolate the unit under test and prevent dependencies from affecting test results.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Ignoring Pylint Warnings:** Ignoring Pylint warnings can lead to code quality issues and potential bugs. Always address Pylint warnings promptly.\n*   **Over-Suppressing Messages:** Over-suppressing Pylint messages can hide important issues. Only suppress messages when you are certain that they are not relevant.\n*   **Not Customizing Pylint Configuration:** Not customizing the Pylint configuration to match your project's needs can result in irrelevant warnings and missed issues. Customize the configuration to suit your project.\n*   **Using Broad Exceptions:** Using broad exception clauses (e.g., `except Exception:`) can catch unintended exceptions and hide potential problems.\n*   **Not Testing Edge Cases:** Not testing edge cases can lead to unexpected behavior and bugs.\n*   **Not Using Virtual Environments:** Failing to use virtual environments can lead to dependency conflicts and deployment issues.\n\n### 6.2 Edge Cases\n\n*   **Dynamic Code Generation:** Pylint may have difficulty analyzing code that is dynamically generated at runtime.\n*   **Complex Metaclasses:** Complex metaclasses can confuse Pylint and lead to false positives.\n*   **Third-Party Libraries:** Pylint may not fully support all third-party libraries.\n*   **Cython Extensions:** Cython extensions may not be analyzed correctly by Pylint.\n*   **Monkey Patching**: Dynamic modification of code at runtime can confuse pylint and potentially lead to incorrect analysis.\n\n### 6.3 Version-Specific Issues\n\n*   **Compatibility Issues:** Different versions of Pylint may have compatibility issues with different versions of Python and third-party libraries.\n*   **Message Changes:** Pylint messages may change between versions, requiring updates to your configuration.\n*   **Checker Updates:** New checkers may be added in new versions of Pylint, requiring updates to your codebase.\n\n### 6.4 Compatibility Concerns\n\n*   **Black/Autopep8:** Ensure that Pylint's formatting rules are compatible with formatters like Black or Autopep8 to avoid conflicts.\n*   **Mypy:** Use Mypy to complement Pylint's static analysis with type checking.\n*   **Flake8:** Consider using Flake8 alongside Pylint for additional linting checks.\n\n### 6.5 Debugging Strategies\n\n*   **Read Error Messages Carefully:** Pylint error messages provide valuable information about the cause of the error.\n*   **Use `--verbose`:** Use the `--verbose` flag to get more detailed output from Pylint.\n*   **Isolate the Problem:** Try to isolate the problem to a specific function, class, or module.\n*   **Use a Debugger:** Use a debugger to step through the code and identify the cause of the error.\n*   **Consult the Pylint Documentation:** The Pylint documentation provides detailed information about all of Pylint's features and messages.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code with Python Extension:** VS Code is a popular code editor with excellent Python support.\n*   **PyCharm:** PyCharm is a powerful IDE for Python development.\n*   **Pylance (VS Code extension):** A fast, feature-rich language server for Python in VS Code.\n*   **Docker:** Use Docker for consistent and reproducible development environments.\n\n### 7.2 Build Configuration\n\n*   **Use a Build System:** Use a build system like `Make`, `Poetry`, or `tox` to automate build tasks.\n*   **Define Dependencies:** Define dependencies in a `requirements.txt` or `pyproject.toml` file.\n*   **Use Virtual Environments:** Use virtual environments to isolate project dependencies.\n*   **Automate Pylint Execution:** Automate Pylint execution as part of the build process.\n*   **Include .pylintrc:** Ensure that the `.pylintrc` file is included in the project repository.\n\n### 7.3 Linting and Formatting\n\n*   **Use a Code Formatter:** Use a code formatter like `Black` or `Autopep8` to automatically format code.\n*   **Integrate with Editor:** Integrate Pylint and the code formatter with your code editor for real-time feedback.\n*   **Use Pre-Commit Hooks:** Use pre-commit hooks to run Pylint and the code formatter before committing changes.\n*   **Address all linting and formatting issues consistently.\n\n### 7.4 Deployment\n\n*   **Use a Deployment Pipeline:** Use a deployment pipeline to automate the deployment process.\n*   **Test Before Deployment:** Run unit tests, integration tests, and end-to-end tests before deploying the application.\n*   **Monitor Application:** Monitor the application after deployment to detect and resolve issues.\n*   **Use a Configuration Management Tool:** Use a configuration management tool like Ansible or Chef to manage application configuration in production.\n\n### 7.5 CI/CD Integration\n\n*   **Integrate with CI/CD System:** Integrate Pylint with your CI/CD system (e.g., Jenkins, GitLab CI, GitHub Actions).\n*   **Run Pylint in CI/CD Pipeline:** Run Pylint as part of the CI/CD pipeline to automatically check code quality.\n*   **Fail Build on Errors:** Configure the CI/CD pipeline to fail the build if Pylint reports any errors.\n*   **Collect Metrics:** Collect metrics from Pylint runs to track code quality over time.\n*   **Use code review processes and tools to enforce coding standards.\n\nBy adhering to these best practices, you can leverage Pylint to create high-quality, maintainable, and secure Python code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pylint.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pylint",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "ensure",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pylint",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pyqt",
    "description": "This rule file provides comprehensive guidelines for PyQt development, covering code organization, common patterns, performance, security, testing, and tooling. It aims to help developers create maintainable, efficient, and secure PyQt applications.",
    "author": "sanjeed5",
    "tags": [
      "pyqt",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pyqt.mdc",
    "content": "- **Follow Consistent Importing:**\n  - Avoid wildcard imports like `from PyQt5.QtGui import *`. They clutter the namespace and can lead to naming conflicts.\n  - Instead, import only the necessary modules or classes, e.g., `from PyQt5 import QtGui` and access members with the module prefix: `QtGui.QPushButton`.\n  - *Rationale:* Improves code readability and avoids potential namespace collisions.\n\n- **Adhere to Naming Conventions:**\n  - Follow Qt's camelCase style for method names (e.g., `loadItems()`, `refreshResults()`). This maintains consistency with the Qt API and reduces confusion.\n  - For signals and slots, consistently use camelCase.\n  - *Rationale:* Ensures consistency with Qt's API and reduces cognitive load for developers.\n\n- **Separate GUI and Business Logic (MVC or similar):**\n  - Keep GUI code separate from business logic using patterns like Model-View-Controller (MVC), Model-View-Presenter (MVP), or Model-View-ViewModel (MVVM).\n  - *Model:* Represents the data and business logic.\n  - *View:* Displays the data to the user.\n  - *Controller/Presenter/ViewModel:* Handles user input and updates the Model and View.\n  - *Rationale:* Enhances maintainability, testability, and scalability by decoupling concerns.\n\n- **Leverage Qt Designer (or Alternatives):**\n  - Use Qt Designer (or alternative tools like QML) for layout management and rapid prototyping.\n  - Load the generated `.ui` files into your Python code using `PyQt6.uic.loadUi`.\n  - *Rationale:* Speeds up GUI development and simplifies layout design.\n\n- **Employ Signals and Slots:**\n  - Use Qt's signals and slots mechanism for communication between objects.\n  - Connect signals to slots using `QObject.connect()` or the newer, more Pythonic syntax in PyQt6.\n  - *Rationale:* Provides a type-safe and flexible way to handle events and user interactions.\n\n- **Protect UI Members:**\n  - Treat UI components defined in Qt Designer as protected or private members.\n  - Provide access to child widgets of your class through methods instead of direct access.\n  - *Rationale:* Facilitates future modifications to the UI without breaking external code.\n\n- **Naming Conventions for Designer Components:**\n  - Adopt a consistent naming convention for UI components created in Qt Designer.\n  - Use prefixes like `ui_` to indicate that a component was created in Designer (e.g., `ui_project_combo`, `uiProjectCombo`). Append the component type.\n  - *Rationale:* Improves code readability and makes it easier to identify the origin and purpose of UI components.\n\n- **Getter and Setter Guidelines:**\n  - Use getter and setter methods to access and modify internal data instead of directly exposing public members. Use camelCase for both the getter and setter methods.\n  - Create protected members using a single leading underscore (e.g., `_value`).\n  - *Rationale:* Provides encapsulation, allows for future changes to the internal implementation, and maintains consistency with Qt's style.\n\n- **Never Expose Public Members in Qt Classes:**\n  - In Python, there isn't a strict public/protected/private syntax, but use underscores to flag different types of data.\n  - Python uses underscores to flag different types of data.\n     - `No underscores`: public variable/member\n     - `1 opening underscore`: protected variable/member\n     - `1 trailing underscore`: used when defining a variable that would otherwise clash with a Python internal\n     - `2 opening underscores`: private variable/member (does some funkiness under the hood so it becomes pretty hard to access from outside your class or module)\n     - `2 opening underscores and 2 trailing underscores`: built-in, usually used by internal python variables and methods\n  -  When developing new Qt objects, widgets, or classes you should create protected members, and allow access to them via getter and setter methods.\n\n- **Code Organization and Structure:**\n  - *Directory Structure:* Organize your project into logical directories (e.g., `ui`, `models`, `controllers`, `widgets`).\n  - *File Naming:* Use descriptive file names (e.g., `mainwindow.py`, `user_model.py`).\n  - *Module Organization:* Break your code into smaller, reusable modules.\n  - *Component Architecture:* Design your application using a component-based architecture for better modularity.\n\n- **Common Patterns and Anti-Patterns:**\n  - *Design Patterns:* Apply design patterns like Observer, Singleton, Factory, and Strategy where appropriate.\n  - *Anti-Patterns:* Avoid God classes, tight coupling, and code duplication.\n  - *State Management:* Use signals and slots or dedicated state management libraries for managing application state.\n  - *Error Handling:* Implement robust error handling using try-except blocks and logging.\n\n- **Performance Considerations:**\n  - *Optimization:* Optimize your code by minimizing expensive operations, using caching, and avoiding unnecessary GUI updates.\n  - *Memory Management:* Be mindful of memory usage, especially when dealing with large images or data sets. Use `del` to remove unwanted objects from memory.\n  - *Rendering Optimization:* Optimize rendering by using double buffering, avoiding unnecessary repaints, and using optimized drawing methods.\n  - Deleting objects that are no longer in use.\n  - Limit the number of widgets.\n\n- **Security Best Practices:**\n  - *Vulnerabilities:* Be aware of common vulnerabilities like code injection, cross-site scripting (XSS), and SQL injection if using databases.\n  - *Input Validation:* Validate all user inputs to prevent malicious data from entering your application.\n  - *Authentication:* Implement proper authentication and authorization mechanisms to protect sensitive data.\n  - *Data Protection:* Encrypt sensitive data and use secure communication protocols.\n  - When fetching external data be mindful about malicious data.\n\n- **Testing Approaches:**\n  - *Unit Tests:* Write unit tests for individual components and functions.\n  - *Integration Tests:* Test the interaction between different components.\n  - *End-to-End Tests:* Test the entire application flow.\n  - *Test Organization:* Organize your tests into logical directories and use meaningful names.\n  - *Mocking:* Use mocking and stubbing to isolate components during testing.\n  - Using `pytest` to generate tests.\n\n- **Common Pitfalls and Gotchas:**\n  - *Mistakes:* Avoid circular dependencies, memory leaks, and neglecting event handling.\n  - *Edge Cases:* Be aware of edge cases like unexpected user inputs, network errors, and file system issues.\n  - *Version Issues:* Pay attention to version-specific issues and compatibility concerns when upgrading PyQt or other dependencies.\n  - Ensure the GUI thread is kept responsive.\n\n- **Tooling and Environment:**\n  - *Development Tools:* Use IDEs like VS Code with Python extensions, PyCharm, or Qt Creator.\n  - *Build Configuration:* Use build tools like CMake or setuptools for managing your project build process.\n  - *Linting:* Lint your code using tools like Pylint or Flake8.\n  - *Formatting:* Format your code using tools like Black or autopep8.\n  - *Deployment:* Use tools like PyInstaller or cx_Freeze for creating standalone executables.\n  - *CI/CD:* Integrate your project with CI/CD pipelines for automated testing and deployment.\n\n- **Specific Recommendations:**\n  - Always make sure that long running process happen in the background.\n  - Utilize `QThread` to move computationally heavy process off the main thread.\n\n- **Code Splitting:**\n  - Break large classes and functions into smaller, more manageable units.\n  - Extract reusable code into separate modules or libraries.\n\n- **State Management Best Practices:**\n   - Use signals and slots effectively to propagate state changes throughout the application.\n   - Consider using a dedicated state management library or pattern if your application has complex state requirements.\n\n- **Additional Considerations:**\n    - If you need to handle asynchronous operations, leverage `QFuture` and `QThreadPool` for efficient execution.\n    - Use `QSettings` to store application settings and preferences.\n    - Prioritize accessibility by ensuring your application is usable by people with disabilities (e.g., provide keyboard navigation, use appropriate color contrast).",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pyqt.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "pyqt",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pyqt",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-pyramid",
    "description": "This rule provides comprehensive best practices for developing secure, maintainable, and performant applications using the Pyramid web framework for Python. It covers code structure, security, testing, and deployment considerations.",
    "author": "sanjeed5",
    "tags": [
      "pyramid",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pyramid.mdc",
    "content": "- **Project Structure and Code Organization:**\n  - **Directory Structure:**\n    - `src/`: Contains the main application code.\n    - `src/<project_name>/`: Main application package.\n      - `__init__.py`: Makes the directory a Python package.\n      - `models.py`: Data models (if using an ORM like SQLAlchemy).\n      - `views.py`: View callables (controllers).\n      - `routes.py`: Route configurations.\n      - `templates/`: Jinja2 or other template files.\n      - `static/`: Static assets (CSS, JavaScript, images).\n      - `scripts/`: Management scripts (e.g., database setup, data migration).\n    - `tests/`: Unit and integration tests.\n      - `__init__.py`: Makes the directory a Python package.\n      - `conftest.py`: pytest configuration file.\n      - `test_*.py`: Test modules.\n    - `docs/`: Project documentation (Sphinx).\n    - `venv/`: Virtual environment (should be excluded from version control).\n  - **File Naming Conventions:**\n    - Python files: `snake_case.py` (e.g., `database_utils.py`).\n    - Class names: `CamelCase` (e.g., `User`).\n    - Variable names: `snake_case` (e.g., `user_id`).\n    - Constants: `UPPER_SNAKE_CASE` (e.g., `DEFAULT_TIMEOUT`).\n  - **Module Organization:**\n    - Group related functionality into modules.\n    - Avoid circular dependencies.\n    - Use relative imports within the application package (e.g., `from .models import User`).\n  - **Component Architecture:**\n    - MVC (Model-View-Controller) is a common pattern in Pyramid.\n    - Models represent data and business logic.\n    - Views handle requests and render responses.\n    - Controllers (view callables) act as intermediaries between models and views.\n  - **Code Splitting:**\n    - Break down large modules into smaller, more manageable files.\n    - Use packages to group related modules.\n    - Consider using a service layer to separate business logic from view callables.\n\n- **Common Patterns and Anti-Patterns:**\n  - **Design Patterns:**\n    - **Repository Pattern:** Abstract data access logic behind a repository interface.\n    - **Service Layer Pattern:** Encapsulate business logic in a separate layer.\n    - **Factory Pattern:** Use factories to create complex objects.\n  - **Recommended Approaches:**\n    - Use URL dispatch for routing requests to view callables.\n    - Use decorators (`@view_config`) to associate views with routes.\n    - Use Jinja2 or another templating engine for rendering dynamic content.\n    - Use SQLAlchemy or another ORM for interacting with databases.\n  - **Anti-Patterns:**\n    - **Fat Views:** Avoid putting too much logic in view callables.\n    - **Tight Coupling:** Design components to be loosely coupled.\n    - **Ignoring Exceptions:** Always handle exceptions appropriately.\n  - **State Management:**\n    - Use request attributes to store request-specific data (e.g., database connection, user session).\n    - Use sessions to store user-specific data across multiple requests.\n    - Avoid storing large amounts of data in sessions.\n  - **Error Handling:**\n    - Use try-except blocks to handle exceptions.\n    - Log exceptions with appropriate severity levels (e.g., `error`, `warning`, `info`).\n    - Provide user-friendly error messages.\n    - Use Pyramid's exception views to handle exceptions globally.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use caching to store frequently accessed data (e.g., using `dogpile.cache`).\n    - Optimize database queries (e.g., using indexes, avoiding N+1 queries).\n    - Minimize the number of database connections.\n    - Use efficient data structures and algorithms.\n  - **Memory Management:**\n    - Avoid creating unnecessary objects.\n    - Use generators and iterators to process large datasets.\n    - Clean up resources properly (e.g., closing database connections).\n  - **Rendering Optimization:**\n    - Use template caching.\n    - Minimize the amount of data passed to templates.\n    - Optimize template code.\n  - **Bundle Size Optimization:** (If serving static assets)\n    - Minify CSS and JavaScript files.\n    - Use a content delivery network (CDN) to serve static assets.\n  - **Lazy Loading:**\n    - Lazy-load images and other resources.\n    - Defer loading of non-essential JavaScript.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - **SQL Injection:** Prevent by using parameterized queries or an ORM that escapes input.\n    - **Cross-Site Scripting (XSS):** Prevent by escaping output in templates.\n    - **Cross-Site Request Forgery (CSRF):** Use Pyramid's CSRF protection features.\n    - **Authentication and Authorization Issues:** Implement strong authentication and authorization mechanisms.\n    - **Session Hijacking:** Use secure cookies and regenerate session IDs after login.\n  - **Input Validation:**\n    - Validate all user input.\n    - Use schema validation libraries (e.g., `colander`) to validate input data.\n    - Sanitize input to remove potentially malicious characters.\n  - **Authentication and Authorization:**\n    - Use a robust authentication system (e.g., `pyramid_jwt`, `pyramid_authsanity`).\n    - Implement role-based access control (RBAC).\n    - Secure API endpoints with authentication and authorization checks.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use TLS/SSL for secure communication.\n    - Store passwords securely using strong hashing algorithms (e.g., bcrypt, argon2).\n  - **Secure API Communication:**\n    - Use HTTPS for all API requests.\n    - Authenticate API clients using API keys or tokens.\n    - Implement rate limiting to prevent abuse.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Test individual components in isolation.\n    - Use mocking to isolate components from dependencies.\n    - Use a testing framework (e.g., `pytest`).\n  - **Integration Testing:**\n    - Test the interaction between multiple components.\n    - Test the application's integration with external systems (e.g., databases).\n  - **End-to-End Testing:**\n    - Test the entire application from the user's perspective.\n    - Use a browser automation tool (e.g., `Selenium`, `Playwright`).\n  - **Test Organization:**\n    - Keep tests in a separate `tests/` directory.\n    - Organize tests into modules that correspond to the application's modules.\n    - Use clear and descriptive test names.\n  - **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to create mock objects.\n    - Use stubs to replace dependencies with simplified versions.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - **Misunderstanding URL Dispatch:** Carefully define routes and view predicates.\n    - **Insecure Configuration:** Protect sensitive configuration data.\n    - **Insufficient Testing:** Thoroughly test all parts of the application.\n  - **Edge Cases:**\n    - **Handling Unicode:** Ensure proper Unicode handling throughout the application.\n    - **Dealing with Time Zones:** Use a consistent time zone and handle time zone conversions correctly.\n  - **Version-Specific Issues:**\n    - Be aware of compatibility issues when upgrading Pyramid or its dependencies.\n    - Consult the release notes for any breaking changes.\n  - **Compatibility Concerns:**\n    - Ensure compatibility between Pyramid and other technologies used in the application.\n    - Test the application on all supported platforms and browsers.\n  - **Debugging Strategies:**\n    - Use a debugger to step through code and inspect variables.\n    - Use logging to track the flow of execution and identify errors.\n    - Use Pyramid's debugging toolbar to inspect requests, responses, and configuration.\n\n- **Tooling and Environment:**\n  - **Recommended Tools:**\n    - **Virtualenv or venv:** For creating isolated Python environments.\n    - **pip:** For managing dependencies.\n    - **pytest:** For running tests.\n    - **flake8:** For linting code.\n    - **black:** For formatting code.\n  - **Build Configuration:**\n    - Use a `setup.py` or `pyproject.toml` file to define the project's metadata and dependencies.\n    - Use a build system (e.g., `setuptools`, `poetry`) to package the application.\n  - **Linting and Formatting:**\n    - Use a linter (e.g., `flake8`) to enforce code style guidelines.\n    - Use a formatter (e.g., `black`) to automatically format code.\n    - Configure the linter and formatter to use consistent settings.\n  - **Deployment:**\n    - Use a WSGI server (e.g., `gunicorn`, `uWSGI`) to serve the application.\n    - Use a process manager (e.g., `systemd`, `supervisor`) to manage the WSGI server.\n    - Deploy the application to a production environment (e.g., cloud platform, virtual machine).\n  - **CI/CD:**\n    - Use a continuous integration/continuous deployment (CI/CD) system (e.g., `Jenkins`, `GitLab CI`, `GitHub Actions`) to automate the build, test, and deployment process.\n    - Run tests automatically on every commit.\n    - Deploy the application automatically to staging and production environments.\n\n- **Additional Information:**\n  - Regularly update dependencies to patch security vulnerabilities.\n  - Use a security scanner like Bandit to identify potential security flaws in the code.\n  - Follow the principle of least privilege when granting permissions to users and services.\n  - Monitor the application's performance and security logs to detect and respond to incidents.\n  - Document the application's architecture, configuration, and deployment process.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pyramid.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pyramid",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "secure",
      "maintainable",
      "performant",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pyramid",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pyright",
    "description": "This rule provides comprehensive best practices for using pyright and BasedPyright in Python projects, covering code organization, patterns, performance, security, testing, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "pyright",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pyright.mdc",
    "content": "# pyright and BasedPyright Best Practices: A Comprehensive Guide\n\nThis guide provides comprehensive best practices for using pyright and BasedPyright in Python projects. These practices cover code organization, design patterns, performance optimization, security considerations, testing strategies, common pitfalls, and recommended tooling.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n*   **Flat vs. Nested:** Choose a directory structure that balances simplicity and maintainability. For small projects, a flat structure might suffice. For larger projects, a nested structure that mirrors the module hierarchy is often better. For example:\n\n    \n    my_project/\n    ├── src/\n    │   ├── my_module/\n    │   │   ├── __init__.py\n    │   │   ├── file1.py\n    │   │   ├── file2.py\n    │   ├── main.py\n    ├── tests/\n    │   ├── my_module/\n    │   │   ├── test_file1.py\n    │   │   ├── test_file2.py\n    │   ├── conftest.py\n    ├── pyrightconfig.json\n    ├── pyproject.toml (or setup.py/setup.cfg)\n    ├── README.md\n    \n\n*   **`src` Layout:** Use the `src` layout to separate application code from project metadata. This helps prevent accidental imports of test or configuration files.\n\n### 1.2 File Naming Conventions\n\n*   **Python Naming:** Follow standard Python naming conventions (PEP 8):\n    *   Modules: `lowercase_with_underscores.py`\n    *   Classes: `PascalCase`\n    *   Functions and variables: `lowercase_with_underscores`\n    *   Constants: `UPPERCASE_WITH_UNDERSCORES`\n*   **Test Files:**  Name test files consistently, e.g., `test_<module_name>.py` or `<module_name>_test.py`.\n\n### 1.3 Module Organization\n\n*   **Cohesion:** Group related functions and classes within a single module.\n*   **Coupling:** Minimize dependencies between modules to improve maintainability.\n*   **`__init__.py`:** Use `__init__.py` files to define packages and control namespace imports.  Consider explicit relative imports within packages (e.g., `from . import module` instead of `import module`).\n\n### 1.4 Component Architecture\n\n*   **Layered Architecture:** For complex applications, consider a layered architecture (e.g., presentation, business logic, data access).  This promotes separation of concerns and testability.\n*   **Microservices:** For very large projects, consider breaking the application into microservices.\n\n### 1.5 Code Splitting Strategies\n\n*   **By Feature:** Split code into modules or packages based on features or functionality (e.g., `auth`, `users`, `products`).\n*   **By Layer:**  Split code based on architectural layers (e.g., data access, business logic, presentation). This aligns with Layered architecture.\n*   **Lazy Loading:** Defer loading modules or components until they are needed. This can improve startup time and reduce memory usage. Use the `importlib` module or dynamic imports for lazy loading.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Factory Pattern:** Use factory functions or classes to create objects, especially when the object creation logic is complex or needs to be configurable.\n*   **Strategy Pattern:**  Use the strategy pattern to encapsulate different algorithms or behaviors and switch between them at runtime.  This promotes flexibility and testability.\n*   **Observer Pattern:** Implement the observer pattern for event handling and decoupling components.\n*   **Singleton Pattern:** Use sparingly and only when a single instance of a class is truly required. Consider dependency injection as an alternative.\n\n### 2.2 Recommended Approaches\n\n*   **Type Annotations:**  Embrace type annotations throughout your codebase. This is essential for effective static analysis with pyright and improves code readability and maintainability.\n*   **Configuration:** Externalize configuration data (e.g., database connection strings, API keys) using environment variables or configuration files.  Use libraries like `python-dotenv` or `dynaconf`.\n*   **Logging:** Implement comprehensive logging using the `logging` module.  Configure logging levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) appropriately.\n*   **Dependency Injection:** Use dependency injection to decouple components and improve testability. Libraries like `injector` can simplify dependency injection.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Ignoring Pyright Errors:**  Treat pyright errors as critical issues that need to be addressed.  Do not silence errors without understanding the underlying problem.\n*   **Overuse of `Any`:**  Avoid using `Any` excessively. It defeats the purpose of static typing.  Strive to provide specific type annotations.\n*   **Magic Numbers:**  Avoid hardcoding numerical values or strings directly in your code. Use named constants instead.\n*   **Global State:**  Minimize the use of global variables. Global state can make code harder to understand and test.\n*   **Deeply Nested Code:**  Avoid deeply nested conditional statements or loops.  Refactor complex code into smaller, more manageable functions.\n\n### 2.4 State Management\n\n*   **Immutability:**  Favor immutable data structures where possible. This can simplify reasoning about state and prevent unintended side effects.  Use libraries like `attrs` or `dataclasses` to create immutable classes.\n*   **Centralized State:** For complex applications, consider using a centralized state management solution (e.g., using Redux-like patterns or libraries).\n\n### 2.5 Error Handling\n\n*   **Exceptions:** Use exceptions for exceptional situations.  Raise specific exception types that accurately describe the error.\n*   **`try...except`:** Use `try...except` blocks to handle exceptions gracefully.  Avoid catching generic `Exception` unless absolutely necessary.\n*   **Logging Errors:** Log exceptions with sufficient context (e.g., traceback, relevant variable values). This is crucial for debugging.\n*   **Resource Management:** Use `try...finally` or the `with` statement to ensure resources are properly released, even if an exception occurs.\n*   **Retry logic:** Implement retry mechanisms for network requests or other operations that may transiently fail. Use libraries like `tenacity`.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Profiling:** Use profiling tools (e.g., `cProfile`) to identify performance bottlenecks in your code.\n*   **Efficient Data Structures:** Choose appropriate data structures for your tasks. For example, use sets for membership testing, and dictionaries for fast lookups.\n*   **Algorithm Optimization:** Optimize algorithms to reduce time complexity. Consider using libraries like NumPy for numerical computations.\n*   **Caching:** Implement caching to store frequently accessed data and avoid redundant computations. Use libraries like `functools.lru_cache` or `cachetools`.\n*   **Just-In-Time (JIT) Compilation:** Explore using JIT compilers like Numba to accelerate numerical code.\n\n### 3.2 Memory Management\n\n*   **Generators:** Use generators to process large datasets without loading them into memory all at once.\n*   **Context Managers:** Use context managers (`with` statement) to ensure that resources are properly released, preventing memory leaks.\n*   **Object Reuse:** Reuse objects where possible to reduce memory allocation overhead.\n*   **Avoid Circular References:** Circular references can prevent garbage collection. Use weak references (`weakref` module) to break cycles when needed.\n\n### 3.3 Bundle Size Optimization (Applicable for web applications using pyright in the backend)\n\n*   **Code Minification:** Minify JavaScript and CSS code to reduce bundle size.\n*   **Tree Shaking:** Use tree shaking to remove unused code from your bundles.\n*   **Code Splitting:** Split your code into smaller chunks that can be loaded on demand.\n*   **Image Optimization:** Optimize images to reduce their file size.\n*   **Compression:** Enable compression (e.g., gzip or Brotli) on your web server.\n\n### 3.4 Lazy Loading\n\n*   **Dynamic Imports:** Use dynamic imports (`import()`) to load modules or components on demand.\n*   **Conditional Imports:** Conditionally import modules based on certain conditions.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **SQL Injection:** Use parameterized queries or ORM libraries to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks. (Relevant if the backend code generates HTML output)\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection for web forms.\n*   **Authentication and Authorization Flaws:** Use secure authentication and authorization mechanisms.\n*   **Denial-of-Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n*   **Dependency Vulnerabilities:** Regularly scan your dependencies for known vulnerabilities using tools like `pip-audit` or `safety`.\n\n### 4.2 Input Validation\n\n*   **Validate All Input:** Validate all user input, including data from forms, API requests, and command-line arguments.\n*   **Whitelisting:** Use whitelisting to specify allowed characters or patterns.\n*   **Data Type Validation:** Ensure that input data is of the expected type.\n*   **Length Validation:** Validate the length of input strings.\n*   **Range Validation:** Validate that numerical values are within the expected range.\n\n### 4.3 Authentication and Authorization\n\n*   **Strong Passwords:** Enforce strong password policies.\n*   **Hashing:** Hash passwords securely using libraries like `bcrypt` or `argon2`.\n*   **Salt:** Use a unique salt for each password.\n*   **Two-Factor Authentication (2FA):** Implement 2FA for enhanced security.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **JSON Web Tokens (JWT):** Use JWTs for secure authentication and authorization in APIs.\n\n### 4.4 Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in logs and other non-production environments.\n*   **Access Control:** Implement strict access control policies to limit access to sensitive data.\n*   **Regular Backups:** Perform regular backups of your data.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Keys:** Protect API keys and store them securely.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Validation:** Validate all API requests.\n*   **Output Sanitization:** Sanitize API responses to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **`unittest` or `pytest`:** Use the `unittest` or `pytest` framework for unit testing.\n*   **Test Coverage:** Aim for high test coverage (e.g., 80% or higher).\n*   **Test-Driven Development (TDD):** Consider using TDD to write tests before writing code.\n*   **Arrange-Act-Assert:** Structure your unit tests using the Arrange-Act-Assert pattern.\n*   **Mocking and Stubbing:** Use mocking and stubbing to isolate units of code and test them in isolation.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions:** Test the interactions between different components or modules.\n*   **Database Testing:** Test the integration with databases.\n*   **API Testing:** Test the integration with external APIs.\n*   **Real Dependencies:** Use real dependencies (e.g., a real database) for integration tests when possible.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate User Flows:** Simulate real user flows to test the entire application from end to end.\n*   **UI Testing:** Use UI testing frameworks (e.g., Selenium, Playwright) to test the user interface.\n*   **Browser Automation:** Automate browser interactions to simulate user behavior.\n\n### 5.4 Test Organization\n\n*   **Separate Test Directory:** Keep your tests in a separate `tests` directory.\n*   **Mirror Module Structure:** Mirror the module structure in your test directory.\n*   **`conftest.py`:** Use `conftest.py` to define fixtures and configuration for your tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **`unittest.mock` or `pytest-mock`:** Use the `unittest.mock` module or the `pytest-mock` plugin for mocking and stubbing.\n*   **Patching:** Use patching to replace objects or functions with mocks during testing.\n*   **Context Managers:** Use context managers to manage mock objects.\n*   **Side Effects:** Define side effects for mock objects to simulate different scenarios.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect Type Annotations:** Using incorrect or incomplete type annotations.\n*   **Ignoring Pyright Errors:** Ignoring or silencing pyright errors without understanding the root cause.\n*   **Overuse of `Any`:** Overusing the `Any` type, which defeats the purpose of static typing.\n*   **Incorrect Configuration:** Incorrectly configuring pyright settings.\n*   **Not Updating Stubs:** Failing to update stubs (`.pyi` files) when the code changes.\n\n### 6.2 Edge Cases\n\n*   **Dynamic Typing:** Dealing with dynamic typing features of Python.\n*   **Type Inference Limitations:** Understanding the limitations of pyright's type inference capabilities.\n*   **Complex Generics:** Handling complex generic types.\n*   **Meta-programming:** Dealing with meta-programming techniques.\n\n### 6.3 Version-Specific Issues\n\n*   **Python Version Compatibility:** Ensuring compatibility with different Python versions.\n*   **Pyright Version Compatibility:** Being aware of changes and bug fixes in different pyright versions.\n\n### 6.4 Compatibility Concerns\n\n*   **Third-Party Libraries:** Dealing with third-party libraries that may not have complete or accurate type annotations.\n*   **Integration with Other Tools:** Ensuring compatibility with other tools in your development workflow.\n\n### 6.5 Debugging Strategies\n\n*   **Read Pyright Output Carefully:** Carefully examine pyright's error messages and warnings.\n*   **Use a Debugger:** Use a debugger (e.g., `pdb` or the debugger in your IDE) to step through your code and inspect variables.\n*   **Simplify the Code:** Simplify the code to isolate the source of the error.\n*   **Consult Documentation:** Consult the pyright documentation and community resources.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Visual Studio Code:** VS Code with the Pylance extension (or the BasedPyright extension for BasedPyright features).\n*   **pyright CLI:** The pyright command-line tool for static analysis.\n*   **pre-commit:** pre-commit for automated code formatting and linting.\n*   **mypy:** Consider using mypy in conjunction with pyright, as some checks can be performed by mypy that pyright does not offer.\n\n### 7.2 Build Configuration\n\n*   **`pyrightconfig.json` or `pyproject.toml`:** Configure pyright settings using a `pyrightconfig.json` or `pyproject.toml` file.\n*   **Include and Exclude Paths:** Specify include and exclude paths to control which files are analyzed by pyright.\n*   **Type Checking Mode:** Set the type checking mode to `basic`, `strict`, or `off`.\n*   **Python Version:** Specify the target Python version.\n*   **Enable Strict Rules:** Enable strict rules to enforce more stringent type checking.\n\n### 7.3 Linting and Formatting\n\n*   **`flake8` or `ruff`:** Use linters like `flake8` or `ruff` to enforce code style guidelines.\n*   **`black`:** Use `black` for automatic code formatting.\n*   **pre-commit Hooks:** Integrate linters and formatters into your pre-commit workflow.\n\n### 7.4 Deployment Best Practices\n\n*   **Containerization:** Use Docker to containerize your application.\n*   **Infrastructure as Code (IaC):** Use IaC tools (e.g., Terraform, Ansible) to manage your infrastructure.\n*   **Continuous Integration/Continuous Deployment (CI/CD):** Implement a CI/CD pipeline for automated testing and deployment.\n*   **Monitoring:** Monitor your application's performance and health in production.\n\n### 7.5 CI/CD Integration\n\n*   **GitHub Actions or GitLab CI:** Use CI/CD platforms like GitHub Actions or GitLab CI.\n*   **Automated Testing:** Run automated tests in your CI/CD pipeline.\n*   **Static Analysis:** Run pyright and other static analysis tools in your CI/CD pipeline.\n*   **Deployment Automation:** Automate the deployment process in your CI/CD pipeline.\n\n## BasedPyright Specific Enhancements:\n\n*   **reportUnreachable:** Reports errors on unreachable code, enhancing error detection in conditional blocks.\n*   **reportAny:** Bans the `Any` type completely, encouraging more precise type annotations and reducing potential runtime errors.\n*   **reportPrivateLocalImportUsage:** Restricts private imports within local code, promoting explicit re-exports and clearer module interfaces.\n*   **reportImplicitRelativeImport:** Flags incorrect relative imports, preventing module loading issues in various execution contexts.\n*   **reportInvalidCast:** Prevents non-overlapping casts, ensuring type safety during casting operations.\n*   **reportUnsafeMultipleInheritance:** Discourages multiple inheritance from classes with constructors, reducing the risk of unexpected behavior in complex class hierarchies.\n*   **Pylance Feature Re-implementations:** Enables features previously exclusive to Pylance such as import suggestions, semantic highlighting, and improved docstrings for compiled modules, offering more robust IDE support across different editors.\n*   **Inline TypedDict Support:** Reintroduces the support for defining TypedDicts inline, offering convenient type annotation syntax.\n*   **Better CI Integration:** Leverages GitHub Actions and GitLab CI for seamless error reporting in pull requests and merge requests.\n*   **Strict Defaults:** Defaults to a stricter type checking mode (all) and assumes code can run on any operating system (All), promoting more comprehensive type analysis.\n\nBy following these best practices, you can leverage pyright and BasedPyright to improve the quality, maintainability, and security of your Python projects.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pyright.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pyright",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "basedpyright",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pyright",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pyside",
    "description": "This rule enforces best practices and coding standards for developing applications with the PySide library. It covers code organization, performance, security, testing, and common pitfalls to ensure maintainable and robust applications.",
    "author": "sanjeed5",
    "tags": [
      "pyside",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pyside.mdc",
    "content": "# PySide Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing applications with the PySide library. Adhering to these guidelines will promote code readability, maintainability, and robustness.\n\n## 1. General Guidelines\n\n- **Follow PEP 8:**  Adhere to the PEP 8 style guide for Python code. This includes:\n    - Consistent naming conventions (e.g., `snake_case` for functions and variables, `CamelCase` for classes).\n    - 4 spaces for indentation.\n    - Maximum line length of 79 characters (or 99 if agreed upon by the team).\n    - Blank lines separating top-level function and class definitions.\n- **Qt and Python Naming Conventions:** Prefer Qt's `CamelCase` naming conventions for methods within classes inheriting from Qt widgets. This promotes consistency with the Qt framework. For example, use `loadItems()` instead of `load_items()`.\n- **Avoid Wildcard Imports:** Import specific classes or modules instead of using wildcard imports (`from PySide2.QtWidgets import *`). This keeps the namespace clean and avoids potential conflicts.\n- **Use Docstrings and Comments:** Document your methods and classes using docstrings (following PEP 257) to explain their purpose and usage. Use inline comments sparingly to clarify complex code, ensuring they are up-to-date.\n- **Use Virtual Environments:** Always use virtual environments (e.g., `venv`, `conda`) to manage dependencies for each project. This isolates project dependencies and avoids conflicts between different projects.\n- **Consistent Style:** Maintain a consistent coding style throughout the project. Use a linter and formatter (e.g., `flake8`, `pylint`, `black`, `autopep8`) to enforce the coding style.\n- **Meaningful Variable Names:**  Choose descriptive and meaningful names for variables, functions, and classes.\n\n## 2. Code Organization and Structure\n\n- **Directory Structure:** A well-defined directory structure is crucial for maintainability. Consider the following structure:\n\n  \n  project_name/\n  ├── src/\n  │   ├── main.py          # Entry point of the application\n  │   ├── gui/\n  │   │   ├── __init__.py\n  │   │   ├── main_window.py   # Main window class\n  │   │   ├── widgets/\n  │   │   │   ├── __init__.py\n  │   │   │   ├── custom_widget.py # Custom widgets\n  │   │   ├── models/\n  │   │   │   ├── __init__.py\n  │   │   │   ├── data_model.py    # Data models\n  │   ├── core/\n  │   │   ├── __init__.py\n  │   │   ├── logic.py         # Core application logic\n  │   ├── resources/\n  │   │   ├── __init__.py\n  │   │   ├── icons/\n  │   │   │   ├── ...\n  │   │   ├── ui/             # Stores .ui files generated by Qt Designer\n  │   │   │   ├── main_window.ui\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── test_main_window.py # Unit tests for main window\n  ├── requirements.txt    # Project dependencies\n  ├── README.md           # Project documentation\n  ├── .gitignore          # Git ignore file\n  \n\n- **File Naming Conventions:**\n    - Python files: `snake_case.py` (e.g., `main_window.py`, `custom_widget.py`).\n    - UI files: `snake_case.ui` (e.g., `main_window.ui`, `settings_dialog.ui`).\n    - Resource files:  Descriptive names (e.g., `app_icons.qrc`).\n\n- **Module Organization:** Organize related classes and functions into modules. This improves code reusability and maintainability.\n    - Use packages (`__init__.py` files) to group related modules.\n\n- **Component Architecture:** Design the application with a component-based architecture. This promotes modularity and testability.\n    - Separate the UI (views) from the application logic (controllers and models).\n    - Use signals and slots for communication between components.\n    - Use dependency injection to decouple components.\n\n- **Code Splitting:** Split large files into smaller, more manageable files. This makes it easier to understand and maintain the code.\n    - Group related functions and classes into separate modules.\n    - Extract common code into utility functions or classes.\n    - Consider splitting UI logic into separate files (e.g., event handlers, data binding).\n\n## 3. Common Patterns and Anti-Patterns\n\n- **Model-View-Controller (MVC) or Model-View-Presenter (MVP):** Use these patterns to separate the UI from the application logic.\n    - **Model:** Represents the data and business logic.\n    - **View:** Displays the data to the user and handles user input.\n    - **Controller/Presenter:** Acts as an intermediary between the Model and the View, handling user actions and updating the View based on changes in the Model.\n\n- **Signals and Slots:** Leverage Qt's signals and slots mechanism for communication between objects. This is a powerful and flexible way to handle events and notifications.\n    - Use named signals and slots for better readability and maintainability.  Avoid directly connecting signals and slots by string names if possible, prefer member functions.\n    - Disconnect signals when they are no longer needed to avoid memory leaks.\n\n- **Resource Management:** Properly manage resources (e.g., files, network connections, database connections) to avoid memory leaks and ensure the application runs smoothly.\n    - Use `with` statements or `try...finally` blocks to ensure resources are released even if exceptions occur.\n    - Consider using `QScopedPointer` for managing Qt objects.\n\n- **Data Binding:** Use data binding to automatically synchronize data between the Model and the View. This simplifies UI development and reduces boilerplate code.\n    - PySide supports data binding through `QDataWidgetMapper` and custom models.\n\n- **Anti-Patterns:**\n    - **God Objects:** Avoid creating classes that are too large and do too much. Split them into smaller, more focused classes.\n    - **Copy-Pasting Code:** Avoid duplicating code. Extract common code into reusable functions or classes.\n    - **Ignoring Exceptions:** Don't just catch exceptions and ignore them. Log the exception and handle it appropriately.\n    - **Tight Coupling:** Avoid tight coupling between components. Use dependency injection and interfaces to decouple components.\n\n- **State Management:**\n    - Use a central state management system (e.g., Redux-like pattern, or a simple state class) to manage the application's state.  This is particularly helpful in large applications.\n    - Consider making the state immutable for easier debugging and predictability.\n\n- **Error Handling:**\n    - Use `try...except` blocks to handle exceptions.  Catch specific exceptions whenever possible.  Log exceptions using Python's `logging` module.\n    - Provide informative error messages to the user.  Consider using message boxes or a status bar to display error messages.\n\n## 4. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Avoid Blocking the Main Thread:**  Long-running operations (e.g., network requests, file I/O) should be performed in a separate thread to avoid blocking the main UI thread.\n        - Use `QThread` or `QThreadPool` for multithreading.  Use signals and slots to communicate between threads.\n    - **Efficient Data Structures:** Choose the appropriate data structures for the task.  For example, use `QHash` instead of `QMap` if order doesn't matter and you need faster lookups.\n    - **Minimize Widget Creation:** Creating and destroying widgets can be expensive.  Reuse widgets whenever possible.  Consider using `QStackedWidget` to switch between different views without creating new widgets.\n    - **Optimize Painting:**  Optimize custom painting operations by minimizing the amount of drawing and using caching techniques.\n    - **Profiling:** Use profiling tools to identify performance bottlenecks. Python's `cProfile` and `line_profiler` can be useful. Qt also offers profiling tools.\n\n- **Memory Management:**\n    - **Avoid Circular References:** Circular references can prevent objects from being garbage collected.  Use `weakref` or manually break the references.\n    - **Use `QObject` Parenting:** Take advantage of `QObject`'s parenting mechanism for automatic memory management. When a parent object is destroyed, all its children are also destroyed.\n    - **Delete Objects Manually:** In some cases, you may need to manually delete objects to free memory.  Use `del` to delete Python objects, and consider using `QScopedPointer` or manually calling `deleteLater()` on `QObject` instances when appropriate (especially when dealing with C++ objects exposed to Python).\n\n- **Rendering Optimization:**\n    - **Use Double Buffering:** Enable double buffering to reduce flickering during repainting.\n    - **Minimize Overlapping Updates:**  Reduce the number of times the UI is updated by batching updates together.\n    - **Use Graphics Effects Sparingly:** Graphics effects can be expensive. Use them sparingly and optimize their settings.\n    - **Caching:** Cache frequently used resources (e.g., images, fonts) to avoid reloading them repeatedly.\n\n- **Bundle Size Optimization:** (Relevant for deployment using tools like PyInstaller)\n    - **Minimize Dependencies:** Only include the necessary dependencies in the project.  Remove unused dependencies.\n    - **Use UPX Compression:** UPX can compress the executable file to reduce its size.\n    - **Exclude Unnecessary Files:** Exclude unnecessary files (e.g., documentation, tests) from the bundle.\n\n- **Lazy Loading:** Delay the loading of resources or components until they are needed. This can improve startup time and reduce memory usage.\n    - Load UI files on demand.\n    - Load images or data only when they are visible.\n\n## 5. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Code Injection:** Prevent code injection by validating user input and avoiding the use of `eval()` or `exec()`.  Be very cautious about using `pickle` to deserialize data, as it can be exploited for code execution.\n    - **Cross-Site Scripting (XSS):**  If the application displays user-generated content, sanitize the input to prevent XSS attacks.  Consider using Qt's built-in functions for HTML encoding.\n    - **SQL Injection:**  If the application uses a database, use parameterized queries to prevent SQL injection attacks.  Never concatenate user input directly into SQL queries.\n    - **Path Traversal:**  Validate user-provided file paths to prevent path traversal attacks.  Use `QDir::cleanPath()` to sanitize file paths.\n    - **Denial of Service (DoS):**  Implement rate limiting and other measures to protect against DoS attacks.\n\n- **Input Validation:**\n    - **Validate all user input:**  Check that the input is of the correct type, format, and range.\n    - **Use regular expressions for complex validation:**  Regular expressions can be used to validate email addresses, phone numbers, and other complex data formats.\n    - **Sanitize input:** Remove or encode any potentially harmful characters from the input.\n\n- **Authentication and Authorization:**\n    - **Use strong passwords:**  Enforce strong password policies and use a secure hashing algorithm (e.g., bcrypt, Argon2) to store passwords.\n    - **Implement proper authentication:** Verify the user's identity before granting access to protected resources.\n    - **Implement authorization:** Control which users have access to which resources.\n    - **Use secure communication protocols:** Use HTTPS to encrypt communication between the client and the server.\n\n- **Data Protection:**\n    - **Encrypt sensitive data:** Encrypt sensitive data (e.g., passwords, credit card numbers) before storing it.\n    - **Use secure storage:** Store sensitive data in a secure location, such as a hardware security module (HSM) or a secure enclave.\n    - **Protect against data leaks:**  Be careful about logging sensitive data or storing it in temporary files.\n\n- **Secure API Communication:**\n    - **Use HTTPS:** Always use HTTPS for communication with APIs.\n    - **Validate API responses:**  Verify that the API response is valid and that it hasn't been tampered with.\n    - **Use API keys or tokens:**  Use API keys or tokens to authenticate API requests.\n\n## 6. Testing Approaches\n\n- **Unit Testing:** Test individual components (e.g., classes, functions) in isolation.\n    - Use a unit testing framework (e.g., `unittest`, `pytest`).\n    - Mock or stub dependencies to isolate the component being tested.\n    - Test all possible scenarios, including edge cases and error conditions.\n\n- **Integration Testing:** Test the interaction between different components.\n    - Verify that the components work together correctly.\n    - Use real dependencies or integration test environments.\n    - Test common use cases.\n\n- **End-to-End Testing:** Test the entire application from the user's perspective.\n    - Simulate user interactions.\n    - Verify that the application behaves as expected.\n    - Use an end-to-end testing framework (e.g., Selenium, Playwright).\n\n- **Test Organization:**\n    - Create a separate `tests` directory for test files.\n    - Organize test files to mirror the source code structure.\n    - Use descriptive test names.\n    - Run tests automatically using a CI/CD pipeline.\n\n- **Mocking and Stubbing:**\n    - Use mocking to replace dependencies with controlled objects.\n    - Use stubbing to provide canned responses for dependencies.\n    - Use a mocking framework (e.g., `unittest.mock`, `pytest-mock`).\n    - Be careful not to over-mock.  Only mock the dependencies that are necessary to isolate the component being tested.\n\n## 7. Common Pitfalls and Gotchas\n\n- **QObject Ownership and Memory Management:** Incorrect object ownership can lead to memory leaks or crashes. Ensure that `QObject` instances have a clear parent-child relationship or are managed with `QScopedPointer`.\n- **Event Loop Blocking:** Long-running tasks in the main thread will freeze the UI. Offload these tasks to separate threads using `QThread` or `QThreadPool`.\n- **Signal-Slot Connections:** Incorrect signal-slot connections can lead to unexpected behavior. Always check that the signal and slot signatures match.\n- **Thread Safety:** Be aware of thread safety issues when accessing shared resources from multiple threads. Use mutexes or other synchronization mechanisms to protect shared data.\n- **UI Thread Access:** Only access UI elements from the main thread. Use `QMetaObject::invokeMethod()` to invoke methods on UI objects from other threads.\n- **Resource File Paths:** Be careful with resource file paths. Use absolute paths or relative paths that are relative to the application's resource directory. Use `:/` to refer to Qt resources.\n- **Unicode Handling:** Ensure that the application correctly handles Unicode characters. Use `QString` for storing and manipulating text.\n- **Layout Management:**  Understand and use layout managers (`QHBoxLayout`, `QVBoxLayout`, `QGridLayout`, etc.) effectively.  Avoid hardcoding widget positions and sizes.\n- **Qt Designer Limitations:** Be aware of the limitations of Qt Designer. Some UI elements or behaviors may require manual coding.\n- **Event Filters:**  Be cautious when using event filters, as they can impact performance and make it harder to debug the application.  Only use event filters when necessary.\n- **Context Menus and Actions:** When adding actions to context menus ensure you specify the parent to avoid a memory leak.\n\n## 8. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **Qt Creator:** An IDE specifically designed for Qt development.\n    - **PyCharm:** A popular Python IDE with excellent support for Qt and PySide.\n    - **VS Code:** A lightweight and versatile code editor with support for Python and Qt through extensions.\n    - **Qt Designer:** A visual tool for designing UI layouts.\n\n- **Build Configuration:**\n    - **Use `setuptools` or `poetry` for managing dependencies and building the application.**\n    - **Create a `setup.py` file for the project.**\n    - **Use a virtual environment to isolate project dependencies.**\n\n- **Linting and Formatting:**\n    - **Use `flake8`, `pylint`, or `ruff` for linting the code.**\n    - **Use `black` or `autopep8` for formatting the code.**\n    - **Configure the linter and formatter to follow the project's coding style.**\n\n- **Deployment:**\n    - **Use `PyInstaller`, `cx_Freeze`, or similar tools to create standalone executables.**\n    - **Bundle all necessary dependencies with the executable.**\n    - **Test the executable on different platforms.**\n\n- **CI/CD Integration:**\n    - **Use a CI/CD platform (e.g., Jenkins, GitHub Actions, GitLab CI) to automate the build, test, and deployment process.**\n    - **Run tests automatically on every commit.**\n    - **Create deployment packages automatically on every release.**\n    - **Automate code quality checks with linting and formatting tools.**",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pyside.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "pyside",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "applications",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pyside",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-pytest",
    "description": "This rule file outlines comprehensive best practices for using pytest in Python projects, covering code organization, testing strategies, performance optimization, security measures, and common pitfalls to avoid.",
    "author": "sanjeed5",
    "tags": [
      "pytest",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pytest.mdc",
    "content": "# Pytest Best Practices: A Comprehensive Guide\n\nThis document provides a detailed guide to using pytest effectively in Python projects, covering various aspects from code organization to security considerations. It aims to provide actionable guidance for developers to improve their testing practices and build robust applications.\n\n## Library Information:\n- Name: pytest\n- Tags: development, testing, python\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability and testability. Here are best practices for structuring your pytest projects:\n\n### 1.1. Directory Structure\n\n- **Separate `tests/` directory:** Keep your tests in a directory separate from your application code, typically named `tests/`. This promotes isolation and cleaner project structure.\n\n  \n  my_project/\n  ├── my_app/\n  │   ├── __init__.py\n  │   ├── module1.py\n  │   └── module2.py\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── test_module1.py\n  │   └── test_module2.py\n  └── pyproject.toml\n  \n\n- **`src` layout (Recommended):** Consider using a `src` layout to further isolate application code from the project root. This prevents import conflicts and improves clarity.\n\n  \n  my_project/\n  ├── src/\n  │   └── my_app/\n  │       ├── __init__.py\n  │       ├── module1.py\n  │       └── module2.py\n  ├── tests/\n  │   ├── __init__.py\n  │   ├── test_module1.py\n  │   └── test_module2.py\n  └── pyproject.toml\n  \n\n### 1.2. File Naming Conventions\n\n- **`test_*.py` or `*_test.py`:** pytest automatically discovers test files matching these patterns.\n- **Descriptive names:** Use clear and descriptive names for your test files to indicate what they are testing (e.g., `test_user_authentication.py`).\n\n### 1.3. Module Organization\n\n- **Mirror application structure:** Structure your test modules to mirror the structure of your application code. This makes it easier to locate tests for specific modules.\n- **`__init__.py`:** Include `__init__.py` files in your test directories to ensure they are treated as Python packages.\n\n### 1.4. Component Architecture\n\n- **Isolate components:** Design your application with well-defined components that can be tested independently.\n- **Dependency injection:** Use dependency injection to provide components with their dependencies, making it easier to mock and stub external resources during testing.\n\n### 1.5. Code Splitting\n\n- **Small, focused functions:** Break down large functions into smaller, focused functions that are easier to test.\n- **Modular design:** Organize your code into modules with clear responsibilities.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Arrange-Act-Assert (AAA):** Structure your tests following the AAA pattern for clarity.\n    - **Arrange:** Set up the test environment and prepare any necessary data.\n    - **Act:** Execute the code being tested.\n    - **Assert:** Verify that the code behaved as expected.\n\n  python\n  def test_example():\n      # Arrange\n      data = ...\n      expected_result = ...\n\n      # Act\n      result = function_under_test(data)\n\n      # Assert\n      assert result == expected_result\n  \n\n- **Fixture factory:** Use fixture factories to create reusable test data.\n\n  python\n  import pytest\n\n  @pytest.fixture\n  def user_factory():\n      def create_user(username, email):\n          return {\"username\": username, \"email\": email}\n      return create_user\n\n  def test_create_user(user_factory):\n      user = user_factory(\"testuser\", \"test@example.com\")\n      assert user[\"username\"] == \"testuser\"\n  \n\n### 2.2. Recommended Approaches\n\n- **Use fixtures for setup and teardown:** Fixtures help manage test dependencies and ensure a clean test environment.\n- **Parameterize tests:** Use `@pytest.mark.parametrize` to run the same test with different inputs and expected outputs, reducing code duplication.\n- **Use descriptive names for tests and fixtures:** This makes it easier to understand the purpose of each test and fixture.\n- **Single Assertion per Test:** A single assertion per test makes it easier to identify the specific failure point.\n\n### 2.3. Anti-patterns and Code Smells\n\n- **Over-reliance on fixtures:** Avoid creating too many fixtures, especially for simple data.  Use direct data definition in the test if it's not reused.\n- **Implicit dependencies:** Make dependencies explicit by passing them as arguments to your functions and tests.\n- **Testing implementation details:** Focus on testing the behavior of your code, not the implementation details.  This makes your tests more resilient to refactoring.\n- **Skipping Tests Without a Reason:** Don't skip tests without a valid reason or comment explaining why.\n\n### 2.4. State Management\n\n- **Stateless tests:** Ensure your tests are stateless and independent to avoid unexpected side effects. Each test should set up its own data and clean up after itself.\n- **Fixture scopes:** Use fixture scopes (`session`, `module`, `function`) to control the lifecycle of fixtures and manage state effectively.\n\n### 2.5. Error Handling\n\n- **Test exception handling:** Write tests to verify that your code handles exceptions correctly.\n\n  python\n  import pytest\n\n  def divide(a, b):\n      if b == 0:\n          raise ValueError(\"Cannot divide by zero\")\n      return a / b\n\n  def test_divide_by_zero():\n      with pytest.raises(ValueError) as e:\n          divide(10, 0)\n      assert str(e.value) == \"Cannot divide by zero\"\n  \n\n- **Use `pytest.raises`:** Use `pytest.raises` to assert that a specific exception is raised.\n- **Log errors:** Ensure your application logs errors appropriately, and consider writing tests to verify that errors are logged correctly.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Profile slow tests:** Use the `--durations` option to identify slow tests and optimize them.\n- **Parallel test execution:** Use `pytest-xdist` to run tests in parallel and reduce overall test execution time. `pip install pytest-xdist` then run `pytest -n auto`.  The `auto` option utilizes all available CPU cores.\n- **Caching:** Cache expensive computations to avoid redundant calculations during testing.\n\n### 3.2. Memory Management\n\n- **Resource cleanup:** Ensure your tests clean up any resources they allocate, such as temporary files or database connections.\n- **Limit fixture scope:** Use the appropriate fixture scope to minimize the lifetime of fixtures and reduce memory consumption.\n\n### 3.3. Bundle Size Optimization\n\n- **N/A:** Pytest itself doesn't directly impact bundle sizes, but your application code should be optimized separately.\n\n### 3.4. Lazy Loading\n\n- **N/A:** Lazy loading is more relevant to application code than pytest itself, but can be used within fixtures if necessary to defer initialization.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n- **Injection attacks:** Prevent injection attacks by validating and sanitizing user inputs.\n- **Cross-site scripting (XSS):** Protect against XSS vulnerabilities by escaping user-generated content.\n- **Authentication and authorization flaws:** Implement secure authentication and authorization mechanisms to protect sensitive data.\n\n### 4.2. Input Validation\n\n- **Validate all inputs:** Validate all user inputs to ensure they conform to expected formats and ranges.\n- **Use parameterized tests:** Use parameterized tests to test input validation logic with a variety of inputs, including edge cases and invalid values.\n\n### 4.3. Authentication and Authorization\n\n- **Test authentication:** Write tests to verify that your authentication mechanisms are working correctly.\n- **Test authorization:** Write tests to verify that users only have access to the resources they are authorized to access.\n\n### 4.4. Data Protection\n\n- **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n- **Use secure storage:** Store sensitive data in secure storage locations with appropriate access controls.\n\n### 4.5. Secure API Communication\n\n- **Use HTTPS:** Always use HTTPS for API communication to protect data in transit.\n- **Validate API responses:** Validate API responses to ensure they are valid and haven't been tampered with.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- **Test individual units:** Unit tests should focus on testing individual functions, methods, or classes in isolation.\n- **Mock dependencies:** Use mocking to isolate units under test from their dependencies.\n\n### 5.2. Integration Testing\n\n- **Test interactions:** Integration tests should focus on testing the interactions between different components of your application.\n- **Use real dependencies (where appropriate):** For integration tests, it's often appropriate to use real dependencies, such as databases or external APIs, to ensure that the different components work together correctly.  Consider using test containers for database and service dependencies.\n\n### 5.3. End-to-End Testing\n\n- **Test complete workflows:** End-to-end tests should focus on testing complete user workflows, from start to finish.\n- **Use browser automation:** Use browser automation tools like Selenium or Playwright to simulate user interactions with your application.\n\n### 5.4. Test Organization\n\n- **Organize tests by feature:** Group tests by the feature they are testing to improve organization and maintainability.\n- **Use clear naming conventions:** Use clear naming conventions for your tests and test files to indicate what they are testing.\n\n### 5.5. Mocking and Stubbing\n\n- **Use `mocker` fixture:** Use the `mocker` fixture provided by the `pytest-mock` plugin for mocking and stubbing.\n- **Mock external dependencies:** Mock external dependencies, such as databases or APIs, to isolate your tests and prevent them from relying on external resources.\n- **Use `autospec=True`:** Use `autospec=True` when mocking to ensure that your mocks have the same API as the original objects. This helps prevent errors caused by incorrect mock implementations.\n\n  python\n  def test_example(mocker):\n      mock_external_api = mocker.patch(\"module.external_api\", autospec=True)\n      mock_external_api.return_value = {\"data\": \"test data\"}\n  \n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Not isolating tests:** Failing to isolate tests can lead to unpredictable results and make it difficult to debug failures.\n- **Testing implementation details:** Testing implementation details makes your tests brittle and difficult to maintain.\n- **Ignoring warnings:** Ignoring warnings from pytest can mask underlying problems in your tests.\n\n### 6.2. Edge Cases\n\n- **Empty inputs:** Test your code with empty inputs to ensure it handles them gracefully.\n- **Invalid inputs:** Test your code with invalid inputs to ensure it handles them correctly and raises appropriate exceptions.\n- **Boundary conditions:** Test your code with boundary conditions to ensure it handles them correctly.\n\n### 6.3. Version-Specific Issues\n\n- **Check release notes:** Check the release notes for each new version of pytest to be aware of any breaking changes or new features.\n- **Pin dependencies:** Pin your pytest dependency to a specific version to avoid unexpected behavior caused by updates.\n\n### 6.4. Compatibility Concerns\n\n- **Check compatibility:** Check the compatibility of pytest with other technologies you are using, such as specific versions of Python or Django.\n\n### 6.5. Debugging Strategies\n\n- **Use `--pdb`:** Use the `--pdb` option to drop into the Python debugger when a test fails.\n- **Use logging:** Use logging to add debugging information to your tests.\n- **Simplify tests:** Simplify failing tests to isolate the cause of the failure.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **IDE:** Use a good IDE with pytest support, such as VS Code with the Python extension, PyCharm, or Sublime Text with the appropriate plugins.\n- **pytest-watch:** Use `pytest-watch` for automatic test rerunning on file changes. `pip install pytest-watch`, then run `ptw`.\n\n### 7.2. Build Configuration\n\n- **Use `pyproject.toml`:** Use a `pyproject.toml` file to configure your pytest settings.\n\n  toml\n  [tool.pytest.ini_options]\n  addopts = [\n      \"--cov=my_app\",\n      \"--cov-report term-missing\",\n      \"-v\",\n  ]\n  testpaths = [\n      \"tests\",\n  ]\n  \n\n### 7.3. Linting and Formatting\n\n- **Use `flake8-pytest-style`:** Use the `flake8-pytest-style` plugin to enforce pytest-specific coding standards.  `pip install flake8 flake8-pytest-style`\n- **Use `black` or `autopep8`:** Use a code formatter like `black` or `autopep8` to ensure consistent code formatting.  `pip install black`, then run `black .`\n\n### 7.4. Deployment\n\n- **Include tests in your deployment pipeline:** Ensure your tests are run as part of your deployment pipeline to prevent regressions.\n- **Use a dedicated test environment:** Use a dedicated test environment to avoid interfering with your production environment.\n\n### 7.5. CI/CD Integration\n\n- **Integrate with CI/CD:** Integrate pytest with your CI/CD system, such as GitHub Actions, GitLab CI, or Jenkins, to automatically run your tests on every commit.\n\n  Example GitHub Actions workflow (`.github/workflows/test.yml`):\n\n  \n  name: Test\n  on:\n    push:\n      branches: [ main ]\n    pull_request:\n      branches: [ main ]\n  jobs:\n    build:\n      runs-on: ubuntu-latest\n      steps:\n        - uses: actions/checkout@v3\n        - name: Set up Python 3.10\n          uses: actions/setup-python@v3\n          with:\n            python-version: \"3.10\"\n        - name: Install dependencies\n          run: |\n            python -m pip install --upgrade pip\n            pip install pytest pytest-cov flake8 flake8-pytest-style black\n            pip install -e .  # Install your project in editable mode\n        - name: Lint with flake8\n          run: |\n            flake8 .\n        - name: Test with pytest\n          run: |\n            pytest --cov --cov-report xml\n        - name: Upload coverage to Codecov\n          uses: codecov/codecov-action@v3\n          with:\n            token: ${{ secrets.CODECOV_TOKEN }}\n            flags: unittests\n            env_vars: OS,PYTHON\n            name: codecov-pytest\n  \n\nBy following these best practices, you can write effective and maintainable tests with pytest, improving the quality and reliability of your Python applications.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pytest.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "pytest",
      "this",
      "rule",
      "file",
      "outlines",
      "comprehensive",
      "best",
      "practices",
      "using",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pytest",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-python",
    "description": "Comprehensive guidelines for Python development, covering code organization, performance, security, testing, and more.  These rules promote maintainable, efficient, and secure Python codebases.",
    "author": "sanjeed5",
    "tags": [
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/python.mdc",
    "content": "# Python Best Practices and Coding Standards\n\nThis document outlines comprehensive best practices and coding standards for Python development, aiming to promote clean, efficient, maintainable, and secure code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n*   **Flat is better than nested (but not always).**  Start with a simple structure and refactor as needed.\n*   **Packages vs. Modules:** Use packages (directories with `__init__.py`) for logical grouping of modules.\n*   **src layout:** Consider using a `src` directory to separate application code from project-level files (setup.py, requirements.txt, etc.). This helps avoid import conflicts and clarifies the project's boundaries.\n*   **Typical Project Structure:**\n\n    \n    project_name/\n    ├── src/\n    │   ├── package_name/\n    │   │   ├── __init__.py\n    │   │   ├── module1.py\n    │   │   ├── module2.py\n    │   ├── main.py  # Entry point\n    ├── tests/\n    │   ├── __init__.py\n    │   ├── test_module1.py\n    │   ├── test_module2.py\n    ├── docs/\n    │   ├── conf.py\n    │   ├── index.rst\n    ├── .gitignore\n    ├── pyproject.toml or setup.py\n    ├── README.md\n    ├── requirements.txt or requirements-dev.txt\n    \n\n### 1.2. File Naming Conventions\n\n*   **Modules:**  Lowercase, with underscores for readability (e.g., `my_module.py`).\n*   **Packages:** Lowercase (e.g., `my_package`). Avoid underscores unless necessary.\n*   **Tests:** Start with `test_` (e.g., `test_my_module.py`).\n\n### 1.3. Module Organization Best Practices\n\n*   **Single Responsibility Principle:** Each module should have a well-defined purpose.\n*   **Imports:**\n    *   Order: standard library, third-party, local.\n    *   Absolute imports are generally preferred (e.g., `from my_package.module1 import function1`).\n    *   Use explicit relative imports (`from . import sibling_module`) when dealing with complex package layouts where absolute imports are overly verbose or impractical.\n*   **Constants:**  Define module-level constants in uppercase (e.g., `MAX_ITERATIONS = 100`).\n*   **Dunder names:** `__all__`, `__version__`, etc. should be after the module docstring but before any imports (except `from __future__`).  Use `__all__` to explicitly define the public API.\n\n### 1.4. Component Architecture Recommendations\n\n*   **Layered Architecture:** Suitable for larger applications, separating concerns into presentation, business logic, and data access layers.\n*   **Microservices:**  For very large applications, consider breaking the system into smaller, independent services.\n*   **Hexagonal/Clean Architecture:** Emphasizes decoupling business logic from external dependencies like databases and frameworks.\n*   **Dependency Injection:** Use dependency injection to improve testability and reduce coupling.\n\n### 1.5. Code Splitting Strategies\n\n*   **By Functionality:**  Split code into modules based on distinct functionalities (e.g., user management, data processing).\n*   **By Layer:** Separate presentation, business logic, and data access code.\n*   **Lazy Loading:** Use `importlib.import_module()` to load modules on demand, improving startup time.\n*   **Conditional Imports:** Import modules only when needed, based on certain conditions.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton:**  Restrict instantiation of a class to one object.\n*   **Factory:**  Create objects without specifying the exact class to be created.\n*   **Observer:**  Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified.\n*   **Strategy:**  Define a family of algorithms, encapsulate each one, and make them interchangeable.\n*   **Decorator:**  Add responsibilities to objects dynamically.\n*   **Context Manager:** Guarantees resources are properly cleaned up (e.g., files are closed).\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Validation:** Use libraries like `pydantic` or `marshmallow` for data validation and serialization.\n*   **Configuration Management:** Use libraries like `python-decouple`, `dynaconf` or standard library's `configparser` to manage environment-specific settings.\n*   **Logging:** Use the `logging` module for structured logging. Configure log levels and handlers appropriately.\n*   **Command-Line Interfaces:** Use `argparse`, `click` or `typer` for creating command-line interfaces.\n*   **Asynchronous Programming:** Use `asyncio` for I/O-bound and concurrency problems.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **God Class:** A class that does too much.  Break it down into smaller, more focused classes.\n*   **Shotgun Surgery:**  Making small changes to many different classes at once. Indicates poor cohesion.\n*   **Spaghetti Code:**  Unstructured and difficult-to-follow code.  Refactor using well-defined functions and classes.\n*   **Duplicate Code:**  Extract common code into reusable functions or classes (DRY - Don't Repeat Yourself).\n*   **Magic Numbers/Strings:**  Use named constants instead of hardcoded values.\n*   **Nested Callbacks:**  Avoid excessive nesting of callbacks. Use `async/await` or promises for better readability.\n*   **Premature Optimization:** Don't optimize code before identifying bottlenecks.\n\n### 2.4. State Management Best Practices\n\n*   **Stateless Functions:** Prefer stateless functions where possible.\n*   **Immutable Data:** Use immutable data structures to prevent accidental modification.\n*   **Explicit State:**  Manage state explicitly using classes or data structures.  Avoid relying on global variables.\n*   **Context Variables:** Use `contextvars` (Python 3.7+) for managing request-scoped state in asynchronous applications.\n*   **Redux-like patterns:** Consider redux-like patterns for managing client-side and complex application state.\n\n### 2.5. Error Handling Patterns\n\n*   **Specific Exceptions:** Catch specific exceptions rather than broad `Exception` or `BaseException`.\n*   **`try...except...finally`:** Use `finally` to ensure cleanup code is always executed.\n*   **Context Managers:**  Use context managers (`with open(...) as f:`) for resource management.\n*   **Logging Errors:** Log exceptions with complete traceback information.\n*   **Raising Exceptions:** Raise exceptions with informative error messages.\n*   **Custom Exceptions:** Create custom exception classes for specific error conditions.\n*   **Avoid using exceptions for control flow.** Exceptions should represent exceptional circumstances.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Profiling:**  Use `cProfile` to identify performance bottlenecks.\n*   **Efficient Data Structures:**  Choose the right data structure for the task (e.g., `set` for membership testing, `dict` for lookups).\n*   **List Comprehensions and Generators:**  Use list comprehensions and generator expressions for concise and efficient code.\n*   **Vectorization with NumPy:**  Use NumPy for numerical computations, leveraging vectorized operations.\n*   **Just-In-Time Compilation (JIT):**  Consider using JIT compilers like Numba for performance-critical code.\n*   **Caching:** Implement caching mechanisms using `functools.lru_cache` or external caching libraries like Redis or Memcached.\n*   **String Concatenation:** Use `''.join(iterable)` for efficient string concatenation.\n*   **Avoid Global Variables:** Accessing local variables is faster than accessing global variables.\n*   **Cython:** Use Cython to write C extensions for Python, improving performance.\n\n### 3.2. Memory Management Considerations\n\n*   **Garbage Collection:**  Understand Python's garbage collection mechanism.\n*   **Object References:**  Be mindful of object references and circular dependencies, which can prevent garbage collection.\n*   **Memory Profiling:** Use `memory_profiler` to identify memory leaks.\n*   **Slots:** Use `__slots__` in classes to reduce memory footprint (disables `__dict__`).\n*   **Generators:** Use generators for processing large datasets without loading them into memory.\n*   **Data type sizing:** Use the most efficient data types possible to reduce memory use.\n\n### 3.3. Rendering Optimization\n\n*   N/A for core Python libraries. Relevant for GUI frameworks (e.g., Tkinter, PyQt, Kivy).\n*   For web development with frameworks such as Django, Flask, or Pyramid, use efficient templating, caching and database query optimizations.\n\n### 3.4. Bundle Size Optimization\n\n*   N/A for core Python libraries. Relevant for web applications or when creating executable bundles.\n*   Use tools like `PyInstaller` or `cx_Freeze` to create executable bundles.\n*   Minimize dependencies to reduce bundle size.\n*   Use code minification techniques.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Module Loading:**  Use `importlib.import_module()` to load modules on demand.\n*   **Data Loading:** Load large datasets only when needed.\n*   **Deferred Execution:**  Use generators or coroutines to defer execution of code.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **SQL Injection:**  Use parameterized queries or ORMs to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input and escape output to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):**  Use CSRF tokens to protect against CSRF attacks.\n*   **Command Injection:**  Avoid executing arbitrary commands based on user input. If necessary, sanitize input carefully.\n*   **Path Traversal:**  Validate file paths to prevent path traversal attacks.\n*   **Denial of Service (DoS):** Implement rate limiting and input validation to protect against DoS attacks.\n*   **Pickle Deserialization:**  Avoid using `pickle` to deserialize untrusted data, as it can lead to arbitrary code execution. Use safer alternatives like JSON or Protocol Buffers.\n*   **Dependency Vulnerabilities:** Regularly audit and update dependencies to address security vulnerabilities.\n*   **Hardcoded Secrets:** Never hardcode secrets (passwords, API keys) in code. Use environment variables or secure configuration files.\n\n### 4.2. Input Validation Best Practices\n\n*   **Whitelisting:**  Validate input against a whitelist of allowed values.\n*   **Regular Expressions:** Use regular expressions to validate input formats.\n*   **Data Type Validation:**  Ensure input data types are correct.\n*   **Length Validation:**  Limit the length of input strings.\n*   **Sanitization:**  Remove or escape potentially harmful characters from input.\n*   **Use libraries:** Use libraries like `cerberus` and `schematics` to assist with validating the input.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **Authentication:**\n    *   Use strong password hashing algorithms (e.g., bcrypt, Argon2).\n    *   Implement multi-factor authentication (MFA).\n    *   Use secure session management techniques.\n    *   Consider using a dedicated authentication service (e.g., Auth0, Okta).\n*   **Authorization:**\n    *   Implement role-based access control (RBAC) or attribute-based access control (ABAC).\n    *   Use a permissions system to control access to resources.\n    *   Enforce the principle of least privilege.\n    *   Use access tokens (JWTs).\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data when displaying it to users.\n*   **Tokenization:** Replace sensitive data with non-sensitive tokens.\n*   **Data Loss Prevention (DLP):** Implement DLP measures to prevent sensitive data from leaving the organization.\n*   **Regular backups and disaster recovery plans.**\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:**  Always use HTTPS for API communication.\n*   **API Keys:**  Use API keys for authentication.\n*   **OAuth 2.0:**  Use OAuth 2.0 for delegated authorization.\n*   **Input validation**: Validate all API requests before processing.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Web Application Firewall (WAF)** Implement WAF to provide centralized security layer.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Test Individual Units:** Test individual functions, classes, or modules in isolation.\n*   **Test-Driven Development (TDD):** Write tests before writing code.\n*   **Coverage:**  Aim for high test coverage.\n*   **Assertion Styles:** Use appropriate assertion methods (e.g., `assertEqual`, `assertTrue`, `assertRaises`).\n*   **Boundary conditions:** Test boundary conditions and edge cases.\n*   **Error conditions:** Test that exceptions are raised when appropriate.\n\n### 5.2. Integration Testing Approaches\n\n*   **Test Interactions:** Test the interactions between different modules or components.\n*   **Database Testing:** Test database interactions.\n*   **API Testing:** Test API endpoints.\n*   **Mock External Services:** Use mocks to simulate external services during integration tests.\n*   **Focus on key workflows.** Integration tests should exercise the most important user workflows.\n\n### 5.3. End-to-End Testing Recommendations\n\n*   **Test Entire System:** Test the entire system from end to end.\n*   **User Perspective:** Write tests from the perspective of the user.\n*   **Browser Automation:** Use browser automation tools like Selenium or Playwright.\n*   **Real-World Scenarios:** Simulate real-world scenarios in end-to-end tests.\n*   **Focus on critical paths.** End-to-end tests are expensive to write and maintain, so focus on the most critical paths.\n\n### 5.4. Test Organization Best Practices\n\n*   **Separate Test Directory:**  Keep tests in a separate `tests` directory.\n*   **Mirror Source Structure:**  Mirror the source code structure in the test directory.\n*   **Test Modules:** Create test modules for each source module.\n*   **Test Classes:**  Use test classes to group related tests.\n*   **Use a test runner:** Use `pytest` or `unittest` test runners.\n*   **Use fixtures:** Utilize fixtures to setup and tear down resources for tests.\n\n### 5.5. Mocking and Stubbing Techniques\n\n*   **`unittest.mock`:** Use the `unittest.mock` module for mocking and stubbing.\n*   **Patching:**  Use `patch` to replace objects with mocks during tests.\n*   **Side Effects:**  Define side effects for mocks to simulate different scenarios.\n*   **Mocking External Dependencies:** Mock external dependencies like databases, APIs, and file systems.\n*   **Use dependency injection for testability.** Dependency injection makes it easier to mock dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Mutable Default Arguments:**  Avoid using mutable default arguments in function definitions.\n*   **Scope of Variables:**  Be aware of variable scope in nested functions.\n*   **`==` vs. `is`:**  Use `==` for value comparison and `is` for object identity comparison.\n*   **`try...except` Blocks:** Placing too much code inside try blocks. Keep try blocks as small as possible.\n*   **Ignoring Exceptions:** Swallowing exceptions without handling or logging them.\n*   **Incorrect indentation.**  Indentation errors are a common source of bugs.\n*   **Not using virtual environments.** Not using virtual environments can lead to dependency conflicts.\n\n### 6.2. Edge Cases\n\n*   **Floating-Point Arithmetic:** Be aware of the limitations of floating-point arithmetic.\n*   **Unicode Handling:** Handle Unicode strings carefully.\n*   **File Encoding:**  Specify file encoding when reading and writing files.\n*   **Time Zones:**  Handle time zones correctly.\n*   **Resource limits:** Be aware of and handle system resource limits (e.g., file handles, memory).\n\n### 6.3. Version-Specific Issues\n\n*   **Python 2 vs. Python 3:** Be aware of the differences between Python 2 and Python 3.\n*   **Syntax Changes:**  Be aware of syntax changes in different Python versions.\n*   **Library Compatibility:**  Ensure that libraries are compatible with the Python version being used.\n*   **Deprecated features.** Avoid using deprecated features.\n\n### 6.4. Compatibility Concerns\n\n*   **Operating Systems:** Test code on different operating systems (Windows, macOS, Linux).\n*   **Python Implementations:**  Consider compatibility with different Python implementations (CPython, PyPy, Jython).\n*   **Database Versions:** Ensure compatibility with different database versions.\n*   **External Libraries:**  Be aware of compatibility issues with external libraries.\n\n### 6.5. Debugging Strategies\n\n*   **`pdb`:**  Use the `pdb` debugger for interactive debugging.\n*   **Logging:**  Use logging to track program execution.\n*   **Print Statements:** Use print statements for simple debugging.\n*   **Assertions:**  Use assertions to check for expected conditions.\n*   **Profiling:** Use profilers to identify performance bottlenecks.\n*   **Code Analysis Tools:** Use code analysis tools like pylint or flake8 to detect potential problems.\n*   **Remote debugging:** Use remote debugging tools when debugging code running on remote servers.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDEs:** PyCharm, VS Code (with Python extension), Sublime Text.\n*   **Virtual Environment Managers:** `venv` (built-in), `virtualenv`, `conda`, `pipenv`.\n*   **Package Managers:** `pip` (default), `conda`, `poetry`.\n*   **Debuggers:** `pdb`, IDE debuggers.\n*   **Profilers:** `cProfile`, `memory_profiler`.\n*   **Linters:** `pylint`, `flake8`.\n*   **Formatters:** `black`, `autopep8`, `YAPF`.\n*   **Static Analyzers:** `mypy`, `pytype`.\n*    **Notebook environments**: Jupyter Notebook, Jupyter Lab, Google Colab.\n\n### 7.2. Build Configuration Best Practices\n\n*   **`pyproject.toml`:**  Use `pyproject.toml` for build configuration (PEP 518, PEP 621).\n*   **`setup.py`:**  Use `setup.py` for legacy projects (but prefer `pyproject.toml` for new projects).\n*   **Dependency Management:**  Specify dependencies in `requirements.txt` or `pyproject.toml`.\n*   **Virtual Environments:**  Use virtual environments to isolate project dependencies.\n*   **Reproducible builds:** Ensure reproducible builds by pinning dependencies.\n\n### 7.3. Linting and Formatting Recommendations\n\n*   **PEP 8:** Adhere to PEP 8 style guidelines.\n*   **Linters:** Use linters to enforce code style and detect potential problems.\n*   **Formatters:** Use formatters to automatically format code according to PEP 8.\n*   **Pre-commit Hooks:** Use pre-commit hooks to run linters and formatters before committing code.\n*   **Consistent Style:** Maintain a consistent code style throughout the project.\n\n### 7.4. Deployment Best Practices\n\n*   **Virtual Environments:** Deploy applications in virtual environments.\n*   **Dependency Management:**  Install dependencies using `pip install -r requirements.txt` or `poetry install`.\n*   **Process Managers:** Use process managers like `systemd`, `Supervisor`, or `Docker` to manage application processes.\n*   **Web Servers:**  Use web servers like Gunicorn or uWSGI to serve web applications.\n*   **Load Balancing:** Use load balancers to distribute traffic across multiple servers.\n*   **Containerization:** Use containerization technologies like Docker to package and deploy applications.\n*   **Infrastructure as Code (IaC)** Manage infrastructure using IaC tools like Terraform or CloudFormation.\n\n### 7.5. CI/CD Integration Strategies\n\n*   **Continuous Integration (CI):** Automatically build and test code on every commit.\n*   **Continuous Delivery (CD):** Automatically deploy code to staging or production environments.\n*   **CI/CD Tools:** Use CI/CD tools like Jenkins, GitLab CI, GitHub Actions, CircleCI, or Travis CI.\n*   **Automated Testing:**  Include automated tests in the CI/CD pipeline.\n*   **Code Analysis:** Integrate code analysis tools into the CI/CD pipeline.\n*   **Automated deployments.** Automate the deployment process to reduce manual effort and errors.\n\nBy adhering to these best practices and coding standards, developers can create Python code that is more robust, maintainable, and secure.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "python.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "python",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "testing",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-pytorch",
    "description": "This rule provides comprehensive guidelines for PyTorch development, covering code organization, performance optimization, security, testing, and common pitfalls. It aims to ensure readable, maintainable, and efficient PyTorch code.",
    "author": "sanjeed5",
    "tags": [
      "pytorch",
      "ml",
      "ai",
      "python",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "data-ai",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/pytorch.mdc",
    "content": "# PyTorch Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for developing PyTorch projects, encompassing code organization, performance optimization, security, testing methodologies, and common pitfalls. Adhering to these best practices will result in more readable, maintainable, and efficient PyTorch code.\n\n**Library Information:**\n- Name: PyTorch\n- Category: ai_ml\n- Subcategory: machine_learning\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nA well-organized directory structure enhances code maintainability and collaboration. Here's a recommended structure for PyTorch projects:\n\n\nproject_root/\n├── data/\n│   ├── raw/\n│   ├── processed/\n│   └── ...\n├── models/\n│   ├── layers.py\n│   ├── networks.py\n│   ├── losses.py\n│   ├── ops.py\n│   └── model_name.py\n├── src/\n│   ├── data/\n│   │   ├── datasets.py\n│   │   ├── dataloaders.py\n│   │   └── transforms.py\n│   ├── models/\n│   │   └── ... (model-related code)\n│   ├── utils/\n│   │   └── ... (utility functions)\n│   └── visualization/\n│       └── ...\n├── notebooks/\n│   └── ... (Jupyter notebooks for experimentation)\n├── tests/\n│   ├── unit/\n│   ├── integration/\n│   └── ...\n├── scripts/\n│   └── train.py\n│   └── eval.py\n├── configs/\n│   └── ... (Configuration files, e.g., YAML)\n├── README.md\n├── requirements.txt\n├── .gitignore\n└── ...\n\n\n-   `data/`: Stores raw and processed datasets.\n-   `models/`: Contains PyTorch model definitions, layers, and custom loss functions.  Separate network architectures, individual layers/blocks, and operations into different files.\n-   `src/`: Holds the main source code, including data loading, model definitions, utility functions, and visualization tools.  It's common to split the `src/` folder further based on responsibilities.\n-   `notebooks/`: Jupyter notebooks for experimentation and exploration.  Use notebooks for initial exploration and prototyping but transition finalized code to Python scripts.\n-   `tests/`: Unit, integration, and end-to-end tests.\n-   `scripts/`: Training, evaluation, and deployment scripts.  The main training script should import model definitions.\n-   `configs/`: Configuration files for hyperparameter settings and other parameters.\n\n### 1.2 File Naming Conventions\n\n-   Use descriptive and consistent file names.\n-   Python files: `lower_with_under.py` (e.g., `data_loader.py`, `model_utils.py`).\n-   Model files: `model_name.py` (e.g., `resnet.py`, `transformer.py`).\n-   Configuration files: `config_name.yaml` (e.g., `train_config.yaml`).\n\n### 1.3 Module Organization\n\n-   Group related functions and classes into modules.\n-   Use clear and concise module names.\n-   Include a docstring at the beginning of each module to describe its purpose.\n-   Follow a consistent import style:\n    python\n    # Standard library imports\n    import os\n    import sys\n\n    # Third-party library imports\n    import numpy as np\n    import torch\n    import torchvision\n\n    # Local application/library imports\n    from src.data import data_loader\n    from src.models import resnet\n    from src.utils import helper_functions\n    \n\n### 1.4 Component Architecture\n\n-   **`nn.Module`:**  The fundamental building block for creating neural networks in PyTorch.  Always subclass `nn.Module` for defining models, layers, and custom operations.\n-   **`forward()` method:**  Implement the forward pass of your module within the `forward()` method. PyTorch uses the `__call__` method, which executes `forward()`, to pass data through the model. \n-   **Separation of Concerns:**  Design models as compositions of smaller, reusable modules.  This promotes modularity and simplifies debugging.\n\nExample:\n\npython\nimport torch.nn as nn\n\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        self.relu = nn.ReLU()\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.bn(x)\n        return x\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.conv1 = ConvBlock(3, 32)\n        self.conv2 = ConvBlock(32, 64)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc = nn.Linear(64 * 8 * 8, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.pool(x)\n        x = self.conv2(x)\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n\n\n### 1.5 Code Splitting Strategies\n\n-   **Vertical Splitting (Feature-based):**  Divide code based on features or functionalities (e.g., data loading, model definition, training loop). This approach aligns well with module organization.\n-   **Horizontal Splitting (Layer-based):**  Split code based on layers or components of a neural network.  This is suitable for complex models with distinct layers (e.g., encoder, decoder).  The `models/` directory structure supports this.\n-   **Microservices (for large projects):** For very large and complex machine learning deployments, consider breaking the workload into microservices - one for training, one for inference, another for data preprocessing, etc.  This can improve scalability and fault tolerance.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to PyTorch\n\n-   **`nn.Sequential`:**  A container for chaining layers in a sequential manner.  Suitable for simple, linear models.\n-   **Custom `nn.Module`:**  Create custom modules for encapsulating reusable blocks of layers or operations.  This promotes modularity and code reuse.\n-   **Hooks:**  Utilize forward and backward hooks for inspecting and modifying activations and gradients during training.  Useful for debugging and research.\n-   **DataParallel/DistributedDataParallel:** Wrap models with `DataParallel` or `DistributedDataParallel` to leverage multiple GPUs for training. `DistributedDataParallel` is generally preferred for multi-node training and offers better performance.\n-   **Transfer Learning:** Reuse pretrained models from `torchvision.models` as a starting point for new tasks. Fine-tune the pretrained weights or add custom layers.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Data Loading:** Use `torch.utils.data.Dataset` and `torch.utils.data.DataLoader` for efficient data loading and batching. Use custom Datasets to control data transformation.\n-   **Model Definition:** Define models as classes that inherit from `nn.Module`. Use the layers defined in `torch.nn` to build the model.\n-   **Training Loop:** Implement a structured training loop that iterates over epochs and batches. Include forward pass, loss calculation, backward pass, and optimization steps.\n-   **Validation:** Evaluate model performance on a validation set during training to monitor overfitting and tune hyperparameters.\n-   **Checkpointing:** Save model weights and optimizer state during training to resume training or load the best model.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Hardcoding shapes:** Avoid hardcoding input or output shapes. Use dynamic shapes or calculate shapes based on input data.\n-   **Global Variables:** Minimize the use of global variables. Pass data and configurations as function arguments.\n-   **Magic Numbers:** Avoid using magic numbers without explanation. Define constants with descriptive names.\n-   **Deeply Nested Loops:**  Optimize performance-critical sections of code.  Consider using vectorized operations or optimized data structures to avoid nested loops where possible.\n-   **Ignoring Warnings:**  Address all warnings. They often indicate potential problems or inefficiencies in your code. Use a debugger and logging to diagnose runtime behavior.\n-   **Over-commenting:**  Avoid redundant comments that simply reiterate the code. Focus on explaining the *why* rather than the *what*.\n-   **Not using GPU when Available:** Always check if cuda is available and moves tensors and models to cuda for faster training and inference.\n\n### 2.4 State Management Best Practices\n\n-   **Model Parameters:** Model parameters are automatically managed by PyTorch. Use `nn.Parameter` to register tensors as model parameters.\n-   **Buffers:** Use `nn.Buffer` to store non-trainable tensors that are part of the model state (e.g., running statistics in BatchNorm).\n-   **Optimizer State:** The optimizer maintains its own state, such as learning rate and momentum. Access and modify optimizer state through the `optimizer.state_dict()` and `optimizer.load_state_dict()` methods.\n-   **Random Seeds:** Set random seeds for reproducibility:\n\n    python\n    import numpy as np\n    import torch\n\n    def set_seed(seed):\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed(seed)\n            torch.cuda.manual_seed_all(seed)  # if using multiple GPUs\n            torch.backends.cudnn.deterministic = True #Ensures that CUDA uses deterministic algorithms.\n            torch.backends.cudnn.benchmark = False #Prevents CUDA from benchmarking multiple convolution algorithms. \n    \n\n### 2.5 Error Handling Patterns\n\n-   **Specific Exception Handling:** Catch specific exceptions rather than using bare `except` clauses. This allows you to handle different error scenarios appropriately.\n-   **Logging:** Use the `logging` module to log errors and warnings. Include relevant information, such as timestamps, file names, and line numbers.\n-   **Assertion Statements:** Use `assert` statements to check for unexpected conditions. This can help catch errors early in development.\n-   **Custom Exceptions:** Define custom exception classes for specific error conditions in your application. This improves code readability and maintainability.\n-   **Graceful Degradation:**  Implement mechanisms to handle errors gracefully, such as providing default values or skipping problematic data points.  Avoid crashing the application.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **GPU Utilization:** Use a GPU for training and inference. Move models and tensors to the GPU using `.to('cuda')`.\n-   **Batch Size:** Tune the batch size to maximize GPU utilization without running out of memory. Larger batch sizes generally lead to better performance.\n-   **Data Loading:** Optimize data loading by using multiple workers in the `DataLoader`. Consider using asynchronous data loading techniques.\n-   **Mixed Precision Training:** Use mixed precision training (`torch.cuda.amp`) to reduce memory usage and accelerate training on NVIDIA GPUs with Tensor Cores.\n-   **Gradient Accumulation:** Accumulate gradients over multiple batches to simulate a larger batch size when memory is limited.\n-   **Operator Fusion:**  Utilize PyTorch's JIT compiler (`torch.jit.script` or `torch.jit.trace`) to fuse multiple operations into a single kernel, reducing overhead and improving performance.\n-   **Memory Usage:** When using `DataParallel`, ensure that the input data is evenly distributed across the available GPUs. Uneven data distribution can result in memory imbalances and slow down training.\n\n### 3.2 Memory Management\n\n-   **Tensor Deletion:** Delete unnecessary tensors using `del` to free up memory.\n-   **`torch.no_grad()`:** Use `torch.no_grad()` during inference to disable gradient calculation and reduce memory usage.\n-   **In-place Operations:** Use in-place operations (e.g., `x.add_(1)`) to modify tensors directly without creating new tensors. Be cautious with in-place operations as they can sometimes cause issues with autograd.\n-   **Memory Profiling:** Use memory profiling tools to identify memory leaks and optimize memory usage.\n-   **Garbage Collection:**  Explicitly call `gc.collect()` to force garbage collection.  This can be useful in situations where memory is not being released promptly.\n\n### 3.3 Rendering Optimization (if applicable)\n\n-   This section applies if PyTorch is used for rendering tasks (e.g., neural rendering).\n-   **Optimize Mesh Data Structures:** Use efficient mesh data structures to reduce memory usage and improve rendering performance.\n-   **Level of Detail (LOD):** Implement LOD techniques to reduce the complexity of rendered objects at a distance.\n-   **Caching:** Cache frequently accessed data to reduce rendering time.\n\n### 3.4 Bundle Size Optimization (if applicable)\n\n-   This section applies if PyTorch models are deployed in web applications or other size-sensitive environments.\n-   **Model Quantization:** Quantize models to reduce their size. Use `torch.quantization` to quantize models to 8-bit integers.\n-   **Model Pruning:** Prune unimportant weights from models to reduce their size. Use `torch.nn.utils.prune` to prune models.\n-   **ONNX Export:** Convert PyTorch models to ONNX format for deployment on various platforms.\n\n### 3.5 Lazy Loading Strategies\n\n-   **Lazy Initialization:** Defer the initialization of expensive resources until they are needed.\n-   **Data Streaming:** Load data in smaller chunks instead of loading the entire dataset into memory at once.\n-   **Just-In-Time (JIT) Compilation:** Use `torch.jit.script` or `torch.jit.trace` to compile models just before they are used.  This can improve performance and reduce memory usage.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **Adversarial Attacks:**  Be aware of adversarial attacks that can manipulate model predictions. Implement techniques like adversarial training and input sanitization.\n-   **Data Poisoning:**  Protect against data poisoning attacks by validating input data and using robust training techniques.\n-   **Model Extraction:**  Prevent model extraction by limiting access to model weights and predictions.\n-   **Integer Overflow:** Be aware of integer overflow issues in user-provided data.\n\n### 4.2 Input Validation\n\n-   **Data Type Validation:** Ensure that input data has the correct data type.\n-   **Range Validation:** Check that input values are within a valid range.\n-   **Format Validation:** Validate the format of input strings (e.g., URLs, email addresses).\n-   **Sanitization:** Sanitize input data to remove potentially malicious characters or code.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **API Keys:** Use API keys to authenticate clients accessing your models.\n-   **OAuth 2.0:** Implement OAuth 2.0 for secure authorization of user access.\n-   **Role-Based Access Control (RBAC):** Use RBAC to restrict access to specific models or functionalities based on user roles.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption:** Encrypt sensitive data at rest and in transit.\n-   **Anonymization:** Anonymize data to protect user privacy.\n-   **Differential Privacy:** Use differential privacy techniques to protect the privacy of training data.\n-   **Access Control:** Implement strict access control policies to limit access to sensitive data.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS:** Use HTTPS to encrypt communication between clients and your API.\n-   **TLS/SSL:** Use TLS/SSL certificates to secure your API endpoints.\n-   **Rate Limiting:** Implement rate limiting to prevent denial-of-service attacks.\n-   **Input Validation:** Always validate and sanitize input data to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test Individual Modules:** Write unit tests for individual modules to ensure they function correctly.\n-   **Test Edge Cases:** Test edge cases and boundary conditions to identify potential errors.\n-   **Use Assertions:** Use assertions to verify expected outcomes.\n-   **Test Model Outputs:** Verify that model outputs have the correct shape and data type.\n\n### 5.2 Integration Testing\n\n-   **Test Interactions Between Modules:** Write integration tests to ensure that different modules work together correctly.\n-   **Test Data Pipelines:** Test the entire data pipeline, from data loading to model output.\n-   **Test End-to-End Functionality:** Test the entire application to ensure that it meets the requirements.\n\n### 5.3 End-to-End Testing\n\n-   **Simulate User Interactions:** Write end-to-end tests that simulate user interactions with the application.\n-   **Test the Entire System:** Test the entire system, including the user interface, API, and database.\n-   **Verify Expected Outcomes:** Verify that the application produces the expected outcomes.\n\n### 5.4 Test Organization\n\n-   **Separate Test Files:** Create separate test files for each module or component.\n-   **Use a Test Runner:** Use a test runner (e.g., `pytest`, `unittest`) to discover and run tests.\n-   **Follow a Consistent Naming Convention:** Follow a consistent naming convention for test files and test functions.\n\n### 5.5 Mocking and Stubbing\n\n-   **Use Mocks to Isolate Units:** Use mocks to isolate units of code from their dependencies.\n-   **Use Stubs to Provide Test Data:** Use stubs to provide test data to units of code.\n-   **Verify Interactions with Dependencies:** Verify that units of code interact with their dependencies as expected.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Incorrect Tensor Shapes:** Pay close attention to tensor shapes when performing operations. Use `torch.Size()` to check tensor shapes.\n-   **Gradient Issues:**  Be mindful of gradient flow.  Ensure that gradients are properly calculated and propagated through the network. Use `torch.autograd.set_detect_anomaly(True)` for debugging autograd issues.\n-   **Memory Leaks:** Be careful to deallocate tensors when they are no longer needed.  Use memory profiling tools to identify memory leaks.\n-   **Data Type Mismatches:** Ensure that tensors have the correct data type (e.g., `torch.float32`, `torch.int64`).\n-   **Device Mismatches:** Ensure that tensors and models are on the same device (CPU or GPU).\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **Empty Datasets:** Handle cases where datasets are empty or contain missing data.\n-   **Out-of-Memory Errors:** Handle out-of-memory errors gracefully by reducing batch size or using gradient accumulation.\n-   **Numerical Instability:** Be aware of numerical instability issues, such as vanishing or exploding gradients. Use techniques like gradient clipping and batch normalization.\n\n### 6.3 Version-Specific Issues\n\n-   **Compatibility with Libraries:**  Be aware of compatibility issues between different versions of PyTorch and other libraries.\n-   **API Changes:**  Track API changes in PyTorch releases and update your code accordingly.\n\n### 6.4 Compatibility Concerns\n\n-   **Hardware Compatibility:** Ensure that your code is compatible with different hardware configurations (e.g., different GPUs).\n-   **Operating System Compatibility:** Ensure that your code is compatible with different operating systems (e.g., Linux, Windows, macOS).\n\n### 6.5 Debugging Strategies\n\n-   **Print Statements:** Use print statements to inspect the values of tensors and variables.\n-   **Debuggers:** Use a debugger (e.g., `pdb`) to step through your code and inspect the state of your application.\n-   **TensorBoard:** Use TensorBoard to visualize model training progress, including loss curves, metrics, and model architecture.\n-   **`torch.autograd.set_detect_anomaly(True)`:**  A powerful tool for debugging autograd issues.  It will raise an error when a NaN gradient is detected, helping you pinpoint the source of the problem.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **IDEs:** Visual Studio Code (with Python extension), PyCharm.\n-   **Virtual Environments:** `venv`, `conda`.\n-   **Debugging Tools:** `pdb`, `ipdb`.\n-   **Profiling Tools:** `torch.profiler`, `memory_profiler`.\n\n### 7.2 Build Configuration\n\n-   **`requirements.txt`:**  Specify project dependencies in a `requirements.txt` file. Use `pip freeze > requirements.txt` to generate the file.\n\n    Example `requirements.txt`:\n    \n    torch==1.13.1\ntorchvision==0.14.1\nnumpy==1.24.1\n    \n-   **`setup.py` (for libraries):** Use `setup.py` to define your library's metadata and dependencies.\n\n### 7.3 Linting and Formatting\n\n-   **Linters:** `flake8`, `pylint`.\n-   **Formatters:** `black`, `autopep8`.\n-   **Pre-commit Hooks:** Use pre-commit hooks to automatically run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n-   **Model Serialization:** Use `torch.save` to serialize models for deployment. Use `torch.load` to load models.\n-   **ONNX Export:** Convert PyTorch models to ONNX format for deployment on various platforms.\n-   **Serving Frameworks:** Use serving frameworks like TorchServe, FastAPI, or Flask to deploy PyTorch models as REST APIs.\n\n### 7.5 CI/CD Integration\n\n-   **Continuous Integration (CI):** Use CI tools like Jenkins, GitHub Actions, or GitLab CI to automatically build and test your code.\n-   **Continuous Deployment (CD):** Use CD tools to automatically deploy your code to production environments.\n-   **Automated Testing:**  Integrate automated testing into your CI/CD pipeline to ensure code quality and prevent regressions.  Run unit, integration, and end-to-end tests.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "pytorch.mdc"
    },
    "subcategory": "machine-learning",
    "keywords": [
      "cursor",
      "pytorch",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "organization",
      "ml",
      "ai",
      "python",
      "cursor-rule",
      "mdc",
      "languages",
      "machine-learning"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "pytorch",
        "ml",
        "ai",
        "python",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-qwik",
    "description": "This rule provides comprehensive best practices for developing Qwik applications, covering code organization, performance, security, testing, and common pitfalls. It aims to guide developers in writing maintainable, efficient, and secure Qwik code.",
    "author": "sanjeed5",
    "tags": [
      "qwik",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/qwik.mdc",
    "content": "# Qwik Library Best Practices\n\nThis document outlines the best practices for developing Qwik applications. Adhering to these guidelines will help you write maintainable, efficient, and secure code.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - `src/`: Contains the source code of your application.\n        - `components/`: Reusable UI components.\n        - `routes/`: Defines the application's routes and pages.  Use the file system routing for easy setup. Each file under `routes` will become a route based on the filename.\n        - `services/`: Contains business logic and data fetching services.\n        - `utils/`: Utility functions and helpers.\n        - `styles/`: Global styles and themes.\n        - `types/`: Type definitions used throughout the application.\n    - `public/`: Static assets like images, fonts, and favicons.\n    - `vite.config.ts`: Vite configuration file.\n    - `tsconfig.json`: TypeScript configuration file.\n    - `.eslintrc.js`: ESLint configuration file.\n\n- **File Naming Conventions:**\n    - Components: `ComponentName.tsx` (e.g., `MyButton.tsx`).\n    - Services: `serviceName.ts` (e.g., `userService.ts`).\n    - Utilities: `utilityName.ts` (e.g., `dateUtils.ts`).\n    - Styles: `componentName.css` or `componentName.module.css`.\n    - Routes: Filename dictates the route path (e.g., `index.tsx` for `/`, `about.tsx` for `/about`).\n\n- **Module Organization:**\n    - Group related components, services, and utilities into modules.\n    - Use `index.ts` files to re-export members from a module for cleaner imports.\n    - Keep modules focused and avoid creating large, monolithic modules.\n\n- **Component Architecture:**\n    - Favor small, reusable components.\n    - Use a component-based architecture for building UIs.\n    - Separate concerns: presentational components and container components.\n        - Presentational components: Focus on rendering UI elements based on props.\n        - Container components: Handle data fetching, state management, and business logic.\n    - Use Qwik's `component$` and `use*` APIs for creating and managing components.\n\n- **Code Splitting Strategies:**\n    - Use Qwik's automatic code splitting capabilities.\n    - Ensure routes are lazily loaded by their nature in Qwik.\n    - For larger components or modules, consider manually triggering lazy loading.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Composition:** Build complex components by composing smaller, reusable components.\n    - **Provider Pattern:** Use Context to share state or services across multiple components.\n    - **Hooks:** Use Qwik's `use*` hooks to manage state, effects, and other side effects.\n    - **Factories:** For complex object creation, consider using factory functions.\n\n- **Recommended Approaches:**\n    - Use Qwik's state management features (`useStore`, `useSignal`) for managing component state.\n    - Use Qwik City's routing capabilities for defining routes and navigation.\n    - Use Qwik's optimizer and server rendering for performance.\n\n- **Anti-patterns and Code Smells:**\n    - **Large Components:** Avoid creating overly large components. Break them down into smaller, more manageable pieces.\n    - **Tight Coupling:** Reduce dependencies between components and modules.\n    - **Mutating Props:** Never directly modify props passed to a component.\n    - **Global State Abuse:** Avoid using global state excessively. Prefer component-level state management.\n    - **Ignoring Server Rendering:** Ensure your components are server-renderable for initial page load performance.\n\n- **State Management Best Practices:**\n    - Use Qwik's `useStore` for reactive state management.\n    - Consider `useSignal` for simpler reactive values.\n    - Avoid direct DOM manipulation; rely on Qwik's component rendering.\n\n- **Error Handling Patterns:**\n    - Use `try...catch` blocks to handle errors gracefully.\n    - Display user-friendly error messages.\n    - Log errors for debugging and monitoring.\n    - Consider using error boundary components to prevent entire application crashes.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - Use Qwik's optimizer to minimize bundle size and improve performance.\n    - Leverage server rendering to improve initial page load time.\n    - Optimize images and other assets.\n    - Use Qwik's built-in lazy loading features.\n\n- **Memory Management:**\n    - Avoid memory leaks by properly cleaning up resources.\n    - Unsubscribe from subscriptions and event listeners when components unmount.\n\n- **Rendering Optimization:**\n    - Use `track` property in `useStore` to selectively trigger updates.\n    - Memoize expensive computations using `useComputed$()`\n    - Avoid unnecessary re-renders by ensuring component props are stable.\n\n- **Bundle Size Optimization:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused code and dependencies.\n    - Use tree shaking to eliminate dead code.\n\n- **Lazy Loading Strategies:**\n    - Use Qwik's built-in lazy loading features for components and routes.\n    - Consider using dynamic imports for loading modules on demand.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user inputs and using Qwik's built-in escaping mechanisms.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection by using tokens and validating requests.\n    - **Injection Attacks:** Prevent SQL injection and other injection attacks by using parameterized queries and escaping user inputs.\n\n- **Input Validation:**\n    - Validate all user inputs on both the client and server sides.\n    - Use appropriate data types and formats.\n    - Sanitize user inputs to prevent XSS attacks.\n\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication mechanism, such as OAuth or JWT.\n    - Implement proper authorization checks to ensure users only have access to the resources they are authorized to access.\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between the client and server.\n    - Implement proper access controls to protect data from unauthorized access.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API requests.\n    - Validate API responses.\n    - Implement rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual components, services, and utilities.\n    - Use a testing framework like Jest or Vitest.\n    - Mock dependencies to isolate units under test.\n\n- **Integration Testing:**\n    - Write integration tests to verify interactions between different parts of the application.\n    - Test the integration of components, services, and routes.\n\n- **End-to-end Testing:**\n    - Write end-to-end tests to verify the entire application flow.\n    - Use a testing framework like Playwright or Cypress.\n    - Test user interactions and navigation.\n\n- **Test Organization:**\n    - Organize tests into separate directories based on the type of test.\n    - Use descriptive test names.\n    - Follow a consistent testing style.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate units under test.\n    - Mock external dependencies, such as APIs and databases.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Forgetting to use Qwik's `component$` for creating components.\n    - Not using `use*` hooks for managing state and effects.\n    - Over-reliance on `globalThis`.\n\n- **Edge Cases:**\n    - Handling errors during server rendering.\n    - Dealing with different browser environments.\n    - Managing application state across multiple pages.\n\n- **Version-Specific Issues:**\n    - Be aware of breaking changes between Qwik versions.\n    - Consult the Qwik changelog for migration instructions.\n\n- **Compatibility Concerns:**\n    - Ensure your application is compatible with different browsers and devices.\n    - Use polyfills to support older browsers.\n\n- **Debugging Strategies:**\n    - Use browser developer tools for debugging.\n    - Use Qwik's built-in debugging features.\n    - Log errors and warnings.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - Visual Studio Code with the Qwik extension.\n    - Node.js and npm.\n    - A modern web browser.\n\n- **Build Configuration:**\n    - Use Vite for building and bundling Qwik applications.\n    - Configure Vite to optimize the build for production.\n\n- **Linting and Formatting:**\n    - Use ESLint and Prettier for linting and formatting code.\n    - Configure ESLint and Prettier to follow Qwik's coding style.\n\n- **Deployment Best Practices:**\n    - Deploy your application to a serverless environment, such as Netlify or Vercel.\n    - Configure your server to serve static assets efficiently.\n    - Use a CDN to cache static assets.\n\n- **CI/CD Integration:**\n    - Integrate your application with a CI/CD pipeline.\n    - Automate testing, building, and deployment.",
    "metadata": {
      "globs": "*.ts?(x)",
      "format": "mdc",
      "originalFile": "qwik.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "qwik",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "qwik",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-railway",
    "description": "This rule outlines the best practices and coding standards for developing and deploying applications on the Railway platform, covering aspects from code organization to security and performance.",
    "author": "sanjeed5",
    "tags": [
      "railway",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/railway.mdc",
    "content": "# Railway Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to best practices for developing and deploying applications on the Railway platform. Following these guidelines ensures optimized, secure, and maintainable deployments.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **Project Root:** Contains the `railway.toml` (or `railway.json`) file defining the project configuration, README, LICENSE, and other top-level files.\n*   **src/:**  Holds the source code of the application. Further divided into modules and components.\n*   **config/:** Stores configuration files for different environments (development, staging, production). Use environment variables within Railway for sensitive data.\n*   **scripts/:** Contains utility scripts for build, deployment, and maintenance tasks.\n*   **tests/:** Includes unit, integration, and end-to-end tests.\n*   **docs/:** Holds project documentation, API specifications, and other relevant documentation.\n\nExample:\n\n\nmy-railway-app/\n├── railway.toml\n├── README.md\n├── LICENSE\n├── src/\n│   ├── components/\n│   │   ├── Button.js\n│   │   └── Input.js\n│   ├── modules/\n│   │   ├── auth.js\n│   │   └── data.js\n│   ├── app.js\n│   └── index.js\n├── config/\n│   ├── development.js\n│   └── production.js\n├── scripts/\n│   ├── build.sh\n│   └── deploy.sh\n├── tests/\n│   ├── unit/\n│   ├── integration/\n│   └── e2e/\n└── docs/\n\n\n### 1.2. File Naming Conventions\n\n*   **Source Code:** Use descriptive and consistent naming conventions (e.g., `ComponentName.js`, `moduleName.ts`).\n*   **Configuration Files:** Name configuration files according to their environment (e.g., `development.json`, `production.yml`).\n*   **Test Files:**  Follow a naming convention that clearly identifies the tested component or module (e.g., `ComponentName.test.js`, `moduleName.spec.ts`).\n\n### 1.3. Module Organization\n\n*   **Functional Grouping:** Organize modules based on their functionality (e.g., authentication, data fetching, UI components).\n*   **Loose Coupling:**  Design modules to be loosely coupled, minimizing dependencies between them.\n*   **Clear Interfaces:** Define clear and well-documented interfaces for each module.\n*   **Avoid Circular Dependencies:** Prevent circular dependencies between modules to improve maintainability.\n\n### 1.4. Component Architecture\n\n*   **Component-Based Approach:** Break down the application into reusable components.\n*   **Single Responsibility Principle:** Each component should have a single, well-defined responsibility.\n*   **Presentational and Container Components:** Separate presentational components (UI) from container components (logic and data fetching).\n*   **Props and State Management:** Use props for passing data down the component tree and manage state appropriately (using libraries like Redux, Zustand or React Context where necessary).\n\n### 1.5. Code Splitting Strategies\n\n*   **Route-Based Splitting:** Split the application based on routes, loading only the necessary components and modules for each route.\n*   **Component-Based Splitting:**  Split large components into smaller chunks, loading them on demand.\n*   **Dynamic Imports:** Use dynamic imports (`import()`) to load modules and components asynchronously.\n*   **Webpack/Parcel Configuration:** Configure your bundler (Webpack, Parcel, etc.) to optimize code splitting and chunking.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Dependency Injection:**  Use dependency injection to manage dependencies and improve testability.\n*   **Observer Pattern:**  Implement the observer pattern for handling events and notifications.\n*   **Singleton Pattern:** Use the singleton pattern sparingly, only when a single instance of a class is truly required.\n*   **Factory Pattern:** Utilize factory patterns to abstract object creation.\n\n### 2.2. Recommended Approaches\n\n*   **Environment Variables:** Utilize Railway's environment variables for configuration and secrets management.  Access them in your application using appropriate methods for your language (e.g., `process.env` in Node.js, `os.environ` in Python).\n*   **Private Networking:**  Use Railway's private networking to ensure secure and efficient communication between services within the same project and environment using the `RAILWAY_PRIVATE_DOMAIN` environment variable.\n*   **Reference Variables:** Use Railway's reference variables to dynamically reference other variables, either from a variable set on the current service or from another service in the same project using the `${{serviceName.VARIABLE_NAME}}` syntax, keeping your variable values in sync and avoiding hardcoding.\n*   **Config as Code:** Utilize Railway's config as code feature to maintain your Railway configuration in a JSON or TOML file, enabling you to keep track of changes just as you do with your source code.\n\n### 2.3. Anti-patterns\n\n*   **Hardcoding Secrets:** Avoid hardcoding secrets or API keys in your code. Use environment variables instead.\n*   **Ignoring Errors:**  Don't ignore errors or exceptions. Implement proper error handling and logging.\n*   **Over-Engineering:** Avoid over-engineering solutions. Keep the code simple and maintainable.\n*   **Tight Coupling:** Minimize dependencies between modules and components.\n*   **Long-Lived Branches:**  Avoid creating long-lived branches. Use feature branches and merge them frequently.\n\n### 2.4. State Management\n\n*   **Local State:** Use component-level state for simple UI-related state.\n*   **Context API (React):**  Use the Context API for sharing state between components within a subtree.\n*   **State Management Libraries (Redux, Zustand, Recoil):** Use state management libraries for complex application state and predictable state updates.\n*   **Immutable Data Structures:**  Use immutable data structures to prevent accidental state mutations.\n\n### 2.5. Error Handling\n\n*   **Try-Catch Blocks:** Use `try-catch` blocks to handle exceptions gracefully.\n*   **Error Boundaries (React):** Use error boundaries to catch errors during rendering and prevent the entire application from crashing.\n*   **Centralized Error Handling:** Implement a centralized error handling mechanism for logging errors and displaying user-friendly messages.\n*   **Asynchronous Error Handling:** Handle errors in asynchronous operations (e.g., Promises) using `.catch()` or `async/await` with `try-catch`.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Code Optimization:** Optimize code for performance (e.g., minimizing DOM manipulations, using efficient algorithms).\n*   **Caching:** Implement caching mechanisms to reduce server load and improve response times. Use Railway environment variables to configure cache TTLs.\n*   **Database Optimization:** Optimize database queries and indexing for faster data retrieval. Select database types that optimize well with Railway. Consider a database cluster for production workloads.\n*   **Image Optimization:** Optimize images for web delivery (e.g., compressing images, using appropriate formats).\n*   **Gzip Compression:**  Enable Gzip compression to reduce the size of transferred data.\n\n### 3.2. Memory Management\n\n*   **Memory Leaks:**  Identify and fix memory leaks in your code.  Use memory profiling tools to detect leaks.\n*   **Garbage Collection:**  Understand how garbage collection works in your language and optimize memory usage accordingly.  Ensure resources are properly released and terminated.\n*   **Large Data Structures:** Avoid loading large data structures into memory unnecessarily.  Use streaming or pagination techniques.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n*   **Virtual DOM (React):**  Take advantage of the virtual DOM in frameworks like React to minimize DOM updates.\n*   **Memoization:** Use memoization techniques to prevent unnecessary re-renders.\n*   **Code Splitting:** Split code into smaller chunks to reduce initial load time.\n\n### 3.4. Bundle Size Optimization\n\n*   **Dead Code Elimination:**  Eliminate dead code and unused dependencies using tools like Webpack's tree shaking.\n*   **Minification:**  Minify code to reduce its size.\n*   **Dependency Optimization:**  Optimize dependencies by using smaller alternatives or by importing only the necessary parts of a library.\n\n### 3.5. Lazy Loading\n\n*   **Route-Based Lazy Loading:**  Lazy load routes to improve initial load time.\n*   **Component-Based Lazy Loading:** Lazy load components that are not immediately visible or necessary.\n*   **Intersection Observer:** Use the Intersection Observer API to lazy load images and other resources when they come into view.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **SQL Injection:**  Prevent SQL injection by using parameterized queries or ORM libraries.\n*   **Cross-Site Scripting (XSS):**  Prevent XSS by sanitizing user inputs and escaping outputs.\n*   **Cross-Site Request Forgery (CSRF):**  Prevent CSRF by using anti-CSRF tokens.\n*   **Authentication and Authorization Vulnerabilities:** Implement secure authentication and authorization mechanisms.\n*   **Dependency Vulnerabilities:**  Keep dependencies up to date to address known vulnerabilities.\n\n### 4.2. Input Validation\n\n*   **Server-Side Validation:**  Validate all user inputs on the server-side.\n*   **Whitelisting:** Use whitelisting to allow only valid inputs.\n*   **Sanitization:** Sanitize user inputs to remove potentially harmful characters.\n*   **Regular Expressions:** Use regular expressions to validate input formats.\n\n### 4.3. Authentication and Authorization\n\n*   **Secure Password Storage:**  Use strong hashing algorithms (e.g., bcrypt, Argon2) to store passwords securely.\n*   **Multi-Factor Authentication (MFA):** Implement MFA for enhanced security.\n*   **Role-Based Access Control (RBAC):**  Implement RBAC to control access to resources based on user roles.\n*   **JSON Web Tokens (JWT):**  Use JWT for stateless authentication.\n\n### 4.4. Data Protection\n\n*   **Encryption:**  Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data in logs and reports.\n*   **Regular Backups:**  Create regular backups of your data to prevent data loss. Use Railway's volume and backup features.\n*   **Data Minimization:** Only store the data that is necessary.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:**  Use HTTPS for all API communication.\n*   **API Keys:** Protect API keys and other sensitive credentials.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Validation:** Validate all API requests.\n*   **Output Encoding:** Encode API responses to prevent injection attacks.\n*   **Private Networking:** Use private networking to protect your services from malicious threats by keeping them unexposed to the public network. Secure communication between services in the same project and environment.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test-Driven Development (TDD):**  Write tests before writing code.\n*   **Component Isolation:**  Isolate components during unit testing.\n*   **Mocking Dependencies:** Mock dependencies to control the behavior of external systems.\n*   **Code Coverage:**  Aim for high code coverage.\n\n### 5.2. Integration Testing\n\n*   **Integration with External Systems:**  Test the integration between different components and external systems.\n*   **Database Integration:**  Test database interactions.\n*   **API Integration:** Test API endpoints.\n\n### 5.3. End-to-End Testing\n\n*   **User Flows:** Test complete user flows to ensure that the application works as expected.\n*   **Browser Automation:**  Use browser automation tools (e.g., Selenium, Cypress) to simulate user interactions.\n*   **Environment Parity:** Run end-to-end tests in an environment that closely resembles production.\n\n### 5.4. Test Organization\n\n*   **Test Suites:** Organize tests into logical test suites.\n*   **Test Naming Conventions:**  Use consistent test naming conventions.\n*   **Test Documentation:**  Document tests to explain their purpose and expected behavior.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mocking External Services:**  Mock external services (e.g., APIs, databases) to control their behavior during testing.\n*   **Stubbing Functions:**  Stub functions to replace their implementation with a predefined behavior.\n*   **Mocking Libraries:** Use mocking libraries (e.g., Jest, Mocha) to simplify the mocking process.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Incorrect Environment Variable Configuration:**  Ensure that environment variables are correctly configured and accessible in your application.\n*   **Failing to Configure Restart Policies:** Configure your services' restart policy to mitigate performance degradation and user impact when a service crashes.\n*   **Not Utilizing Private Networking:**  Make sure to use private networking for faster networking along with no egress fees for service-to-service communication within a project.\n*   **Ignoring Asynchronous Operations:**  Handle asynchronous operations correctly to prevent race conditions and unexpected behavior.\n*   **Overlooking Security Vulnerabilities:**  Stay informed about common security vulnerabilities and take steps to mitigate them.\n\n### 6.2. Edge Cases\n\n*   **Handling Edge Cases:**  Consider and handle edge cases in your code.\n*   **Input Validation:**  Validate all user inputs to prevent unexpected behavior.\n*   **Error Handling:**  Handle errors gracefully to prevent application crashes.\n\n### 6.3. Version-Specific Issues\n\n*   **Compatibility Issues:** Be aware of compatibility issues between different versions of Railway and its dependencies.\n*   **Breaking Changes:**  Stay informed about breaking changes in Railway releases and update your code accordingly.\n\n### 6.4. Compatibility Concerns\n\n*   **Dependency Conflicts:**  Resolve dependency conflicts between Railway and other technologies.\n*   **Integration Issues:**  Address integration issues between Railway and other services.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Use logging to track the execution flow and identify potential issues.\n*   **Debugging Tools:** Use debugging tools to step through your code and inspect variables.\n*   **Remote Debugging:**  Use remote debugging to debug applications running on Railway servers.\n*   **Log Explorer:** Familiarize yourself with the Log Explorer so you can query logs across all of your services in one place.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE (Integrated Development Environment):**  Use a suitable IDE (e.g., VS Code, IntelliJ IDEA) with appropriate extensions for your language.\n*   **CLI (Command-Line Interface):**  Use the Railway CLI for managing your Railway projects and services.\n*   **Version Control System (Git):**  Use Git for version control.\n\n### 7.2. Build Configuration\n\n*   **Build Scripts:**  Define build scripts in your `package.json` (Node.js) or equivalent file.\n*   **Dependency Management:**  Use a dependency management tool (e.g., npm, yarn, pip, maven) to manage dependencies.\n*   **Configuration Management:**  Use configuration management tools to manage configuration files across different environments.\n\n### 7.3. Linting and Formatting\n\n*   **Linters:**  Use linters (e.g., ESLint, Pylint) to enforce code style and identify potential errors.\n*   **Formatters:**  Use formatters (e.g., Prettier, Black) to automatically format your code.\n*   **Editor Integration:**  Integrate linters and formatters with your editor to provide real-time feedback.\n\n### 7.4. Deployment Best Practices\n\n*   **Automated Deployments:**  Automate the deployment process using CI/CD pipelines.\n*   **Zero-Downtime Deployments:**  Implement zero-downtime deployments to minimize downtime during deployments.  (Consider using blue-green deployments or rolling updates).\n*   **Rollbacks:** Implement a rollback strategy to quickly revert to a previous deployment in case of issues.  Be sure to check out the deployment rollback feature, in case you need to rollback to a previous deployment.\n*   **Check Suites:** Enable check suites to have Railway wait for your GitHub workflows to complete successfully before triggering a deployment.\n\n### 7.5. CI/CD Integration\n\n*   **CI/CD Pipelines:**  Set up CI/CD pipelines to automatically build, test, and deploy your application.\n*   **GitHub Actions:**  Use GitHub Actions for CI/CD.\n*   **GitLab CI:** Use GitLab CI for CI/CD.\n*   **Environment Variables:** Use environment variables to configure the CI/CD pipeline.\n*   **Webhooks and Email Notifications:** Setup webhooks and email notifications to be alerted if the deployment status of your services change.\n\nBy adhering to these best practices, you can develop and deploy robust, scalable, and secure applications on the Railway platform.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.py,*.go,*.java,*.rs,*.c,*.cpp,*.cs,*.html,*.css,*.yml,*.yaml,*.json,*.sh",
      "format": "mdc",
      "originalFile": "railway.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "railway",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "deploying",
      "applications",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "railway",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-react-mobx",
    "description": "This rule provides comprehensive best practices for developing React applications with Mobx, covering code organization, performance, testing, and security considerations. It aims to guide developers in building robust and maintainable applications using React-Mobx.",
    "author": "sanjeed5",
    "tags": [
      "react-mobx",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/react-mobx.mdc",
    "content": "# React-Mobx Best Practices\n\nThis document outlines best practices for developing React applications with Mobx. Following these guidelines will help you build robust, maintainable, and performant applications.\n\n## 1. Core Principles\n\n- **Model observable state:**  Define the source of truth in your Mobx stores and make them observable.\n- **Use derived state (computed properties):**  Derive data from your observable state using `computed` properties to avoid unnecessary re-renders and ensure data consistency.\n- **Embrace mutability:** Mobx encourages direct mutation of observable state within actions.\n- **Use strict mode:** Enforce predictable state changes by using `use strict` or enabling strict mode in Mobx to ensure all state modifications happen within actions.\n- **Keep actions in MobX stores:** Encapsulate state mutations within Mobx actions to ensure data integrity and simplify debugging.\n- **Prefer class vs object syntax:** Use class syntax for creating stores as it offers better structure, inheritance, and maintainability.\n- **Inject store rather than importing:**  Use dependency injection (e.g., React Context) to provide stores to components instead of importing them directly to improve testability and reduce tight coupling.\n\n## 2. Code Organization and Structure\n\n- **Directory Structure:**\n    - `/src`:\n        - `/components`: React components (presentational and container components).\n        - `/stores`: Mobx stores containing observable state and actions.\n        - `/models`: Data models and types definitions.\n        - `/services`: API clients and other services.\n        - `/utils`: Utility functions.\n        - `/hooks`: Custom React hooks.\n        - `/constants`: Application-wide constants.\n    - `/test`: Unit, integration, and end-to-end tests.\n\n- **File Naming Conventions:**\n    - Components: `ComponentName.jsx` or `ComponentName.tsx`\n    - Stores: `StoreName.store.js` or `StoreName.store.ts`\n    - Models: `ModelName.model.js` or `ModelName.model.ts`\n    - Services: `ServiceName.service.js` or `ServiceName.service.ts`\n    - Hooks: `useHookName.js` or `useHookName.ts`\n\n- **Module Organization:**\n    - Group related components, stores, and models into modules.\n    - Use clear and descriptive module names.\n    - Avoid circular dependencies between modules.\n\n- **Component Architecture:**\n    - **Presentational Components:**  Responsible for rendering UI and receiving data via props.\n    - **Container Components:**  Connect presentational components to Mobx stores and manage state updates.\n    - Use the `observer` decorator/function from `mobx-react-lite` to make components react to observable changes.\n\n- **Code Splitting Strategies:**\n    - Use React's `lazy` and `Suspense` components for lazy loading routes or components.\n    - Implement route-based code splitting to load only necessary code for the current route.\n    - Consider using `dynamic imports` for on-demand loading of modules.\n\n## 3. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Observer Pattern:** Mobx uses the observer pattern to automatically update components when observable state changes.\n    - **Dependency Injection:** Use React Context to inject stores into components, making them more testable and reusable.\n    - **Provider Pattern:** Use a Provider component to make stores available to the component tree.\n\n- **Recommended Approaches:**\n    - **Form Handling:** Use Mobx to manage form state and validation.\n    - **Asynchronous Operations:** Use Mobx actions to handle asynchronous operations and update the state accordingly.\n    - **List Rendering:** Optimize list rendering using `key` props and `React.memo`.\n\n- **Anti-patterns and Code Smells:**\n    - **Modifying State Outside Actions:** Always modify observable state within Mobx actions to ensure data consistency.\n    - **Deeply Nested Observables:** Avoid deeply nested observable objects as they can impact performance.\n    - **Computing Data in Components:**  Use `computed` properties in stores to derive data instead of computing it directly in components.\n    - **Over-Observing:** Only observe the specific parts of the store that a component needs.\n\n- **State Management Best Practices:**\n    - **Single Source of Truth:** Keep the application state in Mobx stores and avoid duplicating data.\n    - **Normalization:** Normalize data to reduce redundancy and improve data consistency.\n    - **Immutability (with Mutation):**  While Mobx encourages mutation, treat observable state as immutable from the perspective of components (i.e., components shouldn't directly mutate the store).\n\n- **Error Handling Patterns:**\n    - Implement centralized error handling using a dedicated error store.\n    - Use try-catch blocks within actions to handle potential errors.\n    - Display user-friendly error messages to the user.\n\n## 4. Performance Considerations\n\n- **Optimization Techniques:**\n    - **`React.memo`:**  Wrap components with `React.memo` to prevent unnecessary re-renders when props haven't changed.\n    - **`useMemo` and `useCallback`:**  Use `useMemo` and `useCallback` hooks to memoize values and callbacks, preventing unnecessary re-renders of child components.\n    - **Computed Properties:**  Use `computed` properties to derive data from observable state and cache the results.\n    - **Optimize List Rendering:**  Use `key` props when rendering lists and consider using virtualized lists for large datasets.\n\n- **Memory Management:**\n    - **Dispose of Observers:**  Dispose of observers when components unmount to prevent memory leaks.\n    - **Avoid Retaining Large Data Sets:**  Remove or release references to large data sets when they are no longer needed.\n\n- **Rendering Optimization:**\n    - **Minimize Re-renders:**  Optimize component rendering by using `React.memo` and avoiding unnecessary state updates.\n    - **Use ShouldComponentUpdate (if needed):** In class components, use `shouldComponentUpdate` lifecycle method to control when a component should re-render.  This is less common with `observer`.  Be careful, can lead to bugs.\n\n- **Bundle Size Optimization:**\n    - **Code Splitting:** Implement code splitting to reduce the initial bundle size.\n    - **Tree Shaking:**  Use a bundler that supports tree shaking to remove unused code.\n    - **Minification:**  Minify your code to reduce the bundle size.\n\n- **Lazy Loading Strategies:**\n    - **React.lazy and Suspense:** Use React's built-in lazy loading mechanism.\n    - **Dynamic Imports:** Use dynamic imports to load modules on demand.\n\n## 5. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Sanitize user inputs to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection mechanisms.\n    - **Injection Attacks:**  Validate user inputs to prevent SQL injection and other injection attacks.\n\n- **Input Validation:**\n    - **Server-Side Validation:**  Always validate user inputs on the server-side.\n    - **Client-Side Validation:**  Implement client-side validation to provide immediate feedback to the user.\n\n- **Authentication and Authorization Patterns:**\n    - **JSON Web Tokens (JWT):**  Use JWTs for authentication and authorization.\n    - **Role-Based Access Control (RBAC):**  Implement RBAC to control access to different parts of the application.\n\n- **Data Protection Strategies:**\n    - **Encryption:**  Encrypt sensitive data both in transit and at rest.\n    - **Data Masking:**  Mask sensitive data to protect user privacy.\n\n- **Secure API Communication:**\n    - **HTTPS:**  Use HTTPS for all API communication.\n    - **Rate Limiting:**  Implement rate limiting to prevent abuse.\n\n## 6. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Test individual components and stores in isolation.\n    - Mock dependencies to isolate the unit under test.\n    - Use testing libraries like Jest and React Testing Library.\n\n- **Integration Testing:**\n    - Test the interaction between different components and stores.\n    - Use a testing environment that closely resembles the production environment.\n\n- **End-to-End Testing:**\n    - Test the entire application flow from the user's perspective.\n    - Use testing frameworks like Cypress or Selenium.\n\n- **Test Organization:**\n    - Organize tests into separate directories for unit, integration, and end-to-end tests.\n    - Use descriptive test names.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries to mock dependencies in unit tests.\n    - Use stubbing to replace complex dependencies with simpler implementations.\n\n## 7. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Forgetting to decorate components with `observer`.\n    - Modifying state outside of actions.\n    - Not disposing of observers properly.\n    - Over-observing state.\n\n- **Edge Cases:**\n    - Handling large datasets efficiently.\n    - Dealing with complex asynchronous operations.\n    - Managing nested observable objects.\n\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in Mobx and React versions.\n    - Consult the Mobx and React documentation for migration guides.\n\n- **Compatibility Concerns:**\n    - Ensure compatibility with different browsers and devices.\n    - Test your application on different platforms.\n\n- **Debugging Strategies:**\n    - Use the Mobx devtools to inspect observable state and track changes.\n    - Use browser developer tools to debug React components.\n    - Add logging statements to track the flow of data and execution.\n\n## 8. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **VS Code:**  A popular code editor with excellent support for React and Mobx.\n    - **Mobx Devtools:**  A browser extension for inspecting Mobx state.\n    - **React Devtools:**  A browser extension for inspecting React components.\n\n- **Build Configuration:**\n    - **Webpack:**  A popular module bundler for React applications.\n    - **Parcel:**  A zero-configuration bundler that's easy to use.\n    - **Rollup:** A bundler focused on creating libraries and smaller bundles.\n\n- **Linting and Formatting:**\n    - **ESLint:**  A JavaScript linter for enforcing code style and preventing errors.\n    - **Prettier:**  A code formatter for automatically formatting code.\n    - **Husky/lint-staged:** Tools to automatically lint code before commits\n\n- **Deployment Best Practices:**\n    - **Continuous Integration/Continuous Deployment (CI/CD):** Automate the build, test, and deployment process.\n    - **Caching:**  Use caching to improve performance.\n    - **Content Delivery Network (CDN):**  Use a CDN to serve static assets.\n\n- **CI/CD Integration:**\n    - Integrate your application with a CI/CD pipeline to automate the build, test, and deployment process.\n    - Use tools like Jenkins, Travis CI, or CircleCI.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "react-mobx.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "react",
      "mobx",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "applications",
      "with",
      "react-mobx",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "react-mobx",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-react-native",
    "description": "This rule provides comprehensive best practices and coding standards for React Native development, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "react-native",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "mobile",
      "cross-platform",
      "ios",
      "android",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/react-native.mdc",
    "content": "- Use TypeScript for type safety and improved code maintainability.\n- Prefer functional components with hooks over class components for simplicity and reusability.\n- Maintain a clear and consistent project structure for scalability and maintainability.\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - Adopt a feature-based or component-based structure. For example:\n        \n        src/\n        ├── components/\n        │   ├── Button/\n        │   │   ├── Button.tsx\n        │   │   ├── Button.styles.ts\n        │   │   ├── Button.test.tsx\n        │   ├── Input/\n        │   └── ...\n        ├── screens/\n        │   ├── Home/\n        │   │   ├── HomeScreen.tsx\n        │   │   ├── HomeScreen.styles.ts\n        │   │   ├── HomeScreen.test.tsx\n        │   ├── Profile/\n        │   └── ...\n        ├── navigation/\n        ├── services/\n        ├── utils/\n        ├── types/\n        └── App.tsx\n        \n    - Separate concerns into distinct directories (e.g., components, screens, navigation, services, utils, types).\n\n- **File Naming Conventions:**\n    - Use descriptive names for files and components (e.g., `HomeScreen.tsx`, `useUserData.ts`).\n    - Follow a consistent naming convention (e.g., PascalCase for components, camelCase for functions and variables).\n    - Use `.styles.ts` for style files and `.test.tsx` for test files to keep components readable and organized.\n\n- **Module Organization:**\n    - Group related components and modules into logical units.\n    - Use absolute imports and module aliases to avoid long relative paths (e.g., `@components/Button` instead of `../../../components/Button`).\n    - Configure module aliases in `tsconfig.json` or `jsconfig.json`.\n\n- **Component Architecture:**\n    - Favor small, reusable components with a single responsibility (Single Responsibility Principle).\n    - Use composition over inheritance to create complex components.\n    - Consider using a UI library like React Native Paper or NativeBase for pre-built components.\n\n- **Code Splitting Strategies:**\n    - Implement lazy loading for screens or components that are not immediately needed.\n    - Use `React.lazy` and `Suspense` to load components on demand.\n    - Utilize dynamic imports for conditional loading of modules.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - **Higher-Order Components (HOCs):** Use HOCs for cross-cutting concerns like authentication or logging.\n    - **Render Props:** Use render props to share code between React components.\n    - **Hooks:** Use custom hooks to encapsulate logic and stateful behavior.\n\n- **Recommended Approaches:**\n    - **State Management:**\n        - Use React Context for simple state management.\n        - Use Redux, Zustand, or Jotai for complex state management.\n        - Consider using Recoil for fine-grained state management.\n    - **API Calls:**\n        - Use `axios` or `fetch` for making API requests.\n        - Create a service layer to handle API calls and data transformations.\n    - **Navigation:**\n        - Use React Navigation for managing app navigation.\n        - Define navigation stacks and routes in a separate module.\n\n- **Anti-patterns and Code Smells:**\n    - **Long Component Files:** Break down large components into smaller, more manageable pieces.\n    - **Deeply Nested Components:** Avoid excessive nesting, which can impact performance.\n    - **Mutating State Directly:** Always use `setState` or a state management library to update state.\n    - **Unnecessary Re-renders:** Optimize components to prevent unnecessary re-renders.\n    - **Global Styles:** Avoid using global styles, as they can lead to conflicts and make it difficult to maintain the application.\n\n- **State Management Best Practices:**\n    - Choose a state management solution that fits the complexity of your application.\n    - Keep state minimal and derive values when possible.\n    - Use selectors to access state and memoize computed values.\n\n- **Error Handling Patterns:**\n    - Use `try...catch` blocks to handle errors gracefully.\n    - Implement a global error handler to catch unhandled exceptions.\n    - Log errors to a remote monitoring service.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - **Memoization:** Use `React.memo` to memoize components and prevent unnecessary re-renders.\n    - **Pure Components:** Extend `React.PureComponent` for components that only depend on props.\n    - **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of function calls.\n    - **Virtualization:** Use `FlatList` or `SectionList` for rendering large lists of data.\n\n- **Memory Management:**\n    - Avoid memory leaks by properly cleaning up event listeners and timers.\n    - Use `useCallback` and `useMemo` to prevent creating new functions and objects on every render.\n\n- **Rendering Optimization:**\n    - Minimize the number of re-renders by optimizing component updates.\n    - Use `shouldComponentUpdate` (for class components) or `React.memo` to control re-renders.\n    - Avoid using inline styles, as they are re-created on every render.\n\n- **Bundle Size Optimization:**\n    - Use code splitting to reduce the initial bundle size.\n    - Remove unused code and dependencies.\n    - Use a bundler like Metro or Webpack with tree shaking enabled.\n    - Compress images and other assets.\n\n- **Lazy Loading Strategies:**\n    - Implement lazy loading for images and other assets using `React.lazy` and `Suspense`.\n    - Use dynamic imports to load modules on demand.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n    - **SQL Injection:** Use parameterized queries to prevent SQL injection attacks.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection tokens.\n    - **Man-in-the-Middle (MITM) Attacks:** Use HTTPS to encrypt communication.\n\n- **Input Validation:**\n    - Validate user input on both the client and server sides.\n    - Use regular expressions or validation libraries to enforce input constraints.\n\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication protocol like OAuth 2.0 or JWT.\n    - Implement role-based access control (RBAC) to restrict access to sensitive resources.\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms for storing API keys and other secrets.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement API rate limiting to prevent abuse.\n    - Validate API responses to prevent data injection attacks.\n\n## 5. Testing Approaches:\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual components and modules.\n    - Use a testing framework like Jest or Mocha.\n    - Mock dependencies to isolate the component being tested.\n\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between components and modules.\n    - Test the integration with external APIs and services.\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the entire application flow.\n    - Use a testing framework like Detox or Appium.\n\n- **Test Organization:**\n    - Organize tests into separate directories based on component or module.\n    - Use descriptive names for test files and test cases.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components and control their behavior during testing.\n    - Use a mocking library like Jest or Sinon.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n    - **Directly Mutating State:** Always use `setState` or a state management library to update state.\n    - **Ignoring Platform Differences:** Test your application on both iOS and Android devices.\n    - **Over-Optimizing:** Optimize only when necessary, as premature optimization can lead to complex code.\n    - **Not Using a Debugger:** Utilize the React Native debugger for efficient debugging.\n\n- **Edge Cases:**\n    - **Handling Device Orientation Changes:** Implement logic to handle device orientation changes gracefully.\n    - **Handling Network Connectivity Issues:** Implement error handling for network connectivity issues.\n    - **Handling Different Screen Sizes and Densities:** Design your UI to adapt to different screen sizes and densities.\n\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in React Native and its dependencies.\n    - Test your application with different versions of React Native.\n\n- **Compatibility Concerns:**\n    - Ensure that your application is compatible with the target operating systems and devices.\n    - Use polyfills to support older browsers and devices.\n\n- **Debugging Strategies:**\n    - Use the React Native debugger to inspect the component tree and state.\n    - Use the console to log messages and debug code.\n    - Use a remote debugging tool to debug on a physical device.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - **VS Code:** Use VS Code with the React Native Tools extension for debugging and code completion.\n    - **React Native CLI:** Use the React Native CLI for creating and managing React Native projects.\n    - **Expo CLI:** Use the Expo CLI for developing and testing React Native applications without native code.\n    - **Android Studio:** Use Android Studio for building and debugging Android applications.\n    - **Xcode:** Use Xcode for building and debugging iOS applications.\n\n- **Build Configuration:**\n    - Use a build system like Gradle (Android) or CocoaPods (iOS) to manage dependencies.\n    - Configure build variants for different environments (e.g., development, staging, production).\n\n- **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce code style and catch potential errors.\n    - Configure ESLint and Prettier to automatically format code on save.\n\n- **Deployment Best Practices:**\n    - Use a continuous integration and continuous deployment (CI/CD) pipeline to automate the deployment process.\n    - Use a service like App Center or Bitrise for building and deploying React Native applications.\n\n- **CI/CD Integration:**\n    - Integrate your code repository with a CI/CD service like GitHub Actions or CircleCI.\n    - Configure the CI/CD pipeline to run tests and build the application on every commit.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "react-native.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "react",
      "native",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "react-native",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "mobile",
      "cross-platform",
      "ios",
      "android",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "react-native",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-react-query",
    "description": "This rule enforces best practices for using react-query in React applications, covering code organization, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "react-query",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/react-query.mdc",
    "content": "# react-query Best Practices\n\nThis document outlines the best practices for using react-query in React applications, covering various aspects such as code organization, performance considerations, security, and testing.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n*   **Feature-based Organization:** Group react-query hooks and related components within feature-specific directories.  This improves modularity and maintainability.\n    \n    src/\n    ├── features/\n    │   ├── users/\n    │   │   ├── components/\n    │   │   │   ├── UserList.tsx\n    │   │   │   └── UserDetails.tsx\n    │   │   ├── hooks/\n    │   │   │   ├── useUsersQuery.ts\n    │   │   │   └── useCreateUserMutation.ts\n    │   │   ├── api/\n    │   │   │   └── usersApi.ts\n    │   │   └── types/\n    │   │       └── user.ts\n    │   ├── products/\n    │   └── ...\n    ├── ...\n    \n\n*   **Dedicated API Service Layer:** Abstract API interaction logic into separate modules.  This allows for easier testing and decoupling of components from specific API implementations. Consider using a dedicated `api` directory within each feature.\n\n### 1.2 File Naming Conventions\n\n*   **Consistent Naming:** Follow a consistent naming convention for react-query hooks.  Prefix hooks with `use` and postfix with `Query` or `Mutation` to clearly indicate their purpose (e.g., `usePostsQuery`, `useUpdatePostMutation`).\n\n*   **Descriptive Names:** Use descriptive names for files and variables to improve code readability.  For example, `useFetchUsersQuery.ts` is more informative than `useUsers.ts`.\n\n### 1.3 Module Organization\n\n*   **Custom Hooks for Reusability:** Encapsulate react-query logic within custom hooks to promote reusability and separation of concerns.\n\n    typescript\n    // src/features/users/hooks/useUsersQuery.ts\n    import { useQuery } from '@tanstack/react-query';\n    import { fetchUsers } from '../api/usersApi';\n\n    export const useUsersQuery = () => {\n      return useQuery('users', fetchUsers);\n    };\n    \n\n*   **Separate Query and Mutation Files:** Organize queries and mutations into separate files or modules. This enhances code readability and maintainability.\n\n### 1.4 Component Architecture\n\n*   **Presentational and Container Components:** Separate presentational components (UI) from container components (data fetching and state management).  This improves testability and reusability.\n\n*   **Composition:** Use component composition to build complex UIs from smaller, reusable components.  Leverage React Context for shared state when appropriate.\n\n### 1.5 Code Splitting Strategies\n\n*   **Route-Based Splitting:** Split your application into separate bundles based on routes.  This reduces the initial load time and improves perceived performance. React.lazy and React.Suspense can assist with this.\n\n*   **Component-Based Splitting:** Split large components into smaller chunks that can be loaded on demand.  This can improve the performance of individual pages or components.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to react-query\n\n*   **Custom Hooks for Data Fetching:** As highlighted earlier, encapsulating react-query logic within custom hooks. This promotes reusability and separation of concerns. These hooks will typically return the result of a `useQuery` or `useMutation` call.\n\n*   **Optimistic Updates:** Implement optimistic updates to improve perceived performance.  This involves updating the UI before the API request completes, and then reverting the changes if the request fails.  react-query provides utilities like `onMutate` to handle this.\n\n*   **Pessimistic Updates:** Update the UI only after a successful response from the API. Simpler to implement but provides a less snappy user experience.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Prefetching Data:** Prefetch data for routes or components that the user is likely to visit next.  This can significantly improve the user experience.  Use `queryClient.prefetchQuery`.\n\n*   **Pagination and Infinite Scrolling:** Implement pagination and infinite scrolling to handle large datasets efficiently.  react-query provides hooks like `useInfiniteQuery` to simplify this.\n\n*   **Dependent Queries:** Fetch data based on the result of a previous query. Use the `enabled` option in `useQuery` to conditionally execute queries.\n\n    typescript\n    const { data: user } = useQuery(['user', userId], () => fetchUser(userId));\n\n    const { data: posts } = useQuery(['posts', user?.id], () => fetchPosts(user.id), {\n      enabled: !!user,\n    });\n    \n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Directly Calling API in Components:** Avoid making API calls directly within components.  This makes testing difficult and tightly couples components to specific API implementations.\n\n*   **Ignoring Error Handling:** Always handle errors properly.  Display user-friendly error messages and provide options for retrying requests.\n\n*   **Over-fetching Data:** Fetch only the data that is required by the component.  Use GraphQL or API query parameters to reduce the amount of data transferred.\n\n*   **Deeply Nested Queries:** Avoid deeply nesting queries, as this can lead to performance issues and make the code difficult to understand. Consider combining queries or using a different approach.\n\n### 2.4 State Management Best Practices\n\n*   **Local vs. Global State:** Determine whether data should be stored in local component state or in a global state management solution.  Use local state for component-specific data and global state for data that needs to be shared across multiple components.\n\n*   **react-query as a State Manager:** Leverage react-query's built-in caching and state management capabilities.  Avoid using external state management libraries for data that is already managed by react-query.\n\n### 2.5 Error Handling Patterns\n\n*   **Centralized Error Handling:** Implement centralized error handling to provide consistent error messages and logging.\n\n*   **Retry Logic:** Implement retry logic to automatically retry failed requests. react-query provides options for configuring retry behavior.\n\n*   **Error Boundaries:** Use Error Boundaries to catch errors that occur during rendering. This prevents the entire application from crashing.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Query Invalidation:** Invalidate queries when data changes. This ensures that the UI is always up-to-date.\n\n*   **Stale-While-Revalidate:** Use the `staleTime` and `cacheTime` options to configure how long data should be considered fresh.  `staleWhileRevalidate` allows the UI to display cached data while fetching fresh data in the background.\n\n*   **Window Focus Refetching:**  Configure refetching on window focus to keep data fresh when the user switches back to the application.\n\n*   **Polling/Refetch Intervals:** Use `refetchInterval` to periodically refetch data.  This is useful for data that changes frequently.\n\n### 3.2 Memory Management\n\n*   **Query Cache Management:** Understand how react-query manages its cache.  Configure the `cacheTime` option to control how long data is stored in the cache.\n\n*   **Garbage Collection:** Ensure that unused queries are garbage collected properly.  Use the `gcTime` option to configure how long inactive queries should be kept in the cache.\n\n### 3.3 Rendering Optimization\n\n*   **Memoization:** Use `React.memo` to prevent unnecessary re-renders of components.  This is especially important for components that display data fetched from react-query.\n\n*   **Virtualization:** Use virtualization techniques (e.g., `react-window`, `react-virtualized`) to efficiently render large lists of data.\n\n### 3.4 Bundle Size Optimization\n\n*   **Tree Shaking:** Ensure that your build process is configured for tree shaking.  This removes unused code from the final bundle.\n\n*   **Code Splitting:** As mentioned earlier, use code splitting to reduce the initial load time.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Load Components:** Use `React.lazy` to lazy load components that are not immediately needed.\n\n*   **Lazy Load Data:** Fetch data only when it is needed.  Use dependent queries to fetch data based on user interactions.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks. Use a library like DOMPurify to sanitize HTML.\n\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection to prevent attackers from performing actions on behalf of the user. Use a library or framework that provides CSRF protection.\n\n*   **Injection Attacks:** Protect against injection attacks by validating user input and using parameterized queries.\n\n### 4.2 Input Validation\n\n*   **Client-Side Validation:** Implement client-side validation to provide immediate feedback to the user.\n\n*   **Server-Side Validation:** Always validate user input on the server-side to prevent malicious data from being stored in the database.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **JSON Web Tokens (JWT):** Use JWTs for authentication. Store the JWT in a secure cookie or in local storage (with caution). Use `httpOnly` flag on cookies containing JWTs when possible to prevent client-side script access.\n\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to different parts of the application. Use middleware or custom hooks to check user roles.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit. Use HTTPS to encrypt data in transit. Encrypt sensitive data in the database.\n\n*   **Data Masking:** Mask sensitive data in logs and reports. This prevents sensitive data from being exposed to unauthorized users.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication. This encrypts data in transit and prevents eavesdropping.\n\n*   **API Rate Limiting:** Implement API rate limiting to prevent abuse.\n\n*   **CORS:** Configure CORS properly to prevent cross-origin requests from unauthorized domains.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Custom Hooks:** Unit test custom react-query hooks to ensure they are working correctly.  Mock the API calls using libraries like `msw` (Mock Service Worker).\n\n*   **Test Components in Isolation:** Unit test components in isolation to ensure they render correctly and handle user interactions properly. Use libraries like `react-testing-library`.\n\n### 5.2 Integration Testing\n\n*   **Test Data Flow:** Integration test the data flow between components and APIs.  Verify that data is fetched correctly and displayed properly.\n\n*   **Test Error Handling:** Integration test error handling scenarios to ensure that errors are handled properly.\n\n### 5.3 End-to-End Testing\n\n*   **Simulate User Interactions:** Use end-to-end testing frameworks like Cypress or Playwright to simulate user interactions and verify that the application is working correctly from the user's perspective.\n\n*   **Test Critical Paths:** Focus on testing critical user flows, such as login, registration, and checkout.\n\n### 5.4 Test Organization\n\n*   **Colocate Tests with Components:** Colocate tests with the components they are testing.  This makes it easier to find and maintain tests.\n\n*   **Use Descriptive Test Names:** Use descriptive test names to clearly indicate what each test is verifying.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mock API Calls:** Use mocking libraries like `msw` to mock API calls during testing. This allows you to test components in isolation without relying on a real API.\n\n*   **Stub External Dependencies:** Stub external dependencies to isolate components and make tests more predictable.\n\n## 6. Common Pitfalls and Gotchas\n\n*   **Forgetting to Invalidate Queries:** Failing to invalidate queries when data changes can lead to stale data being displayed in the UI.\n\n*   **Incorrect Cache Configuration:** Incorrectly configuring the `cacheTime` and `staleTime` options can lead to performance issues or stale data.\n\n*   **Not Handling Errors Properly:** Not handling errors properly can lead to unexpected behavior and a poor user experience.\n\n*   **Over-relying on Default Configuration:** Customizing react-query to match specific needs is essential.\n\n*   **Ignoring Devtools:** The react-query devtools are invaluable for debugging and understanding what is happening under the hood.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code:** Use VS Code with extensions like ESLint, Prettier, and TypeScript to improve developer productivity.\n\n*   **React Developer Tools:** Use the React Developer Tools browser extension to inspect React components and state.\n\n*   **react-query Devtools:** Use the react-query Devtools to inspect the react-query cache and track query and mutation status.\n\n### 7.2 Build Configuration\n\n*   **Webpack or Parcel:** Use a bundler like Webpack or Parcel to bundle your code for production. Configure the bundler for tree shaking and code splitting.\n\n*   **Babel:** Use Babel to transpile your code to older versions of JavaScript. This ensures that your code is compatible with older browsers.\n\n### 7.3 Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce coding standards and prevent errors. Configure ESLint to use a popular style guide like Airbnb or Google.\n\n*   **Prettier:** Use Prettier to automatically format your code. This ensures that your code is consistently formatted and easy to read.\n\n### 7.4 Deployment Best Practices\n\n*   **CDN:** Use a CDN to serve static assets. This improves performance and reduces the load on your server.\n\n*   **Caching:** Configure caching properly on your server and CDN. This reduces the number of requests to your server and improves performance.\n\n### 7.5 CI/CD Integration\n\n*   **Automated Testing:** Integrate automated testing into your CI/CD pipeline. This ensures that your code is tested automatically before it is deployed.\n\n*   **Automated Deployment:** Automate the deployment process to reduce the risk of errors and improve efficiency.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "react-query.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "react",
      "query",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "using",
      "applications",
      "react-query",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "react-query",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-react-redux",
    "description": "Enforces best practices for structuring and maintaining React-Redux applications, focusing on code organization, performance, and maintainability. This rule provides guidelines for developers to write efficient, scalable, and testable React-Redux code.",
    "author": "sanjeed5",
    "tags": [
      "react-redux",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/react-redux.mdc",
    "content": "# React-Redux Best Practices\n\nThis document outlines best practices for developing React applications with Redux for state management. Following these guidelines will help you write maintainable, scalable, and performant code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nOrganize your code around features rather than technical concerns. A feature-based directory structure promotes modularity and makes it easier to understand the application's purpose.\n\n\nsrc/\n  ├── app/\n  │   ├── components/\n  │   │   └── App.tsx\n  │   └── App.css\n  ├── features/\n  │   ├── featureName/\n  │   │   ├── components/\n  │   │   │   ├── FeatureComponent.tsx\n  │   │   │   └── FeatureComponent.css\n  │   │   ├── FeatureSlice.ts  # Redux slice for the feature\n  │   │   ├── FeatureSelectors.ts  # Selectors for accessing feature state\n  │   │   ├── FeatureActions.ts  # Actions related to this feature\n  │   │   └── api.ts  # API calls related to the feature\n  │   ├── anotherFeature/\n  │   │   └── ...\n  ├── store.ts          # Redux store configuration\n  ├── index.tsx         # Entry point for the React application\n  └── ...\n\n\n### 1.2. File Naming Conventions\n\n*   **Components:** Use PascalCase (e.g., `MyComponent.tsx`).\n*   **Redux Slice Files:** Use PascalCase and end with `Slice.ts` or `Slice.js` (e.g., `UserSlice.ts`).\n*   **Selectors:**  `selectors.ts` or `selectors.js` or `FeatureSelectors.ts` to include a feature name prefix\n*   **Actions:** `actions.ts` or `actions.js` or `FeatureActions.ts` to include a feature name prefix\n*   **Styles:** Use either `ComponentName.module.css` (for CSS Modules) or `ComponentName.css` (for global styles).\n*   **Utility Functions:** Use camelCase (e.g., `formatDate.ts`).\n\n### 1.3. Module Organization\n\n*   **Encapsulation:** Each feature should be a self-contained module with its components, actions, reducers, and selectors.\n*   **Single Responsibility Principle:** Each module should have a single, well-defined purpose.\n*   **Clear Boundaries:** Define clear boundaries between modules to minimize dependencies and prevent tight coupling.\n\n### 1.4. Component Architecture\n\n*   **Presentational and Container Components:**\n    *   **Presentational (Dumb) Components:** Focus on rendering UI and receiving data and callbacks as props. They should be reusable and independent of Redux.\n    *   **Container (Smart) Components:** Connect to the Redux store and pass data and actions to presentational components.  Use `connect` or `useSelector` and `useDispatch` hooks.\n*   **Small and Reusable Components:** Break down complex UIs into smaller, reusable components to promote code reuse and maintainability.\n*   **Component Composition:** Build complex UIs by composing smaller components.\n\n### 1.5. Code Splitting Strategies\n\n*   **Route-Based Splitting:** Split the application into chunks based on routes to reduce the initial load time. Use `React.lazy` and `Suspense` for lazy loading components.\n*   **Component-Based Splitting:** Split large components into smaller chunks that can be loaded on demand. Use dynamic imports for loading components asynchronously.\n*   **Library Splitting:** Extract commonly used libraries into separate chunks to allow browsers to cache them independently.\n\n## 2. Common Patterns and Anti-Patterns\n\n### 2.1. Design Patterns\n\n*   **Selectors:** Use selectors to abstract the state shape and compute derived data. Selectors improve performance by memoizing results and prevent components from re-rendering unnecessarily.\n*   **Custom Hooks:** Create custom hooks for accessing Redux state and dispatching actions. This simplifies component logic and promotes code reuse. For example:\n\n    typescript\n    import { useDispatch, useSelector } from 'react-redux';\n    import { increment, decrement } from './counterSlice';\n    import { RootState } from './store';\n\n    export const useCounter = () => {\n      const count = useSelector((state: RootState) => state.counter.value);\n      const dispatch = useDispatch();\n\n      const handleIncrement = () => {\n        dispatch(increment());\n      };\n\n      const handleDecrement = () => {\n        dispatch(decrement());\n      };\n\n      return { count, handleIncrement, handleDecrement };\n    };\n    \n*   **Redux Toolkit:** Utilize Redux Toolkit to simplify Redux setup and reduce boilerplate code.  Redux Toolkit provides utilities for creating reducers, actions, and the store.\n\n### 2.2. Recommended Approaches\n\n*   **Normalize State:** Structure your state as a normalized data structure, where each piece of data has a unique ID, and relationships between data are represented by IDs. This improves performance and simplifies data management.  Use libraries like Normalizr to help with this.\n*   **Immutability:** Treat your state as immutable and use immutable update patterns. This ensures predictable state transitions and prevents unexpected side effects.\n*   **Middleware for Side Effects:** Use Redux middleware (e.g., Redux Thunk, Redux Saga) to handle asynchronous operations and side effects. Avoid performing side effects directly in reducers.\n\n### 2.3. Anti-Patterns and Code Smells\n\n*   **Mutating State Directly:** Never mutate the state directly in reducers. Always create a new copy of the state with the desired changes.\n*   **Performing Side Effects in Reducers:** Reducers should be pure functions and should not perform any side effects (e.g., API calls, logging).\n*   **Storing UI State in Redux:** Avoid storing UI-specific state (e.g., component visibility, form input values) in the Redux store. Store UI state locally in component state.\n*   **Over-reliance on Global State:** Avoid putting everything in the Redux store.  Only store data that needs to be accessed by multiple components or across the entire application.  Consider React Context or local component state for component-specific data.\n\n### 2.4. State Management Best Practices\n\n*   **Minimize Global State:** Only store data in the Redux store that needs to be shared across multiple components. For component-specific state, use local component state.\n*   **Use Selectors:** Use selectors to access and transform data from the Redux store. This allows you to abstract the state shape and prevent components from re-rendering unnecessarily.\n*   **Immutable Updates:** Always update state immutably to ensure predictable state transitions and prevent unexpected side effects. Use libraries like Immer to simplify immutable updates.\n\n### 2.5. Error Handling Patterns\n\n*   **Centralized Error Handling:** Implement a centralized error handling mechanism to catch and handle errors consistently throughout the application. Use error boundary components to catch errors in the UI.\n*   **Action Creators for Errors:** Dispatch error actions to the Redux store when errors occur. This allows you to track errors and display error messages in the UI.\n*   **Logging Errors:** Log errors to a central logging service for debugging and monitoring purposes.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Memoization:** Use memoization techniques (e.g., `React.memo`, `useMemo`, Reselect) to prevent components from re-rendering unnecessarily.\n*   **Batch Updates:** Batch multiple Redux dispatches into a single update to improve performance. Use `redux-batched-updates` or `unstable_batchedUpdates` from React DOM.\n*   **Virtualization:** Use virtualization techniques (e.g., `react-window`, `react-virtualized`) to efficiently render large lists and tables.\n*   **Code Splitting:** Split the application into smaller chunks to reduce the initial load time.\n\n### 3.2. Memory Management\n\n*   **Avoid Memory Leaks:** Be mindful of memory leaks, especially in event listeners, timers, and subscriptions. Clean up resources properly when components unmount.\n*   **Use WeakRefs:** Use WeakRefs to hold references to objects without preventing them from being garbage collected.\n*   **Profile Memory Usage:** Use the browser's developer tools to profile memory usage and identify potential memory leaks.\n\n### 3.3. Rendering Optimization\n\n*   **ShouldComponentUpdate / React.memo:** Use `shouldComponentUpdate` (for class components) or `React.memo` (for functional components) to prevent components from re-rendering unnecessarily.\n*   **Pure Components:** Use pure components to automatically implement `shouldComponentUpdate` based on prop comparisons.\n*   **Immutable Data Structures:** Use immutable data structures to make it easier to detect changes and prevent re-renders.\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove dead code from your bundles. Configure your bundler (e.g., Webpack, Parcel) to enable tree shaking.\n*   **Code Splitting:** Split the application into smaller chunks to reduce the initial load time.\n*   **Minification:** Minify your code to reduce the bundle size.\n*   **Compression:** Compress your bundles using gzip or Brotli.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Route-Based Lazy Loading:** Load components only when their corresponding routes are visited.\n*   **Component-Based Lazy Loading:** Load components on demand when they become visible in the UI.\n*   **Image Lazy Loading:** Load images only when they scroll into view.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS vulnerabilities by sanitizing user input and escaping output.\n*   **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using anti-CSRF tokens.\n*   **Injection Attacks:** Prevent injection attacks (e.g., SQL injection, command injection) by validating user input and using parameterized queries.\n*   **Authentication and Authorization:** Implement secure authentication and authorization mechanisms to protect sensitive data and resources.\n\n### 4.2. Input Validation\n\n*   **Server-Side Validation:** Always validate user input on the server-side to prevent malicious data from being stored in the database.\n*   **Client-Side Validation:** Use client-side validation to provide immediate feedback to users and reduce the load on the server.\n*   **Whitelisting:** Use whitelisting to allow only specific characters or patterns in user input.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **JSON Web Tokens (JWT):** Use JWTs for authentication and authorization. JWTs are stateless and can be easily verified on the server-side.\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization. OAuth 2.0 allows users to grant third-party applications access to their resources without sharing their credentials.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Data Masking:** Mask sensitive data to prevent unauthorized access.\n*   **Data Anonymization:** Anonymize data to remove personally identifiable information (PII).\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **API Keys:** Use API keys to authenticate API requests.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse and denial-of-service attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Test Reducers:** Test reducers to ensure that they handle actions correctly and update the state as expected.\n*   **Test Selectors:** Test selectors to ensure that they return the correct data from the state.\n*   **Test Actions:** Test action creators to ensure that they return the correct actions.\n*   **Test Components:** Test components to ensure that they render correctly and handle user interactions as expected. Use tools like React Testing Library.\n\n### 5.2. Integration Testing\n\n*   **Test Component Interactions:** Test how components interact with each other and with the Redux store.\n*   **Test Data Flow:** Test the flow of data through the application, from the UI to the Redux store and back.\n*   **Test API Integrations:** Test how the application integrates with external APIs.\n\n### 5.3. End-to-End Testing\n\n*   **Test User Flows:** Test complete user flows to ensure that the application functions correctly from end to end.  Use tools like Cypress or Playwright.\n*   **Test Critical Functionality:** Test critical functionality (e.g., login, checkout) to ensure that it is working as expected.\n*   **Test Accessibility:** Test the application for accessibility to ensure that it is usable by people with disabilities.\n\n### 5.4. Test Organization\n\n*   **Test Folder Structure:** Organize tests in a way that mirrors the application's directory structure.\n*   **Test Suites:** Group tests into logical suites based on functionality or component.\n*   **Test Naming Conventions:** Use clear and consistent naming conventions for tests.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock API Calls:** Mock API calls to isolate components and reducers during testing.\n*   **Stub External Dependencies:** Stub external dependencies to control their behavior during testing.\n*   **Use Mock Store:** Use a mock Redux store to test components that are connected to the store.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Forgetting to Connect Components:** Forgetting to connect components to the Redux store, resulting in components not receiving state updates.\n*   **Incorrectly Mapping State to Props:** Incorrectly mapping state to props, resulting in components not receiving the correct data.\n*   **Not Updating State Immutably:** Not updating state immutably, leading to unexpected side effects and re-renders.\n*   **Using `setState` with Redux:** Mixing `setState` with Redux can lead to inconsistencies and difficult-to-debug issues. Avoid using `setState` in components connected to Redux, unless for purely local, non-Redux-related state.\n\n### 6.2. Edge Cases\n\n*   **Race Conditions:** Be aware of race conditions when handling asynchronous operations.\n*   **Memory Leaks:** Watch out for memory leaks in event listeners, timers, and subscriptions.\n*   **Performance Bottlenecks:** Identify and address performance bottlenecks, such as unnecessary re-renders or slow API calls.\n\n### 6.3. Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes when upgrading React and Redux.\n*   **Deprecated Features:** Avoid using deprecated features and migrate to the recommended alternatives.\n\n### 6.4. Compatibility Concerns\n\n*   **Browser Compatibility:** Test the application in different browsers to ensure compatibility.\n*   **Device Compatibility:** Test the application on different devices to ensure compatibility.\n\n### 6.5. Debugging Strategies\n\n*   **Redux DevTools:** Use the Redux DevTools to inspect the Redux store, track actions, and time travel through state changes.\n*   **Console Logging:** Use console logging to debug code and track the flow of data.\n*   **Breakpoints:** Use breakpoints to pause execution and inspect variables in the debugger.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Redux DevTools:** The Redux DevTools extension for Chrome and Firefox allows you to inspect the Redux store, track actions, and time travel through state changes.\n*   **React Developer Tools:** The React Developer Tools extension for Chrome and Firefox allows you to inspect the React component tree and profile component performance.\n*   **ESLint:** ESLint is a linter that helps you identify and fix code style issues and potential errors.\n*   **Prettier:** Prettier is a code formatter that automatically formats your code to ensure consistency.\n\n### 7.2. Build Configuration\n\n*   **Webpack:** Webpack is a module bundler that bundles your code and dependencies into optimized bundles for production.\n*   **Parcel:** Parcel is a zero-configuration bundler that is easy to use and provides fast build times.\n*   **Create React App:** Create React App is a tool that sets up a React development environment with sensible defaults.\n\n### 7.3. Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce code style rules and prevent potential errors. Configure ESLint to use a popular style guide, such as Airbnb or Standard.\n*   **Prettier:** Use Prettier to automatically format your code to ensure consistency. Integrate Prettier with ESLint to automatically fix code style issues.\n*   **Husky and Lint-Staged:** Use Husky and Lint-Staged to automatically run linters and formatters on staged files before committing code.\n\n### 7.4. Deployment Best Practices\n\n*   **Environment Variables:** Use environment variables to configure the application for different environments (e.g., development, staging, production).\n*   **Continuous Integration:** Use a continuous integration (CI) system to automatically build and test the application whenever code is committed.\n*   **Continuous Deployment:** Use a continuous deployment (CD) system to automatically deploy the application to production whenever a new release is created.\n*   **Caching:** Configure caching on the server-side and client-side to improve performance.\n\n### 7.5. CI/CD Integration\n\n*   **GitHub Actions:** Use GitHub Actions to automate the build, test, and deployment process.\n*   **CircleCI:** Use CircleCI to automate the build, test, and deployment process.\n*   **Jenkins:** Use Jenkins to automate the build, test, and deployment process.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "react-redux.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "react",
      "redux",
      "enforces",
      "best",
      "practices",
      "structuring",
      "maintaining",
      "applications",
      "focusing",
      "code",
      "react-redux",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "react-redux",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-react",
    "description": "Comprehensive guide to React best practices, covering code organization, performance, security, testing, and common pitfalls. Adhering to these guidelines helps developers build maintainable, scalable, and high-performing React applications.",
    "author": "sanjeed5",
    "tags": [
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/react.mdc",
    "content": "# React Best Practices: A Comprehensive Guide\n\nThis document outlines the best practices for developing React applications, covering various aspects from code organization to security and testing. Following these guidelines leads to more maintainable, scalable, and performant applications.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nA well-defined directory structure is crucial for maintainability. Here's a recommended structure:\n\n\nsrc/\n  ├── components/\n  │   ├── Button/\n  │   │   ├── Button.jsx\n  │   │   ├── Button.module.css\n  │   │   └── Button.test.jsx\n  │   ├── Input/\n  │   │   ├── Input.jsx\n  │   │   ├── Input.module.css\n  │   │   └── Input.test.jsx\n  │   └── ...\n  ├── contexts/\n  │   ├── AuthContext.jsx\n  │   └── ThemeContext.jsx\n  ├── hooks/\n  │   ├── useAuth.js\n  │   └── useTheme.js\n  ├── pages/\n  │   ├── Home.jsx\n  │   ├── About.jsx\n  │   └── ...\n  ├── services/\n  │   ├── api.js\n  │   └── auth.js\n  ├── utils/\n  │   ├── helpers.js\n  │   └── validators.js\n  ├── App.jsx\n  ├── index.jsx\n  └── ...\n\n\n-   **`components/`**: Reusable UI components.\n    -   Each component has its own directory containing the component file, associated styles (using CSS modules), and tests.\n-   **`contexts/`**: React context providers.\n-   **`hooks/`**: Custom React hooks.\n-   **`pages/`**: Top-level components representing different routes or views.\n-   **`services/`**: API interaction logic.\n-   **`utils/`**: Utility functions.\n\n### 1.2 File Naming Conventions\n\n-   **Components**: Use PascalCase (e.g., `MyComponent.jsx`).\n-   **Hooks**: Use camelCase prefixed with `use` (e.g., `useMyHook.js`).\n-   **Contexts**: Use PascalCase suffixed with `Context` (e.g., `MyContext.jsx`).\n-   **Services/Utils**: Use camelCase (e.g., `apiService.js`, `stringUtils.js`).\n-   **CSS Modules**: Use `.module.css` or `.module.scss` (e.g., `Button.module.css`).\n\n### 1.3 Module Organization\n\n-   **Co-location**: Keep related files (component, styles, tests) together in the same directory.\n-   **Single Responsibility**: Each module should have a clear and specific purpose.\n-   **Avoid Circular Dependencies**: Ensure modules don't depend on each other in a circular manner.\n\n### 1.4 Component Architecture\n\n-   **Atomic Design**: Consider using Atomic Design principles (Atoms, Molecules, Organisms, Templates, Pages) to structure components.\n-   **Composition over Inheritance**: Favor component composition to reuse code and functionality.\n-   **Presentational and Container Components**: Separate UI rendering (presentational) from state management and logic (container).\n\n### 1.5 Code Splitting Strategies\n\n-   **Route-Based Splitting**: Use `React.lazy` and `Suspense` to load components only when a specific route is accessed.  This is very common and improves initial load time.\n-   **Component-Based Splitting**: Split large components into smaller chunks that can be loaded on demand.\n-   **Bundle Analyzer**: Use a tool like `webpack-bundle-analyzer` to identify large dependencies and optimize bundle size.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n-   **Higher-Order Components (HOCs)**: Reusable logic that wraps components (use with caution; prefer hooks).\n-   **Render Props**: Sharing code using a prop whose value is a function.\n-   **Compound Components**: Components that work together implicitly (e.g., `Tabs`, `Tab`).\n-   **Hooks**: Reusable stateful logic that can be shared across functional components.\n\n### 2.2 Recommended Approaches\n\n-   **Form Handling**: Use controlled components with local state or a form library like Formik or React Hook Form.\n-   **API Calls**: Use `useEffect` hook to make API calls and manage loading states.\n-   **Conditional Rendering**: Use short-circuit evaluation (`&&`) or ternary operators for simple conditions; use separate components for complex scenarios.\n-   **List Rendering**: Always provide a unique and stable `key` prop when rendering lists.\n\n### 2.3 Anti-patterns and Code Smells\n\n-   **Direct DOM Manipulation**: Avoid directly manipulating the DOM; let React handle updates.\n-   **Mutating State Directly**: Always use `setState` or the state updater function to modify state.\n-   **Inline Styles**: Use CSS modules or styled-components for maintainable styles.\n-   **Over-Engineering**: Avoid using complex solutions for simple problems.\n-   **Prop Drilling**: Passing props through multiple levels of components without them being used.\n\n### 2.4 State Management Best Practices\n\n-   **Local State**: Use `useState` for component-specific state.\n-   **Context API**: Use `useContext` for global state accessible to many components, but avoid for very frequently updated data.\n-   **Redux/Mobx**: Use these libraries for complex state management in large applications.\n-   **Recoil/Zustand**: Lightweight alternatives to Redux, often easier to set up and use.\n-   **Immutable Data**: Treat state as immutable to prevent unexpected side effects.\n\n### 2.5 Error Handling Patterns\n\n-   **Error Boundaries**: Wrap components with error boundaries to catch errors during rendering and prevent crashes.\n-   **Try-Catch Blocks**: Use try-catch blocks for handling errors in asynchronous operations and event handlers.\n-   **Centralized Error Logging**: Implement a centralized error logging service to track errors and improve application stability.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Memoization**: Use `React.memo`, `useMemo`, and `useCallback` to prevent unnecessary re-renders and recalculations.\n-   **Virtualization**: Use libraries like `react-window` or `react-virtualized` to efficiently render large lists or tables.\n-   **Debouncing/Throttling**: Limit the rate at which functions are executed (e.g., in input fields).\n-   **Code Splitting**: Load code on demand using `React.lazy` and `Suspense`.\n\n### 3.2 Memory Management\n\n-   **Avoid Memory Leaks**: Clean up event listeners, timers, and subscriptions in `useEffect`'s cleanup function.\n-   **Release Unused Objects**: Avoid holding onto large objects in memory when they are no longer needed.\n-   **Garbage Collection**: Understand how JavaScript's garbage collection works and avoid creating unnecessary objects.\n\n### 3.3 Rendering Optimization\n\n-   **Minimize State Updates**: Avoid unnecessary state updates that trigger re-renders.\n-   **Batch Updates**: Batch multiple state updates into a single update using `ReactDOM.unstable_batchedUpdates`.\n-   **Keys**: Ensure that keys are unique and consistent across renders.\n\n### 3.4 Bundle Size Optimization\n\n-   **Tree Shaking**: Remove unused code during the build process.\n-   **Minification**: Reduce the size of JavaScript and CSS files.\n-   **Image Optimization**: Compress and optimize images to reduce file size.\n-   **Dependency Analysis**: Use tools like `webpack-bundle-analyzer` to identify large dependencies.\n\n### 3.5 Lazy Loading Strategies\n\n-   **Route-Based Lazy Loading**: Load components when a user navigates to a specific route.\n-   **Component-Based Lazy Loading**: Load components when they are about to be rendered.\n-   **Intersection Observer**: Load components when they become visible in the viewport.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n-   **Cross-Site Scripting (XSS)**: Sanitize user input to prevent malicious code injection.\n-   **Cross-Site Request Forgery (CSRF)**: Use anti-CSRF tokens to protect against unauthorized requests.\n-   **Denial of Service (DoS)**: Implement rate limiting and request validation to prevent abuse.\n-   **Injection Attacks**: Avoid directly embedding user input into database queries or system commands.\n\n### 4.2 Input Validation\n\n-   **Client-Side Validation**: Validate user input in the browser to provide immediate feedback.\n-   **Server-Side Validation**: Always validate user input on the server to prevent malicious data.\n-   **Sanitize Input**: Sanitize user input to remove potentially harmful characters or code.\n\n### 4.3 Authentication and Authorization\n\n-   **Secure Authentication**: Use secure authentication mechanisms like OAuth 2.0 or JWT.\n-   **Role-Based Access Control (RBAC)**: Implement RBAC to control access to resources based on user roles.\n-   **Multi-Factor Authentication (MFA)**: Enable MFA to add an extra layer of security.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption**: Encrypt sensitive data at rest and in transit.\n-   **Data Masking**: Mask sensitive data in logs and UI displays.\n-   **Regular Backups**: Create regular backups of application data.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS**: Use HTTPS to encrypt communication between the client and the server.\n-   **API Keys**: Protect API keys and secrets.\n-   **CORS**: Configure Cross-Origin Resource Sharing (CORS) to prevent unauthorized access to APIs.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n-   **Test Components**: Test individual components in isolation.\n-   **Testing Library**: Use React Testing Library for UI testing, focusing on user behavior.\n-   **Jest**: Use Jest as the test runner.\n\n### 5.2 Integration Testing\n\n-   **Test Component Interactions**: Test how components interact with each other.\n-   **Mock API Calls**: Mock API calls to test component behavior in different scenarios.\n-   **React Testing Library**: Effective for testing integration points in components.\n\n### 5.3 End-to-End (E2E) Testing\n\n-   **Test Full Application Flows**: Test complete user flows, such as login, registration, and checkout.\n-   **Cypress/Playwright**: Use tools like Cypress or Playwright for E2E testing.\n-   **Automated Browser Tests**: Automate browser tests to ensure application stability.\n\n### 5.4 Test Organization\n\n-   **Co-locate Tests**: Keep test files close to the components they test (e.g., `Button.test.jsx` in the `Button` directory).\n-   **Descriptive Names**: Use descriptive names for test files and test cases.\n-   **Test Suites**: Organize tests into logical suites.\n\n### 5.5 Mocking and Stubbing\n\n-   **Mock Modules**: Mock external modules or API calls to isolate components during testing.\n-   **Stub Functions**: Stub function implementations to control component behavior.\n-   **Jest Mocks**: Utilize Jest's mocking capabilities for effective unit testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n-   **Ignoring Keys in Lists**: Forgetting to provide unique and stable `key` props when rendering lists.\n-   **Incorrect State Updates**: Mutating state directly instead of using `setState` or the state updater function.\n-   **Missing Dependencies in `useEffect`**: Not including all dependencies in the dependency array of the `useEffect` hook.\n-   **Over-Using State**: Storing derived data in state instead of calculating it on demand.\n\n### 6.2 Edge Cases\n\n-   **Asynchronous State Updates**: Handling state updates in asynchronous operations.\n-   **Race Conditions**: Preventing race conditions when making multiple API calls.\n-   **Handling Errors in Event Handlers**: Properly handling errors in event handlers to prevent crashes.\n\n### 6.3 Version-Specific Issues\n\n-   **React 16 vs. React 17/18**: Understanding differences in lifecycle methods, error handling, and concurrent mode.\n-   **Deprecated Features**: Being aware of deprecated features and using recommended alternatives.\n\n### 6.4 Compatibility Concerns\n\n-   **Browser Compatibility**: Ensuring compatibility with different browsers and devices.\n-   **Library Compatibility**: Ensuring compatibility between React and other libraries.\n\n### 6.5 Debugging Strategies\n\n-   **React DevTools**: Use React DevTools to inspect component hierarchies, props, and state.\n-   **Console Logging**: Use console logging to debug code and track variables.\n-   **Breakpoints**: Set breakpoints in the code to step through execution and inspect variables.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **VS Code**: A popular code editor with excellent React support.\n-   **Create React App**: A tool for quickly setting up a new React project.\n-   **React DevTools**: A browser extension for inspecting React components.\n-   **ESLint**: A linter for enforcing code style and preventing errors.\n-   **Prettier**: A code formatter for automatically formatting code.\n\n### 7.2 Build Configuration\n\n-   **Webpack/Vite**: Configure Webpack or Vite to bundle and optimize code.\n-   **Babel**: Configure Babel to transpile JavaScript code to older versions.\n-   **Environment Variables**: Use environment variables to configure different environments.\n\n### 7.3 Linting and Formatting\n\n-   **ESLint**: Configure ESLint with recommended React rules.\n-   **Prettier**: Configure Prettier to automatically format code.\n-   **Husky/lint-staged**: Use Husky and lint-staged to run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n-   **Static Hosting**: Host static assets on a CDN.\n-   **Server-Side Rendering (SSR)**: Use SSR to improve SEO and initial load time.\n-   **Continuous Deployment**: Automate the deployment process using CI/CD.\n\n### 7.5 CI/CD Integration\n\n-   **GitHub Actions/GitLab CI**: Use GitHub Actions or GitLab CI to automate testing, linting, and deployment.\n-   **Automated Testing**: Run automated tests on every commit or pull request.\n-   **Automated Deployment**: Automatically deploy code to production after successful tests.\n\nBy following these best practices, React developers can build high-quality, maintainable, and scalable applications that meet the demands of modern web development. Continual education and adaptation to emerging trends in the React ecosystem are crucial for sustained success.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "react.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "react",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-redis",
    "description": "This rule provides best practices for working with Redis, covering code organization, performance, security, testing, and common pitfalls to ensure efficient and reliable usage. It applies to any language file interacting with Redis.",
    "author": "sanjeed5",
    "tags": [
      "redis",
      "cache",
      "database",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/redis.mdc",
    "content": "- **General Best Practices**\n  - Follow official Redis documentation and community best practices.\n  - Use the most recent stable version of the Redis client library for your language.\n  - Regularly update the Redis server and client libraries to benefit from bug fixes, performance improvements, and security patches.\n\n- **Connection Management**\n  - **Connection Pooling:** Use connection pooling to reduce the overhead of creating new connections for each operation.  This significantly improves performance, especially in high-traffic scenarios.\n  - **Connection Timeout:** Configure appropriate connection timeouts to prevent indefinite blocking in case of network issues.\n  - **Retry Logic:** Implement retry logic with exponential backoff for transient connection errors.\n  - **Secure Connections:**  When connecting to a remote Redis instance, always use TLS/SSL encryption (redis+ssl://) to protect data in transit, especially when dealing with sensitive information. Ensure proper certificate validation.\n\n- **Data Modeling and Serialization**\n  - **Key Naming:** Use consistent and meaningful key naming conventions. Consider using namespaces or prefixes to organize keys and avoid collisions.\n  - **Data Serialization:** Choose an efficient serialization format (e.g., JSON, Protocol Buffers, MessagePack) and use it consistently.  Consider the trade-offs between human readability, storage space, and serialization/deserialization performance.\n  - **Smaller Values:**  Redis works best with smaller values. Break larger data structures into smaller chunks and distribute them across multiple keys.  This improves memory utilization and performance.\n  - **Data Types:**  Leverage Redis's rich data types (strings, lists, sets, sorted sets, hashes, streams) effectively to optimize data storage and operations.  Choose the data type that best suits the use case.\n\n- **Command Usage**\n  - **Transactions:** Use transactions (`MULTI`, `EXEC`, `DISCARD`, `WATCH`) to ensure atomicity when performing multiple operations.  Be aware of the limitations of Redis transactions (no rollback on individual command failure).\n  - **Pipelines:** Use pipelines to batch multiple commands together and reduce network round-trip time. This dramatically improves performance for bulk operations.\n  - **Lua Scripting:** Use Lua scripting for complex operations that require atomicity and server-side processing.  This reduces network traffic and improves performance compared to executing multiple individual commands.\n  - **Avoid Blocking Commands:**  Avoid using blocking commands like `KEYS`, `FLUSHALL`, `FLUSHDB`, `SORT` without `LIMIT` in production environments. These commands can block the Redis server and degrade performance.\n  - **Use SCAN:** Instead of `KEYS`, use the `SCAN` command for iterating over keys in a non-blocking manner.  This allows the Redis server to continue serving other requests while iterating.\n  - **Efficient Deletion:** Instead of `FLUSHALL` or `FLUSHDB`, use `SCAN` with `DEL` to delete keys in batches, minimizing disruption to the server.\n  - **TTL Management:** Set appropriate Time-To-Live (TTL) values for keys to automatically expire data that is no longer needed. This helps manage memory usage and prevent data from becoming stale.\n\n- **Memory Management**\n  - **Maxmemory:** Configure the `maxmemory` directive to limit the amount of memory Redis can use.  When the limit is reached, Redis will evict keys based on the configured eviction policy.\n  - **Eviction Policies:** Choose an appropriate eviction policy (e.g., `LRU`, `LFU`, `volatile-ttl`) based on your application's needs. Understand the trade-offs between different eviction policies.\n  - **Memory Fragmentation:** Monitor memory fragmentation and consider restarting Redis periodically to defragment memory. The `INFO memory` command provides information about memory usage and fragmentation.\n\n- **Performance Monitoring and Tuning**\n  - **Redis Monitor:** Use the `MONITOR` command (with caution in production) to observe real-time commands being executed on the server.  This can help identify performance bottlenecks.\n  - **Redis Slow Log:** Configure the Redis slow log to record commands that take longer than a specified amount of time to execute. Analyze the slow log to identify performance issues.\n  - **INFO Command:** Use the `INFO` command to gather information about the Redis server, including memory usage, CPU usage, and client connections.  This information can be used to monitor performance and identify potential problems.\n  - **Latency Monitoring:** Monitor Redis latency using tools like `redis-cli --latency` or dedicated monitoring solutions.  High latency can indicate performance issues.\n\n- **Security Considerations**\n  - **Authentication:**  Enable authentication using the `requirepass` directive to protect the Redis server from unauthorized access.  Use a strong password.\n  - **Access Control Lists (ACLs):** Use ACLs to restrict access to specific commands and keys for different users.  This provides fine-grained control over access to Redis data.\n  - **Network Security:**  Restrict network access to the Redis server using firewalls or other network security measures.  Only allow connections from trusted sources.\n  - **Disable Unsafe Commands:**  Disable or rename potentially dangerous commands like `FLUSHALL`, `FLUSHDB`, `KEYS`, `EVAL` using the `rename-command` directive.  This reduces the risk of accidental or malicious misuse.\n  - **Regular Audits:** Conduct regular security audits of the Redis configuration and usage patterns to identify and address potential vulnerabilities.\n  - **Input Validation:** Always validate and sanitize any data being stored in Redis to prevent injection attacks.\n\n- **Testing Strategies**\n  - **Unit Tests:** Write unit tests to verify the functionality of your code that interacts with Redis.  Use mocking or stubbing to isolate the Redis interactions from the rest of the code.\n  - **Integration Tests:** Write integration tests to verify the interaction between your code and the Redis server.  Use a dedicated test Redis instance for integration tests.\n  - **End-to-End Tests:** Write end-to-end tests to verify the entire application flow, including the interaction with Redis.  This ensures that the application works correctly in a realistic environment.\n  - **Data Population:** When testing, consider populating your redis database with a representative set of data. \n  - **Test Organization:** Organize tests logically, separating unit, integration, and end-to-end tests into different directories or modules.\n  - **Mocking and Stubbing:** Use mocking and stubbing frameworks to simulate Redis behavior during unit tests.\n\n- **Code Organization and Structure**\n  - **Dedicated Module:** Create a dedicated module or class to encapsulate all Redis-related operations.  This promotes code reuse and maintainability.\n  - **Configuration Management:** Store Redis connection parameters (host, port, password) in a configuration file or environment variables.  This makes it easy to change the Redis configuration without modifying code.\n  - **Abstraction Layer:**  Consider creating an abstraction layer on top of the Redis client library to provide a higher-level API for your application.  This can improve code readability and make it easier to switch to a different Redis client library in the future.\n\n- **Common Pitfalls and Gotchas**\n  - **N+1 Problem:** Avoid the N+1 problem when retrieving data from Redis.  Instead of making multiple individual requests, use pipelining or Lua scripting to retrieve the data in a single request.\n  - **Race Conditions:** Be aware of potential race conditions when updating data in Redis.  Use transactions or Lua scripting to ensure atomicity.\n  - **Large Values:** Avoid storing extremely large values in Redis.  This can lead to performance issues and memory exhaustion.\n  - **Key Expiration:**  Be careful when using key expiration (TTL).  If keys expire unexpectedly, it can lead to data loss or inconsistent application behavior.\n  - **Blocking Operations in Event Loops:** Do not perform blocking Redis operations directly in event loops or GUI threads. Use asynchronous operations instead to avoid blocking the main thread.\n\n- **Tooling and Environment**\n  - **Redis CLI:** Use the Redis CLI (`redis-cli`) for interacting with the Redis server, executing commands, and monitoring performance.\n  - **Redis Desktop Manager:** Use a Redis desktop manager (e.g., RedisInsight, Medis) for visualizing data, managing keys, and monitoring the Redis server.\n  - **Linting and Formatting:** Configure linters and formatters to enforce consistent code style and best practices in your Redis-related code.\n  - **CI/CD Integration:** Integrate Redis testing and deployment into your CI/CD pipeline to automate the testing and deployment process.\n  - **Monitoring Tools:** Utilize monitoring tools like Prometheus, Grafana, or Datadog to monitor Redis performance and health in production environments.",
    "metadata": {
      "globs": "*.py,*.js,*.go,*.java,*.c,*.cpp,*.rb,*.php,*.ts,*.rs,*.kt,*.scala",
      "format": "mdc",
      "originalFile": "redis.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "redis",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "working",
      "with",
      "covering",
      "code",
      "cache",
      "database",
      "cursor-rule",
      "mdc",
      "data-ai",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "redis",
        "cache",
        "database",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "data-ai"
    }
  },
  {
    "name": "cursor-redux",
    "description": "This rule provides comprehensive guidance on Redux best practices, covering code structure, performance optimization, testing strategies, and common pitfalls to ensure robust and maintainable Redux applications.",
    "author": "sanjeed5",
    "tags": [
      "redux",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/redux.mdc",
    "content": "- **Introduction:** This document outlines best practices for developing applications with Redux, covering various aspects from code organization to performance optimization.\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:** Organize your Redux-related files in a clear and maintainable structure. A feature-based approach is recommended.\n    - Example:\n      \n      src/\n      ├── app/\n      │   ├── store.js          # Redux store configuration\n      ├── features/\n      │   ├── counter/        # Feature module (e.g., 'counter')\n      │   │   ├── counterSlice.js # Redux slice (reducers + actions)\n      │   │   ├── Counter.jsx      # React component\n      │   │   ├── counterAPI.js   # API interaction logic\n      │   │   └── counterSelectors.js # Selectors\n      │   ├── todos/\n      │   │   └── ...\n      ├── components/          # Reusable UI components\n      ├── utils/               # Utility functions\n      └── ...\n      \n\n- **File Naming Conventions:** Use consistent and descriptive names for your files.\n    - Example:\n        - `counterSlice.js` for Redux slice files\n        - `Counter.jsx` for React components\n        - `counterActions.js` or preferably included in slice\n        - `counterSelectors.js` for selectors\n\n- **Module Organization:** Group related logic into modules. Each feature should have its own directory containing its Redux slice, components, and selectors.\n\n- **Component Architecture:** Use a container/presentational component pattern to separate data fetching and state management logic from UI rendering.\n    - **Container Components:** Connect to the Redux store and pass data to presentational components.\n    - **Presentational Components:** Focus on UI rendering and receive data and callbacks as props.\n\n- **Code Splitting Strategies:** Implement code splitting to reduce the initial bundle size and improve loading times.\n    - **Route-based splitting:** Load different parts of the application based on the current route.\n    - **Component-based splitting:** Lazy-load components that are not immediately needed.\n    - Use `React.lazy` and `<Suspense>` for component-based splitting.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - **Flux Standard Actions (FSA):** A convention for structuring Redux actions with a `type` and an optional `payload` and `error` property.\n    - **Selectors:** Use selectors (e.g., with Reselect) to derive data from the Redux store efficiently.\n    - **Thunks/Sagas:** Manage asynchronous side effects using Redux Thunk or Redux Saga.\n\n- **Recommended Approaches:**\n    - **Redux Toolkit:** Use Redux Toolkit to simplify Redux development and reduce boilerplate.\n    - **Immutability:** Treat state as immutable and use immutable data structures or techniques to update it.\n    - **Normalization:** Normalize your state to reduce data duplication and improve data consistency.\n\n- **Anti-patterns and Code Smells:**\n    - **Mutating State Directly:** Never mutate state directly. Always create new copies of objects and arrays.\n    - **Putting too much logic in components:** Keep components focused on rendering. Move complex logic to reducers, selectors, or middleware.\n    - **Large Reducers:** Split large reducers into smaller, more manageable reducers using `combineReducers`.\n    - **Over-fetching Data:** Fetch only the data that is needed by the component. Use selectors to derive specific data subsets from the state.\n\n- **State Management Best Practices:**\n    - **Single Source of Truth:** Keep all application state in the Redux store.\n    - **Predictable State Updates:** Ensure that state updates are predictable and deterministic.\n    - **Minimize Global State:** Only store data that is truly global in the Redux store. Local component state should be used for UI-specific data.\n\n- **Error Handling Patterns:**\n    - **Action-based Error Handling:** Dispatch actions to indicate errors and update the state accordingly.\n    - **Middleware Error Handling:** Use middleware to catch errors and log them to a central error reporting service.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - **Memoization:** Use memoization to avoid unnecessary re-renders. Use `React.memo` for functional components and `shouldComponentUpdate` for class components.\n    - **Selectors:** Use selectors with memoization (e.g., Reselect) to avoid recomputing derived data when the input state hasn't changed.\n    - **Batch Updates:** Batch multiple state updates into a single update to reduce the number of re-renders.\n    - **Debouncing/Throttling:** Use debouncing or throttling to limit the frequency of updates.\n\n- **Memory Management:**\n    - **Avoid Memory Leaks:** Clean up event listeners and timers when components unmount.\n    - **Optimize Data Structures:** Use efficient data structures to reduce memory usage.\n\n- **Rendering Optimization:**\n    - **Virtualization:** Use virtualization for large lists to only render the visible items.\n    - **Code Splitting:** Reduce the initial bundle size by splitting the code into smaller chunks.\n\n- **Bundle Size Optimization:**\n    - **Tree Shaking:** Remove unused code from the bundle using tree shaking.\n    - **Minification:** Minify the code to reduce the bundle size.\n    - **Compression:** Compress the bundle using Gzip or Brotli.\n\n- **Lazy Loading Strategies:**\n    - **Route-based Lazy Loading:** Load different routes on demand.\n    - **Component-based Lazy Loading:** Load components on demand using `React.lazy`.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user inputs and escaping outputs.\n    - **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by using anti-CSRF tokens.\n    - **Data Injection:** Prevent data injection attacks by validating and sanitizing inputs.\n\n- **Input Validation:**\n    - **Client-Side Validation:** Validate inputs on the client-side to provide immediate feedback to the user.\n    - **Server-Side Validation:** Validate inputs on the server-side to ensure data integrity.\n\n- **Authentication and Authorization Patterns:**\n    - **JWT (JSON Web Tokens):** Use JWTs for authentication and authorization.\n    - **Role-Based Access Control (RBAC):** Implement RBAC to control access to different parts of the application.\n\n- **Data Protection Strategies:**\n    - **Encryption:** Encrypt sensitive data at rest and in transit.\n    - **Data Masking:** Mask sensitive data to protect it from unauthorized access.\n\n- **Secure API Communication:**\n    - **HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n    - **API Rate Limiting:** Implement API rate limiting to prevent abuse.\n\n## 5. Testing Approaches:\n\n- **Unit Testing Strategies:**\n    - **Test Reducers:** Test reducers to ensure that they update the state correctly.\n    - **Test Actions:** Test actions to ensure that they dispatch the correct payloads.\n    - **Test Selectors:** Test selectors to ensure that they derive the correct data from the state.\n\n- **Integration Testing:**\n    - **Test Components:** Test components to ensure that they render correctly and interact with the Redux store.\n    - **Test Middleware:** Test middleware to ensure that they handle side effects correctly.\n\n- **End-to-end Testing:**\n    - **Test User Flows:** Test user flows to ensure that the application works as expected from the user's perspective.\n\n- **Test Organization:**\n    - **Test Directory Structure:** Organize tests in a clear and maintainable structure.\n        - Example:\n          \n          src/\n          ├── features/\n          │   ├── counter/\n          │   │   ├── counterSlice.test.js\n          │   │   ├── Counter.test.jsx\n          \n\n- **Mocking and Stubbing:**\n    - **Mock API Calls:** Mock API calls to isolate components and reducers during testing.\n    - **Stub Dependencies:** Stub external dependencies to control their behavior during testing.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n    - **Forgetting to Return State:** Reducers must always return the new state.  If no change, return the original state.\n    - **Incorrectly Updating Nested Objects:** Remember to create copies of all levels when updating nested objects.\n    - **Not Handling Asynchronous Actions Correctly:** Using thunks or sagas incorrectly can lead to unexpected behavior.\n\n- **Edge Cases:**\n    - **Initial State:** Ensure that the initial state is correctly defined.\n    - **Handling Errors:** Handle errors gracefully and provide informative error messages.\n    - **Empty States:** Handle empty states correctly to avoid unexpected behavior.\n\n- **Version-Specific Issues:**\n    - **React Redux v8 vs v7:** Be aware of the changes introduced in React Redux v8, such as the improved performance and the new `useSyncExternalStore` hook.\n\n- **Compatibility Concerns:**\n    - **Browser Compatibility:** Ensure that the application works correctly in all supported browsers.\n    - **Device Compatibility:** Ensure that the application works correctly on all supported devices.\n\n- **Debugging Strategies:**\n    - **Redux DevTools:** Use the Redux DevTools extension to inspect the state and track actions.\n    - **Console Logging:** Use console logging to debug code and track state changes.\n    - **Debugging Tools:** Use browser debugging tools to step through code and inspect variables.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - **Redux DevTools Extension:** Inspect Redux state and actions.\n    - **VS Code with Redux Extension:** Provides code completion, linting, and debugging support for Redux.\n\n- **Build Configuration:**\n    - **Webpack/Parcel/Rollup:** Use a module bundler to bundle the code and optimize it for production.\n    - **Babel:** Use Babel to transpile the code to older versions of JavaScript.\n\n- **Linting and Formatting:**\n    - **ESLint:** Use ESLint to enforce code style and prevent errors.\n    - **Prettier:** Use Prettier to automatically format the code.\n\n- **Deployment Best Practices:**\n    - **Environment Variables:** Use environment variables to configure the application for different environments.\n    - **CDN:** Use a CDN to serve static assets.\n\n- **CI/CD Integration:**\n    - **Automated Testing:** Run tests automatically as part of the CI/CD pipeline.\n    - **Automated Deployment:** Deploy the application automatically to different environments.\n\nThis comprehensive guide should help you build robust, maintainable, and performant Redux applications. Remember to stay up-to-date with the latest best practices and tools in the Redux ecosystem.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "redux.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "redux",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "redux",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-remix",
    "description": "This rule file provides comprehensive best practices for Remix development, covering code organization, performance, security, testing, and more. It aims to guide developers in building maintainable, scalable, and secure Remix applications.",
    "author": "sanjeed5",
    "tags": [
      "remix",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/remix.mdc",
    "content": "## Remix Best Practices and Coding Standards\n\nThis document outlines the recommended best practices and coding standards for developing Remix applications. Following these guidelines will promote code consistency, maintainability, performance, and security.\n\n### 1. Code Organization and Structure\n\n#### 1.1. Directory Structure\n\nA well-structured directory is crucial for maintainability and scalability. Here's a recommended structure:\n\n\nmy-remix-app/\n├── app/\n│   ├── components/       # Reusable UI components\n│   │   ├── Button.tsx\n│   │   ├── Card.tsx\n│   │   └── ...\n│   ├── utils/            # Utility functions (e.g., date formatting, API helpers)\n│   │   ├── date-utils.ts\n│   │   ├── api.ts\n│   │   └── ...\n│   ├── services/         # Business logic and data access\n│   │   ├── auth.server.ts  # Authentication logic (server-only)\n│   │   ├── user.server.ts  # User data access (server-only)\n│   │   └── ...\n│   ├── routes/            # Remix route modules\n│   │   ├── _index.tsx       # Index route\n│   │   ├── about.tsx        # About page\n│   │   ├── blog/\n│   │   │   ├── $slug.tsx     # Dynamic blog post route\n│   │   │   └── index.tsx     # Blog index page\n│   │   ├── api/\n│   │   │   ├── auth.ts        # API routes for authentication\n│   │   │   └── ...\n│   │   └── ...\n│   ├── styles/            # Global stylesheets\n│   │   ├── global.css\n│   │   └── ...\n│   ├── entry.client.tsx   # Client-side entry point\n│   ├── entry.server.tsx   # Server-side entry point\n│   ├── root.tsx           # Root component (HTML structure)\n│   └── remix.env.d.ts\n├── public/             # Static assets (images, fonts, etc.)\n├── .gitignore\n├── jsconfig.json\n├── package-lock.json\n├── package.json\n├── remix.config.js\n└── tsconfig.json\n\n\n*   `components`:  Reusable UI elements. Separate presentational components from container components (smart vs. dumb components).\n*   `utils`:  Helper functions that are not specific to any React component. This promotes reusability and testability.\n*   `services`: Business logic related files that handle server-side interactions.\n*   `routes`: Defines the application's routes. Each file represents a route segment.  Use nested routes for complex layouts and data dependencies.\n*   `styles`: Global styles.\n*   `public`:  Static assets.\n\n#### 1.2. File Naming Conventions\n\n*   **Components:** PascalCase (e.g., `Button.tsx`).\n*   **Route Modules:** kebab-case (e.g., `about-us.tsx`).  Use `$param` for dynamic route segments (e.g., `$postId.tsx`).\n*   **Utility Functions:** camelCase (e.g., `formatDate.ts`).\n*   **Stylesheets:** kebab-case (e.g., `global.css`).\n*   Server only utilities that do not include UI (e.g `auth.server.ts`)\n\n#### 1.3. Module Organization\n\n*   Group related components, utilities, and services into modules.  A module is a directory containing files that work together to provide a specific functionality.  This improves code discoverability and reduces naming conflicts.\n*   Use index files (`index.ts` or `index.tsx`) to re-export members from a module, providing a single entry point.\n\n\ncomponents/\n├── Button.tsx\n├── Input.tsx\n└── index.ts  # export { Button } from './Button'; export { Input } from './Input';\n\n\n#### 1.4. Component Architecture\n\n*   **Presentational vs. Container Components:** Separate components that handle data fetching and state management (container components) from components that only render UI (presentational components).  This promotes reusability and testability.\n*   **Composition:** Favor composition over inheritance. Use React's `children` prop or render props to create flexible and reusable components.\n*   **Controlled vs Uncontrolled Components:** Understand the difference between controlled and uncontrolled components. Controlled components manage their own state, while uncontrolled components rely on the DOM.\n\n#### 1.5. Code Splitting\n\n*   Remix automatically handles route-based code splitting. Each route module is loaded independently, reducing the initial bundle size.\n*   For larger components or modules, consider using dynamic imports (`React.lazy`) to further split your code. This is particularly helpful for features that are not immediately needed on page load.\n*   Utilize Remix's built-in support for resource routes to handle data loading and background tasks separately, preventing them from blocking the main UI thread.\n\n\n### 2. Common Patterns and Anti-patterns\n\n#### 2.1. Design Patterns\n\n*   **Compound Components:** Useful for components that need to share state or logic implicitly (e.g., Tabs, Accordions).  Uses React Context to provide communication between parent and child components.\n*   **Render Props/Function as Child:**  Provides maximum flexibility by allowing the parent component to control the rendering of its children.\n*   **Hooks:** Extract reusable stateful logic into custom hooks. This promotes code reuse and makes components more readable.\n*   **Provider Pattern:** For managing global state or providing context to a subtree of components.\n\n#### 2.2. Recommended Approaches\n\n*   **Data Loading:** Use Remix loaders for server-side data fetching. This ensures that data is available before the component renders, improving performance and SEO.\n*   **Data Mutations:** Use Remix actions for handling form submissions and data updates. This centralizes data mutations and simplifies state management.\n*   **Error Handling:** Implement error boundaries at the route level to catch errors and prevent the entire application from crashing.\n*   **Authentication:** Implement authentication using server-side sessions or cookies. Avoid storing sensitive data in client-side storage.\n*   **Authorization:** Implement authorization checks in loaders and actions to ensure that users only have access to authorized resources.\n\n#### 2.3. Anti-patterns\n\n*   **Direct DOM Manipulation:** Avoid direct DOM manipulation using `document.querySelector` or `document.getElementById`.  Use React's state management and rendering capabilities instead.\n*   **Over-reliance on Client-Side State:** Utilize Remix's server-side capabilities to minimize client-side state management.  This improves performance and reduces the risk of state inconsistencies.\n*   **Ignoring Server-Side Rendering:**  Take advantage of Remix's server-side rendering capabilities for improved performance and SEO.  Don't perform all data fetching and rendering on the client-side.\n*   **Complex Conditional Rendering in JSX:** Avoid deeply nested conditional rendering within JSX.  Extract complex logic into separate functions or components.\n\n#### 2.4. State Management\n\n*   Remix encourages server-side data fetching and mutations, reducing the need for complex client-side state management.\n*   For simple component-level state, use React's `useState` hook.\n*   For more complex application-level state, consider using Context API with `useReducer` or a state management library like Zustand or Jotai.\n*   If needed, integrate third party state management libraries like Redux with caution, considering the benefits of Remix's built in data handling.\n\n#### 2.5. Error Handling\n\n*   Utilize Remix's ErrorBoundary component to create dedicated error screens for routes.  This provides a better user experience when errors occur.\n*   Handle errors gracefully in loaders and actions. Return error responses or throw exceptions to trigger the error boundary.\n*   Implement logging to track errors and diagnose issues.\n*   Avoid try-catch blocks within components and rely on ErrorBoundaries for global exception handling.\n\n\n### 3. Performance Considerations\n\n#### 3.1. Optimization Techniques\n\n*   **Minimize Bundle Size:**  Remove unused code, optimize images, and use code splitting to reduce the initial bundle size.\n*   **Optimize Data Fetching:**  Fetch only the data that is needed for a specific route. Avoid over-fetching data.\n*   **Cache Data:** Use HTTP caching or server-side caching to reduce the number of requests to the server.\n*   **Memoization:** Use `React.memo` or `useMemo` to prevent unnecessary re-renders of components.\n*   **Debouncing and Throttling:** Use debouncing and throttling to limit the frequency of event handlers, improving performance for user input and animations.\n\n#### 3.2. Memory Management\n\n*   Avoid memory leaks by properly cleaning up event listeners and subscriptions.\n*   Use the `useEffect` hook with a cleanup function to unsubscribe from subscriptions when a component unmounts.\n*   Avoid storing large amounts of data in component state. Consider using a server-side data store or a more efficient data structure.\n\n#### 3.3. Rendering Optimization\n\n*   Use the `shouldComponentUpdate` lifecycle method (or `React.memo`) to prevent unnecessary re-renders of components. Carefully analyze component re-renders with the React Profiler.\n*   Virtualize long lists or tables to improve rendering performance.\n*   Optimize CSS and avoid complex selectors that can slow down rendering.\n\n#### 3.4. Bundle Size Optimization\n\n*   Use tools like `webpack-bundle-analyzer` or `rollup-plugin-visualizer` to analyze your bundle size and identify areas for optimization.\n*   Remove unused dependencies and use tree shaking to eliminate dead code.\n*   Use code splitting to load only the code that is needed for a specific route or component.\n\n#### 3.5. Lazy Loading\n\n*   Use `React.lazy` to lazily load components that are not immediately needed on page load.  This improves the initial load time.\n*   Use Intersection Observer API to load images or other resources when they are visible in the viewport.\n\n\n### 4. Security Best Practices\n\n#### 4.1. Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):**  Prevent XSS attacks by sanitizing user input and escaping HTML entities.\n*   **Cross-Site Request Forgery (CSRF):**  Protect against CSRF attacks by using anti-CSRF tokens in forms and API requests.\n*   **SQL Injection:**  Prevent SQL injection attacks by using parameterized queries or ORMs.\n*   **Authentication and Authorization Issues:**  Implement strong authentication and authorization mechanisms to protect sensitive data and resources.\n\n#### 4.2. Input Validation\n\n*   Validate all user input on both the client-side and server-side.\n*   Use a validation library like Zod or Yup to define schemas for your data.\n*   Sanitize user input to remove potentially malicious characters or code.\n\n#### 4.3. Authentication and Authorization\n\n*   Use a secure authentication protocol like OAuth 2.0 or OpenID Connect.\n*   Store user credentials securely using hashing and salting.\n*   Implement role-based access control (RBAC) to restrict access to sensitive resources.\n*   Use server-side sessions or cookies for authentication. Avoid storing sensitive data in client-side storage.\n\n#### 4.4. Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use HTTPS to secure communication between the client and server.\n*   Protect against data breaches by implementing strong access controls and monitoring for suspicious activity.\n*   Implement data masking or anonymization to protect sensitive data in development and testing environments.\n\n#### 4.5. Secure API Communication\n\n*   Use HTTPS to encrypt API communication.\n*   Implement API rate limiting to prevent abuse.\n*   Validate API requests and responses to prevent data injection attacks.\n*   Use authentication tokens to authorize API requests.\n\n\n### 5. Testing Approaches\n\n#### 5.1. Unit Testing\n\n*   Write unit tests for individual components, utilities, and services.\n*   Use a testing framework like Jest or Mocha.\n*   Mock dependencies to isolate the unit under test.\n*   Test component rendering, state updates, and event handlers.\n\n#### 5.2. Integration Testing\n\n*   Write integration tests to verify the interaction between different parts of the application.\n*   Test data flow between components, loaders, and actions.\n*   Use a testing library like React Testing Library to simulate user interactions.\n*   Mock external APIs and services to ensure that integration tests are reliable.\n\n#### 5.3. End-to-End Testing\n\n*   Write end-to-end tests to verify the entire application flow from the user's perspective.\n*   Use a testing framework like Cypress or Playwright.\n*   Test user authentication, data input, and navigation.\n*   Run end-to-end tests in a continuous integration environment to ensure that the application is working as expected.\n\n#### 5.4. Test Organization\n\n*   Organize tests in a directory structure that mirrors the application code.\n*   Create separate test files for each component, utility, or service.\n*   Use descriptive test names to clearly communicate the purpose of each test.\n*   Keep tests small and focused to improve readability and maintainability.\n\n#### 5.5. Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate units under test and control their dependencies.\n*   Use mocking libraries like Jest's `jest.fn()` or Mock Service Worker (MSW) to mock API responses and external services.\n*   Avoid over-mocking, which can lead to tests that are not representative of the real application.\n\n\n### 6. Common Pitfalls and Gotchas\n\n#### 6.1. Frequent Mistakes\n\n*   **Incorrectly Using Loaders and Actions:** Understanding the lifecycle and purpose of loaders and actions is crucial.  Incorrect use can lead to performance issues and data inconsistencies.\n*   **Ignoring Server-Side Rendering:**  Failing to leverage Remix's server-side rendering capabilities can result in poor SEO and performance.\n*   **Over-Complicating State Management:**  Using complex state management libraries for simple applications can add unnecessary overhead.\n*   **Not Validating User Input:**  Failing to validate user input can lead to security vulnerabilities and data corruption.\n*   **Using Browser Specific APIs in Server Code**: Only use web standard API that are available in Node.js in server code.\n\n#### 6.2. Edge Cases\n\n*   **Handling Empty Data Sets:**  Properly handle cases where loaders return empty data sets.  Display appropriate messages to the user.\n*   **Dealing with Network Errors:**  Implement robust error handling to gracefully handle network errors and API failures.\n*   **Managing User Sessions:**  Implement secure session management to protect user data and prevent unauthorized access.\n*   **Handling Concurrent Requests:**  Be aware of potential race conditions when handling concurrent requests to the server.\n\n#### 6.3. Version-Specific Issues\n\n*   Stay up-to-date with the latest Remix version and be aware of any breaking changes or bug fixes.\n*   Consult the Remix documentation and release notes for information about version-specific issues.\n*   Test your application thoroughly after upgrading to a new version of Remix.\n\n#### 6.4. Compatibility Concerns\n\n*   Be aware of compatibility issues between Remix and other technologies, such as third-party libraries or server-side environments.\n*   Test your application thoroughly in different environments to ensure that it is working as expected.\n*   Use polyfills or shims to address compatibility issues when necessary.\n\n#### 6.5. Debugging Strategies\n\n*   Use the browser's developer tools to debug client-side code.\n*   Use server-side logging to track requests, responses, and errors.\n*   Use a debugger to step through code and inspect variables.\n*   Use profiling tools to identify performance bottlenecks.\n\n\n### 7. Tooling and Environment\n\n#### 7.1. Recommended Tools\n\n*   **Code Editor:** VS Code, Sublime Text, or Atom with appropriate extensions for JavaScript/TypeScript, React, and Remix.\n*   **Browser:** Chrome or Firefox with developer tools for debugging and performance analysis.\n*   **Testing Framework:** Jest or Mocha.\n*   **Testing Library:** React Testing Library or Enzyme.\n*   **Linting:** ESLint with recommended Remix and React rules.\n*   **Formatting:** Prettier.\n\n#### 7.2. Build Configuration\n\n*   Use Remix's built-in build configuration for optimal performance.\n*   Customize the build configuration as needed to optimize bundle size and performance.\n*   Use environment variables to configure the application for different environments.\n\n#### 7.3. Linting and Formatting\n\n*   Use ESLint to enforce code style and prevent errors.\n*   Use Prettier to automatically format code for consistency.\n*   Configure ESLint and Prettier to work together seamlessly.\n*   Use a pre-commit hook to run ESLint and Prettier before committing code.\n\n#### 7.4. Deployment\n\n*   Deploy Remix applications to a serverless environment like Vercel or Netlify for optimal performance and scalability.\n*   Use a containerization platform like Docker to package and deploy the application.\n*   Use a CDN to cache static assets and improve delivery speed.\n\n#### 7.5. CI/CD Integration\n\n*   Use a continuous integration/continuous deployment (CI/CD) pipeline to automate the build, test, and deployment process.\n*   Use a CI/CD platform like GitHub Actions or GitLab CI.\n*   Automate code linting, formatting, and testing in the CI/CD pipeline.\n*   Automate deployment to different environments in the CI/CD pipeline.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "remix.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "remix",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "remix",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-requests",
    "description": "This rule file outlines best practices for using the Python requests library, covering performance, security, code organization, and testing.",
    "author": "sanjeed5",
    "tags": [
      "requests",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/requests.mdc",
    "content": "---\n\n# Requests Library Best Practices\n\nThis document provides comprehensive guidelines for using the Python `requests` library effectively. It covers various aspects, including code organization, common patterns, performance considerations, security best practices, testing approaches, common pitfalls, and tooling.\n\n## Library Information:\n\n- Name: requests\n- Tags: web, python, http-client\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices:\n\n*   **Simple Scripts:** For simple, single-file scripts, the structure is less critical. Keep related resources (e.g., configuration files, data files) in the same directory.\n*   **Larger Projects:** For larger projects:\n    \n    my_project/\n    ├── src/\n    │   ├── __init__.py\n    │   ├── api_client.py  # Contains requests-related functions\n    │   ├── models.py       # Data models for API responses\n    │   ├── utils.py        # Utility functions\n    │   └── config.py       # Configuration settings\n    ├── tests/\n    │   ├── __init__.py\n    │   ├── test_api_client.py\n    │   └── conftest.py      # pytest configuration\n    ├── README.md\n    ├── requirements.txt\n    └── .gitignore\n    \n    *   `src/`: Contains the main application code.\n    *   `api_client.py`:  Houses the `requests` calls, session management, and error handling.\n    *   `models.py`: Defines data classes/namedtuples to represent the structure of API responses, aiding type hinting and validation.\n    *   `tests/`: Contains unit and integration tests.\n    *   `requirements.txt`: Lists project dependencies.\n\n### 1.2 File Naming Conventions:\n\n*   Use descriptive names for files related to `requests`, such as `api_client.py`, `http_utils.py`, or `<service_name>_client.py`.\n*   Follow PEP 8 guidelines: lowercase with underscores (e.g., `get_data.py`).\n\n### 1.3 Module Organization Best Practices:\n\n*   **Grouping by Functionality:**  Organize code into modules based on functionality. For example, a module for authentication, another for data retrieval, and another for error handling.\n*   **Avoiding Circular Dependencies:**  Design modules to minimize dependencies between them and prevent circular imports.\n\n### 1.4 Component Architecture Recommendations:\n\n*   **Layered Architecture:** Use a layered architecture to separate concerns:\n    *   **Presentation Layer:** (If applicable) Handles user input and displays data.\n    *   **Business Logic Layer:** Orchestrates the application logic and uses the data access layer.\n    *   **Data Access Layer:**  Contains the `requests` calls and interacts with external APIs.  This layer should abstract away the details of the HTTP client.\n*   **Dependency Injection:** Use dependency injection to provide the `requests` session or client to components that need it, allowing for easier testing and configuration.\n\n### 1.5 Code Splitting Strategies:\n\n*   **By API Endpoint:** If your application interacts with multiple API endpoints, consider creating separate modules or classes for each endpoint to improve maintainability.\n*   **Functional Decomposition:**  Split complex tasks into smaller, manageable functions.  This promotes reusability and testability.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to `requests`:\n\n*   **Singleton (for Session):**  Use a singleton pattern to manage a single `requests.Session` instance, ensuring connection pooling is used effectively across the application.  Be mindful of potential thread-safety issues with singletons in multithreaded environments.\n*   **Adapter Pattern:** Create an adapter class around the `requests` library to abstract away the underlying HTTP client. This makes it easier to switch to a different library in the future or add custom logic.\n*   **Retry Pattern:** Implement retry logic with exponential backoff to handle transient network errors and API rate limits.\n\n### 2.2 Recommended Approaches for Common Tasks:\n\n*   **Fetching Data:** Use `requests.get()` for retrieving data. Handle potential errors using `response.raise_for_status()` and appropriate exception handling.\n*   **Sending Data:** Use `requests.post()`, `requests.put()`, or `requests.patch()` for sending data. Set the `Content-Type` header appropriately (e.g., `application/json`).\n*   **Authentication:** Utilize the `auth` parameter for authentication. Use appropriate authentication schemes such as HTTP Basic Auth, Bearer tokens, or OAuth.\n*   **File Uploads:**  Use the `files` parameter to upload files. Provide a dictionary where the keys are the field names and the values are file-like objects or tuples containing the filename and file-like object.\n\n### 2.3 Anti-patterns and Code Smells to Avoid:\n\n*   **Ignoring Errors:** Not handling exceptions raised by `requests` can lead to unexpected behavior and application crashes.\n*   **Hardcoding URLs:** Hardcoding URLs makes the code less flexible and harder to maintain. Store URLs in configuration files or environment variables.\n*   **Not Using Sessions:** Failing to use `requests.Session()` for multiple requests to the same host can result in performance degradation due to repeated connection setups.\n*   **Disabling SSL Verification Unnecessarily:** Disabling SSL verification (`verify=False`) should only be done when absolutely necessary and with caution, as it can expose the application to man-in-the-middle attacks.  Investigate the root cause of SSL verification failures instead of simply disabling it.\n*   **Excessive Retries without Backoff:** Retrying requests excessively without an exponential backoff strategy can overwhelm the server and worsen the situation.\n*   **Storing Sensitive Information in Code:** Avoid storing API keys, passwords, and other sensitive information directly in the code. Use environment variables or a secure configuration management system.\n*   **Not setting timeouts:** Not setting timeouts on requests can lead to your application hanging indefinitely if a server is unresponsive.\n\n### 2.4 State Management Best Practices:\n\n*   **Stateless API Clients:** Design API clients to be stateless whenever possible. Avoid storing request-specific data within the client object. Pass all necessary data as arguments to the request methods.\n*   **Session Management:** Use `requests.Session()` to maintain state (e.g., cookies, authentication) across multiple requests.\n\n### 2.5 Error Handling Patterns:\n\n*   **Catching Exceptions:** Catch `requests.exceptions.RequestException` and its subclasses (e.g., `requests.exceptions.HTTPError`, `requests.exceptions.ConnectionError`, `requests.exceptions.Timeout`) to handle different types of errors.\n*   **Using `raise_for_status()`:** Call `response.raise_for_status()` to raise an exception for HTTP error codes (4xx and 5xx).\n*   **Logging Errors:** Log detailed error messages, including the URL, status code, and response content, to aid in debugging.\n*   **Returning Meaningful Error Responses:** When creating your own APIs that use the `requests` library internally, return informative error responses to the client.\n*   **Retry Logic:** Implement retry logic for transient errors (e.g., network timeouts, temporary server errors) with exponential backoff.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques:\n\n*   **Using Sessions:** Utilize `requests.Session()` to reuse connections and reduce overhead.\n*   **Connection Pooling:** The `requests.Session()` object automatically handles connection pooling, which improves performance by reusing existing connections.\n*   **Streaming Responses:** For large responses, use `stream=True` to process data incrementally and avoid loading the entire response into memory at once.  Remember to close the response after processing.\n*   **Caching Responses:** Consider caching responses to reduce redundant API calls. Use libraries like `requests_cache` to store responses temporarily.\n*   **Using HTTP/2:** If the server supports HTTP/2, use the `HTTPX` library, which provides both synchronous and asynchronous support for HTTP/2.\n*   **Compression:** Ensure the server is using compression (e.g., gzip) and that the `Accept-Encoding` header is set appropriately in the request.\n\n### 3.2 Memory Management Considerations:\n\n*   **Streaming Large Responses:** Use `stream=True` to avoid loading the entire response into memory.\n*   **Closing Responses:** Close the response object after processing the data to release resources.  Use a `try...finally` block or a context manager to ensure the response is always closed.\n*   **Iterating over Chunks:** When streaming, iterate over the response content in chunks using `response.iter_content()` or `response.iter_lines()` to process data in smaller pieces.\n\n### 3.3 Bundle Size Optimization:\n\n*   **Minimize Dependencies:** Only include the dependencies that are strictly necessary.\n\n### 3.4 Lazy Loading Strategies:\n\n*   **Lazy Initialization of Clients:**  Initialize the `requests` session or client only when it is first needed, rather than at application startup. This can improve startup time if the API client is not immediately required.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them:\n\n*   **Man-in-the-Middle Attacks:** Always use HTTPS to encrypt communication and prevent eavesdropping. Verify SSL certificates unless absolutely necessary to disable verification.\n*   **Cross-Site Scripting (XSS):** If displaying data from API responses in a web application, sanitize the data to prevent XSS attacks.\n*   **Server-Side Request Forgery (SSRF):**  Avoid constructing URLs based on user input without proper validation. This can prevent attackers from making requests to internal resources.\n*   **Exposure of Sensitive Information:** Store API keys, passwords, and other sensitive information securely using environment variables or a secrets management system.\n*   **Denial of Service (DoS):**  Implement timeouts and rate limiting to prevent attackers from overwhelming the server with requests.\n\n### 4.2 Input Validation Best Practices:\n\n*   **Validating Input Data:** Validate all input data before sending it to the API. This can prevent injection attacks and other security vulnerabilities.\n*   **Sanitizing Input Data:** Sanitize input data to remove potentially malicious characters or code.\n*   **Using Prepared Statements:** When constructing database queries with data from API responses, use prepared statements to prevent SQL injection attacks.\n\n### 4.3 Authentication and Authorization Patterns:\n\n*   **Using Secure Authentication Schemes:** Use strong authentication schemes such as OAuth 2.0 or JWT (JSON Web Tokens) to protect API endpoints.\n*   **Storing Credentials Securely:** Store API keys, passwords, and other credentials securely using environment variables, a secrets management system, or a hardware security module (HSM).\n*   **Implementing Authorization:** Implement authorization to control which users or applications have access to specific API endpoints.\n*   **Using HTTPS:** Always use HTTPS to encrypt communication and protect credentials during transmission.\n\n### 4.4 Data Protection Strategies:\n\n*   **Encrypting Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Masking Sensitive Data:** Mask sensitive data in logs and error messages.\n*   **Complying with Data Privacy Regulations:** Ensure compliance with relevant data privacy regulations such as GDPR and CCPA.\n\n### 4.5 Secure API Communication:\n\n*   **HTTPS:** Always use HTTPS for all API communication.\n*   **TLS Versions:**  Ensure that the server and client support the latest TLS versions (TLS 1.2 or 1.3) and disable older, insecure versions (SSLv3, TLS 1.0, TLS 1.1).\n*   **Cipher Suites:**  Configure the server to use strong cipher suites that provide forward secrecy and authenticated encryption.\n*   **Certificate Pinning:**  Consider using certificate pinning to prevent man-in-the-middle attacks by verifying the server's SSL certificate against a known good certificate.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies:\n\n*   **Testing Individual Functions:** Write unit tests for individual functions that make `requests` calls.\n*   **Mocking `requests`:** Use mocking libraries like `unittest.mock` or `pytest-mock` to mock the `requests` library and isolate the code being tested.\n*   **Testing Error Handling:** Write unit tests to verify that the code handles different types of errors correctly.\n*   **Parametrizing Tests:** Use parametrization to test the same function with different inputs and expected outputs.\n*   **Test Data:**  Create a set of test data (e.g., JSON files) to simulate API responses.\n\n### 5.2 Integration Testing Approaches:\n\n*   **Testing API Client Integrations:** Write integration tests to verify that the API client integrates correctly with other components of the application.\n*   **Using a Test API Server:** Set up a test API server (e.g., using Flask or FastAPI) to simulate the real API and control the responses.\n*   **Verifying Data Integrity:** Verify that the data returned by the API is processed correctly and stored in the database or other data store.\n\n### 5.3 End-to-End Testing Recommendations:\n\n*   **Testing Complete Workflows:** Write end-to-end tests to verify that complete workflows involving the API client work correctly.\n*   **Using Automation Tools:** Use automation tools like Selenium or Playwright to automate end-to-end tests.\n\n### 5.4 Test Organization Best Practices:\n\n*   **Separating Tests:** Separate unit tests, integration tests, and end-to-end tests into different directories or files.\n*   **Using a Test Runner:** Use a test runner like pytest to discover and run tests automatically.\n*   **Following Test Naming Conventions:** Follow consistent test naming conventions to make it easier to understand the purpose of each test.\n\n### 5.5 Mocking and Stubbing Techniques:\n\n*   **Mocking the `requests` Library:** Use mocking to replace the `requests` library with a mock object that returns predefined responses.\n*   **Using Mock Objects:** Create mock objects to simulate the behavior of external APIs.\n*   **Stubbing Functions:** Use stubbing to replace functions with simplified versions that return predefined values.\n*   **Using Context Managers for Mocking:** Use context managers to temporarily replace objects with mock objects during tests.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make:\n\n*   **Not Handling Exceptions:** Ignoring exceptions raised by `requests` can lead to unexpected behavior and application crashes.\n*   **Not Using Sessions:** Failing to use `requests.Session()` for multiple requests to the same host can result in performance degradation.\n*   **Not Setting Timeouts:** Not setting timeouts on requests can lead to your application hanging indefinitely if a server is unresponsive.\n*   **Disabling SSL Verification Unnecessarily:** Disabling SSL verification (`verify=False`) should only be done when absolutely necessary and with caution.\n*   **Not Handling Rate Limits:** Not handling API rate limits can lead to the application being blocked by the API provider.\n*   **Incorrectly Handling Character Encoding:**  Failing to properly handle character encoding when dealing with non-ASCII characters in request or response bodies.\n\n### 6.2 Edge Cases to Be Aware Of:\n\n*   **Handling Redirects:**  Be aware of how `requests` handles redirects by default (following them).  If you need to control redirect behavior, use the `allow_redirects` parameter.\n*   **Dealing with Large Payloads:** When sending or receiving large payloads, use streaming to avoid memory issues.\n*   **Handling Keep-Alive Connections:** Be aware that `requests` uses keep-alive connections by default, which can lead to issues if the server closes the connection unexpectedly.\n*   **Proxy Configuration:** Properly configure proxies if your application needs to access the internet through a proxy server.\n\n### 6.3 Version-Specific Issues:\n\n*   **Changes in API:** Be aware of changes in the `requests` API between different versions.  Consult the release notes for each version to identify any breaking changes.\n*   **Dependency Conflicts:**  Be aware of potential dependency conflicts between `requests` and other libraries in your project.  Use a virtual environment to isolate dependencies.\n\n### 6.4 Compatibility Concerns:\n\n*   **Python Versions:** Ensure that the version of `requests` you are using is compatible with the version of Python you are using.\n*   **Operating Systems:** Be aware of potential compatibility issues between `requests` and different operating systems (e.g., Windows, Linux, macOS).\n\n### 6.5 Debugging Strategies:\n\n*   **Logging Requests and Responses:** Log detailed information about requests and responses, including URLs, headers, and bodies, to aid in debugging.\n*   **Using Debugging Tools:** Use debugging tools such as `pdb` or `ipdb` to step through the code and inspect variables.\n*   **Capturing Network Traffic:** Use network traffic analysis tools like Wireshark or tcpdump to capture and analyze network traffic.\n*   **Using `httpbin.org` for Testing:** Use the `httpbin.org` service to test different types of requests and responses.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools:\n\n*   **Virtual Environments:** Use virtual environments (e.g., `venv`, `virtualenv`) to isolate project dependencies.\n*   **pip:** Use `pip` to install and manage dependencies.\n*   **IDEs:** Use an IDE such as Visual Studio Code, PyCharm, or Sublime Text to write and debug code.\n*   **Debugging Tools:** Use debugging tools such as `pdb` or `ipdb` to step through the code and inspect variables.\n\n### 7.2 Build Configuration Best Practices:\n\n*   **Using `requirements.txt`:** Use a `requirements.txt` file to specify project dependencies.\n*   **Using `setup.py`:** Use a `setup.py` file to define the project metadata and package the code for distribution.\n*   **Using a Build System:** Consider using a build system such as Make or Poetry to automate the build process.\n\n### 7.3 Linting and Formatting Recommendations:\n\n*   **Using a Linter:** Use a linter such as `flake8` or `pylint` to identify potential code quality issues.\n*   **Using a Formatter:** Use a formatter such as `black` or `autopep8` to automatically format the code according to PEP 8 guidelines.\n*   **Configuring the IDE:** Configure the IDE to use the linter and formatter automatically.\n\n### 7.4 Deployment Best Practices:\n\n*   **Using a Production Environment:** Deploy the application to a production environment that is separate from the development environment.\n*   **Using a Process Manager:** Use a process manager such as Supervisor or systemd to manage the application process.\n*   **Using a Load Balancer:** Use a load balancer to distribute traffic across multiple instances of the application.\n*   **Monitoring the Application:** Monitor the application for errors and performance issues.\n\n### 7.5 CI/CD Integration Strategies:\n\n*   **Using a CI/CD System:** Use a CI/CD system such as Jenkins, GitLab CI, GitHub Actions, or CircleCI to automate the build, test, and deployment processes.\n*   **Running Tests Automatically:** Configure the CI/CD system to run tests automatically on every commit.\n*   **Deploying Automatically:** Configure the CI/CD system to deploy the application automatically to the production environment after the tests have passed.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "requests.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "requests",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "using",
      "python",
      "library",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "requests",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-rich",
    "description": "Comprehensive best practices and coding standards for the Rich library, focusing on code quality, performance, and maintainability within Python terminal applications.",
    "author": "sanjeed5",
    "tags": [
      "rich",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/rich.mdc",
    "content": "- **General Guidelines**\n  - Adhere to PEP 8 coding style guidelines for Python code, emphasizing readability and consistency.\n  - Limit lines to a maximum of 79 characters to enhance readability across different environments.\n  - Prioritize code clarity and simplicity, making it easy to understand and maintain.\n  - Use UTF-8 encoding for source files to ensure compatibility with a wide range of characters.\n\n- **Installation and Environment**\n  - Use `uv` for installing dependencies to improve speed and reliability, if appropriate.\n  - Specify Python 3.12 or later to leverage the latest language features and performance improvements.  (If applicable for the specific features of rich you are using)\n\n- **Code Organization and Structure**\n\n  - **Directory Structure:** Follow a logical directory structure.\n    \n    project_root/\n    ├── src/\n    │   ├── main.py        # Entry point of the application\n    │   ├── utils/\n    │   │   ├── __init__.py\n    │   │   ├── helper_functions.py\n    │   ├── modules/\n    │   │   ├── __init__.py\n    │   │   ├── module_a.py  # Rich-related components\n    │   │   ├── module_b.py\n    ├── tests/\n    │   ├── __init__.py\n    │   ├── test_main.py\n    │   ├── test_module_a.py\n    ├── README.md\n    ├── pyproject.toml  # Or requirements.txt\n    \n  - **File Naming:** Use descriptive lowercase names with underscores (e.g., `console_output.py`).\n  - **Module Organization:** Group related functionalities into separate modules (e.g., `rich_display.py`, `data_formatting.py`).\n  - **Component Architecture:** Design modular components with clear interfaces for reusability and maintainability.\n  - **Code Splitting:**  Break down large files into smaller, more manageable pieces based on functionality. Consider lazy loading of less-frequently used modules.\n\n- **Coding Style and Best Practices**\n\n  - **Indentation:** Use 4 spaces for indentation.\n  - **Blank Lines:** Separate top-level functions and classes with two blank lines, and methods within a class with one blank line.\n  - **Imports:**\n    - Group imports in the following order:\n      1. Standard library imports\n      2. Third-party library imports (including Rich)\n      3. Local application imports\n    - Use absolute imports for clarity, unless relative imports significantly improve readability within a package.\n    - Avoid wildcard imports (`from module import *`).\n  - **Naming Conventions:**\n    - Use lowercase with underscores for function and variable names (`my_variable`, `my_function`).\n    - Use CapWords for class names (`MyClass`).\n    - Use UPPER_CASE_WITH_UNDERSCORES for constants (`MAX_VALUE`).\n  - **String Quotes:** Use double quotes consistently for strings, especially for docstrings.\n\n- **Rich Library Specific Best Practices**\n\n  - **Console Instantiation:** Create a single `Console` instance for your application and reuse it throughout.\n    python\n    from rich.console import Console\n\n    console = Console()\n\n    def my_function():\n        console.print(\"Hello, [bold red]World![/bold red]\")\n    \n  - **Styling:** Use Rich's markup system for styling text.  Refer to the Rich documentation for available styles and their usage.\n    python\n    console.print(\"[link=https://example.com]Click here[/link] to visit example.com\")\n    \n  - **Tables:** Utilize the `Table` class for structured data display.  Configure columns and rows appropriately.\n    python\n    from rich.table import Table\n\n    table = Table(title=\"My Data\")\n    table.add_column(\"Name\", style=\"cyan\", no_wrap=True)\n    table.add_column(\"Age\", style=\"magenta\")\n    table.add_row(\"Alice\", \"30\")\n    table.add_row(\"Bob\", \"25\")\n    console.print(table)\n    \n  - **Progress Bars:** Employ the `Progress` class for tracking long-running tasks.  Configure the progress bar to accurately reflect the task's progress.\n    python\n    from rich.progress import Progress\n    import time\n\n    with Progress() as progress:\n        task1 = progress.add_task(\"[red]Downloading...\", total=1000)\n        task2 = progress.add_task(\"[green]Processing...\", total=100)\n\n        while not progress.finished:\n            progress.update(task1, advance=0.5)\n            progress.update(task2, advance=0.1)\n            time.sleep(0.01) #Simulate some work\n    \n  - **Inspect:** Use `console.inspect()` for debugging and understanding objects.  This is invaluable for exploring Rich's own classes and objects, or any object in your application.\n    python\n    from rich.panel import Panel\n\n    panel = Panel(\"Hello, World!\")\n    console.inspect(panel, methods=True)\n    \n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**  Employ appropriate design patterns such as Factory Pattern for creating Rich objects or Strategy Pattern for different output styles.\n  - **Recommended Approaches:**  Use Rich's features for displaying data structures (lists, dictionaries) in a human-readable format.\n  - **Anti-patterns:**  Avoid directly printing to the console using `print()` when you should be using `console.print()` to take advantage of Rich's features. Avoid excessive nesting of Rich markup, which can reduce readability.\n  - **State Management:** Manage the state of Rich components appropriately, especially when creating dynamic displays.  Avoid mutating objects directly without updating the console output.\n  - **Error Handling:** Handle exceptions gracefully and use Rich's features to display error messages to the user in a clear and informative way.\n    python\n    try:\n        result = 1 / 0\n    except Exception as e:\n        console.print_exception(show_locals=True)\n    \n\n- **Performance Considerations**\n  - **Optimization Techniques:** Use Rich's built-in caching mechanisms to avoid re-rendering the same content repeatedly.  Minimize the use of computationally expensive Rich features when performance is critical.\n  - **Memory Management:** Be mindful of memory usage when displaying large amounts of data with Rich. Consider using generators or iterators to process data in chunks.\n  - **Rendering Optimization:** If applicable, profile your Rich-based application to identify rendering bottlenecks. Optimize the rendering of complex Rich elements by simplifying the markup or reducing the number of elements.\n  - **Bundle Size Optimization:** Not directly applicable since rich is primarily server-side for terminal apps but for web integrated terminals, ensure only necessary Rich dependencies are bundled.\n  - **Lazy Loading:** Not directly applicable, but relevant for other parts of your application that might interact with Rich.\n\n- **Security Best Practices**\n  - **Vulnerabilities:** Be aware of potential vulnerabilities related to untrusted input. Sanitize any user-provided text before displaying it with Rich to prevent markup injection attacks.\n  - **Input Validation:** Validate any input before using it in Rich's markup to prevent unexpected behavior or security issues.\n  - **Authentication and Authorization:** Not directly applicable to Rich, but ensure proper authentication and authorization mechanisms are in place for any data displayed by Rich.\n  - **Data Protection:** Protect sensitive data by masking or redacting it before displaying it with Rich.  Utilize Rich's styling options to emphasize sensitive data that requires special attention.\n\n- **Testing Approaches**\n  - **Unit Testing:** Write unit tests for individual Rich components to ensure they function correctly.  Mock the `Console` object to isolate the component under test.\n  - **Integration Testing:** Test the integration of Rich components with other parts of your application to ensure they work together seamlessly.\n  - **End-to-end Testing:** Verify the overall behavior of your Rich-based application by simulating user interactions and validating the output displayed on the console.\n  - **Test Organization:** Organize your tests into logical modules that correspond to the structure of your application.\n  - **Mocking and Stubbing:** Use mocking and stubbing techniques to isolate components and simulate dependencies during testing.  The `unittest.mock` module provides tools for creating mock objects.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:** Forgetting to import the `Console` class or using `print()` instead of `console.print()`.  Overcomplicating Rich markup, leading to unreadable code.\n  - **Edge Cases:** Handling Unicode characters correctly.  Dealing with terminals that have limited color support. Handling very large data sets, which can cause memory issues or performance problems.\n  - **Version-Specific Issues:** Being aware of breaking changes or new features in different versions of Rich. Consult the Rich changelog for details.\n  - **Compatibility Concerns:** Ensuring compatibility between Rich and other terminal libraries or frameworks you are using.\n  - **Debugging:** Using `console.inspect()` to explore objects and identify issues.  Setting breakpoints and stepping through the code to understand the flow of execution.\n\n- **Tooling and Environment**\n  - **Recommended Tools:** VS Code with the Python extension, PyCharm, or any other IDE that supports Python development. Consider using a Rich-specific plugin if available.\n  - **Build Configuration:** Use `pyproject.toml` (preferred) or `requirements.txt` to manage project dependencies, including Rich.\n  - **Linting and Formatting:** Use Pylint, Flake8, and Black to enforce code style guidelines and catch potential errors.\n  - **Deployment:** Ensure the target environment has Python and Rich installed. Consider using a virtual environment to isolate dependencies.\n  - **CI/CD Integration:** Integrate Rich-based applications into your CI/CD pipeline to automate testing and deployment.  Use tools like Jenkins, GitLab CI, or GitHub Actions.\n\n- **Additional Notes**\n  - Consult the official Rich documentation (https://rich.readthedocs.io) for the most up-to-date information and examples.\n  - Explore Rich's examples and demonstrations to learn more about its capabilities.\n  - Contribute to the Rich community by reporting bugs, suggesting features, or submitting pull requests.\n\n- **References**\n  - PEP 8: Style Guide for Python Code (https://peps.python.org/pep-0008/)\n  - Rich Documentation: (https://rich.readthedocs.io)",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "rich.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "rich",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "library",
      "focusing",
      "code",
      "quality",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "rich",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-riverpod",
    "description": "Enforces Riverpod library best practices for Flutter applications.  This rule provides guidance on code organization, performance, testing, and common pitfalls when using Riverpod.",
    "author": "sanjeed5",
    "tags": [
      "riverpod",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/riverpod.mdc",
    "content": "- **Core Principles:**\n  - **Provider Initialization:**  Avoid initializing providers within widgets. Providers should initialize themselves, managing their own state and dependencies independently.  This ensures proper lifecycle management and prevents unexpected behavior during widget rebuilds.  Specifically, do not initialize providers inside `build()` methods or widget constructors.\n  - **Provider Usage:** Primarily use `Provider` as the foundation for your state management.  Avoid legacy solutions like `ChangeNotifierProvider`, `StateNotifierProvider`, and `StateProvider` unless there are compelling reasons to use them, such as compatibility with existing code.  Prefer `StateProvider` or `NotifierProvider` (or `AsyncNotifierProvider`) for mutable state.\n  - **Immutability:** Strive for immutability in your state management where possible.  Immutable data structures simplify debugging and prevent unexpected side effects. Use `freezed` or similar libraries to help enforce immutability.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:**  Adopt a feature-based directory structure.  Group related files (providers, widgets, models, services) into dedicated directories representing specific features or modules. For example:\n\n    \n    lib/\n    ├── features/\n    │   ├── authentication/\n    │   │   ├── data/\n    │   │   │   ├── auth_repository.dart\n    │   │   │   └── models/\n    │   │   │       └── user.dart\n    │   │   ├── presentation/\n    │   │   │   ├── login_screen.dart\n    │   │   │   ├── login_controller.dart\n    │   │   │   └── providers.dart\n    │   ├── home/\n    │   │   ├── data/\n    │   │   ├── presentation/\n    │   │   └── providers.dart\n    ├── core/\n    │   ├── providers.dart  # Global providers\n    │   └── services/\n    │       └── api_service.dart\n    └── main.dart\n    \n  - **File Naming Conventions:**  Use descriptive and consistent file names. For example:\n    - `feature_name_screen.dart` (for widgets/screens)\n    - `feature_name_service.dart` (for services)\n    - `feature_name_repository.dart` (for repositories)\n    - `feature_name_provider.dart` (for provider definitions)\n  - **Module Organization:**  Break down your application into loosely coupled modules.  Each module should have a clear responsibility and a well-defined interface.  Use dependency injection to manage dependencies between modules, leveraging Riverpod's provider system.\n  - **Component Architecture:** Design your UI with reusable components.  Extract common UI elements into separate widgets to promote code reuse and maintainability. Favor composition over inheritance.\n  - **Code Splitting Strategies:**  Implement code splitting to reduce the initial load time of your application.  Use Flutter's lazy loading capabilities and consider splitting your application into smaller modules that can be loaded on demand.  Leverage `flutter_modular` or similar packages for advanced module management.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Repository Pattern:**  Abstract data access logic behind repositories.  Repositories handle data retrieval and persistence, isolating the rest of the application from the specifics of data sources (e.g., local storage, API).\n    - **Service Pattern:**  Encapsulate business logic into services.  Services perform specific tasks or operations, such as authentication, data processing, or API integration.  Providers can depend on services to provide data or perform actions.\n    - **Provider as State Holder:** Utilize Riverpod's providers to hold and manage application state.  Choose the appropriate provider type based on the state's characteristics (e.g., `StateProvider` for simple mutable state, `NotifierProvider` for complex state with side effects, `FutureProvider` or `StreamProvider` for asynchronous data).\n  - **Recommended Approaches:**\n    - **Asynchronous Data Handling:**  Use `FutureProvider` and `StreamProvider` to handle asynchronous data.  Display loading indicators while data is being fetched and handle errors gracefully.\n    - **State Updates:** Use `state = newState` for `StateProvider` and `NotifierProvider`. Use `AsyncValue` to represent the different states of an asynchronous operation (loading, data, error).  Use `.when()` to handle different states in your UI.\n    - **Side Effects:** Isolate side effects (e.g., API calls, database updates) in dedicated services or repositories.  Avoid performing side effects directly within widgets or providers.\n  - **Anti-patterns and Code Smells:**\n    - **Over-reliance on `ChangeNotifier`:** In most cases, `StateProvider` or `NotifierProvider` offer more straightforward and type-safe solutions than `ChangeNotifier`.\n    - **Initializing Providers in Widgets:** This leads to provider recreation on every widget rebuild, impacting performance and potentially causing unexpected behavior.\n    - **Directly Mutating State:**  Avoid directly mutating state managed by providers.  Instead, use the `state` setter for `StateProvider` or update the state within the `build` method of a `Notifier` / `AsyncNotifier`.\n    - **Complex Logic in Widgets:**  Keep widgets focused on UI rendering. Move complex logic to services, repositories, or providers.\n  - **State Management Best Practices:**\n    - **Single Source of Truth:** Ensure that each piece of state has a single, authoritative source. Avoid duplicating state across multiple providers or widgets.\n    - **Scoped Providers:** Use `providerScope` to scope providers to specific parts of the widget tree, avoiding unnecessary rebuilds. This also helps to manage the lifecycle of providers and prevent memory leaks.\n  - **Error Handling Patterns:**\n    - **Use `AsyncValue`'s `.when`:**  Handle different states of asynchronous operations, using `AsyncValue.when` to display loading indicators, data, and error messages.\n    - **Global Error Handling:** Implement a global error handling mechanism to catch and log unexpected errors.  Consider using a `ProviderListener` to listen for errors and display appropriate error messages.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - **`select`:** Use `.select` to only rebuild widgets when specific parts of a provider's state change.  This can significantly reduce unnecessary rebuilds.\n    - **`Consumer` Widget:** Use `Consumer` widgets to rebuild only the parts of the widget tree that depend on a specific provider.\n    - **`useProvider` Hook:**  Use the `useProvider` hook in functional components to access provider values efficiently.\n  - **Memory Management:**\n    - **Dispose Providers:** Ensure that providers are properly disposed of when they are no longer needed.  Use `ScopedProvider` to automatically dispose of providers when their scope is destroyed.\n    - **Avoid Memory Leaks:**  Be mindful of potential memory leaks, especially when using streams or listeners.  Cancel subscriptions and dispose of resources when they are no longer needed.\n  - **Rendering Optimization:**\n    - **Minimize Widget Rebuilds:**  Use techniques like `const` constructors, `shouldRepaint`, and `useMemoized` to minimize unnecessary widget rebuilds.\n    - **Optimize Image Loading:**  Use cached network images and optimize image sizes to improve rendering performance.\n  - **Bundle Size Optimization:**\n    - **Tree Shaking:**  Enable tree shaking to remove unused code from your application's bundle.  Use `flutter build apk --split-debug-info` for Android.\n    - **Code Splitting:** Implement code splitting to reduce the initial load time of your application.\n  - **Lazy Loading Strategies:** Load resources on demand to improve startup time and reduce memory consumption. Use `FutureProvider` and `StreamProvider` to load data lazily.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - **Data Injection:**  Sanitize user input to prevent data injection attacks.\n    - **Authentication Bypass:**  Implement robust authentication and authorization mechanisms to prevent unauthorized access.\n    - **Insecure Data Storage:**  Protect sensitive data by encrypting it and storing it securely.\n  - **Input Validation:**\n    - **Validate User Input:**  Validate all user input on both the client-side and the server-side to prevent invalid data from being processed.\n    - **Use Strong Data Types:**  Use strong data types to enforce data integrity and prevent type-related errors.\n  - **Authentication and Authorization Patterns:**\n    - **Secure Authentication:**  Use secure authentication protocols like OAuth 2.0 or JWT to authenticate users.\n    - **Role-Based Authorization:**  Implement role-based authorization to control access to resources based on user roles.\n  - **Data Protection Strategies:**\n    - **Encryption:**  Encrypt sensitive data both in transit and at rest.\n    - **Data Masking:**  Mask sensitive data in logs and error messages.\n  - **Secure API Communication:**\n    - **HTTPS:**  Use HTTPS to encrypt communication between the client and the server.\n    - **API Keys:**  Protect API keys and store them securely.\n\n- **Testing Approaches:**\n  - **Unit Testing Strategies:**\n    - **Test Provider Logic:**  Write unit tests to verify the logic within your providers.\n    - **Mock Dependencies:**  Use mocking frameworks like `mockito` to isolate your providers from external dependencies.\n  - **Integration Testing:**\n    - **Test Provider Interactions:**  Write integration tests to verify how providers interact with each other and with other parts of the application.\n    - **Test Data Flow:**  Test the data flow through the application to ensure that data is being processed correctly.\n  - **End-to-End Testing:**\n    - **Test User Flows:**  Write end-to-end tests to simulate user interactions and verify that the application behaves as expected.\n    - **Automated UI Tests:**  Use tools like `flutter_driver` or `patrol` to automate UI tests.\n  - **Test Organization:**\n    - **Organize Tests by Feature:**  Organize your tests into directories that correspond to the features they test.\n    - **Use Descriptive Test Names:**  Use descriptive test names that clearly explain what each test is verifying.\n  - **Mocking and Stubbing:**\n    - **Use Mocking Frameworks:** Use mocking frameworks like `mockito` to create mock objects for testing purposes.\n    - **Create Test Doubles:** Create test doubles to replace real dependencies with simplified versions that are easier to test.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - **Forgetting to dispose of providers:**  Leads to memory leaks.\n    - **Incorrect provider scope:**  Leads to unexpected widget rebuilds.\n    - **Not handling asynchronous errors:** Leads to unhandled exceptions.\n  - **Edge Cases:**\n    - **Provider lifecycle management:** Understand when providers are created and disposed of.\n    - **Concurrency issues:**  Be aware of potential concurrency issues when working with asynchronous data.\n  - **Version-Specific Issues:**\n    - **Breaking changes:**  Be aware of breaking changes in new versions of Riverpod.\n    - **Deprecated features:**  Avoid using deprecated features.\n  - **Compatibility Concerns:**\n    - **Flutter version compatibility:**  Ensure that your version of Riverpod is compatible with your version of Flutter.\n    - **Package dependencies:** Resolve version conflicts between Riverpod and other packages.\n  - **Debugging Strategies:**\n    - **Use the Riverpod DevTools:**  Use the Riverpod DevTools to inspect provider state and dependencies.\n    - **Logging:** Add logging statements to your providers to track their behavior.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:**\n    - **VS Code or IntelliJ IDEA:** Use a powerful IDE with Flutter and Dart support.\n    - **Riverpod DevTools:**  Install the Riverpod DevTools extension for your IDE to inspect provider state and dependencies.\n  - **Build Configuration:**\n    - **Use `flutter build`:**  Use the `flutter build` command to build your application.\n    - **Configure Build Flavors:**  Use build flavors to create different versions of your application for different environments (e.g., development, staging, production).\n  - **Linting and Formatting:**\n    - **Use `flutter analyze`:**  Use the `flutter analyze` command to analyze your code for potential problems.\n    - **Use `dart format`:**  Use the `dart format` command to format your code according to the Dart style guide.\n    - **Configure your linter**: Configure your linter to enforce Riverpod best practices.\n  - **Deployment Best Practices:**\n    - **Use CI/CD:** Use CI/CD pipelines to automate the build, test, and deployment process.\n    - **Configure your environments**: Configure your different environments (development, staging, production) and their secrets properly. Using `flutter_dotenv` or similar.\n  - **CI/CD Integration:**\n    - **Integrate with GitHub Actions or GitLab CI:**  Integrate your CI/CD pipeline with GitHub Actions or GitLab CI.\n    - **Automate Testing and Deployment:**  Automate the testing and deployment process to ensure that your application is always up-to-date.",
    "metadata": {
      "globs": "*.dart",
      "format": "mdc",
      "originalFile": "riverpod.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "riverpod",
      "enforces",
      "library",
      "best",
      "practices",
      "flutter",
      "applications",
      "this",
      "rule",
      "provides",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "riverpod",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-rocket",
    "description": "Comprehensive guidelines for developing robust and maintainable web applications with the Rocket web framework, covering code organization, security, performance, testing, and more.",
    "author": "sanjeed5",
    "tags": [
      "rocket",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/rocket.mdc",
    "content": "- **Code Organization and Structure:**\n  - **Directory Structure:** Organize your project with a clear and maintainable directory structure. A common pattern is:\n    - `src/`: Contains the main source code.\n      - `main.rs`: Entry point of the application.\n      - `lib.rs`:  Defines library components.\n      - `routes/`: Contains route handlers.\n        - `mod.rs`:  Defines and exports route modules.\n        - `resource_name.rs`: Individual route files.\n      - `models/`: Defines data structures and database interactions.\n        - `mod.rs`: Defines and exports model modules.\n        - `data_model.rs`: Individual model definitions.\n      - `utils/`: Utility functions and modules.\n        - `mod.rs`: Defines and exports utility modules.\n        - `helper_functions.rs`: Individual utility function files.\n      - `config/`: Configuration files and settings.\n    - `static/`: Static assets like CSS, JavaScript, and images.\n    - `templates/`:  Templates for rendering dynamic content (using templating engines like Handlebars or Tera).\n    - `tests/`: Unit and integration tests.\n    - `migrations/`: Database migrations (if applicable).\n  - **File Naming Conventions:** Use descriptive and consistent file names.  Follow Rust's conventions, such as `snake_case` for file and module names.  For example, `user_routes.rs`, `database_connection.rs`.\n  - **Module Organization:** Break down your code into logical modules.  Use `mod.rs` files to define and re-export modules within a directory.\n  - **Component Architecture:** Design your application using a component-based architecture. This promotes reusability and maintainability.  Consider using traits to define interfaces between components.\n  - **Code Splitting Strategies:**  For larger applications, split your code into smaller, manageable crates to improve compilation times and code organization.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Repository Pattern:** Abstract data access logic behind a repository interface.\n    - **Service Layer Pattern:** Decouple route handlers from business logic using a service layer.\n    - **State Pattern:**  Manage complex state transitions within route handlers or components.\n  - **Recommended Approaches for Common Tasks:**\n    - **Database Interactions:** Use an ORM like Diesel or SeaORM to interact with databases.  Use connection pooling to efficiently manage database connections.\n    - **Authentication and Authorization:** Implement authentication using JWT (JSON Web Tokens) or sessions. Use role-based access control (RBAC) for authorization.\n    - **Input Validation:**  Thoroughly validate user input to prevent security vulnerabilities and data corruption.\n  - **Anti-patterns and Code Smells:**\n    - **Global Variables:** Avoid using global variables, as they can lead to unexpected side effects and make code harder to reason about. Use dependency injection instead.\n    - **Tight Coupling:** Minimize dependencies between components.  Use interfaces and abstractions to decouple components.\n    - **Long Functions:** Break down long functions into smaller, more manageable functions.\n  - **State Management:** Use Rocket's managed state feature (`#[rocket::State]`) to manage application-level state.\n  - **Error Handling:** Use Rust's `Result` type for error handling.  Provide informative error messages to the user.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - **Asynchronous Programming:** Use asynchronous programming (`async/await`) to handle concurrent requests efficiently.\n    - **Caching:**  Implement caching to reduce database load and improve response times.\n    - **Connection Pooling:**  Use connection pooling to reuse database connections.\n  - **Memory Management:** Be mindful of memory allocation and deallocation. Use Rust's ownership and borrowing system to prevent memory leaks and data races.\n  - **Rendering Optimization:**  Optimize your templates to reduce rendering time.  Use template caching.\n  - **Bundle Size Optimization:** Minimize the size of your application's binary. Use release mode compilation (`cargo build --release`). Strip debug symbols.\n  - **Lazy Loading Strategies:**  Load resources on demand to improve initial page load time.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM.\n    - **Cross-Site Scripting (XSS):**  Sanitize user input to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):**  Implement CSRF protection using tokens.\n  - **Input Validation:**  Validate all user input on both the client-side and server-side.\n  - **Authentication and Authorization:**\n    - Use strong password hashing algorithms (e.g., bcrypt or Argon2).\n    - Implement two-factor authentication (2FA).\n    - Use role-based access control (RBAC) to restrict access to resources.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between the client and server.\n    - Store passwords securely using a strong hashing algorithm.\n  - **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement rate limiting to prevent abuse.\n    - Use API keys or JWT for authentication.\n\n- **Testing Approaches:**\n  - **Unit Testing:** Write unit tests to verify the functionality of individual functions and modules.  Use the `#[cfg(test)]` attribute to define test modules.\n  - **Integration Testing:** Write integration tests to verify the interaction between different parts of your application.  Test routes and database interactions.\n  - **End-to-End Testing:**  Write end-to-end tests to verify the complete functionality of your application.  Use a testing framework like Selenium or Cypress.\n  - **Test Organization:**  Organize your tests in a clear and maintainable way. Create separate test modules for each component or module.\n  - **Mocking and Stubbing:**  Use mocking and stubbing to isolate units of code during testing.  Use a mocking framework like Mockall.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - **Forgetting to handle errors:** Always handle errors properly using `Result` and provide informative error messages.\n    - **Not validating user input:** Always validate user input to prevent security vulnerabilities.\n    - **Using global state:** Avoid using global state, as it can lead to unexpected side effects.\n  - **Edge Cases:**\n    - **Handling concurrent requests:**  Use asynchronous programming to handle concurrent requests efficiently.\n    - **Dealing with large files:** Use streaming to process large files without loading them into memory.\n    - **Handling database connection errors:**  Implement retry logic to handle database connection errors.\n  - **Version-Specific Issues:**  Be aware of version-specific issues and compatibility concerns.  Consult the Rocket documentation and release notes.\n  - **Compatibility Concerns:**  Ensure that your application is compatible with the target platform and browser versions.\n  - **Debugging Strategies:**\n    - Use the `println!` macro for debugging.\n    - Use a debugger like GDB or LLDB.\n    - Use logging to track the execution of your application.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:**\n    - **Rust toolchain:** Install the Rust toolchain using `rustup`.\n    - **IDE:** Use an IDE like Visual Studio Code with the Rust Analyzer extension.\n    - **Database client:** Use a database client like DBeaver or pgAdmin.\n  - **Build Configuration:** Configure your build using `Cargo.toml`.  Specify dependencies, build scripts, and other build settings.\n  - **Linting and Formatting:**\n    - Use `rustfmt` for code formatting.\n    - Use `clippy` for linting.\n    - Configure your IDE to automatically format and lint your code.\n  - **Deployment Best Practices:**\n    - Use a process manager like systemd or PM2 to manage your application.\n    - Use a reverse proxy like Nginx or Apache to handle incoming requests.\n    - Use a load balancer to distribute traffic across multiple instances of your application.\n  - **CI/CD Integration:**\n    - Use a CI/CD platform like GitHub Actions or GitLab CI to automate your build, test, and deployment process.\n    - Write tests to ensure that your application is working correctly before deploying.",
    "metadata": {
      "globs": "*.rs",
      "format": "mdc",
      "originalFile": "rocket.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "rocket",
      "comprehensive",
      "guidelines",
      "developing",
      "robust",
      "maintainable",
      "applications",
      "with",
      "framework",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "rocket",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-ros",
    "description": "This rule provides comprehensive best practices and coding standards for ROS (Robot Operating System) development, covering code organization, common patterns, performance, security, testing, and tooling. It aims to enhance code quality, maintainability, and interoperability in ROS projects.",
    "author": "sanjeed5",
    "tags": [
      "ros",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ros.mdc",
    "content": "# ROS Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing robust, maintainable, and interoperable ROS (Robot Operating System) code. It covers various aspects of ROS development, from code organization to security considerations, based on community best practices and official guidelines.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nA standard ROS package directory structure helps maintainability and discoverability. Here's a recommended structure:\n\n\nmy_package/\n├── CMakeLists.txt          # CMake build file\n├── package.xml             # Package manifest\n├── include/                # Header files (C++)\n│   └── my_package/\n│       └── my_node.h\n├── src/                    # Source code (C++ and Python)\n│   ├── my_node.cpp\n│   └── my_python_node.py\n├── scripts/                # Executable scripts (e.g., Python)\n│   └── my_script.py\n├── msg/                    # Message definitions (.msg files)\n│   └── MyMessage.msg\n├── srv/                    # Service definitions (.srv files)\n│   └── MyService.srv\n├── action/                 # Action definitions (.action files)\n│   └── MyAction.action\n├── launch/                 # Launch files (.launch or .launch.py)\n│   └── my_launch.launch.py\n├── config/                 # Configuration files (YAML)\n│   └── my_config.yaml\n├── urdf/                   # URDF files for robot models (.urdf or .xacro)\n│   └── my_robot.urdf.xacro\n├── rviz/                   # RViz configuration files (.rviz)\n│   └── my_rviz_config.rviz\n├── test/                    # Test files\n│   ├── my_node_test.cpp\n│   └── my_python_node_test.py\n└── doc/                     # Documentation\n    └── README.md\n\n\n### 1.2 File Naming Conventions\n\n-   **Packages:** Use underscore-separated lowercase names (e.g., `my_package`).\n-   **Source Files:** Use underscore-separated lowercase names with `.cpp` or `.py` extension (e.g., `my_node.cpp`, `my_python_node.py`).\n-   **Header Files:** Use underscore-separated lowercase names with `.h` extension, typically matching the class name (e.g., `my_class.h`).\n-   **Message/Service/Action Definitions:** Use CamelCase for names (e.g., `MyMessage.msg`, `MyService.srv`, `MyAction.action`).\n-   **Launch Files:** Use underscore-separated lowercase names with `.launch.py` or `.launch` extension (e.g., `my_launch.launch.py`).\n-   **Configuration Files:** Use underscore-separated lowercase names with `.yaml` extension (e.g., `my_config.yaml`).\n\n### 1.3 Module Organization\n\n-   **Logical Grouping:** Group related functionalities into separate modules or classes.\n-   **Namespaces (C++):** Use namespaces to avoid naming conflicts and organize code (e.g., `namespace my_package`).\n-   **Python Modules:** Organize code into Python modules within the `src` directory.\n\n### 1.4 Component Architecture\n\n-   **Node Design:** Design nodes to be modular and focused on specific tasks. Avoid monolithic nodes.\n-   **Communication:** Use ROS topics, services, and actions appropriately for communication between nodes. Consider using ROS 2 actions over services when a task could take a long time to perform. Using actionlib, nodes can execute goals asynchronously, provide feedback, and be cancelled.\n-   **Composition:** Use ROS 2 component composition to combine multiple nodes into a single process for improved performance.\n\n### 1.5 Code Splitting\n\n-   **Libraries:** Extract reusable code into libraries within the package (e.g., in a `lib` subdirectory).\n-   **Configuration Files:** Use configuration files (YAML) to parameterize node behavior without modifying code.\n-   **Launch Files:** Separate node execution and configuration into launch files for easy deployment and modification.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n-   **Publisher-Subscriber:** Use topics for asynchronous, one-to-many communication.\n-   **Request-Reply:** Use services for synchronous, one-to-one communication requiring a response.\n-   **Actionlib:** Use actions for long-running tasks with feedback and cancellation capabilities.\n-   **State Machine:** Implement state machines for complex node behavior.\n-   **Parameterization:** Externalize configurable parameters to YAML files loaded at runtime.\n-   **Lifecycle Management:** Implement node lifecycle management for controlled startup and shutdown (ROS 2).\n-   **Sensor Drivers:** Create dedicated nodes that abstract the hardware and provide a unified interface to the sensor.  This also provides a single point of failure and restart for sensor data.\n\n### 2.2 Recommended Approaches\n\n-   **Configuration:** Prefer using ROS parameters and dynamic reconfigure for node configuration.\n-   **Logging:** Use `ROS_INFO`, `ROS_WARN`, `ROS_ERROR`, and `ROS_DEBUG` macros (C++) or `rospy.loginfo`, `rospy.logwarn`, `rospy.logerr`, and `rospy.logdebug` (Python) for logging messages.\n-   **Error Handling:** Use exceptions (C++) or handle errors gracefully in Python with `try...except` blocks.\n-   **Time Handling:** Use `ros::Time::now()` (C++) or `rospy.Time.now()` (Python) for getting the current ROS time.\n-   **Transformations:** Use the `tf2` library for managing coordinate transformations.\n-   **Unit Testing:** Create comprehensive unit tests for individual components.\n\n### 2.3 Anti-patterns and Code Smells\n\n-   **God Nodes:** Avoid creating nodes that perform too many unrelated tasks.\n-   **Hardcoded Values:** Avoid hardcoding values in the code; use parameters instead.\n-   **Spinning Too Much:** Avoid busy-waiting loops; use `ros::Rate` or `rospy.Rate` to control loop frequency.\n-   **Ignoring Errors:** Handle potential errors and exceptions properly.\n-   **Global Variables:** Avoid using global variables; use class members or local variables instead.\n-   **Magic Numbers:** Define constants for important values instead of using magic numbers.\n\n### 2.4 State Management\n\n-   **Internal State:** Encapsulate node state within class members or local variables.\n-   **External State:** Use ROS parameters to store and manage persistent state.\n-   **State Machines:** Employ state machines for complex state transitions and behavior.\n\n### 2.5 Error Handling\n\n-   **Exceptions (C++):** Use exceptions to signal errors and handle them appropriately.\n-   **Try...Except (Python):** Use `try...except` blocks to catch and handle exceptions.\n-   **Return Codes:** In cases where exceptions are not appropriate, use return codes to indicate success or failure.\n-   **Logging:** Log error messages using `ROS_ERROR` or `rospy.logerr`.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Minimize Data Copying:** Use references or pointers to avoid unnecessary data copying.\n-   **Efficient Data Structures:** Use appropriate data structures (e.g., `std::vector`, `std::map`) for efficient data storage and retrieval.\n-   **Pre-allocation:** Pre-allocate memory for frequently used data structures.\n-   **Node Composition (ROS 2):** Compose multiple nodes into a single process for improved inter-node communication.\n-   **ZeroMQ (ROS 2):** Use the ZeroMQ transport for low-latency communication.\n\n### 3.2 Memory Management\n\n-   **Smart Pointers (C++):** Use smart pointers (`std::shared_ptr`, `std::unique_ptr`) to manage memory automatically and prevent memory leaks.\n-   **Resource Acquisition Is Initialization (RAII):** Use RAII to ensure that resources are released when they are no longer needed.\n-   **Memory Pools:** Use memory pools for allocating and deallocating memory efficiently.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n-   **Minimize Polygons:** Use fewer polygons in 3D models.\n-   **Texture Optimization:** Optimize textures for size and resolution.\n-   **Culling:** Implement view frustum culling to avoid rendering objects that are not visible.\n\n### 3.4 Bundle Size Optimization\n\n-   **Minimal Dependencies:** Only include the necessary dependencies in the package manifest.\n-   **Code Stripping:** Strip unnecessary symbols and debug information from binaries.\n\n### 3.5 Lazy Loading\n\n-   **On-Demand Loading:** Load resources (e.g., 3D models, textures) only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n-   **Unvalidated Input:** Protect against injection attacks by validating all input data.\n-   **Buffer Overflows:** Prevent buffer overflows by using safe string manipulation functions.\n-   **Denial of Service (DoS):** Protect against DoS attacks by limiting resource consumption.\n-   **Man-in-the-Middle (MitM):** Use secure communication protocols (e.g., TLS/SSL) to prevent MitM attacks.\n-   **Remote Code Execution (RCE):** Avoid RCE vulnerabilities by carefully sanitizing user input and preventing the execution of arbitrary code.\n\n### 4.2 Input Validation\n\n-   **Data Type Validation:** Ensure that input data matches the expected data type.\n-   **Range Checking:** Verify that input values are within the allowed range.\n-   **String Sanitization:** Sanitize string input to prevent injection attacks.\n\n### 4.3 Authentication and Authorization\n\n-   **ROS 2 Security Features:** Utilize the built-in security features of ROS 2, such as authentication and access control.\n-   **Secure Communication:** Use secure communication protocols (e.g., TLS/SSL) for sensitive data.\n-   **Access Control:** Implement access control mechanisms to restrict access to sensitive resources.\n\n### 4.4 Data Protection\n\n-   **Encryption:** Encrypt sensitive data at rest and in transit.\n-   **Data Masking:** Mask sensitive data to protect it from unauthorized access.\n-   **Data Auditing:** Audit data access and modifications to detect potential security breaches.\n\n### 4.5 Secure API Communication\n\n-   **API Keys:** Use API keys for authenticating API requests.\n-   **Rate Limiting:** Implement rate limiting to prevent abuse of APIs.\n-   **Input Validation:** Validate all input data to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n-   **Individual Components:** Test individual components (e.g., classes, functions) in isolation.\n-   **Test Frameworks:** Use testing frameworks like Google Test (C++) or `unittest` (Python).\n-   **Test Coverage:** Aim for high test coverage to ensure that all code paths are tested.\n\n### 5.2 Integration Testing\n\n-   **Multiple Components:** Test the interaction between multiple components or nodes.\n-   **ROS Integration Tests:** Use ROS-specific testing tools (e.g., `rostest`) to test ROS nodes and their communication.\n\n### 5.3 End-to-End Testing\n\n-   **Complete System:** Test the entire ROS system from end to end.\n-   **Simulation:** Use simulation environments (e.g., Gazebo) for testing in a realistic setting.\n\n### 5.4 Test Organization\n\n-   **Test Directory:** Create a dedicated `test` directory in the package.\n-   **Test Naming:** Use descriptive names for test files and functions.\n-   **Test Suites:** Group related tests into test suites.\n\n### 5.5 Mocking and Stubbing\n\n-   **Mock Objects:** Use mock objects to simulate the behavior of dependencies.\n-   **Stub Functions:** Use stub functions to replace complex or external functions with simplified versions.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n-   **Incorrect Topic Names:** Double-check topic names for typos or inconsistencies.\n-   **Missing Dependencies:** Ensure that all dependencies are declared in the package manifest.\n-   **Incorrect Time Handling:** Be aware of the difference between real-world time and ROS time.\n-   **Ignoring TF2:** Don't forget to use TF2 for managing coordinate transformations.\n\n### 6.2 Edge Cases\n\n-   **Network Latency:** Consider the impact of network latency on ROS communication.\n-   **Message Loss:** Handle potential message loss in unreliable networks.\n-   **Concurrency Issues:** Be aware of concurrency issues when using multiple threads.\n\n### 6.3 Version-Specific Issues\n\n-   **ROS 1 vs. ROS 2:** Be aware of the differences between ROS 1 and ROS 2.\n-   **Package Compatibility:** Ensure that packages are compatible with the ROS distribution being used.\n\n### 6.4 Compatibility Concerns\n\n-   **Operating Systems:** Test ROS code on different operating systems (e.g., Linux, macOS, Windows).\n-   **Hardware Platforms:** Ensure that ROS code is compatible with different hardware platforms.\n\n### 6.5 Debugging Strategies\n\n-   **ROS Logging:** Use `ROS_INFO`, `ROS_WARN`, `ROS_ERROR`, and `ROS_DEBUG` (C++) or `rospy.loginfo`, `rospy.logwarn`, `rospy.logerr`, and `rospy.logdebug` (Python) to log messages for debugging.\n-   **RViz:** Use RViz for visualizing ROS data and debugging visual issues.\n-   **Rosbag:** Use Rosbag for recording and playing back ROS messages.\n-   **GDB (C++):** Use GDB for debugging C++ code.\n-   **pdb (Python):** Use pdb for debugging Python code.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n-   **IDE:** VS Code with ROS extension, Eclipse, or other IDEs.\n-   **Build System:** CMake (ROS 1 and ROS 2).\n-   **Package Manager:** `apt` (Ubuntu), `pip` (Python).\n-   **Version Control:** Git.\n-   **Containerization:** Docker.\n\n### 7.2 Build Configuration\n\n-   **CMakeLists.txt:** Configure the build process using `CMakeLists.txt`.\n-   **package.xml:** Declare package dependencies and metadata in `package.xml`.\n\n### 7.3 Linting and Formatting\n\n-   **C++:** Use `clang-format` for code formatting and `cpplint` for code style checking.\n-   **Python:** Use `flake8` for code style checking and `black` for code formatting.\n-   **ROS Lint:** Use `roslint` for checking ROS-specific code style issues.\n\n### 7.4 Deployment\n\n-   **Debian Packages:** Create Debian packages for easy deployment on Ubuntu systems.\n-   **Docker Containers:** Package ROS applications into Docker containers for portability.\n\n### 7.5 CI/CD Integration\n\n-   **GitHub Actions:** Use GitHub Actions for continuous integration and continuous deployment.\n-   **Jenkins:** Use Jenkins for automated testing and deployment.\n-   **ROS Buildfarm:** Leverage the ROS buildfarm for automated builds and testing.\n\nThis document provides a comprehensive guide to ROS best practices. Adhering to these guidelines will improve the quality, maintainability, and interoperability of ROS projects.",
    "metadata": {
      "globs": "*.cpp,*.h,*.py,*.launch,*.msg,*.srv,*.action,*.yaml",
      "format": "mdc",
      "originalFile": "ros.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "ros",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "robot",
      "operating",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ros",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-ruby",
    "description": "Comprehensive best practices for Ruby development, covering code organization, common patterns, performance, security, testing, and tooling. This guide offers actionable advice to improve Ruby code quality, maintainability, and efficiency.",
    "author": "sanjeed5",
    "tags": [
      "ruby",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/ruby.mdc",
    "content": "# Ruby Best Practices\n\nThis document outlines best practices for Ruby development to ensure code quality, maintainability, performance, and security. It covers various aspects of Ruby projects, from code structure to testing and deployment.\n\n## 1. Code Organization and Structure\n\n### Directory Structure Best Practices\n\nFollowing a consistent and well-defined directory structure makes Ruby projects easier to navigate and maintain. Here's a recommended structure, especially for Rails applications but adaptable for other Ruby projects:\n\n\nproject_root/\n├── app/\n│   ├── models/\n│   ├── controllers/\n│   ├── views/\n│   ├── helpers/\n│   ├── mailers/\n│   ├── assets/\n│   │   ├── stylesheets/\n│   │   ├── javascripts/\n│   │   └── images/\n│   └── jobs/\n├── config/\n│   ├── routes.rb\n│   ├── database.yml\n│   ├── environments/\n│   │   ├── development.rb\n│   │   ├── test.rb\n│   │   └── production.rb\n│   └── application.rb\n├── db/\n│   ├── migrate/\n│   └── seeds.rb\n├── lib/\n│   ├── tasks/\n│   └── modules/\n├── log/\n├── public/\n├── test/\n│   ├── models/\n│   ├── controllers/\n│   ├── integration/\n│   ├── fixtures/\n│   └── support/\n├── vendor/\n│   └── cache/\n├── Gemfile\n├── Gemfile.lock\n├── Rakefile\n└── README.md\n\n\n-   **app/:** Contains the core application code, organized into models, controllers, views, helpers, mailers, assets, and jobs.\n-   **config/:** Holds configuration files, including routes, database settings, environment-specific configurations, and the main application configuration.\n-   **db/:** Contains database-related files, such as migration scripts and seed data.\n-   **lib/:** Used for custom modules, utility classes, and reusable code that doesn't fit into the app/ directory.\n-   **log/:** Stores application logs.\n-   **public/:** Contains static assets like HTML files, images, and compiled JavaScript/CSS.\n-   **test/:** Holds test files organized in a structure mirroring the app/ directory.\n-   **vendor/:** Stores third-party code, gems, or libraries.\n-   **Gemfile:** Specifies the gems (Ruby packages) required by the project.\n-   **Rakefile:** Defines Rake tasks for automating common development tasks.\n\n### File Naming Conventions\n\nConsistent file naming improves readability and maintainability. Follow these conventions:\n\n-   **Models:** Use singular names (e.g., `user.rb`, `product.rb`).\n-   **Controllers:** Use plural names (e.g., `users_controller.rb`, `products_controller.rb`).\n-   **Views:** Use corresponding controller and action names (e.g., `users/index.html.erb`, `products/show.html.erb`).\n-   **Helpers:** Use corresponding controller names with `_helper` suffix (e.g., `users_helper.rb`, `products_helper.rb`).\n-   **Migrations:** Use descriptive names with timestamps (e.g., `20240101000000_create_users.rb`).\n-   **Jobs:** Use descriptive names with `_job` suffix (e.g., `send_email_job.rb`).\n\n### Module Organization\n\nModules provide a way to organize code into logical groups and avoid namespace collisions. Use modules to encapsulate related classes and methods:\n\nruby\nmodule MyModule\n  class MyClass\n    def my_method\n      # ...\n    end\n  end\nend\n\n\n-   Organize modules in the `lib/modules/` directory.\n-   Use namespaces to avoid naming conflicts.\n-   Consider extracting complex logic into separate modules.\n\n### Component Architecture Recommendations\n\nFor larger applications, consider a component-based architecture. This involves breaking down the application into independent, reusable components:\n\n-   **Define Components:** Identify logical components (e.g., user authentication, payment processing, data analytics).\n-   **Encapsulate Logic:** Each component should encapsulate its own logic, data, and dependencies.\n-   **Expose Interfaces:** Define clear interfaces for components to interact with each other.\n-   **Use Gems or Internal Libraries:** Package components as gems or internal libraries for reuse across multiple projects.\n\n### Code Splitting Strategies\n\nCode splitting can improve performance by reducing the amount of code that needs to be loaded at once. Common strategies include:\n\n-   **Lazy Loading:** Load code only when it's needed. This can be achieved using `require` or `autoload`.\n-   **Conditional Loading:** Load code based on certain conditions (e.g., user roles, feature flags).\n-   **Service Objects:** Decompose large controllers/models into service objects which can be loaded as required.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n-   **Singleton:** Ensures that a class has only one instance and provides a global point of access to it.\n\n    ruby\n    class Configuration\n      @instance = Configuration.new\n\n      private_class_method :new\n\n      def self.instance\n        @instance\n      end\n    end\n    \n-   **Observer:** Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n\n    ruby\n    class Subject\n      attr_accessor :observers\n\n      def initialize\n        @observers = []\n      end\n\n      def attach(observer)\n        @observers << observer\n      end\n\n      def detach(observer)\n        @observers.delete(observer)\n      end\n\n      def notify\n        @observers.each { |observer| observer.update(self) }\n      end\n    end\n    \n\n-   **Factory:** Provides an interface for creating objects without specifying their concrete classes.\n\n    ruby\n    class AnimalFactory\n      def self.create(type)\n        case type\n        when :dog\n          Dog.new\n        when :cat\n          Cat.new\n        else\n          raise \"Unknown animal type\"\n        end\n      end\n    end\n    \n\n-   **Strategy:** Defines a family of algorithms, encapsulates each one, and makes them interchangeable. Strategy lets the algorithm vary independently from clients that use it.\n\n    ruby\n    class PaymentProcessor\n      def initialize(strategy)\n        @strategy = strategy\n      end\n\n      def process_payment(amount)\n        @strategy.process(amount)\n      end\n    end\n    \n\n### Recommended Approaches for Common Tasks\n\n-   **Data Validation:** Use ActiveRecord validations to ensure data integrity.\n-   **Authentication:** Use Devise gem for authentication.\n-   **Authorization:** Use CanCanCan or Pundit gem for authorization.\n-   **Background Processing:** Use Sidekiq or Resque for background jobs.\n-   **API Development:** Use Rails API or Grape gem for building APIs.\n\n### Anti-patterns and Code Smells\n\n-   **Fat Models:** Models that contain too much business logic. Move logic to service objects or POROs.\n-   **God Classes:** Classes that do too much. Break them down into smaller, more focused classes.\n-   **Duplicated Code:** Code that is repeated in multiple places. Follow the DRY principle and extract it into a shared method or module.\n-   **Long Methods:** Methods that are too long and complex. Break them down into smaller, more focused methods.\n-   **Magic Numbers:** Hardcoded numerical values that are difficult to understand. Use constants or enums instead.\n\n### State Management Best Practices\n\n-   **Session:** Use Rails session for storing user-specific data.\n-   **Cookies:** Use cookies for storing small amounts of data on the client-side.\n-   **Cache:** Use Rails cache for storing frequently accessed data.\n-   **Database:** Use the database for storing persistent data.\n-   **Redis/Memcached:** For complex state data or background job processing.\n\n### Error Handling Patterns\n\n-   **Exceptions:** Use exceptions for handling unexpected errors.\n\n    ruby\n    begin\n      # Code that might raise an exception\n    rescue SomeException => e\n      # Handle the exception\n      Rails.logger.error(\"Error: #{e.message}\")\n    end\n    \n\n-   **Error Objects:** Use error objects for handling expected errors.\n\n    ruby\n    class Result\n      attr_reader :success, :error, :data\n\n      def initialize(success:, error: nil, data: nil)\n        @success = success\n        @error = error\n        @data = data\n      end\n\n      def self.success(data: nil)\n        new(success: true, data: data)\n      end\n\n      def self.failure(error:)\n        new(success: false, error: error)\n      end\n    end\n    \n\n-   **Logging:** Log errors for debugging and monitoring.\n\n    ruby\n    Rails.logger.error(\"Error: Something went wrong\")\n    \n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n-   **Database Queries:** Optimize database queries by using indexes, eager loading, and avoiding N+1 queries.\n\n    ruby\n    # N+1 query problem\n    users = User.all\n    users.each { |user| puts user.posts.count } # one query per user\n\n    # Eager loading to solve N+1\n    users = User.includes(:posts).all\n    users.each { |user| puts user.posts.count } # only two queries\n    \n\n-   **Caching:** Use caching to reduce database load and improve response times.\n\n    ruby\n    Rails.cache.fetch(\"user_count\", expires_in: 1.hour) do\n      User.count\n    end\n    \n\n-   **Code Profiling:** Use code profiling tools to identify performance bottlenecks.\n-   **Garbage Collection:** Understand how Ruby's garbage collection works and optimize memory usage.\n-   **Use Efficient Algorithms:** Choose appropriate algorithms and data structures for performance-critical operations.\n\n### Memory Management\n\n-   **Avoid Memory Leaks:** Be careful about creating objects that are never garbage collected.\n-   **Use Object Pooling:** Reuse objects instead of creating new ones.\n-   **Minimize Object Creation:** Reduce the number of objects created in performance-critical sections of code.\n\n### Bundle Size Optimization\n\n-   **Remove Unused Gems:** Identify and remove gems that are not being used.\n-   **Use Lightweight Gems:** Choose smaller, more efficient gems when possible.\n-   **Compress Assets:** Compress CSS, JavaScript, and image assets.\n\n### Lazy Loading Strategies\n\n-   **Load Associations Lazily:** Use `lazy_load: true` option in associations.\n-   **Load Code Lazily:** Use `require` or `autoload` to load code only when it's needed.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities\n\n-   **SQL Injection:** Prevent SQL injection by using parameterized queries and avoiding string interpolation in SQL queries.\n\n    ruby\n    # Unsafe\n    User.where(\"email = '#{params[:email]}'\")\n\n    # Safe\n    User.where(email: params[:email])\n    \n\n-   **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input and using content security policies.\n\n    erb\n    <%= sanitize @user.bio %> # Sanitize user input\n    \n\n-   **Cross-Site Request Forgery (CSRF):** Protect against CSRF by using CSRF tokens.\n-   **Mass Assignment:** Protect against mass assignment vulnerabilities by using strong parameters.\n\n    ruby\n    def user_params\n      params.require(:user).permit(:name, :email, :password, :password_confirmation)\n    end\n    \n\n### Input Validation\n\n-   **Validate User Input:** Always validate user input to ensure it meets expected criteria.\n-   **Sanitize User Input:** Sanitize user input to remove potentially harmful characters.\n-   **Use Strong Parameters:** Use strong parameters to protect against mass assignment vulnerabilities.\n\n### Authentication and Authorization\n\n-   **Use Devise:** Use Devise gem for authentication.\n-   **Use CanCanCan or Pundit:** Use CanCanCan or Pundit gem for authorization.\n-   **Implement Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n\n### Data Protection\n\n-   **Encrypt Sensitive Data:** Encrypt sensitive data such as passwords and API keys.\n-   **Use HTTPS:** Use HTTPS to encrypt communication between the client and server.\n-   **Store Passwords Securely:** Use bcrypt or other secure password hashing algorithms.\n\n### Secure API Communication\n\n-   **Use API Keys:** Use API keys to authenticate API requests.\n-   **Implement Rate Limiting:** Implement rate limiting to prevent abuse.\n-   **Use OAuth:** Use OAuth for secure authorization.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n-   **Test Individual Components:** Write unit tests to test individual components in isolation.\n-   **Use Mocks and Stubs:** Use mocks and stubs to isolate components from external dependencies.\n-   **Test Edge Cases:** Test edge cases to ensure code handles unexpected input or conditions.\n\n### Integration Testing\n\n-   **Test Interactions Between Components:** Write integration tests to test interactions between components.\n-   **Test External Dependencies:** Test interactions with external dependencies such as databases and APIs.\n\n### End-to-End Testing\n\n-   **Test Entire Application Flow:** Write end-to-end tests to test the entire application flow.\n-   **Use Selenium or Capybara:** Use Selenium or Capybara to automate browser interactions.\n\n### Test Organization\n\n-   **Mirror App Directory:** Organize tests in a directory structure mirroring the app/ directory.\n-   **Use Descriptive Names:** Use descriptive names for test files and methods.\n\n### Mocking and Stubbing\n\n-   **Use RSpec Mocks and Stubs:** Use RSpec's mocking and stubbing features to isolate components.\n\n    ruby\n    # Mocking\n    allow(User).to receive(:find).with(1).and_return(mock_user)\n\n    # Stubbing\n    allow(mock_user).to receive(:name).and_return(\"John Doe\")\n    \n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n-   **Not Using ActiveRecord Validations:** Forgetting to validate data in models can lead to data integrity issues.\n-   **Not Understanding the Scope of Variables:** Misunderstanding variable scope can lead to unexpected behavior.\n-   **Not Handling Exceptions:** Failing to handle exceptions can cause the application to crash.\n-   **Not Writing Tests:** Neglecting to write tests can lead to bugs and regressions.\n\n### Edge Cases\n\n-   **Handling Empty Datasets:** Ensure code handles empty datasets gracefully.\n-   **Handling Large Datasets:** Optimize code to handle large datasets efficiently.\n-   **Handling Time Zones:** Be aware of time zone issues when working with dates and times.\n\n### Version-Specific Issues\n\n-   **Ruby Version Compatibility:** Ensure code is compatible with the target Ruby version.\n-   **Rails Version Compatibility:** Ensure code is compatible with the target Rails version.\n\n### Compatibility Concerns\n\n-   **Database Compatibility:** Be aware of compatibility issues between different databases.\n-   **Operating System Compatibility:** Be aware of compatibility issues between different operating systems.\n\n### Debugging Strategies\n\n-   **Use Debugger:** Use a debugger to step through code and inspect variables.\n-   **Use Logging:** Use logging to track application behavior.\n-   **Read Error Messages:** Carefully read error messages to understand the cause of the error.\n-   **Use `binding.pry`:** Insert `binding.pry` into your code to pause execution and inspect variables.\n\n## 7. Tooling and Environment\n\n### Recommended Tools\n\n-   **Text Editor:** VSCode, Sublime Text, Atom, RubyMine\n-   **Debugger:** Byebug, RubyMine Debugger\n-   **Testing Framework:** RSpec, Minitest\n-   **Code Analysis:** RuboCop, Reek\n-   **Package Manager:** Bundler\n-   **Version Manager:** rbenv, rvm\n\n### Build Configuration\n\n-   **Use Bundler:** Use Bundler to manage gem dependencies.\n\n    ruby\n    # Gemfile\nsource 'https://rubygems.org'\n\ngem 'rails', '~> 7.0'\ngem 'pg'\n    \n\n-   **Specify Ruby Version:** Specify the Ruby version in the `Gemfile`.\n\n    ruby\n    # Gemfile\n    ruby '3.2.2'\n    \n\n-   **Use `.env` Files:** Use `.env` files to store environment variables.\n\n### Linting and Formatting\n\n-   **Use RuboCop:** Use RuboCop to enforce Ruby style guidelines.\n-   **Configure RuboCop:** Configure RuboCop to match project coding standards.\n\n    \n    # .rubocop.yml\nAllCops:\n  TargetRubyVersion: 3.2\n  Exclude:\n    - 'vendor/*'\n\nStyle/Documentation:\n  Enabled: false\n    \n\n-   **Use Prettier:** Use Prettier for code formatting.\n\n### Deployment\n\n-   **Use a Deployment Tool:** Use a deployment tool such as Capistrano or Heroku.\n-   **Automate Deployment:** Automate the deployment process to reduce errors and improve efficiency.\n-   **Use a Production Database:** Use a production-grade database such as PostgreSQL or MySQL.\n-   **Configure a Web Server:** Configure a web server such as Nginx or Apache.\n\n### CI/CD Integration\n\n-   **Use a CI/CD Tool:** Use a CI/CD tool such as Jenkins, GitLab CI, or CircleCI.\n-   **Automate Testing:** Automate testing as part of the CI/CD pipeline.\n-   **Automate Deployment:** Automate deployment as part of the CI/CD pipeline.",
    "metadata": {
      "globs": "*.rb",
      "format": "mdc",
      "originalFile": "ruby.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "ruby",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "organization",
      "common",
      "patterns",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "ruby",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-rust",
    "description": "This rule provides comprehensive best practices for Rust development, covering code organization, common patterns, performance, security, testing, pitfalls, and tooling. It aims to guide developers in writing idiomatic, efficient, secure, and maintainable Rust code.",
    "author": "sanjeed5",
    "tags": [
      "rust",
      "systems",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/rust.mdc",
    "content": "# Rust Best Practices\n\nThis document outlines a comprehensive set of best practices for Rust development, covering various aspects from code organization to security and tooling. Adhering to these guidelines will help you write idiomatic, efficient, secure, and maintainable Rust code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n-   **`src/`**: Contains all the Rust source code.\n    -   **`main.rs`**: The entry point for binary crates.\n    -   **`lib.rs`**: The entry point for library crates.\n    -   **`bin/`**:  Contains source files for multiple binary executables within the same project.  Each file in `bin/` will be compiled into a separate executable.\n    -   **`modules/` or `components/`**: (Optional)  For larger projects, group related modules or components into subdirectories. Use descriptive names.\n    -   **`tests/`**:  Integration tests. (See Testing section below for more details.)\n    -   **`examples/`**: Example code that demonstrates how to use the library.\n-   **`benches/`**: Benchmark tests (using `criterion` or similar).\n-   **`Cargo.toml`**: Project manifest file.\n-   **`Cargo.lock`**: Records the exact versions of dependencies used. **Do not manually edit.**\n-   **`.gitignore`**: Specifies intentionally untracked files that Git should ignore.\n-   **`README.md`**: Project documentation, including usage instructions, build instructions, and license information.\n-   **`LICENSE`**: Contains the project's license.\n\n\nmy_project/\n├── Cargo.toml\n├── Cargo.lock\n├── src/\n│   ├── main.rs         # Entry point for a binary crate\n│   ├── lib.rs          # Entry point for a library crate\n│   ├── modules/\n│   │   ├── module_a.rs # A module within the crate\n│   │   └── module_b.rs # Another module\n│   └── bin/\n│       ├── cli_tool.rs # A separate binary executable\n│       └── worker.rs   # Another binary executable\n├── tests/\n│   └── integration_test.rs # Integration tests\n├── benches/\n│   └── my_benchmark.rs # Benchmark tests using Criterion\n├── examples/\n│   └── example_usage.rs # Example code using the library\n├── README.md\n└── LICENSE\n\n\n### 1.2. File Naming Conventions\n\n-   Rust source files use the `.rs` extension.\n-   Module files (e.g., `module_a.rs`) should be named after the module they define.\n-   Use snake_case for file names (e.g., `my_module.rs`).\n\n### 1.3. Module Organization\n\n-   Use modules to organize code into logical units.\n-   Declare modules in `lib.rs` or `main.rs` using the `mod` keyword.\n-   Use `pub mod` to make modules public.\n-   Create separate files for each module to improve readability and maintainability.\n-   Use `use` statements to bring items from other modules into scope.\n\nrust\n// lib.rs\n\npub mod my_module;\n\nmod internal_module; // Not public\n\n\nrust\n// my_module.rs\n\npub fn my_function() {\n    //...\n}\n\n\n### 1.4. Component Architecture\n\n-   For larger applications, consider using a component-based architecture.\n-   Each component should be responsible for a specific part of the application's functionality.\n-   Components should communicate with each other through well-defined interfaces (traits).\n-   Consider using dependency injection to decouple components and improve testability.\n\n### 1.5. Code Splitting Strategies\n\n-   Split code into smaller, reusable modules.\n-   Use feature flags to conditionally compile code for different platforms or features.\n-   Consider using dynamic linking (if supported by your target platform) to reduce binary size.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Builder Pattern**: For constructing complex objects with many optional parameters.\n-   **Factory Pattern**: For creating objects without specifying their concrete types.\n-   **Observer Pattern**: For implementing event-driven systems.\n-   **Strategy Pattern**: For selecting algorithms at runtime.\n-   **Visitor Pattern**: For adding new operations to existing data structures without modifying them.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n-   **Data Structures**: Use `Vec` for dynamic arrays, `HashMap` for key-value pairs, `HashSet` for unique elements, `BTreeMap` and `BTreeSet` for sorted collections.\n-   **Concurrency**: Use `Arc` and `Mutex` for shared mutable state, channels for message passing, and the `rayon` crate for data parallelism.\n-   **Asynchronous Programming**: Use `async` and `await` for writing asynchronous code.\n-   **Error Handling**: Use the `Result` type for recoverable errors and `panic!` for unrecoverable errors.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Unnecessary Cloning**: Avoid cloning data unless it is absolutely necessary. Use references instead.\n-   **Excessive `unwrap()` Calls**: Handle errors properly instead of using `unwrap()`, which can cause the program to panic.\n-   **Overuse of `unsafe`**: Minimize the use of `unsafe` code and carefully review any unsafe code to ensure it is correct.\n-   **Ignoring Compiler Warnings**: Treat compiler warnings as errors and fix them.\n-   **Premature Optimization**: Focus on writing clear, correct code first, and then optimize only if necessary.\n\n### 2.4. State Management\n\n-   **Immutability by Default**: Prefer immutable data structures and functions that return new values instead of modifying existing ones.\n-   **Ownership and Borrowing**: Use Rust's ownership and borrowing system to manage memory and prevent data races.\n-   **Interior Mutability**: Use `Cell`, `RefCell`, `Mutex`, and `RwLock` for interior mutability when necessary, but be careful to avoid data races.\n\n### 2.5. Error Handling\n\n-   **`Result<T, E>`**: Use `Result` to represent fallible operations. `T` is the success type, and `E` is the error type.\n-   **`Option<T>`**: Use `Option` to represent the possibility of a missing value. `Some(T)` for a value, `None` for no value.\n-   **`?` Operator**: Use the `?` operator to propagate errors up the call stack.\n-   **Custom Error Types**: Define custom error types using enums or structs to provide more context about errors.\n-   **`anyhow` and `thiserror` Crates**: Consider using the `anyhow` crate for simple error handling and the `thiserror` crate for defining custom error types.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Profiling**: Use profiling tools (e.g., `perf`, `cargo flamegraph`) to identify performance bottlenecks.\n-   **Benchmarking**: Use benchmarking tools (e.g., `criterion`) to measure the performance of code changes.\n-   **Zero-Cost Abstractions**: Leverage Rust's zero-cost abstractions, such as iterators, closures, and generics.\n-   **Inlining**: Use the `#[inline]` attribute to encourage the compiler to inline functions.\n-   **LTO (Link-Time Optimization)**: Enable LTO to improve performance by optimizing across crate boundaries.\n\n### 3.2. Memory Management\n\n-   **Minimize Allocations**: Reduce the number of allocations and deallocations by reusing memory and using stack allocation when possible.\n-   **Avoid Copying Large Data Structures**: Use references or smart pointers to avoid copying large data structures.\n-   **Use Efficient Data Structures**: Choose the right data structure for the job based on its performance characteristics.\n-   **Consider `Box` and `Rc`**: `Box` for single ownership heap allocation, `Rc` and `Arc` for shared ownership (latter thread-safe).\n\n### 3.3. Rendering Optimization\n\n-   **(Relevant if the Rust application involves rendering, e.g., a game or GUI)**\n-   **Batch draw calls**: Combine multiple draw calls into a single draw call to reduce overhead.\n-   **Use efficient data structures**: Use data structures that are optimized for rendering, such as vertex buffers and index buffers.\n-   **Profile rendering performance**: Use profiling tools to identify rendering bottlenecks.\n\n### 3.4. Bundle Size Optimization\n\n-   **Strip Debug Symbols**: Remove debug symbols from release builds to reduce binary size.\n-   **Enable LTO**: LTO can also reduce binary size by removing dead code.\n-   **Use `minisize` Profile**: Create a `minisize` profile in `Cargo.toml` for optimizing for size.\n-   **Avoid Unnecessary Dependencies**: Only include the dependencies that are absolutely necessary.\n\n### 3.5. Lazy Loading\n\n-   **Load Resources on Demand**: Load resources (e.g., images, sounds, data files) only when they are needed.\n-   **Use a Loading Screen**: Display a loading screen while resources are being loaded.\n-   **Consider Streaming**: Stream large resources from disk or network instead of loading them all at once.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n-   **Buffer Overflows**: Prevent buffer overflows by using safe indexing methods (e.g., `get()`, `get_mut()`) and validating input sizes.\n-   **SQL Injection**: Prevent SQL injection by using parameterized queries and escaping user input.\n-   **Cross-Site Scripting (XSS)**: Prevent XSS by escaping user input when rendering HTML.\n-   **Command Injection**: Prevent command injection by avoiding the use of `std::process::Command` with user-supplied arguments.\n-   **Denial of Service (DoS)**: Protect against DoS attacks by limiting resource usage (e.g., memory, CPU, network connections).\n-   **Integer Overflows**:  Use the `checked_add`, `checked_sub`, `checked_mul`, etc. methods on integers to prevent overflows.\n-   **Use-After-Free**:  Rust's ownership system largely prevents this, but be cautious when using `unsafe` code or dealing with raw pointers.\n-   **Data Races**:  Avoid data races by using appropriate synchronization primitives (`Mutex`, `RwLock`, channels).\n-   **Uninitialized Memory**: Rust generally initializes memory, but `unsafe` code can bypass this.  Be careful when working with uninitialized memory.\n\n### 4.2. Input Validation\n\n-   **Validate All Input**: Validate all input from external sources, including user input, network data, and file contents.\n-   **Use a Whitelist Approach**: Define a set of allowed values and reject any input that does not match.\n-   **Sanitize Input**: Remove or escape any potentially dangerous characters from input.\n-   **Limit Input Length**: Limit the length of input strings to prevent buffer overflows.\n-   **Check Data Types**: Ensure that input data is of the expected type.\n\n### 4.3. Authentication and Authorization\n\n-   **Use Strong Passwords**: Require users to create strong passwords and store them securely using a hashing algorithm like Argon2 or bcrypt.\n-   **Implement Two-Factor Authentication (2FA)**: Add an extra layer of security by requiring users to authenticate with a second factor, such as a code from their phone.\n-   **Use JSON Web Tokens (JWT)**: Use JWTs for stateless authentication and authorization.\n-   **Implement Role-Based Access Control (RBAC)**: Define roles with specific permissions and assign users to those roles.\n-   **Principle of Least Privilege**:  Grant users only the minimum necessary privileges to perform their tasks.\n-   **Regular Audits**: Perform regular security audits of authentication and authorization mechanisms.\n\n### 4.4. Data Protection\n\n-   **Encrypt Sensitive Data**: Encrypt sensitive data at rest and in transit using strong encryption algorithms like AES-256.\n-   **Use HTTPS**: Use HTTPS to encrypt communication between the client and the server.\n-   **Protect API Keys**: Store API keys securely and restrict their usage to authorized users.\n-   **Handle Secrets Securely**: Use environment variables or dedicated secret management tools (e.g., Vault, AWS Secrets Manager) to store secrets.\n-   **Avoid Hardcoding Secrets**: Never hardcode secrets directly into the code.\n-   **Data Masking/Redaction**: Mask or redact sensitive data when logging or displaying it.\n\n### 4.5. Secure API Communication\n\n-   **Use TLS/SSL**: Enforce TLS/SSL for all API communication.\n-   **Validate Certificates**: Properly validate server certificates to prevent man-in-the-middle attacks.\n-   **Rate Limiting**: Implement rate limiting to prevent abuse and DoS attacks.\n-   **API Versioning**: Use API versioning to maintain backward compatibility and allow for future changes.\n-   **Input and Output Validation**: Thoroughly validate both input to and output from the API.\n-   **Content Security Policy (CSP)**: Use CSP headers to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   **Test Individual Units of Code**: Write unit tests to verify the correctness of individual functions, modules, and components.\n-   **Use the `#[test]` Attribute**: Use the `#[test]` attribute to mark functions as unit tests.\n-   **Use `assert!` and `assert_eq!`**: Use `assert!` and `assert_eq!` macros to check that the code behaves as expected.\n-   **Test Driven Development (TDD)**: Consider writing tests before writing code.\n-   **Table-Driven Tests**:  Use parameterized tests or table-driven tests for testing multiple scenarios with different inputs.\n\nrust\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_add() {\n        assert_eq!(add(2, 3), 5);\n    }\n}\n\n\n### 5.2. Integration Testing\n\n-   **Test Interactions Between Components**: Write integration tests to verify that different components of the application work together correctly.\n-   **Create a `tests/` Directory**: Place integration tests in a `tests/` directory at the root of the project.\n-   **Use Separate Test Files**: Create separate test files for each integration test.\n\n### 5.3. End-to-End Testing\n\n-   **Test the Entire Application**: Write end-to-end tests to verify that the entire application works as expected.\n-   **Use a Testing Framework**: Use a testing framework (e.g., `cucumber`, `selenium`) to automate end-to-end tests.\n-   **Test User Flows**: Test common user flows to ensure that the application is usable.\n\n### 5.4. Test Organization\n\n-   **Group Tests by Functionality**: Organize tests into modules and submodules based on the functionality they test.\n-   **Use Descriptive Test Names**: Use descriptive test names that clearly indicate what the test is verifying.\n-   **Keep Tests Separate from Production Code**: Keep tests in separate files and directories to avoid cluttering the production code.\n-   **Run tests frequently**: Integrate tests into your development workflow and run them frequently to catch errors early.\n\n### 5.5. Mocking and Stubbing\n\n-   **Use Mocking Libraries**: Use mocking libraries (e.g., `mockall`, `mockito`) to create mock objects for testing.\n-   **Use Traits for Interfaces**: Define traits for interfaces to enable mocking and stubbing.\n-   **Avoid Global State**: Avoid global state to make it easier to mock and stub dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Borrowing Rules**: Misunderstanding Rust's borrowing rules can lead to compile-time errors. Ensure you understand ownership, borrowing, and lifetimes.\n-   **Move Semantics**: Be aware of move semantics and how they affect ownership. Data is moved by default, not copied.\n-   **Lifetime Annotations**: Forgetting lifetime annotations can lead to compile-time errors. Annotate lifetimes when necessary.\n-   **Error Handling**: Not handling errors properly can lead to unexpected panics. Use `Result` and the `?` operator to handle errors gracefully.\n-   **Unsafe Code**: Overusing or misusing `unsafe` code can lead to undefined behavior and security vulnerabilities.\n\n### 6.2. Edge Cases\n\n-   **Integer Overflow**: Be aware of integer overflow and use checked arithmetic methods to prevent it.\n-   **Unicode**: Handle Unicode characters correctly to avoid unexpected behavior.\n-   **File Paths**: Handle file paths correctly, especially when dealing with different operating systems.\n-   **Concurrency**: Be careful when writing concurrent code to avoid data races and deadlocks.\n\n### 6.3. Version-Specific Issues\n\n-   **Check Release Notes**: Review the release notes for new versions of Rust to identify any breaking changes or new features that may affect your code.\n-   **Use `rustup`**: Use `rustup` to manage multiple versions of Rust.\n-   **Update Dependencies**: Keep your dependencies up to date to take advantage of bug fixes and new features.\n\n### 6.4. Compatibility Concerns\n\n-   **C Interoperability**: Be careful when interacting with C code to avoid undefined behavior.\n-   **Platform-Specific Code**: Use conditional compilation to handle platform-specific code.\n-   **WebAssembly**: Be aware of the limitations of WebAssembly when targeting the web.\n\n### 6.5. Debugging Strategies\n\n-   **Use `println!`**: Use `println!` statements to print debugging information.\n-   **Use a Debugger**: Use a debugger (e.g., `gdb`, `lldb`) to step through the code and inspect variables.\n-   **Use `assert!`**: Use `assert!` to check that the code behaves as expected.\n-   **Use Logging**: Use a logging library (e.g., `log`, `tracing`) to record debugging information.\n-   **Clippy**: Use Clippy to catch common mistakes and improve code quality.\n-   **cargo-flamegraph**: Use cargo-flamegraph to profile and visualize the execution of your code.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n-   **Rustup**: For managing Rust toolchains and versions.\n-   **Cargo**: The Rust package manager and build tool.\n-   **IDE/Editor**: VS Code with the rust-analyzer extension, IntelliJ Rust, or other editors with Rust support.\n-   **Clippy**: A linter for Rust code.\n-   **Rustfmt**: A code formatter for Rust code.\n-   **Cargo-edit**: A utility for easily modifying `Cargo.toml` dependencies.\n-   **Cargo-watch**: Automatically runs tests on file changes.\n-   **lldb or GDB**: Debuggers for Rust applications.\n\n### 7.2. Build Configuration\n\n-   **Use `Cargo.toml`**: Configure build settings, dependencies, and metadata in the `Cargo.toml` file.\n-   **Use Profiles**: Define different build profiles for development, release, and testing.\n-   **Feature Flags**: Use feature flags to conditionally compile code for different platforms or features.\n\ntoml\n[package]\nname = \"my_project\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nserde = { version = \"1.0\", features = [\"derive\"] }\n\n[dev-dependencies]\nrand = \"0.8\"\n\n[features]\ndefault = [\"serde\"] # 'default' feature enables 'serde'\nexpensive_feature = []\n\n[profile.release]\nopt-level = 3\ndebug = false\nlto = true\n\n\n### 7.3. Linting and Formatting\n\n-   **Use Clippy**: Use Clippy to catch common mistakes and enforce coding standards.\n-   **Use Rustfmt**: Use Rustfmt to automatically format code according to the Rust style guide.\n-   **Configure Editor**: Configure your editor to automatically run Clippy and Rustfmt on save.\n-   **Pre-commit Hooks**: Set up pre-commit hooks to run Clippy and Rustfmt before committing code.\n\nshell\n# Install Clippy\nrustup component add clippy\n\n# Run Clippy\ncargo clippy\n\n# Install Rustfmt\nrustup component add rustfmt\n\n# Run Rustfmt\ncargo fmt\n\n\n### 7.4. Deployment Best Practices\n\n-   **Build Release Binaries**:  Build your application in release mode (`cargo build --release`) to optimize for performance.\n-   **Minimize Dependencies**: Reduce the number of dependencies to minimize the size of the deployed application.\n-   **Containerization (Docker)**: Use Docker to create a consistent and reproducible deployment environment.\n-   **Static Linking**: Consider static linking to create a single executable file.\n-   **Process Manager (systemd, supervisord)**:  Use a process manager to ensure your application restarts automatically if it crashes.\n\n### 7.5. CI/CD Integration\n\n-   **Use a CI/CD System**: Use a CI/CD system (e.g., GitHub Actions, GitLab CI, Jenkins) to automate the build, test, and deployment process.\n-   **Run Tests on CI**: Run unit tests, integration tests, and end-to-end tests on CI.\n-   **Run Linters and Formatters on CI**: Run Clippy and Rustfmt on CI to enforce coding standards.\n-   **Automate Deployment**: Automate the deployment process to reduce manual effort and errors.\n\n\n# Example GitHub Actions workflow\nname: CI\n\non:\n  push:\n    branches:\n      - main\n  pull_request:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n      - uses: actions/cache@v3\n        with:\n          path: | \n            ~/.cargo/registry\n            ~/.cargo/git\n            target\n          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}\n\n      - name: Install Rust\n        run: rustup default stable\n\n      - name: Build\n        run: cargo build --verbose\n\n      - name: Run tests\n        run: cargo test --verbose\n\n      - name: Run clippy\n        run: cargo clippy -- -D warnings\n\n\nBy following these best practices, you can write high-quality Rust code that is efficient, secure, and maintainable. Remember to stay up-to-date with the latest Rust features and best practices to continuously improve your skills and knowledge.",
    "metadata": {
      "globs": "*.rs",
      "format": "mdc",
      "originalFile": "rust.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "rust",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "systems",
      "performance",
      "cursor-rule",
      "mdc",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "rust",
        "systems",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-sanic",
    "description": "This rule file outlines best practices and coding standards for developing Sanic applications, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "sanic",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sanic.mdc",
    "content": "- This document outlines the best practices for developing applications using the Sanic framework. Following these guidelines will lead to more maintainable, performant, and secure applications.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:** Organize your project into logical directories. A recommended structure is:\n  \n  project_root/\n  ├── app/\n  │   ├── __init__.py\n  │   ├── main.py          # Main application file\n  │   ├── routes.py        # Defines application routes\n  │   ├── models.py        # Data models (if using an ORM)\n  │   ├── views.py         # Request handlers and view logic\n  │   ├── config.py        # Application configuration\n  │   ├── utils.py         # Utility functions and helpers\n  │   ├── middlewares.py   # Sanic middlewares\n  │   ├── exceptions.py    # Custom exception definitions\n  │   └── services/        # Business logic and service layers\n  ├── tests/             # Unit and integration tests\n  │   ├── __init__.py\n  │   ├── conftest.py     # Pytest configuration file\n  │   ├── unit/\n  │   └── integration/\n  ├── migrations/        # Database migration scripts\n  ├── requirements.txt   # Project dependencies\n  ├── .env               # Environment variables\n  └── README.md          # Project documentation\n  \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent naming.\n    - `routes.py`, `models.py`, `views.py`, `config.py`, etc. are good examples.\n    - For service modules, use `service_name_service.py` (e.g., `user_service.py`).\n    - Test files should mirror the source file names (e.g., `test_routes.py` for `routes.py`).\n\n- **Module Organization:**\n    - Keep modules focused and cohesive.\n    - Avoid large, monolithic modules.\n    - Group related functionality into separate modules and packages.\n    - Use relative imports within the `app` package.\n\n- **Component Architecture:**\n    - Adopt a layered architecture (e.g., presentation, business logic, data access).\n    - Use dependency injection to decouple components.\n    - Employ service objects for complex business logic.\n\n- **Code Splitting:**\n    - Defer loading non-critical modules using dynamic imports.\n    - Split large route handlers into smaller, manageable functions.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Dependency Injection:** Use dependency injection to manage dependencies and improve testability.\n    - **Service Layer:** Encapsulate business logic in service objects.\n    - **Repository Pattern:** Abstract data access logic using repositories.\n    - **Middleware Pattern:** Use middleware for request pre-processing and response post-processing.\n\n- **Recommended Approaches:**\n    - **Configuration:** Use environment variables for configuration and load them with a library like `python-dotenv`.\n    - **Database Access:** Utilize an ORM (e.g., SQLAlchemy) for interacting with databases.\n    - **Asynchronous Tasks:** Use `asyncio` or a task queue (e.g., Celery) for background tasks.\n    - **Response Handling:** Standardize response formats and error handling using custom exception handlers.\n\n- **Anti-patterns:**\n    - **Global State:** Avoid using global variables to store application state; use dependency injection instead.\n    - **Tight Coupling:** Reduce coupling between components through interfaces and dependency injection.\n    - **Long Functions:** Break down large functions into smaller, more manageable units.\n    - **Ignoring Exceptions:** Always handle exceptions properly; avoid bare `except` clauses.\n\n- **State Management:**\n    - Use application context or dependency injection to manage shared state.\n    - Avoid using global variables.\n    - Utilize a dedicated state management library (if needed).\n\n- **Error Handling:**\n    - Use custom exception classes for specific error conditions.\n    - Implement global exception handlers for uncaught exceptions.\n    - Log errors with detailed context information.\n    - Return informative error messages to the client.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Asynchronous Operations:** Use `async` and `await` for I/O-bound operations to prevent blocking the event loop.\n    - **Connection Pooling:** Use connection pooling for database connections to reduce overhead.\n    - **Caching:** Implement caching strategies to reduce database load.\n    - **Gzip Compression:** Enable Gzip compression for responses to reduce network bandwidth usage.\n\n- **Memory Management:**\n    - Avoid creating unnecessary objects.\n    - Use generators for large datasets to reduce memory consumption.\n    - Profile your application to identify memory leaks.\n\n- **Rendering Optimization:**\n    - Use efficient template engines (e.g., Jinja2) and cache rendered templates.\n    - Minimize the amount of data passed to templates.\n    - Use response streaming for very large responses.\n\n- **Bundle Size Optimization:**\n    - Not directly applicable to Sanic (as it's a backend framework), but if serving static files, minimize and compress them.\n\n- **Lazy Loading:**\n    - Defer loading non-critical modules until they are needed.\n    - Use lazy imports to improve startup time.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **SQL Injection:** Prevent SQL injection by using parameterized queries or an ORM.\n    - **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Implement CSRF protection for state-changing requests.\n    - **Authentication and Authorization Issues:** Secure your application with proper authentication and authorization mechanisms.\n\n- **Input Validation:**\n    - Validate all user input to prevent injection attacks.\n    - Use data validation libraries (e.g., `marshmallow`) to enforce data types and constraints.\n    - Escape special characters in user input.\n\n- **Authentication and Authorization:**\n    - Use a secure authentication protocol (e.g., OAuth 2.0, JWT).\n    - Implement role-based access control (RBAC) to manage user permissions.\n    - Protect sensitive endpoints with authentication and authorization middleware.\n\n- **Data Protection:**\n    - Use HTTPS to encrypt data in transit.\n    - Store sensitive data (e.g., passwords) securely using hashing and salting.\n    - Use encryption for data at rest.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API endpoints.\n    - Implement rate limiting to prevent abuse.\n    - Validate API requests and responses against a schema.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - Use a testing framework like `pytest` or `unittest`.\n    - Write unit tests for individual components (e.g., models, services, utilities).\n    - Mock external dependencies to isolate components.\n\n- **Integration Testing:**\n    - Test the interaction between different components.\n    - Use a test database for integration tests.\n    - Verify that requests are handled correctly and data is persisted.\n\n- **End-to-End Testing:**\n    - Use a tool like `Selenium` or `Playwright` to simulate user interactions.\n    - Test the entire application flow from the client to the database.\n    - Verify that the application behaves as expected in a production-like environment.\n\n- **Test Organization:**\n    - Organize tests into separate directories (e.g., `unit`, `integration`).\n    - Use descriptive test names.\n    - Follow the arrange-act-assert pattern.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to isolate components.\n    - Create stubs for external dependencies that are difficult to test directly.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Blocking the Event Loop:** Avoid performing long-running or I/O-bound operations in the main event loop.\n    - **Incorrect Use of `async` and `await`:** Ensure that all asynchronous operations are properly awaited.\n    - **Not Handling Exceptions:** Always handle exceptions properly to prevent application crashes.\n    - **Security Vulnerabilities:** Be aware of common security vulnerabilities and take steps to prevent them.\n\n- **Edge Cases:**\n    - **Handling Large Requests:** Properly handle large requests to prevent denial-of-service attacks.\n    - **Graceful Shutdown:** Implement graceful shutdown to avoid data loss.\n    - **Concurrency Issues:** Be aware of potential concurrency issues when working with shared resources.\n\n- **Version-Specific Issues:**\n    - Consult the Sanic documentation and release notes for version-specific issues and migration guides.\n\n- **Compatibility Concerns:**\n    - Ensure that your dependencies are compatible with the version of Sanic you are using.\n    - Test your application with different versions of Python to ensure compatibility.\n\n- **Debugging Strategies:**\n    - Use the built-in debugger or an IDE with debugging support.\n    - Log detailed information about requests and responses.\n    - Use profiling tools to identify performance bottlenecks.\n    - Check Sanic application and server logs when troubleshooting issues.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **IDE:** VS Code, PyCharm\n    - **Package Manager:** pip, uv\n    - **Virtual Environment:** venv, virtualenv\n    - **Testing Framework:** pytest\n    - **Linting:** flake8, pylint\n    - **Formatting:** black, autopep8\n    - **Debugging:** pdb, ipdb\n\n- **Build Configuration:**\n    - Use a `requirements.txt` file to manage dependencies.\n    - Use a `Makefile` or `tox.ini` file to automate build tasks.\n    - Use a `Dockerfile` to containerize your application.\n\n- **Linting and Formatting:**\n    - Use a linter (e.g., `flake8`, `pylint`) to enforce code style.\n    - Use a formatter (e.g., `black`, `autopep8`) to automatically format your code.\n    - Configure your IDE to run linters and formatters automatically.\n\n- **Deployment Best Practices:**\n    - Use a process manager like `Gunicorn` or `uvicorn` to serve your application.\n    - Deploy your application behind a reverse proxy like `Nginx`.\n    - Use a containerization platform like `Docker` to package and deploy your application.\n    - Monitor your application using a monitoring tool like `Prometheus` or `Sentry`.\n\n- **CI/CD Integration:**\n    - Use a CI/CD platform like `GitHub Actions`, `GitLab CI`, or `Jenkins` to automate the build, test, and deployment process.\n    - Configure your CI/CD pipeline to run linters, formatters, and tests.\n    - Use a deployment strategy like blue-green deployment or canary deployment.\n\nBy adhering to these best practices, you can develop robust, scalable, and maintainable applications using the Sanic framework. Remember to stay updated with the latest Sanic documentation and community recommendations.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "sanic.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "sanic",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sanic",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-scikit-image",
    "description": "This rule provides guidelines for best practices and coding standards when using the scikit-image library for image processing in Python. It covers code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "scikit-image",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/scikit-image.mdc",
    "content": "- Always use UV when installing dependencies for faster and more deterministic dependency resolution.\n- Always use Python 3.12 or later to leverage the latest language features and performance improvements.\n- Utilize classes instead of standalone functions where appropriate for better code organization and encapsulation, especially when dealing with stateful image processing operations.\n\n## Scikit-image Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for using the scikit-image library in Python for image processing. Following these guidelines will help ensure code clarity, maintainability, performance, and security.\n\n### Library Information:\n- Name: scikit-image\n- Tags: python, image-processing, scientific-computing\n\n### 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - Adopt a modular directory structure to organize your scikit-image projects.\n    - Example:\n      \n      project_name/\n          ├── data/          # Contains image data (e.g., input images, sample datasets)\n          ├── src/           # Source code directory\n          │   ├── __init__.py  # Marks src as a Python package\n          │   ├── modules/\n          │   │   ├── __init__.py\n          │   │   ├── image_io.py   # Image input/output related functions\n          │   │   ├── processing.py # Core image processing algorithms\n          │   │   ├── segmentation.py # Segmentation algorithms\n          │   │   └── feature.py    # Feature extraction modules\n          │   ├── utils.py       # Utility functions\n          │   └── main.py        # Main application entry point\n          ├── tests/         # Unit and integration tests\n          │   ├── __init__.py\n          │   ├── test_image_io.py\n          │   ├── test_processing.py\n          │   └── test_segmentation.py\n          ├── notebooks/    # Jupyter notebooks for exploration\n          ├── requirements.txt # Project dependencies\n          ├── pyproject.toml   # Project metadata and build system\n          └── README.md      # Project documentation\n      \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - Module files: `image_io.py`, `processing.py`, `segmentation.py`\n    - Test files: `test_image_io.py`, `test_processing.py`\n    - Utility files: `utils.py`\n\n- **Module Organization:**\n    - Group related functions and classes into modules.\n    - Avoid monolithic modules; break down large modules into smaller, more manageable ones.\n    - Use `__init__.py` files to define packages and control namespace exposure.\n    - Example (in `src/modules/processing.py`):\n      python\n      from skimage import filters\n      from skimage import morphology\n      import numpy as np\n\n      def apply_threshold(image, threshold_value=128):\n          \"\"\"Applies a simple threshold to an image.\"\"\"\n          return image > threshold_value\n\n      def remove_small_objects(binary_image, min_size=100):\n          \"\"\"Removes small connected components from a binary image.\"\"\"\n          return morphology.remove_small_objects(binary_image, min_size=min_size)\n      \n\n- **Component Architecture:**\n    - Design components with clear responsibilities and well-defined interfaces.\n    - Favor composition over inheritance for greater flexibility.\n    - Use abstract base classes (ABCs) to define interfaces for components.\n    - Example:\n      python\n      from abc import ABC, abstractmethod\n\n      class ImageProcessor(ABC):\n          @abstractmethod\n          def process_image(self, image):\n              pass\n\n      class GrayscaleConverter(ImageProcessor):\n          def process_image(self, image):\n              from skimage.color import rgb2gray\n              return rgb2gray(image)\n      \n\n- **Code Splitting Strategies:**\n    - Decompose complex image processing pipelines into smaller, reusable functions.\n    - Use generators or iterators for processing large images in chunks.\n    - Consider using multiprocessing or multithreading for parallel processing of image regions.\n    - Utilize lazy loading techniques for large image datasets.\n\n### 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - **Factory Pattern:** Use factory functions or classes to create image processing objects.\n    - **Strategy Pattern:** Implement different image processing algorithms as strategies that can be swapped at runtime.\n    - **Observer Pattern:** Notify observers when an image processing operation completes.\n\n- **Recommended Approaches:**\n    - Use NumPy arrays as the primary data structure for image representation.\n    - Leverage scikit-image's functional API for modular and composable image processing pipelines.\n    - Use `img_as_float` or other data type conversion utilities to ensure consistent data types.\n    - Document image processing functions and classes using docstrings.\n\n- **Anti-patterns and Code Smells:**\n    - **Global State:** Avoid using global variables to store image data or processing parameters.\n    - **Magic Numbers:** Use named constants instead of hardcoded numerical values.\n    - **Deeply Nested Loops:** Optimize image processing loops using NumPy's vectorized operations.\n    - **Ignoring Data Types:** Always be aware of the data types of images and intermediate results.\n    - **Over-Complicating Code:** Aim for simplicity and readability in your image processing code.\n\n- **State Management:**\n    - Encapsulate state within classes or data structures.\n    - Use immutable data structures where possible.\n    - Avoid modifying image data in-place unless necessary.\n\n- **Error Handling:**\n    - Use try-except blocks to handle potential exceptions (e.g., file I/O errors, invalid image formats).\n    - Log errors and warnings using the `logging` module.\n    - Provide informative error messages to the user.\n    - Consider custom exception types for scikit-image related errors.\n    - Example:\n        python\n        import logging\n        from skimage import io\n\n        logging.basicConfig(level=logging.ERROR)\n\n        def load_image(filepath):\n            try:\n                image = io.imread(filepath)\n                return image\n            except FileNotFoundError:\n                logging.error(f\"File not found: {filepath}\")\n                return None\n            except Exception as e:\n                logging.exception(f\"Error loading image: {e}\")\n                return None\n        \n\n### 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - Vectorize image processing operations using NumPy's broadcasting and array manipulation features.\n    - Use Cython to optimize performance-critical sections of code.\n    - Explore Numba for just-in-time (JIT) compilation of image processing functions.\n    - Utilize `skimage.util.apply_parallel` for parallel processing of image regions.\n    - Example using NumPy vectorization:\n      python\n      import numpy as np\n\n      def brighten_image(image, factor=1.5):\n          \"\"\"Brightens an image by multiplying each pixel by a factor.\"\"\"\n          return np.clip(image * factor, 0, 255).astype(image.dtype) # Clip values to valid range\n      \n\n- **Memory Management:**\n    - Use appropriate data types to minimize memory usage (e.g., `uint8` for grayscale images).\n    - Release large image arrays when they are no longer needed.\n    - Avoid creating unnecessary copies of image data.\n    - Consider using memory-mapped arrays for very large images.\n\n- **Rendering Optimization:**\n    - Optimize image display using appropriate colormaps and scaling.\n    - Use hardware acceleration (e.g., OpenGL) for faster rendering.\n\n- **Bundle Size Optimization:**\n    - Minimize dependencies in your scikit-image projects.\n    - Use tree shaking to remove unused code from your bundles.\n    - Compress image assets using appropriate compression algorithms.\n\n- **Lazy Loading:**\n    - Load large images only when they are needed.\n    - Use generators or iterators to process images in chunks.\n    - Implement caching mechanisms to avoid redundant image loading.\n\n### 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n    - **Denial-of-Service (DoS) Attacks:** Protect against DoS attacks by limiting the size of input images.\n    - **Code Injection:** Sanitize user-provided image processing parameters to prevent code injection attacks.\n\n- **Input Validation:**\n    - Validate the format, size, and data type of input images.\n    - Check for malicious image headers or metadata.\n    - Sanitize user-provided parameters to prevent code injection.\n    - Example:\n      python\n      from skimage import io\n\n      def process_image(filepath, resize_factor):\n          if not isinstance(resize_factor, (int, float)):\n              raise ValueError(\"Resize factor must be a number.\")\n          if resize_factor <= 0:\n              raise ValueError(\"Resize factor must be positive.\")\n\n          try:\n              image = io.imread(filepath)\n              # Perform image processing operations using resize_factor\n          except Exception as e:\n              print(f\"Error processing image: {e}\")\n      \n\n- **Authentication and Authorization:**\n    - Implement authentication and authorization mechanisms to control access to image processing resources.\n    - Use secure protocols (e.g., HTTPS) for API communication.\n\n- **Data Protection:**\n    - Encrypt sensitive image data at rest and in transit.\n    - Implement access control policies to protect image data.\n    - Use secure storage mechanisms for image data.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement rate limiting to prevent abuse.\n    - Use input validation to prevent injection attacks.\n\n### 5. Testing Approaches:\n\n- **Unit Testing:**\n    - Write unit tests for individual functions and classes.\n    - Use mocking and stubbing to isolate components during testing.\n    - Test edge cases and boundary conditions.\n\n- **Integration Testing:**\n    - Write integration tests to verify the interaction between components.\n    - Test complex image processing pipelines.\n    - Use realistic test data.\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the entire application workflow.\n    - Use automated testing frameworks (e.g., Selenium).\n\n- **Test Organization:**\n    - Organize tests into separate directories for unit, integration, and end-to-end tests.\n    - Use descriptive test names.\n    - Follow a consistent testing style.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`) to replace external dependencies with mock objects.\n    - Use stubbing to provide predefined outputs for specific function calls.\n\n### 6. Common Pitfalls and Gotchas:\n\n- **Data Type Issues:**\n    - Be aware of the data types of images and intermediate results.\n    - Use `img_as_float` or other data type conversion utilities to ensure consistent data types.\n    - Pay attention to data type ranges (e.g., 0-255 for `uint8`, 0.0-1.0 for float).\n\n- **Coordinate Conventions:**\n    - Understand the coordinate conventions used by scikit-image (row, col) and NumPy.\n\n- **Memory Consumption:**\n    - Avoid creating unnecessary copies of image data.\n    - Process large images in chunks or tiles.\n\n- **Version Compatibility:**\n    - Be aware of version-specific API changes and deprecations.\n    - Check scikit-image's changelog for breaking changes.\n\n- **Image I/O Issues:**\n    - Use appropriate image formats for your application.\n    - Handle file I/O errors gracefully.\n\n### 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - IDE: VS Code, PyCharm\n    - Debugger: pdb, ipdb\n    - Profiler: cProfile, line_profiler\n\n- **Build Configuration:**\n    - Use `pyproject.toml` to manage project metadata and build dependencies.\n    - Use `requirements.txt` to specify project dependencies.\n\n- **Linting and Formatting:**\n    - Use a linter (e.g., flake8, pylint) to enforce coding style and detect errors.\n    - Use a formatter (e.g., black, autopep8) to automatically format code.\n    - Configure your IDE to run linters and formatters automatically.\n\n- **Deployment:**\n    - Use virtual environments to isolate project dependencies.\n    - Containerize your scikit-image applications using Docker.\n    - Deploy your applications to cloud platforms (e.g., AWS, Azure, GCP).\n\n- **CI/CD Integration:**\n    - Use a CI/CD pipeline (e.g., GitHub Actions, GitLab CI, Jenkins) to automate testing, building, and deployment.\n    - Run linters, formatters, and tests in your CI/CD pipeline.\n    - Use code coverage tools to measure the effectiveness of your tests.\n\nBy adhering to these best practices, you can develop robust, maintainable, and performant image processing applications using the scikit-image library.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "scikit-image.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "scikit",
      "image",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "coding",
      "standards",
      "when",
      "using",
      "scikit-image",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "scikit-image",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-scikit-learn",
    "description": "Enforces best practices and coding standards for scikit-learn projects, promoting maintainability, performance, and security. This rule provides guidelines on code organization, common patterns, performance optimization, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "scikit-learn",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/scikit-learn.mdc",
    "content": "# Scikit-learn Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing with scikit-learn, aiming to improve code quality, maintainability, performance, and security.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - Organize your project into logical modules or components. A typical structure might include:\n        - `src/`: Source code for your project.\n            - `models/`: Contains the implementation of machine learning models.\n            - `features/`: Feature engineering and processing logic.\n            - `utils/`: Utility functions and helper modules.\n        - `data/`: Datasets used for training and testing.\n            - `raw/`: Original, unprocessed data.\n            - `processed/`: Cleaned and preprocessed data.\n        - `notebooks/`: Jupyter notebooks for experimentation and analysis.\n        - `tests/`: Unit and integration tests.\n        - `scripts/`: Scripts for training, evaluation, and deployment.\n        - `config/`: Configuration files (e.g., YAML, JSON).\n    - Example:\n\n      \n      project_root/\n      ├── src/\n      │   ├── models/\n      │   │   ├── __init__.py\n      │   │   ├── model_1.py\n      │   │   └── model_2.py\n      │   ├── features/\n      │   │   ├── __init__.py\n      │   │   ├── feature_engineering.py\n      │   │   └── feature_selection.py\n      │   ├── utils/\n      │   │   ├── __init__.py\n      │   │   └── helpers.py\n      │   ├── __init__.py\n      │   └── main.py\n      ├── data/\n      │   ├── raw/\n      │   │   └── data.csv\n      │   └── processed/\n      │       └── processed_data.csv\n      ├── notebooks/\n      │   └── exploratory_data_analysis.ipynb\n      ├── tests/\n      │   ├── __init__.py\n      │   ├── test_models.py\n      │   └── test_features.py\n      ├── scripts/\n      │   ├── train.py\n      │   └── evaluate.py\n      ├── config/\n      │   └── config.yaml\n      ├── README.md\n      └── requirements.txt\n      \n\n- **File Naming Conventions:**\n    - Use descriptive and consistent names for files and modules.\n    - Prefer snake_case for Python files and variables (e.g., `model_training.py`, `n_samples`).\n\n- **Module Organization:**\n    - Each module should have a clear and specific purpose.\n    - Use `__init__.py` files to define packages and modules within directories.\n    - Minimize dependencies between modules to improve maintainability.\n\n- **Component Architecture:**\n    - Design your application with loosely coupled components.\n    - Implement interfaces or abstract classes to define contracts between components.\n    - Use dependency injection to manage dependencies and promote testability.\n\n- **Code Splitting Strategies:**\n    - Split large files into smaller, more manageable modules.\n    - Group related functions and classes into modules based on functionality.\n    - Consider splitting code based on layers (e.g., data access, business logic, presentation).\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Pipeline:** Use scikit-learn's `Pipeline` class to chain together multiple data preprocessing and modeling steps. This helps prevent data leakage and ensures consistent data transformations.\n    - **Model Selection:** Employ techniques like cross-validation and grid search to select the best model and hyperparameters for your data. Use `GridSearchCV` or `RandomizedSearchCV`.\n    - **Ensemble Methods:** Leverage ensemble methods like Random Forests, Gradient Boosting, and Voting Classifiers to improve model accuracy and robustness.\n    - **Custom Transformers:** Create custom transformers using `BaseEstimator` and `TransformerMixin` to encapsulate complex feature engineering logic.\n\n- **Recommended Approaches:**\n    - **Data Preprocessing:** Always split your data into training and testing sets *before* any preprocessing steps.\n    - **Feature Scaling:** Apply appropriate feature scaling techniques (e.g., StandardScaler, MinMaxScaler) to numerical features before training models.\n    - **Categorical Encoding:** Use one-hot encoding or ordinal encoding for categorical features.\n    - **Missing Value Imputation:** Handle missing values using imputation techniques like mean, median, or k-NN imputation.\n    - **Model Persistence:** Save trained models to disk using `joblib` or `pickle` for later use.\n\n- **Anti-patterns and Code Smells:**\n    - **Data Leakage:** Avoid data leakage by preprocessing the entire dataset before splitting into training and testing sets.\n    - **Overfitting:** Be cautious of overfitting by using regularization techniques and cross-validation.\n    - **Ignoring Data Distributions:**  Always visualize and understand data distributions before applying transformations or choosing models.\n    - **Hardcoding Parameters:** Avoid hardcoding parameters directly in the code. Use configuration files or command-line arguments instead.\n    - **Ignoring Warnings:** Pay attention to scikit-learn warnings, as they often indicate potential problems with your code or data.\n\n- **State Management:**\n    - Use classes to encapsulate state and behavior related to models or data processing steps.\n    - Avoid global variables and mutable state whenever possible.\n    - Use immutable data structures where appropriate to prevent unintended side effects.\n\n- **Error Handling:**\n    - Use try-except blocks to handle exceptions and prevent your application from crashing.\n    - Log errors and warnings to a file or logging service.\n    - Provide informative error messages to users.\n    - Implement retry mechanisms for transient errors.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Vectorization:** Utilize NumPy's vectorized operations to perform calculations on entire arrays instead of looping through individual elements. Use `.values` from pandas DataFrames when passing to scikit-learn.\n    - **Memory Optimization:** Minimize memory usage by using appropriate data types (e.g., `int8`, `float32`) and avoiding unnecessary copies of data.\n    - **Algorithm Selection:** Choose efficient algorithms that are well-suited for your data and task. For example, use `MiniBatchKMeans` for large datasets.\n    - **Parallelization:** Use scikit-learn's built-in support for parallel processing to speed up training and prediction.\n\n- **Memory Management:**\n    - Use memory profiling tools to identify memory leaks and optimize memory usage.\n    - Release unused memory by deleting variables or using the `gc` module.\n    - Use data streaming techniques for large datasets that don't fit into memory.\n\n- **Lazy Loading Strategies:**\n    - Load data and models only when they are needed.\n    - Use generators or iterators to process large datasets in chunks.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Model Poisoning:** Protect against model poisoning attacks by validating input data and sanitizing user-provided data.\n    - **Adversarial Attacks:** Be aware of adversarial attacks that can manipulate model predictions. Consider using techniques like adversarial training to improve model robustness.\n\n- **Input Validation:**\n    - Validate all input data to ensure it conforms to the expected format and range.\n    - Sanitize user-provided data to prevent injection attacks.\n\n- **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use access control mechanisms to restrict access to data and models.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n    - Write unit tests for individual functions and classes.\n    - Use mocking to isolate components and test them in isolation.\n    - Assert that your code produces the expected output for different inputs.\n\n- **Integration Testing:**\n    - Write integration tests to verify that different components work together correctly.\n    - Test the interaction between your code and external dependencies.\n\n- **Test Organization:**\n    - Organize your tests into a separate directory (e.g., `tests`).\n    - Use descriptive names for your test files and functions.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries like `unittest.mock` or `pytest-mock` to create mock objects for testing.\n    - Use stubs to replace complex dependencies with simpler implementations.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Data Type Mismatches:** Ensure that the data types of your input features are compatible with the model you are using.\n- **Feature Scaling Issues:** Use the correct scaling method for your features, understanding how each scaler behaves.\n- **Improper Cross-Validation:** Make sure the cross-validation strategy you choose is appropriate for your dataset and model.\n- **Version Compatibility:** Be aware of compatibility issues between different versions of scikit-learn and its dependencies.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **IDE:** Use an IDE like VS Code, PyCharm, or JupyterLab.\n    - **Version Control:** Use Git for version control.\n    - **Package Manager:** Use pip or Conda for managing dependencies.\n    - **Virtual Environments:** Create virtual environments for each project to isolate dependencies.\n\n- **Linting and Formatting:**\n    - Use linters like pylint or flake8 to enforce code style and identify potential errors.\n    - Use formatters like black or autopep8 to automatically format your code.\n\n- **CI/CD Integration:**\n    - Integrate your code with a CI/CD system like Jenkins, Travis CI, or CircleCI.\n    - Automatically run tests and linters on every commit.\n    - Deploy your application to a production environment automatically.\n\n## General Coding Style\n- Use underscores to separate words in non-class names: `n_samples` rather than `nsamples`.\n- Avoid multiple statements on one line.\n- Use relative imports for references inside scikit-learn (except for unit tests, which should use absolute imports).\n\nBy following these best practices, you can write cleaner, more maintainable, and more efficient scikit-learn code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "scikit-learn.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "scikit",
      "learn",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "promoting",
      "maintainability",
      "scikit-learn",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "scikit-learn",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-scipy",
    "description": "This rule outlines coding standards, best practices, and common pitfalls for developing scientific computing applications using the SciPy library. It emphasizes clarity, maintainability, performance, and security for efficient SciPy development.",
    "author": "sanjeed5",
    "tags": [
      "scipy",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/scipy.mdc",
    "content": "- Adhere to PEP 8 style guidelines for Python code. This includes consistent indentation (4 spaces), line length (79 characters for code, 72 for docstrings), and naming conventions (e.g., `lower_case_with_underscores` for functions and variables, `CamelCase` for classes).\n- Write comprehensive docstrings for all functions, classes, and modules. Docstrings should follow the NumPy/SciPy docstring standard, detailing parameters, return values, and examples.\n- Use meaningful and descriptive variable names to enhance code readability. Avoid single-character variable names (except for loop counters) and abbreviations that are not widely understood.\n- Break down complex tasks into smaller, modular functions. Each function should have a single, well-defined purpose.\n- Employ object-oriented programming principles (classes, inheritance, polymorphism) when appropriate to structure and organize your code.\n- Implement unit tests for all critical functions and classes. Use the `unittest` or `pytest` framework to ensure code correctness and prevent regressions.\n- Utilize version control (e.g., Git) to track changes, collaborate effectively, and manage different versions of your code.\n- Comment your code to explain complex logic, algorithms, or design decisions. Comments should be concise and up-to-date.\n- Employ virtual environments (e.g., `venv` or `conda`) to manage project dependencies and ensure reproducibility.\n- Use a linter (e.g., `flake8` or `pylint`) to automatically check your code for style violations, errors, and potential bugs.\n- Format your code using a formatter (e.g., `black` or `autopep8`) to ensure consistent code style.\n- Consider using type hints (using `typing` module) to improve code readability and catch type-related errors early on.\n- Be mindful of performance considerations when using SciPy functions. Vectorize operations whenever possible to avoid explicit loops.\n- Choose appropriate SciPy functions and algorithms based on the specific problem and data characteristics.\n- Avoid unnecessary data copies to minimize memory usage and improve performance.\n- Utilize SciPy's sparse matrix functionality when dealing with large, sparse datasets.\n- Profile your code using tools like `cProfile` to identify performance bottlenecks.\n- Consider using Numba or Cython to accelerate computationally intensive SciPy code.\n- Implement error handling using `try...except` blocks to gracefully handle exceptions and prevent program crashes.\n- Log errors and warnings using the `logging` module to facilitate debugging and monitoring.\n- Validate user inputs to prevent security vulnerabilities, such as code injection or data corruption.\n- Store sensitive data securely using appropriate encryption and access control mechanisms.\n- Keep your SciPy library up-to-date to benefit from bug fixes, performance improvements, and new features.\n- Be aware of the compatibility between different versions of SciPy and other libraries in your project.\n- Refer to the SciPy documentation and community resources for guidance and best practices.\n- Avoid modifying SciPy arrays in place when it can lead to unexpected side effects. Instead, create copies of the arrays and perform the modifications on the copies.\n- When working with random numbers, use `numpy.random.default_rng()` for more modern and controllable random number generation.\n- When writing custom functions that operate on NumPy arrays, make sure to handle different data types correctly.\n- When possible, avoid creating intermediate arrays, by chaining operations and making the maximum use of SciPy functions features. This can decrease memory consumption especially on large arrays.\n- Use the `optimize` module functions whenever possible to avoid manual implementation of optimization algorithms.\n- Use sparse matrices when working with large matrices that have mostly zero values. This will save memory and improve performance.\n- Use the `fft` module for fast Fourier transforms when working with signals and images.\n- Use the `signal` module for signal processing tasks such as filtering, windowing, and spectral analysis.\n- Use the `ndimage` module for image processing tasks such as filtering, segmentation, and feature extraction.\n- Use the `integrate` module for numerical integration tasks such as quadrature and differential equation solving.\n- Use the `interpolate` module for interpolation tasks such as spline interpolation and polynomial interpolation.\n- Use the `stats` module for statistical analysis tasks such as hypothesis testing, probability distributions, and regression analysis.\n- When selecting a statistical test, ensure it's appropriate for your data type (continuous vs. discrete) and number of samples, and take care to interpret p-values correctly.\n- Do not assume that optimized SciPy functions automatically make your overall code efficient; always profile your code.\n- Be cautious when combining SciPy functions with external C/C++ code, ensuring data type consistency and memory management.\n- Document and share your SciPy-based code using appropriate version control and licensing to facilitate collaboration.\n- If you encounter performance issues with SciPy functions, consider trying alternative algorithms or implementations. Different problems may require different solutions.\n- Remember that NumPy is a dependency of SciPy. SciPy builds upon NumPy; leverage the strengths of both libraries in your code. Master basic NumPy array manipulation before diving deeply into SciPy.\n- Make sure to always use `pip install -U scipy` when installing or upgrading scipy package.\n- If possible try to use conda to install dependencies. The management of binary dependencies is much simpler to solve.\n- When collaborating with others, define common interfaces and expectations on what can be changed and what cannot. Do not change interfaces without notifying the other developers.\n- Separate the code from data. Do not include hardcoded data or configuration into the code. Use files, databases, or environment variables.\n- Use code reviews whenever is possible. Code reviews are useful not only to detect errors and bugs, but also to share knowledge and best practices.\n- When generating documentation, if possible add badges that show the test coverage and the status of continuous integration.\n- Test numerical code with randomized inputs to ensure code stability. Numerical algorithms are difficult to be completely covered only with fixed test cases.\n- Try to avoid global shared mutable state, specially if your application needs to run in parallel.\n- Try to use parallelization to improve your code efficiency, but be careful with shared mutable state. Use message passing to synchronize data between processes or threads.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "scipy.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "scipy",
      "this",
      "rule",
      "outlines",
      "coding",
      "standards",
      "best",
      "practices",
      "common",
      "pitfalls",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "scipy",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-scrapy",
    "description": "This rule provides comprehensive best practices for Scrapy development, including code organization, performance, security, testing, and common pitfalls to avoid. It aims to guide developers in building robust, efficient, and maintainable web scraping applications with Scrapy.",
    "author": "sanjeed5",
    "tags": [
      "scrapy",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/scrapy.mdc",
    "content": "# Scrapy Best Practices\n\nThis document outlines the recommended best practices for developing Scrapy web scraping applications. Following these guidelines will help you create robust, efficient, secure, and maintainable scrapers.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n-   **Project Root:** Contains `scrapy.cfg`, project directory, and any `README.md`, `LICENSE`, or other project-level files.\n-   **Project Directory (e.g., `my_project`):**\n    -   `__init__.py`:  Marks the directory as a Python package.\n    -   `items.py`: Defines the data structures (Scrapy Items) for the scraped data.\n    -   `middlewares.py`:  Contains the Scrapy middleware components, used for request/response processing.\n    -   `pipelines.py`:  Defines the data processing pipelines, used for cleaning, validating, and storing the scraped data.\n    -   `settings.py`:  Configures the Scrapy project, including settings for pipelines, middleware, concurrency, etc.\n    -   `spiders/`:\n        -   `__init__.py`:  Marks the directory as a Python package.\n        -   `my_spider.py`: Contains the spider definitions (Scrapy Spiders) responsible for crawling and scraping data.\n\nExample:\n\n\nmy_project/\n├── scrapy.cfg\n├── my_project/\n│   ├── __init__.py\n│   ├── items.py\n│   ├── middlewares.py\n│   ├── pipelines.py\n│   ├── settings.py\n│   └── spiders/\n│       ├── __init__.py\n│       └── my_spider.py\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n-   **Spider Files:** `spider_name.py` (e.g., `product_spider.py`, `news_spider.py`)\n-   **Item Files:** `items.py` (standard naming)\n-   **Middleware Files:** `middlewares.py` (standard naming)\n-   **Pipeline Files:** `pipelines.py` (standard naming)\n-   **Settings Files:** `settings.py` (standard naming)\n\n### 1.3. Module Organization\n\n-   **Small Projects:** All spiders can reside in the `spiders/` directory.\n-   **Large Projects:** Consider organizing spiders into subdirectories based on the target website or data type (e.g., `spiders/news/`, `spiders/ecommerce/`).\n-   **Custom Modules:** Create custom modules (e.g., `utils/`, `lib/`) for reusable code, helper functions, and custom classes.\n\n### 1.4. Component Architecture\n\n-   **Spiders:** Focus on crawling and extracting raw data.\n-   **Items:** Define the structure of the scraped data.\n-   **Pipelines:** Handle data cleaning, validation, transformation, and storage.\n-   **Middleware:** Manage request/response processing, error handling, and proxy management.\n\n### 1.5. Code Splitting\n\n-   **Separate Concerns:**  Keep spiders lean and focused on crawling logic. Move data processing and storage to pipelines.\n-   **Reusable Components:**  Extract common functionality (e.g., custom item loaders, helper functions) into separate modules or classes.\n-   **Configuration:**  Use `settings.py` to manage project-wide configuration and avoid hardcoding values in spiders.\n-   **Modular Middleware:** Create small, focused middleware components for specific tasks (e.g., user agent rotation, request retries).\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n-   **Strategy Pattern:** Use different parsing strategies within a spider based on the page structure or data type.\n-   **Factory Pattern:** Create a factory function to instantiate items with default values or based on specific criteria.\n-   **Singleton Pattern:** (Use sparingly) For global resources like database connections, consider using a singleton pattern, but ensure thread safety.\n-   **Observer Pattern:** Use Scrapy signals to trigger actions based on specific events (e.g., item scraped, spider closed).\n\n### 2.2. Recommended Approaches\n\n-   **Item Loaders:** Use Item Loaders to populate items with extracted data, providing data validation and cleaning.\n-   **CSS and XPath Selectors:**  Master CSS and XPath selectors for efficient data extraction.\n-   **Response Objects:**  Utilize the methods provided by the `response` object (e.g., `css()`, `xpath()`, `urljoin()`, `follow()`).\n-   **Asynchronous Operations:**  Understand Scrapy's asynchronous nature and use deferreds for handling asynchronous tasks (though Scrapy abstracts a lot of this away).\n-   **Robots.txt:** Respect the robots.txt file and configure `ROBOTSTXT_OBEY` accordingly.\n-   **Settings:** Centralize settings in `settings.py` instead of hardcoding values.\n\n### 2.3. Anti-patterns and Code Smells\n\n-   **Hardcoded Values:** Avoid hardcoding URLs, selectors, or other configuration values directly in the code.\n-   **Overly Complex Spiders:** Keep spiders focused on crawling.  Move complex data processing to pipelines.\n-   **Ignoring Errors:**  Implement proper error handling and logging to identify and address issues.\n-   **Excessive Logging:**  Avoid verbose logging that can impact performance. Use appropriate log levels (DEBUG, INFO, WARNING, ERROR).\n-   **Blocking Operations:** Avoid blocking operations (e.g., synchronous network requests) in spiders, as they can significantly reduce performance. Let Scrapy handle the concurrency.\n-   **Unnecessary Recursion:** Overly complex recursion within `parse` methods can lead to stack overflow errors.\n-   **Abusing Global State:** Avoid overly relying on global variables, since Scrapy manages concurrency it can lead to race conditions or unpredictable spider behavior.\n\n### 2.4. State Management\n\n-   **Spider Attributes:** Store spider-specific state in spider attributes (e.g., current page number, filters).\n-   **Request.meta:** Use `Request.meta` to pass data between callbacks (e.g., passing data extracted from one page to the next).\n-   **Settings:** Use Scrapy settings to manage project-level configuration.\n-   **External Databases/Caches:** For persistent state or data sharing between spiders, consider using an external database or cache (e.g., Redis).\n\n### 2.5. Error Handling\n\n-   **`try...except` Blocks:** Use `try...except` blocks to handle potential exceptions during data extraction or processing.\n-   **Scrapy Logging:** Utilize Scrapy's logging system to record errors, warnings, and informational messages.\n-   **Retry Middleware:** Configure the Retry Middleware to automatically retry failed requests.\n-   **Error Handling in Pipelines:** Implement error handling in pipelines to catch and log errors during data processing.\n-   **Error Handling in Middlewares:** Implement error handling in middleware to deal with request or response issues\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n-   **Concurrency:** Adjust `CONCURRENT_REQUESTS`, `CONCURRENT_REQUESTS_PER_DOMAIN`, and `DOWNLOAD_DELAY` to optimize crawling speed while avoiding server overload.\n-   **Item Pipelines:** Optimize item pipelines for efficient data processing and storage.\n-   **Caching:** Use HTTP caching to avoid re-downloading unchanged pages (`HTTPCACHE_ENABLED = True`).\n-   **Offsite Middleware:** Enable the Offsite Spider Middleware to prevent crawling outside the allowed domains.\n-   **Keep-Alive:** Ensure HTTP keep-alive is enabled for persistent connections.\n-   **DNS Caching:** Optimize DNS resolution by enabling DNS caching.\n-   **Efficient Selectors:** Optimize XPath and CSS selectors for faster data extraction.\n-   **Asynchronous Request Handling:** Scrapy's asynchronous architecture handles concurrency, utilize it by avoid blocking operations\n\n### 3.2. Memory Management\n\n-   **Large Datasets:** For very large datasets, consider using Scrapy's built-in support for chunked responses or processing data in batches.\n-   **Avoid Storing Everything in Memory:** Process items in pipelines and avoid storing the entire scraped data in memory at once.\n-   **Limit Response Body Size:** Set `DOWNLOAD_MAXSIZE` to limit the maximum size of downloaded responses to prevent memory exhaustion.\n-   **Garbage Collection:** Manually trigger garbage collection if necessary to reclaim memory (use with caution).\n\n### 3.3. Rendering Optimization\n\n-   **Splash/Selenium:** If JavaScript rendering is required, use Scrapy Splash or Selenium, but be aware of the performance overhead.\n-   **Render Only When Necessary:**  Only render pages that require JavaScript execution. Avoid rendering static HTML pages.\n-   **Minimize Browser Interactions:**  Reduce the number of interactions with the browser (e.g., clicks, form submissions) to improve rendering performance.\n-   **Caching Rendered Results:** Cache rendered HTML to avoid redundant rendering.\n\n### 3.4. Bundle Size Optimization\n\n- Scrapy does not have bundles like web development frameworks, so this section does not apply.\n\n### 3.5. Lazy Loading\n\n-   **Pagination:** Implement pagination to crawl websites in smaller chunks.\n-   **Lazy Item Processing:** Defer item processing in pipelines until necessary to reduce memory consumption.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n-   **Cross-Site Scripting (XSS):** Sanitize scraped data before displaying it on a website to prevent XSS attacks. Don't output raw scraped content.\n-   **SQL Injection:** If storing scraped data in a database, use parameterized queries or ORMs to prevent SQL injection vulnerabilities.\n-   **Command Injection:** Avoid executing arbitrary commands based on scraped data to prevent command injection attacks.\n-   **Denial of Service (DoS):** Implement rate limiting and politeness policies to avoid overwhelming target websites.\n-   **Data Poisoning:** Validate scraped data to ensure its integrity and prevent data poisoning.\n\n### 4.2. Input Validation\n\n-   **Validate Scraped Data:**  Implement validation logic in item pipelines to ensure that scraped data conforms to expected formats and ranges.\n-   **Data Type Validation:**  Check the data type of scraped values to prevent unexpected errors.\n-   **Regular Expressions:**  Use regular expressions to validate string values and enforce specific patterns.\n\n### 4.3. Authentication and Authorization\n\n-   **HTTP Authentication:** Use Scrapy's built-in support for HTTP authentication to access password-protected websites.\n-   **Cookies:**  Manage cookies properly to maintain sessions and avoid authentication issues.\n-   **API Keys:**  Store API keys securely and avoid exposing them in the code.\n-   **OAuth:**  Implement OAuth authentication if required to access protected resources.\n\n### 4.4. Data Protection\n\n-   **Encryption:**  Encrypt sensitive data during storage and transmission.\n-   **Anonymization:**  Anonymize or pseudonymize personal data to protect user privacy.\n-   **Access Control:**  Implement access control mechanisms to restrict access to sensitive data.\n\n### 4.5. Secure API Communication\n\n-   **HTTPS:**  Always use HTTPS for secure communication with APIs.\n-   **SSL/TLS:**  Ensure that SSL/TLS certificates are properly configured.\n-   **API Authentication:**  Use API keys or tokens for authentication.\n-   **Rate Limiting:**  Implement rate limiting to prevent abuse and protect APIs.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n-   **Spider Logic:** Unit test individual components of spiders, such as selector logic, data extraction, and URL generation.\n-   **Item Pipelines:** Unit test item pipelines to verify data cleaning, validation, and transformation.\n-   **Middleware:** Unit test middleware components to ensure proper request/response processing.\n-   **Helper Functions:** Unit test helper functions to ensure correct behavior.\n\n### 5.2. Integration Testing\n\n-   **Spider Integration:** Integrate spiders with item pipelines to test the entire data flow.\n-   **Middleware Integration:** Integrate middleware components with spiders to test request/response handling.\n-   **External Services:** Integrate with external services (e.g., databases, APIs) to test data storage and retrieval.\n\n### 5.3. End-to-End Testing\n\n-   **Full Crawl:** Run a full crawl of the target website and verify that all data is extracted correctly.\n-   **Data Validation:** Validate the scraped data against expected values or schemas.\n-   **Performance Testing:** Measure the performance of the scraper and identify potential bottlenecks.\n\n### 5.4. Test Organization\n\n-   **Separate Test Directory:** Create a separate `tests/` directory to store test files.\n-   **Test Modules:** Organize tests into modules based on the component being tested (e.g., `tests/test_spiders.py`, `tests/test_pipelines.py`).\n-   **Test Fixtures:** Use test fixtures to set up test data and dependencies.\n\n### 5.5. Mocking and Stubbing\n\n-   **Mock Responses:** Mock HTTP responses to test spider logic without making actual network requests.\n-   **Stub External Services:** Stub external services (e.g., databases, APIs) to isolate components during testing.\n-   **Mock Item Pipelines:** Mock item pipelines to prevent actual data storage during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n-   **Incorrect Selectors:**  Using incorrect or brittle CSS/XPath selectors that break when the website structure changes.\n-   **Ignoring Robots.txt:**  Ignoring the `robots.txt` file and potentially violating the website's terms of service.\n-   **Overloading the Target Website:**  Making too many requests too quickly and potentially causing a denial of service.\n-   **Not Handling JavaScript:**  Failing to handle JavaScript-rendered content.\n-   **Not Handling Pagination:**  Failing to properly handle pagination and missing data from multiple pages.\n-   **Incorrectly handling Cookies:** Failing to persist or handle cookies properly can cause unpredictable behavior.\n\n### 6.2. Edge Cases\n\n-   **Website Structure Changes:**  Websites frequently change their structure, breaking existing scrapers. Implement robust selectors and monitoring to detect changes.\n-   **Anti-Scraping Measures:**  Websites may implement anti-scraping measures (e.g., CAPTCHAs, IP blocking) to prevent scraping. Use appropriate techniques to bypass these measures.\n-   **Dynamic Content:**  Websites may use dynamic content (e.g., AJAX, WebSockets) to load data. Use appropriate techniques to handle dynamic content.\n-   **Rate Limiting:**  Websites may implement rate limiting to restrict the number of requests from a single IP address. Use proxies or distributed crawling to overcome rate limits.\n\n### 6.3. Version-Specific Issues\n\n-   **Scrapy API Changes:**  Be aware of API changes between Scrapy versions and update your code accordingly.\n-   **Dependency Conflicts:**  Manage dependencies carefully to avoid conflicts between Scrapy and other libraries.\n-   **Python Version Compatibility:**  Ensure that your code is compatible with the supported Python versions.\n\n### 6.4. Compatibility Concerns\n\n-   **JavaScript Rendering Libraries:** Ensure that the JavaScript rendering library is compatible with the target website and Scrapy.\n-   **Data Storage Libraries:**  Ensure that the data storage library is compatible with Scrapy and the chosen data format.\n-   **Proxy Management Libraries:** Ensure that the proxy management library is compatible with Scrapy.\n\n### 6.5. Debugging Strategies\n\n-   **Scrapy Shell:** Use the Scrapy shell to test selectors and extract data interactively.\n-   **Logging:**  Use Scrapy's logging system to record errors, warnings, and informational messages.\n-   **Debugging Tools:** Use Python debugging tools (e.g., `pdb`, `ipdb`) to step through the code and inspect variables.\n-   **Middleware Debugging:** Use middleware to inspect requests and responses and identify potential issues.\n-   **Verbose Output:** Use `-v` or `-vv` when running spiders to get more verbose output.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n-   **IDE:**  Use a capable IDE such as VS Code, PyCharm, or Sublime Text.\n-   **Virtual Environment:**  Use virtual environments (e.g., `venv`, `conda`) to manage dependencies and isolate projects.\n-   **Scrapy Shell:** Use the Scrapy shell for interactive testing and debugging.\n-   **Browser Developer Tools:** Use browser developer tools to inspect website structure and identify selectors.\n\n### 7.2. Build Configuration\n\n-   **`setup.py`:** Use a `setup.py` file to define project dependencies and metadata for larger projects and for distribution.\n-   **`requirements.txt`:** Use a `requirements.txt` file to list project dependencies for easy installation.\n-   **`pip freeze`:** Use `pip freeze > requirements.txt` to generate a list of installed packages and their versions.\n\n### 7.3. Linting and Formatting\n\n-   **PEP 8:**  Follow PEP 8 style guidelines for code readability.\n-   **Linters:**  Use linters (e.g., `flake8`, `pylint`) to identify code style issues and potential errors.\n-   **Formatters:**  Use code formatters (e.g., `black`, `autopep8`) to automatically format code according to PEP 8.\n\n### 7.4. Deployment\n\n-   **Scrapyd:**  Use Scrapyd to deploy and manage Scrapy spiders on a server.\n-   **Docker:**  Use Docker to containerize Scrapy applications for easy deployment and scalability.\n-   **Cloud Platforms:**  Deploy Scrapy applications on cloud platforms such as AWS, Google Cloud, or Azure.\n-   **Scheduled Tasks:**  Use scheduled tasks (e.g., cron jobs) to run Scrapy spiders on a regular basis.\n\n### 7.5. CI/CD Integration\n\n-   **Testing:**  Integrate unit and integration tests into the CI/CD pipeline to ensure code quality.\n-   **Linting and Formatting:**  Integrate linters and formatters into the CI/CD pipeline to enforce code style.\n-   **Automated Deployment:**  Automate the deployment process to deploy new versions of the scraper automatically.\n-   **Monitoring:**  Integrate monitoring tools to track the performance and health of the scraper in production.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "scrapy.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "scrapy",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "development",
      "including",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "scrapy",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-seaborn",
    "description": "This rule provides best practices for coding standards in Seaborn, emphasizing clear, reproducible code, optimal performance, and secure data handling within AI and machine learning data science development.",
    "author": "sanjeed5",
    "tags": [
      "seaborn",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/seaborn.mdc",
    "content": "By following these best practices and coding standards, you can write clear, reproducible, and maintainable Seaborn code that is optimized for performance and security.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "seaborn.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "seaborn",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "emphasizing",
      "clear",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "seaborn",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-selenium",
    "description": "This rule provides best practices and coding standards for using the Selenium library in Python. It covers code organization, performance, security, testing, common pitfalls, and tooling to ensure maintainable and efficient Selenium projects.",
    "author": "sanjeed5",
    "tags": [
      "selenium",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/selenium.mdc",
    "content": "# Selenium Best Practices and Coding Standards\n\nThis guide outlines the best practices and coding standards for developing robust, maintainable, and efficient Selenium-based projects in Python.\n\nLibrary Information:\n- Name: Selenium\n- Tags: python, web-scraping, browser-automation, testing\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nAdopt a well-defined directory structure to maintain code clarity and modularity. A recommended structure includes:\n\n\nproject_root/\n├── src/\n│   ├── pages/\n│   │   ├── base_page.py  # Base class for all page objects\n│   │   ├── login_page.py # Page object for the login page\n│   │   ├── home_page.py  # Page object for the home page\n│   │   └── ...\n│   ├── components/\n│   │   ├── search_bar.py # Reusable component for the search bar\n│   │   ├── navigation.py # Reusable component for site navigation\n│   │   └── ...\n│   ├── utils/\n│   │   ├── config.py    # Configuration settings\n│   │   ├── logger.py    # Logging utilities\n│   │   ├── helpers.py   # Helper functions (e.g., element finding, waits)\n│   │   └── ...\n│   ├── drivers/\n│   │   ├── chromedriver.exe  # Or geckodriver.exe, etc.\n│   │   └── ...\n│   ├── __init__.py\n├── tests/\n│   ├── unit/\n│   │   ├── test_login_page.py  # Unit tests for the login page\n│   │   └── ...\n│   ├── integration/\n│   │   ├── test_home_page_integration.py # Integration tests\n│   │   └── ...\n│   ├── e2e/\n│   │   ├── test_login_flow.py # End-to-end tests for login flow\n│   │   └── ...\n│   ├── conftest.py # pytest configuration file\n│   ├── __init__.py\n├── requirements.txt\n├── README.md\n├── .gitignore\n└── ...\n\n\n- `src/`: Contains the main application code.\n  - `pages/`: Holds page object models.\n  - `components/`: Contains reusable UI components.\n  - `utils/`: Includes utility functions, configuration, and logging.\n  - `drivers/`: Stores browser driver executables.\n- `tests/`: Contains all test-related code.\n  - `unit/`: Unit tests.\n  - `integration/`: Integration tests.\n  - `e2e/`: End-to-end tests.\n  - `conftest.py`: pytest configuration file to manage fixtures, command-line options, and plugins.\n- `requirements.txt`: Lists project dependencies.\n- `README.md`: Project documentation.\n- `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n\n### 1.2. File Naming Conventions\n\n- **Python files:** Use lowercase with underscores (e.g., `login_page.py`, `base_page.py`).\n- **Classes:** Use PascalCase (e.g., `LoginPage`, `BasePage`).\n- **Functions/Methods:** Use lowercase with underscores (e.g., `login`, `get_title`).\n- **Variables:** Use lowercase with underscores (e.g., `username`, `password`).\n- **Constants:** Use uppercase with underscores (e.g., `DEFAULT_TIMEOUT`, `LOGIN_URL`).\n\n### 1.3. Module Organization\n\n- **Keep modules focused:** Each module should have a clear and specific purpose. Avoid creating large, monolithic modules.\n- **Use packages:** Group related modules into packages using `__init__.py` files.\n- **Explicit imports:** Use explicit imports (`from module import item`) rather than wildcard imports (`from module import *`) to improve code readability and prevent naming conflicts.\n- **Relative imports:** Use relative imports (`from . import module`) within packages to maintain internal dependencies.\n\n### 1.4. Component Architecture\n\n- **Page Object Model (POM):** Implement the Page Object Model design pattern for better code organization and maintainability. Each web page is represented as a class, and its elements and actions are defined as methods within that class.\n- **Reusable Components:** Identify and create reusable UI components (e.g., search bars, navigation menus) as separate classes or functions.\n- **Abstraction:** Abstract away Selenium-specific details (e.g., element locators, WebDriver calls) within page objects and components to make the code more resilient to UI changes.\n\n### 1.5. Code Splitting Strategies\n\n- **Functional Decomposition:** Break down complex tasks into smaller, more manageable functions.\n- **Class-Based Decomposition:** Use classes to encapsulate related data and behavior.\n- **Module-Based Decomposition:** Split code into separate modules based on functionality (e.g., page objects, utilities).\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **Page Object Model (POM):** As mentioned earlier, POM is crucial for Selenium projects. It promotes code reuse, reduces redundancy, and simplifies maintenance.\n- **Factory Pattern:** Use a factory pattern to create WebDriver instances with different configurations (e.g., different browsers, headless mode).\n- **Singleton Pattern:** Use a singleton pattern for configuration objects to ensure consistent access to settings throughout the project. However, be mindful of the potential for global state issues.\n- **Strategy Pattern:** Useful for implementing different waiting strategies (explicit vs. implicit) or different authentication methods.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n- **Finding Elements:**\n  - **Prioritize specific locators:** Use `ID`, `NAME`, or custom attributes whenever possible. They are usually more stable than `XPATH` or `CSS_SELECTOR`.\n  - **Use explicit waits:** Always use `WebDriverWait` to wait for elements to be present, visible, or clickable before interacting with them. This avoids common `NoSuchElementException` and `ElementNotInteractableException` errors.\n  - **Dynamic locators:** If necessary, use dynamic locators with caution, ensuring they are robust and unlikely to break with minor UI changes.\n- **Handling Forms:**\n  - **Clear input fields:** Always clear input fields using `element.clear()` before sending keys.\n  - **Submit forms correctly:** Use `element.submit()` on a form element to submit the form, rather than clicking a submit button. This handles edge cases more reliably.\n  - **Handle dropdowns:** Use the `Select` class to interact with dropdown menus.\n- **Handling Alerts and Popups:**\n  - **Switch to alerts:** Use `driver.switch_to.alert` to interact with JavaScript alerts and confirmation dialogs.\n  - **Handle windows:** Use `driver.switch_to.window` to switch between browser windows and tabs.\n\n### 2.3. Anti-patterns and Code Smells\n\n- **Implicit Waits:** Avoid using implicit waits (`driver.implicitly_wait`). They can lead to unpredictable behavior and make it difficult to debug timing issues. Prefer explicit waits using `WebDriverWait`.\n- **Hardcoded Waits:** Avoid using `time.sleep()` for waiting. It's unreliable and inefficient. Use explicit waits instead.\n- **Fragile Locators:** Avoid using overly complex or brittle locators that are prone to breaking with minor UI changes.\n- **Code Duplication:** Avoid duplicating code, especially locator definitions and common actions. Use POM and reusable components to reduce redundancy.\n- **Ignoring Exceptions:** Avoid catching exceptions without handling them properly. Log exceptions and re-raise them if necessary.\n- **Global State:** Minimize the use of global variables and shared state, which can make tests difficult to reason about and prone to conflicts.\n- **Over-reliance on XPATH:** While XPATH is powerful, avoid using overly complex XPATH expressions when simpler, more robust locators are available.\n- **Assuming Immediate Availability:** Don't assume elements are immediately available. Websites load asynchronously, and you need to explicitly wait for elements to appear.\n\n### 2.4. State Management\n\n- **Stateless Tests:** Design tests to be as stateless as possible. Each test should be independent and not rely on the state of previous tests.\n- **Fixture-Based Setup:** Use test fixtures (e.g., pytest fixtures) to set up and tear down test environments consistently.\n- **Avoid Shared WebDriver Instances:** Use a new WebDriver instance for each test or test suite to avoid conflicts and ensure isolation.\n- **Clear Cookies and Cache:** Clear cookies and cache before each test or test suite to start with a clean browser state.\n\n### 2.5. Error Handling\n\n- **Specific Exception Handling:** Catch specific Selenium exceptions (e.g., `NoSuchElementException`, `TimeoutException`) rather than general `Exception` to handle errors more precisely.\n- **Logging:** Log all exceptions and errors with detailed information (e.g., element locator, URL, screenshot).\n- **Retries:** Implement retry mechanisms for flaky tests or actions that may fail intermittently due to network issues or timing problems.\n- **Screenshots on Failure:** Capture screenshots when tests fail to aid in debugging and identify UI issues.\n- **Graceful Shutdown:** Ensure that WebDriver instances are properly closed and resources are released even when tests fail.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Headless Mode:** Run tests in headless mode (without a GUI) to reduce resource consumption and improve execution speed.\n- **Parallel Execution:** Run tests in parallel using a test runner that supports parallel execution (e.g., pytest-xdist).\n- **Efficient Locators:** Use the most efficient locators possible (e.g., `ID`, `NAME`) to minimize element lookup time.\n- **Lazy Loading:** If applicable, implement lazy loading for images and other resources to reduce initial page load time.\n- **Connection Pooling:**  If using a remote WebDriver, consider connection pooling to reuse connections and reduce overhead.\n\n### 3.2. Memory Management\n\n- **Close WebDriver Instances:** Ensure that WebDriver instances are properly closed after each test or test suite to release memory.\n- **Avoid Large Data Structures:** Avoid storing large amounts of data in memory during test execution.\n- **Use Generators:** Use generators for processing large datasets to avoid loading the entire dataset into memory at once.\n- **Garbage Collection:** Be aware of Python's garbage collection and consider using `gc.collect()` to force garbage collection if necessary.\n\n### 3.3. Rendering Optimization (If Applicable)\n\n- **Minimize DOM Manipulation:** Minimize DOM manipulation in JavaScript code to reduce rendering time.\n- **Optimize CSS:** Optimize CSS selectors and styles to reduce rendering time.\n- **Hardware Acceleration:** Enable hardware acceleration in the browser to improve rendering performance.\n\n### 3.4. Bundle Size Optimization (If Applicable)\n\n- **Tree Shaking:** Use tree shaking to remove unused code from JavaScript bundles.\n- **Code Splitting:** Split JavaScript bundles into smaller chunks that can be loaded on demand.\n- **Minification:** Minify JavaScript and CSS code to reduce bundle size.\n- **Compression:** Use gzip or Brotli compression to reduce the size of transferred resources.\n\n### 3.5. Lazy Loading\n\n- **Image Lazy Loading:** Implement lazy loading for images to improve initial page load time.\n- **Component Lazy Loading:** Lazy load components that are not immediately visible to the user.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n- **Cross-Site Scripting (XSS):** Prevent XSS attacks by properly escaping user input and avoiding the use of `eval()` or other unsafe JavaScript functions.\n- **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or ORM frameworks.\n- **Clickjacking:** Prevent clickjacking attacks by setting the `X-Frame-Options` header to `DENY` or `SAMEORIGIN`.\n- **Man-in-the-Middle (MITM):** Use HTTPS to encrypt communication between the client and server and prevent MITM attacks.\n\n### 4.2. Input Validation\n\n- **Validate All User Input:** Validate all user input on both the client-side and server-side to prevent malicious data from entering the system.\n- **Use Whitelists:** Use whitelists to define the allowed characters, formats, and values for user input.\n- **Escape User Input:** Escape user input before displaying it on the page to prevent XSS attacks.\n\n### 4.3. Authentication and Authorization\n\n- **Use Strong Passwords:** Enforce the use of strong passwords and store passwords securely using hashing algorithms (e.g., bcrypt).\n- **Multi-Factor Authentication (MFA):** Implement MFA to add an extra layer of security.\n- **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n- **Session Management:** Use secure session management techniques to prevent session hijacking.\n\n### 4.4. Data Protection\n\n- **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n- **Data Masking:** Mask sensitive data when displaying it on the page or in logs.\n- **Data Retention Policies:** Implement data retention policies to ensure that data is not stored longer than necessary.\n- **Access Control:** Implement strict access control policies to limit access to sensitive data.\n\n### 4.5. Secure API Communication\n\n- **Use HTTPS:** Use HTTPS to encrypt communication between the client and server.\n- **API Keys:** Use API keys to authenticate requests to external APIs.\n- **Rate Limiting:** Implement rate limiting to prevent abuse of APIs.\n- **Input Validation:** Validate all input to external APIs to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- **Test Individual Components:** Unit tests should focus on testing individual components (e.g., page objects, utilities) in isolation.\n- **Mock External Dependencies:** Mock external dependencies (e.g., WebDriver, APIs) to isolate the component being tested.\n- **Assert Expected Behavior:** Use assertions to verify that the component behaves as expected.\n- **Test Edge Cases:** Test edge cases and error conditions to ensure that the component is robust.\n\n### 5.2. Integration Testing\n\n- **Test Interactions Between Components:** Integration tests should focus on testing the interactions between different components.\n- **Use Real Dependencies:** Use real dependencies (e.g., WebDriver) to test the component's behavior in a realistic environment.\n- **Verify System Behavior:** Verify that the system as a whole behaves as expected.\n\n### 5.3. End-to-End Testing\n\n- **Test Complete Workflows:** End-to-end tests should focus on testing complete workflows from start to finish.\n- **Simulate User Interactions:** Simulate user interactions to test the system's behavior in a realistic scenario.\n- **Verify Business Requirements:** Verify that the system meets the business requirements.\n\n### 5.4. Test Organization\n\n- **Separate Test Files:** Create separate test files for each component or feature.\n- **Use Descriptive Names:** Use descriptive names for test files and test functions.\n- **Group Tests:** Group related tests into test suites or test classes.\n- **Use Test Fixtures:** Use test fixtures to set up and tear down test environments consistently.\n\n### 5.5. Mocking and Stubbing\n\n- **Mock WebDriver:** Mock the WebDriver instance to isolate components from the browser.\n- **Stub API Responses:** Stub API responses to test the component's behavior with different data.\n- **Verify Method Calls:** Verify that methods are called with the expected arguments.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Incorrect Locator Strategy:** Choosing the wrong locator strategy (e.g., relying on fragile XPATH expressions).\n- **Not Waiting for Elements:** Not waiting for elements to be present or visible before interacting with them.\n- **Ignoring Exceptions:** Ignoring exceptions and not handling errors properly.\n- **Code Duplication:** Duplicating code and not using reusable components.\n- **Global State:** Using global state and not isolating tests properly.\n\n### 6.2. Edge Cases\n\n- **Dynamic Content:** Handling dynamic content that changes frequently.\n- **Asynchronous Operations:** Dealing with asynchronous operations and race conditions.\n- **Complex User Interactions:** Simulating complex user interactions (e.g., drag and drop, file uploads).\n- **Cross-Browser Compatibility:** Ensuring that tests work correctly across different browsers.\n- **Mobile Testing:** Testing on mobile devices and emulators.\n\n### 6.3. Version-Specific Issues\n\n- **WebDriver Compatibility:** Ensuring that the WebDriver version is compatible with the browser version.\n- **Selenium API Changes:** Being aware of changes to the Selenium API in different versions.\n- **Python Version Compatibility:** Ensuring compatibility with the correct Python version.\n\n### 6.4. Compatibility Concerns\n\n- **Framework Conflicts:** Conflicts with other testing frameworks or libraries.\n- **Browser Extensions:** Interference from browser extensions.\n- **Operating System Differences:** Differences in behavior between different operating systems.\n\n### 6.5. Debugging Strategies\n\n- **Logging:** Use logging to track the execution of tests and identify errors.\n- **Screenshots:** Capture screenshots when tests fail to aid in debugging.\n- **Debugging Tools:** Use debugging tools to step through the code and inspect variables.\n- **Remote Debugging:** Use remote debugging to debug tests running on remote machines.\n- **Browser Developer Tools:** Utilize browser developer tools (e.g., Chrome DevTools) to inspect the DOM and network traffic.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **IDE:** PyCharm, VS Code with Python extension\n- **Test Runner:** pytest, unittest\n- **WebDriver Manager:** webdriver-manager\n- **Linter:** pylint, flake8\n- **Formatter:** black, autopep8\n- **Virtual Environment:** virtualenv, venv, conda\n\n### 7.2. Build Configuration\n\n- **Use a Build System:** Use a build system (e.g., Make, tox) to automate the build process.\n- **Define Dependencies:** Define project dependencies in a `requirements.txt` file.\n- **Use Virtual Environments:** Use virtual environments to isolate project dependencies.\n- **Configure Test Execution:** Configure test execution options (e.g., browser, headless mode, parallel execution) in a configuration file.\n\n### 7.3. Linting and Formatting\n\n- **Use a Linter:** Use a linter (e.g., pylint, flake8) to enforce coding standards and identify potential errors.\n- **Use a Formatter:** Use a formatter (e.g., black, autopep8) to automatically format code according to coding standards.\n- **Configure Editor Integration:** Configure editor integration to automatically run linters and formatters when saving files.\n\n### 7.4. Deployment\n\n- **Containerization:** Use containerization (e.g., Docker) to package the application and its dependencies into a single unit.\n- **Cloud Deployment:** Deploy the application to a cloud platform (e.g., AWS, Azure, GCP).\n- **Continuous Integration:** Integrate the deployment process with a continuous integration system.\n\n### 7.5. CI/CD Integration\n\n- **Use a CI/CD System:** Use a CI/CD system (e.g., Jenkins, Travis CI, CircleCI, GitHub Actions) to automate the build, test, and deployment process.\n- **Configure Triggers:** Configure triggers to automatically run the CI/CD pipeline when code is pushed to the repository.\n- **Automate Testing:** Automate the execution of unit tests, integration tests, and end-to-end tests in the CI/CD pipeline.\n- **Automate Deployment:** Automate the deployment process in the CI/CD pipeline.\n\nBy following these best practices, you can develop robust, maintainable, and efficient Selenium-based projects in Python.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "selenium.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "selenium",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "using",
      "library",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "selenium",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-sentry",
    "description": "This rule provides comprehensive best practices for integrating and utilizing Sentry in your projects. It covers code organization, performance, security, testing, and common pitfalls when using Sentry for error tracking and performance monitoring.",
    "author": "sanjeed5",
    "tags": [
      "sentry",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sentry.mdc",
    "content": "- Ensure that your codebase is connected to Sentry, with source code management integrations (e.g., GitHub, GitLab, Bitbucket) and source maps properly configured. This enables Sentry to link errors to specific lines of code, dramatically improving debugging efficiency.\n- Implement custom alerts tailored to your needs, avoiding alert fatigue by prioritizing alerts based on severity or user impact. Set up different notification channels for varying alert priorities (e.g., Slack for low-priority, PagerDuty for high-priority).\n- Leverage Sentry's performance monitoring capabilities to track application performance metrics and identify slow transactions. Use distributed tracing to visualize request flows and pinpoint performance bottlenecks.\n- Implement alerts based on session-affected percentages when applicable to handle dynamic traffic.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n  - Group Sentry-related initialization and configuration files in a dedicated directory (e.g., `sentry/`) for easy management.\n  - Consider separate files for Sentry SDK initialization, custom integrations, and alert configurations.\n- **File Naming Conventions:**\n  - Use descriptive names for Sentry-related files (e.g., `sentry.init.js`, `sentry.config.py`, `sentry.integrations.ts`).\n- **Module Organization:**\n  - Encapsulate Sentry-related functionality within dedicated modules or classes to promote code reusability and maintainability.\n  - Avoid direct Sentry SDK calls throughout the application; instead, use an abstraction layer or helper functions.\n- **Component Architecture:**\n  - When using Sentry in UI frameworks (e.g., React, Vue), wrap key components with error boundaries to catch and report errors gracefully.\n  - Create reusable components or hooks for common Sentry interactions, such as capturing user feedback or breadcrumbs.\n- **Code Splitting:**\n  - Lazy-load Sentry SDK and related code to minimize initial bundle size and improve application loading times.\n  - Use dynamic imports or similar techniques to load Sentry code only when it's needed.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n  - **Singleton:** Use a singleton pattern for the Sentry client instance to ensure consistent configuration and behavior.\n  - **Observer:** Implement an observer pattern to capture and report application-specific events to Sentry.\n  - **Decorator:** Utilize decorators to automatically capture exceptions or performance metrics for specific functions or methods.\n- **Recommended Approaches:**\n  - Use breadcrumbs to capture user actions and application state leading up to an error, providing valuable context for debugging.\n  - Set user context (ID, email, username) to associate errors with specific users, facilitating troubleshooting and impact assessment.\n  - Capture release information (version, environment) to track errors across different deployments and environments.\n- **Anti-patterns:**\n  - Avoid hardcoding sensitive information (DSN, API keys) directly in the code; use environment variables or configuration files.\n  - Do not capture personally identifiable information (PII) without proper anonymization or consent; adhere to privacy regulations.\n  - Refrain from disabling Sentry entirely in production; instead, configure appropriate sampling rates or filters to manage data volume.\n- **State Management:**\n  - In applications using state management libraries (e.g., Redux, Vuex), integrate Sentry middleware to capture state changes and actions leading up to an error.\n  - Serialize relevant state information and include it in the error context for debugging purposes.\n- **Error Handling:**\n  - Use try-catch blocks to handle potential errors gracefully and report them to Sentry.\n  - Implement global error handlers to catch uncaught exceptions and unhandled rejections.\n  - Provide informative error messages to users and avoid exposing sensitive implementation details.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n  - Enable compression for Sentry payloads to reduce network bandwidth and improve transmission speed.\n  - Use Sentry's sampling options to control the number of events captured, balancing data accuracy with performance impact.\n  - Configure Sentry's throttling options to prevent excessive event submission and potential performance bottlenecks.\n- **Memory Management:**\n  - Be mindful of memory usage when capturing large payloads or attachments; avoid unnecessary data serialization.\n  - Periodically flush the Sentry event queue to release memory and prevent out-of-memory errors.\n- **Rendering Optimization:**\n  - For UI frameworks, defer Sentry initialization until after the initial render to avoid blocking the user interface.\n  - Optimize breadcrumb and event data collection to minimize performance overhead during rendering.\n- **Bundle Size Optimization:**\n  - Tree-shake the Sentry SDK to remove unused modules and reduce bundle size.\n  - Use code splitting to load Sentry code only when it's needed.\n- **Lazy Loading:**\n  - Implement lazy loading for Sentry components and modules to improve initial page load times.\n  - Use dynamic imports or similar techniques to load Sentry code on demand.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities:**\n  - **Data Leakage:** Ensure that sensitive information (PII, API keys) is not inadvertently exposed in Sentry events or breadcrumbs.\n  - **Cross-Site Scripting (XSS):** Sanitize user-generated content before capturing it in Sentry to prevent XSS attacks.\n  - **Denial of Service (DoS):** Implement rate limiting and throttling to prevent excessive event submission from malicious actors.\n- **Input Validation:**\n  - Validate user input on both the client and server sides to prevent malicious data from reaching Sentry.\n  - Sanitize and escape user input before capturing it in Sentry events or breadcrumbs.\n- **Authentication and Authorization:**\n  - Implement strong authentication and authorization mechanisms to protect Sentry API endpoints and data.\n  - Restrict access to Sentry projects and events based on user roles and permissions.\n- **Data Protection:**\n  - Implement data anonymization and masking techniques to protect sensitive user information in Sentry events.\n  - Comply with data privacy regulations (e.g., GDPR, CCPA) when collecting and processing user data with Sentry.\n- **Secure API Communication:**\n  - Use HTTPS for all communication with Sentry API endpoints to encrypt data in transit.\n  - Verify the SSL/TLS certificates of Sentry API endpoints to prevent man-in-the-middle attacks.\n\n## 5. Testing Approaches\n\n- **Unit Testing:**\n  - Write unit tests to verify the functionality of Sentry-related modules and components.\n  - Mock or stub Sentry SDK functions to isolate the code under test.\n- **Integration Testing:**\n  - Perform integration tests to ensure that Sentry is properly integrated with the application and that events are captured correctly.\n  - Use a test Sentry project to capture and verify events during integration testing.\n- **End-to-End Testing:**\n  - Conduct end-to-end tests to simulate real-world user scenarios and verify that errors are captured and reported to Sentry.\n  - Use a staging environment or test Sentry project for end-to-end testing.\n- **Test Organization:**\n  - Organize Sentry-related tests in a dedicated directory or module.\n  - Follow a consistent naming convention for Sentry-related test files and functions.\n- **Mocking and Stubbing:**\n  - Use mocking libraries (e.g., Jest, Sinon) to create mock Sentry SDK objects for testing purposes.\n  - Stub Sentry SDK functions to control their behavior and verify that they are called correctly.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n  - Forgetting to initialize the Sentry SDK properly.\n  - Capturing sensitive information without proper anonymization.\n  - Overloading Sentry with too many events or attachments.\n  - Ignoring Sentry alerts or dashboards.\n- **Edge Cases:**\n  - Handling errors during Sentry SDK initialization.\n  - Dealing with network connectivity issues when sending events.\n  - Managing Sentry SDK configuration in different environments.\n- **Version-Specific Issues:**\n  - Review Sentry SDK release notes for breaking changes and compatibility issues.\n  - Test Sentry SDK upgrades in a staging environment before deploying to production.\n- **Compatibility Concerns:**\n  - Ensure compatibility between the Sentry SDK and other libraries or frameworks used in the application.\n  - Resolve any conflicts or version mismatches that may arise.\n- **Debugging Strategies:**\n  - Use Sentry's debug mode to log SDK activity and troubleshoot integration issues.\n  - Inspect Sentry events in the Sentry UI to verify data accuracy and identify potential problems.\n  - Utilize Sentry's breadcrumbs and user context to gain insights into the cause of errors.\n\n## 7. Tooling and Environment\n\n- **Recommended Tools:**\n  - Sentry CLI for managing Sentry projects and releases.\n  - Source code management system (e.g., Git) for version control.\n  - Package manager (e.g., npm, pip) for managing Sentry SDK dependencies.\n- **Build Configuration:**\n  - Integrate Sentry SDK into the build process to capture build errors and performance metrics.\n  - Use environment variables or configuration files to manage Sentry SDK settings in different environments.\n- **Linting and Formatting:**\n  - Configure linters (e.g., ESLint, PyLint) to enforce code style and best practices for Sentry code.\n  - Use code formatters (e.g., Prettier, Black) to automatically format Sentry code and ensure consistency.\n- **Deployment:**\n  - Deploy Sentry SDK and related code as part of the application deployment process.\n  - Configure Sentry SDK to capture deployment information (version, environment) for tracking errors across releases.\n- **CI/CD Integration:**\n  - Integrate Sentry SDK into the CI/CD pipeline to automate error capture and reporting during testing and deployment.\n  - Use Sentry's release tracking features to associate errors with specific deployments and releases.\n\nBy adhering to these best practices, you can effectively leverage Sentry to improve the reliability, performance, and security of your applications.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.py,*.java,*.kt,*.swift,*.go,*.rb,*.php,*.cs,*.cpp,*.c,*.m,*.mm,*.clj,*.cljs,*.scala,*.groovy,*.lua,*.erl,*.hrl,*.fs,*.fsi,*.vb,*.vba,*.sh,*.bash,*.zsh,*.ps1,*.psm1,*.sql,*.html,*.htm,*.css,*.scss,*.less,*.graphql,*.gql",
      "format": "mdc",
      "originalFile": "sentry.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "sentry",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "integrating",
      "utilizing",
      "your",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sentry",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-servemux",
    "description": "This rule enforces best practices for using the `net/http` ServeMux in Go, promoting clean, maintainable, and efficient code. It covers routing, handler design, and error handling specifics to help developers leverage ServeMux effectively.",
    "author": "sanjeed5",
    "tags": [
      "servemux",
      "go",
      "backend",
      "performance",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/servemux.mdc",
    "content": "---\n# servemux Best Practices and Coding Standards\n\nThis document provides comprehensive guidelines for using the `net/http` ServeMux in Go, promoting best practices, coding standards, and efficient development.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n-   **Modular Design:** Organize your code into logical modules, each responsible for a specific set of functionalities.\n-   **Handler Grouping:** Group related handlers within the same directory or package. For instance, all user-related handlers could reside in a `users` package.\n-   **Middleware Directory:** Create a dedicated `middleware` directory for reusable middleware functions.\n-   **Internal vs. External:** Utilize the `internal` directory to encapsulate code that should not be exposed outside your module.  This enhances encapsulation and reduces the API surface.\n\n\nproject-root/\n├── cmd/\n│   └── my-app/\n│       └── main.go\n├── internal/\n│   ├── handlers/\n│   │   ├── users.go\n│   │   └── products.go\n│   └── middleware/\n│       ├── auth.go\n│       └── logging.go\n├── pkg/\n│   └── utils/\n│       └── utils.go\n└── go.mod\n\n\n### 1.2 File Naming Conventions\n\n-   **Descriptive Names:** Use clear and descriptive file names that reflect the functionality they contain. For example, `users.go` for user-related handlers, and `auth.go` for authentication middleware.\n-   **Handler Specifics:** If a file contains a specific handler, name it accordingly. For example, `get_user_handler.go` or `create_product_handler.go`.\n-   **Lowercase:** Use lowercase for all file names.\n\n### 1.3 Module Organization\n\n-   **`go.mod`:** Ensure your project has a `go.mod` file to manage dependencies.  Run `go mod init <module_name>` to create one.\n-   **Semantic Versioning:** Follow semantic versioning for your modules.  Use tags (e.g., `v1.0.0`) to mark releases.\n-   **Vendor Dependencies:** Consider vendoring dependencies using `go mod vendor` to ensure reproducibility.\n\n### 1.4 Component Architecture\n\n-   **Separation of Concerns:** Design your components to have a single responsibility.  Separate handler logic from business logic and data access.\n-   **Interfaces:** Use interfaces to define contracts between components, promoting loose coupling and testability. For example:\n\n    go\ntype UserStore interface {\n    GetUser(id int) (*User, error)\n    CreateUser(user *User) error\n}\n\ntype UserHandler struct {\n    store UserStore\n}\n    \n\n### 1.5 Code Splitting Strategies\n\n-   **Package-Based Splitting:** Divide your application into packages based on functionality.  Each package should be cohesive and have a clear purpose.\n-   **Feature-Based Splitting:**  Organize code based on features.  Each feature gets its own directory or package containing all relevant components.\n-   **Layered Architecture:**  Implement a layered architecture (e.g., presentation, business logic, data access) and split the code accordingly.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to servemux\n\n-   **Middleware Chaining:** Implement middleware as a chain of functions that decorate the handler. This allows for modular and reusable logic. Example:\n\n    go\nfunc LoggingMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        log.Printf(\"Request: %s %s\", r.Method, r.URL.Path)\n        next.ServeHTTP(w, r)\n    })\n}\n\n// Usage:\nmux := http.NewServeMux()\nmux.Handle(\"/\", LoggingMiddleware(http.HandlerFunc(myHandler)))\n    \n\n-   **Context-Aware Handlers:** Utilize the `context.Context` to pass request-scoped values to handlers. This facilitates tracing, request cancellation, and data sharing.\n\n    go\nfunc MyHandler(w http.ResponseWriter, r *http.Request) {\n    userID := r.Context().Value(\"userID\").(int)\n    // ...\n}\n\n// Setting context value in middleware:\nctx := context.WithValue(r.Context(), \"userID\", 123)\nr = r.WithContext(ctx)\n    \n\n-   **Route Grouping (with custom muxes):** Use separate ServeMux instances for different route groups (e.g., API v1, API v2, admin routes).  This improves organization and maintainability.\n\n    go\nv1Mux := http.NewServeMux()\nv1Mux.HandleFunc(\"/users\", v1UsersHandler)\nv1Mux.HandleFunc(\"/products\", v1ProductsHandler)\n\nv2Mux := http.NewServeMux()\nv2Mux.HandleFunc(\"/users\", v2UsersHandler)\nv2Mux.HandleFunc(\"/products\", v2ProductsHandler)\n\nhttp.Handle(\"/api/v1/\", v1Mux)\nhttp.Handle(\"/api/v2/\", v2Mux)\n    \n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **Creating a New ServeMux:** Always use `http.NewServeMux()` to create a new ServeMux instance. Avoid using the default `http.DefaultServeMux` to prevent global state issues. Example:\n\n    go\nmux := http.NewServeMux()\nmux.HandleFunc(\"/\", myHandler)\nhttp.ListenAndServe(\":8080\", mux)\n    \n\n-   **Registering Handlers:**  Use `mux.HandleFunc()` or `mux.Handle()` to register handlers with the ServeMux.\n\n    go\nmux.HandleFunc(\"/users\", usersHandler)\nmux.Handle(\"/products\", productHandler{})\n    \n\n-   **Serving Static Files:** Use `http.FileServer()` to serve static files.\n\n    go\nfs := http.FileServer(http.Dir(\"./static\"))\nmux.Handle(\"/static/\", http.StripPrefix(\"/static/\", fs))\n    \n\n-   **Handling HTTP Methods:**  Use `http.MethodGet`, `http.MethodPost`, etc., constants to check the HTTP method.  With Go 1.22+, specify methods in the pattern itself for `HandleFunc`.\n\n    go\nmux.HandleFunc(\"GET /users/{id}\", getUserHandler)\nmux.HandleFunc(\"POST /users\", createUserHandler)\n    \n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Global State:** Avoid using global variables or the default `http.DefaultServeMux` for request handling, as it can lead to race conditions and difficult debugging.\n-   **Overlapping Routes:** Be mindful of overlapping routes.  Go 1.22+ will panic if conflicting patterns are registered. Ensure that your routes are distinct and do not cause conflicts. Properly consider precedence rules.\n-   **Ignoring Errors:**  Always handle errors returned by functions. Log errors and return appropriate HTTP status codes to the client.\n-   **Long Handler Functions:**  Keep handler functions short and focused. Delegate complex logic to other functions or services.\n-   **Hardcoding Values:**  Avoid hardcoding configuration values.  Use environment variables or configuration files.\n-   **Lack of Input Validation:** Always validate user input to prevent security vulnerabilities.\n\n### 2.4 State Management Best Practices\n\n-   **Stateless Handlers:** Design handlers to be stateless whenever possible. If state is required, store it in the request context or an external data store.\n-   **Request-Scoped Values:**  Use the `context.Context` to store request-scoped values. Avoid using global variables to store state related to a specific request.\n-   **Sessions:** Use secure session management techniques to maintain user sessions.\n\n### 2.5 Error Handling Patterns\n\n-   **Centralized Error Handling:**  Implement a centralized error handling middleware to catch and log errors. Return appropriate HTTP status codes and error messages to the client.\n\n    go\nfunc ErrorHandlingMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        defer func() {\n            if err := recover(); err != nil {\n                log.Printf(\"Panic: %v\", err)\n                http.Error(w, \"Internal Server Error\", http.StatusInternalServerError)\n            }\n        }()\n        next.ServeHTTP(w, r)\n    })\n}\n    \n\n-   **Custom Error Types:** Define custom error types to provide more context about the error.\n\n    go\ntype ValidationError struct {\n    Field   string\n    Message string\n}\n\nfunc (e *ValidationError) Error() string {\n    return fmt.Sprintf(\"Validation error: %s - %s\", e.Field, e.Message)\n}\n    \n\n-   **Logging Errors:** Log errors with sufficient detail for debugging.\n-   **Returning Appropriate Status Codes:** Return appropriate HTTP status codes based on the error. Use descriptive error messages in the response body.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Connection Pooling:** Use connection pooling for database connections to reduce overhead.\n-   **Caching:** Implement caching for frequently accessed data to reduce database load.\n-   **Gzip Compression:** Enable Gzip compression for responses to reduce bandwidth usage.\n\n    go\nfunc GzipMiddleware(next http.Handler) http.Handler {\n    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n        if strings.Contains(r.Header.Get(\"Accept-Encoding\"), \"gzip\") {\n            gz, err := gzip.NewWriterLevel(w, gzip.BestSpeed)\n            if err != nil {\n                http.Error(w, err.Error(), http.StatusInternalServerError)\n                return\n            }\n            defer gz.Close()\n            w.Header().Set(\"Content-Encoding\", \"gzip\")\n            next.ServeHTTP(gzipResponseWriter{Writer: gz, ResponseWriter: w}, r)\n        } else {\n            next.ServeHTTP(w, r)\n        }\n    })\n}\n\ntype gzipResponseWriter struct {\n    io.Writer\n    http.ResponseWriter\n}\n\nfunc (w gzipResponseWriter) Write(b []byte) (int, error) {\n    return w.Writer.Write(b)\n}\n    \n\n-   **Keep-Alive Connections:** Enable keep-alive connections to reduce connection establishment overhead.\n-   **Efficient Data Structures:**  Use efficient data structures and algorithms for data processing.\n\n### 3.2 Memory Management\n\n-   **Avoid Memory Leaks:** Be aware of potential memory leaks, especially when using goroutines. Ensure that all goroutines are properly terminated.\n-   **Object Pooling:** Consider using object pooling for frequently allocated objects.\n-   **String Conversions:**  Minimize unnecessary string conversions, as they can be expensive.\n-   **Defer Statements:**  Use `defer` statements carefully. While convenient, they can add overhead if overused in performance-critical sections.\n\n### 3.3 Rendering Optimization\n\n-   **Template Caching:** Cache templates to reduce parsing overhead.\n-   **Efficient Template Rendering:** Use efficient template rendering techniques. Consider using pre-compiled templates.\n-   **Minimize DOM Updates:** Minimize DOM updates in the client-side JavaScript code.\n\n### 3.4 Bundle Size Optimization\n\n-   **Code Minification:** Minify JavaScript and CSS code to reduce bundle size.\n-   **Tree Shaking:** Use tree shaking to remove unused code from the bundle.\n-   **Image Optimization:** Optimize images to reduce file size.\n\n### 3.5 Lazy Loading Strategies\n\n-   **Lazy Loading Images:** Lazy load images that are not immediately visible.\n-   **Code Splitting:** Split the code into smaller chunks that can be loaded on demand.\n-   **Dynamic Imports:** Use dynamic imports to load modules only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **SQL Injection:** Prevent SQL injection by using parameterized queries or ORMs.\n-   **Cross-Site Scripting (XSS):** Prevent XSS by escaping user input before rendering it in HTML.\n-   **Cross-Site Request Forgery (CSRF):** Prevent CSRF by using CSRF tokens.\n-   **Authentication Bypass:** Implement robust authentication and authorization mechanisms to prevent authentication bypass.\n-   **Denial-of-Service (DoS):** Implement rate limiting and request validation to prevent DoS attacks.\n\n### 4.2 Input Validation\n\n-   **Validate All Inputs:** Validate all user inputs to ensure that they conform to the expected format and values. Use libraries like `ozzo-validation` for complex validation rules.\n-   **Sanitize Inputs:** Sanitize inputs to remove potentially malicious characters.\n-   **Whitelist Inputs:** Use a whitelist approach to only allow specific characters or patterns.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   **Authentication Middleware:** Implement authentication middleware to verify user credentials.\n-   **Authorization Middleware:** Implement authorization middleware to check user permissions.\n-   **JWT (JSON Web Tokens):** Use JWT for stateless authentication.\n-   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n-   **Role-Based Access Control (RBAC):** Implement RBAC to manage user permissions.\n\n### 4.4 Data Protection Strategies\n\n-   **Encryption:** Encrypt sensitive data at rest and in transit.\n-   **Hashing:** Hash passwords with a strong hashing algorithm like bcrypt.\n-   **Salting:** Use salts to prevent rainbow table attacks.\n-   **Data Masking:** Mask sensitive data in logs and error messages.\n\n### 4.5 Secure API Communication\n\n-   **HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n-   **TLS (Transport Layer Security):** Use TLS 1.3 or higher for secure communication.\n-   **Certificate Pinning:** Consider using certificate pinning to prevent man-in-the-middle attacks.\n-   **Rate Limiting:** Implement rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   **Test Individual Units:** Unit test individual functions and methods in isolation.\n-   **Mock Dependencies:** Use mocks to isolate the unit under test from its dependencies. Use libraries like `gomock` or `testify/mock`.\n-   **Test Boundary Conditions:** Test boundary conditions and edge cases.\n-   **Table-Driven Tests:** Use table-driven tests to test multiple scenarios with different inputs and outputs.\n\n### 5.2 Integration Testing\n\n-   **Test Interactions Between Components:** Integration test the interactions between different components of the application.\n-   **Test Database Interactions:** Test the interactions with the database.\n-   **Test API Endpoints:** Test the API endpoints.\n\n### 5.3 End-to-End Testing\n\n-   **Test the Entire Application:** End-to-end test the entire application flow.\n-   **Use Automated Testing Tools:** Use automated testing tools like Selenium or Cypress.\n\n### 5.4 Test Organization\n\n-   **Keep Tests Close to Code:** Keep test files in the same directory as the code they test. Use the `_test.go` suffix for test files.\n-   **Separate Test Packages:** Consider creating separate test packages for integration and end-to-end tests.\n-   **Descriptive Test Names:** Use descriptive test names that clearly indicate what is being tested.\n\n### 5.5 Mocking and Stubbing\n\n-   **Use Interfaces:** Define interfaces for dependencies to facilitate mocking.\n-   **Use Mocking Libraries:** Use mocking libraries like `gomock` or `testify/mock` to generate mocks.\n-   **Create Stub Implementations:** Create stub implementations for dependencies that are difficult to mock.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Forgetting to Handle Errors:** Always check and handle errors returned by functions.\n-   **Ignoring Context Cancellation:** Respect context cancellation signals and terminate long-running operations.\n-   **Not Validating Inputs:** Always validate user inputs to prevent security vulnerabilities.\n-   **Using Global State:** Avoid using global variables for request handling, as it can lead to race conditions.\n-   **Overlapping Routes:**  Failing to understand route precedence, especially in Go 1.22+ can lead to unexpected behavior or panics during server initialization. Thoroughly test route registrations.\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **Trailing Slashes:** Be aware of how trailing slashes affect route matching. In Go 1.22+, use `{$}` to match only the path with the trailing slash.\n-   **Wildcard Matching:** Understand how wildcards match different segments of the path. Use `{pathname...}` to match all remaining segments.\n-   **Method Matching:** Ensure that the correct HTTP method is being used for each route. With Go 1.22+, be aware that `GET` also matches `HEAD` requests.\n\n### 6.3 Version-Specific Issues\n\n-   **Go 1.22 Routing Enhancements:** Be aware of the new routing enhancements in Go 1.22, including method matching and wildcard support. Understand the new precedence rules.\n-   **Compatibility Issues:** Check for compatibility issues when upgrading to new versions of Go or third-party libraries.\n\n### 6.4 Compatibility Concerns\n\n-   **Backwards Compatibility:** Ensure that changes do not break backwards compatibility. Use feature flags to gradually introduce new features.\n-   **API Versioning:** Use API versioning to manage changes to the API.\n-   **Client Compatibility:** Ensure that client applications are compatible with the API.\n\n### 6.5 Debugging Strategies\n\n-   **Logging:** Use logging to track the execution flow and identify errors.\n-   **Debugging Tools:** Use debugging tools like `delve` to step through the code and inspect variables.\n-   **Profiling:** Use profiling tools to identify performance bottlenecks.\n-   **Tracing:** Use tracing tools to track requests across different services.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **GoLand:** A powerful IDE for Go development.\n-   **Visual Studio Code with Go Extension:** A lightweight and versatile code editor with excellent Go support.\n-   **Delve:** A Go debugger.\n-   **Profiling Tools:** `pprof` is the built-in Go profiler.\n\n### 7.2 Build Configuration\n\n-   **Makefile:** Use a Makefile to automate common build tasks.\n-   **`go build`:** Use `go build` to compile the application.\n-   **`go test`:** Use `go test` to run tests.\n\n### 7.3 Linting and Formatting\n\n-   **`go fmt`:** Use `go fmt` to format the code according to the Go style guidelines.\n-   **`go vet`:** Use `go vet` to identify potential errors in the code.\n-   **`golangci-lint`:** Use `golangci-lint` for more advanced linting.\n\n### 7.4 Deployment Best Practices\n\n-   **Containerization:** Use containers (e.g., Docker) to package the application and its dependencies.\n-   **Orchestration:** Use orchestration tools (e.g., Kubernetes) to manage and scale the application.\n-   **Immutable Infrastructure:** Deploy immutable infrastructure to ensure consistency and reproducibility.\n\n### 7.5 CI/CD Integration\n\n-   **Continuous Integration:** Integrate with a CI/CD pipeline to automate the build, test, and deployment process.\n-   **Automated Testing:** Run automated tests as part of the CI/CD pipeline.\n-   **Automated Deployment:** Automate the deployment process using tools like Jenkins, CircleCI, or GitHub Actions.\n\n## Additional Best Practices\n\n-   **Meaningful Handler Names:** Use meaningful, concise names for handlers, avoiding repetition of context in function names (as per the Google Style Guide).\n-   **Document Code:** Write clear and concise documentation for all functions, methods, and types.\n-   **Code Reviews:** Conduct regular code reviews to ensure code quality and identify potential issues.\n-   **Stay Updated:** Stay up-to-date with the latest Go best practices and security vulnerabilities.\n\nBy following these best practices and coding standards, you can develop robust, maintainable, and efficient applications using the `net/http` ServeMux in Go.",
    "metadata": {
      "globs": "*.go",
      "format": "mdc",
      "originalFile": "servemux.mdc"
    },
    "subcategory": "go",
    "keywords": [
      "cursor",
      "servemux",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "using",
      "http",
      "promoting",
      "clean",
      "go",
      "backend",
      "performance",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "servemux",
        "go",
        "golang",
        "backend",
        "performance",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-setuptools",
    "description": "This rule provides guidance on best practices for using setuptools in Python projects, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "setuptools",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/setuptools.mdc",
    "content": "# setuptools Best Practices\n\nThis document outlines best practices for using `setuptools` in Python projects. Following these guidelines ensures maintainable, performant, and secure code.\n\n## Library Information:\n- Name: setuptools\n- Tags: development, build-tool, python, packaging\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - At the root:\n        - `setup.py`:  The main setup script.\n        - `setup.cfg`: Configuration file for `setup.py` (optional but recommended).\n        - `pyproject.toml`: Build system configuration (modern approach).\n        - `README.md` or `README.rst`: Project description.\n        - `LICENSE.txt`: License information.\n        - `.gitignore`: Specifies intentionally untracked files that Git should ignore.\n    - A top-level package directory (e.g., `my_package`):\n        - `my_package/`:\n            - `__init__.py`: Makes the directory a Python package.\n            - `module1.py`: Module containing code.\n            - `module2.py`: Another module.\n            - `data/`: Directory for package data (optional).\n    - `tests/`:\n        - `test_module1.py`: Unit tests for `module1.py`.\n        - `test_module2.py`: Unit tests for `module2.py`.\n        - `conftest.py`:  Configuration file for pytest.\n        - `__init__.py` (optional).\n    - `docs/` (optional):\n        - Project documentation (e.g., using Sphinx).\n\n- **File Naming Conventions:**\n    - Python modules: `module_name.py` (snake_case).\n    - Test files: `test_module_name.py` or `module_name_test.py`.\n    - Package directories: `package_name/` (lowercase).\n    - Configuration files: `setup.cfg`, `pyproject.toml`, `MANIFEST.in`.\n\n- **Module Organization:**\n    - Group related functions and classes within a module.\n    - Keep modules focused on a specific responsibility.\n    - Use clear and descriptive module names.\n    - Utilize subpackages for logical grouping of modules within larger projects.\n\n- **Component Architecture:**\n    - Favor modular design, breaking down the project into reusable components.\n    - Define clear interfaces between components.\n    - Follow the Single Responsibility Principle (SRP) for each component.\n    - Consider using a layered architecture if appropriate for your project's complexity.\n\n- **Code Splitting Strategies:**\n    - Split large modules into smaller, more manageable files.\n    - Decompose complex functions into smaller, well-defined functions.\n    - Extract reusable code into separate modules or packages.\n    - Employ lazy loading for modules that are not immediately needed.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - **Factory Pattern:**  Use factory functions or classes to create instances of objects, especially when complex initialization is required.\n    - **Dependency Injection:**  Inject dependencies into classes or functions to improve testability and reduce coupling.\n    - **Facade Pattern:**  Provide a simplified interface to a complex subsystem.\n    - **Singleton Pattern:**  Use sparingly; ensure thread safety if needed.\n    - **Observer Pattern:**  Useful for event handling and asynchronous operations.\n\n- **Recommended Approaches:**\n    - **Declaring Dependencies:**  Use `install_requires` in `setup.py` or `pyproject.toml` (preferred) to specify project dependencies.\n    - **Managing Package Data:**  Use `package_data` in `setup.py` to include non-code files (e.g., data files, templates) within your package.\n    - **Creating Entry Points:** Define console scripts using `entry_points` in `setup.py` or `pyproject.toml` to create command-line tools.\n    - **Versioning:** Follow Semantic Versioning (SemVer) to clearly communicate the nature of changes in each release.\n    - **Using `pyproject.toml`:** Utilize `pyproject.toml` for build system configuration, build dependencies and other metadata. This aligns with modern packaging practices.\n\n- **Anti-patterns and Code Smells:**\n    - **Large `setup.py` Files:**  Keep `setup.py` concise; move complex logic to separate modules.\n    - **Hardcoded Paths:**  Avoid hardcoding file paths; use relative paths or the `pkg_resources` module to access package data.\n    - **Global State:**  Minimize the use of global variables; prefer passing state as arguments to functions or methods.\n    - **Ignoring Errors:**  Always handle exceptions appropriately; never ignore errors without logging or taking corrective action.\n    - **Over-engineering:** Avoid unnecessary complexity; keep the design simple and focused.\n\n- **State Management:**\n    - For CLI tools, use configuration files or environment variables to store persistent state.\n    - For more complex applications, consider using a database or other persistent storage mechanism.\n    - Avoid storing sensitive information in plain text configuration files; use encryption or secure storage.\n\n- **Error Handling:**\n    - Use `try...except` blocks to handle exceptions gracefully.\n    - Log errors with sufficient context for debugging.\n    - Raise custom exceptions to provide more specific error information.\n    - Avoid catching generic exceptions (`except Exception:`) unless you re-raise them or log the error.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - **Code Profiling:** Use profiling tools (e.g., `cProfile`) to identify performance bottlenecks.\n    - **Algorithm Optimization:** Choose efficient algorithms and data structures.\n    - **Caching:** Implement caching mechanisms to reduce redundant computations.\n    - **Code Optimization:**  Use efficient code constructs and avoid unnecessary operations.\n    - **Concurrency/Parallelism:**  Consider using threading or multiprocessing for CPU-bound tasks.\n\n- **Memory Management:**\n    - Use generators or iterators to process large datasets without loading everything into memory.\n    - Release resources (e.g., file handles, network connections) promptly.\n    - Avoid creating unnecessary copies of data.\n    - Be mindful of memory leaks; use memory profiling tools to detect them.\n\n- **Bundle Size Optimization:**\n    - Minimize the size of your package by excluding unnecessary files (e.g., test files, documentation) from the distribution.\n    - Use compression to reduce the size of package data.\n    - Consider using a smaller version of a dependency or only requiring features of the dependency that you need.\n\n- **Lazy Loading:**\n    - Defer loading of modules or data until they are actually needed.\n    - Use the `importlib` module to dynamically import modules at runtime.\n    - Implement lazy properties to defer the computation of attribute values.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n    - **Dependency Confusion:**  Prevent dependency confusion attacks by using a unique package name and verifying dependencies.\n    - **Arbitrary Code Execution:**  Avoid using `eval()` or `exec()` to execute untrusted code.\n    - **Injection Attacks:**  Sanitize user inputs to prevent injection attacks (e.g., SQL injection, command injection).\n    - **Cross-Site Scripting (XSS):**  Encode output to prevent XSS attacks, particularly when dealing with web interfaces.\n\n- **Input Validation:**\n    - Validate all user inputs to ensure they conform to expected formats and ranges.\n    - Use regular expressions or validation libraries to enforce input constraints.\n    - Sanitize inputs to remove or escape potentially malicious characters.\n\n- **Authentication and Authorization:**\n    - Use secure authentication mechanisms (e.g., OAuth 2.0, JWT) to verify user identities.\n    - Implement authorization checks to ensure that users only have access to the resources they are authorized to access.\n    - Store passwords securely using hashing algorithms (e.g., bcrypt, scrypt).\n\n- **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between clients and servers.\n    - Implement data masking or anonymization techniques to protect personally identifiable information (PII).\n\n- **Secure API Communication:**\n    - Use API keys or tokens to authenticate API requests.\n    - Enforce rate limiting to prevent denial-of-service attacks.\n    - Validate API requests and responses to ensure data integrity.\n\n## 5. Testing Approaches:\n\n- **Unit Testing:**\n    - Write unit tests for each module and function to verify their correctness.\n    - Use mocking or stubbing to isolate units of code from their dependencies.\n    - Aim for high test coverage to ensure that all code paths are tested.\n    - Use `pytest` and `unittest` modules.\n\n- **Integration Testing:**\n    - Write integration tests to verify the interactions between different components of the system.\n    - Test the integration with external dependencies (e.g., databases, APIs).\n    - Use test doubles or test environments to simulate external dependencies.\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to verify the functionality of the entire system from the user's perspective.\n    - Use browser automation tools (e.g., Selenium, Playwright) to simulate user interactions.\n    - Test the system in a realistic environment.\n\n- **Test Organization:**\n    - Organize tests into separate directories (e.g., `tests/`).\n    - Use descriptive test names to clearly indicate what each test is verifying.\n    - Group related tests into test classes or modules.\n    - Use test fixtures to set up and tear down test environments.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries (e.g., `unittest.mock`, `pytest-mock`) to create mock objects that simulate the behavior of dependencies.\n    - Use stubbing to replace dependencies with simplified versions that return predefined values.\n    - Avoid over-mocking; only mock dependencies that are difficult to test directly.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n    - **Incorrect Dependency Specifications:**  Ensure that dependencies are correctly specified in `install_requires` or `pyproject.toml` with accurate version constraints.\n    - **Missing Package Data:**  Remember to include non-code files in `package_data` if they are required at runtime.\n    - **Inconsistent Versioning:**  Follow Semantic Versioning (SemVer) consistently and update version numbers appropriately.\n    - **Ignoring Encoding Issues:**  Handle text encoding correctly to avoid errors when dealing with non-ASCII characters.\n    - **Failing to Test:**  Write comprehensive tests to catch errors early and prevent regressions.\n\n- **Edge Cases:**\n    - **Platform-Specific Issues:**  Test your package on different operating systems and Python versions to identify platform-specific issues.\n    - **Dependency Conflicts:**  Be aware of potential dependency conflicts and use virtual environments to isolate your project's dependencies.\n    - **Unicode Handling:**  Handle Unicode characters correctly, especially when dealing with user inputs or file names.\n    - **Resource Limits:**  Be mindful of resource limits (e.g., memory, file handles) when processing large datasets.\n\n- **Version-Specific Issues:**\n    - Be aware of compatibility issues between different versions of setuptools.\n    - Consult the setuptools documentation for version-specific recommendations.\n\n- **Compatibility Concerns:**\n    - Test your package with different versions of Python to ensure compatibility.\n    - Be aware of potential conflicts with other libraries or frameworks.\n    - Use conditional imports or feature detection to handle compatibility issues gracefully.\n\n- **Debugging Strategies:**\n    - Use a debugger to step through your code and inspect variables.\n    - Add logging statements to track the flow of execution and identify errors.\n    - Use unit tests to isolate and reproduce bugs.\n    - Consult online resources (e.g., Stack Overflow) and the setuptools documentation for troubleshooting tips.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - **Virtual Environment Managers:** `venv`, `virtualenv`, `conda` or Poetry to create isolated Python environments.\n    - **Package Managers:** `pip` or Poetry to install and manage dependencies.\n    - **Code Editors:** VS Code, PyCharm, Sublime Text, or other IDEs with Python support.\n    - **Debuggers:** `pdb` or IDE-integrated debuggers.\n    - **Profilers:** `cProfile` to identify performance bottlenecks.\n    - **Testing Frameworks:** `pytest` or `unittest` for writing and running tests.\n    - **Linters and Formatters:** `flake8`, `pylint`, `black`, and `isort` to enforce code style and quality.\n    - **Build System:** `build` to build distributions.\n\n- **Build Configuration:**\n    - Use `setup.cfg` or `pyproject.toml` to configure the build process.\n    - Specify dependencies, package data, and entry points in the configuration file.\n    - Use build scripts to automate build tasks.\n\n- **Linting and Formatting:**\n    - Use `flake8` or `pylint` to enforce code style guidelines.\n    - Use `black` to automatically format your code.\n    - Use `isort` to sort imports alphabetically.\n\n- **Deployment:**\n    - Use `twine` to securely upload your package to PyPI.\n    - Use virtual environments to isolate your application's dependencies in production.\n    - Consider using containerization (e.g., Docker) to create reproducible deployment environments.\n\n- **CI/CD:**\n    - Use CI/CD systems (e.g., GitHub Actions, Jenkins, Travis CI, CircleCI) to automate building, testing, and deploying your package.\n    - Configure CI/CD pipelines to run tests, linters, and formatters on every commit.\n    - Automate the release process using CI/CD.\n\nBy adhering to these best practices, you can effectively leverage `setuptools` to create well-structured, maintainable, and high-quality Python packages.",
    "metadata": {
      "globs": "**/setup.py",
      "format": "mdc",
      "originalFile": "setuptools.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "setuptools",
      "this",
      "rule",
      "provides",
      "guidance",
      "best",
      "practices",
      "using",
      "python",
      "projects",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "setuptools",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-shadcn",
    "description": "This rule provides comprehensive best practices for developing with Shadcn UI, covering code organization, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "shadcn",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/shadcn.mdc",
    "content": "# Shadcn UI Best Practices\n\nThis document outlines best practices for developing with Shadcn UI, covering code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - Organize components into logical directories based on functionality or domain. For example, place form-related components in a `components/forms` directory.\n    - Separate components into their own files.  Each component should have a dedicated file named after the component (e.g., `Button.tsx`).\n    - Consider using an `index.ts` file within each directory to export all components from that directory, simplifying imports.\n    - Structure directories to reflect the UI hierarchy.  For example, `/components/layout` for layout related components and `/components/ui` for reusable UI elements.\n\n- **File Naming Conventions:**\n    - Use PascalCase for component file names (e.g., `MyComponent.tsx`).\n    - Use camelCase for variable and function names (e.g., `handleClick`).\n    - Use descriptive names that clearly indicate the purpose of the component or function.\n\n- **Module Organization:**\n    - Break down complex components into smaller, reusable modules.\n    - Keep components focused on a single responsibility.\n    - Utilize shared utility functions and constants to avoid code duplication.  Create a `utils` directory for helper functions.\n    - Use `components` directory to store UI components.\n\n- **Component Architecture:**\n    - Favor composition over inheritance. Create flexible components that can be customized through props.\n    - Design components with clear separation of concerns: presentational components (UI) and container components (logic).\n    - Use functional components with hooks for managing state and side effects.\n\n- **Code Splitting Strategies:**\n    - Implement lazy loading for non-critical components to improve initial load time.\n    - Utilize React.lazy and Suspense for code splitting at the component level.\n    - Configure your bundler (e.g., Webpack, Parcel) to automatically split code into smaller chunks.\n    - Consider route-based code splitting for larger applications.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns Specific to Shadcn UI:**\n    - Leverage the existing components provided by Shadcn UI whenever possible.\n    - Customize components using styling solutions like Tailwind CSS's utility classes or CSS variables.\n    - Create compound components by combining existing Shadcn UI components to build more complex UI elements.\n\n- **Recommended Approaches for Common Tasks:**\n    - Use Shadcn UI's form components (e.g., `Input`, `Select`) for handling user input.\n    - Implement accessible components by following ARIA guidelines and using appropriate HTML semantics.\n    - Use the `cn` utility (classnames library) provided by Shadcn UI to manage CSS class names effectively.\n\n- **Anti-patterns and Code Smells to Avoid:**\n    - Directly modifying the Shadcn UI component code.\n    - Overusing custom CSS, as Shadcn UI is built with Tailwind CSS.\n    - Neglecting accessibility considerations.\n    - Creating overly complex components with too many responsibilities.\n\n- **State Management Best Practices:**\n    - Use React's built-in `useState` hook for simple component-level state.\n    - Consider using a state management library like Zustand, Redux, or Recoil for more complex application state.\n    - Avoid mutating state directly; always use the setState function or a state management library's update methods.\n\n- **Error Handling Patterns:**\n    - Implement error boundaries to catch errors in components and prevent the entire application from crashing.\n    - Use try-catch blocks to handle errors in asynchronous operations and API calls.\n    - Provide informative error messages to users.\n    - Log errors to a monitoring service for debugging and analysis.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - Minimize re-renders by using `React.memo` for functional components and `shouldComponentUpdate` for class components.\n    - Optimize event handlers by using useCallback to prevent unnecessary re-creation of functions.\n    - Debounce or throttle expensive operations to reduce the frequency of execution.\n\n- **Memory Management:**\n    - Avoid memory leaks by properly cleaning up event listeners and timers in the `useEffect` hook.\n    - Release unused resources, such as large data structures, when they are no longer needed.\n\n- **Rendering Optimization:**\n    - Use virtualized lists or grids for rendering large datasets.\n    - Batch DOM updates to minimize reflows and repaints.\n    - Use CSS containment to isolate rendering changes to specific parts of the DOM.\n\n- **Bundle Size Optimization:**\n    - Remove unused code and dependencies using tree shaking.\n    - Minify JavaScript and CSS files to reduce their size.\n    - Compress images using tools like ImageOptim or TinyPNG.\n\n- **Lazy Loading Strategies:**\n    - Implement lazy loading for images and other media assets.\n    - Use the Intersection Observer API to detect when elements are visible in the viewport and load them on demand.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - Prevent cross-site scripting (XSS) attacks by sanitizing user input and escaping HTML entities.\n    - Protect against cross-site request forgery (CSRF) attacks by using anti-CSRF tokens.\n    - Avoid storing sensitive information, such as API keys or passwords, in client-side code.\n\n- **Input Validation:**\n    - Validate user input on both the client-side and server-side.\n    - Use a validation library like Zod or Yup to define data schemas and enforce validation rules.\n    - Sanitize user input to remove potentially harmful characters or code.\n\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication protocol, such as OAuth 2.0 or OpenID Connect.\n    - Implement role-based access control (RBAC) to restrict access to sensitive resources.\n    - Store user credentials securely using hashing and salting.\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to protect data transmitted between the client and server.\n    - Implement data masking to hide sensitive information from unauthorized users.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API requests.\n    - Implement rate limiting to prevent abuse and denial-of-service attacks.\n    - Validate API responses to ensure data integrity.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual components and functions.\n    - Use a testing framework like Jest or Mocha.\n    - Test component behavior with different props and inputs.\n\n- **Integration Testing:**\n    - Write integration tests to verify that components work together correctly.\n    - Test the interaction between components and APIs.\n\n- **End-to-End Testing:**\n    - Write end-to-end tests to simulate user interactions and verify that the application functions as expected.\n    - Use a testing framework like Cypress or Playwright.\n\n- **Test Organization:**\n    - Organize tests into separate files based on the component or feature being tested.\n    - Use descriptive test names that clearly indicate the purpose of the test.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components and functions during testing.\n    - Mock external dependencies, such as APIs or third-party libraries.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes Developers Make:**\n    - Forgetting to handle edge cases.\n    - Overcomplicating components.\n    - Neglecting accessibility.\n    - Ignoring performance considerations.\n\n- **Edge Cases to Be Aware Of:**\n    - Handling different screen sizes and devices.\n    - Dealing with slow network connections.\n    - Handling invalid or unexpected user input.\n\n- **Version-Specific Issues:**\n    - Be aware of breaking changes between Shadcn UI versions.\n    - Consult the Shadcn UI changelog for migration instructions.\n\n- **Compatibility Concerns:**\n    - Ensure that your application is compatible with the target browsers and devices.\n    - Test your application on different browsers and devices.\n\n- **Debugging Strategies:**\n    - Use browser developer tools to inspect the DOM and debug JavaScript code.\n    - Use console logging to track the flow of execution and identify errors.\n    - Use a debugger to step through code and inspect variables.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - Visual Studio Code (VS Code) with extensions for React, TypeScript, and Tailwind CSS.\n    - A browser with developer tools (e.g., Chrome DevTools, Firefox Developer Tools).\n    - A terminal for running commands and scripts.\n\n- **Build Configuration:**\n    - Use a build tool like Webpack, Parcel, or Rollup to bundle your application.\n    - Configure your build tool to optimize code for production.\n\n- **Linting and Formatting:**\n    - Use ESLint to enforce code style and identify potential errors.\n    - Use Prettier to automatically format code.\n    - Configure your editor to automatically lint and format code on save.\n\n- **Deployment Best Practices:**\n    - Deploy your application to a reliable hosting provider.\n    - Use a content delivery network (CDN) to serve static assets.\n    - Configure your server to serve compressed files.\n\n- **CI/CD Integration:**\n    - Use a continuous integration and continuous deployment (CI/CD) pipeline to automate the build, test, and deployment process.\n    - Integrate your CI/CD pipeline with your version control system.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "shadcn.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "shadcn",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "shadcn",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-smolagents",
    "description": "This rule provides comprehensive best practices for developing with the smolagents library, covering code organization, performance, security, testing, and common pitfalls. It aims to guide developers in building robust, maintainable, and efficient AI agent applications.",
    "author": "sanjeed5",
    "tags": [
      "smolagents",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/smolagents.mdc",
    "content": "# smolagents Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing with the smolagents library. Following these guidelines will help you create robust, maintainable, and efficient AI agent applications.\n\n## Library Information:\n- Name: smolagents\n- Tags: ai, ml, llm, python, agent-framework, lightweight\n\n## Core Principles\n- **Simplicity:** Embrace smolagents' focus on minimal code and clear abstractions.\n- **Documentation:** Thoroughly document your code, as AI models lack memory and context.\n- **Security:** Prioritize secure coding practices to prevent vulnerabilities.\n- **Code Review:** Regularly review code to catch design errors and maintain quality.\n- **Code-First Approach:** Utilize smolagents' code-first approach, where agents write their actions in Python.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n\nproject_root/\n├── agents/\n│   ├── __init__.py\n│   ├── my_agent.py  # Agent definitions\n│   └── ...\n├── tools/\n│   ├── __init__.py\n│   ├── web_search_tool.py # Custom tool definitions\n│   └── ...\n├── models/\n│   ├── __init__.py\n│   ├── llm_model.py  # Model configurations\n│   └── ...\n├── config/\n│   ├── config.py      # Configuration settings\n│   └── ...\n├── tests/\n│   ├── __init__.py\n│   ├── test_agents.py # Unit and integration tests\n│   └── ...\n├── utils/\n│   ├── __init__.py\n│   ├── helper_functions.py # Helper functions\n│   └── ...\n├── main.py        # Entry point for the application\n├── requirements.txt # Project dependencies\n├── README.md      # Project documentation\n└── .env           # Environment variables\n\n\n-   **agents/:**  Contains the definitions for your AI agents.\n-   **tools/:**   Holds custom tools that your agents can use.\n-   **models/:**  Defines configurations for LLMs (e.g., Hugging Face models).\n-   **config/:**  Stores configuration settings for your application.\n-   **tests/:**   Includes unit, integration, and end-to-end tests.\n-   **utils/:**   Contains helper functions and utilities.\n-   **main.py:** The entry point for your application.\n-   **.env:** Store sensitive information and configuration variables.\n\n### 1.2 File Naming Conventions\n\n-   Use descriptive and consistent names for files and modules.\n-   Agent files: `my_agent.py`, `task_specific_agent.py`\n-   Tool files: `web_search_tool.py`, `data_analysis_tool.py`\n-   Model files: `llm_model.py`, `embedding_model.py`\n-   Configuration files: `config.py`, `api_keys.py`\n-   Test files: `test_agents.py`, `test_tools.py`\n\n### 1.3 Module Organization\n\n-   Group related functionalities into modules.\n-   Use `__init__.py` files to define packages.\n-   Keep modules focused on a specific task or domain.\n\n### 1.4 Component Architecture\n\n-   Design your application with reusable components.\n-   Agents, tools, and models should be modular and easily swappable.\n-   Use interfaces to define contracts between components.\n\n### 1.5 Code Splitting Strategies\n\n-   Break down large agent implementations into smaller, manageable functions and classes.\n-   Consider splitting code based on different stages of the agent's workflow (e.g., planning, execution, evaluation).\n-   Use separate modules for reusable logic.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n-   **Tool Pattern:** Encapsulate external functionalities (e.g., web search, data analysis) into reusable tools. Example: \n    python\n    from smolagents import tool\n\n    @tool\n    def search_wikipedia(query: str) -> str:\n        \"\"\"Searches Wikipedia for the given query.\"\"\"\n        # Implementation\n        pass\n    \n-   **Chain of Responsibility:** Implement agent workflows as a chain of tasks or sub-agents.\n-   **Strategy Pattern:** Allow agents to switch between different strategies (e.g., different reasoning approaches) at runtime.\n\n### 2.2 Recommended Approaches\n\n-   **Secure Code Execution:** Use sandboxed environments (e.g., E2B) to execute agent code safely.\n-   **Hub Integration:** Leverage the Hugging Face Hub for tool sharing and discovery.\n-   **Model Agnosticism:** Design your agents to work with different LLMs.\n\n### 2.3 Anti-patterns and Code Smells\n\n-   **Hardcoding API Keys:**  Store API keys in environment variables or configuration files, not directly in the code.\n-   **Ignoring Errors:** Implement proper error handling and logging.\n-   **Overly Complex Agents:** Keep agent logic simple and focused.\n-   **Lack of Documentation:** Always document your code, especially agent logic.\n\n### 2.4 State Management\n\n-   Use classes to encapsulate agent state.\n-   Consider using a state management library for more complex applications.\n-   Avoid global state.\n\n### 2.5 Error Handling\n\n-   Use `try-except` blocks to handle exceptions.\n-   Log errors with meaningful messages.\n-   Implement retry mechanisms for transient errors.\n-   Raise custom exceptions for specific error conditions.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Caching:** Cache LLM responses to avoid redundant API calls.\n-   **Asynchronous Operations:** Use asynchronous operations for I/O-bound tasks.\n-   **Efficient Data Structures:** Choose appropriate data structures for your use case.\n-   **Prompt Optimization:** Craft prompts carefully to reduce LLM processing time.\n\n### 3.2 Memory Management\n\n-   Be mindful of memory usage when processing large datasets.\n-   Use generators to process data in chunks.\n-   Delete unnecessary objects to free up memory.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n-   If your agent interacts with a user interface, optimize rendering performance by minimizing DOM updates and using efficient rendering techniques.\n\n### 3.4 Bundle Size Optimization (If Applicable)\n\n-   If you are deploying your agent as a web application, optimize bundle size by removing unused code and using code splitting.\n\n### 3.5 Lazy Loading\n\n-   Load modules and data only when they are needed to improve startup time.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n-   **Prompt Injection:** Protect against malicious prompts that can manipulate the agent's behavior.\n-   **Code Injection:** Prevent agents from executing arbitrary code.\n-   **Data Leakage:** Ensure that sensitive data is not exposed.\n\n### 4.2 Input Validation\n\n-   Validate all inputs to your agents to prevent injection attacks.\n-   Sanitize inputs to remove potentially harmful characters.\n\n### 4.3 Authentication and Authorization\n\n-   Implement authentication and authorization to control access to your agents.\n-   Use secure credentials management practices.\n\n### 4.4 Data Protection\n\n-   Encrypt sensitive data at rest and in transit.\n-   Use secure storage solutions for sensitive data.\n\n### 4.5 Secure API Communication\n\n-   Use HTTPS for all API communication.\n-   Validate API responses to prevent data tampering.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n-   Write unit tests for individual components (agents, tools, models).\n-   Use mocking to isolate components during testing.\n\n### 5.2 Integration Testing\n\n-   Test the interaction between different components.\n-   Verify that the agent workflow works as expected.\n\n### 5.3 End-to-End Testing\n\n-   Test the entire application from end to end.\n-   Simulate user interactions to verify functionality.\n\n### 5.4 Test Organization\n\n-   Organize tests into separate modules based on functionality.\n-   Use clear and descriptive test names.\n\n### 5.5 Mocking and Stubbing\n\n-   Use mocking to replace external dependencies with controlled substitutes.\n-   Use stubbing to provide predefined responses for specific inputs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n-   **Ignoring Documentation:**  Failing to read the smolagents documentation thoroughly.\n-   **Overcomplicating Agents:** Creating agents that are too complex and difficult to maintain.\n-   **Not Using Sandboxed Environments:** Running agent code without proper security measures.\n-   **Failing to Update Documentation:**  Allowing code documentation to become outdated.\n\n### 6.2 Edge Cases\n\n-   Handle edge cases and unexpected inputs gracefully.\n-   Test your agents with a variety of inputs to identify potential issues.\n\n### 6.3 Version-Specific Issues\n\n-   Be aware of version-specific issues and compatibility concerns when upgrading smolagents.\n-   Consult the release notes for information on breaking changes.\n\n### 6.4 Compatibility Concerns\n\n-   Ensure that smolagents is compatible with other technologies you are using.\n-   Test your application with different versions of dependencies.\n\n### 6.5 Debugging Strategies\n\n-   Use logging to track the execution of your agents.\n-   Use a debugger to step through code and inspect variables.\n-   Use print statements to debug simple issues.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n-   **VS Code:**  A popular code editor with excellent Python support and extensions for AI development.\n-   **PyCharm:**  A dedicated Python IDE with advanced features for debugging and testing.\n-   **Docker:**  A containerization platform for deploying your agents in isolated environments.\n-   **E2B:** A secure sandboxed environment for executing agent code.\n\n### 7.2 Build Configuration\n\n-   Use a build system like `poetry` or `pipenv` to manage dependencies.\n-   Define build scripts for common tasks like testing and linting.\n\n### 7.3 Linting and Formatting\n\n-   Use a linter like `pylint` or `flake8` to enforce code style.\n-   Use a formatter like `black` to automatically format your code.\n\n### 7.4 Deployment\n\n-   Deploy your agents to a cloud platform like AWS, Azure, or Google Cloud.\n-   Use containerization to ensure consistent deployment across different environments.\n\n### 7.5 CI/CD\n\n-   Integrate your project with a CI/CD pipeline to automate testing and deployment.\n-   Use a CI/CD tool like Jenkins, GitLab CI, or GitHub Actions.\n\n## Additional Recommendations\n\n-  **Prompt Engineering:**\n    - Be extremely careful about how you craft the prompts being sent to the LLM.  The quality of the prompt directly correlates to the quality of the output. Consider using techniques like few-shot learning, chain-of-thought prompting, and prompt templates.\n-   **Modular Tools:**\n    - Design tools to be as reusable and composable as possible. This will allow you to create more complex agent workflows by combining simpler tools.\n-   **Cost Tracking:**\n    - When using paid LLM APIs, it's important to track the cost of each agent run. This can help you optimize your prompts and agent workflows to reduce costs.\n-   **Monitoring:**\n    - Monitor your agents in production to identify issues and performance bottlenecks.  Implement logging and alerting to catch errors early.\n\nBy following these best practices, you can develop robust, maintainable, and efficient AI agent applications with smolagents.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "smolagents.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "smolagents",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "library",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "smolagents",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-socket-io",
    "description": "This rule provides guidelines and best practices for developing robust, scalable, and secure real-time applications using Socket.IO. It covers code organization, performance optimization, security considerations, testing strategies, and common pitfalls to avoid when working with Socket.IO.",
    "author": "sanjeed5",
    "tags": [
      "socket-io",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/socket-io.mdc",
    "content": "# Socket.IO Best Practices\n\nThis document outlines best practices for developing robust, scalable, and secure real-time applications using Socket.IO. It covers various aspects, from code organization to security considerations.\n\n## Library Information:\n- Name: socket-io\n- Tags: websockets, real-time, javascript, communication\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability and scalability. For Socket.IO projects, consider the following structure:\n\n\nproject-root/\n├── node_modules/\n├── src/\n│   ├── app.ts (or app.js)         # Main application entry point\n│   ├── config/                  # Configuration files\n│   │   └── socket.ts          # Socket.IO configuration\n│   ├── socket/                  # Socket event handlers and logic\n│   │   ├── index.ts             # Centralized socket connection and event handling\n│   │   ├── events/             # Directory for different socket event modules\n│   │   │   ├── chat.ts        # Chat-related events\n│   │   │   ├── notifications.ts # Notification-related events\n│   │   │   └── ...            # Other event modules\n│   │   ├── middleware/          # Socket.IO middleware for authentication, etc.\n│   │   │   └── auth.ts        # Example authentication middleware\n│   │   └── utils/            # Utility functions for socket operations\n│   ├── models/                  # Data models\n│   ├── services/                # Business logic services\n│   ├── utils/                   # Utility functions\n│   ├── types/                   # TypeScript type definitions\n│   └── public/                  # Static assets (if applicable)\n├── tests/                   # Unit and integration tests\n├── .env                       # Environment variables\n├── package.json               # Project dependencies and scripts\n├── tsconfig.json              # TypeScript configuration (if using TypeScript)\n└── README.md                  # Project documentation\n\n\n### File Naming Conventions\n\n*   Use descriptive names for files and directories.\n*   Follow a consistent naming convention (e.g., `camelCase` or `kebab-case`).\n*   For TypeScript projects, use `.ts` for source files and `.d.ts` for declaration files.\n\n### Module Organization\n\n*   Break down your application into smaller, modular components.\n*   Use ES modules (import/export) or CommonJS (require) for module organization.\n*   Consider using a dependency injection container for managing dependencies.\n\n### Component Architecture\n\n*   Adopt a component-based architecture to promote reusability and separation of concerns.\n*   Create reusable components for common Socket.IO tasks, such as message handling or authentication.\n*   Utilize design patterns like the Observer pattern for managing socket events.\n\n### Code Splitting\n\n*   For large applications, consider using code splitting to reduce the initial bundle size.\n*   Load socket event handlers on demand when they are needed.\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns\n\n*   **Observer Pattern:** Used extensively in Socket.IO to manage real-time updates.\n*   **Factory Pattern:** Create socket instances and event handlers.\n*   **Middleware Pattern:** Implement authentication, authorization, and data validation.\n\n### Recommended Approaches\n\n*   Use a class-based approach to encapsulate socket-related logic.\n*   Organize your code into namespaces and rooms to manage different parts of your application effectively.\n*   Implement automatic reconnection and handle disconnections gracefully.\n*   Use heartbeats to maintain active connections.\n\n### Anti-patterns\n\n*   **Global Socket Instance:** Avoid using a global socket instance. Instead, pass the socket instance to the relevant components.\n*   **Overly Complex Event Handlers:** Keep event handlers small and focused. Delegate complex logic to separate functions or services.\n*   **Ignoring Errors:** Always handle errors properly and log them for debugging purposes.\n*   **Sending Large Payloads:** Avoid sending large payloads over Socket.IO. Optimize your data structures and compress data if necessary.\n*   **Tight Coupling:** Avoid tight coupling between your socket event handlers and your application logic. Use dependency injection or other techniques to decouple your code.\n\n### State Management\n\n*   Use a centralized state management solution (e.g., Redux, Zustand, or a simple in-memory store) to manage the state of your Socket.IO application.\n*   Keep the state synchronized between the client and the server.\n*   Use immutable data structures to simplify state management and prevent unexpected side effects.\n\n### Error Handling\n\n*   Use try-catch blocks to handle synchronous errors.\n*   Use promise rejections to handle asynchronous errors.\n*   Implement a global error handler to catch unhandled exceptions.\n*   Log all errors to a file or a monitoring service.\n*   Consider using a circuit breaker pattern to prevent cascading failures.\n*   Inform the client about errors in a user-friendly way.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   Minimize data transmission size and frequency.\n*   Use data compression techniques (e.g., gzip or brotli) to reduce payload sizes.\n*   Optimize message payloads (e.g., use binary data instead of JSON strings).\n*   Use namespaces and rooms to target messages to specific clients.\n*   Implement pagination or filtering to reduce the amount of data sent to the client.\n\n### Memory Management\n\n*   Monitor memory usage and identify memory leaks.\n*   Use garbage collection to reclaim unused memory.\n*   Avoid creating large objects in memory.\n*   Use streams to process large data sets.\n\n### Rendering Optimization\n\n*   Use virtual DOM techniques to minimize DOM updates.\n*   Batch DOM updates to improve performance.\n*   Use CSS transforms and animations instead of JavaScript animations.\n\n### Bundle Size Optimization\n\n*   Use a bundler (e.g., Webpack, Parcel, or Rollup) to optimize your JavaScript bundles.\n*   Minify and compress your JavaScript code.\n*   Remove unused code (dead code elimination).\n*   Use code splitting to load code on demand.\n\n### Lazy Loading\n\n*   Load socket event handlers on demand when they are needed.\n*   Lazy load images and other assets.\n*   Use dynamic imports to load modules on demand.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and encoding output.\n*   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or an ORM.\n*   **Denial-of-Service (DoS):** Prevent DoS attacks by limiting request rates and using a CDN.\n*   **Man-in-the-Middle (MitM):** Prevent MitM attacks by using HTTPS and validating SSL/TLS certificates.\n*   **Unauthorized Access:** Prevent unauthorized access by implementing proper authentication and authorization mechanisms.\n\n### Input Validation\n\n*   Validate all incoming data on the server-side.\n*   Use a schema validation library (e.g., Joi or Yup) to define and enforce data schemas.\n*   Sanitize user input to prevent XSS attacks.\n*   Escape special characters to prevent SQL injection attacks.\n\n### Authentication and Authorization\n\n*   Use a strong authentication mechanism (e.g., JSON Web Tokens (JWT) or OAuth 2.0).\n*   Implement role-based access control (RBAC) to restrict access to sensitive resources.\n*   Use HTTPS to protect authentication credentials in transit.\n*   Store passwords securely using a hashing algorithm (e.g., bcrypt).\n*   Implement two-factor authentication (2FA) for enhanced security.\n*   Use Socket.IO middleware to authenticate users before allowing them to connect.\n\n### Data Protection\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use a strong encryption algorithm (e.g., AES-256).\n*   Store encryption keys securely.\n*   Implement data masking to protect sensitive data from unauthorized access.\n*   Comply with relevant data privacy regulations (e.g., GDPR or CCPA).\n\n### Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Validate SSL/TLS certificates.\n*   Implement rate limiting to prevent DoS attacks.\n*   Use API keys or tokens to authenticate API requests.\n*   Log all API requests and responses for auditing purposes.\n\n## 5. Testing Approaches\n\n### Unit Testing\n\n*   Write unit tests for individual components and functions.\n*   Use a testing framework (e.g., Jest, Mocha, or Jasmine).\n*   Mock dependencies to isolate the component being tested.\n*   Test edge cases and error conditions.\n*   Aim for high code coverage.\n\n### Integration Testing\n\n*   Write integration tests to verify that different parts of your application work together correctly.\n*   Test the interaction between Socket.IO clients and the server.\n*   Use a testing framework (e.g., Supertest or Cypress).\n*   Set up a test environment that mimics the production environment.\n\n### End-to-End Testing\n\n*   Write end-to-end tests to simulate real-world user scenarios.\n*   Use a testing framework (e.g., Selenium, Puppeteer, or Cypress).\n*   Test the entire application stack, from the client to the database.\n*   Test performance and scalability under load.\n\n### Test Organization\n\n*   Organize your tests in a separate directory (e.g., `tests`).\n*   Use a consistent naming convention for test files.\n*   Group tests by component or feature.\n*   Write clear and concise test descriptions.\n\n### Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate components and simplify testing.\n*   Use a mocking library (e.g., Sinon.js or Jest's built-in mocking capabilities).\n*   Mock external dependencies, such as databases or APIs.\n*   Stub functions to control their behavior during testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes\n\n*   Forgetting to handle disconnections gracefully.\n*   Not validating user input.\n*   Not securing WebSocket connections.\n*   Using a global socket instance.\n*   Overly complex event handlers.\n*   Ignoring errors.\n*   Sending large payloads.\n*   Tight coupling.\n*   Not monitoring memory usage.\n*   Not testing the application thoroughly.\n\n### Edge Cases\n\n*   Handling network interruptions and reconnections.\n*   Dealing with slow or unreliable connections.\n*   Managing multiple concurrent connections.\n*   Handling large data sets.\n*   Dealing with different browser implementations of WebSockets.\n\n### Version-Specific Issues\n\n*   Be aware of breaking changes between Socket.IO versions.\n*   Consult the Socket.IO changelog for information about version-specific issues.\n*   Test your application thoroughly after upgrading Socket.IO.\n\n### Compatibility Concerns\n\n*   Ensure that your Socket.IO client and server versions are compatible.\n*   Be aware of compatibility issues between Socket.IO and other technologies, such as load balancers or firewalls.\n\n### Debugging Strategies\n\n*   Use the Socket.IO client and server debug logs to troubleshoot issues.\n*   Use browser developer tools to inspect WebSocket traffic.\n*   Use a network monitoring tool (e.g., Wireshark) to capture and analyze network packets.\n*   Use a code debugger (e.g., VS Code's built-in debugger) to step through your code and inspect variables.\n\n## 7. Tooling and Environment\n\n### Recommended Tools\n\n*   **Code Editor:** VS Code, Sublime Text, or Atom\n*   **Testing Framework:** Jest, Mocha, or Jasmine\n*   **Bundler:** Webpack, Parcel, or Rollup\n*   **Linting and Formatting:** ESLint and Prettier\n*   **Network Monitoring:** Wireshark\n*   **Load Testing:** Apache JMeter or Artillery\n\n### Build Configuration\n\n*   Use a build tool (e.g., Webpack or Parcel) to automate the build process.\n*   Configure your build tool to minify and compress your JavaScript code.\n*   Use environment variables to configure your application for different environments (e.g., development, testing, and production).\n\n### Linting and Formatting\n\n*   Use a linter (e.g., ESLint) to enforce code style and identify potential errors.\n*   Use a code formatter (e.g., Prettier) to automatically format your code.\n*   Configure your linter and formatter to work together seamlessly.\n*   Use a Git hook to run your linter and formatter before committing code.\n\n### Deployment Best Practices\n\n*   Use a process manager (e.g., PM2 or Nodemon) to manage your Node.js application.\n*   Deploy your application to a cloud platform (e.g., AWS, Azure, or Google Cloud).\n*   Use a load balancer to distribute traffic across multiple servers.\n*   Use a CDN to serve static assets.\n*   Monitor your application's performance and uptime.\n\n### CI/CD Integration\n\n*   Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   Use a CI/CD tool (e.g., Jenkins, Travis CI, or CircleCI).\n*   Run unit tests, integration tests, and end-to-end tests as part of your CI/CD pipeline.\n*   Automate the deployment process to reduce the risk of human error.\n\nBy following these best practices, you can develop robust, scalable, and secure real-time applications using Socket.IO. Remember to adapt these guidelines to your specific project requirements and context.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx",
      "format": "mdc",
      "originalFile": "socket-io.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "socket",
      "io",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "developing",
      "robust",
      "scalable",
      "secure",
      "socket-io",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "socket-io",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-solidity",
    "description": "This rule provides best practices and coding standards for Solidity smart contract development, covering code organization, security, performance, and testing.",
    "author": "sanjeed5",
    "tags": [
      "solidity",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/solidity.mdc",
    "content": "# Solidity Smart Contract Best Practices and Coding Standards\n\nThis guide provides comprehensive best practices and coding standards for writing secure, efficient, and maintainable Solidity smart contracts. It covers various aspects of smart contract development, from code organization to security considerations.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **contracts/:** Contains Solidity contract files (.sol).\n*   **interfaces/:**  Contains interface definitions (.sol).\n*   **libraries/:**  Contains reusable libraries (.sol).\n*   **test/:** Contains test scripts (e.g., using Hardhat, Foundry, or Truffle).\n*   **scripts/:** Contains deployment and utility scripts.\n*   **deployments/:** Stores contract deployment information (addresses, ABIs, etc.).\n*   **artifacts/:** (Typically generated) Contains compiled contract ABIs and bytecode.\n*   **node_modules/:** (Typically generated) Contains installed npm packages.\n\nExample:\n\n\nmy-project/\n├── contracts/\n│   ├── MyContract.sol\n│   └── ERC20.sol\n├── interfaces/\n│   └── IMyContract.sol\n├── libraries/\n│   └── SafeMath.sol\n├── test/\n│   ├── MyContract.test.js\n│   └── ERC20.test.js\n├── scripts/\n│   ├── deploy.js\n│   └── utils.js\n├── deployments/\n│   └── rinkeby/\n│       └── MyContract.json\n├── artifacts/\n│   └── contracts/\n│       ├── MyContract.json\n│       └── ERC20.json\n├── node_modules/\n├── hardhat.config.js\n├── package.json\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   Use PascalCase for contract names (e.g., `MyContract.sol`).\n*   Use PascalCase starting with I for interface names (e.g., `IMyContract.sol`).\n*   Use PascalCase for library names (e.g., `SafeMath.sol`).\n*   Filenames should match the contract name defined within the file.\n\n### 1.3. Module Organization\n\n*   Keep contracts small and focused on a single responsibility (Single Responsibility Principle).\n*   Use libraries for reusable code blocks and mathematical operations.\n*   Use interfaces to define the functionality of contracts without implementation.\n*   Group related contracts into modules or subdirectories.\n\n### 1.4. Component Architecture\n\n*   **Modular Design:** Break down complex systems into smaller, manageable, and reusable components.\n*   **Layered Architecture:** Separate concerns into different layers (e.g., data access, business logic, presentation).\n*   **Dependency Injection:**  Decouple components by injecting dependencies instead of hardcoding them.\n\n### 1.5. Code Splitting Strategies\n\n*   Use libraries for common functionality to reduce contract size and gas costs.\n*   Consider using the delegatecall pattern for complex logic, but be aware of the security implications.\n*   Split large contracts into smaller, more manageable contracts using inheritance or composition.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Ownable:** Restricts access to certain functions to the contract owner.\n*   **Pausable:** Allows pausing contract functionality in case of emergency.\n*   **Pull over Push:** Favors withdrawing funds over automatically sending them.\n*   **Proxy Pattern:** Allows upgrading contract logic without changing the contract address (e.g., using UUPS or transparent proxies).\n*   **Factory Pattern:**  Used to create new contract instances.\n*   **State Machine:** Manages different states of a contract.\n*   **Circuit Breaker:** Prevents a function from being called if it has repeatedly failed.\n\n### 2.2. Recommended Approaches\n\n*   Use SafeMath library for arithmetic operations to prevent overflows and underflows (or use Solidity >= 0.8.0, which includes built-in overflow/underflow protection).\n*   Use events to log important state changes.\n*   Use modifiers to enforce access control and preconditions.\n*   Follow the Checks-Effects-Interactions pattern to prevent reentrancy attacks.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Unchecked Arithmetic:** Not using SafeMath or built-in overflow/underflow protection.\n*   **Reentrancy:**  Vulnerable to reentrancy attacks.\n*   **Timestamp Dependence:**  Relying on block timestamps for critical logic.\n*   **Integer Overflow/Underflow:** Not handling potential overflows and underflows.\n*   **Gas Limit Issues:**  Causing transactions to run out of gas.\n*   **Centralization:** Over-reliance on a single administrator or owner.\n*   **Magic Numbers:** Using hardcoded values without explanation.\n*   **Tight Coupling:** Components are highly dependent on each other, making it difficult to modify or reuse them.\n\n### 2.4. State Management Best Practices\n\n*   Minimize state variables to reduce gas costs.\n*   Use appropriate data types for state variables.\n*   Initialize state variables correctly.\n*   Consider using immutables for constants.\n*   Use structs and mappings to organize related data.\n\n### 2.5. Error Handling Patterns\n\n*   Use `require()` to validate inputs and preconditions.\n*   Use `revert()` to handle errors and return informative error messages.\n*   Use custom errors to provide more context about errors (Solidity >= 0.8.4).\n*   Avoid using `assert()` in production code (it consumes all remaining gas).\n*   Consider using try/catch blocks for external calls.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Gas Optimization:** Aim to reduce gas consumption by using efficient data structures, minimizing storage writes, and optimizing control flow.\n*   **Storage Optimization:** Minimize storage usage by using appropriate data types and packing variables.\n*   **Function Optimization:** Optimize functions by reducing the number of operations and minimizing gas costs.\n*   **Loop Optimization:** Avoid unnecessary loops and optimize loop conditions.\n*   **Use Calldata:** Pass function arguments as calldata instead of memory when possible.\n*   **Short Circuiting:**  Leverage short circuiting in conditional statements.\n\n### 3.2. Memory Management\n\n*   Minimize memory usage by using calldata for function arguments when possible.\n*   Avoid creating large arrays in memory.\n*   Use memory efficiently in loops.\n*   Consider using assembly for memory-intensive operations.\n\n### 3.3. Rendering Optimization (Applicable for front-ends interacting with contracts)\n\n*  This section refers to optimization of the front-end, typically written in Javascript, used to display data from the blockchain. Data retrieved from the blockchain should be displayed in an efficient manner. This is more applicable to traditional software engineering, and less applicable to Solidity itself. For the sake of completeness, it's added here.\n*   Use virtualization or pagination for large datasets.\n*   Optimize rendering logic to minimize DOM updates.\n*   Use caching to avoid unnecessary re-renders.\n\n### 3.4. Bundle Size Optimization (Applicable for front-ends interacting with contracts)\n*  This section refers to optimization of the front-end, typically written in Javascript, used to display data from the blockchain. The bundle size of the front end app should be as minimal as possible, to provide a performant user experience. This is more applicable to traditional software engineering, and less applicable to Solidity itself. For the sake of completeness, it's added here.\n*   Remove unused code and dependencies.\n*   Use code splitting to load only necessary code.\n*   Compress assets (images, JavaScript, CSS).\n\n### 3.5. Lazy Loading Strategies (Applicable for front-ends interacting with contracts)\n*  This section refers to optimization of the front-end, typically written in Javascript, used to display data from the blockchain. Lazy loading can be used to improve the performance of a front-end that interacts with a blockchain. This is more applicable to traditional software engineering, and less applicable to Solidity itself. For the sake of completeness, it's added here.\n*   Load images and other resources only when they are needed.\n*   Use lazy loading for off-screen components.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **Reentrancy:** Prevent reentrancy attacks by following the Checks-Effects-Interactions pattern, using reentrancy guards, or using `transfer()`/`send()` to limit gas available for callbacks.\n*   **Integer Overflow/Underflow:** Use SafeMath or built-in overflow/underflow protection (Solidity >= 0.8.0).\n*   **Denial of Service (DoS):** Protect against DoS attacks by limiting gas consumption, avoiding unbounded loops, and using pull-over-push pattern.\n*   **Timestamp Dependence:** Avoid relying on block timestamps for critical logic, as they can be manipulated by miners.\n*   **Front Running:** Protect against front running by using commit-reveal schemes or off-chain order matching.\n*   **Gas Limit Issues:** Ensure that functions do not consume excessive gas, which can lead to transactions running out of gas.\n*   **Delegatecall:** Be extremely careful when using `delegatecall`, as the called contract can modify the caller's storage.\n*   **Uninitialized Storage Pointers:** Ensure all storage pointers are initialized before use.\n*   **Access Control:** Implement robust access control mechanisms to restrict access to sensitive functions and data.\n*   **Signature Replay:** Use nonces or other mechanisms to prevent signature replay attacks.\n\n### 4.2. Input Validation\n\n*   Validate all inputs to ensure they are within expected ranges.\n*   Check for zero addresses and invalid values.\n*   Sanitize inputs to prevent injection attacks.\n*   Use appropriate data types for inputs.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **Ownable:** Use the Ownable pattern to restrict access to certain functions to the contract owner.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to assign different roles to users and grant them specific permissions.\n*   **Multi-Signature Wallets:** Use multi-signature wallets for critical operations that require multiple approvals.\n*   **Access Control Lists (ACLs):** Use ACLs to define fine-grained access control rules.\n\n### 4.4. Data Protection Strategies\n\n*   Use encryption to protect sensitive data.\n*   Store sensitive data off-chain.\n*   Use access control to restrict access to sensitive data.\n*   Consider using zero-knowledge proofs for privacy.\n\n### 4.5. Secure API Communication\n\n*   Use HTTPS for secure communication.\n*   Validate all data received from external sources.\n*   Implement rate limiting to prevent abuse.\n*   Use authentication and authorization to protect APIs.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   Write unit tests for all functions.\n*   Test all possible scenarios and edge cases.\n*   Use assertions to verify expected behavior.\n*   Use code coverage tools to ensure that all code is tested.\n*   Test state transitions and event emissions.\n\n### 5.2. Integration Testing\n\n*   Test interactions between multiple contracts.\n*   Test integration with external systems.\n*   Test deployment and upgrade processes.\n\n### 5.3. End-to-End Testing\n\n*   Test the entire system from end to end.\n*   Simulate real-world scenarios.\n*   Test user interactions and workflows.\n\n### 5.4. Test Organization\n\n*   Organize tests into separate files or directories.\n*   Use descriptive test names.\n*   Group tests by functionality or module.\n\n### 5.5. Mocking and Stubbing\n\n*   Use mocking to isolate contracts and simulate dependencies.\n*   Use stubbing to replace external calls with predefined responses.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Unchecked Arithmetic:** Not using SafeMath or built-in overflow/underflow protection.\n*   **Reentrancy:** Not protecting against reentrancy attacks.\n*   **Timestamp Dependence:** Relying on block timestamps for critical logic.\n*   **Gas Limit Issues:** Causing transactions to run out of gas.\n*   **Ignoring Event Emissions:** Failing to emit events for important state changes, making off-chain monitoring and indexing difficult.\n\n### 6.2. Edge Cases\n\n*   **Zero Values:** Handling cases where input values are zero.\n*   **Large Numbers:** Handling cases where input values are very large.\n*   **Empty Strings:** Handling cases where input strings are empty.\n*   **Extreme Conditions:** Testing the contract under extreme network conditions, such as high gas prices or network congestion.\n\n### 6.3. Version-Specific Issues\n\n*   Be aware of breaking changes between Solidity versions.\n*   Test your contracts with the target Solidity version.\n*   Use the latest compiler version to leverage improvements and security patches.\n\n### 6.4. Compatibility Concerns\n\n*   Ensure compatibility with different Ethereum clients and networks.\n*   Test your contracts on different testnets before deploying to mainnet.\n*   Consider compatibility with different wallets and browsers.\n\n### 6.5. Debugging Strategies\n\n*   Use debugging tools like Remix, Hardhat, or Truffle.\n*   Use console.log statements for debugging.\n*   Use event logs to track state changes.\n*   Use revert reasons to understand why transactions failed.\n*   Use fuzzing to find unexpected behavior and vulnerabilities.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Remix:** Online IDE for writing, compiling, and deploying Solidity contracts.\n*   **Hardhat:** Development environment for Ethereum smart contracts.\n*   **Truffle:** Development framework for Ethereum with testing and deployment capabilities.\n*   **Foundry:** Blazing-fast, portable and modular toolkit for Ethereum application development\n*   **VS Code:** Code editor with Solidity extensions for syntax highlighting, linting, and debugging.\n\n### 7.2. Build Configuration\n\n*   Use a build tool like Hardhat or Truffle to manage the build process.\n*   Configure the compiler version and optimization settings.\n*   Generate contract ABIs and bytecode.\n\n### 7.3. Linting and Formatting\n\n*   Use a linter like Solhint to enforce code style and best practices.\n*   Use a formatter like Prettier to format code consistently.\n*   Configure linting and formatting rules to match your project's standards.\n\n### 7.4. Deployment Best Practices\n\n*   Deploy contracts to a testnet before deploying to mainnet.\n*   Verify contract code on Etherscan.\n*   Use a deployment script to automate the deployment process.\n*   Store contract deployment information (addresses, ABIs, etc.).\n\n### 7.5. CI/CD Integration\n\n*   Integrate testing and deployment into your CI/CD pipeline.\n*   Run tests automatically on every commit.\n*   Automate the deployment process to reduce errors.\n\nBy following these best practices, you can write more secure, efficient, and maintainable Solidity smart contracts.",
    "metadata": {
      "globs": "*.sol",
      "format": "mdc",
      "originalFile": "solidity.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "solidity",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "smart",
      "contract",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "solidity",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-solidjs",
    "description": "This comprehensive guide outlines best practices for SolidJS development, covering code organization, performance, security, testing, and common pitfalls. It provides actionable guidelines for building maintainable, efficient, and secure SolidJS applications.",
    "author": "sanjeed5",
    "tags": [
      "solidjs",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/solidjs.mdc",
    "content": "# SolidJS Best Practices: A Comprehensive Guide\n\nThis document provides a detailed overview of best practices for SolidJS development, covering various aspects from code organization to security and performance. It aims to guide developers in building robust, scalable, and maintainable SolidJS applications.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nA well-defined directory structure is crucial for maintaining a large SolidJS application. Here's a recommended structure:\n\n\nmy-solid-app/\n├── src/\n│   ├── components/\n│   │   ├── Button/\n│   │   │   ├── Button.tsx\n│   │   │   ├── Button.module.css\n│   │   │   ├── Button.test.tsx\n│   │   ├── Card/\n│   │   │   ├── Card.tsx\n│   │   │   ├── Card.module.css\n│   │   ├── index.ts # Exports all components\n│   ├── contexts/\n│   │   ├── ThemeContext.tsx\n│   ├── hooks/\n│   │   ├── useTheme.ts\n│   ├── utils/\n│   │   ├── api.ts\n│   │   ├── helpers.ts\n│   ├── routes/\n│   │   ├── Home.tsx\n│   │   ├── About.tsx\n│   ├── styles/\n│   │   ├── global.css\n│   ├── App.tsx\n│   ├── index.tsx\n│   ├── types.d.ts # Global type definitions\n│   ├── vite-env.d.ts # vite type definitions\n├── public/\n│   ├── favicon.svg\n│   ├── assets/\n├── .env\n├── vite.config.ts\n├── tsconfig.json\n├── package.json\n├── README.md\n\n\n**Explanation:**\n\n*   **src/:** Contains the source code of your application.\n    *   **components/:** Reusable UI components. Each component should have its own directory containing the component file, styles, and tests.\n    *   **contexts/:** SolidJS Context providers for managing global state and shared data.\n    *   **hooks/:** Custom hooks for reusable logic.\n    *   **utils/:** Utility functions such as API calls, data formatting, etc.\n    *   **routes/:** Components that define different routes in your application.\n    *   **styles/:** Global styles or shared CSS modules.\n    *   **App.tsx:** The root component of your application.\n    *   **index.tsx:** Entry point for rendering the App component into the DOM.\n    *   **types.d.ts:** Global typescript type definitions for the project\n    *   **vite-env.d.ts:** vite environment type definitions\n*   **public/:** Static assets such as images, fonts, etc.\n*   **.env:** Stores environment variables.\n*   **vite.config.ts:** Vite configuration file.\n*   **tsconfig.json:** TypeScript configuration file.\n*   **package.json:** Node.js package file.\n*   **README.md:** Project documentation.\n\n### 1.2 File Naming Conventions\n\n*   **Components:** Use PascalCase for component file names (e.g., `Button.tsx`, `UserProfile.jsx`).\n*   **Hooks:** Use camelCase prefixed with `use` for hook file names (e.g., `useTheme.ts`, `useFetchData.js`).\n*   **Utilities:** Use camelCase for utility file names (e.g., `api.ts`, `formatDate.js`).\n*   **Styles:** Use the `.module.css` extension for CSS modules (e.g., `Button.module.css`). If using other styling solutions like styled-components, follow their recommended practices.\n\n### 1.3 Module Organization\n\n*   **Keep components modular:** Each component should have a single responsibility.\n*   **Export components:** Export components to make them reusable in other parts of the application (e.g., `export default Button;`).\n*   **Create an `index.ts` file:** In each directory (e.g., `components/`) export all the modules in that directory. This allows simpler imports from other components. e.g., `import {Button, Card} from '../components'`\n\n### 1.4 Component Architecture\n\n*   **Functional Components:** Use functional components with Solid's reactivity system for managing state and UI updates. Avoid class components.\n*   **Props:** Use props to pass data from parent to child components. Be explicit about prop types using TypeScript.\n*   **Context API:** Use Solid's Context API for sharing data between components without prop drilling. Use cases: themes, user authentication, global configuration.\n*   **Signals:** Employ SolidJS Signals for managing component-level state. Prefer derived signals or memoization for expensive computations.\n\n### 1.5 Code Splitting Strategies\n\n*   **Route-Based Splitting:** Use dynamic imports to load components only when a route is visited. Leverage Solid Router's lazy loading capabilities with `lazy`.\n*   **Component-Based Splitting:** Split large components into smaller chunks that can be loaded on demand. Use `Suspense` to handle loading states.\n*   **Library Splitting:** If using large libraries, consider splitting them into smaller chunks or using tree-shaking to remove unused code.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to SolidJS\n\n*   **Renderless Components:** Create components that encapsulate logic without rendering any UI elements. They can be used as hooks or utility functions to share logic between components.\n*   **Compound Components:** Build components that work together implicitly, often using Context to share state. (e.g., Tabs, Accordions).\n*   **Reactivity-Based Composition:** Compose components based on shared reactive state, rather than inheritance. This allows more flexibility and better performance.\n*   **Custom Control Flow Components:** Create reusable components to handle conditional rendering or list iteration with specific optimization strategies. Examples include more performant alternatives to `<For/>` in certain specific use cases.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Fetching Data:** Use `createResource` for handling asynchronous data fetching. Use `AbortController` for cancelling requests on component unmount or data changes.\n*   **Managing Forms:** Use signals to track form input values. Implement validation logic and handle form submission.\n*   **Handling Events:** Attach event handlers to elements using JSX attributes (e.g., `onClick`). Use arrow functions or bind methods to ensure correct `this` context.\n*   **Global State Management:** Use Solid's Context API or a dedicated state management library (e.g., `solid-zustand`, `solid-js/store`) for sharing data between components.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Reading and Writing to the Same Signal in an Effect:** This creates an infinite loop. Use the functional update form `setCount(count => count + 1)` or derived signals.\n*   **Writing to Signals in Effects for Derived Values:** Prefer derived signals or memoization for expensive computations (using `createMemo`).\n*   **Destructuring Props:** This breaks reactivity. Access props directly or use `mergeProps` and `splitProps`.\n*   **Using `.map` and Ternary Operators for Control Flow:** Use Solid's control flow components (`<For>`, `<Index>`, `<Show>`) to avoid unnecessary DOM elements.\n*   **Mutating Resource Data Directly:** Always create new objects when mutating resource data to prevent unnecessary re-renders. use `createMutable` judiciously only where mutability is needed.\n*   **Ignoring Cleanup Functions:** Neglecting `onCleanup` can lead to memory leaks and unexpected behavior when components unmount.\n\n### 2.4 State Management Best Practices\n\n*   **Component-Level State:** Use signals for managing simple, component-specific state.\n*   **Context API:** For sharing data between components without prop drilling, especially themes or user authentication.\n*   **Global Stores:** Use store solutions or third-party libraries (e.g., `solid-zustand`, `solid-js/store`) for complex global state management.\n*   **Immutability:** Treat state as immutable.  Always create new objects/arrays when updating state, especially with resources or stores.\n*   **Single Source of Truth:** Ensure that each piece of state has a single, authoritative source. Avoid duplicating state across components.\n\n### 2.5 Error Handling Patterns\n\n*   **`Suspense` for Loading States:** Wrap asynchronous operations like `createResource` with `Suspense` to display loading indicators.\n*   **Error Boundaries:** Implement error boundaries to catch errors during rendering and display fallback UI.\n*   **Try-Catch Blocks:** Use `try-catch` blocks for handling synchronous errors or errors in event handlers.\n*   **Centralized Error Logging:** Implement a centralized error logging mechanism to track and monitor errors in your application.\n*   **User-Friendly Error Messages:** Display user-friendly error messages to guide users on how to resolve issues.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Fine-Grained Reactivity:** Solid's fine-grained reactivity ensures that only the necessary parts of the UI are updated when state changes. Leverage this by breaking down components into smaller, more focused units.\n*   **Derived Signals and Memos:** Use derived signals and memos to avoid recomputing expensive values unnecessarily.\n*   **Control Flow Components:** Use `<For>`, `<Index>`, and `<Show>` for efficient conditional rendering and list iteration.\n*   **Lazy Loading:** Load components and modules only when they are needed.\n*   **Virtualization:** For rendering large lists, use virtualization techniques to only render the visible items.\n*   **Debouncing and Throttling:** Implement debouncing or throttling for event handlers that trigger frequent updates.\n\n### 3.2 Memory Management\n\n*   **Cleanup Functions:** Always use `onCleanup` to release resources when a component is unmounted, such as timers, event listeners, and subscriptions.\n*   **Avoid Memory Leaks:** Be mindful of potential memory leaks when using closures or retaining references to DOM elements.\n*   **Weak References:** Use `WeakRef` or `WeakMap` for holding references to objects without preventing them from being garbage collected.\n\n### 3.3 Rendering Optimization\n\n*   **Minimize DOM Updates:** Solid's reactivity system minimizes DOM updates, but avoid unnecessary renders by optimizing component structure and state management.\n*   **Batch Updates:** Use `batchedUpdates` to batch multiple state updates into a single render cycle (use with caution).\n*   **Avoid Inline Styles:** Prefer CSS classes or CSS modules for styling components.\n*   **Use CSS Transitions and Animations:** Leverage CSS transitions and animations for smoother UI updates.\n\n### 3.4 Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from your bundle. Vite automatically performs tree shaking.\n*   **Code Splitting:** Split your application into smaller chunks that can be loaded on demand.\n*   **Minification and Compression:** Minify and compress your code to reduce bundle size. Vite handles minification by default.\n*   **Image Optimization:** Optimize images by compressing them and using appropriate formats (e.g., WebP).\n*   **Dependency Analysis:** Analyze your dependencies to identify and remove unnecessary libraries.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Route-Based Lazy Loading:** Load components only when a route is visited using dynamic imports and the `lazy` function from Solid Router.\n*   **Component-Based Lazy Loading:** Split large components into smaller chunks that can be loaded on demand.\n*   **Conditional Lazy Loading:** Load components based on specific conditions, such as user interactions or device capabilities.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user inputs and escaping data when rendering it in the DOM. Avoid using `dangerouslySetInnerHTML`.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection by using anti-CSRF tokens in forms and validating them on the server.\n*   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or ORMs when interacting with databases.\n*   **Authentication and Authorization:** Secure your application by implementing proper authentication and authorization mechanisms.\n*   **Denial-of-Service (DoS):** Protect against DoS attacks by implementing rate limiting, input validation, and resource quotas.\n\n### 4.2 Input Validation\n\n*   **Server-Side Validation:** Always validate user inputs on the server to prevent malicious data from being stored in your database.\n*   **Client-Side Validation:** Provide client-side validation for a better user experience, but never rely on it as the sole means of protection.\n*   **Sanitize Inputs:** Sanitize user inputs to remove potentially harmful characters or code.\n*   **Use Validation Libraries:** Use validation libraries to simplify the input validation process.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **JSON Web Tokens (JWT):** Use JWTs for managing user authentication and authorization.\n*   **OAuth 2.0:** Implement OAuth 2.0 for third-party authentication and authorization.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Multi-Factor Authentication (MFA):** Implement MFA for enhanced security.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit using appropriate encryption algorithms.\n*   **Data Masking:** Mask sensitive data when displaying it to users or storing it in logs.\n*   **Data Redaction:** Redact sensitive data from logs and audit trails.\n*   **Data Retention Policies:** Implement data retention policies to ensure that data is only stored for as long as it is needed.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n*   **API Keys:** Use API keys for authenticating clients and controlling access to your APIs.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse of your APIs.\n*   **Input Validation:** Validate all API inputs to prevent malicious data from being processed.\n*   **Output Encoding:** Encode API outputs to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components in isolation.\n*   **Mock Dependencies:** Mock dependencies to isolate the component being tested.\n*   **Test All Scenarios:** Test all possible scenarios and edge cases.\n*   **Use Assertions:** Use assertions to verify that the component behaves as expected.\n\n### 5.2 Integration Testing\n\n*   **Test Component Interactions:** Integration tests should focus on testing the interactions between components.\n*   **Mock External Services:** Mock external services to isolate the component being tested.\n*   **Test Data Flow:** Test the flow of data between components.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Application:** End-to-end tests should focus on testing the entire application from the user's perspective.\n*   **Use a Testing Framework:** Use a testing framework such as Cypress or Playwright to automate the testing process.\n*   **Test User Flows:** Test common user flows to ensure that the application works as expected.\n\n### 5.4 Test Organization\n\n*   **Colocate Tests:** Place test files alongside the components they are testing.\n*   **Use a Consistent Naming Convention:** Use a consistent naming convention for test files (e.g., `Button.test.tsx`).\n*   **Organize Tests by Feature:** Organize tests by feature or module.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking Libraries:** Use mocking libraries such as Jest or Vitest to create mocks and stubs.\n*   **Mock External Dependencies:** Mock external dependencies to isolate the component being tested.\n*   **Stub API Calls:** Stub API calls to control the data returned by the API.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Incorrectly Using Effects:** Misunderstanding the dependency tracking of `createEffect` can lead to unnecessary re-runs or infinite loops.\n*   **Forgetting `onCleanup`:** Not using `onCleanup` for resources and subscriptions causes memory leaks.\n*   **Mutating State Directly:** Directly mutating objects or arrays used as state leads to unexpected behavior and broken reactivity.\n*   **Over-Optimizing Prematurely:** Focusing on micro-optimizations before addressing fundamental architectural issues.\n*   **Not Understanding Solid's Reactivity:**  Failing to grasp the nuances of Solid's reactive system can lead to inefficient code.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **SSR Hydration Issues:** When doing SSR, ensure that the initial state on the server matches the client to avoid hydration errors.\n*   **Reactivity with Non-Reactive Values:**  Passing plain JS objects or arrays to components without making them reactive can cause issues with updates.\n*   **Transitions and Resource Updates:** Interactions between transitions and resource updates can sometimes be tricky, especially around loading states.\n*   **Nested Reactivity:** Managing reactivity in complex, deeply nested data structures can be challenging.\n\n### 6.3 Version-Specific Issues\n\n*   **Compatibility:** Consider backwards compatibility when upgrading SolidJS or related libraries.\n*   **Deprecations:** Be aware of deprecated features and APIs and migrate to the recommended alternatives.\n*   **Bug Fixes:** Stay up-to-date with bug fixes and security patches in newer versions of SolidJS.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:** Test your application in different browsers to ensure compatibility.\n*   **Device Compatibility:** Test your application on different devices, such as desktops, tablets, and mobile phones.\n*   **Accessibility:** Ensure that your application is accessible to users with disabilities.\n\n### 6.5 Debugging Strategies\n\n*   **Use Browser Developer Tools:** Use the browser's developer tools to inspect the DOM, network requests, and console output.\n*   **SolidJS Devtools:** Use the SolidJS Devtools extension to inspect components, signals, and resources.\n*   **Logging:** Add logging statements to your code to track the flow of execution and the values of variables.\n*   **Debugging Tools:** Use debugging tools such as VS Code's debugger to step through your code and inspect variables.\n*   **Reproducible Examples:** Create reproducible examples to isolate and debug issues more effectively.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Vite:** Use Vite as the build tool. SolidJS uses Vite as its default.\n*   **VS Code:** Use VS Code as the code editor, along with extensions for TypeScript, ESLint, and Prettier.\n*   **SolidJS Devtools:** Use the SolidJS Devtools browser extension to inspect components, signals, and resources.\n*   **TypeScript:** Utilize TypeScript for type safety and improved code maintainability.\n\n### 7.2 Build Configuration\n\n*   **Vite Configuration:** Configure Vite to optimize your build for production (e.g., code splitting, minification, compression).\n*   **TypeScript Configuration:** Configure TypeScript to enforce strict type checking and code quality.\n*   **Environment Variables:** Use environment variables to store sensitive data and configure your application for different environments.\n\n### 7.3 Linting and Formatting\n\n*   **ESLint:** Use ESLint to enforce code style and identify potential errors.\n*   **Prettier:** Use Prettier to automatically format your code.\n*   **Husky:** Use Husky to run linters and formatters before committing code.\n\n### 7.4 Deployment Best Practices\n\n*   **Choose a Hosting Platform:** Select a suitable hosting platform for your SolidJS application (e.g., Netlify, Vercel, AWS).\n*   **Configure a Production Environment:** Configure your hosting platform to use a production environment with appropriate settings.\n*   **Automate Deployment:** Automate the deployment process using CI/CD tools.\n*   **Monitor Your Application:** Monitor your application for errors and performance issues.\n\n### 7.5 CI/CD Integration\n\n*   **Choose a CI/CD Tool:** Select a CI/CD tool such as GitHub Actions, GitLab CI, or CircleCI.\n*   **Configure CI/CD Pipelines:** Configure CI/CD pipelines to automatically build, test, and deploy your application.\n*   **Automate Testing:** Automate unit tests, integration tests, and end-to-end tests in your CI/CD pipelines.\n*   **Automate Deployment:** Automate the deployment process to deploy new versions of your application with minimal manual intervention.\n\nThis document provides a comprehensive set of best practices for SolidJS development. By following these guidelines, developers can build high-quality, maintainable, and secure SolidJS applications.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "solidjs.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "solidjs",
      "this",
      "comprehensive",
      "guide",
      "outlines",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "solidjs",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-spacy",
    "description": "This rule file provides comprehensive best practices and coding standards for developing projects using spaCy, covering code organization, performance, security, testing, and more. It aims to guide developers in building maintainable, efficient, and secure NLP applications with spaCy.",
    "author": "sanjeed5",
    "tags": [
      "spacy",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/spacy.mdc",
    "content": "# spaCy Best Practices and Coding Standards\n\nThis document outlines the recommended best practices and coding standards for developing projects using spaCy. Adhering to these guidelines will result in more maintainable, efficient, and secure NLP applications.\n\n## Library Information:\n- Name: spaCy\n- Tags: python, nlp, text-processing\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nOrganizing your spaCy project with a clear directory structure enhances maintainability and collaboration. Here’s a recommended structure:\n\n\nproject_root/\n├── data/                  # Contains raw and processed datasets\n│   ├── raw/              # Raw data files (e.g., .txt, .csv)\n│   ├── processed/        # Processed data (e.g., spaCy Doc objects)\n│   └── README.md        # Description of the data and preprocessing steps\n├── models/                # Trained spaCy models\n│   ├── en_core_web_sm/   # Example model directory\n│   └── README.md        # Information about the trained models\n├── scripts/               # Python scripts for training, evaluation, and data processing\n│   ├── train.py           # Script for training the spaCy model\n│   ├── evaluate.py        # Script for evaluating the model\n│   ├── preprocess.py      # Script for preprocessing the data\n│   └── utils.py           # Utility functions\n├── components/            # Custom spaCy components\n│   ├── custom_ner.py      # Custom NER component\n│   └── custom_tokenizer.py # Custom tokenizer\n├── tests/                 # Unit and integration tests\n│   ├── unit/             # Unit tests\n│   ├── integration/      # Integration tests\n│   └── conftest.py        # Pytest configuration file\n├── notebooks/             # Jupyter notebooks for exploration and prototyping\n│   └── data_exploration.ipynb # Example notebook\n├── requirements.txt       # Project dependencies\n├── pyproject.toml         # Project configuration and build dependencies (recommended over setup.py)\n├── README.md            # Project overview and instructions\n├── .gitignore             # Specifies intentionally untracked files that Git should ignore\n└── .cursor/              # Cursor IDE configuration\n\n\n### 1.2 File Naming Conventions\n\nFollow these conventions for consistency and readability:\n\n- **Python Files:** `lowercase_with_underscores.py`\n- **Data Files:** `lowercase-with-hyphens.csv`\n- **Model Files:** `descriptive_name.spacy`\n- **Configuration Files:** `config.cfg` or `config.yaml`\n\n### 1.3 Module Organization\n\nOrganize your code into modules based on functionality:\n\n- **Data Processing:**  Modules for loading, cleaning, and transforming data.\n- **Model Training:** Modules for training spaCy models.\n- **Custom Components:** Modules for custom spaCy components (e.g., custom NER, custom tokenizer).\n- **Evaluation:** Modules for evaluating model performance.\n- **Utilities:** Modules for helper functions and shared logic.\n\n### 1.4 Component Architecture Recommendations\n\nWhen building custom spaCy components, follow these guidelines:\n\n- **Encapsulation:** Each component should have a well-defined purpose and encapsulate its logic.\n- **Modularity:**  Components should be designed to be reusable in different parts of your project.\n- **Configuration:** Make components configurable through parameters passed during initialization.\n- **Testing:**  Write unit tests for each component to ensure its correctness.\n\nExample of a custom component structure:\n\npython\n# components/custom_ner.py\nimport spacy\nfrom spacy.language import Language\nfrom spacy.tokens import Doc, Span\nfrom spacy.util import filter_spans\n\n@Language.factory(\n    \"custom_ner\",\n    default_config={\n        \"label\": \"CUSTOM\",\n        \"patterns\": []\n    },\n)\ndef create_custom_ner(\n    nlp: Language,\n    name: str,\n    label: str,\n    patterns: list\n):\n    return CustomNer(nlp, name, label, patterns)\n\n\nclass CustomNer:\n    def __init__(self, nlp: Language, name: str, label: str, patterns: list):\n        self.label = label\n        self.patterns = patterns\n        self.ruler = nlp.add_pipe(\"entity_ruler\")\n        self.ruler.add_patterns([{\"label\": self.label, \"pattern\": p} for p in self.patterns])\n\n\n    def __call__(self, doc: Doc) -> Doc:\n        #Add the custom patterns to the entity recognizer\n        doc.ents = filter_spans(doc.ents)\n        return doc\n\n\n### 1.5 Code Splitting Strategies\n\nFor large projects, split your code into smaller, manageable files:\n\n- **Functional Decomposition:** Split code based on functionality (e.g., data loading, preprocessing, model training).\n- **Component-Based Splitting:**  Each custom spaCy component should reside in its own file.\n- **Layered Architecture:** If applicable, separate the presentation, business logic, and data access layers.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Pipeline Pattern:** Leverage spaCy's pipeline architecture for sequential processing of text.\n- **Factory Pattern:** Use factory functions to create spaCy components with specific configurations.\n- **Strategy Pattern:** Implement different strategies for text processing (e.g., different tokenization methods) and switch between them based on the input.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Text Preprocessing:** Use spaCy's built-in tokenization, lemmatization, and stop word removal for efficient text preprocessing.\n- **Named Entity Recognition:** Utilize spaCy's NER capabilities or train custom NER models for specific entity types.\n- **Dependency Parsing:**  Leverage spaCy's dependency parser to extract relationships between words in a sentence.\n- **Similarity Analysis:**  Use spaCy's word vectors to compute similarity between documents or phrases.\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Ignoring Errors:** Always handle exceptions and log errors appropriately.\n- **Global Variables:**  Avoid using global variables; use dependency injection or configuration files instead.\n- **Hardcoding Paths:**  Use relative paths or environment variables for file paths.\n- **Overly Complex Functions:**  Keep functions short and focused on a single task.\n- **Lack of Documentation:**  Document your code with docstrings and comments.\n\n### 2.4 State Management Best Practices\n\n- **Stateless Components:** Design spaCy components to be stateless whenever possible to avoid unexpected side effects.\n- **Configuration Objects:** Use configuration objects to manage component state.\n- **Immutability:**  Prefer immutable data structures to prevent unintended modifications.\n\n### 2.5 Error Handling Patterns\n\n- **Try-Except Blocks:** Use try-except blocks to handle potential exceptions during text processing.\n- **Logging:**  Log errors and warnings to a file for debugging and monitoring.\n- **Custom Exceptions:** Define custom exceptions for specific error conditions.\n- **Graceful Degradation:**  Implement fallback mechanisms to handle errors gracefully.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Model Selection:** Use smaller spaCy models (e.g., `en_core_web_sm`) for faster processing if accuracy is not critical.\n- **Batch Processing:** Process large texts in batches to improve throughput.\n- **GPU Acceleration:** Utilize GPU acceleration for faster processing of large datasets (requires `cupy`).\n- **Disable Unnecessary Components:** Disable pipeline components that are not needed for a specific task.\n- **Cython Optimization:** Write performance-critical code in Cython for faster execution.\n- **Vector Data:** Utilize vector data whenever possible for performance as it can be GPU accelerated.\n\n### 3.2 Memory Management\n\n- **Object Reuse:** Reuse spaCy Doc objects to reduce memory allocation overhead.\n- **Data Streaming:** Stream large data files instead of loading them into memory at once.\n- **Garbage Collection:**  Explicitly trigger garbage collection when memory usage is high (use with caution).\n\n### 3.3 Bundle Size Optimization (If applicable)\n\n- **Tree shaking** If deploying spaCy models to the web or other bundle-size-sensitive environments, use tree shaking to remove unused code from the spaCy library.\n\n### 3.4 Lazy Loading Strategies\n\n- **Model Loading on Demand:** Load spaCy models only when they are needed, rather than at application startup.\n- **Component Initialization on Demand:** Initialize custom spaCy components only when they are used.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n- **Injection Attacks:** Prevent injection attacks by sanitizing user inputs before passing them to spaCy.\n- **Denial of Service:** Limit the size of input texts to prevent denial-of-service attacks.\n- **Model Poisoning:** Protect against model poisoning by verifying the integrity of trained spaCy models.\n\n### 4.2 Input Validation\n\n- **Text Length Limits:** Limit the length of input texts to prevent excessive processing time and memory usage.\n- **Character Encoding:**  Validate that input texts are encoded in a supported character encoding (e.g., UTF-8).\n- **Whitelist Validation:**  Use whitelist validation to allow only specific characters or patterns in input texts.\n\n### 4.3 Authentication and Authorization (If applicable)\n\n- **API Keys:** Use API keys to authenticate clients accessing spaCy services.\n- **Role-Based Access Control:** Implement role-based access control to restrict access to sensitive spaCy features.\n\n### 4.4 Data Protection\n\n- **Data Encryption:** Encrypt sensitive data at rest and in transit.\n- **Data Masking:** Mask or redact sensitive data in log files and debugging output.  Use the retokenizer features to create [REDACTED] names or private identifiable information\n- **Anonymization:**  Anonymize data before storing it for analysis or research purposes.\n\n### 4.5 Secure API Communication (If applicable)\n\n- **HTTPS:** Use HTTPS for all API communication to encrypt data in transit.\n- **Input Sanitization:**  Sanitize any data received from the user to prevent injections of malicious code.\n- **Rate limiting** Implement rate limiting to mitigate denial-of-service (DoS) attacks by restricting the number of requests a user can make within a specific timeframe.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- **Component Testing:** Write unit tests for each custom spaCy component to ensure its correctness.\n- **Function Testing:** Test individual functions in your code to verify their behavior.\n- **Mocking:** Use mocking to isolate components and functions during testing.\n\n### 5.2 Integration Testing\n\n- **Pipeline Testing:** Test the integration of multiple spaCy components in a pipeline.\n- **Data Flow Testing:** Test the flow of data through your application to ensure that it is processed correctly.\n- **API Testing:** Test the integration of your spaCy application with external APIs.\n\n### 5.3 End-to-End Testing\n\n- **User Interface Testing (if applicable):** Test the user interface of your spaCy application to ensure that it is user-friendly and functions as expected.\n- **System Testing:** Test the entire system to ensure that all components work together correctly.\n\n### 5.4 Test Organization\n\n- **Separate Test Directory:** Keep tests in a separate `tests/` directory.\n- **Test Modules:**  Organize tests into modules based on the functionality being tested.\n- **Test Fixtures:**  Use test fixtures to set up test data and dependencies.\n- **Coverage Analysis:**  Use coverage analysis to identify untested code.\n\n### 5.5 Mocking and Stubbing Techniques\n\n- **Mocking External Dependencies:** Mock external dependencies (e.g., APIs, databases) to isolate your code during testing.\n- **Stubbing Function Calls:** Stub function calls to control the behavior of dependencies.\n- **Monkey Patching:** Use monkey patching to replace functions or objects during testing (use with caution).\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Not Handling Exceptions:** Failing to handle exceptions properly can lead to unexpected application crashes.\n- **Ignoring Performance:**  Not optimizing your code for performance can result in slow processing times.\n- **Lack of Testing:**  Insufficient testing can lead to bugs and regressions.\n- **Incorrect model versions:** Using the wrong model version for your spaCy version may cause incompatibility errors.\n\n### 6.2 Edge Cases\n\n- **Unicode Characters:**  Handle Unicode characters correctly to avoid encoding issues.\n- **Rare Words:**  Be aware of rare words that may not be in spaCy's vocabulary.\n- **Out-of-Vocabulary Words:**  Handle out-of-vocabulary words gracefully.\n\n### 6.3 Version-Specific Issues\n\n- **API Changes:**  Be aware of API changes in spaCy versions and update your code accordingly.\n- **Model Compatibility:**  Ensure that trained spaCy models are compatible with the spaCy version you are using.\n\n### 6.4 Compatibility Concerns\n\n- **Dependency Conflicts:**  Be aware of dependency conflicts between spaCy and other libraries.\n- **Operating System Compatibility:**  Ensure that your spaCy application is compatible with the target operating systems.\n\n### 6.5 Debugging Strategies\n\n- **Logging:** Use logging to track the execution flow of your code and identify errors.\n- **Debugging Tools:**  Use a debugger to step through your code and inspect variables.\n- **Print Statements:**  Use print statements to output debugging information.\n- **Profiling:**  Use a profiler to identify performance bottlenecks in your code.\n- **Error Messages:**  Read and understand error messages to diagnose problems.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE:** Visual Studio Code, PyCharm, or other Python IDE.\n- **Virtual Environment:** Use virtual environments (e.g., `venv`, `conda`) to isolate project dependencies.\n- **Package Manager:** Use `pip` or `conda` to manage project dependencies.\n\n### 7.2 Build Configuration\n\n- **`pyproject.toml`:** Use `pyproject.toml` for build configuration and dependency management (recommended).\n- **`setup.py`:** Use `setup.py` for older projects or when `pyproject.toml` is not supported.\n- **`requirements.txt`:**  Use `requirements.txt` to specify project dependencies.\n\n### 7.3 Linting and Formatting\n\n- **`flake8`:** Use `flake8` for linting Python code.\n- **`pylint`:** Use `pylint` for static code analysis.\n- **`black`:** Use `black` for automatic code formatting.\n- **`isort`:**  Use `isort` for sorting imports.\n\n### 7.4 Deployment\n\n- **Docker:** Use Docker to containerize your spaCy application.\n- **Cloud Platforms:** Deploy your spaCy application to cloud platforms such as AWS, Google Cloud, or Azure.\n- **Serverless Functions:** Deploy your spaCy application as serverless functions (e.g., AWS Lambda, Google Cloud Functions).\n\n### 7.5 CI/CD Integration\n\n- **GitHub Actions:** Use GitHub Actions for continuous integration and continuous deployment.\n- **Jenkins:** Use Jenkins for continuous integration.\n- **Travis CI:** Use Travis CI for continuous integration.\n- **Automated Testing:** Automate unit, integration, and end-to-end tests as part of your CI/CD pipeline.\n- **Automated Deployment:**  Automate the deployment of your spaCy application to staging and production environments.\n\nBy following these best practices, you can build robust, scalable, and maintainable NLP applications with spaCy.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "spacy.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "spacy",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "spacy",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-sphinx",
    "description": "This rule file provides comprehensive guidelines for writing high-quality Sphinx documentation, covering code style, structure, performance, and best practices. It aims to ensure consistency, readability, and maintainability of Sphinx-based projects.",
    "author": "sanjeed5",
    "tags": [
      "sphinx",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sphinx.mdc",
    "content": "- **Use reStructuredText (reST) or MyST markdown:** These are the primary markup languages for Sphinx. reST is the default and provides powerful semantic markup capabilities. MyST is a markdown flavor compatible with Sphinx. Choose one and stick to it for consistency.\n\n- **Follow PEP 8 and PEP 257:** Adhere to PEP 8 for Python code style within your documentation, emphasizing readability and consistency (e.g., 4 spaces for indentation, line length limits). Follow PEP 257 for docstring conventions for Python code.\n\n- **Structure Your Documentation Hierarchically:** Organize documentation into a clear, hierarchical structure with logical sections.  Use proper headings (H1, H2, etc.) to delineate content.\n\n- **Use Semantic Markup:** Leverage reST's semantic markup for functions, classes, modules, and other code elements to enable cross-referencing and automatic linking. Example: `:func:`my_function``.\n\n- **Cross-Referencing:** Utilize Sphinx's cross-referencing capabilities extensively to link related documentation sections, functions, classes, and other elements. This improves navigation and understanding.  Use `:ref:`, `:func:`, `:class:`, `:mod:` roles.\n\n- **Document Code:** Use Sphinx's `autodoc` extension to automatically generate documentation from Python docstrings. Ensure your docstrings are comprehensive, following PEP 257 conventions. Include parameters, return types, and exceptions.\n\n- **Use Code Blocks:** Clearly define code blocks using the `.. code-block:: language` directive to enable syntax highlighting and improve readability.\n\n- **Whitespace and Formatting:** Maintain consistent whitespace for clarity.  Use blank lines to separate sections and ensure code blocks are clearly defined.\n\n- **Maintain Line Length:** Limit line lengths to 79 characters for code and 72 characters for docstrings/comments to improve readability and compatibility with various tools and editors.\n\n- **Version Control:** Use version control (e.g., Git) to manage your Sphinx documentation project. This allows for tracking changes, collaboration, and easy rollback to previous versions.\n\n- **Use a Sphinx Theme:** Choose a Sphinx theme that suits your project's style and audience.  Many built-in themes (alabaster, classic, sphinxdoc) and third-party themes (sphinx_rtd_theme, pydata_sphinx_theme) are available.\n\n- **Configure Sphinx Properly:** Carefully configure Sphinx using the `conf.py` file to customize the output format, extensions, theme, and other settings. Use meaningful project metadata (name, version, author).\n\n- **Test Your Documentation:** Use Sphinx's `doctest` extension to automatically test code snippets within your documentation.  This ensures the code examples are correct and up-to-date.\n\n- **Use Extensions:** Explore and utilize Sphinx extensions to enhance your documentation with features like mathematical equations, diagrams, and other specialized content.\n\n- **Internationalization:** Consider internationalizing your documentation using Sphinx's internationalization features if your project targets a global audience.\n\n- **Linkcheck Builder:** Use the linkcheck builder to automatically check for broken links in your documentation. This ensures the documentation remains up-to-date and accurate.\n\n- **Contribute Extensions**: Create your own sphinx extensions to manage repeated formatting or add complex rendering.\n\n- **Naming Conventions**\n  - Use descriptive and consistent names for files, directories, and variables.\n  - Follow Python's naming conventions for modules, classes, functions, and variables.\n  - Use all lowercase for modules. Use underscores if it improves readability. Example: `my_module.py`\n  - Use CapWords for class names. Example: `MyClass`\n  - Use lowercase with underscores for functions and variables. Example: `my_function`, `my_variable`\n  - Use UPPERCASE with underscores for constants. Example: `MAX_VALUE`\n\n- **Common Patterns and Anti-Patterns**\n  - **Pattern:** Use the Model-View-Controller (MVC) pattern for complex documentation structures, where the Model represents the data, the View renders the data, and the Controller handles user interactions.\n  - **Anti-Pattern:** Avoid deeply nested directory structures, which can make it difficult to navigate and maintain the documentation.\n  - **Anti-Pattern:** Avoid inconsistent formatting and style throughout the documentation, which can make it look unprofessional and difficult to read.\n\n- **Performance Considerations**\n  - Optimize images by compressing them without sacrificing quality.\n  - Use lazy loading for large images or other resources that are not immediately visible on the page.\n  - Use caching to reduce the number of times that resources need to be loaded.\n  - Minify CSS and JavaScript files to reduce their size.\n\n- **Security Best Practices**\n  - Sanitize user inputs to prevent cross-site scripting (XSS) attacks.\n  - Use HTTPS to encrypt communication between the user's browser and the server.\n  - Keep Sphinx and its extensions up-to-date to patch security vulnerabilities.\n\n- **Testing Approaches**\n  - Write unit tests for custom Sphinx extensions.\n  - Use integration tests to verify that the different parts of the documentation work together correctly.\n  - Use end-to-end tests to simulate user interactions with the documentation and verify that the documentation behaves as expected.\n\n- **Common Pitfalls and Gotchas**\n  - Be aware of the different versions of Sphinx and their compatibility with different Python versions and extensions.\n  - Use the appropriate encoding for your documentation files (UTF-8 is recommended).\n  - Be careful when using the `raw` directive, as it can introduce security vulnerabilities if not used properly.\n\n- **Tooling and Environment**\n  - Use a code editor or IDE with syntax highlighting and linting for reStructuredText or Markdown.\n  - Use a build automation tool (e.g., Make, tox) to automate the documentation build process.\n  - Use a CI/CD system (e.g., Jenkins, Travis CI, GitHub Actions) to automatically build and deploy the documentation whenever the code changes.\n\n- **Deployment Best Practices**\n  - Use a dedicated server or hosting platform for your documentation.\n  - Use a content delivery network (CDN) to distribute your documentation to users around the world.\n  - Use HTTPS to secure your documentation.\n  - Use a robots.txt file to prevent search engines from indexing sensitive parts of your documentation.\n\n- **Documenting Objects**\n  - Use `autodoc` to automatically generate documentation for Python objects.\n  - Use directives like `.. automodule::`, `.. autoclass::`, and `.. autofunction::` to document modules, classes, and functions, respectively.\n  - Use the `:members:`, `:undoc-members:`, and `:show-inheritance:` options to control which members are documented.\n  - Write clear and concise docstrings for all objects, following PEP 257 conventions.\n\n- **Intersphinx**\n  - Use the `intersphinx` extension to link to documentation of other Sphinx projects.\n  - Configure `intersphinx_mapping` in `conf.py` to specify the locations of other Sphinx documentation.\n  - Use the `:py:mod:`, `:py:class:`, and `:py:func:` roles to link to modules, classes, and functions in other projects.\n\n- **reStructuredText Specific Tips**\n  - Use titles and sections to structure your documentation.\n  - Use bullet lists and numbered lists to present information in a clear and concise way.\n  - Use tables to organize data.\n  - Use images to illustrate concepts.\n  - Use footnotes and citations to provide additional information and give credit to sources.\n\n- **Example `conf.py` settings:**\n  python\n  # Configuration file for the Sphinx documentation builder.\n  # For the full list of built-in configuration values, see the documentation:\n  # https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n  # -- Project information -----------------------------------------------------\n\n  project = 'My Project'\n  copyright = '2023, My Company'\n  author = 'John Doe'\n  release = '1.0.0'\n\n  # -- General configuration ---------------------------------------------------\n\n  extensions = [\n      'sphinx.ext.autodoc',\n      'sphinx.ext.napoleon',\n      'sphinx.ext.intersphinx',\n      'sphinx.ext.todo',\n      'sphinx.ext.viewcode',\n      'sphinx.ext.mathjax',\n      'sphinx.ext.ifconfig',\n      'sphinx.ext.githubpages',\n      'sphinx.ext.graphviz'\n  ]\n\n  templates_path = ['_templates']\n  exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n\n  language = 'en'\n\n  # -- Options for HTML output -------------------------------------------------\n\n  html_theme = 'sphinx_rtd_theme'\n  html_static_path = ['_static']\n\n  # -- Extension configuration -------------------------------------------------\n\n  # napoleon configuration (for Google-style docstrings)\n  napoleon_google_docstring = True\n  napoleon_include_init_with_doc = True\n  napoleon_include_private_with_doc = False\n  napoleon_include_special_with_doc = True\n  napoleon_use_rtype = True\n  napoleon_use_param = True\n\n  # intersphinx configuration\n  intersphinx_mapping = {\n      'python': ('https://docs.python.org/3', None),\n      'numpy': ('https://numpy.org/doc/stable/', None),\n  }\n\n  # todo configuration\n  todo_include_todos = True\n\n  # graphviz configuration\n  graphviz_output_format = 'svg'\n\n\n  # -- Options for Markdown files --------------------------------------------\n\n  from recommonmark.parser import CommonMarkParser\n\nsource_parsers = {\n    '.md': CommonMarkParser,\n}\n\n  source_suffix = ['.rst', '.md']",
    "metadata": {
      "globs": "*.rst",
      "format": "mdc",
      "originalFile": "sphinx.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "sphinx",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "guidelines",
      "writing",
      "high",
      "quality",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sphinx",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-spring",
    "description": "This rule set provides comprehensive best practices and coding standards for developing robust and maintainable Java backend applications using the Spring Boot framework. It focuses on code structure, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "spring",
      "java",
      "backend",
      "enterprise",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/spring.mdc",
    "content": "- **Code Organization and Structure**\n  - **Directory Structure Best Practices**\n    - **Layered Architecture:** Organize code into layers: `controller`, `service`, `repository`, `model`, `configuration`, and `exception`.  This provides clear separation of concerns. Example:\n      \n      src/\n      └── main/\n          └── java/\n              └── com/example/app/\n                  ├── controller/\n                  │   └── OrderController.java\n                  ├── service/\n                  │   └── OrderService.java\n                  ├── repository/\n                  │   └── OrderRepository.java\n                  ├── model/\n                  │   └── Order.java\n                  ├── configuration/\n                  │   └── AppConfig.java\n                  └── exception/\n                      └── OrderNotFoundException.java\n      \n    - **Feature-Based Organization:** Group code by feature rather than layer. This keeps related files together for easier navigation.  Use when features are more important than technical separation.\n      \n      src/\n      └── main/\n          └── java/\n              └── com/example/app/\n                  ├── order/\n                  │   ├── OrderController.java\n                  │   ├── OrderService.java\n                  │   ├── OrderRepository.java\n                  │   └── Order.java\n                  └── customer/\n                      ├── CustomerController.java\n                      ├── CustomerService.java\n                      ├── CustomerRepository.java\n                      └── Customer.java\n      \n  - **File Naming Conventions**\n    - **Classes:** Use `PascalCase`.  Names should be nouns representing the purpose of the class. Example: `OrderService`, `ProductController`.\n    - **Interfaces:** Use `PascalCase`.  Often named with an `-able` suffix (e.g., `Runnable`, `Serializable`) or prefixed with `I` (e.g., `IUserService`). Example: `OrderRepository`, `UserService`.\n    - **Methods:** Use `camelCase`.  Names should be verbs indicating the action performed. Example: `createOrder()`, `calculateTotalPrice()`.\n    - **Variables:** Use `camelCase`.  Descriptive and concise names providing context. Avoid abbreviations unless widely understood. Example: `orderTotal`, `userList`.\n    - **Constants:** Use `UPPER_SNAKE_CASE`. Example: `MAX_RETRIES`, `DEFAULT_TIMEOUT`.\n  - **Module Organization**\n    - **Modular Monolith:**  Break down the application into logical modules, each with a specific responsibility.  This promotes maintainability and testability without the complexity of microservices.  Maven or Gradle can be used to manage modules.\n    - **Microservices:** When appropriate, consider breaking the application into independent microservices communicating over APIs. This provides scalability and independent deployment.  Example: `Order Service`, `Payment Service`, `Customer Service`.\n  - **Component Architecture**\n    - **Controllers:** Handle HTTP requests and delegate business logic to services.  Keep controllers thin and focused on request mapping and response formatting.\n    - **Services:** Contain the core business logic of the application. Services should be stateless and independent of HTTP concerns.\n    - **Repositories:** Handle data access and persistence. Use Spring Data JPA repositories to simplify database interactions.\n    - **Data Transfer Objects (DTOs):**  Use DTOs for request and response payloads to separate API contracts from domain models.  This allows for flexibility in evolving the API without affecting internal data structures.\n  - **Code Splitting Strategies**\n    - **By Feature:** Split code into modules based on features, improving maintainability and scalability.\n    - **By Layer:** Split code into distinct layers (presentation, business, data) to separate concerns and improve testability.\n\n- **Common Patterns and Anti-Patterns**\n  - **Design Patterns**\n    - **Dependency Injection:** Core to Spring. Use constructor injection for required dependencies and setter injection for optional dependencies.  Avoid field injection.\n    - **Inversion of Control (IoC):** Let the Spring container manage the creation and lifecycle of beans.\n    - **Aspect-Oriented Programming (AOP):** Use AOP for cross-cutting concerns like logging, security, and transaction management. Use `@Aspect` annotation.\n    - **Template Method:** Apply when different implementations of an algorithm are needed. Spring's `JdbcTemplate` is a classical example.\n    - **Factory Pattern:** Can be used for abstracting object creation.\n    - **Singleton Pattern:** Spring beans are singletons by default, but be mindful when dealing with stateful beans.\n  - **Recommended Approaches**\n    - **Configuration Properties:** Externalize configuration using `@ConfigurationProperties` for type-safe access to properties.\n    - **Event Handling:** Use Spring's event publishing and listening mechanism for decoupling components. Use `@EventListener` annotation.\n    - **Transaction Management:** Use `@Transactional` annotation for declarative transaction management.\n    - **Validation:** Use `@Validated` and JSR-303 annotations for request parameter and body validation.\n  - **Anti-Patterns and Code Smells**\n    - **God Classes:** Avoid classes with too many responsibilities.  Apply the Single Responsibility Principle.\n    - **Long Methods:** Break down long methods into smaller, more focused methods.\n    - **Primitive Obsession:** Avoid using primitive types excessively.  Encapsulate related data into value objects.\n    - **Magic Numbers/Strings:** Replace hardcoded values with constants or configuration properties.\n    - **Tight Coupling:** Minimize dependencies between components through dependency injection and interfaces.\n  - **State Management**\n    - **Stateless Services:** Services should be stateless to improve scalability and concurrency.\n    - **Session Management:** Use Spring Session for managing user sessions in a distributed environment.  Consider using Redis or other external storage for session data.\n    - **Caching:** Implement caching strategically to reduce database load and improve response times. Use Spring Cache abstraction with appropriate cache providers.\n  - **Error Handling Patterns**\n    - **Global Exception Handling:** Use `@ControllerAdvice` and `@ExceptionHandler` to handle exceptions globally and provide consistent error responses.\n    - **Custom Exceptions:** Create custom exception classes to represent application-specific errors.\n    - **Logging:** Log exceptions with appropriate levels (e.g., `error`, `warn`, `info`).\n    - **Return Meaningful Error Responses:** Return well-structured error responses with clear error codes and messages.  Use a consistent format for error responses.\n\n- **Performance Considerations**\n  - **Optimization Techniques**\n    - **Database Connection Pooling:** Use a connection pool (e.g., HikariCP) to reuse database connections and reduce overhead.\n    - **Caching:** Implement caching using Spring Cache abstraction to store frequently accessed data.\n    - **Asynchronous Processing:** Use `@Async` for long-running tasks that don't need to be executed synchronously.\n    - **Lazy Loading:** Use lazy loading for entities and relationships in JPA to avoid loading unnecessary data.\n    - **Profiling:** Use profiling tools (e.g., VisualVM, JProfiler) to identify performance bottlenecks.\n  - **Memory Management**\n    - **Garbage Collection Tuning:** Tune JVM garbage collection settings for optimal performance.  Monitor GC performance and adjust parameters as needed.\n    - **Object Pooling:** Consider using object pooling for frequently created and destroyed objects.\n    - **Avoid Memory Leaks:**  Be careful to release resources properly to prevent memory leaks. Use try-with-resources for closing streams and other resources.\n  - **Rendering Optimization**\n    - *(Not Directly Applicable to Spring Backend - Focus on API Response times and efficiency)*\n    - **Minimize Data Transfer:** Only return the data needed by the client.\n    - **Use Efficient Data Structures:** Use appropriate data structures for API responses (e.g., lists, maps).\n    - **Compression:** Enable GZIP compression for API responses to reduce the size of the data transferred over the network.\n  - **Bundle Size Optimization**\n    - *(Not Directly Applicable to Spring Backend - Although Dependency Management is crucial)*\n    - **Minimize Dependencies:** Only include necessary dependencies.\n    - **Use Code Analysis Tools:** Use tools like SonarQube to identify unused code and dependencies.\n  - **Lazy Loading**\n    - **JPA Lazy Loading:**  Use lazy loading for JPA relationships to avoid loading unnecessary data. Use the `@OneToMany(fetch = FetchType.LAZY)` annotation.\n\n- **Security Best Practices**\n  - **Common Vulnerabilities and Prevention**\n    - **SQL Injection:** Use parameterized queries or ORM frameworks (e.g., Spring Data JPA) to prevent SQL injection.\n    - **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Use CSRF protection mechanisms (e.g., Spring Security's CSRF support).\n    - **Authentication/Authorization Flaws:**  Implement robust authentication and authorization mechanisms using Spring Security.\n    - **Dependency Vulnerabilities:** Regularly scan dependencies for known vulnerabilities and update them.\n  - **Input Validation**\n    - **Server-Side Validation:** Always perform input validation on the server-side.\n    - **JSR-303 Validation:** Use JSR-303 annotations for validating request parameters and body.\n    - **Custom Validation:** Implement custom validation logic for complex validation rules.\n  - **Authentication and Authorization**\n    - **Spring Security:** Use Spring Security for authentication and authorization.\n    - **OAuth 2.0/OpenID Connect:** Use OAuth 2.0/OpenID Connect for delegating authentication and authorization to external providers.\n    - **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n  - **Data Protection**\n    - **Encryption:** Encrypt sensitive data at rest and in transit.\n    - **Hashing:** Hash passwords using strong hashing algorithms (e.g., bcrypt, Argon2).\n    - **Data Masking:** Mask sensitive data when displaying or logging it.\n  - **Secure API Communication**\n    - **HTTPS:** Use HTTPS for all API communication.\n    - **API Keys:** Use API keys for authenticating clients.\n    - **Rate Limiting:** Implement rate limiting to prevent abuse.\n\n- **Testing Approaches**\n  - **Unit Testing**\n    - **JUnit:** Use JUnit for writing unit tests.\n    - **Mockito:** Use Mockito for mocking dependencies.\n    - **Test-Driven Development (TDD):** Write tests before writing code.\n    - **Focus on Business Logic:**  Focus unit tests on the business logic of the application.\n  - **Integration Testing**\n    - **Spring Boot Test:** Use `@SpringBootTest` annotation for integration tests.\n    - **TestRestTemplate:** Use `TestRestTemplate` for testing REST endpoints.\n    - **Database Testing:**  Use an in-memory database (e.g., H2, embedded database) or a test database for integration tests.\n    - **Verify Component Interactions:**  Verify that different components of the application work together correctly.\n  - **End-to-End Testing**\n    - **Selenium:** Use Selenium for end-to-end testing of web applications.\n    - **Cypress:** Use Cypress as another alternative for end-to-end testing.\n    - **Test the Entire System:**  Test the entire system from the user interface to the database.\n  - **Test Organization**\n    - **Separate Test Directory:** Keep tests in a separate directory from the source code.\n    - **Test Naming Conventions:**  Use clear and consistent naming conventions for tests (e.g., `ClassNameTest`).\n    - **Organize Tests by Component:**  Organize tests by component or feature.\n  - **Mocking and Stubbing**\n    - **Mockito Annotations:** Use Mockito annotations (e.g., `@Mock`, `@InjectMocks`) to simplify mocking.\n    - **When/Then:** Use the `when()` and `thenReturn()` methods to define mock behavior.\n    - **Verify Interactions:** Use the `verify()` method to verify that mock interactions occurred.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes**\n    - **Over-Engineering:**  Avoid over-engineering solutions. Keep it simple and only add complexity when needed.\n    - **Ignoring Exceptions:** Don't catch exceptions and ignore them. Always log exceptions and handle them appropriately.\n    - **Hardcoding Values:**  Avoid hardcoding values. Use configuration properties instead.\n    - **Not Using Dependency Injection Properly:**  Use dependency injection to decouple components and improve testability.\n  - **Edge Cases**\n    - **Null Values:**  Handle null values gracefully.\n    - **Concurrency Issues:** Be aware of concurrency issues when dealing with shared resources.\n    - **Resource Exhaustion:**  Handle resource exhaustion gracefully (e.g., database connections, memory).\n  - **Version-Specific Issues**\n    - **Check Release Notes:**  Review release notes for each version of Spring Boot and its dependencies to identify potential issues.\n    - **Test Upgrades:**  Thoroughly test upgrades to ensure compatibility.\n  - **Compatibility Concerns**\n    - **Dependency Conflicts:**  Manage dependency conflicts using Maven or Gradle.\n    - **Java Version Compatibility:**  Ensure compatibility between Spring Boot and the Java version.\n  - **Debugging Strategies**\n    - **Logging:** Use logging liberally to track the flow of execution and identify issues.\n    - **Debuggers:** Use debuggers to step through code and inspect variables.\n    - **Remote Debugging:** Use remote debugging to debug applications running in remote environments.\n\n- **Tooling and Environment**\n  - **Recommended Development Tools**\n    - **IntelliJ IDEA:** Popular IDE with excellent Spring Boot support.\n    - **Eclipse:** Another popular IDE with Spring Tool Suite plugin.\n    - **Spring Initializr:** Web-based tool for generating Spring Boot projects.\n  - **Build Configuration**\n    - **Maven:** Use Maven for dependency management and building projects.\n    - **Gradle:** Use Gradle as another alternative to Maven.\n    - **Spring Boot Plugin:** Use the Spring Boot Maven or Gradle plugin for building executable JARs.\n  - **Linting and Formatting**\n    - **Checkstyle:** Use Checkstyle for enforcing coding standards.\n    - **PMD:** Use PMD for finding potential bugs and code smells.\n    - **SpotBugs:** Use SpotBugs to find potential bug patterns in the code.\n    - **Prettier:** Use Prettier for formatting code consistently.\n  - **Deployment Best Practices**\n    - **Containerization:** Use Docker for containerizing applications.\n    - **Cloud Platforms:** Deploy applications to cloud platforms (e.g., AWS, Azure, GCP).\n    - **Immutable Infrastructure:**  Use immutable infrastructure for deploying applications.\n  - **CI/CD Integration**\n    - **Jenkins:** Use Jenkins for continuous integration and continuous deployment.\n    - **GitLab CI:** Use GitLab CI as another CI/CD alternative.\n    - **GitHub Actions:** Use GitHub Actions for automating build, test, and deployment workflows.\n\n- **Additional Tips**\n    - **Use Spring Boot DevTools:** These tools provide automatic application restarts, live reloading, and other useful features during development.\n    - **Monitor Application Health:** Use Spring Boot Actuator to monitor application health and performance metrics.\n    - **Stay Up-to-Date:** Keep up-to-date with the latest Spring Boot releases and best practices.",
    "metadata": {
      "globs": "*.java",
      "format": "mdc",
      "originalFile": "spring.mdc"
    },
    "subcategory": "java",
    "keywords": [
      "cursor",
      "spring",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "robust",
      "java",
      "backend",
      "enterprise",
      "cursor-rule",
      "mdc",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "spring",
        "java",
        "backend",
        "enterprise",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-springboot",
    "description": "This rule provides comprehensive best practices and coding standards for developing robust, maintainable, and performant Spring Boot applications, covering code structure, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "springboot",
      "spring",
      "java",
      "backend",
      "enterprise",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/springboot.mdc",
    "content": "# Spring Boot Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing applications with Spring Boot. Following these guidelines will help ensure that your applications are robust, maintainable, performant, and secure.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nAdopt a layered architecture to separate concerns and improve maintainability. A recommended directory structure is:\n\n\nsrc/\n ├── main/\n │   ├── java/\n │   │   └── com/example/app/\n │   │       ├── Application.java (Main entry point)\n │   │       ├── config/          (Configuration classes)\n │   │       ├── controller/      (REST controllers)\n │   │       ├── service/         (Business logic services)\n │   │       ├── repository/      (Data access repositories)\n │   │       ├── model/           (Data transfer objects (DTOs), entities)\n │   │       ├── exception/       (Custom exceptions)\n │   │       ├── util/            (Utility classes)\n │   │       └── security/        (Security-related classes)\n │   └── resources/\n │       ├── application.properties/application.yml (Application configuration)\n │       ├── static/            (Static resources like HTML, CSS, JavaScript)\n │       └── templates/         (View templates, e.g., Thymeleaf)\n └── test/\n     ├── java/\n     │   └── com/example/app/\n     │       ├── controller/      (Controller tests)\n     │       ├── service/         (Service tests)\n     │       └── repository/      (Repository tests)\n     └── resources/\n         ├── application.properties/application.yml (Test-specific configuration)\n\n\n*   **Root Package:** Choose a meaningful root package name (e.g., `com.yourcompany.appname`).\n*   **Modularization:** For larger applications, consider breaking down the application into modules (e.g., using Maven or Gradle modules) based on business domains or features.\n\n### 1.2 File Naming Conventions\n\n*   **Classes:** Use PascalCase (e.g., `UserController`, `ProductService`).\n*   **Interfaces:** Use PascalCase, often prefixed with `I` (e.g., `ProductRepository`, `IOrderService`). Consider omitting the `I` prefix if it doesn't add value.\n*   **Methods:** Use camelCase (e.g., `getUserById`, `calculateTotal`).\n*   **Variables:** Use camelCase (e.g., `userName`, `productPrice`).\n*   **Constants:** Use UPPER_SNAKE_CASE (e.g., `MAX_RETRIES`, `DEFAULT_TIMEOUT`).\n*   **Configuration Files:** Use lowercase with hyphens (e.g., `application.properties`, `bootstrap.yml`).\n\n### 1.3 Module Organization\n\nFor larger projects, break down the application into modules. Each module should represent a distinct business domain or feature.\n\n*   **Maven/Gradle Modules:** Use Maven or Gradle to manage module dependencies and build processes.\n*   **Clear Boundaries:** Define clear interfaces between modules to promote loose coupling.\n*   **Independent Deployments:** Design modules to be independently deployable, if possible.\n\n### 1.4 Component Architecture\n\n*   **Controllers:** Handle incoming requests and delegate to services. Keep controllers thin.\n*   **Services:** Implement business logic. Services should be transactional.\n*   **Repositories:** Provide data access abstraction. Use Spring Data JPA or other data access technologies.\n*   **Models:** Represent data structures. Use DTOs for transferring data between layers and entities for persistence.\n\n### 1.5 Code Splitting Strategies\n\n*   **Feature-Based Splitting:** Group code related to a specific feature into its own package or module.\n*   **Layer-Based Splitting:** Separate code based on layers (e.g., presentation, business logic, data access).\n*   **Horizontal vs. Vertical Slicing:** Consider horizontal slicing (grouping similar functionalities across features) or vertical slicing (grouping all functionalities for a specific feature) based on project needs.\n\n## 2. Common Patterns and Anti-Patterns\n\n### 2.1 Design Patterns Specific to Spring Boot\n\n*   **Dependency Injection (DI):** Use constructor injection for required dependencies and setter injection for optional dependencies.\n*   **Inversion of Control (IoC):** Let the Spring container manage the lifecycle and dependencies of your beans.\n*   **Aspect-Oriented Programming (AOP):** Use AOP for cross-cutting concerns like logging, security, and transaction management.\n*   **Repository Pattern:** Use Spring Data repositories for simplified data access.\n*   **Service Layer Pattern:** Decouple controllers from business logic by introducing a service layer.\n*   **Template Method Pattern:** Use `JdbcTemplate` or `RestTemplate` for consistent data access or external API calls.\n*   **Factory Pattern:** Use `@Configuration` classes and `@Bean` methods to define and configure beans.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Configuration:** Use `application.properties` or `application.yml` for externalized configuration. Use `@ConfigurationProperties` to bind configuration properties to a class.\n*   **Logging:** Use SLF4J for logging abstraction and a suitable logging implementation (e.g., Logback or Log4j2).\n*   **Exception Handling:** Use `@ControllerAdvice` to handle exceptions globally. Create custom exception classes for specific error scenarios.\n*   **Validation:** Use JSR-303 Bean Validation for validating request parameters and request bodies. Use `@Validated` annotation with appropriate groups.\n*   **Data Transfer:** Use DTOs to transfer data between layers to avoid exposing internal data structures.\n*   **Asynchronous Operations:** Use `@Async` annotation and `TaskExecutor` to perform asynchronous operations.\n*   **Caching:** Use Spring's caching abstraction with implementations like Ehcache, Caffeine, or Redis.\n*   **Scheduling:** Use `@Scheduled` annotation to schedule tasks.\n*   **Transaction Management:** Use `@Transactional` annotation for managing transactions.\n\n### 2.3 Anti-Patterns and Code Smells to Avoid\n\n*   **God Class:** A class that does too much. Break it down into smaller, more focused classes.\n*   **Long Method:** A method that is too long and complex. Extract smaller methods.\n*   **Feature Envy:** A method that accesses data from another object more than its own. Move the method to the other object.\n*   **Data Clumps:** Groups of data that frequently appear together. Create a new class to encapsulate the data clump.\n*   **Primitive Obsession:** Using primitive data types instead of creating meaningful domain objects.\n*   **Shotgun Surgery:** Making small changes in many different places. Refactor the code to centralize the changes.\n*   **Spaghetti Code:** Code that is difficult to understand and maintain due to its tangled structure.\n*   **Copy-Paste Programming:** Duplicating code instead of reusing existing code. Create reusable components or methods.\n*   **Field Injection:** Use constructor injection instead for required dependencies.\n*   **Tight Coupling:** Classes that are highly dependent on each other. Decouple the classes using interfaces or abstract classes.\n*   **Ignoring Exceptions:** Catching exceptions but not handling them properly. Log the exception and take appropriate action.\n*   **Over-Engineering:** Making the code too complex for the problem it solves. Keep it simple and only add complexity when needed.\n\n### 2.4 State Management Best Practices\n\n*   **Stateless Services:** Design services to be stateless whenever possible. This improves scalability and testability.\n*   **Session Management:** Use Spring Session to manage user sessions in a distributed environment. Store session data in a persistent store like Redis or a database.\n*   **Caching:** Use caching to store frequently accessed data. Choose a suitable caching strategy (e.g., LRU, FIFO).\n*   **Database:** Use a relational database or a NoSQL database to persist data.\n*   **Distributed Transactions:** Use distributed transaction management techniques like two-phase commit (2PC) or Saga pattern for transactions spanning multiple services.\n\n### 2.5 Error Handling Patterns\n\n*   **Global Exception Handling:** Use `@ControllerAdvice` and `@ExceptionHandler` to handle exceptions globally.\n*   **Custom Exceptions:** Create custom exception classes for specific error scenarios.\n*   **Logging:** Log exceptions with sufficient context information (e.g., request parameters, user ID).\n*   **Error Responses:** Return meaningful error responses with appropriate HTTP status codes and error messages.\n*   **Retry Mechanism:** Implement a retry mechanism for transient errors.\n*   **Circuit Breaker:** Use a circuit breaker pattern to prevent cascading failures.\n*   **Dead Letter Queue:** Use a dead letter queue to handle messages that cannot be processed.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Database Query Optimization:** Use indexes, optimize queries, and avoid N+1 queries.\n*   **Caching:** Use caching to reduce database load and improve response times.\n*   **Connection Pooling:** Use connection pooling to reuse database connections.\n*   **Asynchronous Operations:** Use asynchronous operations to offload long-running tasks from the main thread.\n*   **Load Balancing:** Use load balancing to distribute traffic across multiple instances.\n*   **Gzip Compression:** Use Gzip compression to reduce the size of HTTP responses.\n*   **Code Profiling:** Use profiling tools to identify performance bottlenecks.\n\n### 3.2 Memory Management\n\n*   **Object Pooling:** Use object pooling to reuse objects and reduce object creation overhead.\n*   **Avoid Memory Leaks:** Ensure that objects are properly garbage collected.\n*   **Use Appropriate Data Structures:** Choose data structures that are efficient for the operations you perform.\n*   **Optimize Collections:** Use appropriate collection types (e.g., `ArrayList` vs. `LinkedList`) based on usage patterns.\n*   **Lazy Loading:** Use lazy loading to load data only when it is needed.\n\n### 3.3 Rendering Optimization\n\n*   **Template Caching:** Cache frequently used templates to reduce rendering time.\n*   **Minimize DOM Manipulations:** Minimize DOM manipulations in the view layer.\n*   **Use CDN:** Use a Content Delivery Network (CDN) to serve static resources.\n\n### 3.4 Bundle Size Optimization\n\n*   **Code Splitting:** Split the code into smaller bundles to reduce the initial load time.\n*   **Tree Shaking:** Remove unused code from the bundles.\n*   **Minification:** Minify the code to reduce the bundle size.\n*   **Compression:** Compress the bundles to reduce the transfer size.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Initialization:** Initialize objects only when they are first accessed.\n*   **Virtual Proxy:** Use a virtual proxy to delay the loading of an object until it is needed.\n*   **Database Lazy Loading:** Use lazy loading features provided by JPA or other data access technologies.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:** Use parameterized queries or ORM frameworks to prevent SQL injection attacks.\n*   **Cross-Site Scripting (XSS):** Sanitize user input and use output encoding to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Use CSRF tokens to prevent CSRF attacks.\n*   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms.\n*   **Session Management:** Secure session management to prevent session hijacking.\n*   **Denial of Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n*   **Insecure Direct Object References (IDOR):** Implement access control checks to prevent unauthorized access to objects.\n*   **Security Misconfiguration:** Properly configure security settings to prevent misconfigurations.\n*   **Using Components with Known Vulnerabilities:** Keep dependencies up-to-date to address known vulnerabilities.\n*   **Insufficient Logging and Monitoring:** Implement sufficient logging and monitoring to detect and respond to security incidents.\n\n### 4.2 Input Validation\n\n*   **Whitelisting:** Validate input against a whitelist of allowed values.\n*   **Regular Expressions:** Use regular expressions to validate input format.\n*   **Data Type Validation:** Validate that input is of the expected data type.\n*   **Length Validation:** Validate that input is within the allowed length limits.\n*   **Encoding Validation:** Validate that input is properly encoded.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **OAuth 2.0:** Use OAuth 2.0 for delegated authorization.\n*   **JWT (JSON Web Token):** Use JWT for stateless authentication.\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Attribute-Based Access Control (ABAC):** Implement ABAC for fine-grained access control based on attributes.\n*   **Spring Security:** Leverage Spring Security for authentication and authorization.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit.\n*   **Hashing:** Hash passwords and other sensitive data using strong hashing algorithms.\n*   **Salting:** Use salting to protect against rainbow table attacks.\n*   **Data Masking:** Mask sensitive data when it is displayed or used for non-production purposes.\n*   **Tokenization:** Tokenize sensitive data to replace it with non-sensitive tokens.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for secure communication.\n*   **TLS/SSL:** Use TLS/SSL to encrypt data in transit.\n*   **API Keys:** Use API keys to authenticate API clients.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse.\n*   **Input Validation:** Validate all input to prevent injection attacks.\n*   **Output Encoding:** Encode output to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test-Driven Development (TDD):** Write tests before writing the code.\n*   **Mocking:** Use mocking frameworks (e.g., Mockito) to isolate the unit under test.\n*   **Assertion Libraries:** Use assertion libraries (e.g., AssertJ) for expressive assertions.\n*   **Code Coverage:** Aim for high code coverage.\n*   **Test Naming:** Use clear and descriptive test names.\n*   **Arrange-Act-Assert:** Structure tests using the Arrange-Act-Assert pattern.\n\n### 5.2 Integration Testing\n\n*   **Test Slices:** Use Spring Boot's test slices (e.g., `@WebMvcTest`, `@DataJpaTest`) to test specific parts of the application.\n*   **TestContainers:** Use Testcontainers to run integration tests with real dependencies (e.g., databases, message queues).\n*   **Spring Test:** Use Spring's testing support for integration tests.\n*   **Database Testing:** Use an in-memory database or a test database for database integration tests.\n\n### 5.3 End-to-End Testing\n\n*   **Selenium:** Use Selenium to automate browser-based end-to-end tests.\n*   **REST Assured:** Use REST Assured to test REST APIs.\n*   **Headless Browser:** Use a headless browser for faster end-to-end tests.\n\n### 5.4 Test Organization\n\n*   **Test Packages:** Create separate packages for unit tests, integration tests, and end-to-end tests.\n*   **Test Classes:** Create test classes that correspond to the classes under test.\n*   **Test Suites:** Use test suites to group related tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mockito:** Use Mockito for mocking dependencies.\n*   **Spring MockMvc:** Use Spring MockMvc for testing controllers.\n*   **WireMock:** Use WireMock for stubbing external services.\n*   **Avoid Over-Mocking:** Mock only the dependencies that are necessary to isolate the unit under test.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Not Understanding Spring Boot Concepts:** Jumping into Spring Boot without a solid understanding of Spring and Dependency Injection.\n*   **Overusing `@Autowired`:** Using `@Autowired` for field injection instead of constructor injection.\n*   **Not Using Spring Boot Starters:** Manually adding dependencies instead of using Spring Boot Starters.\n*   **Not Externalizing Configuration:** Hardcoding configuration values instead of using `application.properties` or `application.yml`.\n*   **Not Handling Exceptions Properly:** Ignoring exceptions or not providing meaningful error responses.\n*   **Not Writing Tests:** Neglecting to write unit tests and integration tests.\n*   **Using `System.out.println` for Logging:** Using `System.out.println` instead of a proper logging framework.\n*   **Not Securing the Application:** Failing to implement proper security measures.\n*   **Not Monitoring the Application:** Not setting up proper monitoring and alerting.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **Null Values:** Handle null values gracefully.\n*   **Empty Collections:** Handle empty collections properly.\n*   **Large Datasets:** Optimize performance for large datasets.\n*   **Concurrency Issues:** Handle concurrency issues properly.\n*   **Network Errors:** Handle network errors gracefully.\n\n### 6.3 Version-Specific Issues\n\n*   **Spring Boot Version Compatibility:** Ensure that dependencies are compatible with the Spring Boot version.\n*   **Java Version Compatibility:** Ensure that the Java version is compatible with the Spring Boot version.\n*   **Third-Party Library Compatibility:** Ensure that third-party libraries are compatible with the Spring Boot version.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:** Ensure that the application is compatible with different browsers.\n*   **Operating System Compatibility:** Ensure that the application is compatible with different operating systems.\n*   **Device Compatibility:** Ensure that the application is compatible with different devices.\n\n### 6.5 Debugging Strategies\n\n*   **Logging:** Use logging to trace the execution flow and identify errors.\n*   **Debuggers:** Use debuggers to step through the code and inspect variables.\n*   **Profiling Tools:** Use profiling tools to identify performance bottlenecks.\n*   **Remote Debugging:** Use remote debugging to debug applications running on remote servers.\n*   **Heap Dumps:** Use heap dumps to analyze memory usage.\n*   **Thread Dumps:** Use thread dumps to analyze thread activity.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** IntelliJ IDEA, Eclipse, or Visual Studio Code.\n*   **Build Tool:** Maven or Gradle.\n*   **Version Control:** Git.\n*   **Database Client:** DBeaver or SQL Developer.\n*   **API Testing Tool:** Postman or Insomnia.\n\n### 7.2 Build Configuration\n\n*   **Maven:** Use `pom.xml` to define dependencies and build configuration.\n*   **Gradle:** Use `build.gradle` to define dependencies and build configuration.\n*   **Spring Boot Maven Plugin:** Use the Spring Boot Maven Plugin for packaging and running the application.\n*   **Spring Boot Gradle Plugin:** Use the Spring Boot Gradle Plugin for packaging and running the application.\n\n### 7.3 Linting and Formatting\n\n*   **Checkstyle:** Use Checkstyle to enforce coding style guidelines.\n*   **PMD:** Use PMD to find potential code defects.\n*   **FindBugs/SpotBugs:** Use FindBugs/SpotBugs to find potential bugs.\n*   **EditorConfig:** Use EditorConfig to maintain consistent coding styles across different editors.\n*   **IntelliJ IDEA Code Style:** Configure IntelliJ IDEA's code style settings to match the project's coding style.\n\n### 7.4 Deployment Best Practices\n\n*   **Containerization:** Use Docker to containerize the application.\n*   **Orchestration:** Use Kubernetes or Docker Swarm to orchestrate containers.\n*   **Cloud Deployment:** Deploy the application to a cloud platform (e.g., AWS, Azure, Google Cloud).\n*   **Configuration Management:** Use configuration management tools (e.g., Spring Cloud Config) to manage configuration in a distributed environment.\n*   **Monitoring:** Set up monitoring to track application performance and health.\n*   **Logging:** Aggregate logs to a central location for analysis.\n\n### 7.5 CI/CD Integration\n\n*   **Continuous Integration (CI):** Use a CI server (e.g., Jenkins, Travis CI, CircleCI) to automatically build and test the application.\n*   **Continuous Delivery (CD):** Use a CD pipeline to automatically deploy the application to production.\n*   **Automated Testing:** Automate unit tests, integration tests, and end-to-end tests.\n*   **Code Quality Checks:** Integrate code quality checks (e.g., Checkstyle, PMD, FindBugs/SpotBugs) into the CI pipeline.",
    "metadata": {
      "globs": "*.java",
      "format": "mdc",
      "originalFile": "springboot.mdc"
    },
    "subcategory": "java",
    "keywords": [
      "cursor",
      "springboot",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "robust",
      "spring",
      "java",
      "backend",
      "enterprise",
      "cursor-rule",
      "mdc",
      "backend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "springboot",
        "spring",
        "java",
        "backend",
        "enterprise",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "backend-frameworks"
    }
  },
  {
    "name": "cursor-sqlalchemy",
    "description": "Enforces best practices for SQLAlchemy, covering code organization, performance, security, testing, and common pitfalls to ensure maintainable, efficient, and secure database interactions.",
    "author": "sanjeed5",
    "tags": [
      "sqlalchemy",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sqlalchemy.mdc",
    "content": "# SQLAlchemy Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for using SQLAlchemy in Python projects. Following these guidelines will help you write maintainable, efficient, and secure code.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nA well-organized directory structure improves code readability and maintainability. Here's a recommended structure for SQLAlchemy-based projects:\n\n\nproject_name/\n ├── app/\n │   ├── __init__.py\n │   ├── models/\n │   │   ├── __init__.py\n │   │   ├── user.py\n │   │   ├── product.py\n │   │   └── ...\n │   ├── database.py  # SQLAlchemy engine and session setup\n │   ├── routes/\n │   │   ├── __init__.py\n │   │   ├── user_routes.py\n │   │   ├── product_routes.py\n │   │   └── ...\n │   ├── schemas/\n │   │   ├── __init__.py\n │   │   ├── user_schema.py\n │   │   ├── product_schema.py\n │   │   └── ...\n │   ├── utils.py\n │   └── main.py  # Entry point for the application\n ├── tests/\n │   ├── __init__.py\n │   ├── conftest.py # Fixtures for testing\n │   ├── test_models.py\n │   ├── test_routes.py\n │   └── ...\n ├── migrations/\n │   ├── versions/\n │   │   ├── ... (Alembic migration scripts)\n │   ├── alembic.ini\n │   └── env.py\n ├── .env  # Environment variables\n ├── requirements.txt\n ├── pyproject.toml # Define project dependencies\n └── README.md\n\n\n### 1.2 File Naming Conventions\n\n*   **Models:** Use descriptive names for model files (e.g., `user.py`, `product.py`).\n*   **Schemas:** Use `_schema.py` suffix for schema files (e.g., `user_schema.py`).\n*   **Routes/Controllers:** Use `_routes.py` or `_controllers.py` suffix (e.g., `user_routes.py`).\n*   **Database:** A central `database.py` or `db.py` file is standard.\n*   **Migrations:** Alembic manages migration script names automatically.\n\n### 1.3 Module Organization\n\n*   **Models:** Group related models into separate modules for clarity.\n*   **Schemas:** Define schemas in separate modules for serialization/deserialization.\n*   **Routes/Controllers:** Organize API endpoints into logical modules.\n\n### 1.4 Component Architecture\n\n*   **Data Access Layer (DAL):** Abstract database interactions into a separate layer using the Repository Pattern to decouple the application logic from the database implementation.\n*   **Service Layer:** Implement business logic in a service layer that utilizes the DAL.\n*   **Presentation Layer:** (Routes/Controllers) Handle request processing and response generation.\n\n### 1.5 Code Splitting\n\n*   **Model Definition:** Split large models into smaller, manageable classes.\n*   **Query Logic:** Move complex query logic into reusable functions or methods.\n*   **Configuration:** Externalize configuration settings using environment variables.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Repository Pattern:** Centralizes data access logic, improving testability and maintainability.  Example:\n\n    python\n    class UserRepository:\n        def __init__(self, session: Session):\n            self.session = session\n\n        def get_user_by_id(self, user_id: int) -> User | None:\n            return self.session.get(User, user_id)\n    \n*   **Unit of Work Pattern:** Tracks changes to multiple entities and commits them as a single transaction, ensuring data consistency.\n*   **Data Mapper Pattern:** Provides a layer of indirection between the database and domain objects, allowing for independent evolution.\n\n### 2.2 Recommended Approaches\n\n*   **Declarative Base:** Use `declarative_base()` to define models.\n*   **Context Managers:** Use context managers for session management to ensure sessions are properly closed.\n*   **Parameterized Queries:** Always use parameterized queries to prevent SQL injection.\n*   **Eager Loading:** Use `joinedload()`, `subqueryload()`, or `selectinload()` to optimize query performance and avoid the N+1 problem.\n*   **Alembic:** Use Alembic for database migrations.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Raw SQL:** Avoid writing raw SQL queries whenever possible; leverage SQLAlchemy's ORM or Core features.\n*   **Global Sessions:** Avoid using global session objects; create sessions within request/transaction scopes.\n*   **Long-Lived Sessions:** Keep sessions short-lived to prevent stale data and concurrency issues.\n*   **Over-Fetching:** Avoid retrieving more data than necessary; use targeted queries.\n*   **N+1 Query Problem:** Identify and address the N+1 query problem using eager loading.\n\n### 2.4 State Management\n\n*   **Session Scope:** Manage the SQLAlchemy session within the scope of a request or transaction.\n*   **Thread Safety:** Ensure thread safety when using SQLAlchemy in multi-threaded environments.\n*   **Asynchronous Sessions:** Use asynchronous sessions for non-blocking database operations in asynchronous applications.\n\n### 2.5 Error Handling\n\n*   **Exception Handling:** Implement robust exception handling to catch database errors and prevent application crashes.\n*   **Rollbacks:** Use `session.rollback()` to revert changes in case of errors.\n*   **Logging:** Log database errors and queries for debugging and monitoring purposes.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Indexing:** Add indexes to frequently queried columns to improve query performance.\n*   **Query Optimization:** Analyze query execution plans and optimize queries accordingly.\n*   **Connection Pooling:** Configure connection pooling to reuse database connections and reduce overhead.\n*   **Caching:** Implement caching strategies to reduce database load.\n*   **Batch Operations:** Use batch operations for bulk inserts, updates, and deletes.\n\n### 3.2 Memory Management\n\n*   **Session Management:** Close sessions promptly to release resources.\n*   **Result Set Size:** Limit the size of result sets to prevent memory exhaustion.\n*   **Streaming Results:** Use streaming results for large datasets to reduce memory usage.\n\n### 3.3 Lazy Loading Strategies\n\n*   **Joined Loading**: Load related entities in a single query using a JOIN.\n*   **Subquery Loading**: Load related entities using a subquery, suitable for complex relationships.\n*   **Selectin Loading**: Load related entities using a separate SELECT IN query, efficient for collections.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **SQL Injection:** Prevent SQL injection by using parameterized queries and avoiding string concatenation.\n*   **Data Exposure:** Protect sensitive data by encrypting it at rest and in transit.\n*   **Authentication Bypass:** Implement robust authentication and authorization mechanisms to prevent unauthorized access.\n\n### 4.2 Input Validation\n\n*   **Schema Validation:** Use schemas to validate input data and ensure it conforms to the expected format.\n*   **Sanitization:** Sanitize input data to remove malicious characters and prevent cross-site scripting (XSS) attacks.\n\n### 4.3 Authentication and Authorization\n\n*   **Authentication:** Use secure authentication protocols such as OAuth 2.0 or JWT (JSON Web Tokens).\n*   **Authorization:** Implement role-based access control (RBAC) or attribute-based access control (ABAC) to restrict access to resources.\n\n### 4.4 Data Protection\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit using strong encryption algorithms.\n*   **Hashing:** Hash passwords and other sensitive data using strong hashing algorithms.\n*   **Data Masking:** Mask sensitive data in non-production environments to prevent data breaches.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS to encrypt communication between the client and the server.\n*   **API Keys:** Use API keys to authenticate API requests.\n*   **Rate Limiting:** Implement rate limiting to prevent denial-of-service (DoS) attacks.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Model Testing:** Test model methods and properties.\n*   **Repository Testing:** Test repository methods in isolation.\n*   **Service Testing:** Test service layer logic.\n\n### 5.2 Integration Testing\n\n*   **Database Integration:** Test database interactions and ensure data integrity.\n*   **API Integration:** Test API endpoints and ensure they function correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Full Application Testing:** Test the entire application workflow to ensure all components work together seamlessly.\n\n### 5.4 Test Organization\n\n*   **Test Directory:** Organize tests into a separate `tests` directory.\n*   **Test Modules:** Create separate test modules for each component.\n*   **Test Fixtures:** Use test fixtures to set up test data and dependencies.\n\n### 5.5 Mocking and Stubbing\n\n*   **Mocking Databases**: Use `unittest.mock` or `pytest-mock` to mock the SQLAlchemy engine and session during testing.\n*   **Patching External Dependencies**: Patch external dependencies to isolate the component under test.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Forgetting to Commit:** Always commit changes to the database after making modifications.\n*   **Incorrect Relationship Configuration:** Ensure relationships are configured correctly to avoid data integrity issues.\n*   **Not Handling Exceptions:** Always handle exceptions to prevent application crashes.\n*   **Lack of Query Optimization:** Neglecting to optimize queries can lead to performance bottlenecks.\n\n### 6.2 Edge Cases\n\n*   **Concurrency Issues:** Be aware of concurrency issues when multiple users access the database simultaneously.\n*   **Data Type Mismatches:** Ensure data types in the application and the database are compatible.\n*   **Large Result Sets:** Handle large result sets efficiently to avoid memory issues.\n\n### 6.3 Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different SQLAlchemy versions.\n*   **Compatibility Issues:** Ensure compatibility between SQLAlchemy and other libraries.\n\n### 6.4 Debugging Strategies\n\n*   **Logging:** Use logging to track database queries and errors.\n*   **Debugging Tools:** Use debugging tools to step through code and inspect variables.\n*   **Query Analysis:** Analyze query execution plans to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Use a good IDE such as VS Code, PyCharm, or Spyder.\n*   **Database Client:** Use a database client such as pgAdmin, Dbeaver, or MySQL Workbench.\n*   **SQLAlchemy Profiler:** Use an SQLAlchemy profiler to analyze query performance.\n\n### 7.2 Build Configuration\n\n*   **Dependencies:** Use `requirements.txt` or `pyproject.toml` to manage dependencies.\n*   **Environment Variables:** Use environment variables to configure the application.\n\n### 7.3 Linting and Formatting\n\n*   **Linting:** Use linters such as pylint or flake8 to enforce code style.\n*   **Formatting:** Use formatters such as black or autopep8 to automatically format code.\n\n### 7.4 Deployment Best Practices\n\n*   **Database Configuration:** Configure the database connection settings correctly.\n*   **Security Hardening:** Harden the server and database to prevent security breaches.\n*   **Monitoring:** Implement monitoring to track application performance and errors.\n\n### 7.5 CI/CD Integration\n\n*   **Automated Testing:** Run automated tests during the CI/CD pipeline.\n*   **Database Migrations:** Apply database migrations during deployment.\n*   **Rollbacks:** Implement rollbacks in case of deployment failures.\n\nBy adhering to these best practices, you can build robust, scalable, and maintainable applications with SQLAlchemy. Remember to adapt these guidelines to your specific project requirements and context.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "sqlalchemy.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "sqlalchemy",
      "enforces",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "security",
      "testing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sqlalchemy",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-sqlite",
    "description": "This rule provides comprehensive guidance for SQLite development, covering best practices for schema design, performance optimization, security, testing, and more. It aims to ensure efficient, secure, and maintainable SQLite database applications.",
    "author": "sanjeed5",
    "tags": [
      "sqlite",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sqlite.mdc",
    "content": "# SQLite Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing with SQLite. It covers various aspects, including schema design, performance optimization, security considerations, testing strategies, common pitfalls, and tooling.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nA well-organized directory structure improves code maintainability and readability.\n\n\nproject_root/\n├── data/\n│   ├── production.db # Production database\n│   ├── development.db # Development database\n│   ├── test.db        # Test database\n│   └── migrations/   # Directory for database schema migrations\n│       ├── 001_initial_schema.sql\n│       └── 002_add_indexes.sql\n├── src/\n│   ├── database.py    # Database connection and helper functions\n│   ├── models.py        # Data models (if using an ORM)\n│   ├── queries.py       # Reusable SQL queries\n│   └── utils.py         # Utility functions\n├── tests/\n│   ├── conftest.py    # pytest configuration\n│   ├── test_database.py # Tests for database operations\n│   └── test_models.py   # Tests for data models\n├── .env               # Environment variables\n├── README.md          # Project documentation\n└── requirements.txt   # Python dependencies\n\n\n### 1.2. File Naming Conventions\n\n*   Database files: Use `.db`, `.sqlite`, or `.sqlite3` extensions (e.g., `mydatabase.db`).\n*   SQL migration files: Prefix with a sequence number and use descriptive names (e.g., `001_create_users_table.sql`).\n*   Python modules: Use lowercase with underscores (e.g., `database.py`, `models.py`).\n\n### 1.3. Module Organization\n\n*   **Database Connection Module:**  Encapsulate database connection logic within a dedicated module. This promotes reusability and simplifies connection management. The module should handle connection establishment, cursor creation, and resource cleanup.\n\n    python\n    # database.py\n    import sqlite3\n\n    DATABASE_PATH = \"./data/mydatabase.db\"\n\n    def get_db_connection():\n        conn = sqlite3.connect(DATABASE_PATH)\n        conn.row_factory = sqlite3.Row  # Access columns by name\n        return conn\n\n    def close_db_connection(conn):\n        if conn:\n            conn.close()\n    \n\n*   **Data Models Module:** Define Python classes or data structures that represent database tables. This abstraction simplifies data access and manipulation, especially when using an ORM. Data models can include validation and serialization logic.\n\n    python\n    # models.py\n    class User:\n        def __init__(self, id, username, email):\n            self.id = id\n            self.username = username\n            self.email = email\n    \n\n*   **Queries Module:** Store reusable SQL queries in a separate module. This promotes code reuse, reduces redundancy, and makes it easier to maintain queries. Queries can be parameterized to prevent SQL injection vulnerabilities.\n\n    python\n    # queries.py\n    CREATE_USER = \"\"\"INSERT INTO users (username, email) VALUES (?, ?);\"\"\"\n    GET_USER_BY_ID = \"\"\"SELECT id, username, email FROM users WHERE id = ?;\"\"\"\n    \n\n### 1.4. Component Architecture\n\nA layered architecture helps separate concerns and improve testability.\n\n*   **Data Access Layer:**  Manages interaction with the database. Contains functions for executing queries, retrieving data, and updating records. Uses the database connection and queries modules.\n*   **Business Logic Layer:** Contains the application's core logic. Processes data from the data access layer and implements business rules. Interacts with data models.\n*   **Presentation Layer:** Handles user interface and input/output. Communicates with the business logic layer to display data and receive user input.\n\n### 1.5. Code Splitting Strategies\n\n*   **Feature-based Splitting:** Group related code into modules or packages based on application features (e.g., user management, product catalog). This improves modularity and simplifies navigation.\n*   **Functional Splitting:** Separate code based on functionality (e.g., data access, business logic, UI components). This promotes reuse and simplifies testing.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Repository Pattern:** Abstract the data access layer behind an interface. Allows you to easily switch data sources or implement caching.\n*   **Data Mapper Pattern:**  Transfer data between domain objects and the database. Useful when working with complex data structures.\n*   **Unit of Work Pattern:** Track changes to domain objects within a transaction. Ensures data consistency and simplifies transaction management.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Connecting to the database:**  Use a connection pool to efficiently manage database connections, especially in multi-threaded environments.  See example above in Module Organization.\n*   **Executing queries:** Use parameterized queries to prevent SQL injection. Always close cursors and connections when finished.\n*   **Fetching data:** Use `fetchall()` or iterate over the cursor to retrieve all results. Use `fetchone()` to retrieve a single row.\n*   **Handling transactions:** Use `conn.commit()` to save changes and `conn.rollback()` to undo changes in case of errors.  Use `with conn:` to ensure transactions are handled properly.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Hardcoding SQL queries:**  Avoid embedding SQL queries directly within application code. Use parameterized queries and store queries in a separate module.\n*   **Ignoring errors:** Always check for errors after executing SQL statements. Use try-except blocks to handle exceptions gracefully.\n*   **Leaking database connections:** Ensure that connections are closed properly after use. Use context managers (`with conn:`) to automate connection management.\n*   **Over-fetching data:** Only retrieve the columns that are needed for a particular operation. Use `EXPLAIN QUERY PLAN` to optimize queries.\n*   **Using string concatenation for SQL queries:** **Never** use string concatenation to build SQL queries. This is a major security vulnerability that can lead to SQL injection attacks. Always use parameterized queries.\n\n### 2.4. State Management\n\n*   **Connection State:** Manage database connections at the application level. Use a single connection object for the entire application or connection pooling to efficiently manage multiple connections.\n*   **Transaction State:**  Use transactions to ensure data consistency. Commit changes only when all operations are successful. Rollback changes in case of errors.\n*   **Data Caching:** Cache frequently accessed data in memory to improve performance. Use a caching library or implement a custom caching mechanism.\n\n### 2.5. Error Handling\n\n*   **Use try-except blocks:** Wrap database operations in try-except blocks to catch potential exceptions.\n*   **Log errors:** Log error messages to a file or console for debugging purposes.\n*   **Rollback transactions:** If an error occurs during a transaction, rollback the transaction to prevent data corruption.\n*   **Raise custom exceptions:** Define custom exceptions to represent specific database errors.  This allows for more fine-grained error handling in higher-level code.\n\n    python\n    class DatabaseError(Exception):\n        pass\n\n    try:\n        with conn:\n            cursor.execute(\"INSERT INTO users (username) VALUES (?)\", (\"invalid username\",))\n    except sqlite3.IntegrityError as e:\n        raise DatabaseError(f\"Failed to insert user: {e}\")\n    \n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Schema Design:** Keep the database schema simple and avoid unnecessary generalization. Use strict tables to enforce type checking and ensure primary keys are non-nullable.\n*   **Indexing:** Create indexes on columns that are frequently used in `WHERE` clauses or `JOIN` conditions.\n*   **Prepared Statements:** Prepare SQL statements and bind values to reduce parsing overhead. Use transactions for batch operations, and prefer temporary tables for intermediate results. Avoid excessive use of indices and sub-queries, as they can degrade performance.\n*   **Transactions:** Use transactions to group multiple operations into a single atomic unit.\n*   **Appropriate Data Types:** Choosing the right data type can significantly impact performance.  For numeric primary keys, always use the `INTEGER` type for `rowid` aliasing.  Limit the size of TEXT columns to prevent excessive storage usage.\n*   **Avoid `SELECT *`:**  Instead, specify only the required columns.  This reduces the amount of data transferred from the database.\n*   **Use `EXPLAIN QUERY PLAN`:**  Analyze query execution plans to identify performance bottlenecks.  This allows you to optimize queries by adding indexes or rewriting the query.\n*   **Consider `WITHOUT ROWID` tables:** For tables where the `rowid` is not needed and all columns are part of the primary key, using `WITHOUT ROWID` can save space and improve performance.\n*   **Optimize table order in joins**:  Place tables without indexes on join columns at the far left of the SELECT statement.\n*   **Use `pragma optimize`**: Run this statement to optimize the database after making many changes.\n\n### 3.2. Memory Management\n\n*   **Connection Pooling:** Use a connection pool to reuse database connections and reduce connection overhead.\n*   **Cursor Management:** Close cursors after use to release resources. Use context managers to automatically close cursors.\n*   **Result Set Size:** Limit the size of result sets to prevent excessive memory usage. Use pagination or filtering to reduce the amount of data retrieved.\n*   **Bulk operations:**  Use `executemany` for bulk inserts or updates instead of looping and executing individual statements.\n*   **Large Blobs:** If storing large binary data (BLOBs), consider storing them as separate files and only store the file path in the database.\n\n### 3.3. Bundle Size Optimization (Applicable for applications bundling SQLite library)\n\n*   **Strip Debug Symbols:** Remove debug symbols from the SQLite library to reduce its size.\n*   **Enable Compile-Time Options:**  Disable unused SQLite features to reduce binary size.  Compile with options like `-DSQLITE_OMIT_...` to remove features that are not needed.\n*   **Use a Minimal Build:**  If possible, use a pre-built SQLite library that is optimized for size.\n\n### 3.4. Lazy Loading\n\n*   **Lazy Loading Relationships:** Load related data only when it is needed. This can improve performance, especially when dealing with complex relationships.\n*   **Virtual Tables:** Use virtual tables to access data from external sources on demand. This can reduce memory usage and improve performance.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **SQL Injection:**  The most common vulnerability. Prevent it by using parameterized queries (also known as prepared statements) exclusively. Never construct SQL queries using string concatenation with user-provided input.\n*   **Database File Access:**  Restrict access to the SQLite database file to only the necessary users and processes.  Use appropriate file system permissions to prevent unauthorized access.\n*   **Denial of Service (DoS):** Limit the amount of memory and CPU time that SQLite can consume to prevent DoS attacks. Use the `sqlite3_limit()` and `sqlite3_hard_heap_limit64()` functions.\n*   **Malicious Database Files:**  Be cautious when reading SQLite database files from untrusted sources.  A malicious database file can contain triggers or virtual tables that execute arbitrary code.  Use `PRAGMA integrity_check` and `PRAGMA quick_check` to verify the database file's integrity.\n\n### 4.2. Input Validation\n\n*   **Sanitize User Input:**  Always sanitize user input before using it in SQL queries.  This includes escaping special characters and validating data types.\n*   **Use Constraints:**  Define constraints on database columns to enforce data integrity.  This can help prevent invalid data from being inserted into the database.\n*   **Limit Input Lengths:**  Limit the length of text fields to prevent buffer overflows and DoS attacks.  Always define a maximum length on `TEXT` columns.\n\n### 4.3. Authentication and Authorization\n\n*   **SQLite Limitations:** SQLite itself does not provide built-in authentication or authorization mechanisms.\n*   **Application-Level Implementation:** Implement authentication and authorization logic in the application code that interacts with the database.  This can involve checking user credentials against a stored hash or using a role-based access control system.\n*   **Encryption:** Encrypt the SQLite database file to protect sensitive data. Use a library like SQLCipher to encrypt the database file.\n\n### 4.4. Data Protection\n\n*   **Encryption at Rest:**  Encrypt the database file to protect sensitive data when it is stored on disk. This protects against unauthorized access to the database file itself.\n*   **Encryption in Transit:**  Use SSL/TLS to encrypt communication between the application and the database, especially if the database is accessed over a network (though rare with SQLite).\n*   **Data Masking:** Mask sensitive data in query results or log files to prevent accidental disclosure. Use SQL functions or application-level logic to mask data.\n*   **Backup and Recovery:** Regularly back up the SQLite database file to prevent data loss. Store backups in a secure location.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication to protect data in transit.\n*   **API Keys:** Use API keys to authenticate API requests.\n*   **Rate Limiting:** Implement rate limiting to prevent DoS attacks.\n*   **Input Validation:** Validate all API inputs to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components of the application in isolation.  This includes testing data models, data access functions, and business logic.\n*   **Mock Database:** Use a mock database (e.g., an in-memory SQLite database) to isolate tests from the real database.  This allows you to run tests quickly and reliably without affecting the production database.\n*   **Verify Queries:** Assert that the correct SQL queries are executed by the data access functions.  This can be done by capturing the queries executed by the cursor and comparing them to expected values.\n*   **Test Edge Cases:**  Test edge cases and error conditions to ensure that the application handles them gracefully.  This includes testing invalid data inputs, database connection errors, and transaction failures.\n*   **Use `pytest` fixtures:** Employ `pytest` fixtures to set up and tear down the test environment (e.g., create and populate the mock database).\n\n    python\n    # tests/conftest.py\n    import pytest\n    import sqlite3\n    from src.database import get_db_connection, close_db_connection\n\n    @pytest.fixture\n    def test_db():\n        conn = sqlite3.connect(':memory:')  # In-memory database\n        conn.row_factory = sqlite3.Row\n        cursor = conn.cursor()\n        cursor.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, username TEXT)\")\n        cursor.execute(\"INSERT INTO users (username) VALUES (?)\", (\"testuser\",))\n        conn.commit()\n        yield conn\n        conn.close()\n\n    # tests/test_database.py\n    def test_get_user(test_db):\n        cursor = test_db.cursor()\n        cursor.execute(\"SELECT * FROM users WHERE username = ?\", (\"testuser\",))\n        user = cursor.fetchone()\n        assert user['username'] == \"testuser\"\n    \n\n### 5.2. Integration Testing\n\n*   **Test Interactions:** Integration tests should focus on testing the interactions between different components of the application.  This includes testing the interactions between the data access layer, the business logic layer, and the presentation layer.\n*   **Use a Test Database:** Use a separate test database for integration tests. This prevents integration tests from affecting the production database.\n*   **Verify Data Integrity:**  Verify that data is correctly stored and retrieved from the database.  This includes testing data validation, data transformations, and data relationships.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Application:** End-to-end tests should focus on testing the entire application from the user interface to the database.  This includes testing user workflows, data flows, and system integrations.\n*   **Use a Production-Like Environment:** Use a production-like environment for end-to-end tests.  This ensures that the tests are run in an environment that is similar to the production environment.\n*   **Automate Tests:** Automate end-to-end tests to ensure that they are run regularly and consistently.\n\n### 5.4. Test Organization\n\n*   **Separate Test Files:** Create separate test files for each component or module of the application. This makes it easier to organize and maintain tests.\n*   **Descriptive Test Names:** Use descriptive test names that clearly indicate what is being tested. This makes it easier to understand test results and debug failures.\n*   **Follow Arrange-Act-Assert Pattern:** Structure tests according to the Arrange-Act-Assert pattern. This makes tests more readable and maintainable.\n*   **Keep Tests Independent:** Ensure that tests are independent of each other. This prevents tests from interfering with each other and makes it easier to run tests in parallel.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock External Dependencies:** Use mocking to isolate tests from external dependencies, such as network services or file systems. This allows you to test components in isolation without relying on external resources.\n*   **Stub Database Calls:** Use stubs to replace database calls with pre-defined results. This allows you to test components that interact with the database without actually accessing the database.\n*   **Verify Interactions:** Verify that the correct methods are called on mock objects or stubs. This ensures that components are interacting with each other as expected.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **SQL Injection:** Failing to use parameterized queries.\n*   **Data Type Mismatches:** Inserting data with incorrect data types into database columns. Strict mode and explicit type definitions can help mitigate this.\n*   **Concurrency Issues:**  Not handling concurrency correctly in multi-threaded environments.  Use connection pooling and proper transaction management.\n*   **Deadlocks:** Creating deadlocks by acquiring locks in the wrong order. Be aware of transaction isolation levels and lock contention.\n*   **Schema Evolution:** Failing to plan for schema evolution. Use database migrations to manage schema changes.\n\n### 6.2. Edge Cases\n\n*   **Large Databases:** Handling databases with large amounts of data. Use pagination, indexing, and query optimization techniques.\n*   **Concurrent Access:** Handling concurrent access to the database. Use connection pooling, transactions, and locking mechanisms.\n*   **Corrupted Database Files:**  Handling corrupted database files.  Use `PRAGMA integrity_check` and implement a backup and recovery strategy.\n*   **Full Disk:** Handle situations where disk space is exhausted and database writes fail.\n\n### 6.3. Version-Specific Issues\n\n*   **Compatibility Changes:** Be aware of compatibility changes between different versions of SQLite. Consult the SQLite documentation for details.\n*   **New Features:** Take advantage of new features in newer versions of SQLite. This can improve performance, security, or functionality.\n\n### 6.4. Compatibility Concerns\n\n*   **Cross-Platform Compatibility:** Ensure that the application is compatible with different operating systems and architectures. Test the application on different platforms.\n*   **Data Type Differences:** Be aware of data type differences between SQLite and other database systems. Use compatible data types or perform data conversions as needed.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Use logging to track database operations and errors. Log SQL queries, execution times, and error messages.\n*   **Debugging Tools:** Use debugging tools to inspect the database schema, data, and query execution plans. Tools like DB Browser for SQLite are very useful.\n*   **Error Messages:** Pay attention to error messages. Error messages can provide valuable clues about the cause of the problem.\n*   **Simplify Queries:** Simplify complex queries to isolate the source of the problem.\n*   **Replicate the Issue:** Try to replicate the issue in a controlled environment. This can help you identify the root cause of the problem.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **DB Browser for SQLite:** A graphical tool for managing SQLite databases.\n*   **SQLite command-line shell:**  A command-line tool for interacting with SQLite databases.  Available as `sqlite3`.\n*   **Python sqlite3 module:** Python's built-in module for working with SQLite databases.\n*   **SQLCipher:** An open-source extension to SQLite that provides transparent encryption.\n*   **ORM (Object-Relational Mapper):**  Libraries like SQLAlchemy or PonyORM can simplify database interactions, but use caution and understand the underlying SQL generated, as ORMs can sometimes lead to inefficient queries.\n\n### 7.2. Build Configuration\n\n*   **Dependencies:** Manage dependencies using a dependency management tool (e.g., `pip`, `poetry`, `conda`).\n*   **Compiler Options:** Use appropriate compiler options to optimize the SQLite library for performance.\n*   **Linking:** Link the SQLite library statically or dynamically depending on the application requirements.\n\n### 7.3. Linting and Formatting\n\n*   **SQL Linters:** Use SQL linters to enforce coding standards and identify potential errors in SQL queries. Use tools like `sqlfluff`.\n*   **Code Formatters:** Use code formatters to automatically format SQL queries and code. Use formatters available through IDE extensions or command-line tools.\n*   **Consistency:** Maintain consistency in code formatting and style across the project.\n\n### 7.4. Deployment\n\n*   **Database File Location:** Store the SQLite database file in a secure location on the server.\n*   **File Permissions:** Set appropriate file permissions on the database file to prevent unauthorized access.\n*   **Backup Strategy:** Implement a backup and recovery strategy to protect against data loss.\n*   **Connection Limits:** Configure connection limits to prevent denial-of-service attacks.\n\n### 7.5. CI/CD Integration\n\n*   **Automated Tests:** Integrate automated tests into the CI/CD pipeline to ensure that code changes do not break existing functionality.\n*   **Database Migrations:** Automate database migrations as part of the deployment process.\n*   **Rollback Strategy:** Implement a rollback strategy to revert to a previous version of the application in case of deployment failures.\n\nBy following these best practices and coding standards, developers can create efficient, secure, and maintainable SQLite database applications.",
    "metadata": {
      "globs": "*.db,*.sqlite,*.sqlite3,*.sql",
      "format": "mdc",
      "originalFile": "sqlite.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "sqlite",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "development",
      "covering",
      "best",
      "practices",
      "cursor-rule",
      "mdc",
      "data-ai",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sqlite",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "data-ai"
    }
  },
  {
    "name": "cursor-statsmodels",
    "description": "A comprehensive guide to best practices for using the statsmodels library in Python, covering code organization, performance, testing, and common pitfalls. These guidelines promote maintainable, reliable, and efficient statsmodels code.",
    "author": "sanjeed5",
    "tags": [
      "statsmodels",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/statsmodels.mdc",
    "content": "# Statsmodels Library Best Practices\n\nThis document outlines best practices and coding standards for effectively using the statsmodels library in Python for statistical modeling, machine learning, and data science applications. Following these guidelines will help ensure code that is readable, maintainable, efficient, and statistically sound.\n\n## Library Information:\n- Name: statsmodels\n- Tags: ai, ml, data-science, python, statistics\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nAdopt a clear and organized directory structure for your projects:\n\n\nproject_root/\n├── data/              # Raw and processed datasets\n├── models/            # Saved model artifacts\n├── scripts/           # Data processing, model training, evaluation scripts\n├── notebooks/          # Exploratory data analysis and prototyping (use sparingly for final code)\n├── tests/             # Unit, integration, and end-to-end tests\n├── docs/              # Project documentation\n├── requirements.txt  # Project dependencies\n└── main.py            # Entry point for the application (if applicable)\n\n\n### 1.2 File Naming Conventions\n\n- Use descriptive and consistent file names.\n- Data files: `data_description.csv`, `data_description.parquet`\n- Script files: `process_data.py`, `train_model.py`, `evaluate_model.py`\n- Model files: `model_name.pkl` (if pickling, but consider other serialization methods)\n- Test files: `test_module.py`\n\n### 1.3 Module Organization\n\n- Break down your code into reusable modules.\n- `data_loading.py`: Functions for loading and preprocessing data.\n- `model_definition.py`: Classes or functions for defining statsmodels models.\n- `model_training.py`: Functions for training models.\n- `model_evaluation.py`: Functions for evaluating model performance.\n- `utils.py`: Utility functions used throughout the project.\n\n### 1.4 Component Architecture\n\n- Employ a modular architecture to separate concerns.\n- **Data Layer:** Handles data loading, cleaning, and transformation.\n- **Model Layer:** Defines and trains statsmodels models.\n- **Evaluation Layer:** Assesses model performance using appropriate metrics.\n- **Application Layer:** Integrates the model into an application (if applicable).\n\n### 1.5 Code Splitting Strategies\n\n- Split large files into smaller, more manageable modules.\n- Group related functions and classes into separate modules.\n- Use clear and concise function and class names to indicate their purpose.\n- Consider a `config.py` file for global project settings.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Factory Pattern:** Use a factory pattern to create different statsmodels models based on configuration.\n- **Strategy Pattern:** Implement different evaluation strategies using the strategy pattern.\n- **Observer Pattern:** If changes in the underlying data need to trigger model retraining, consider the observer pattern.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Data Preprocessing:** Always use Pandas DataFrames for data manipulation before feeding data into statsmodels.\n- **Model Selection:** Choose models based on the statistical properties of your data and the research question.\n- **Model Fitting:** Use `statsmodels.api` to fit models, and carefully interpret the output.\n- **Result Interpretation:**  Focus on coefficients, p-values, confidence intervals, and model diagnostics.\n- **Visualization:** Utilize Matplotlib and Seaborn to visualize data, model results, and diagnostics.\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Magic Numbers:** Avoid hardcoding constants directly in your code; define them with descriptive names.\n- **Copy-Pasted Code:** Refactor duplicated code into reusable functions or classes.\n- **Overly Long Functions:** Break down long functions into smaller, more manageable units.\n- **Lack of Documentation:**  Always document your code with docstrings to explain its purpose and usage.\n- **Ignoring Warnings:** Pay attention to warnings generated by statsmodels; they often indicate potential issues.\n\n### 2.4 State Management\n\n- Avoid global state as much as possible.  Pass data and model parameters explicitly.\n- If you need to persist model state, use appropriate serialization techniques (e.g., pickling, but with caution due to security risks).  Consider alternatives like ONNX or joblib.\n- For complex applications, use dependency injection frameworks to manage dependencies and state.\n\n### 2.5 Error Handling\n\n- Use try-except blocks to handle potential errors gracefully.\n- Log errors and warnings using the `logging` module.\n- Raise exceptions with informative error messages to help with debugging.\n- Consider custom exception classes for specific statsmodels-related errors.\n\npython\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ntry:\n    model = sm.OLS(y, X).fit()\nexcept Exception as e:\n    logger.error(f\"Error fitting model: {e}\")\n    raise  # Re-raise the exception for higher-level handling\n\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **Vectorization:**  Utilize NumPy's vectorized operations whenever possible to speed up computations.\n- **Profiling:** Use profiling tools like `cProfile` to identify performance bottlenecks.\n- **Caching:** Cache frequently used results to avoid redundant computations (use `functools.lru_cache` for example).\n- **Algorithm Selection:** Choose the most efficient algorithms for your specific task (e.g., different optimization methods in statsmodels).\n\n### 3.2 Memory Management\n\n- **Data Types:**  Use appropriate data types to minimize memory usage (e.g., `np.int32` instead of `np.int64` if possible).\n- **Lazy Loading:**  Load large datasets in chunks to avoid loading the entire dataset into memory at once.\n- **Garbage Collection:**  Explicitly release unused memory using `del` or `gc.collect()` if necessary.\n\n### 3.3 Parallelization\n\n- Explore parallelization options using libraries like `multiprocessing` or `joblib` for computationally intensive tasks.\n- Statsmodels may leverage underlying NumPy and SciPy functions that support parallel execution.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n- **Pickle Deserialization:** Avoid deserializing untrusted pickle files, as they can execute arbitrary code. Use safer serialization formats like JSON or ONNX.\n- **Injection Attacks:**  Sanitize user inputs to prevent injection attacks if your application takes user-provided data and uses it in statsmodels models.\n- **Denial of Service (DoS):**  Implement rate limiting and resource constraints to prevent DoS attacks on your statsmodels-based services.\n\n### 4.2 Input Validation\n\n- Validate all input data to ensure it conforms to the expected format and range.\n- Use schemas (e.g., using `jsonschema` or `pydantic`) to define and enforce data validation rules.\n- Check for missing values, outliers, and inconsistencies in the data.\n\n### 4.3 Authentication and Authorization\n\n- Implement authentication and authorization mechanisms to control access to your statsmodels-based services.\n- Use secure authentication protocols like OAuth 2.0 or JWT.\n- Enforce role-based access control (RBAC) to restrict access to sensitive data and operations.\n\n### 4.4 Data Protection\n\n- Encrypt sensitive data at rest and in transit.\n- Use secure communication protocols like HTTPS.\n- Implement data masking and anonymization techniques to protect user privacy.\n\n### 4.5 Secure API Communication\n\n- Use secure APIs (e.g., REST APIs with HTTPS) to communicate with your statsmodels services.\n- Implement input validation and output sanitization to prevent injection attacks.\n- Use API keys or other authentication mechanisms to secure your APIs.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- Write unit tests for individual functions and classes.\n- Use the `unittest` or `pytest` framework.\n- Test edge cases and boundary conditions.\n- Mock external dependencies to isolate the code being tested.\n\npython\nimport unittest\nimport statsmodels.api as sm\nimport numpy as np\n\nclass TestOLS(unittest.TestCase):\n    def test_ols_fit(self):\n        # Create some sample data\n        X = np.array([[1, 1], [1, 2], [1, 3]])\n        y = np.array([2, 4, 5])\n\n        # Fit an OLS model\n        model = sm.OLS(y, X).fit()\n\n        # Assert that the model converged\n        self.assertTrue(model.converged)\n\n        # Assert that the coefficients are close to the expected values\n        expected_coefs = np.array([0.5, 1.5])\n        np.testing.assert_allclose(model.params, expected_coefs, rtol=1e-5)\n\nif __name__ == '__main__':\n    unittest.main()\n\n\n### 5.2 Integration Testing\n\n- Write integration tests to verify the interaction between different components.\n- Test the data pipeline from data loading to model evaluation.\n- Verify that the model produces correct results on sample datasets.\n\n### 5.3 End-to-End Testing\n\n- Write end-to-end tests to simulate real-world usage scenarios.\n- Test the entire application from start to finish.\n- Use tools like Selenium or Cypress to automate browser-based testing (if applicable).\n\n### 5.4 Test Organization\n\n- Organize your tests in a separate `tests` directory.\n- Use a consistent naming convention for test files (e.g., `test_module.py`).\n- Group related tests into test classes.\n\n### 5.5 Mocking and Stubbing\n\n- Use mocking libraries like `unittest.mock` or `pytest-mock` to isolate the code being tested.\n- Mock external dependencies like databases or APIs.\n- Stub out complex functions to simplify testing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Incorrect Model Specification:** Choosing the wrong model for the data.\n- **Ignoring Data Assumptions:** Failing to check the assumptions of the statistical tests or models being used.\n- **Overfitting:** Training a model that performs well on the training data but poorly on unseen data.\n- **Misinterpreting Results:** Drawing incorrect conclusions from the model output.\n- **Not Scaling Features**: Some models will perform poorly if the data is not scaled or normalized\n\n### 6.2 Edge Cases\n\n- **Multicollinearity:** Independent variables being highly correlated\n- **Missing Data:** Handling missing values appropriately.\n- **Outliers:** Identifying and handling outliers in the data.\n- **Non-Normal Data:** Dealing with data that doesn't follow a normal distribution.\n\n### 6.3 Version-Specific Issues\n\n- Be aware of changes in statsmodels API between versions.\n- Check the release notes for any breaking changes or bug fixes.\n- Use a virtual environment to manage dependencies and ensure compatibility.\n\n### 6.4 Compatibility Concerns\n\n- Ensure compatibility between statsmodels and other libraries like NumPy, SciPy, and Pandas.\n- Check the documentation for any known compatibility issues.\n\n### 6.5 Debugging Strategies\n\n- Use a debugger (e.g., `pdb`) to step through the code and inspect variables.\n- Add logging statements to track the execution flow and identify potential issues.\n- Use assertions to verify that the code is behaving as expected.\n- Consult the statsmodels documentation and community forums for help.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE:** VS Code, PyCharm, or other Python IDE.\n- **Virtual Environment Manager:** `venv`, `conda`.\n- **Package Manager:** `pip`, `conda`.\n- **Debugger:** `pdb`, `ipdb`.\n- **Profiler:** `cProfile`.\n\n### 7.2 Build Configuration\n\n- Use `setuptools` or `poetry` to manage project dependencies and build configurations.\n- Create a `requirements.txt` file to specify project dependencies.\n- Use a `setup.py` file to define the project metadata and build process.\n\n### 7.3 Linting and Formatting\n\n- Use linters like `flake8` or `pylint` to enforce code style and identify potential errors.\n- Use formatters like `black` or `autopep8` to automatically format your code.\n- Configure your IDE to run linters and formatters automatically on save.\n\n### 7.4 Deployment\n\n- Containerize your application using Docker.\n- Use a deployment platform like AWS, Azure, or Google Cloud.\n- Monitor your application for performance and errors.\n\n### 7.5 CI/CD\n\n- Use a CI/CD platform like GitHub Actions, Jenkins, or CircleCI to automate the build, test, and deployment process.\n- Run unit tests, integration tests, and end-to-end tests as part of the CI/CD pipeline.\n- Deploy your application automatically to a staging or production environment after successful testing.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "statsmodels.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "statsmodels",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "using",
      "library",
      "python",
      "covering",
      "code",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "statsmodels",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-streamlit",
    "description": "This rule provides guidelines and best practices for developing maintainable, performant, and secure Streamlit applications. It covers code organization, performance optimization, security considerations, testing strategies, and common pitfalls to avoid.",
    "author": "sanjeed5",
    "tags": [
      "streamlit",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/streamlit.mdc",
    "content": "- **Code Organization and Structure**:\n  - **Directory Structure**: Structure your Streamlit application using a modular directory structure to improve maintainability and collaboration. A suggested layout includes folders for pages, services, models, components, and utilities.\n    \n    my_streamlit_app/\n    ├── app.py                # Main entry point for the Streamlit app\n    ├── pages/              # Directory for individual app pages\n    │   ├── dashboard.py    # Dashboard page\n    │   ├── reports.py      # Reports page\n    │   └── settings.py     # Settings page\n    ├── services/           # Directory for business logic and data operations\n    │   ├── data_loader.py  # Handles data loading\n    │   ├── analysis.py     # Contains data analysis functions\n    │   └── utils.py        # Utility functions\n    ├── models/             # Directory for data models and schemas\n    │   └── data_model.py   # Defines data structures\n    ├── components/         # Directory for reusable UI components\n    │   ├── button.py       # Custom button component\n    │   └── chart.py        # Custom chart component\n    ├── utils/              # Miscellaneous utility functions\n    │   └── helpers.py      # Helper functions\n    ├── requirements.txt      # List of Python dependencies\n    ├── .gitignore            # Specifies intentionally untracked files that Git should ignore\n    └── .venv/                # Python virtual environment (optional)\n    \n  - **File Naming Conventions**: Use descriptive and consistent file names for your Streamlit components, services, and pages.  For example, `data_loader.py`, `dashboard.py`, and `button.py`.\n  - **Module Organization**: Organize your Streamlit application into logical modules to promote code reuse and reduce complexity.  Create separate modules for data loading, data processing, UI components, and utility functions.  Use relative imports to maintain a clear module structure.\n  - **Component Architecture**: Build reusable UI components using Streamlit's `st.components.v1` API or custom functions.  Encapsulate component logic and styling to promote consistency and maintainability.  Use props or parameters to customize component behavior and appearance.\n  - **Code Splitting**: Split large Streamlit applications into multiple pages using the `st.page_config` and `st.switch_page` functions. This enhances navigation and reduces initial loading times. Consider lazy loading strategies using the `secrets` feature to control which parts of the application are loaded when. \n\n- **Common Patterns and Anti-patterns**:\n  - **Design Patterns**: Employ the Observer pattern for reactive UIs, Facade pattern for simplifying complex interactions, and Strategy pattern to manage different data sources or algorithms.\n  - **Recommended Approaches**: Utilize Streamlit's `st.form` for handling user input and submission. Use `st.session_state` to manage application state across reruns. Leverage Streamlit's caching mechanisms (`@st.cache_data`, `@st.cache_resource`) to optimize performance.\n  - **Anti-patterns**: Avoid performing expensive computations or data loading operations directly within the main Streamlit application loop.  Do not store large datasets in `st.session_state`.  Avoid using global variables, as they can lead to unexpected behavior.\n  - **State Management**:  Use `st.session_state` for storing and managing application state across reruns.  Initialize session state variables using a conditional statement (`if 'key' not in st.session_state:`) to prevent overwriting values on subsequent reruns. Consider implementing a state management class or module to encapsulate and manage complex state logic.\n  - **Error Handling**:  Implement comprehensive error handling throughout your Streamlit application.  Use `try...except` blocks to catch exceptions and display informative error messages to the user using `st.error` or `st.exception`.  Log errors to a file or monitoring system for debugging and analysis.\n\n- **Performance Considerations**:\n  - **Optimization Techniques**: Use caching (`@st.cache_data`, `@st.cache_resource`) to store the results of expensive computations or data loading operations. Optimize data loading by using appropriate data formats (e.g., Parquet, Feather) and filtering data at the source. Debounce user interactions to reduce the frequency of reruns.\n  - **Memory Management**:  Avoid loading large datasets into memory unnecessarily.  Use data streaming techniques or chunking to process large datasets in smaller portions.  Delete unused variables and data structures to release memory.\n  - **Rendering Optimization**:  Use Streamlit's built-in rendering optimizations, such as delta generation, to minimize the amount of data that needs to be sent to the browser.  Avoid creating complex layouts with deeply nested components, as this can impact rendering performance.\n  - **Bundle Size**: Minimize external dependencies to reduce the bundle size and improve loading times. Use a `.streamlitignore` file to exclude unnecessary files and directories from the Streamlit deployment bundle.  Consider using a CDN to serve static assets.\n  - **Lazy Loading**: Implement lazy loading for expensive components or sections of your Streamlit application.  Load components only when they are needed, using conditional rendering or callbacks. Utilize the `secrets` functionality to control the conditional loading of certain modules if access to a given secret is available. \n\n- **Security Best Practices**:\n  - **Common Vulnerabilities**: Be aware of common vulnerabilities, such as cross-site scripting (XSS), SQL injection, and command injection.  Prevent these vulnerabilities by implementing proper input validation and sanitization, and by avoiding the execution of untrusted code.\n  - **Input Validation**: Validate all user inputs to prevent malicious code from being injected into your Streamlit application.  Use regular expressions or custom validation functions to ensure that inputs conform to expected formats and ranges. Sanitize user inputs by encoding or escaping special characters.\n  - **Authentication and Authorization**: Implement authentication and authorization mechanisms to control access to sensitive data and functionality.  Use Streamlit's `secrets` API to store API keys, passwords, and other sensitive information securely.  Consider using a third-party authentication provider, such as Auth0 or Google Identity Platform.\n  - **Data Protection**: Protect sensitive data by encrypting it at rest and in transit.  Use HTTPS to secure communication between the browser and the Streamlit application.  Implement data masking or redaction to prevent sensitive data from being displayed to unauthorized users.\n  - **Secure API Communication**: Always use HTTPS for API communications. Validate the origin and authenticity of data from external APIs. Protect API keys using Streamlit secrets and environment variables.\n\n- **Testing Approaches**:\n  - **Unit Testing**: Unit test individual Streamlit components, services, and utility functions using the `pytest` framework.  Mock external dependencies to isolate the code being tested.  Write test cases that cover a range of inputs and edge cases.\n  - **Integration Testing**: Integrate test Streamlit applications to verify that components and modules work together correctly.  Use Streamlit's testing utilities to simulate user interactions and verify the output.\n  - **End-to-end Testing**: Perform end-to-end tests to verify that the entire Streamlit application works as expected.  Use Selenium or Cypress to automate browser interactions and verify the UI and functionality.\n  - **Test Organization**: Organize your tests into a separate `tests` directory within your Streamlit project.  Use descriptive test names and docstrings to explain the purpose of each test.  Follow a consistent naming convention for test files and functions.\n  - **Mocking and Stubbing**: Use mocking and stubbing techniques to isolate the code being tested and to simulate external dependencies.  Use the `unittest.mock` module or a third-party mocking library to create mock objects and stubs.\n\n- **Common Pitfalls and Gotchas**:\n  - **Frequent Mistakes**: Forgetting to use `@st.cache_data` or `@st.cache_resource` for expensive operations, not managing `st.session_state` properly, and neglecting error handling are common mistakes.\n  - **Edge Cases**: Be aware of edge cases, such as handling missing data, dealing with invalid inputs, and managing concurrent user sessions.\n  - **Version-Specific Issues**: Check the Streamlit documentation and release notes for version-specific issues and compatibility concerns. Be aware of breaking changes when upgrading to a newer version of Streamlit.\n  - **Compatibility Concerns**: Ensure that your Streamlit application is compatible with the browsers and operating systems that your users will be using.  Test your application on different devices and browsers to identify and resolve compatibility issues.\n  - **Debugging Strategies**: Use Streamlit's debugging tools, such as the debugger and the console, to identify and resolve issues.  Print debug messages to the console to track the execution flow and to inspect variables. Use `st.experimental_rerun` to programmatically trigger reruns during debugging.\n\n- **Tooling and Environment**:\n  - **Recommended Tools**: Use VS Code with the Python extension for development. Use `pip` or `uv` for dependency management, and Docker for containerization.\n  - **Build Configuration**: Create a `requirements.txt` file to list your Streamlit application's dependencies.  Use a virtual environment to isolate your project's dependencies from the system-level Python installation.  Consider using a build tool, such as Make or Poetry, to automate the build process.\n  - **Linting and Formatting**: Use linters and formatters, such as `flake8` and `black`, to enforce code style guidelines and to identify potential errors. Configure your editor to automatically run linters and formatters on save.\n  - **Deployment**: Deploy your Streamlit application to Streamlit Cloud, Heroku, AWS, or another cloud platform.  Use Docker to containerize your application and to ensure consistent deployment across different environments.\n  - **CI/CD Integration**: Integrate your Streamlit project with a CI/CD pipeline to automate the testing, building, and deployment processes.  Use GitHub Actions, GitLab CI, or another CI/CD platform to configure your pipeline.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "streamlit.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "streamlit",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "developing",
      "maintainable",
      "performant",
      "secure",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "streamlit",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-stripe",
    "description": "This rule file outlines best practices for integrating Stripe's payment processing services into web and mobile applications, focusing on security, performance, and maintainability. It provides guidelines on coding standards, error handling, and testing to ensure a robust and reliable Stripe integration.",
    "author": "sanjeed5",
    "tags": [
      "stripe",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/stripe.mdc",
    "content": "# Stripe Integration Best Practices\n\nThis document provides a comprehensive guide to best practices for integrating Stripe's payment processing services. It covers code organization, common patterns, performance considerations, security, testing, common pitfalls, and tooling.\n\n## Library Information:\n- Name: stripe\n- Tags: payments, api, e-commerce, financial\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nOrganizing your project effectively enhances maintainability and readability.  Consider the following structure:\n\n\nproject-root/\n├── src/\n│   ├── components/       # Reusable UI components (if applicable)\n│   ├── services/\n│   │   └── stripe/       # Stripe-related services\n│   │       ├── payments.js/ts  # Payment processing logic\n│   │       ├── subscriptions.js/ts # Subscription management\n│   │       ├── webhooks.js/ts    # Webhook handling\n│   │       ├── utils.js/ts       # Utility functions\n│   ├── models/            # Data models and types\n│   ├── config/           # Configuration files (API keys, etc.)\n│   ├── utils/             # General utility functions\n├── tests/             # Test suites\n├── .env               # Environment variables\n└── ...\n\n\n*   `components`:  If you're building a UI, this directory holds reusable UI components. This might include components that display payment forms or payment status indicators.\n*   `services/stripe`: This directory encapsulates all Stripe-related interactions. This promotes separation of concerns and makes it easier to update or replace the Stripe integration in the future.\n*   `payments.js/ts`: Contains functions for creating charges, handling payment intents, and processing refunds.\n*   `subscriptions.js/ts`:  Includes logic for creating, updating, and canceling subscriptions.\n*   `webhooks.js/ts`: Handles incoming Stripe webhook events.  Crucially important for asynchronous payment flows.\n*   `utils.js/ts`: Contains utility functions, such as formatting currency or validating data.\n*   `models`: Defines data models for Stripe objects (e.g., Customer, Charge, PaymentIntent).  This can be useful for type checking and data validation.\n*   `config`: Stores configuration settings, including your Stripe API keys. Never commit your secret keys to version control. Use environment variables.\n*   `utils`:  General utility functions used throughout your application.\n*   `tests`: Contains unit and integration tests for your Stripe integration.\n\n### 1.2 File Naming Conventions\n\n*   Use descriptive names for files and functions.\n*   Follow the naming conventions of your chosen language (e.g., camelCase in JavaScript, snake_case in Python).\n*   Example:\n    *   `stripePayments.js` (JavaScript)\n    *   `stripe_payments.py` (Python)\n    *   `StripePayments.java` (Java)\n\n### 1.3 Module Organization\n\n*   Break down your Stripe integration into smaller, reusable modules.\n*   Use clear and consistent naming conventions for modules.\n*   Export only the necessary functions and classes from each module to maintain a clean API.\n\n### 1.4 Component Architecture (If Applicable)\n\n*   If building a UI, design reusable components for payment forms, payment status displays, and other Stripe-related elements.\n*   Use a component-based framework (e.g., React, Vue.js, Angular) to manage UI complexity.\n*   Consider using a state management library (e.g., Redux, Zustand, Vuex) to manage Stripe-related state.\n\n### 1.5 Code Splitting Strategies\n\n*   Lazy-load Stripe-related code to reduce the initial bundle size of your application.\n*   Dynamically import modules containing Stripe-specific logic only when they are needed.\n*   Use code splitting features provided by your bundler (e.g., Webpack, Parcel) to separate Stripe code into its own chunk.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Facade:** Create a facade to simplify the Stripe API and provide a higher-level interface for your application.\n*   **Adapter:** Use an adapter to map data between your application's data model and Stripe's data model.\n*   **Strategy:** Implement a strategy pattern to handle different payment methods.\n*   **Observer:**  Implement an observer pattern with webhooks. When certain events occur in Stripe, your application gets notified by the Observer (Stripe's Webhooks).\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Creating a Charge:** Use Payment Intents for new integrations, and migrate from Charges if possible.  Payment Intents handle SCA and other authentication requirements more gracefully.\n*   **Handling Webhooks:**  Implement robust webhook handling with retries and proper error handling.\n*   **Managing Subscriptions:**  Use Stripe's Subscription API to manage recurring payments.\n*   **Storing Card Details:** Use Stripe Elements to securely collect and tokenize card details.\n*   **Handling Errors:** Implement comprehensive error handling to gracefully handle API errors.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Storing API Keys in Client-Side Code:**  Never expose your secret API keys in client-side code.  All server side interaction only.\n*   **Directly Accessing the Stripe API from UI Components:**  Introduce a service layer to decouple UI components from Stripe API calls.\n*   **Ignoring Webhook Events:**  Always handle webhook events to ensure that your application is synchronized with Stripe's state.\n*   **Not Validating Input:**  Always validate user input to prevent security vulnerabilities.\n*   **Creating CHARGES directly:** Prefer PaymentIntents which abstract away much of the complexity and make the code future-proof.\n\n### 2.4 State Management\n\n*   Use a state management library (e.g., Redux, Zustand, Vuex) to manage Stripe-related state in UI applications.\n*   Store only the necessary data in the state to minimize memory usage.\n*   Use immutable data structures to simplify state updates and prevent unexpected side effects.\n\n### 2.5 Error Handling\n\n*   Implement comprehensive error handling to gracefully handle API errors.\n*   Log errors to a central location for monitoring and debugging.\n*   Provide informative error messages to the user.\n*   Implement retry logic for transient errors.\n*   Handle specific Stripe errors (e.g., card declined, invalid API key) appropriately.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   Cache frequently accessed data to reduce API calls.\n*   Use Stripe's pagination features to retrieve large datasets in smaller chunks.\n*   Optimize database queries to improve performance.\n*   Minimize the number of API calls required to complete a task.\n*   Use webhooks to avoid polling the Stripe API.\n\n### 3.2 Memory Management\n\n*   Avoid storing large amounts of Stripe data in memory.\n*   Use pagination to retrieve large datasets in smaller chunks.\n*   Release resources when they are no longer needed.\n\n### 3.3 Rendering Optimization (If Applicable)\n\n*   Optimize UI components to minimize rendering time.\n*   Use techniques such as virtualization and memoization to improve rendering performance.\n*   Avoid re-rendering components unnecessarily.\n\n### 3.4 Bundle Size Optimization\n\n*   Use code splitting to reduce the initial bundle size of your application.\n*   Remove unused code from your Stripe integration.\n*   Use a minifier to reduce the size of your code.\n\n### 3.5 Lazy Loading\n\n*   Lazy-load Stripe-related code to reduce the initial bundle size of your application.\n*   Dynamically import modules containing Stripe-specific logic only when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n*   **Cross-Site Scripting (XSS):**  Sanitize user input to prevent XSS attacks.  Use Stripe Elements to securely collect card details.\n*   **Cross-Site Request Forgery (CSRF):**  Protect against CSRF attacks by using anti-CSRF tokens.\n*   **SQL Injection:**  Use parameterized queries to prevent SQL injection attacks.\n*   **API Key Exposure:**  Never expose your secret API keys in client-side code. Store API Keys as environment variables on a secure server.\n*   **Man-in-the-Middle Attacks:** Enforce HTTPS to protect against man-in-the-middle attacks.\n\n### 4.2 Input Validation\n\n*   Validate all user input to prevent security vulnerabilities.\n*   Use strong validation rules to ensure that data is valid.\n*   Sanitize user input to remove malicious characters.\n\n### 4.3 Authentication and Authorization\n\n*   Use Stripe's API keys to authenticate requests.\n*   Use restricted API keys for granular permissions.\n*   Implement role-based access control to restrict access to sensitive data.\n\n### 4.4 Data Protection\n\n*   Use Stripe Elements to securely collect and tokenize card details.\n*   Encrypt sensitive data at rest and in transit.\n*   Follow PCI DSS compliance guidelines.\n*   Regularly review your security practices to mitigate risks.\n*   Implement tokenization to protect sensitive payment information.\n\n### 4.5 Secure API Communication\n\n*   Enforce HTTPS for all API communication.\n*   Use TLS 1.2 or higher.\n*   Verify the authenticity of Stripe's servers using SSL/TLS certificates.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   Write unit tests for individual components and functions in your Stripe integration.\n*   Use mocking and stubbing to isolate components from external dependencies.\n*   Test edge cases and error conditions.\n\n### 5.2 Integration Testing\n\n*   Write integration tests to verify that different parts of your Stripe integration work together correctly.\n*   Test the interaction between your application and the Stripe API.\n*   Use a test Stripe account to avoid affecting live data.\n\n### 5.3 End-to-End Testing\n\n*   Write end-to-end tests to verify that your Stripe integration works correctly from the user's perspective.\n*   Use a testing framework such as Cypress or Selenium to automate end-to-end tests.\n\n### 5.4 Test Organization\n\n*   Organize your tests into logical suites based on functionality.\n*   Use clear and consistent naming conventions for tests.\n*   Run tests automatically as part of your CI/CD pipeline.\n\n### 5.5 Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate components from external dependencies.\n*   Mock the Stripe API to simulate different scenarios and error conditions.\n*   Use a mocking library such as Jest or Sinon.js.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Not Handling Webhooks:** Failing to handle webhook events can lead to inconsistent data and missed events.\n*   **Storing API Keys in Client-Side Code:** Exposing your secret API keys in client-side code can compromise your account.\n*   **Not Validating Input:** Failing to validate user input can lead to security vulnerabilities.\n*   **Using Test Data in Production:** Using test data in a live environment can lead to incorrect transactions and data corruption.\n*   **Ignoring Error Messages:**  Treat stripe error messages as a core part of the functionality. Do not display generic error messages.\n\n### 6.2 Edge Cases\n\n*   **Idempotency:**  Handle requests carefully by using idempotency keys. These keys ensure that accidental duplicate requests do not result in unexpected behavior, like multiple charges for the same transaction.\n*   **Network Errors:** Handle network errors gracefully by implementing retry logic.\n*   **Rate Limiting:** Be aware of Stripe's rate limits and implement a backoff strategy.\n*   **Concurrency:** Handle concurrent requests carefully to avoid race conditions.\n*   **SCA (Strong Customer Authentication):**  Handle SCA requirements for European customers.\n\n### 6.3 Version-Specific Issues\n\n*   Be aware of breaking changes in new versions of the Stripe API.\n*   Test your integration thoroughly after upgrading to a new version of the Stripe API.\n*   Use Stripe's API versioning feature to maintain compatibility with older versions of the API.\n\n### 6.4 Compatibility Concerns\n\n*   Ensure that your Stripe integration is compatible with all supported browsers and devices.\n*   Test your integration on different platforms to identify compatibility issues.\n\n### 6.5 Debugging Strategies\n\n*   Use Stripe's logging features to track API requests and responses.\n*   Use a debugger to step through your code and identify errors.\n*   Use Stripe's API explorer to test API requests.\n*   Consult Stripe's documentation and support resources.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **IDE:** Visual Studio Code, IntelliJ IDEA, or similar.\n*   **Testing Framework:** Jest, Mocha, or similar.\n*   **Mocking Library:** Jest, Sinon.js, or similar.\n*   **Bundler:** Webpack, Parcel, or similar.\n*   **Linting:** ESLint, Pylint, or similar.\n*   **Formatter:** Prettier, Black, or similar.\n*   **Stripe CLI:** Stripe Command Line Interface is incredibly valuable.\n\n### 7.2 Build Configuration\n\n*   Use a build tool to automate the build process.\n*   Configure your build tool to minify and optimize your code.\n*   Use environment variables to store configuration settings.\n\n### 7.3 Linting and Formatting\n\n*   Use a linter to enforce code style and identify potential errors.\n*   Use a formatter to automatically format your code.\n*   Configure your editor to automatically lint and format your code on save.\n\n### 7.4 Deployment\n\n*   Deploy your application to a secure server.\n*   Use HTTPS to encrypt communication between your application and the server.\n*   Monitor your application for errors and performance issues.\n\n### 7.5 CI/CD Integration\n\n*   Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   Run tests automatically as part of your CI/CD pipeline.\n*   Use a deployment tool such as Docker to package and deploy your application.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.py,*.rb,*.php,*.java,*.go",
      "format": "mdc",
      "originalFile": "stripe.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "stripe",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "integrating",
      "payment",
      "processing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "stripe",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-supabase",
    "description": "Comprehensive best practices for developing with Supabase, covering code organization, performance, security, testing, and common pitfalls. This rule provides actionable guidance for developers to build robust and scalable applications using Supabase.",
    "author": "sanjeed5",
    "tags": [
      "supabase",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/supabase.mdc",
    "content": "# Supabase Best Practices: A Comprehensive Guide\n\nThis document outlines best practices for developing with Supabase, covering various aspects from code organization to security and performance.\n\n## 1. Code Organization and Structure\n\nA well-organized codebase is crucial for maintainability and scalability. Here's how to structure your Supabase project:\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a modular structure that separates concerns:\n\n\nproject-root/\n├── src/\n│   ├── components/        # Reusable UI components\n│   ├── pages/             # Page-level components (routes)\n│   ├── services/          # Supabase client initialization and data fetching\n│   │   ├── supabase.ts   # Supabase client initialization\n│   │   ├── auth.ts       # Authentication-related functions\n│   │   ├── database.ts   # Database interaction functions\n│   ├── utils/             # Utility functions (e.g., date formatting)\n│   ├── types/             # TypeScript types and interfaces\n│   ├── hooks/             # Custom React hooks\n│   ├── styles/            # Global styles and theme\n│   └── App.tsx            # Main application component\n├── migrations/        # Database migrations\n├── tests/              # Unit and integration tests\n├── .env                # Environment variables\n└── package.json          # Project dependencies\n\n\n### 1.2. File Naming Conventions\n\n*   **Components:** Use PascalCase (e.g., `UserProfile.tsx`).\n*   **Functions:** Use camelCase (e.g., `fetchUserData`).\n*   **Variables:** Use camelCase (e.g., `userName`).\n*   **Files:** Use kebab-case (e.g., `user-profile.tsx`).\n\n### 1.3. Module Organization\n\n*   Group related functionalities into modules.\n*   Use clear and descriptive module names.\n*   Export only what is necessary from each module to minimize the API surface.\n\n### 1.4. Component Architecture\n\n*   Favor small, reusable components.\n*   Use a component-based approach (e.g., React, Vue.js) to build UIs.\n*   Separate presentational components from container components to improve reusability and testability.\n\n### 1.5. Code Splitting Strategies\n\n*   Use dynamic imports to lazy-load modules.\n*   Split large components into smaller chunks.\n*   Implement route-based code splitting to load only the necessary code for each route.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Supabase\n\n*   **Repository Pattern:** Abstract database interactions behind a repository interface for better testability and maintainability.\n*   **Observer Pattern:** Utilize Supabase's real-time capabilities to implement reactive UIs.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Fetching:** Create reusable functions for fetching data from Supabase tables.\n*   **Authentication:** Use Supabase Auth for user authentication and authorization.\n*   **Real-time Updates:** Leverage Supabase Realtime for real-time data synchronization.\n*   **File Storage:** Utilize Supabase Storage for managing file uploads and downloads.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n*   **Direct Database Access from UI Components:** This tightly couples the UI to the database and makes testing difficult. Use a service layer to abstract database interactions.\n*   **Overusing Supabase Functions and Policies:** Keep business logic in your application code whenever possible to avoid vendor lock-in and improve testability.\n*   **Manually Creating Tables Without an ORM:** Always use an ORM to manage your database schema and migrations.\n*   **Ignoring Error Handling:** Implement proper error handling to prevent unexpected crashes and provide informative error messages to users.\n*   **Storing Sensitive Data in Plain Text:** Never store sensitive data like passwords or API keys in plain text. Use encryption and secure storage mechanisms.\n\n### 2.4. State Management Best Practices\n\n*   Choose a state management library (e.g., Redux, Zustand, Recoil) based on your project's complexity.\n*   Use local component state for simple UI state.\n*   Centralize application state in a global store for complex data dependencies.\n*   Use asynchronous actions to handle data fetching and updates.\n\n### 2.5. Error Handling Patterns\n\n*   Use try-catch blocks to handle exceptions.\n*   Implement a global error handler to catch unhandled exceptions.\n*   Log errors to a monitoring service for tracking and analysis.\n*   Display user-friendly error messages to the user.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Indexing:** Add indexes to frequently queried columns to improve query performance.\n*   **Query Optimization:** Use efficient SQL queries and avoid N+1 query problems.\n*   **Caching:** Implement caching strategies to reduce database load.\n*   **Connection Pooling:** Use connection pooling to reuse database connections and reduce overhead.\n\n### 3.2. Memory Management\n\n*   Avoid memory leaks by properly cleaning up resources.\n*   Use garbage collection to reclaim unused memory.\n*   Optimize data structures to reduce memory usage.\n\n### 3.3. Rendering Optimization\n\n*   Use memoization techniques to prevent unnecessary re-renders.\n*   Virtualize long lists to improve rendering performance.\n*   Optimize images and other assets to reduce file sizes.\n\n### 3.4. Bundle Size Optimization\n\n*   Use tree shaking to remove unused code.\n*   Minify code to reduce file sizes.\n*   Compress assets to reduce transfer times.\n\n### 3.5. Lazy Loading Strategies\n\n*   Lazy load images and other assets that are not immediately visible.\n*   Implement infinite scrolling to load data in chunks as the user scrolls.\n*   Use code splitting to load only the necessary code for each route.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **SQL Injection:** Prevent SQL injection by using parameterized queries and prepared statements.\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection to prevent unauthorized requests.\n*   **Authentication and Authorization Issues:** Secure your authentication and authorization mechanisms to prevent unauthorized access.\n\n### 4.2. Input Validation\n\n*   Validate all user input to prevent malicious data from entering your system.\n*   Use server-side validation in addition to client-side validation.\n*   Sanitize user input to remove potentially harmful characters.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   Use Supabase Auth for user authentication and authorization.\n*   Implement role-based access control (RBAC) to manage user permissions.\n*   Use row-level security (RLS) to control data access at the row level.\n\n### 4.4. Data Protection Strategies\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use secure storage mechanisms to store API keys and other secrets.\n*   Implement data masking to protect sensitive data from unauthorized access.\n\n### 4.5. Secure API Communication\n\n*   Use HTTPS to encrypt API traffic.\n*   Implement API rate limiting to prevent abuse.\n*   Validate API requests to prevent malicious input.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   Write unit tests for individual functions and components.\n*   Use mocking and stubbing to isolate units of code.\n*   Aim for high code coverage.\n\n### 5.2. Integration Testing\n\n*   Write integration tests to verify the interaction between different parts of your system.\n*   Test the integration between your application and Supabase.\n\n### 5.3. End-to-end Testing\n\n*   Write end-to-end tests to simulate user interactions and verify the overall functionality of your application.\n*   Use tools like Cypress or Playwright to automate end-to-end tests.\n\n### 5.4. Test Organization\n\n*   Organize tests into separate directories based on functionality.\n*   Use descriptive test names.\n*   Keep tests concise and focused.\n\n### 5.5. Mocking and Stubbing\n\n*   Use mocking to replace external dependencies with controlled substitutes.\n*   Use stubbing to replace specific method calls with predefined values.\n*   Avoid over-mocking, as it can make tests less reliable.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   Not using an ORM for database schema management.\n*   Over-relying on Supabase functions and policies for business logic.\n*   Using Supabase-only features without considering open-source alternatives.\n*   Ignoring error handling and security best practices.\n\n### 6.2. Edge Cases to Be Aware Of\n\n*   Handling large datasets efficiently.\n*   Dealing with real-time data synchronization conflicts.\n*   Managing user sessions and authentication tokens securely.\n\n### 6.3. Version-Specific Issues\n\n*   Be aware of breaking changes in Supabase and its dependencies.\n*   Test your application thoroughly after upgrading Supabase or its dependencies.\n*   Refer to the Supabase documentation for migration guides.\n\n### 6.4. Compatibility Concerns\n\n*   Ensure compatibility between your application and the Supabase client library.\n*   Test your application on different browsers and devices.\n\n### 6.5. Debugging Strategies\n\n*   Use browser developer tools to debug client-side code.\n*   Use server-side logging to track errors and performance issues.\n*   Use the Supabase dashboard to monitor database activity.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   Supabase CLI: For local development and database management.\n*   VS Code: For code editing and debugging.\n*   Drizzle ORM: For database schema management.\n*   Postman/Insomnia: For testing API endpoints.\n\n### 7.2. Build Configuration\n\n*   Use a build tool like Webpack or Parcel to bundle your code.\n*   Configure your build tool to optimize for production.\n*   Use environment variables to configure your application.\n\n### 7.3. Linting and Formatting\n\n*   Use ESLint to enforce code style and prevent errors.\n*   Use Prettier to format your code automatically.\n*   Integrate linting and formatting into your development workflow.\n\n### 7.4. Deployment Best Practices\n\n*   Use a CI/CD pipeline to automate deployments.\n*   Deploy your application to a production-ready environment.\n*   Monitor your application for errors and performance issues.\n\n### 7.5. CI/CD Integration\n\n*   Use a CI/CD tool like GitHub Actions or GitLab CI to automate your build, test, and deployment processes.\n*   Configure your CI/CD pipeline to run tests and linting before deployment.\n*   Use environment variables to configure your application in the CI/CD environment.\n\n## 8. Database Workflow Design\n\n*   **Avoid Direct Changes in Production**: Once your application is live, refrain from making database changes using the Supabase Dashboard. Instead, utilize migration tools and enforce access control to prevent unauthorized modifications.\n*   **Multiple Environments**: Adopt a multi-stage development workflow (`local -> staging -> prod`). This approach allows for thorough testing and validation at each stage before changes are deployed to production.\n*   **Point-in-Time Recovery**: As your database grows, consider moving to Point-in-Time Recovery (PITR) to minimize the impact on database performance during maintenance and ensure data safety.\n*   **Database Migrations**: Use database migration tools to manage schema changes. This practice helps maintain consistency across different environments and simplifies version control.\n*   **Access Control**: Be mindful of who has access to your production environment. Limit access to experienced team members and set clear internal workflows to mitigate risks.\n*   **Security**: Regularly review and update your security measures. Ensure that tables with sensitive data have appropriate access levels and that database secrets and API keys are stored securely.\n*   **Performance Monitoring**: Utilize Supabase's observability tooling to monitor database performance and optimize queries, indexes, and connection management.\n\n## 9. Additional Best Practices\n\n*   **Understand Shared Responsibilities:** When using Supabase, be aware of the shared responsibilities model. Supabase manages infrastructure, but you are responsible for application architecture, security, and data management.\n*   **Proper Indexing:** Essential for query optimization. Indices should be created based on common query patterns to reduce search time.\n*   **Load Testing**: Before deploying changes to production, perform load testing in a staging environment. Tools such as `k6` can simulate traffic and help identify potential bottlenecks.\n*   **Resource Upgrades**: Monitor resource usage and upgrade your database when necessary. For significant traffic surges, contact support in advance for assistance.\n*   **Database Optimization**: Regularly optimize your database by adding filters on large queries, using caching strategies, and managing connections efficiently.\n*   **Regular Backups:** Schedule regular backups of your database to protect against data loss.\n*   **Use of Postgres Features**: As Supabase is built around Postgres, understand and leverage Postgres features for performance and scalability.\n\n## 10. Conclusion\n\nBy following these best practices, you can build robust, scalable, and secure applications with Supabase. Remember to stay up-to-date with the latest Supabase documentation and community resources to continuously improve your development practices.\n\n@file ./supabase_code_examples.mdc",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.sql",
      "format": "mdc",
      "originalFile": "supabase.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "supabase",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "code",
      "organization",
      "performance",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "supabase",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-svelte",
    "description": "Comprehensive Svelte best practices covering code structure, performance, security, testing, and common pitfalls. This rule provides guidance on writing maintainable, efficient, and secure Svelte applications.",
    "author": "sanjeed5",
    "tags": [
      "svelte",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/svelte.mdc",
    "content": "- **Manipulate the DOM with HTML:** Utilize Svelte's HTML-centric approach to manipulate the DOM.\n- **Solve challenges with HTML/CSS first:** Prioritize solving problems with HTML and CSS before resorting to JavaScript.\n- **Write short components:** Aim for concise and focused components to improve readability and maintainability.\n- **Write concise reactive `$:` blocks:** Keep reactive statements short and easy to understand.\n- **Scope CSS to the actual component:** Ensure that CSS styles are scoped to the component to avoid conflicts.\n- **Avoid hard coding data or dimensions:** Use dynamic data and responsive design techniques instead of hard-coded values.\n- **Keep objects immutable:** Treat objects as immutable to prevent unexpected side effects and improve performance.\n- **Use two-way binding effectively:** Leverage two-way binding for efficient data synchronization but be mindful of its potential impact on performance for complex scenarios.\n\n## 1. Code Organization and Structure:\n\n   - **Directory Structure Best Practices:**\n      - `src/`: Contains all the application source code.\n      - `src/components/`: Holds reusable Svelte components, categorized further by feature or domain (e.g., `src/components/Button/`, `src/components/Form/`).\n      - `src/lib/`: Contains utility functions, helper modules, and reusable logic that is not specific to a component.\n      - `src/routes/`: For SvelteKit applications, this directory defines the application's routes.\n      - `src/stores/`: Stores for global state management (if using Svelte's stores).\n      - `static/`: Static assets like images, fonts, and other resources.\n   - **File Naming Conventions:**\n      - Components: Use PascalCase (e.g., `MyComponent.svelte`).\n      - Utility functions: Use camelCase (e.g., `formatDate.js`).\n      - Stores: Use descriptive names related to the data they hold (e.g., `userStore.js`).\n   - **Module Organization:**\n      - Group related components and utilities into modules within their respective directories.\n      - Use `index.js` or `index.svelte` files to export multiple components or functions from a directory, providing a cleaner import experience.\n   - **Component Architecture:**\n      - Favor a component-based architecture where UI is broken down into small, reusable components.\n      - Consider using a composition pattern where complex components are built by composing simpler ones.\n      - Separate concerns: Keep components focused on presentation logic and delegate data fetching or business logic to services or stores.\n   - **Code Splitting Strategies:**\n      - Use dynamic imports (`import()`) to load components or modules on demand, reducing the initial bundle size.\n      - Leverage SvelteKit's built-in code splitting capabilities for route-based splitting.\n      - Consider splitting large components into smaller, lazily loaded sub-components.\n\n## 2. Common Patterns and Anti-patterns:\n\n   - **Design Patterns Specific to Svelte:**\n      - **Store pattern:** Use Svelte's stores for managing application state and reactivity.\n      - **Action pattern:** Use Svelte's actions for manipulating DOM elements or integrating with third-party libraries.\n      - **Component composition:** Build complex UIs by composing smaller, reusable components.\n   - **Recommended Approaches for Common Tasks:**\n      - **Form handling:** Use Svelte's two-way binding (`bind:value`) for simple forms.  For more complex scenarios, consider libraries like Formik or Svelte Formly.\n      - **Data fetching:** Use `fetch` or libraries like Axios for fetching data from APIs.  Handle loading and error states appropriately.\n      - **Event handling:** Use Svelte's event directives (e.g., `on:click`) for handling DOM events.\n   - **Anti-patterns and Code Smells to Avoid:**\n      - **Overusing global state:** Avoid putting everything in a global store.  Use component-level state when appropriate.\n      - **Directly manipulating the DOM outside of actions:**  Rely on Svelte's reactivity system to update the DOM.\n      - **Writing overly complex components:** Break down large components into smaller, more manageable ones.\n   - **State Management Best Practices:**\n      - Use Svelte's built-in stores for managing global or application-level state.\n      - Consider using reactive declarations (`$:`) to derive state from other state variables.\n      - Keep state updates predictable and avoid modifying state directly.\n      - For complex state management needs, explore libraries like Redux or Zustand (though often unnecessary in Svelte).\n   - **Error Handling Patterns:**\n      - Use try-catch blocks to handle potential errors during data fetching or other asynchronous operations.\n      - Display user-friendly error messages in the UI.\n      - Log errors to the console or a logging service for debugging purposes.\n      - Implement global error handling to catch unhandled exceptions.\n\n## 3. Performance Considerations:\n\n   - **Optimization Techniques:**\n      - **Minimize DOM updates:** Svelte is very efficient at updating the DOM, but unnecessary updates can still impact performance.  Use reactive declarations judiciously.\n      - **Use `{#each}` blocks efficiently:** Key your `{#each}` blocks with unique identifiers to help Svelte efficiently update the list.\n      - **Avoid unnecessary component re-renders:** Use the `$:` syntax effectively to only update components when necessary.\n   - **Memory Management:**\n      - Avoid memory leaks by properly cleaning up event listeners and subscriptions when components are destroyed (using `onDestroy`).\n      - Be mindful of large data structures in stores, and consider using techniques like pagination or virtualization to manage them efficiently.\n   - **Rendering Optimization:**\n      - Use the `svelte:options` tag with the `immutable` option for components that receive immutable data as props.\n      - Use `shouldUpdate` to prevent rendering for unchanged immutable props.\n   - **Bundle Size Optimization:**\n      - Use production builds with minification and tree shaking to remove unused code.\n      - Use dynamic imports for code splitting.\n      - Optimize images and other assets.\n   - **Lazy Loading Strategies:**\n      - Use dynamic imports to lazy load components or modules that are not immediately needed.\n      - Implement lazy loading for images or other resources that are below the fold.\n\n## 4. Security Best Practices:\n\n   - **Common Vulnerabilities and How to Prevent Them:**\n      - **Cross-Site Scripting (XSS):** Sanitize user input before displaying it in the UI.  Svelte automatically escapes HTML entities, but be careful when using `@html` or `{@debug}`.\n      - **Cross-Site Request Forgery (CSRF):** Use CSRF tokens to protect against CSRF attacks.\n      - **SQL Injection:** If interacting with a database, use parameterized queries to prevent SQL injection attacks.\n   - **Input Validation:**\n      - Validate user input on both the client-side and server-side.\n      - Use appropriate data types and validation rules to prevent invalid data from being processed.\n   - **Authentication and Authorization Patterns:**\n      - Use secure authentication mechanisms like OAuth or JWT.\n      - Implement proper authorization checks to ensure that users only have access to the resources they are allowed to access.\n   - **Data Protection Strategies:**\n      - Encrypt sensitive data at rest and in transit.\n      - Use secure storage mechanisms for storing sensitive data.\n   - **Secure API Communication:**\n      - Use HTTPS for all API communication.\n      - Validate API responses to ensure that they are valid and not malicious.\n\n## 5. Testing Approaches:\n\n   - **Unit Testing Strategies:**\n      - Use a testing framework like Jest or Mocha to write unit tests for individual components and utility functions.\n      - Mock external dependencies to isolate the code being tested.\n   - **Integration Testing:**\n      - Use a testing framework like Cypress or Playwright to write integration tests that verify the interaction between different components or modules.\n      - Test the integration with APIs and other external services.\n   - **End-to-End Testing:**\n      - Use a testing framework like Cypress or Playwright to write end-to-end tests that simulate user interactions with the application.\n      - Test the entire application flow from start to finish.\n   - **Test Organization:**\n      - Organize tests into directories that mirror the application's directory structure.\n      - Use descriptive names for test files and test cases.\n   - **Mocking and Stubbing:**\n      - Use mocking libraries like Jest's `jest.fn()` or Sinon.js to mock external dependencies.\n      - Use stubbing to replace complex or slow dependencies with simpler implementations for testing purposes.\n\n## 6. Common Pitfalls and Gotchas:\n\n   - **Frequent Mistakes Developers Make:**\n      - **Incorrect reactivity usage:**  Failing to understand how Svelte's reactivity system works can lead to unexpected behavior.\n      - **Over-reliance on `$: `:** Although reactive declarations are powerful, overusing them can make code harder to read and debug. Consider if a regular variable or function would be more appropriate.\n      - **Mutating props directly:**  Modifying props directly inside a component can lead to unexpected side effects.\n   - **Edge Cases to Be Aware Of:**\n      - **Transition and animation behavior:**  Understanding how transitions and animations interact with component updates is important for creating smooth user experiences.\n      - **Server-side rendering (SSR) considerations:**  When using SvelteKit, be aware of the differences between client-side and server-side execution environments.\n   - **Version-Specific Issues:**\n      - Consult the Svelte changelog and migration guides when upgrading to a new version to avoid compatibility issues.\n   - **Compatibility Concerns:**\n      - Ensure that your code is compatible with the target browsers and devices.\n      - Use polyfills or transpilers to support older browsers if necessary.\n   - **Debugging Strategies:**\n      - Use the Svelte Devtools browser extension for inspecting component state and reactivity.\n      - Use `console.log` or the `debugger` statement to debug code execution.\n      - Use SvelteKit's built-in error handling and logging features.\n\n## 7. Tooling and Environment:\n\n   - **Recommended Development Tools:**\n      - **VS Code with the Svelte extension:** Provides syntax highlighting, code completion, and other useful features.\n      - **Svelte Devtools:** A browser extension for inspecting Svelte component state and reactivity.\n      - **ESLint and Prettier:** For linting and formatting code.\n   - **Build Configuration:**\n      - Use a build tool like Vite or Rollup to bundle your Svelte code for production.\n      - Configure the build tool to perform optimizations like minification and tree shaking.\n   - **Linting and Formatting:**\n      - Use ESLint with the `eslint-plugin-svelte3` plugin to lint your Svelte code.\n      - Use Prettier with the `prettier-plugin-svelte` plugin to format your Svelte code.\n   - **Deployment Best Practices:**\n      - Deploy your Svelte application to a CDN or a serverless platform like Netlify or Vercel.\n      - Configure your server to serve the application's static assets with proper caching headers.\n   - **CI/CD Integration:**\n      - Use a CI/CD platform like GitHub Actions or GitLab CI to automate the build, testing, and deployment process.\n      - Run tests and linting checks on every commit to ensure code quality.",
    "metadata": {
      "globs": "*.svelte",
      "format": "mdc",
      "originalFile": "svelte.mdc"
    },
    "subcategory": "svelte",
    "keywords": [
      "cursor",
      "svelte",
      "comprehensive",
      "best",
      "practices",
      "covering",
      "code",
      "structure",
      "performance",
      "security",
      "testing",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "frontend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "svelte",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-sveltekit",
    "description": "This rule provides comprehensive best practices and coding standards for SvelteKit development, covering code structure, performance, security, testing, and common pitfalls. It aims to improve code quality, maintainability, and overall project health.",
    "author": "sanjeed5",
    "tags": [
      "sveltekit",
      "svelte",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/sveltekit.mdc",
    "content": "# SvelteKit Best Practices\n\nThis guide provides comprehensive best practices for developing SvelteKit applications. It covers various aspects, including code organization, performance considerations, security measures, and common pitfalls to avoid.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\n*   **`src/lib`**: Reusable components, utilities, and stores. Organize by feature or domain.\n*   **`src/routes`**: Defines the application's routes. Each directory represents a route segment.\n*   **`src/routes/+page.svelte`**: Represents a page component for a route.\n*   **`src/routes/+layout.svelte`**: Layout component that wraps the page. Useful for consistent UI elements.\n*   **`src/routes/+page.server.ts`**: Server-side code for handling data fetching and form submissions for a page.\n*   **`src/routes/+layout.server.ts`**: Server-side code for layout data, loaded before any +page.server.ts data.\n*   **`src/hooks.server.ts`**: Handle server-side requests and responses.  Useful for authentication and session management.\n*   **`static`**: Static assets like images, fonts, and other files served directly.\n*   **`tests`**: Directory for all tests, mirroring the source structure for clarity.\n\nExample:\n\n\nsrc/\n├── lib/\n│   ├── components/\n│   │   ├── Button.svelte\n│   │   └── Card.svelte\n│   ├── utils/\n│   │   ├── api.ts\n│   │   └── helpers.ts\n│   └── stores/\n│       └── user.ts\n├── routes/\n│   ├── +\n│   │   └── page.svelte\n│   ├── about/\n│   │   ├── +\n│   │   │   └── page.svelte\n│   │   └── +page.server.ts\n│   └── blog/\n│       ├── [slug]/\n│       │   ├── +\n│       │   │   └── page.svelte\n│       │   └── +page.server.ts\n│       └── +\n│           └── page.svelte\n├── hooks.server.ts\n└── app.d.ts\n\n\n### 1.2. File Naming Conventions\n\n*   **Components**: PascalCase (e.g., `MyComponent.svelte`).\n*   **Utility functions**: camelCase (e.g., `formatDate.ts`).\n*   **Stores**: camelCase (e.g., `userStore.ts`).\n*   **Route files**: Follow SvelteKit's routing conventions (`+page.svelte`, `+layout.svelte`, etc.).\n\n### 1.3. Module Organization\n\n*   Group related functionality into modules.\n*   Use `src/lib` for reusable modules.\n*   Employ clear and descriptive module names.\n*   Leverage SvelteKit's `$lib` alias for importing modules from `src/lib`.\n\n### 1.4. Component Architecture\n\n*   **Atomic Design**: Break down UI into small, reusable components (atoms, molecules, organisms, templates, pages).\n*   **Component Composition**: Compose complex UIs from simpler components.\n*   **Props and Events**: Use props for data input and events for component output.\n*   **Slots**: Allow parent components to inject content into child components.\n\n### 1.5. Code Splitting Strategies\n\n*   **Dynamic Imports**: Use dynamic imports (`import()`) to load modules on demand.\n*   **Route-Based Splitting**: SvelteKit automatically splits code based on routes.\n*   **Component-Level Splitting**: Split large components into smaller chunks that can be loaded independently.\n*   **Lazy Loading**: Load non-critical components or modules only when needed.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to SvelteKit\n\n*   **Form Actions**: Use SvelteKit's form actions for handling form submissions on the server.\n*   **Load Functions**: Utilize `load` functions in `+page.server.ts` and `+layout.server.ts` for data fetching.\n*   **Stores for State Management**: Employ Svelte stores for managing application state.\n*   **Server-Side Rendering (SSR)**: Leverage SSR for improved SEO and initial load performance.\n*   **Progressive Enhancement**: Design applications to work even with JavaScript disabled.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Data Fetching**: Use `fetch` API or libraries like `axios` within `load` functions.\n*   **Form Handling**: Use SvelteKit's form actions for server-side validation and processing.\n*   **Authentication**: Implement authentication using libraries like `lucia-auth` or integrate with OAuth providers.\n*   **Authorization**: Implement role-based access control using stores or server-side checks.\n*   **Error Handling**: Use `try...catch` blocks and SvelteKit's `handleError` hook for global error handling.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n*   **Over-reliance on Global State**: Avoid using global stores for component-specific state.\n*   **Direct DOM Manipulation**: Avoid directly manipulating the DOM; use Svelte's reactivity system instead.\n*   **Large, Unmaintainable Components**: Break down large components into smaller, reusable ones.\n*   **Ignoring Accessibility**: Ensure components are accessible to users with disabilities (ARIA attributes, semantic HTML).\n*   **Unnecessary Re-renders**: Optimize components to avoid unnecessary re-renders.\n\n### 2.4. State Management Best Practices\n\n*   **Use Svelte Stores**: Svelte stores are the recommended way to manage application state.\n*   **Divide stores according to feature**: Split stores based on logical domain or feature (e.g. UserStore, CartStore).\n*   **Readable and Writable Stores**: Use readable stores for derived state and writable stores for mutable state.\n*   **Custom Stores**: Create custom stores for complex state management logic.\n\n### 2.5. Error Handling Patterns\n\n*   **`try...catch` Blocks**: Use `try...catch` blocks to handle errors within components and functions.\n*   **`handleError` Hook**: Implement the `handleError` hook in `src/hooks.server.ts` for global error handling.\n*   **Error Boundaries**: Use error boundaries to catch errors in component trees and display fallback UI.\n*   **Logging**: Log errors to a server for monitoring and debugging.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Lazy Loading**: Load non-critical resources (images, components) only when needed.\n*   **Code Splitting**: Split code into smaller chunks to reduce initial load time.\n*   **Image Optimization**: Optimize images using tools like `squoosh` or `tinypng`.\n*   **Server-Side Rendering (SSR)**: Use SSR for improved initial load performance and SEO.\n*   **Caching**: Implement caching strategies for data and assets.\n*   **Preload critical assets**: use `<link rel='preload'>` to fetch critical assets earlier\n\n### 3.2. Memory Management\n\n*   **Avoid Memory Leaks**: Properly clean up resources when components unmount.\n*   **Use WeakRefs**: Use `WeakRefs` for managing objects that might be garbage collected.\n*   **Minimize Object Creation**: Avoid creating unnecessary objects and arrays.\n*   **Properly unsubscrive from stores:** Properly unsubscribe to avoid re-renders when the component is unmounted.\n\n### 3.3. Rendering Optimization\n\n*   **Tracked values**: Use the `$:` syntax to track dependencies of reactive statements.\n*   **Svelte Compiler**: Utilize Svelte's compiler to optimize component rendering.\n*   **Virtual DOM**: Svelte doesn't use a virtual DOM, so updates are generally very efficient.\n*   **Avoid Unnecessary Re-renders**: Use `{#each}` blocks with keys to optimize list rendering.\n*   **Debouncing and Throttling**: Use debouncing and throttling to limit the frequency of updates.\n\n### 3.4. Bundle Size Optimization\n\n*   **Tree Shaking**: Ensure unused code is removed during the build process.\n*   **Minification**: Minify JavaScript and CSS files to reduce bundle size.\n*   **Compression**: Compress assets using gzip or Brotli.\n*   **Dependency Analysis**: Analyze dependencies to identify and remove unused libraries.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Intersection Observer**: Use the Intersection Observer API to detect when elements are visible and load them lazily.\n*   **Dynamic Imports**: Use dynamic imports to load components and modules on demand.\n*   **Placeholder UI**: Display a placeholder UI while resources are loading.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS)**: Sanitize user input to prevent XSS attacks.\n*   **Cross-Site Request Forgery (CSRF)**: Use CSRF tokens to protect against CSRF attacks.\n*   **SQL Injection**: Use parameterized queries or ORMs to prevent SQL injection.\n*   **Authentication and Authorization**: Implement secure authentication and authorization mechanisms.\n*   **Insecure Direct Object References (IDOR)**: Implement proper access controls to prevent unauthorized access to resources.\n\n### 4.2. Input Validation\n\n*   **Server-Side Validation**: Always validate user input on the server.\n*   **Client-Side Validation**: Use client-side validation for immediate feedback, but never rely on it solely.\n*   **Escape User Input**: Escape user input before rendering it in the DOM.\n*   **Use Validation Libraries**: Use libraries like `zod` or `yup` for input validation.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **JWT (JSON Web Tokens)**: Use JWTs for authentication and authorization.\n*   **OAuth 2.0**: Integrate with OAuth providers like Google and Facebook for social login.\n*   **Role-Based Access Control (RBAC)**: Implement RBAC to control access to resources based on user roles.\n*   **Multi-Factor Authentication (MFA)**: Implement MFA for enhanced security.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption**: Encrypt sensitive data at rest and in transit.\n*   **Hashing**: Hash passwords using strong hashing algorithms like bcrypt or Argon2.\n*   **Data Masking**: Mask sensitive data in logs and reports.\n*   **Regular Security Audits**: Conduct regular security audits to identify and address vulnerabilities.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS**: Use HTTPS for all API communication.\n*   **API Keys**: Protect API keys and secrets.\n*   **Rate Limiting**: Implement rate limiting to prevent abuse.\n*   **Input Validation**: Always validate input to your APIs.\n*   **Output Encoding**: Always encode output from your API to prevent injection attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Test Individual Components**: Write unit tests for individual components in isolation.\n*   **Test Utility Functions**: Write unit tests for utility functions and modules.\n*   **Use Mock Data**: Use mock data for testing components and functions.\n*   **Test Edge Cases**: Test edge cases and error conditions.\n*   **Utilize Svelte Testing Library**: Employ `svelte-testing-library` for testing Svelte components.\n\n### 5.2. Integration Testing\n\n*   **Test Component Interactions**: Write integration tests to ensure components interact correctly.\n*   **Test Data Flow**: Test the flow of data between components and modules.\n*   **Test API Integrations**: Test integrations with APIs and external services.\n\n### 5.3. End-to-End Testing\n\n*   **Simulate User Interactions**: Write end-to-end tests to simulate user interactions.\n*   **Test Full Workflows**: Test complete user workflows from start to finish.\n*   **Use Playwright or Cypress**: Use tools like Playwright or Cypress for end-to-end testing.\n\n### 5.4. Test Organization\n\n*   **Mirror Source Structure**: Organize tests in a directory structure that mirrors the source code.\n*   **Use Descriptive Names**: Use descriptive names for test files and functions.\n*   **Separate Test Environments**: Use separate test environments for unit, integration, and end-to-end tests.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock API Calls**: Mock API calls to isolate components during testing.\n*   **Stub External Dependencies**: Stub external dependencies to control their behavior.\n*   **Use Mocking Libraries**: Use libraries like `jest.mock` or `sinon` for mocking and stubbing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   **Incorrectly Using Reactive Statements**: Not understanding how Svelte's reactivity system works.\n*   **Ignoring Accessibility**: Neglecting accessibility considerations when building components.\n*   **Over-complicating State Management**: Using complex state management solutions when simpler ones would suffice.\n*   **Not Handling Errors Properly**: Ignoring errors or not providing informative error messages.\n*   **Premature Optimization**: Optimizing code before it is necessary.\n\n### 6.2. Edge Cases to Be Aware Of\n\n*   **Server-Side Rendering Differences**: Be aware of differences between server-side and client-side rendering.\n*   **Browser Compatibility**: Test applications in different browsers to ensure compatibility.\n*   **Network Latency**: Design applications to handle network latency and unreliable connections.\n*   **Memory Constraints**: Consider memory constraints when building large applications.\n\n### 6.3. Version-Specific Issues\n\n*   **Breaking Changes**: Be aware of breaking changes in new versions of SvelteKit.\n*   **Deprecated Features**: Avoid using deprecated features.\n*   **Upgrade Guides**: Follow upgrade guides when migrating to new versions of SvelteKit.\n\n### 6.4. Compatibility Concerns\n\n*   **Third-Party Libraries**: Ensure third-party libraries are compatible with SvelteKit.\n*   **Browser Support**: Check browser support for new features and APIs.\n*   **Node.js Version**: Ensure the Node.js version is compatible with SvelteKit.\n\n### 6.5. Debugging Strategies\n\n*   **Browser Developer Tools**: Use browser developer tools for debugging JavaScript and CSS.\n*   **Svelte Devtools**: Use the Svelte Devtools extension for inspecting Svelte components.\n*   **Logging**: Use `console.log` statements for debugging.\n*   **Debuggers**: Use debuggers like VS Code's debugger for step-by-step debugging.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **VS Code**: VS Code is a popular code editor with excellent Svelte and TypeScript support.\n*   **Svelte Devtools**: The Svelte Devtools browser extension allows you to inspect Svelte components.\n*   **ESLint**: ESLint is a linter that helps enforce code style and best practices.\n*   **Prettier**: Prettier is a code formatter that automatically formats code to a consistent style.\n*   **TypeScript**: Using typescript is recommended for type safety.\n\n### 7.2. Build Configuration\n\n*   **`svelte.config.js`**: Configure SvelteKit using the `svelte.config.js` file.\n*   **Vite**: SvelteKit uses Vite as its build tool.\n*   **Environment Variables**: Use environment variables for configuration settings.\n*   **Adapters**: Use adapters to deploy SvelteKit applications to different environments.\n\n### 7.3. Linting and Formatting\n\n*   **ESLint**: Configure ESLint to enforce code style and best practices.\n*   **Prettier**: Configure Prettier to automatically format code.\n*   **Husky**: Use Husky to run linters and formatters before committing code.\n*   **Lint Staged**: Use lint-staged to run linters and formatters only on staged files.\n\n### 7.4. Deployment Best Practices\n\n*   **Choose an Adapter**: Use an adapter like `@sveltejs/adapter-node` or `@sveltejs/adapter-static` to deploy the application.\n*   **Configure Environment Variables**: Configure environment variables for production environments.\n*   **Set Up HTTPS**: Set up HTTPS for secure communication.\n*   **Monitor the Application**: Monitor the application for errors and performance issues.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD Pipeline**: Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Automated Tests**: Run automated tests in the CI/CD pipeline.\n*   **Automated Deployments**: Automate deployments to production environments.\n*   **Use tools like GitHub Actions, GitLab CI, or CircleCI**",
    "metadata": {
      "globs": "*.svelte",
      "format": "mdc",
      "originalFile": "sveltekit.mdc"
    },
    "subcategory": "svelte",
    "keywords": [
      "cursor",
      "sveltekit",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "development",
      "svelte",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "frontend-frameworks"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "sveltekit",
        "svelte",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-tailwind",
    "description": "Comprehensive guide for Tailwind CSS best practices, covering code organization, performance optimization, security considerations, and common pitfalls. This rule provides actionable guidance for developers to build scalable and maintainable Tailwind CSS projects.",
    "author": "sanjeed5",
    "tags": [
      "tailwind",
      "css",
      "frontend",
      "styling",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tailwind.mdc",
    "content": "- Leverage Tailwind's PurgeCSS to remove unused styles in production. Configure `purge` in `tailwind.config.js` to specify files to scan for Tailwind classes.  Example:\n  javascript\n  module.exports = {\n    purge: ['./src/*.js,*.jsx,*.ts,*.tsx', './public/index.html'],\n    darkMode: false, // or 'media' or 'class'\n    theme: {\n      extend: {},\n    },\n    variants: {\n      extend: {},\n    },\n    plugins: [],\n  }\n  \n- Use Tailwind's Configuration File (`tailwind.config.js`) to customize the theme, colors, spacing, breakpoints, and other design tokens.  This promotes consistency and maintainability across the project.  Avoid hardcoding values directly in the HTML or components.\n- Adopt a Mobile-First Approach: Design for smaller screens first and then use Tailwind's responsive modifiers (e.g., `md:`, `lg:`) to adapt the layout and styles for larger screens.  This improves the user experience on mobile devices and reduces the amount of CSS needed.\n- Utilize Tailwind UI or other component libraries built with Tailwind CSS to accelerate development and maintain a consistent design language.  Customize the components as needed to fit the specific requirements of the project.  Alternatively, create your own reusable components.\n- Optimize for Performance:  Be mindful of the number of Tailwind classes used on each element.  Consider using `@apply` in CSS or extracting common styles into custom CSS classes to reduce duplication and improve performance. Use `content` variants when needed instead of the `DEFAULT` to control when generated classes are added.  For instance, use `content-[url(..)]` instead of `content-[url(..)]`. Configure the JIT mode for faster build times during development.\n- Stay Organized with Components: Break down the UI into smaller, reusable components.  Use a consistent naming convention for components and Tailwind classes.  Consider using a component library like Storybook to document and showcase the components.\n- Integrate with a Design System: Define a clear design system with consistent colors, typography, and spacing.  Map the design system tokens to Tailwind's configuration file.  This ensures that the UI is consistent and aligned with the brand guidelines.\n- Use semantic class names: While Tailwind promotes utility-first CSS, consider using semantic class names in conjunction with Tailwind classes to improve readability and maintainability. For example, instead of `<button class=\"bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded\">`, you could use `<button class=\"primary-button\">` and define the corresponding styles in your CSS file using `@apply`. This allows you to update the button styles in one place without having to modify the HTML.\n- Create Custom Utilities: Extend Tailwind's functionality by creating custom utilities for frequently used CSS patterns. Add these utilities to `tailwind.config.js` under the `extend.utilities` section. This will allow you to apply these patterns with a single class name.\n- Use the Theme Function:  Leverage the `theme()` function in your CSS or JavaScript files to access values defined in `tailwind.config.js`. This ensures that you are using consistent values throughout your project and that changes to the theme are reflected everywhere.\n- Avoid Inline Styles: Refrain from using inline styles as much as possible. Tailwind provides a comprehensive set of utility classes, so most styling needs can be met without resorting to inline styles. Inline styles can make it harder to maintain and update the styles in your project.\n- Use Layer Directives: Use `@layer` directives in your CSS to organize your styles and ensure that Tailwind's base styles are applied correctly. This can help prevent conflicts between your custom styles and Tailwind's default styles.\n- Be Careful with Arbitrary Values: While Tailwind allows you to use arbitrary values with square bracket notation (e.g., `w-[23px]`), use this feature sparingly. Overuse of arbitrary values can make your code less readable and harder to maintain. Prefer using values defined in your `tailwind.config.js` file whenever possible.\n- Utilize Variants Effectively: Understand and use Tailwind's variants (e.g., `hover:`, `focus:`, `active:`) to create interactive and dynamic styles. Customize the variants in `tailwind.config.js` to match the specific needs of your project.\n- Code Organization and Structure:\n  - Directory structure: Organize your Tailwind CSS files into a logical directory structure. Common approaches include:\n    - `src/css/`: Contains `tailwind.css` (input file) and other custom CSS files.\n    - `src/components/`: Contains reusable UI components.\n    - `src/layout/`: Contains layout components (e.g., header, footer, navigation).\n  - File naming conventions: Use descriptive and consistent file names. For example:\n    - `button.css`: Styles for a button component.\n    - `header.js`: JavaScript file for a header component.\n  - Module organization: Break down your CSS into smaller, manageable modules. Use `@import` in your `tailwind.css` file to import these modules. This improves code organization and maintainability.\n  - Component architecture: Design your UI with a component-based architecture. Each component should have its own CSS file that defines the styles for that component.\n  - Code splitting strategies: Consider using code splitting to reduce the initial load time of your application. This can be achieved by splitting your CSS into smaller chunks and loading them on demand.\n- Common Patterns and Anti-patterns:\n  - Design patterns: \n    - Atomic CSS: Tailwind promotes the atomic CSS approach, where styles are applied using small, single-purpose utility classes.\n    - Utility-first CSS: Prioritize using utility classes over custom CSS classes.\n    - Component-based styling: Encapsulate styles within components.\n  - Recommended approaches: \n    - Use a consistent naming convention for your components and CSS classes.\n    - Document your components and styles.\n    - Test your components and styles.\n  - Anti-patterns: \n    - Overusing custom CSS classes: Try to use Tailwind's utility classes as much as possible.\n    - Hardcoding values: Use the theme configuration instead of hardcoding values.\n    - Not using PurgeCSS: This can lead to a large CSS file in production.\n  - State management: Use a state management library like Redux or Zustand to manage the state of your application. Apply tailwind classes based on state changes.\n  - Error handling: Implement proper error handling to catch and handle errors gracefully.\n- Performance Considerations:\n  - Optimization techniques: \n    - Use PurgeCSS to remove unused styles.\n    - Enable JIT mode.\n    - Optimize images.\n  - Memory management: Be mindful of memory usage, especially when dealing with large datasets or complex UIs.\n  - Rendering optimization: Use techniques like virtualization and memoization to optimize rendering performance.\n  - Bundle size optimization: Reduce the size of your CSS and JavaScript bundles.\n  - Lazy loading: Load resources on demand to improve initial load time.\n- Security Best Practices:\n  - Common vulnerabilities: \n    - Cross-site scripting (XSS)\n    - Cross-site request forgery (CSRF)\n    - Injection attacks\n  - Input validation: Validate all user input to prevent malicious data from being injected into your application.\n  - Authentication and authorization: Implement proper authentication and authorization mechanisms to protect your application from unauthorized access.\n  - Data protection: Protect sensitive data by encrypting it and storing it securely.\n  - Secure API communication: Use HTTPS to encrypt communication between your application and the server.\n- Testing Approaches:\n  - Unit testing: Test individual components and functions in isolation.\n  - Integration testing: Test the interaction between different components and modules.\n  - End-to-end testing: Test the entire application from start to finish.\n  - Test organization: Organize your tests into a logical directory structure.\n  - Mocking and stubbing: Use mocking and stubbing to isolate your tests and avoid dependencies on external resources.\n- Common Pitfalls and Gotchas:\n  - Frequent mistakes: \n    - Not configuring PurgeCSS properly.\n    - Overriding Tailwind's styles without understanding the consequences.\n    - Using arbitrary values excessively.\n  - Edge cases: \n    - Handling different screen sizes and devices.\n    - Dealing with complex layouts and interactions.\n    - Supporting older browsers.\n  - Version-specific issues: Be aware of any version-specific issues and compatibility concerns.\n  - Debugging strategies: Use browser developer tools to inspect the CSS and debug any issues.\n- Tooling and Environment:\n  - Recommended tools: \n    - Visual Studio Code with the Tailwind CSS IntelliSense extension.\n    - PostCSS with the autoprefixer plugin.\n    - ESLint with the eslint-plugin-tailwindcss plugin.\n  - Build configuration: Configure your build process to use PurgeCSS and optimize your CSS.\n  - Linting and formatting: Use a linter and formatter to enforce code style and catch errors.\n  - Deployment: Deploy your application to a production environment that is optimized for performance and security.\n  - CI/CD: Integrate your application with a CI/CD pipeline to automate the build, test, and deployment process.",
    "metadata": {
      "globs": "*.html,*.js,*.jsx,*.ts,*.tsx,*.vue",
      "format": "mdc",
      "originalFile": "tailwind.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "tailwind",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "optimization",
      "css",
      "frontend",
      "styling",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tailwind",
        "css",
        "frontend",
        "styling",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-tauri",
    "description": "This rule provides comprehensive guidelines for developing robust, secure, and performant Tauri applications. It covers code organization, security best practices, performance optimization, testing strategies, and common pitfalls to avoid.",
    "author": "sanjeed5",
    "tags": [
      "tauri",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tauri.mdc",
    "content": "# Tauri Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing Tauri applications. Following these guidelines will help you create maintainable, secure, and performant applications.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\nAdopt a clear and consistent directory structure to improve maintainability and collaboration.\n\n\nmy-tauri-app/\n├── .cargo/              # Cargo configuration\n├── .git/                # Git repository\n├── .gitignore           # Git ignore file\n├── .rustfmt.toml       # Rust code formatting configuration\n├── src-tauri/           # Rust backend source code\n│   ├── src/              # Rust source files\n│   │   ├── main.rs        # Main application entry point\n│   │   ├── commands.rs    # Custom commands\n│   │   ├── models.rs      # Data models\n│   │   ├── utils.rs       # Utility functions\n│   │   └── state.rs       # Application State management\n│   ├── Cargo.toml         # Rust project configuration\n│   ├── tauri.conf.json    # Tauri application configuration\n│   └── icons/             # Application icons\n├── src/                 # Web frontend source code\n│   ├── components/        # Reusable UI components\n│   │   ├── MyComponent.jsx # Example React component\n│   │   └── ...\n│   ├── pages/             # Application pages/routes\n│   │   ├── Home.jsx       # Home page component\n│   │   └── ...\n│   ├── App.jsx            # Main application component\n│   ├── index.css          # Global styles\n│   ├── index.js           # Entry point for web app\n│   ├── assets/            # Static assets (images, fonts, etc.)\n│   │   ├── logo.png       # Application logo\n│   │   └── ...\n│   └── utils/             # Frontend utility functions\n├── static/              # Static resources (images, fonts, etc.) served directly\n├── README.md            # Project documentation\n├── LICENSE              # License file\n└── package.json         # Node.js project configuration\n\n\n### 1.2 File Naming Conventions\n\n-   **Rust files:** Use snake_case for file names (e.g., `my_module.rs`).\n-   **JavaScript/TypeScript files:** Use PascalCase for component files (e.g., `MyComponent.jsx`) and camelCase for other files (e.g., `utils.js`).\n-   **CSS files:** Use kebab-case (e.g., `main-styles.css`).\n-   **HTML files:** Use kebab-case (e.g., `index.html`).\n\n### 1.3 Module Organization\n\n-   Group related functionality into modules.\n-   Use the `mod` keyword in Rust to define modules.\n-   Create separate files for each module.\n-   Use `pub` keyword to export items from modules.\n\nrust\n// src-tauri/src/commands.rs\n\npub mod my_command {\n  use tauri::{{command, State}};\n\n  #[command]\n  pub fn greet(name: String) -> String {\n    format!(\"Hello, {{}}! You've been greeted from Rust!\", name)\n  }\n}\n\n\n\n### 1.4 Component Architecture\n\n-   Adopt a component-based architecture for the frontend (e.g., using React, Vue, or Svelte).\n-   Break down the UI into reusable components.\n-   Follow a consistent component structure (e.g., separate files for component logic, styles, and tests).\n\n### 1.5 Code Splitting Strategies\n\n-   Implement code splitting to reduce the initial bundle size.\n-   Use dynamic imports for lazy-loading modules and components.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Tauri\n\n-   **Command Pattern:** Use Tauri commands to expose Rust functions to the frontend. This allows you to perform complex operations in Rust and communicate the results to the frontend.\n-   **State Management:** Use a state management solution (e.g., Redux, Zustand, or React Context) to manage application state and ensure data consistency between the frontend and backend.  Also use Tauri's `State` to manage state on the Rust side.\n-   **Event System:**  Use Tauri's event system for inter-process communication (IPC). The backend can emit events that the frontend listens for, enabling real-time updates and notifications.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n-   **File System Access:** Use the Tauri API for file system access instead of directly using Node.js APIs. This ensures that your application respects the Tauri security model.\n-   **External API Calls:** Perform external API calls in the Rust backend to protect API keys and sensitive data.\n-   **Data Persistence:** Use a database or local storage for persistent data storage. Consider using an ORM like Diesel or SQLx for database access in Rust.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n-   **Over-reliance on JavaScript:** Offload complex logic to the Rust backend whenever possible to leverage Rust's performance and security features.\n-   **Ignoring Security Policies:**  Always configure and enforce strict Content Security Policies (CSPs) to prevent XSS attacks.\n-   **Exposing Sensitive Data:** Avoid exposing sensitive data (e.g., API keys, database credentials) in the frontend code.\n-   **Blocking the Main Thread:**  Avoid long-running tasks on the main thread, both in Rust and JavaScript, to prevent the UI from freezing.\n\n### 2.4 State Management Best Practices\n\n-   Choose a state management solution that fits your application's complexity.\n-   Use immutable data structures to prevent accidental state mutations.\n-   Centralize state management logic to improve maintainability.\n-   Use Tauri's State management features to manage complex application states on the Rust side.\n\n### 2.5 Error Handling Patterns\n\n-   Use Rust's `Result` type for error handling in the backend.\n-   Provide informative error messages to the frontend.\n-   Implement global error handling to catch unhandled exceptions.\n-   Use appropriate logging to track errors and debug issues.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n-   **Profiling:** Use profiling tools (e.g., Chrome DevTools, Rust's `perf` tool) to identify performance bottlenecks.\n-   **Code Optimization:** Optimize Rust code for performance by using efficient algorithms, data structures, and memory management techniques.\n-   **Webview Optimization:** Optimize frontend code for webview performance by reducing DOM manipulations, minimizing JavaScript execution time, and optimizing CSS styles.\n\n### 3.2 Memory Management\n\n-   Use Rust's ownership and borrowing system to prevent memory leaks and data races.\n-   Avoid unnecessary allocations and deallocations.\n-   Use smart pointers (e.g., `Box`, `Rc`, `Arc`) to manage memory ownership.\n\n### 3.3 Rendering Optimization\n\n-   Use virtual DOM techniques to minimize DOM updates.\n-   Optimize CSS selectors to improve rendering performance.\n-   Use hardware acceleration for animations and transitions.\n\n### 3.4 Bundle Size Optimization\n\n-   Use code splitting to reduce the initial bundle size.\n-   Remove unused code and dependencies.\n-   Optimize images and other assets.\n-   Use a bundler (e.g., Webpack, Parcel, or Rollup) to optimize the bundle.\n\n### 3.5 Lazy Loading Strategies\n\n-   Use dynamic imports to lazy-load modules and components.\n-   Load images and other assets only when they are visible.\n-   Use a virtualized list to render large lists of data.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n-   **Cross-Site Scripting (XSS):** Prevent XSS attacks by enforcing strict Content Security Policies (CSPs) and sanitizing user inputs.\n-   **Remote Code Execution (RCE):** Prevent RCE attacks by avoiding the use of `eval()` and other unsafe JavaScript functions. Isolate the webview context.\n-   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or an ORM.\n-   **Path Traversal:** Prevent path traversal attacks by validating user-provided file paths and using the Tauri API for file system access.\n-   **Dependency Vulnerabilities:** Regularly update dependencies and use tools like `cargo audit` and `npm audit` to identify and fix vulnerabilities.\n\n### 4.2 Input Validation\n\n-   Validate all user inputs on both the frontend and backend.\n-   Use appropriate data types and formats.\n-   Sanitize inputs to remove potentially malicious characters.\n-   Implement rate limiting to prevent brute-force attacks.\n\n### 4.3 Authentication and Authorization Patterns\n\n-   Use a secure authentication protocol (e.g., OAuth 2.0, JWT).\n-   Store passwords securely using a strong hashing algorithm (e.g., bcrypt).\n-   Implement authorization checks to ensure that users only have access to the resources they are authorized to access.\n\n### 4.4 Data Protection Strategies\n\n-   Encrypt sensitive data at rest and in transit.\n-   Use HTTPS for all network communication.\n-   Store API keys and other secrets securely using environment variables or a dedicated secrets management solution.\n-   Avoid storing sensitive data in the frontend code or in local storage.\n\n### 4.5 Secure API Communication\n\n-   Use the Tauri command pattern for secure communication between the frontend and backend.\n-   Validate all data exchanged between the frontend and backend.\n-   Implement rate limiting to prevent abuse.\n-   Use a secure communication protocol (e.g., TLS) for external API calls.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n-   Write unit tests for all critical functions and modules.\n-   Use a testing framework (e.g., `cargo test` for Rust, Jest or Mocha for JavaScript) to automate unit testing.\n-   Aim for high code coverage.\n-   Test edge cases and error conditions.\n\n### 5.2 Integration Testing\n\n-   Write integration tests to verify the interaction between different modules and components.\n-   Use a testing framework to automate integration testing.\n-   Test the integration between the frontend and backend.\n\n### 5.3 End-to-End Testing\n\n-   Write end-to-end tests to verify the entire application flow.\n-   Use a testing framework (e.g., Cypress, Playwright) to automate end-to-end testing.\n-   Test the application in a realistic environment.\n\n### 5.4 Test Organization\n\n-   Organize tests into separate directories for unit tests, integration tests, and end-to-end tests.\n-   Follow a consistent naming convention for test files and functions.\n-   Use test suites to group related tests.\n\n### 5.5 Mocking and Stubbing\n\n-   Use mocking and stubbing to isolate units of code during testing.\n-   Use a mocking framework (e.g., Mockall for Rust, Jest or Sinon.js for JavaScript) to create mocks and stubs.\n-   Mock external dependencies and APIs.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n-   **Incorrectly Configuring CSP:** Not setting a restrictive enough content security policy.\n-   **Misunderstanding Tauri's Security Model:**  Assuming Node.js APIs are safe to use directly in the frontend.\n-   **Ignoring Error Handling:**  Not handling errors properly, leading to unexpected application behavior.\n-   **Overcomplicating the Frontend:**  Trying to do too much in the frontend, instead of leveraging the Rust backend.\n\n### 6.2 Edge Cases to Be Aware Of\n\n-   **File System Permissions:**  Handling file system permissions correctly on different operating systems.\n-   **Webview Compatibility:**  Ensuring compatibility with different webview versions.\n-   **Application Update Process:**  Handling application updates gracefully and securely.\n\n### 6.3 Version-Specific Issues\n\n-   Be aware of breaking changes in Tauri releases.\n-   Consult the Tauri changelog for information about version-specific issues.\n\n### 6.4 Compatibility Concerns\n\n-   Test your application on different operating systems (Windows, macOS, Linux).\n-   Test your application on different architectures (x86, x64, ARM).\n\n### 6.5 Debugging Strategies\n\n-   Use the Tauri developer console for debugging frontend code.\n-   Use Rust's debugging tools for debugging backend code.\n-   Use logging to track application behavior.\n-   Use a debugger to step through code and inspect variables.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n-   **Rust:** Use the latest stable version of Rust.\n-   **Node.js:** Use a recent version of Node.js.\n-   **IDE:** Use a powerful IDE (e.g., Visual Studio Code, IntelliJ IDEA) with Rust and JavaScript/TypeScript support.\n-   **Debugger:** Use a debugger (e.g., GDB, LLDB) for debugging Rust code.\n-   **Web Inspector:** Use the web inspector (e.g., Chrome DevTools, Firefox Developer Tools) for debugging frontend code.\n\n### 7.2 Build Configuration\n\n-   Use the `tauri.conf.json` file to configure the build process.\n-   Configure the application name, version, and other metadata.\n-   Configure the build target and output directory.\n-   Configure the security policies and permissions.\n\n### 7.3 Linting and Formatting\n\n-   Use a linter (e.g., Clippy for Rust, ESLint for JavaScript) to enforce code style and identify potential issues.\n-   Use a code formatter (e.g., Rustfmt for Rust, Prettier for JavaScript) to automatically format your code.\n-   Configure your IDE to automatically run the linter and formatter on save.\n\n### 7.4 Deployment Best Practices\n\n-   Sign your application for the target platform.\n-   Use a code signing certificate to verify the authenticity of your application.\n-   Package your application for distribution using the appropriate tools (e.g., NSIS for Windows, DMG for macOS, DEB/RPM for Linux).\n\n### 7.5 CI/CD Integration\n\n-   Use a CI/CD system (e.g., GitHub Actions, GitLab CI, Jenkins) to automate the build, test, and deployment process.\n-   Configure your CI/CD system to run the linter, formatter, and tests.\n-   Configure your CI/CD system to automatically build and package your application for different platforms.\n-   Automate the deployment process to reduce manual effort and errors.\n\nBy adhering to these best practices, you can develop Tauri applications that are secure, performant, and maintainable. Remember to stay updated with the latest Tauri documentation and community recommendations for continuous improvement.",
    "metadata": {
      "globs": "*.(rs|js|ts|html|css|json|toml|md)",
      "format": "mdc",
      "originalFile": "tauri.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "tauri",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "developing",
      "robust",
      "secure",
      "performant",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tauri",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-tensorflow",
    "description": "Comprehensive guide to TensorFlow best practices, covering code organization, performance, testing, and security for robust and maintainable machine learning projects.",
    "author": "sanjeed5",
    "tags": [
      "tensorflow",
      "ml",
      "ai",
      "python",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "data-ai",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tensorflow.mdc",
    "content": "- **Code Organization and Structure:**\n  - **Directory Structure:**\n    -   Structure your project into logical directories. For example:\n        \n        project_root/\n        ├── data/\n        │   ├── raw/\n        │   └── processed/\n        ├── models/\n        │   ├── training/\n        │   └── saved_models/\n        ├── src/\n        │   ├── utils/\n        │   ├── layers/\n        │   ├── models/\n        │   ├── training/\n        │   └── evaluation/\n        ├── notebooks/  #Jupyter notebooks for experimentation\n        ├── tests/\n        ├── configs/\n        └── README.md\n        \n\n  - **File Naming Conventions:**\n    -   Use descriptive and consistent names. For example:\n        -   `model_name.py`\n        -   `data_processing.py`\n        -   `train.py`\n        -   `evaluate.py`\n        -   `layer_name.py`\n\n  - **Module Organization:**\n    -   Break down code into reusable modules and functions.\n    -   Use `tf.Module` and Keras layers to manage variables. This enables encapsulation and avoids global variable pollution.\n    -   Import modules using explicit relative or absolute paths, such as `from src.models import MyModel`.\n    - Group related functionality into modules/packages.\n\n  - **Component Architecture:**\n    - Employ modular design principles.\n    - Keras `Layers` and `Models` promote a component-based architecture.  Custom layers should inherit from `tf.keras.layers.Layer`. Custom models inherit from `tf.keras.Model`.\n    -   Use dependency injection to decouple components and facilitate testing.\n\n  - **Code Splitting Strategies:**\n    -   Refactor code into smaller, manageable modules.\n    -   Separate data loading, preprocessing, model definition, training, and evaluation into distinct modules.\n    -   Implement generator functions or `tf.data.Dataset` pipelines for large datasets to avoid loading all data into memory at once.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    -   **Strategy Pattern:** Use different strategies for optimization or regularization.\n    -   **Factory Pattern:**  Create model architectures dynamically based on configuration.\n    -   **Observer Pattern:** Monitor training progress and trigger actions based on metrics.\n\n  - **Recommended Approaches:**\n    -   Use Keras layers and models to manage variables. Keras handles the underlying TensorFlow operations.\n    -   Leverage `tf.data.Dataset` for efficient data loading and preprocessing.\n    -   Use `tf.function` to compile Python functions into TensorFlow graphs for improved performance.\n\n  - **Anti-patterns and Code Smells:**\n    -   **God Classes:** Avoid monolithic classes that perform too many tasks. Break them into smaller, more focused classes or functions.\n    -   **Copy-Pasted Code:**  Refactor duplicated code into reusable functions or modules.\n    -   **Magic Numbers:** Use named constants instead of hardcoded values.\n    -   **Global Variables:** Minimize the use of global variables, especially for model parameters.\n\n  - **State Management:**\n    -   Use Keras layers and models for managing model state (weights, biases).\n    -   Use `tf.Variable` objects for persistent state that needs to be tracked during training.\n    -  When creating a model subclass, define trainable weights as tf.Variable objects within the `build()` method.\n    -   Consider using `tf.saved_model` to save and load the entire model state, including the computation graph and variable values.\n\n  - **Error Handling:**\n    -   Use `tf.debugging.assert_*` functions to check tensor values during development and debugging.\n    -   Implement try-except blocks to handle potential exceptions, such as `tf.errors.InvalidArgumentError` or `tf.errors.OutOfRangeError`.\n    -   Log errors and warnings using `tf.compat.v1.logging` or the standard `logging` module.\n    - Ensure error messages are informative and actionable.\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    -   Use `tf.function` to compile Python functions into TensorFlow graphs for improved performance. Use autograph (automatic graph construction).\n    -   Optimize data input pipelines using `tf.data.Dataset.prefetch` and `tf.data.Dataset.cache`.\n    -   Experiment with different optimizers (e.g., Adam, SGD) and learning rates.\n    -  Adjust the default learning rate for some `tf.keras.*` optimizers.\n    -   Use mixed precision training with `tf.keras.mixed_precision.Policy` to reduce memory usage and improve performance on GPUs.\n\n  - **Memory Management:**\n    -   Use `tf.data.Dataset` to stream data from disk instead of loading it all into memory.\n    -   Release unnecessary tensors using `del` to free up memory.\n    -   Use `tf.GradientTape` to compute gradients efficiently, and avoid keeping unnecessary tensors alive within the tape.\n\n  - **GPU Utilization:**\n    -   Ensure that TensorFlow is using the GPU by checking `tf.config.list_physical_devices('GPU')`.\n    -   Use larger batch sizes to maximize GPU utilization.\n    -   Profile your code using TensorFlow Profiler to identify bottlenecks and optimize GPU usage.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    -   **Untrusted Input:**  Validate all user-provided input to prevent malicious code injection or data poisoning attacks.\n    -   **Model Poisoning:** Protect against adversarial attacks that can manipulate the training data and degrade model performance.\n    -   **Model Inversion:**  Implement techniques to protect sensitive data from being extracted from the model.\n\n  - **Input Validation:**\n    -   Sanitize and validate all input data to prevent SQL injection, cross-site scripting (XSS), and other security vulnerabilities.\n    -   Use `tf.io.decode_image` to decode images safely and prevent potential vulnerabilities related to malformed image files.\n    -  Input validation for image and text data is critical.\n\n  - **Data Protection:**\n    -   Encrypt sensitive data at rest and in transit.\n    -   Use differential privacy techniques to protect the privacy of training data.\n    -   Regularly audit your code and infrastructure for security vulnerabilities.\n\n  - **Secure API Communication:**\n    -   Use HTTPS to encrypt communication between the client and the server.\n    -   Implement authentication and authorization mechanisms to restrict access to sensitive data and functionality.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    -   Write unit tests for individual functions and classes using `unittest` or `pytest`.\n    -   Use `tf.test.TestCase` for testing TensorFlow-specific code.\n    -   Mock external dependencies to isolate the code being tested.\n\n  - **Integration Testing:**\n    -   Test the integration of different modules and components.\n    -   Verify that the data pipeline is working correctly.\n    -   Ensure that the model is producing accurate predictions on real-world data.\n\n  - **End-to-End Testing:**\n    -   Test the entire workflow from data loading to model deployment.\n    -   Use tools like Selenium or Cypress to automate end-to-end tests.\n    -   Test for performance and scalability.\n\n  - **Test Organization:**\n    -   Organize tests into logical directories and modules.\n    -   Use clear and descriptive test names.\n    -   Follow the Arrange-Act-Assert pattern for writing tests.\n\n  - **Mocking and Stubbing:**\n    -   Use mocking frameworks like `unittest.mock` or `pytest-mock` to replace external dependencies with mock objects.\n    -   Use stubs to provide controlled responses from external dependencies.\n\n- **Common Pitfalls and Gotchas:**\n  - **Version Compatibility:**\n    -   Be aware of version-specific issues and compatibility concerns when upgrading TensorFlow versions.\n    -   Use `tf.compat.v1` or `tf.compat.v2` to maintain compatibility with older versions of TensorFlow.\n\n  - **Eager Execution:**\n    -   Understand the differences between eager execution and graph execution.\n    -   Use `tf.function` to compile functions into graphs for improved performance in production.\n\n  - **Tensor Shapes and Data Types:**\n    -   Pay attention to tensor shapes and data types to avoid errors.\n    -   Use `tf.debugging.assert_shapes` and `tf.debugging.assert_type` to check tensor shapes and data types during development.\n\n  - **Variable Scope:**\n    -   Be aware of variable scope when using `tf.Variable` objects.\n    -   Use `tf.compat.v1.get_variable` to create or reuse variables within a specific scope.\n\n- **Tooling and Environment:**\n  - **Recommended Development Tools:**\n    -   Jupyter Notebooks or Google Colab for interactive development and experimentation.\n    -   TensorBoard for visualizing training progress and model graphs.\n    -   TensorFlow Profiler for identifying performance bottlenecks.\n    -   Debuggers such as the Python Debugger (pdb) for stepping through code and inspecting variables.\n\n  - **Linting and Formatting:**\n    -   Use linters like pylint or flake8 to enforce code style guidelines.\n    -   Use formatters like black or autopep8 to automatically format your code.\n\n  - **Deployment Best Practices:**\n    -   Use TensorFlow Serving to deploy models in production.\n    -   Use Docker to containerize your application and ensure consistent deployments.\n    -  Use a platform like Vertex AI for scalable model training and deployment.\n\n  - **CI/CD Integration:**\n    -   Integrate your code with a continuous integration/continuous delivery (CI/CD) pipeline.\n    -   Use tools like Jenkins, Travis CI, or CircleCI to automate testing and deployment.\n\n- **References:**\n  - [TensorFlow Core](https://www.tensorflow.org/guide/effective_tf2)\n  - [TensorFlow testing best practices](https://www.tensorflow.org/community/contribute/tests)\n  - [Medium - 10 tips to improve your machine learning models with tensorflow](https://medium.com/decathlondigital/10-tips-to-improve-your-machine-learning-models-with-tensorflow-ba7c724761e2)\n  - [Quora - What are the best practices with TensorFlow](https://www.quora.com/What-are-the-best-practices-with-TensorFlow)",
    "metadata": {
      "globs": "*.py,*.tf,*.keras",
      "format": "mdc",
      "originalFile": "tensorflow.mdc"
    },
    "subcategory": "machine-learning",
    "keywords": [
      "cursor",
      "tensorflow",
      "comprehensive",
      "guide",
      "best",
      "practices",
      "covering",
      "code",
      "organization",
      "performance",
      "testing",
      "ml",
      "ai",
      "python",
      "cursor-rule",
      "mdc",
      "languages",
      "machine-learning"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tensorflow",
        "ml",
        "ai",
        "python",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-terraform",
    "description": "This rule provides guidelines for Terraform best practices, coding standards, and security considerations to ensure maintainable, efficient, and secure infrastructure-as-code.",
    "author": "sanjeed5",
    "tags": [
      "terraform",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "infrastructure",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/terraform.mdc",
    "content": "- **Use Remote State**: Store Terraform state files remotely to enable collaboration and prevent conflicts. Consider using Terraform Cloud, HashiCorp Consul, AWS S3 with DynamoDB locking, or Azure Storage Account with Blob Storage Locking.\n\t- Properly configure access controls for your remote state backend to prevent unauthorized access.\n\t- Implement versioning for state files to track changes and facilitate rollbacks.\n- **Consistent Naming Conventions**: Adopt a consistent naming convention for resources, modules, and variables to improve readability and maintainability.\n\t- Use nouns for resource names (e.g., `aws_instance.web_server` instead of `web_server_instance`).\n\t- Include environment or project context in names (e.g., `dev_web_server` or `prod_db`).\n\t- Follow a consistent casing style (e.g., snake_case or camelCase).\n- **Modularity and Code Structure**: Organize Terraform code into modules to promote reusability and maintainability.\n\t- Create modules for common infrastructure components (e.g., VPC, EC2 instance, database).\n\t- Follow a standard module structure (e.g., `variables.tf`, `outputs.tf`, `main.tf`, `versions.tf`).\n\t- Limit the use of custom scripts within modules; prefer Terraform resources and data sources.\n- **Validation and Formatting**: Always validate and format Terraform code using `terraform fmt` and `terraform validate` to ensure quality and consistency.\n\t- Integrate `terraform fmt` and `terraform validate` into your CI/CD pipeline.\n\t- Use a linter such as TFLint to enforce organization-specific coding best practices.\n- **Use Existing Shared and Community Modules**: Leverage pre-built modules from the Terraform Registry or other trusted sources to avoid reinventing the wheel.\n\t- Thoroughly review modules before use to understand their functionality and security implications.\n\t- Pin module versions to prevent unexpected changes.\n- **Import Existing Infrastructure**: Use the `terraform import` command to bring existing infrastructure under Terraform management.\n\t- Understand the limitations of `terraform import` and manually verify the imported configuration.\n- **Avoid Hard-coding Variables**: Use variables to parameterize Terraform configurations and avoid hard-coding values.\n\t- Define variables in `variables.tf` with appropriate descriptions, types, and default values.\n\t- Use environment variables or Terraform Cloud variables to pass sensitive values.\n- **Tag Resources**: Tag all Terraform resources with relevant metadata (e.g., `Name`, `Environment`, `Project`, `Owner`).\n\t- Use consistent tagging conventions across your infrastructure.\n\t- Leverage tags for cost allocation and resource management.\n- **Introduce Policy as Code**: Implement policy as code using tools like HashiCorp Sentinel or Open Policy Agent (OPA) to enforce compliance and security policies.\n\t- Define policies for resource configurations, naming conventions, and security settings.\n\t- Integrate policy checks into your CI/CD pipeline.\n- **Code Organization and Structure:**\n\t- **Directory Structure Best Practices:** Organize your Terraform project with a clear directory structure. A common pattern:\n\t\t\n\t\t├── modules/\n\t\t│   ├── vpc/\n\t\t│   │   ├── main.tf\n\t\t│   │   ├── variables.tf\n\t\t│   │   └── outputs.tf\n\t\t│   ├── ec2/\n\t\t│   │   ├── main.tf\n\t\t│   │   ├── variables.tf\n\t\t│   │   └── outputs.tf\n\t\t├── environments/\n\t\t│   ├── dev/\n\t\t│   │   ├── main.tf\n\t\t│   │   ├── variables.tf\n\t\t│   │   └── terraform.tfvars\n\t\t│   ├── prod/\n\t\t│   │   ├── main.tf\n\t\t│   │   ├── variables.tf\n\t\t│   │   └── terraform.tfvars\n\t\t├── main.tf  # Top-level resources (if any)\n\t\t├── variables.tf # Global variables\n\t\t└── outputs.tf   # Global outputs\n\t\t\n\t- **File Naming Conventions:** Adhere to consistent file naming. Use `main.tf` for the primary resource definitions, `variables.tf` for variables, `outputs.tf` for outputs, and `terraform.tfvars` for environment-specific variable values.\n\t- **Module Organization:** Keep modules self-contained and reusable. Each module should have a specific purpose (e.g., creating a VPC, an EC2 instance, or a database).\n\t- **Component Architecture:** Design your infrastructure as a collection of loosely coupled components (modules) that can be composed together.\n\t- **Code Splitting Strategies:** Break down large configurations into smaller, more manageable modules and files.\n- **Common Patterns and Anti-patterns:**\n\t- **Design Patterns:**\n\t\t- **Singleton Pattern:** Ensure only one instance of a critical resource exists (e.g., a VPC). Use `count = var.create_vpc ? 1 : 0` to conditionally create a single VPC.\n\t\t- **Factory Pattern:** Use modules to create multiple instances of a resource with different configurations (e.g., multiple EC2 instances with different sizes and roles).\n\t\t- **Facade Pattern:** Create a module that simplifies the creation of complex infrastructure by abstracting away the underlying details.\n\t- **Recommended Approaches:**\n\t\t- Use data sources to retrieve information about existing resources instead of hardcoding their IDs or names.\n\t\t- Use dynamic blocks to create multiple resources or configure resource properties based on variable values.\n\t\t- Use lifecycle rules to manage resource creation, modification, and deletion.\n\t- **Anti-patterns:**\n\t\t- **Hardcoding values:** Avoid hardcoding values in your Terraform configurations. Use variables instead.\n\t\t- **Creating monolithic configurations:** Break down large configurations into smaller, more manageable modules.\n\t\t- **Ignoring errors:** Always handle errors and provide meaningful error messages.\n\t- **State Management Best Practices:**\n\t\t- **Remote State:** Always use remote state to store Terraform state files.\n\t\t- **State Locking:** Enable state locking to prevent concurrent modifications.\n\t\t- **State Encryption:** Encrypt state files to protect sensitive data.\n\t\t- **State Versioning:** Implement versioning for state files.\n\t- **Error Handling Patterns:**\n\t\t- Use the `try` and `can` functions to handle errors when retrieving data or evaluating expressions.\n\t\t- Use `validation` blocks to validate variable values and prevent invalid configurations.\n\t\t- Provide meaningful error messages to help users diagnose and fix issues.\n- **Performance Considerations:**\n\t- **Optimization Techniques:**\n\t\t- Use the `count` and `for_each` meta-arguments to create multiple resources efficiently.\n\t\t- Use data sources to retrieve information about existing resources instead of creating new ones.\n\t\t- Use the `depends_on` meta-argument sparingly to avoid unnecessary dependencies.\n\t- **Memory Management:**\n\t\t- Be mindful of the memory usage of your Terraform configurations, especially when working with large datasets.\n\t\t- Avoid creating large variables or outputs that can consume excessive memory.\n\t- **Rendering Optimization:**\n\t\t- Use efficient string interpolation techniques to avoid unnecessary string concatenation.\n\t\t- Use the `templatefile` function to render complex templates efficiently.\n- **Security Best Practices:**\n\t- **Common Vulnerabilities:**\n\t\t- **Hardcoded secrets:** Avoid hardcoding secrets in your Terraform configurations.\n\t\t- **Publicly accessible resources:** Ensure that resources are not publicly accessible unless explicitly required.\n\t\t- **Insufficient access controls:** Implement strict access controls to prevent unauthorized access to resources.\n\t- **Input Validation:**\n\t\t- Validate variable values to prevent invalid or malicious input.\n\t\t- Use regular expressions to enforce specific input formats.\n\t- **Authentication and Authorization Patterns:**\n\t\t- Use IAM roles and policies to grant resources the necessary permissions.\n\t\t- Use Terraform Cloud or other secrets management tools to manage sensitive credentials.\n\t- **Data Protection Strategies:**\n\t\t- Encrypt sensitive data at rest and in transit.\n\t\t- Use encryption keys managed by a key management service (KMS).\n\t- **Secure API Communication:**\n\t\t- Use HTTPS for all API communication.\n\t\t- Validate API responses to prevent data injection attacks.\n- **Testing Approaches:**\n\t- **Unit Testing Strategies:**\n\t\t- Use `terraform show` and `terraform plan` to verify that your Terraform configurations create the expected resources.\n\t\t- Use `terratest` or other testing frameworks to write automated unit tests.\n\t- **Integration Testing:**\n\t\t- Deploy your Terraform configurations to a test environment and verify that the resources are functioning correctly.\n\t\t- Use automated testing tools to perform integration tests.\n\t- **End-to-end Testing:**\n\t\t- Simulate real-world scenarios and verify that your infrastructure can handle them.\n\t\t- Use automated testing tools to perform end-to-end tests.\n\t- **Test Organization:**\n\t\t- Organize your tests into a clear directory structure.\n\t\t- Use meaningful test names to describe the purpose of each test.\n\t- **Mocking and Stubbing:**\n\t\t- Use mocking and stubbing to isolate your tests and prevent dependencies on external resources.\n\t\t- Use testing frameworks that support mocking and stubbing.\n- **Common Pitfalls and Gotchas:**\n\t- **Frequent Mistakes:**\n\t\t- **Incorrect resource dependencies:** Ensure that resource dependencies are correctly defined.\n\t\t- **Ignoring resource lifecycle:** Understand the lifecycle of Terraform resources and how they are created, modified, and deleted.\n\t\t- **Using outdated Terraform versions:** Keep your Terraform version up to date to take advantage of new features and bug fixes.\n\t- **Edge Cases:**\n\t\t- **Handling resource conflicts:** Be prepared to handle resource conflicts that can occur when multiple Terraform configurations are applied simultaneously.\n\t\t- **Managing resources with external dependencies:** Be aware of resources that have external dependencies (e.g., DNS records) and handle them appropriately.\n\t- **Version-specific Issues:**\n\t\t- Be aware of version-specific issues and compatibility concerns when upgrading Terraform or provider versions.\n\t\t- Consult the Terraform and provider documentation for any breaking changes or migration guides.\n\t- **Compatibility Concerns:**\n\t\t- Ensure that your Terraform configurations are compatible with the target infrastructure environment.\n\t\t- Use provider versions that are compatible with the Terraform version.\n\t- **Debugging Strategies:**\n\t\t- Use the `terraform plan` command to preview the changes that will be made to your infrastructure.\n\t\t- Use the `terraform apply` command with the `-auto-approve` flag to apply changes automatically.\n\t\t- Use the `terraform show` command to inspect the current state of your infrastructure.\n- **Tooling and Environment:**\n\t- **Recommended Development Tools:**\n\t\t- **Terraform CLI:** The official Terraform command-line interface.\n\t\t- **Terraform Cloud/Enterprise:** A collaboration and automation platform for Terraform.\n\t\t- **IDE/Text Editor:** Visual Studio Code with the Terraform extension, Atom, or Sublime Text.\n\t\t- **TFLint:** A linter for Terraform code.\n\t\t- **Terratest:** A testing framework for Terraform code.\n\t- **Build Configuration:**\n\t\t- Use a consistent build configuration across all environments.\n\t\t- Use environment variables or Terraform Cloud variables to configure the build environment.\n\t- **Linting and Formatting:**\n\t\t- Integrate linting and formatting into your CI/CD pipeline.\n\t\t- Use `terraform fmt` and TFLint to ensure code quality and consistency.\n\t- **Deployment Best Practices:**\n\t\t- Use a CI/CD pipeline to automate Terraform deployments.\n\t\t- Use version control to track changes to your Terraform configurations.\n\t\t- Use infrastructure-as-code principles to manage your infrastructure.\n\t- **CI/CD Integration:**\n\t\t- Integrate Terraform into your CI/CD pipeline using tools like Jenkins, GitLab CI, or GitHub Actions.\n\t\t- Automate the execution of `terraform plan` and `terraform apply` commands.\n\t\t- Implement automated testing and validation as part of the CI/CD process.",
    "metadata": {
      "globs": "*.tf",
      "format": "mdc",
      "originalFile": "terraform.mdc"
    },
    "subcategory": "iac",
    "keywords": [
      "cursor",
      "terraform",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "coding",
      "standards",
      "security",
      "cursor-rule",
      "mdc",
      "infrastructure",
      "iac"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "terraform",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "infrastructure"
    }
  },
  {
    "name": "cursor-three-js",
    "description": "This rule provides guidelines and best practices for developing efficient, maintainable, and robust 3D web applications using Three.js. It covers aspects like code organization, performance optimization, security, testing, and common pitfalls to ensure a high-quality development experience.",
    "author": "sanjeed5",
    "tags": [
      "three-js",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/three-js.mdc",
    "content": "# Three.js Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for developing with Three.js. Adhering to these guidelines will help you create efficient, maintainable, and robust 3D web applications.\n\n## Library Information:\n\n- Name: three.js\n- Tags: 3d, graphics, webgl, javascript\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices:\n\nA well-organized directory structure enhances project maintainability and scalability. Consider the following structure:\n\n\nproject-root/\n├── src/\n│   ├── components/        # Reusable 3D components (e.g., models, scenes)\n│   │   ├── MyComponent.js\n│   │   └── ...\n│   ├── scenes/           # Specific scenes for different parts of the application\n│   │   ├── MainScene.js\n│   │   └── ...\n│   ├── models/           # 3D model files (e.g., .glb, .obj)\n│   │   ├── myModel.glb\n│   │   └── ...\n│   ├── textures/         # Texture files (e.g., .jpg, .png)\n│   │   ├── myTexture.jpg\n│   │   └── ...\n│   ├── shaders/          # Custom shader code (GLSL)\n│   │   ├── vertexShader.glsl\n│   │   └── fragmentShader.glsl\n│   ├── utils/            # Utility functions (e.g., math, helpers)\n│   │   ├── mathUtils.js\n│   │   └── ...\n│   ├── core/             # Core application logic (e.g., scene initialization, rendering loop)\n│   │   ├── renderer.js\n│   │   ├── camera.js\n│   │   ├── scene.js\n│   │   └── controls.js\n│   ├── app.js            # Main application entry point\n│   └── index.html        # HTML file to load the application\n├── dist/              # Distribution build\n├── node_modules/      # Node modules\n├── .gitignore\n├── package.json\n└── webpack.config.js    # Or equivalent build tool configuration\n\n\n### 1.2. File Naming Conventions:\n\nConsistent file naming improves code readability.\n\n-   **Components:** Use PascalCase (e.g., `MyComponent.js`).\n-   **Scenes:** Use PascalCase (e.g., `MainScene.js`).\n-   **Models:** Use camelCase (e.g., `myModel.glb`).\n-   **Textures:** Use camelCase (e.g., `myTexture.jpg`).\n-   **Shaders:** Use camelCase (e.g., `vertexShader.glsl`, `fragmentShader.glsl`).\n-   **Utilities:** Use camelCase (e.g., `mathUtils.js`).\n\n### 1.3. Module Organization:\n\nEmploy ES modules for better code organization and dependency management.\n\njavascript\n// MyComponent.js\nimport * as THREE from 'three';\n\nexport class MyComponent extends THREE.Mesh {\n constructor() {\n super();\n // ... component logic ...\n }\n}\n\n\njavascript\n// app.js\nimport { MyComponent } from './components/MyComponent.js';\nimport { MainScene } from './scenes/MainScene.js';\n\nconst scene = new MainScene();\nconst myComponent = new MyComponent();\nscene.add(myComponent);\n\n// ... rest of the application logic ...\n\n\n### 1.4. Component Architecture:\n\nUse a component-based architecture to create reusable and modular 3D elements.\n\n-   Encapsulate Three.js objects (e.g., meshes, lights) within components.\n-   Create components with well-defined interfaces (props and methods).\n-   Use a scene graph to manage the hierarchy of components.\n\n### 1.5. Code Splitting Strategies:\n\nFor large applications, use code splitting to improve initial load time.\n\n-   Split the application into smaller chunks based on routes or features.\n-   Use dynamic imports to load components or scenes on demand.\n-   Leverage Webpack or Parcel to configure code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns:\n\n-   **Factory Pattern:**  Use factory functions or classes to create complex Three.js objects. This can encapsulate the object creation logic, making it easier to manage and reuse. For example, a `ModelFactory` can load and process different 3D model formats.\n-   **Observer Pattern:** Implement an observer pattern for handling events and interactions in the 3D scene. For instance, you can use this to notify components when a user clicks on a specific object or when the scene changes.\n-   **Singleton Pattern:** For global resources like the renderer or scene manager, consider using a singleton pattern to ensure only one instance exists.  However, be cautious as singletons can sometimes make testing more difficult.\n-   **Command Pattern:** Decouple the execution of actions from their trigger by encapsulating them in command objects. This allows for easier undo/redo functionality and more flexible control over the 3D scene.\n\n### 2.2. Recommended Approaches for Common Tasks:\n\n-   **Loading Models:** Use `GLTFLoader` for loading GLTF/GLB models, which are efficient and widely supported.  Handle asynchronous loading using `async/await` or Promises.\n-   **Texture Management:** Use `TextureLoader` to load textures. Ensure textures are properly disposed of when no longer needed to prevent memory leaks.\n-   **Animation:** Use `AnimationMixer` to play animations from loaded models.  Optimize animation performance by reducing the number of animated objects and keyframes.\n-   **User Interaction:** Use `Raycaster` to detect intersections between the mouse cursor and 3D objects. Optimize raycasting by using bounding box checks and limiting the number of objects tested.\n\n### 2.3. Anti-patterns and Code Smells:\n\n-   **Creating Objects Inside Render Loop:** Avoid creating new Three.js objects (e.g., `THREE.Mesh`, `THREE.Material`) within the render loop. This can lead to significant performance degradation due to constant memory allocation and garbage collection. Instead, create objects once and reuse them.\n-   **Unnecessary Object Updates:**  Avoid updating object properties (position, rotation, scale) unnecessarily in the render loop.  Only update properties when they actually change.\n-   **Ignoring Memory Management:** Failing to dispose of Three.js objects (geometries, materials, textures) when they are no longer needed will lead to memory leaks. Always call `dispose()` on these objects to release resources.\n-   **Overly Complex Shaders:**  Writing overly complex or inefficient shaders can negatively impact performance.  Optimize shaders by reducing the number of calculations, using simpler algorithms, and minimizing texture lookups.\n-   **Direct Manipulation of `__webgl` properties:** Avoid directly accessing or manipulating internal properties of Three.js objects that start with `__webgl`. These are implementation details and are subject to change, which can break your code.\n\n### 2.4. State Management Best Practices:\n\n-   **Centralized State:** For complex applications, consider using a centralized state management library like Zustand, Redux, or Vuex to manage the application's state and synchronize changes across components.  This provides a single source of truth and simplifies state updates.\n-   **Immutable State:**  Prefer immutable state updates to make debugging easier and improve performance by avoiding unnecessary re-renders.  Libraries like Immer can help with immutable state management.\n-   **Reactive Programming:** Consider using a reactive programming library like RxJS or MobX to handle asynchronous data streams and side effects in a declarative way.\n\n### 2.5. Error Handling Patterns:\n\n-   **Try-Catch Blocks:**  Use `try-catch` blocks to handle potential errors during model loading, texture loading, and other asynchronous operations.\n-   **Error Boundaries:**  In React or other component-based frameworks, use error boundaries to catch errors in child components and prevent the entire application from crashing.\n-   **Logging:**  Implement a robust logging system to track errors and debug issues in production. Use a library like Winston or Bunyan for structured logging.\n-   **Fallback Mechanisms:**  Provide fallback mechanisms in case of errors. For example, if a model fails to load, display a placeholder object or an error message.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques:\n\n-   **Minimize Draw Calls:** Reduce the number of draw calls by merging geometries, using instancing, and using optimized materials.\n-   **Optimize Shaders:**  Simplify shader code, reduce the number of calculations, and minimize texture lookups.\n-   **Use LOD (Level of Detail):** Implement LOD to render objects with lower polygon counts when they are far from the camera.\n-   **Frustum Culling:**  Enable frustum culling to prevent objects that are outside the camera's view from being rendered.\n-   **Use Compressed Textures:** Use compressed texture formats like ETC1, PVRTC, or ASTC to reduce texture size and improve loading times.\n-   **GPU Instancing:** Use `InstancedMesh` to render multiple copies of the same geometry with different transformations using a single draw call.\n-   **Occlusion Culling:**  Implement occlusion culling to prevent objects that are hidden behind other objects from being rendered.\n-   **Use WebGL2:** If possible, use WebGL2, which offers performance improvements over WebGL1.\n\n### 3.2. Memory Management:\n\n-   **Dispose of Objects:**  Always dispose of Three.js objects (geometries, materials, textures) when they are no longer needed. Use the `dispose()` method.\n-   **Reuse Objects:** Reuse Three.js objects whenever possible instead of creating new ones.\n-   **Avoid Memory Leaks:** Be mindful of memory leaks, especially when dealing with event listeners and closures.\n-   **Use `BufferGeometry`:**  `BufferGeometry` is more memory efficient than `Geometry`. Use it whenever possible.\n\n### 3.3. Rendering Optimization:\n\n-   **Use `requestAnimationFrame`:** Use `requestAnimationFrame` to synchronize rendering with the browser's refresh rate.\n-   **Limit Frame Rate:**  Limit the frame rate to prevent unnecessary rendering and reduce CPU usage.\n-   **Optimize Camera Movement:**  Optimize camera movement and avoid unnecessary updates to the camera's position and rotation.\n-   **Use Post-processing Effects Sparingly:** Post-processing effects can be expensive. Use them sparingly and optimize their parameters.\n\n### 3.4. Bundle Size Optimization:\n\n-   **Tree Shaking:**  Use a bundler like Webpack or Parcel with tree shaking enabled to remove unused code from the Three.js library.\n-   **Code Splitting:** Split the application into smaller chunks to reduce the initial load time.\n-   **Minification:** Minify JavaScript and CSS code to reduce bundle size.\n-   **Gzip Compression:** Enable Gzip compression on the server to reduce the size of the transferred files.\n\n### 3.5. Lazy Loading:\n\n-   **Lazy Load Models and Textures:** Lazy load models and textures when they are needed instead of loading them all at once.\n-   **Use Dynamic Imports:** Use dynamic imports to load modules on demand.\n-   **Implement a Loading Screen:** Display a loading screen while assets are being loaded.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention:\n\n-   **Cross-Site Scripting (XSS):** Prevent XSS by sanitizing user input and avoiding the use of `innerHTML` to inject dynamic content.\n-   **Cross-Site Request Forgery (CSRF):** Protect against CSRF by using anti-CSRF tokens in forms and API requests.\n-   **Third-Party Dependencies:** Regularly audit and update third-party dependencies to patch security vulnerabilities.\n\n### 4.2. Input Validation:\n\n-   **Validate User Input:**  Validate user input to prevent malicious data from being processed by the application.\n-   **Sanitize Data:** Sanitize data before displaying it to the user to prevent XSS attacks.\n-   **Use a Validation Library:** Use a validation library like Joi or Yup to simplify input validation.\n\n### 4.3. Authentication and Authorization:\n\n-   **Use Secure Authentication:**  Use a secure authentication protocol like OAuth 2.0 or OpenID Connect.\n-   **Implement Authorization:**  Implement authorization to restrict access to sensitive data and functionality.\n-   **Use JSON Web Tokens (JWT):** Use JWTs for secure authentication and authorization.\n\n### 4.4. Data Protection:\n\n-   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n-   **Use HTTPS:**  Use HTTPS to encrypt communication between the client and the server.\n-   **Protect API Keys:** Protect API keys and other sensitive credentials.\n\n### 4.5. Secure API Communication:\n\n-   **Use HTTPS:** Always use HTTPS for API communication to protect data in transit.\n-   **Validate API Responses:** Validate API responses to ensure that the data is valid and not malicious.\n-   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of the API.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing:\n\n-   **Test Individual Components:** Unit test individual Three.js components to ensure that they are functioning correctly.\n-   **Use a Testing Framework:** Use a testing framework like Jest or Mocha to write and run unit tests.\n-   **Mock Dependencies:** Mock dependencies to isolate the component being tested.\n\n### 5.2. Integration Testing:\n\n-   **Test Interactions Between Components:** Integration test the interactions between different Three.js components to ensure that they are working together correctly.\n-   **Test Scene Rendering:** Test the rendering of the scene to ensure that the objects are being displayed correctly.\n\n### 5.3. End-to-End Testing:\n\n-   **Test the Entire Application:** End-to-end test the entire application to ensure that all components are working together correctly.\n-   **Use a Testing Tool:** Use a testing tool like Cypress or Puppeteer to automate end-to-end tests.\n\n### 5.4. Test Organization:\n\n-   **Organize Tests by Component:** Organize tests by component to make it easier to find and maintain tests.\n-   **Use Descriptive Test Names:** Use descriptive test names to make it clear what each test is testing.\n-   **Keep Tests Concise:** Keep tests concise and focused on a single aspect of the component being tested.\n\n### 5.5. Mocking and Stubbing:\n\n-   **Mock Three.js Objects:** Mock Three.js objects to isolate the component being tested.\n-   **Stub API Calls:** Stub API calls to prevent the tests from making real API requests.\n-   **Use a Mocking Library:** Use a mocking library like Jest or Sinon to simplify mocking and stubbing.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes:\n\n-   **Not Disposing of Objects:** Forgetting to dispose of Three.js objects, leading to memory leaks.\n-   **Creating Objects in Render Loop:** Creating new objects within the render loop, causing performance issues.\n-   **Ignoring Performance:** Not paying attention to performance and creating inefficient scenes.\n\n### 6.2. Edge Cases:\n\n-   **Mobile Devices:** Mobile devices have limited resources, so optimize performance for mobile.\n-   **Older Browsers:** Older browsers may not support WebGL2, so ensure compatibility with WebGL1.\n-   **Different Screen Sizes:** Different screen sizes require responsive design to ensure the application looks good on all devices.\n\n### 6.3. Version-Specific Issues:\n\n-   **Breaking Changes:** Be aware of breaking changes in new versions of Three.js and update code accordingly.\n-   **Deprecations:** Pay attention to deprecation warnings and update code to use the new APIs.\n\n### 6.4. Compatibility Concerns:\n\n-   **WebGL Support:** Ensure that the user's browser supports WebGL.\n-   **Device Capabilities:** Check the user's device capabilities and adjust the rendering settings accordingly.\n\n### 6.5. Debugging Strategies:\n\n-   **Use the Browser Developer Tools:** Use the browser developer tools to inspect the scene, debug JavaScript code, and profile performance.\n-   **Use the Three.js Inspector:** Use the Three.js inspector to inspect the scene graph, object properties, and shader code.\n-   **Console Logging:** Use console logging to track the execution flow and debug issues.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools:\n\n-   **IDE:** Visual Studio Code, WebStorm\n-   **Browser:** Chrome, Firefox, Safari\n-   **Three.js Inspector:** A browser extension for inspecting Three.js scenes.\n\n### 7.2. Build Configuration:\n\n-   **Use a Bundler:** Use a bundler like Webpack or Parcel to bundle the application's code and dependencies.\n-   **Configure Tree Shaking:** Configure tree shaking to remove unused code from the Three.js library.\n-   **Minify Code:** Minify JavaScript and CSS code to reduce bundle size.\n\n### 7.3. Linting and Formatting:\n\n-   **Use ESLint:** Use ESLint to enforce coding style and identify potential errors.\n-   **Use Prettier:** Use Prettier to format code consistently.\n-   **Configure a Code Editor:** Configure a code editor to automatically format code on save.\n\n### 7.4. Deployment:\n\n-   **Use a CDN:** Use a CDN to host static assets like models and textures.\n-   **Enable Gzip Compression:** Enable Gzip compression on the server to reduce the size of the transferred files.\n-   **Optimize Images:** Optimize images to reduce their size and improve loading times.\n\n### 7.5. CI/CD Integration:\n\n-   **Use a CI/CD Pipeline:** Use a CI/CD pipeline to automate the build, test, and deployment process.\n-   **Run Tests Automatically:** Run tests automatically on every commit.\n-   **Deploy to a Staging Environment:** Deploy to a staging environment before deploying to production.\n\nBy following these best practices, you can create high-quality Three.js applications that are efficient, maintainable, and robust. Remember to stay updated with the latest Three.js documentation and community resources to keep your skills sharp and your projects cutting-edge.",
    "metadata": {
      "globs": "*.js,*.ts,*.jsx,*.tsx,*.mjs,*.html",
      "format": "mdc",
      "originalFile": "three-js.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "three",
      "js",
      "this",
      "rule",
      "provides",
      "guidelines",
      "best",
      "practices",
      "developing",
      "efficient",
      "maintainable",
      "robust",
      "three-js",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "three-js",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-tinygrad",
    "description": "This rule file provides comprehensive best practices for developing with tinygrad, covering code organization, performance, testing, and security.  It aims to improve code quality, maintainability, and prevent common pitfalls when working with tinygrad.",
    "author": "sanjeed5",
    "tags": [
      "tinygrad",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tinygrad.mdc",
    "content": "- **Introduction**\n  This document outlines best practices for developing and maintaining code within the tinygrad library and projects that use tinygrad. Adhering to these guidelines will ensure code readability, maintainability, and optimal performance.  It draws from established software engineering principles, AI/ML coding standards, and the specific nuances of the tinygrad library.\n\n- **General Principles**\n  - **Readability is Paramount:**  Code should be easy to understand, even for those unfamiliar with the specific problem domain.  Use clear, descriptive variable and function names. Comment liberally, explaining the *why* more than the *what*.\n  - **Simplicity First:** Favor simple, straightforward solutions over complex, clever ones.  Optimize for readability and maintainability before raw performance. Premature optimization is the root of all evil.\n  - **Test-Driven Development (TDD):** Write tests before writing code. This clarifies requirements and ensures that the code behaves as expected. Tests should be automated and run frequently.\n  - **Version Control:** All code must be managed with Git. Use meaningful commit messages. Branch frequently for new features and bug fixes.  Pull requests should be reviewed by at least one other developer.\n  - **Continuous Integration/Continuous Deployment (CI/CD):** Automate the build, test, and deployment process.  Use a CI/CD system like GitHub Actions or GitLab CI.\n  - **Documentation:** Document all public APIs.  Include examples of how to use the code. Keep documentation up-to-date.\n  - **SOLID Principles:** Attempt to adhere to the SOLID design principles as appropriate for Machine Learning.\n\n- **Code Organization and Structure**\n  - **Directory Structure:** A suggested directory structure for tinygrad projects is:\n    \n    project_root/\n    ├── tinygrad/\n    │   ├── __init__.py\n    │   ├── tensor.py      # Core tensor implementation\n    │   ├── ops.py         # Basic operations (add, multiply, etc.)\n    │   ├── device.py      # Abstraction for different hardware devices (CPU, GPU)\n    │   ├── nn/            # Neural network modules\n    │   │   ├── __init__.py\n    │   │   ├── layers.py\n    │   │   └── optim.py\n    │   ├── mlops.py       # Matrix library operations\n    │   ├──codegen/         # Code generation related files\n    │   │   ├── __init__.py\n    │   │   ├── linearizer.py\n    │   │   └── opencl.py\n    │   └── ...\n    ├── examples/       # Example usage of tinygrad\n    ├── tests/          # Unit and integration tests\n    ├── README.md\n    ├── setup.py\n    └── requirements.txt\n    \n  - **File Naming Conventions:**\n    - Python files: Use lowercase with underscores (e.g., `tensor.py`, `nn_layers.py`).\n    - Classes: Use PascalCase (e.g., `Tensor`, `NeuralNetworkLayer`).\n    - Functions and variables: Use lowercase with underscores (e.g., `add`, `learning_rate`).\n    - Constants: Use UPPER_CASE with underscores (e.g., `DEFAULT_DEVICE`, `EPSILON`).\n  - **Module Organization:**\n    - Group related functionality into modules. For example, all neural network layers should be in the `nn` module.\n    - Use `__init__.py` files to define the public API of each module.\n    - Avoid circular dependencies between modules.\n  - **Component Architecture:**\n    - Design components with clear interfaces and responsibilities.\n    - Favor composition over inheritance.\n    - Use dependency injection to decouple components.\n  - **Code Splitting:**\n    - Break down large files into smaller, more manageable ones.\n    - Split code based on functionality or responsibility.\n    - Use lazy loading for modules that are not immediately needed.\n\n- **Common Patterns and Anti-patterns**\n  - **Design Patterns:**\n    - **Factory Pattern:** Use factories to create instances of tensors on different devices.\n    - **Strategy Pattern:** Use the strategy pattern to implement different optimization algorithms.\n    - **Observer Pattern:** Implement an observer pattern for monitoring training progress.\n  - **Recommended Approaches:**\n    - When implementing new operators, consider their performance implications on different hardware backends.  Optimize for the common case.\n    - Use NumPy-like syntax where possible to improve code readability for those familiar with NumPy.\n  - **Anti-patterns and Code Smells:**\n    - **God Classes:** Avoid creating classes that do too much. Split them into smaller, more focused classes.\n    - **Long Methods:** Break down long methods into smaller, more manageable ones.\n    - **Duplicated Code:** Extract duplicated code into reusable functions or classes.\n    - **Magic Numbers:** Use named constants instead of hardcoding numerical values.\n    - **Excessive Nesting:** Reduce nesting by using helper functions or early returns.\n  - **State Management:**\n    - Avoid global state. Pass state explicitly to functions and classes.\n    - Use immutable data structures where possible.\n    - Consider using a state management library for complex applications.\n  - **Error Handling:**\n    - Use exceptions to handle errors.\n    - Provide informative error messages.\n    - Catch exceptions at the appropriate level and handle them gracefully.\n    - Avoid swallowing exceptions.\n\n- **Performance Considerations**\n  - **Optimization Techniques:**\n    - **Operator Fusion:** Fuse multiple operations into a single kernel to reduce memory transfers.\n    - **Loop Unrolling:** Unroll loops to improve instruction-level parallelism.\n    - **Vectorization:** Use SIMD instructions to perform operations on multiple data elements in parallel.\n    - **Code generation:** Use code generation to tailor the implementation to the specific hardware backend. Utilize libraries like LLVM.\n  - **Memory Management:**\n    - Minimize memory allocations and deallocations.\n    - Use memory pools to reuse memory.\n    - Be aware of memory alignment requirements for different hardware backends.\n    - Optimize data layout for cache efficiency.\n  - **Lazy Loading:**\n    - Only load data when it is needed.\n    - Use generators to process large datasets in chunks.\n\n- **Security Best Practices**\n  - **Input Validation:**\n    - Validate all inputs to prevent malicious data from corrupting the system.\n    - Check for valid data types, ranges, and formats.\n    - Sanitize inputs to remove potentially harmful characters.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use strong authentication and authorization mechanisms to protect data access.\n\n- **Testing Approaches**\n  - **Unit Testing:**\n    - Test individual components in isolation.\n    - Use mocking and stubbing to isolate dependencies.\n    - Write tests for all public APIs.\n    - Aim for high code coverage.\n  - **Integration Testing:**\n    - Test the interactions between different components.\n    - Test the integration with external systems.\n  - **End-to-End Testing:**\n    - Test the entire application from end to end.\n    - Simulate real-world user scenarios.\n  - **Test Organization:**\n    - Organize tests into a directory structure that mirrors the code structure.\n    - Use meaningful test names.\n    - Keep tests independent of each other.\n  - **Mocking and Stubbing:**\n    - Use mocking to replace dependencies with controlled substitutes.\n    - Use stubbing to provide predefined responses to method calls.\n\n- **Common Pitfalls and Gotchas**\n  - **Frequent Mistakes:**\n    - Neglecting to release allocated memory.\n    - Using incorrect data types.\n    - Incorrectly handling exceptions.\n    - Premature optimization.\n  - **Edge Cases:**\n    - Handling empty tensors.\n    - Handling tensors with different shapes.\n    - Handling numerical instability.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes between different versions of tinygrad.\n    - Consult the release notes for details.\n  - **Compatibility Concerns:**\n    - Be aware of compatibility issues between tinygrad and other libraries.\n    - Test your code with different versions of dependencies.\n  - **Debugging Strategies:**\n    - Use a debugger to step through the code and inspect variables.\n    - Use logging to track the execution flow.\n    - Use assertions to check for unexpected conditions.\n\n- **Tooling and Environment**\n  - **Development Tools:**\n    - PyCharm, VS Code, or other IDE.\n    - Python debugger (pdb).\n    - Profiler (e.g., cProfile).\n    - Memory analyzer (e.g., memory_profiler).\n  - **Build Configuration:**\n    - Use a build system like setuptools.\n    - Define dependencies in `requirements.txt`.\n  - **Linting and Formatting:**\n    - Use a linter like pylint or flake8.\n    - Use a code formatter like black or autopep8.\n    - Configure your IDE to automatically lint and format code.\n  - **Deployment:**\n    - Package your application into a Docker container.\n    - Use a deployment platform like Kubernetes or AWS ECS.\n  - **CI/CD Integration:**\n    - Integrate your build, test, and deployment process into a CI/CD pipeline.\n    - Use a CI/CD system like GitHub Actions or GitLab CI.\n\n- **Additional Best Practices for Tinygrad:**\n    - **Leverage the low-level nature:**  Understand the underlying operations and memory management principles of tinygrad to write efficient code.  Don't shy away from customizing operations when necessary.\n    - **Contribute Back:** If you find a bug or implement a useful feature, consider contributing back to the tinygrad project.  Help the community grow.\n    - **Stay Updated:** Tinygrad is under active development.  Stay up-to-date with the latest releases and best practices.\n    - **Understand the Device Abstraction Layer:**  Tinygrad's strength is its ability to target different hardware backends.  Familiarize yourself with the device abstraction layer to write portable code.\n\nBy following these best practices, you can write high-quality, maintainable, and performant code with tinygrad.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "tinygrad.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "tinygrad",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tinygrad",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-tkinter",
    "description": "This rule file outlines the best practices for developing GUI applications with tkinter in Python, including code organization, performance, security, testing, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "tkinter",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tkinter.mdc",
    "content": "# tkinter Best Practices: Optimizing Performance and Code Structure\n\nThis document outlines the best practices for developing GUI applications with `tkinter` in Python. It covers code organization, performance considerations, common pitfalls, security aspects, testing strategies, and recommended tooling.\n\n## Library Information:\n\n- Name: tkinter\n- Tags: ui, gui, python, desktop\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nA well-organized directory structure is crucial for maintainability and scalability. Here's a recommended structure:\n\n\nmy_tkinter_app/\n├── app/\n│   ├── __init__.py\n│   ├── main_window.py  # Main application window\n│   ├── widgets/\n│   │   ├── __init__.py\n│   │   ├── custom_button.py\n│   │   └── ...\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── data_model.py\n│   │   └── ...\n│   ├── controllers/\n│   │   ├── __init__.py\n│   │   ├── main_controller.py\n│   │   └── ...\n│   ├── views/\n│   │   ├── __init__.py\n│   │   ├── main_view.py\n│   │   └── ...\n│   └── utils.py\n├── tests/\n│   ├── __init__.py\n│   ├── test_main_window.py\n│   ├── test_custom_button.py\n│   └── ...\n├── LICENSE\n├── README.md\n├── requirements.txt\n└── main.py  # Entry point to run the application\n\n\n- `app/`: Contains the application's source code, including UI elements, logic, and data models.\n- `widgets/`: Holds custom widgets that extend `tkinter`'s built-in widgets.\n- `models/`: Defines data models and business logic.\n- `controllers/`: Manages interactions between the view and the model.\n- `views/`: Defines the user interface.\n- `tests/`: Contains unit tests and integration tests.\n- `LICENSE`: Project License\n- `README.md`: Project Documentation\n- `requirements.txt`: Lists project dependencies.\n- `main.py`: Application entry point.\n\n### 1.2. File Naming Conventions\n\n- Use descriptive and consistent names for files and modules.\n- Follow the snake_case naming convention for Python files (e.g., `main_window.py`, `custom_button.py`).\n- For class names, use PascalCase (e.g., `MainWindow`, `CustomButton`).\n- For variable and function names, use snake_case (e.g., `window_width`, `calculate_area`).\n\n### 1.3. Module Organization\n\n- Break down large applications into smaller, manageable modules.\n- Each module should have a specific purpose and should be responsible for a single aspect of the application.\n- Use relative imports within the `app/` directory to maintain a clear hierarchy.\n  python\n  # Example: In app/controllers/main_controller.py\n  from ..models import data_model\n  \n- Avoid circular dependencies between modules.\n\n### 1.4. Component Architecture\n\n- Adopt a component-based architecture to promote reusability and maintainability.\n- Encapsulate UI elements and their associated logic into custom widgets.\n- Consider using the Model-View-Controller (MVC) or Model-View-Presenter (MVP) design patterns.\n\n### 1.5. Code Splitting\n\n- Decompose complex functions and classes into smaller, more focused units.\n- Limit the size of individual files to improve readability and reduce cognitive load.\n- Use separate files for UI definitions, event handling logic, and data processing.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n- **MVC (Model-View-Controller):** Separates data (Model), UI (View), and user interaction logic (Controller).\n- **Observer:** Defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.  Useful for updating the UI when the underlying data changes.\n- **Factory:** Used to create objects without specifying the exact class of object that will be created. Useful for creating widgets dynamically.\n\n### 2.2. Recommended Approaches\n\n- **Object-Oriented Programming (OOP):** Structure your Tkinter application using classes to improve code readability and maintainability. Encapsulate components within their classes for better modularity and separation of concerns.\n- **Consistent Layout Management:** Choose a consistent layout manager (`pack()`, `grid()`, or `place()`) for each container, and avoid mixing them within the same container to prevent layout issues.\n- **Threading for Long Tasks:** Use Python's threading capabilities for long-running tasks to keep the GUI responsive. Run background tasks without freezing the main application window.\n\n### 2.3. Anti-Patterns and Code Smells\n\n- **Global Variables:** Avoid global variables; use instance variables instead to minimize conflicts and enhance code clarity.\n- **Mixing Layout Managers:** Don't mix `pack()`, `grid()`, and `place()` within the same container, as it can lead to unpredictable layout behavior.\n- **Blocking the Main Thread:** Avoid performing long-running operations directly in the main thread, as this can freeze the GUI.\n- **Deeply Nested Code:** Avoid deeply nested code blocks, as they can reduce readability. Break down complex logic into smaller functions.\n- **Magic Numbers/Strings:** Replace numeric literals and string constants with named constants to improve readability and maintainability.\n\n### 2.4. State Management\n\n- Use `StringVar`, `IntVar`, `BooleanVar`, and `DoubleVar` classes to manage widget state and automatically update UI elements.\n- Create dedicated model classes to hold application data.\n- Use observable patterns to notify UI elements of data changes.\n\n### 2.5. Error Handling\n\n- Implement comprehensive error handling using `try...except` blocks.\n- Log errors to a file or console for debugging purposes.\n- Display user-friendly error messages in dialog boxes or status bars.\n- Implement global exception handling to prevent unhandled exceptions from crashing the application.\n- Use `tkinter.messagebox` for displaying warning, info and error messages.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Minimize Redrawing:** Use `update_idletasks()` to reduce unnecessary redraws of the UI, enhancing responsiveness during updates.\n- **Efficient Widget Configuration:** Avoid unnecessary widget configuration changes, as they can trigger redraws.\n- **Caching:** Cache frequently accessed data to reduce database or network I/O.\n- **Debouncing:** Implement debouncing for event handlers that trigger computationally expensive operations.\n\n### 3.2. Memory Management\n\n- Avoid creating unnecessary widget instances.\n- Destroy widgets when they are no longer needed using `.destroy()`.\n- Limit the use of images and large data structures to reduce memory footprint.\n- Use weak references to avoid circular dependencies and memory leaks.\n\n### 3.3. Rendering Optimization\n\n- Use the `Canvas` widget for drawing complex graphics instead of creating many individual widgets.\n- Optimize drawing operations by minimizing the number of draw calls.\n- Use double buffering to prevent flickering during updates.\n\n### 3.4 Lazy Loading\n\n- Load only the necessary data and UI elements when the application starts.\n- Delay loading less frequently used features until they are requested by the user.\n- Use placeholder widgets or progress indicators while data is being loaded.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n- **Command Injection:** Avoid executing shell commands directly from the application, as this can lead to command injection vulnerabilities.\n- **Cross-Site Scripting (XSS):** Be cautious when displaying user-provided data in UI elements, as this can lead to XSS vulnerabilities.\n- **Path Traversal:** Sanitize file paths to prevent path traversal vulnerabilities.\n\n### 4.2. Input Validation\n\n- Validate all user inputs to prevent malicious data from entering the application.\n- Use regular expressions or custom validation functions to ensure that inputs conform to expected formats.\n- Sanitize inputs by escaping special characters and removing potentially harmful content.\n- Implement rate limiting to prevent denial-of-service attacks.\n\n### 4.3. Authentication and Authorization\n\n- Use secure authentication protocols, such as OAuth 2.0 or OpenID Connect.\n- Store user credentials securely using password hashing algorithms like bcrypt or Argon2.\n- Implement role-based access control to restrict access to sensitive data and functionality.\n\n### 4.4. Data Protection\n\n- Encrypt sensitive data at rest and in transit.\n- Use secure communication protocols, such as HTTPS, to protect data during transmission.\n- Implement data masking or redaction to prevent exposure of sensitive information.\n\n### 4.5. Secure API Communication\n\n- Use secure API endpoints with HTTPS.\n- Validate API responses to prevent data injection.\n- Use API keys or authentication tokens to control access to API resources.\n- Implement rate limiting to prevent API abuse.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n- Write unit tests for individual widgets, models, and controllers.\n- Use a testing framework, such as `unittest` or `pytest`, to automate the testing process.\n- Mock external dependencies, such as databases or network connections, to isolate the code being tested.\n- Test different scenarios, including normal conditions, edge cases, and error conditions.\n\n### 5.2. Integration Testing\n\n- Test the interaction between different components of the application.\n- Verify that data flows correctly between widgets, models, and controllers.\n- Test the application with different data sets to ensure that it handles various scenarios.\n\n### 5.3. End-to-End Testing\n\n- Simulate user interactions to test the application from start to finish.\n- Use a GUI testing tool, such as `selenium` or `pywinauto`, to automate the testing process.\n- Verify that the application behaves as expected in different environments.\n\n### 5.4. Test Organization\n\n- Create a separate directory for test files (`tests/`).\n- Organize tests into modules that correspond to the application's module structure.\n- Use descriptive names for test functions to indicate what they are testing.\n\n### 5.5. Mocking and Stubbing\n\n- Use mocking to replace external dependencies with mock objects that simulate their behavior.\n- Use stubs to replace complex functions with simple implementations that return predefined values.\n- Mock GUI elements for testing the underlying logic.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n- **Forgetting `mainloop()`:** The GUI will not display without calling `root.mainloop()` at the end of the script.\n- **Incorrect Event Handling:**  Incorrectly binding events (e.g., binding to the wrong widget or using the wrong event type).\n- **Not Using Classes:**  Failing to use classes for structuring the application, leading to disorganized and hard-to-maintain code.\n- **Confusing `StringVar` and Text:**  Trying to get the value directly from the widget instead of using `StringVar.get()` for Entry or using `Text.get()` with appropriate indices.\n- **Improper Use of Layout Managers:** Mixing layout managers within the same container or failing to understand how they behave.\n\n### 6.2. Edge Cases\n\n- **Window Resizing:** Handling window resizing correctly to ensure that widgets are displayed properly.\n- **Different Screen Resolutions:** Testing the application on different screen resolutions to ensure that it looks good on all devices.\n- **Unicode Support:** Handling Unicode characters correctly to support different languages.\n\n### 6.3. Version-Specific Issues\n\n- There are significant differences between Python 2.x and Python 3.x regarding the `tkinter` module name (Tkinter vs. tkinter). Remember to use `import tkinter as tk` for Python 3 and `import Tkinter as tk` for Python 2.\n\n### 6.4. Compatibility Concerns\n\n- Ensure compatibility between tkinter and other technologies used in the application (e.g., databases, web frameworks).\n- Test the application on different operating systems to ensure that it behaves consistently.\n\n### 6.5. Debugging\n\n- Use the Python debugger (`pdb`) to step through the code and inspect variables.\n- Add logging statements to track the flow of execution and identify errors.\n- Use GUI debugging tools to inspect widget properties and layouts.\n- Learn to read the often cryptic traceback messages from tkinter errors. They often provide valuable clues.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Tools\n\n- **IDE:** VS Code, PyCharm, Spyder\n- **GUI Designer:** Tkinter Designer (third party, code generation), PAGE (drag-and-drop)\n- **Testing Framework:** `unittest`, `pytest`\n- **Linting:** `flake8`, `pylint`\n- **Formatting:** `black`, `autopep8`\n\n### 7.2. Build Configuration\n\n- Use `pip` and `virtualenv` to manage dependencies and create isolated environments.\n- Create a `requirements.txt` file to list all dependencies.\n- Use a build tool, such as `setuptools` or `cx_Freeze`, to create distributable packages.\n\n### 7.3. Linting and Formatting\n\n- Use a linter to enforce coding style and identify potential errors.\n- Use a formatter to automatically format the code according to PEP 8 guidelines.\n- Configure the IDE to run the linter and formatter automatically when saving files.\n\n### 7.4. Deployment\n\n- Use a deployment tool, such as `pyinstaller` or `cx_Freeze`, to create standalone executables.\n- Package the application with all necessary dependencies.\n- Provide installation instructions for different operating systems.\n- For web-based tkinter applications (using something like eel), follow appropriate web deployment strategies.\n\n### 7.5. CI/CD Integration\n\n- Use a CI/CD tool, such as Jenkins, GitLab CI, or GitHub Actions, to automate the build, test, and deployment processes.\n- Configure the CI/CD pipeline to run unit tests, integration tests, and end-to-end tests automatically.\n- Use code coverage tools to measure the effectiveness of the tests.\n\nBy adhering to these best practices, you can create robust, maintainable, and performant tkinter applications.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "tkinter.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "tkinter",
      "this",
      "rule",
      "file",
      "outlines",
      "best",
      "practices",
      "developing",
      "applications",
      "with",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tkinter",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-tornado",
    "description": "Comprehensive best practices and coding standards for the Tornado framework. This rule provides guidelines on code organization, performance, security, testing, and common pitfalls when developing Tornado applications.",
    "author": "sanjeed5",
    "tags": [
      "tornado",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tornado.mdc",
    "content": "## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nA well-structured directory layout enhances code maintainability and scalability. Consider the following structure:\n\n\nproject_name/\n├── app/\n│   ├── __init__.py\n│   ├── handlers/\n│   │   ├── __init__.py\n│   │   ├── base_handler.py  # Base class for handlers\n│   │   ├── home_handler.py  # Specific request handlers\n│   │   ├── auth_handler.py\n│   ├── models/\n│   │   ├── __init__.py\n│   │   ├── user.py        # Data models\n│   │   ├── packet.py\n│   ├── services/\n│   │   ├── __init__.py\n│   │   ├── authentication_service.py # Business Logic\n│   │   ├── packet_service.py\n│   ├── utils/\n│   │   ├── __init__.py\n│   │   ├── database.py    # Database connection and setup\n│   │   ├── helpers.py     # Utility functions\n│   ├── config.py      # Application configuration\n│   ├── application.py # Tornado Application setup\n│   └── main.py        # Entry point for the application\n├── tests/\n│   ├── __init__.py\n│   ├── test_handlers.py  # Unit tests for handlers\n│   ├── test_models.py    # Unit tests for models\n│   └── test_services.py  # Unit tests for services\n├── static/           # Static files (CSS, JavaScript, images)\n├── templates/        # HTML templates\n├── docs/             # Documentation\n├── requirements.txt  # Project dependencies\n├── .env             # Environment variables (development)\n└── README.md\n\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   Handlers: `home_handler.py`, `user_handler.py`\n*   Models: `user.py`, `product.py`\n*   Utilities: `database.py`, `string_utils.py`\n*   Tests: `test_handlers.py`, `test_models.py`\n\n### 1.3. Module Organization\n\n*   Group related functionalities into modules.\n*   Keep modules focused and avoid creating overly large modules.\n*   Use clear and concise names for modules.\n*   Use packages (directories with `__init__.py`) to further organize modules.\n\n### 1.4. Component Architecture\n\n*   **MVC (Model-View-Controller):** A common architectural pattern.\n    *   **Models:** Represent data and business logic.\n    *   **Views:** (Templates) Display data to the user.\n    *   **Controllers (Handlers):** Handle user requests and interact with models.\n*   **Microservices:** Decompose the application into smaller, independent services.\n*   **Hexagonal Architecture (Ports and Adapters):** Isolates the core application logic from external dependencies.\n\n### 1.5. Code Splitting\n\n*   **Split large handler files:** Decompose complex handlers into smaller, reusable functions or classes.\n*   **Modularize functionality:** Extract common logic into separate modules or services.\n*   **Lazy loading:** Import modules only when needed to reduce startup time. Avoid doing heavy imports at the top of the file. Consider `import tornado.ioloop` inside of a method if it's only used there.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Singleton:** For managing global resources like database connections.\n*   **Factory:** For creating instances of objects without specifying their concrete classes.\n*   **Observer:** For implementing event-driven architectures.\n*   **Template Method:** For defining a skeleton algorithm in a base class and letting subclasses implement specific steps.\n*   **Middleware:** Implement custom request processing logic (authentication, logging).\n\n### 2.2. Recommended Approaches\n\n*   **Asynchronous Operations:** Leverage Tornado's asynchronous capabilities (using `async` and `await`) for non-blocking I/O operations. This includes database queries, API calls, and file system operations.\n*   **Use `IOLoop.add_callback` for thread safety:** When interacting with Tornado objects from other threads.\n*   **Configuration Management:** Utilize environment variables for storing configuration settings, adhering to the Twelve-Factor App methodology.\n*   **Logging:** Implement robust logging using Tornado's built-in logging capabilities.\n*   **Routing:** Utilize Tornado's routing system effectively by defining URL patterns and corresponding request handlers.\n*   **Authentication/Authorization:** Employ decorators like `@tornado.web.authenticated` for securing routes.\n*   **Use a BaseHandler class:**  Encapsulate common logic, such as authentication checks, error handling, and template rendering.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **Blocking I/O in Handlers:** Performing synchronous operations within request handlers will block the I/O loop, severely impacting performance. Always use asynchronous alternatives.\n*   **Ignoring Exceptions:** Catching exceptions without proper handling or logging can mask critical errors.\n*   **Overly Complex Handlers:** Large, monolithic handlers are difficult to maintain and test. Break them down into smaller, focused functions or classes.\n*   **Hardcoding Configuration:** Embedding configuration values directly in the code makes it difficult to manage and deploy the application across different environments. Use environment variables or configuration files.\n*   **Global State:** Over-reliance on global variables can lead to unpredictable behavior and make the code harder to reason about. Use dependency injection or other techniques to manage state explicitly.\n*   **Ignoring Thread Safety:** Tornado applications are single-threaded, but interactions with external resources might not be. Using `IOLoop.run_in_executor` is key to thread safety. If using WSGI containers, this becomes extremely important.\n\n### 2.4. State Management\n\n*   **Stateless Handlers:** Design handlers to be stateless to improve scalability and fault tolerance.\n*   **Session Management:** Use signed cookies or external session stores (Redis, Memcached) for managing user sessions.\n*   **Caching:** Implement caching mechanisms (in-memory, Redis, Memcached) to reduce database load and improve response times.\n*   **Avoid Global Variables:** Minimize the use of global variables to prevent unintended side effects.\n\n### 2.5. Error Handling\n\n*   **Centralized Error Handling:** Create a custom error handler (e.g., a base handler with error handling logic) to handle exceptions consistently across the application.\n*   **Logging:** Log all exceptions and errors with sufficient context (request details, user information).\n*   **Custom Error Pages:** Provide user-friendly error pages for common HTTP errors (404, 500).\n*   **Exception Propagation:** Allow exceptions to propagate to the Tornado error handler to ensure proper logging and handling.\n*   **Use `try...except` Blocks:** Wrap potentially failing code blocks in `try...except` blocks to gracefully handle errors.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Asynchronous I/O:** Use asynchronous I/O operations to avoid blocking the I/O loop.\n*   **Connection Pooling:** Use connection pooling for database connections to reduce connection overhead.  Libraries like SQLAlchemy provide this.\n*   **Caching:** Implement caching strategies to reduce database load and improve response times. Consider using `functools.lru_cache` for frequently called, pure functions.\n*   **Gzip Compression:** Enable Gzip compression for responses to reduce bandwidth usage.\n*   **Optimize Database Queries:** Ensure that database queries are efficient and properly indexed.\n*   **Minimize External Dependencies:** Reduce the number of external dependencies to minimize startup time and improve performance.\n*   **WebSockets**: Implement websockets using Tornado's native support for persistent connections to offload work from HTTP handlers.\n\n### 3.2. Memory Management\n\n*   **Avoid Memory Leaks:** Be mindful of memory leaks, especially when dealing with long-lived connections or background tasks. Use tools like `memory_profiler` to identify and fix memory leaks.\n*   **Use Generators:** Use generators for processing large datasets to avoid loading the entire dataset into memory at once.\n*   **Object Pooling:** Use object pooling for frequently created objects to reduce object creation overhead.\n*   **Limit Object Sizes:** Avoid creating excessively large objects that can consume significant memory.\n\n### 3.3. Rendering Optimization (If applicable)\n\n*   **Template Caching:** Cache compiled templates to reduce rendering overhead. Tornado automatically caches templates by default.\n*   **Minimize Template Logic:** Keep template logic simple and move complex calculations to the handler.\n*   **Use Template Inheritance:** Use template inheritance to reuse common template elements and reduce duplication.\n*   **Optimize Static Files:** Minimize, compress, and cache static files (CSS, JavaScript, images).\n\n### 3.4. Bundle Size Optimization (If applicable)\n\n*   **Minify CSS and JavaScript:** Use tools like UglifyJS or CSSNano to minify CSS and JavaScript files.\n*   **Combine CSS and JavaScript:** Combine multiple CSS and JavaScript files into fewer files to reduce HTTP requests.\n*   **Use a CDN:** Serve static files from a Content Delivery Network (CDN) to improve loading times.\n\n### 3.5. Lazy Loading\n\n*   **Lazy-load Modules:** Import modules only when needed to reduce startup time.\n*   **Lazy-load Images:** Load images only when they are visible in the viewport.\n*   **Lazy-load Data:** Fetch data only when it is needed.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities\n\n*   **Cross-Site Scripting (XSS):** Sanitize user input to prevent XSS attacks.\n*   **SQL Injection:** Use parameterized queries or an ORM to prevent SQL injection attacks.\n*   **Cross-Site Request Forgery (CSRF):** Implement CSRF protection to prevent malicious websites from performing unauthorized actions on behalf of logged-in users. Tornado includes CSRF protection features.\n*   **Authentication and Authorization Flaws:** Implement robust authentication and authorization mechanisms to prevent unauthorized access to resources.\n*   **Session Hijacking:** Use secure cookies (HTTPOnly, Secure) and session management techniques to prevent session hijacking.\n*   **Denial of Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n\n### 4.2. Input Validation\n\n*   **Validate All Input:** Validate all user input to prevent malicious data from entering the application.\n*   **Use Whitelisting:** Use whitelisting to define the allowed characters and formats for input fields.\n*   **Sanitize Input:** Sanitize input to remove or escape potentially dangerous characters.\n*   **Escape Output:** Escape output to prevent XSS attacks.\n\n### 4.3. Authentication and Authorization\n\n*   **Use Strong Passwords:** Enforce strong password policies and use a secure hashing algorithm (bcrypt, Argon2) to store passwords.\n*   **Implement Two-Factor Authentication (2FA):** Use 2FA to add an extra layer of security to user accounts.\n*   **Use Role-Based Access Control (RBAC):** Implement RBAC to control access to resources based on user roles.\n*   **Principle of Least Privilege:** Grant users only the minimum privileges required to perform their tasks.\n*   **JSON Web Tokens (JWT):** Use JWT for stateless authentication.\n\n### 4.4. Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Use HTTPS:** Use HTTPS to encrypt communication between the client and server.\n*   **Store Secrets Securely:** Store secrets (API keys, database passwords) securely using environment variables or a secrets management system.\n*   **Regularly Rotate Secrets:** Rotate secrets regularly to reduce the risk of compromise.\n\n### 4.5. Secure API Communication\n\n*   **Use HTTPS:** Enforce HTTPS for all API endpoints.\n*   **Implement API Authentication:** Use API keys, JWT, or OAuth 2.0 to authenticate API clients.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse and DoS attacks.\n*   **Input Validation:** Validate all API input to prevent malicious data from entering the application.\n*   **Output Sanitization:** Sanitize API output to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing\n\n*   **Test Individual Components:** Unit tests should focus on testing individual components (handlers, models, services) in isolation.\n*   **Use Mocking and Stubbing:** Use mocking and stubbing to isolate the component under test from its dependencies.\n*   **Test Edge Cases:** Test edge cases and boundary conditions to ensure that the component handles unexpected inputs correctly.\n*   **Follow Arrange-Act-Assert Pattern:** Structure unit tests using the Arrange-Act-Assert pattern.\n*   **Use `unittest` or `pytest`:** Python's built-in `unittest` module or the popular `pytest` framework are commonly used.\n\n### 5.2. Integration Testing\n\n*   **Test Interactions Between Components:** Integration tests should focus on testing the interactions between different components of the application.\n*   **Use a Test Database:** Use a separate test database to avoid polluting the production database.\n*   **Test API Endpoints:** Test API endpoints to ensure that they function correctly and return the expected results.\n*   **Test Database Interactions:** Test database interactions to ensure that data is being read and written correctly.\n\n### 5.3. End-to-End Testing\n\n*   **Test the Entire Application:** End-to-end tests should test the entire application from the user's perspective.\n*   **Use a Testing Framework:** Use a testing framework like Selenium or Cypress to automate end-to-end tests.\n*   **Test User Flows:** Test common user flows to ensure that the application functions correctly.\n\n### 5.4. Test Organization\n\n*   **Organize Tests by Module:** Organize tests into separate files or directories for each module.\n*   **Use Descriptive Test Names:** Use descriptive test names to make it clear what each test is testing.\n*   **Keep Tests Independent:** Ensure that tests are independent of each other and can be run in any order.\n\n### 5.5. Mocking and Stubbing\n\n*   **Use Mocking Libraries:** Use mocking libraries like `unittest.mock` or `pytest-mock` to create mock objects and stubs.\n*   **Mock External Dependencies:** Mock external dependencies (databases, APIs) to isolate the component under test.\n*   **Stub Complex Logic:** Stub complex logic to simplify the test and focus on the specific behavior being tested.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Blocking the I/O Loop:** Performing synchronous operations in handlers.\n*   **Not Handling Exceptions Properly:** Ignoring or mishandling exceptions.\n*   **Incorrectly Using `async` and `await`:**  Forgetting to `await` asynchronous calls.\n*   **Not Understanding Thread Safety:** Improperly accessing Tornado objects from threads.\n*   **Over-complicating handlers:** Making handlers too long and hard to understand.\n\n### 6.2. Edge Cases\n\n*   **Handling Long-lived Connections:**  Managing WebSocket connections and preventing memory leaks.\n*   **Dealing with Slow Clients:**  Implementing timeouts and connection limits.\n*   **Handling Unexpected Input:**  Validating and sanitizing user input.\n*   **Dealing with Network Errors:** Implementing retry logic and error handling.\n\n### 6.3. Version-Specific Issues\n\n*   **Compatibility with Python Versions:**  Ensuring compatibility with supported Python versions.\n*   **API Changes:** Being aware of API changes between Tornado versions.\n*   **Deprecated Features:**  Avoiding the use of deprecated features.\n\n### 6.4. Compatibility Concerns\n\n*   **WSGI Compatibility:** Understanding the limitations of WSGI integration.\n*   **Asynchronous Libraries:**  Ensuring compatibility with other asynchronous libraries.\n*   **Database Drivers:**  Using asynchronous database drivers compatible with Tornado.\n\n### 6.5. Debugging Strategies\n\n*   **Logging:** Use extensive logging to track the flow of execution and identify errors.\n*   **Debugging Tools:** Use debugging tools like `pdb` or IDE debuggers to step through the code and inspect variables.\n*   **Profiling:** Use profiling tools to identify performance bottlenecks.\n*   **Monitoring:** Use monitoring tools to track the application's health and performance in production.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **IDE:** VS Code, PyCharm\n*   **Virtual Environment:** `venv`, `virtualenvwrapper`, `conda`\n*   **Package Manager:** `pip`, `uv`\n*   **Debugging Tools:** `pdb`, IDE debuggers\n*   **Profiling Tools:** `cProfile`, `memory_profiler`\n*   **Linting and Formatting:** `flake8`, `pylint`, `black`\n*   **Testing Frameworks:** `unittest`, `pytest`\n\n### 7.2. Build Configuration\n\n*   **Use `requirements.txt`:**  Specify project dependencies in a `requirements.txt` file.\n*   **Use `setup.py` or `pyproject.toml`:** For packaging and distributing the application.\n*   **Use a Build System:** Consider using a build system like `make` or `tox` to automate build tasks.\n\n### 7.3. Linting and Formatting\n\n*   **Use a Linter:** Use a linter like `flake8` or `pylint` to enforce coding standards and identify potential errors.\n*   **Use a Formatter:** Use a formatter like `black` to automatically format the code according to PEP 8.\n*   **Configure Editor:** Configure the editor to automatically run the linter and formatter on save.\n\n### 7.4. Deployment\n\n*   **Use a Production-Ready Server:**  Deploy the application on a production-ready server like Gunicorn or uWSGI.\n*   **Use a Reverse Proxy:** Use a reverse proxy like Nginx or Apache to handle SSL termination, load balancing, and caching.\n*   **Use a Process Manager:** Use a process manager like Supervisor or systemd to manage the application process.\n*   **Use a Containerization Technology:** Consider using containerization technologies like Docker to package and deploy the application.\n\n### 7.5. CI/CD Integration\n\n*   **Use a CI/CD System:** Use a CI/CD system like Jenkins, GitLab CI, GitHub Actions, or CircleCI to automate the build, test, and deployment processes.\n*   **Automate Testing:** Automate unit, integration, and end-to-end tests as part of the CI/CD pipeline.\n*   **Automate Deployment:** Automate the deployment process to reduce the risk of human error.\n*   **Implement Rollback Strategy:** Implement a rollback strategy to quickly revert to a previous version in case of errors.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "tornado.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "tornado",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "framework",
      "this",
      "rule",
      "provides",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tornado",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-tortoise-orm",
    "description": "This rule provides comprehensive best practices for using Tortoise ORM in Python projects, covering aspects like code organization, performance, security, and testing.",
    "author": "sanjeed5",
    "tags": [
      "tortoise-orm",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tortoise-orm.mdc",
    "content": "- Use Tortoise ORM for asynchronous database interactions in Python.\n- Always use UV when installing dependencies for faster performance, especially when combined with Tortoise ORM's asynchronous capabilities.\n- Ensure you are using a supported version of Python (>= 3.8). Python 3.12 or later is recommended for the best performance and features.\n- Organize code into classes for better structure and maintainability, especially when defining models and database interactions.\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - `src/`: Root directory for the main application code.\n    - `src/models/`: Contains Tortoise ORM model definitions.\n    - `src/schemas/`: Pydantic schemas for data validation and API interaction (if using FastAPI).\n    - `src/routers/`: FastAPI routers or equivalent for handling API endpoints.\n    - `src/database.py`: Database initialization and connection management.\n    - `src/config.py`: Configuration settings for the application.\n    - `tests/`: Contains unit and integration tests.\n    - `migrations/`: Aerich migration files.\n    - `docs/`: Documentation for the project.\n\n- **File Naming Conventions:**\n    - Models: `user_model.py`, `product_model.py`\n    - Schemas: `user_schema.py`, `product_schema.py`\n    - Routers: `user_router.py`, `product_router.py`\n    - Database: `database.py` or `db.py`\n    - Config: `config.py` or `settings.py`\n\n- **Module Organization:**\n    - Group related models, schemas, and routers into logical modules.\n    - Use namespaces (packages) to avoid naming conflicts.\n    - Keep modules focused and avoid overly large files.\n\n- **Component Architecture:**\n    - Models: Define database entities using Tortoise ORM's `Model` class.\n    - Schemas: Use Pydantic for data validation and serialization.\n    - Services: Encapsulate business logic and database interactions.\n    - Repositories: Abstract data access logic from services (optional).\n    - Controllers/Routers: Handle API requests and responses.\n\n- **Code Splitting:**\n    - Use lazy loading for models with large relationships.\n    - Split large modules into smaller, more manageable files.\n    - Consider using sub-applications (e.g., with FastAPI) to separate concerns.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns:**\n    - Repository Pattern: Abstract data access logic.\n    - Unit of Work Pattern: Manage database transactions.\n    - Factory Pattern: Create model instances with complex dependencies.\n    - DTO (Data Transfer Object): Use Pydantic models for data transfer between layers.\n\n- **Recommended Approaches:**\n    - Use `Tortoise.init()` to initialize the database connection once at application startup.\n    - Use `Tortoise.generate_schemas()` to create database tables.\n    - Use `Tortoise.close_connections()` to close database connections when the application shuts down.\n    - Utilize `prefetch_related` for eager loading of related data to optimize performance.\n    - Implement proper error handling using try-except blocks to catch potential exceptions.\n\n- **Anti-patterns and Code Smells:**\n    - Initializing the database connection on every request.\n    - Not closing database connections, leading to resource leaks.\n    - Over-fetching data without using `prefetch_related`.\n    - Ignoring exceptions, which can hide potential issues.\n    - Writing complex SQL queries directly instead of using Tortoise ORM's query builder.\n    - Performing database operations within a loop without batching.\n\n- **State Management:**\n    - Keep database state separate from application state.\n    - Use transactions to ensure data consistency.\n    - Avoid storing sensitive data in the application state.\n\n- **Error Handling:**\n    - Catch specific exceptions (e.g., `DoesNotExist`, `IntegrityError`) rather than generic `Exception`.\n    - Log errors with detailed information for debugging.\n    - Use custom exception classes for specific error conditions.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - Use `prefetch_related` to reduce the number of database queries.\n    - Use `bulk_create` and `bulk_update` for batch operations.\n    - Use indexes to speed up queries on frequently accessed columns.\n    - Optimize database queries by using `filter` and `exclude` to narrow down results.\n    - Defer loading large fields using Tortoise ORM's field options.\n\n- **Memory Management:**\n    - Close database connections when they are no longer needed.\n    - Use asynchronous generators to process large datasets.\n    - Avoid loading unnecessary data into memory.\n\n- **Rendering Optimization:**\n    - This is generally not applicable to Tortoise ORM itself, but consider optimizing data serialization (e.g., using `orjson`).\n\n- **Bundle Size Optimization:**\n    - Not directly applicable to Tortoise ORM.\n\n- **Lazy Loading:**\n    - Use relationships wisely to avoid over-fetching data.\n    - Implement pagination for large result sets.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities:**\n    - SQL injection: Prevent by using Tortoise ORM's query builder and parameterized queries.\n    - Cross-site scripting (XSS): Prevent by sanitizing user inputs.\n    - Cross-site request forgery (CSRF): Implement CSRF protection in your application.\n\n- **Input Validation:**\n    - Use Pydantic to validate user inputs before saving them to the database.\n    - Sanitize user inputs to prevent XSS attacks.\n    - Limit the length of input fields to prevent buffer overflows.\n\n- **Authentication and Authorization:**\n    - Use a secure authentication mechanism (e.g., JWT).\n    - Implement role-based access control (RBAC) to restrict access to sensitive data.\n    - Use password hashing (e.g., bcrypt) to store passwords securely.\n\n- **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use SSL/TLS to secure API communication.\n    - Implement data masking to protect sensitive data in logs and reports.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API endpoints.\n    - Implement rate limiting to prevent denial-of-service attacks.\n    - Validate API requests and responses.\n\n## 5. Testing Approaches:\n\n- **Unit Testing:**\n    - Test model methods and business logic in isolation.\n    - Use mocking to isolate database interactions.\n    - Use pytest and asyncio.run for async tests.\n\n- **Integration Testing:**\n    - Test the interaction between different components of the application.\n    - Use a test database to avoid affecting the production database.\n    - Use fixtures to set up test data.\n\n- **End-to-End Testing:**\n    - Test the entire application from the user's perspective.\n    - Use a testing framework like Playwright or Selenium.\n\n- **Test Organization:**\n    - Organize tests by module or component.\n    - Use descriptive test names.\n    - Keep tests small and focused.\n\n- **Mocking and Stubbing:**\n    - Use `unittest.mock` to mock database connections and queries.\n    - Use stubs to replace complex dependencies with simplified versions.\n    - Avoid over-mocking, which can make tests less reliable.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes:**\n    - Forgetting to await asynchronous calls.\n    - Using synchronous code in asynchronous contexts.\n    - Not handling exceptions properly.\n    - Over-fetching data.\n    - Not using transactions for complex operations.\n\n- **Edge Cases:**\n    - Handling concurrency and race conditions.\n    - Dealing with large datasets.\n    - Handling database migrations.\n\n- **Version-Specific Issues:**\n    - Refer to the Tortoise ORM changelog for breaking changes and known issues.\n    - Use version pinning to ensure compatibility between Tortoise ORM and other dependencies.\n\n- **Compatibility Concerns:**\n    - Ensure compatibility between Tortoise ORM and the database driver (e.g., `asyncpg`, `aiosqlite`).\n    - Ensure compatibility between Tortoise ORM and other libraries (e.g., FastAPI, Pydantic).\n\n- **Debugging Strategies:**\n    - Use logging to track the execution flow of the application.\n    - Use a debugger to step through the code and inspect variables.\n    - Use database profiling tools to identify slow queries.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - IDE: PyCharm, VS Code\n    - Database client: pgAdmin, Dbeaver\n    - Testing framework: pytest\n    - Linting: pylint, flake8\n    - Formatting: black, autopep8\n\n- **Build Configuration:**\n    - Use a `pyproject.toml` file to manage dependencies.\n    - Use a virtual environment to isolate dependencies.\n\n- **Linting and Formatting:**\n    - Use pylint or flake8 to enforce code style guidelines.\n    - Use black or autopep8 to automatically format code.\n    - Configure linters and formatters to run automatically on every commit.\n\n- **Deployment:**\n    - Use a containerization technology like Docker.\n    - Use a process manager like systemd or supervisord.\n    - Use a reverse proxy like Nginx or Apache.\n\n- **CI/CD Integration:**\n    - Use a CI/CD pipeline to automate testing, linting, and deployment.\n    - Use a version control system like Git.\n    - Use a deployment tool like Ansible or Terraform.\n\n**Additional Considerations:**\n\n- **Use Asynchronous Context Managers for Database Operations:** Tortoise-ORM is an async ORM. Leveraging asynchronous context managers within functions or methods that interact with the database ensures that the database connection is properly released, preventing connection exhaustion and improving overall performance. Use it with `async with`. Example:\n\npython\nasync def create_user(user_data):\n    async with Tortoise.get_connection('default') as conn:\n        await User.create(**user_data)\n\n\n- **Leverage Transactions:** Complex operations should be wrapped in transactions to ensure atomicity. Tortoise-ORM provides a transaction decorator. For example:\n\npython\nfrom tortoise import transaction\n\n@transaction.atomic()\nasync def transfer_funds(from_account, to_account, amount):\n    # Your operations here\n    pass\n\n\n- **Monitor and Profile Database Queries:** Regularly monitor your database queries to identify slow or inefficient queries. Tools like `pg_stat_statements` for PostgreSQL or similar for other databases can provide insights. Profile your code with tools like `cProfile` to find bottlenecks. Use `explain` command on queries to verify execution plans.\n\n- **Regular Database Maintenance:** Perform regular database maintenance tasks such as vacuuming (PostgreSQL), optimizing tables (MySQL), and updating statistics to ensure optimal performance.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "tortoise-orm.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "tortoise",
      "orm",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "python",
      "projects",
      "tortoise-orm",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tortoise-orm",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-tqdm",
    "description": "This rule file provides best practices and coding standards for using the `tqdm` library in Python. It focuses on performance, customization, and avoiding common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "tqdm",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/tqdm.mdc",
    "content": "# tqdm Best Practices and Coding Standards\n\nThis document outlines best practices for using the `tqdm` library in Python, focusing on simplicity, customization, performance optimization, and avoiding common pitfalls. Adhering to these guidelines will help you create efficient and informative progress bars for your projects.\n\n## Library Information\n\n- Name: tqdm\n- Tags: python, utilities, progress-bar, command-line\n\n## 1. Basic Usage and Integration\n\n- **Wrap Iterables Directly:** The simplest and most common way to use `tqdm` is by wrapping your iterable object directly with the `tqdm()` function.\n\n  python\n  from tqdm import tqdm\n\n  for item in tqdm(my_iterable):\n      # Process item\n      ...\n  \n\n- **Descriptive Progress Bars:** Always use the `desc` parameter to add a short, descriptive text to your progress bar, providing context to the user.\n\n  python\n  for item in tqdm(my_iterable, desc=\"Processing Data\"):\n      ...\n  \n\n- **Integration with Pandas:**  Use `tqdm` with Pandas `apply` functions for data analysis tasks.\n\n  python\n  import pandas as pd\n  from tqdm import tqdm\n\n  tqdm.pandas()\n  df['column'].progress_apply(lambda x: some_function(x))\n  \n\n## 2. Performance Considerations\n\n- **Update Frequency:** Avoid updating the progress bar too frequently, as it can significantly impact performance, especially with large datasets or computationally intensive tasks. Adjust `mininterval` and `maxinterval` to optimize refresh rates.\n\n  python\n  for item in tqdm(my_iterable, desc=\"Processing Data\", mininterval=1, maxinterval=10):\n      ...\n  \n\n- **Manual Control for Performance:** In scenarios where automatic iteration tracking isn't feasible, use manual control with `tqdm` to update the progress bar at strategic intervals.\n\n  python\n  from tqdm import tqdm\n  import time\n\n  total_iterations = 1000\n  with tqdm(total=total_iterations, desc=\"Manual Progress\") as pbar:\n      for i in range(total_iterations):\n          # Perform some operation\n          time.sleep(0.001) # simulate work\n          if i % 10 == 0:\n              pbar.update(10) # update after every 10 iterations\n  \n\n- **`tqdm.write()` for Printing:**  Use `tqdm.write()` to print messages to the console without disrupting the progress bar. This is especially useful for logging information or displaying intermediate results.\n\n  python\n  from tqdm import tqdm\n\n  for i in tqdm(range(100), desc='Processing'):\n      if i % 10 == 0:\n          tqdm.write(f'Iteration {i}: Some intermediate result')\n  \n\n## 3. Nested Progress Bars\n\n- **`leave=False` for Nested Bars:** When using nested loops with `tqdm`, set `leave=False` for inner loops to prevent cluttering the output. This ensures that only the outer loop's progress bar remains after the inner loop completes.\n\n  python\n  from tqdm import tqdm\n  import time\n\n  for i in tqdm(range(5), desc=\"Outer Loop\", leave=True):\n      for j in tqdm(range(3), desc=\"Inner Loop\", leave=False):\n          time.sleep(0.1)\n  \n\n## 4. Customization and Advanced Features\n\n- **Dynamic Descriptions:** Update the progress bar description dynamically during iterations to provide more context-specific information.\n\n  python\n  from tqdm import tqdm\n  import time\n\n  with tqdm(range(10), desc=\"Starting\") as pbar:\n      for i in pbar:\n          time.sleep(0.5)\n          pbar.set_description(f\"Step {i+1} completed\")\n  \n\n- **Custom Formatting:** Customize the appearance of the progress bar using `bar_format` to control the layout, colors, and displayed information.\n\n  python\n  from tqdm import tqdm\n  import time\n\n  for i in tqdm(range(5), bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}]\"):\n      time.sleep(0.5)\n  \n\n- **GUI Mode (Jupyter Notebooks):** Use `tqdm.notebook` for a more visually appealing progress bar in Jupyter notebooks.  Import `tqdm.notebook` rather than `tqdm`.\n\n  python\n  from tqdm.notebook import tqdm\n  import time\n\n  for i in tqdm(range(1000)):\n      time.sleep(0.001)\n  \n\n## 5. Common Pitfalls and Anti-Patterns\n\n- **Over-Updating:** Updating the progress bar too frequently is a common mistake.  This can significantly slow down your code.  Adjust `mininterval` and `maxinterval`, or use manual updates.\n\n- **Ignoring `leave=False` in Nested Loops:** Forgetting to set `leave=False` in nested loops can lead to cluttered output, making it difficult to read the progress of the outer loop.\n\n- **Not Closing the Progress Bar:**  If you're using manual control, ensure you close the progress bar with `pbar.close()` to release resources.\n\n- **Incorrect Total Value:** Providing an incorrect `total` value in the `tqdm()` constructor can lead to inaccurate progress display. Double-check the iterable's length.\n\n- **Using `print()` Within the Loop:** Using the standard `print()` function within the loop can disrupt the progress bar display.  Use `tqdm.write()` instead.\n\n## 6. Testing Approaches\n\n- **Unit Tests:** When using `tqdm` in functions, test the function's core logic independently of `tqdm`. If you need to verify `tqdm` output, consider capturing standard output for assertions, though this is generally less valuable than testing the core function logic.\n\n- **Integration Tests:** Ensure that `tqdm` integrates correctly with your data processing pipelines. Verify that the progress bars are displayed accurately and don't introduce unexpected performance bottlenecks.\n\n## 7. Tooling and Environment\n\n- **Development Tools:**  Use standard Python development tools like VS Code, PyCharm, or Jupyter Notebooks for working with `tqdm`.\n\n- **Linting and Formatting:** Adhere to PEP 8 style guidelines and use linters like `flake8` or `pylint` to maintain code quality. Format your code with `black` or `autopep8` for consistency.\n\n## 8. Example: Downloading Files with Progress\n\npython\nimport requests\nfrom tqdm import tqdm\n\n\ndef download_file(url, filename):\n    \"\"\"Downloads a file from a URL with a progress bar.\"\"\"\n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n        total_size = int(response.headers.get('content-length', 0))\n        block_size = 8192  # 8KB\n        with tqdm(desc=filename, total=total_size, unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n            with open(filename, 'wb') as f:\n                for data in response.iter_content(block_size):\n                    f.write(data)\n                    pbar.update(len(data))\n        print(f\"Download complete: {filename}\")\n    except requests.exceptions.RequestException as e:\n        print(f\"Error downloading {url}: {e}\")\n    except IOError as e:\n        print(f\"Error writing to file {filename}: {e}\")\n\n\n# Example usage:\nfile_url = \"https://www.example.com/large_file.zip\"  # Replace with an actual URL\nfile_name = \"large_file.zip\"\ndownload_file(file_url, file_name)\n\n\n## 9. Conclusion\n\nBy following these best practices, you can effectively leverage the `tqdm` library to create informative and efficient progress bars in your Python projects, improving the user experience and providing valuable insights into the execution of your code.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "tqdm.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "tqdm",
      "this",
      "rule",
      "file",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "using",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "tqdm",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-transformers",
    "description": "This rule set enforces best practices for developing with the transformers library, covering code organization, performance, security, and testing to promote maintainable and efficient NLP applications.",
    "author": "sanjeed5",
    "tags": [
      "transformers",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/transformers.mdc",
    "content": "- **Environment Management:**\n  - Use Conda or UV to create isolated environments for consistent dependencies across projects.\n  - Example (Conda): `conda create -n myenv python=3.12`\n  - Example (UV): `uv venv`\n  - Use `environment.yml` or `requirements.txt` to manage dependencies.\n  - Always use Python 3.12.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:** Adopt a modular structure for maintainability.\n    - `src/`: Source code.\n      - `models/`: Transformer model definitions.\n      - `data/`: Data loading and preprocessing.\n      - `training/`: Training scripts and utilities.\n      - `utils/`: Utility functions.\n    - `tests/`: Unit and integration tests.\n    - `notebooks/`: Experimentation and exploration notebooks.\n    - `scripts/`: Deployment and utility scripts.\n    - `config/`: Configuration files.\n  - **File Naming Conventions:**\n    - Use descriptive names: `model.py`, `data_loader.py`, `trainer.py`.\n    - Follow PEP 8 guidelines.\n  - **Module Organization:**\n    - Group related functions and classes into modules.\n    - Use clear and concise module names.\n  - **Component Architecture:**\n    - Implement modular components with well-defined interfaces.\n    - Use classes for stateful components, such as data loaders or model wrappers.\n  - **Code Splitting:**\n    - Split large files into smaller, manageable modules.\n    - Use lazy loading for large models or datasets to improve startup time.\n\n- **Model Training and Evaluation:**\n  - Implement a structured approach for training and evaluating models.\n  - Use Hugging Face Transformers for easy access to pre-trained models.\n  - Log experiments using MLflow or TensorBoard for tracking model performance and versioning.\n  - Create clear separation between training, validation, and test datasets to prevent data leakage.\n  - Use consistent evaluation metrics.\n\n- **Data Handling:**\n  - Preprocess data effectively using libraries like Hugging Face's tokenizers.\n  - Ensure proper tokenization and encoding.\n  - Manage large datasets efficiently with data loaders.\n  - Implement data validation to ensure data quality.\n\n- **Code Structure:**\n  - Organize code into reusable modules and functions.\n  - Follow a consistent naming convention and documentation style (PEP 8) for enhanced readability and collaboration.\n  - Always use classes instead of functions where appropriate to encapsulate state and behavior.\n  - Add docstrings to all functions, classes, and modules.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - Use the Factory pattern for creating different model architectures.\n    - Use the Strategy pattern for different training strategies.\n    - Use the Decorator pattern for adding functionality to models.\n  - **Recommended Approaches:**\n    - Use pipelines for common tasks like text classification or question answering.\n    - Leverage pre-trained models for transfer learning.\n  - **Anti-patterns:**\n    - Avoid hardcoding configurations.\n    - Avoid global variables.\n    - Avoid deeply nested code.\n  - **State Management:**\n    - Encapsulate state within classes.\n    - Use configuration files to manage hyperparameters.\n  - **Error Handling:**\n    - Implement try-except blocks for error handling.\n    - Log errors and warnings using the `logging` module.\n    - Raise informative exceptions.\n\n- **Performance Considerations:**\n  - Use appropriate batch sizes to optimize GPU utilization.\n  - Utilize mixed-precision training (FP16) for faster training and reduced memory consumption.\n  - Cache intermediate results to avoid redundant computations.\n  - Profile code using tools like `cProfile` to identify bottlenecks.\n  - Use optimized libraries like `torch.compile` when available.\n  - **Memory Management:**\n    - Release unused memory using `torch.cuda.empty_cache()`.\n    - Use data loaders with `num_workers` to parallelize data loading.\n  - **Bundle Size Optimization:**\n    - Remove unused dependencies.\n    - Use code minification and compression.\n  - **Lazy Loading:**\n    - Load models and datasets only when needed.\n    - Use `torch.jit.script` to compile model for inference.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - Input injection attacks.\n    - Model poisoning attacks.\n  - **Input Validation:**\n    - Validate input data to prevent injection attacks.\n    - Sanitize user input before feeding it to the model.\n  - **Authentication and Authorization:**\n    - Implement authentication and authorization for API endpoints.\n    - Use secure protocols like HTTPS for communication.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use appropriate access controls to protect data.\n  - **Secure API Communication:**\n    - Use API keys or tokens for authentication.\n    - Implement rate limiting to prevent abuse.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Test individual components in isolation.\n    - Use mocking to isolate dependencies.\n    - Cover all code paths with unit tests.\n  - **Integration Testing:**\n    - Test interactions between different components.\n    - Verify that data flows correctly through the system.\n  - **End-to-End Testing:**\n    - Test the entire application from end to end.\n    - Simulate user interactions to verify functionality.\n  - **Test Organization:**\n    - Organize tests into separate directories.\n    - Use descriptive test names.\n  - **Mocking and Stubbing:**\n    - Use mocking frameworks like `unittest.mock` to isolate dependencies.\n    - Stub out external API calls to prevent network access.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Incorrectly configuring tokenizers.\n    - Using outdated versions of the library.\n    - Not handling edge cases in data preprocessing.\n  - **Edge Cases:**\n    - Handling long sequences.\n    - Dealing with out-of-vocabulary words.\n  - **Version-Specific Issues:**\n    - Check the release notes for breaking changes.\n    - Test code with different versions of the library.\n  - **Compatibility Concerns:**\n    - Ensure compatibility with different hardware and software configurations.\n    - Check compatibility with other libraries.\n  - **Debugging Strategies:**\n    - Use debuggers like `pdb` to step through code.\n    - Use logging to track program execution.\n\n- **Tooling and Environment:**\n  - **Recommended Tools:**\n    - VS Code with Python extension.\n    - PyCharm.\n    - Jupyter Notebook.\n    - Debuggers: pdb, ipdb.\n  - **Build Configuration:**\n    - Use `setup.py` or `pyproject.toml` for build configuration.\n    - Specify dependencies in `requirements.txt` or `environment.yml`.\n  - **Linting and Formatting:**\n    - Use linters like `flake8` and `pylint` to enforce code style.\n    - Use formatters like `black` and `autopep8` to automatically format code.\n  - **Deployment:**\n    - Use Docker to containerize the application.\n    - Deploy to cloud platforms like AWS, Azure, or GCP.\n  - **CI/CD Integration:**\n    - Use CI/CD pipelines to automate testing and deployment.\n    - Integrate with version control systems like Git.\n\n- **Additional Recommendations:**\n  - Always document your code thoroughly.\n  - Write clear and concise commit messages.\n  - Use version control (Git) to track changes.\n  - Participate in the transformers community to learn from others.\n  - Regularly update the library to benefit from bug fixes and new features.\n\n- **References:**\n  - [Hugging Face Transformers Documentation](https://huggingface.co/transformers/)\n  - [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)\n  - [MLflow Documentation](https://www.mlflow.org/docs/latest/index.html)\n  - [BERT Fine-Tuning Tutorial with PyTorch](http://www.mccormickml.com)",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "transformers.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "transformers",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "developing",
      "with",
      "library",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "transformers",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-trio",
    "description": "This rule provides comprehensive best practices for developing with the Trio asynchronous I/O library in Python, covering code organization, performance, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "trio",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/trio.mdc",
    "content": "- Use `flake8-async` to check for issues in Trio code. `@file:flake8_async_rules.mdc`\n- Utilize Trio's nursery feature for managing concurrent tasks to prevent orphaned tasks and improve error handling. Use `async with trio.open_nursery() as nursery: nursery.start_soon(my_task)`. See Trio documentation for advanced usage.\n- Clearly distinguish between async and synchronous functions. Async functions should primarily be used for I/O-bound operations. CPU-bound tasks should run in separate processes or threads to avoid blocking the event loop.\n- Leverage Trio's testing utilities (`trio.testing`) to ensure that your async code behaves as expected. Use tools like `trio.testing.MockClock` to control time in tests.\n- Adhere to PEP 8 for consistent code formatting. Use a linter and formatter like `black` to ensure compliance.\n- Always use absolute imports for better readability and maintainability: `import mypkg.sibling`. Use explicit relative imports (`from . import sibling`) only when necessary in complex package layouts.\n- Avoid wildcard imports (`from <module> import *`).\n- Place module-level dunder names (e.g., `__all__`, `__author__`, `__version__`) after the module docstring but before any import statements (except `from __future__` imports).\n- Use 4 spaces for indentation.\n- Limit lines to a maximum of 79 characters (or 99 if agreed upon within a team). For docstrings and comments, limit lines to 72 characters.\n- Surround top-level function and class definitions with two blank lines. Method definitions inside a class are surrounded by a single blank line.\n- Use blank lines in functions to indicate logical sections.\n- Code in the core Python distribution should always use UTF-8.\n- Follow the naming conventions as described in PEP 8. Class names should use CapWords. Function and variable names should be lowercase with underscores.\n- Always use `self` for the first argument to instance methods and `cls` for the first argument to class methods.\n- Use one leading underscore for non-public methods and instance variables. Use two leading underscores to invoke Python’s name mangling for avoiding name clashes with subclasses.\n- Constants should be defined on a module level and written in all capital letters with underscores separating words.\n- Always decide whether a class’s methods and instance variables should be public or non-public. If in doubt, choose non-public.\n- Comparisons to singletons like `None` should always be done with `is` or `is not`, never the equality operators.\n- Use `is not` operator rather than `not ... is`.\n- When implementing ordering operations with rich comparisons, it is best to implement all six operations (`__eq__`, `__ne__`, `__lt__`, `__le__`, `__gt__`, `__ge__`).\n- Always use a `def` statement instead of an assignment statement that binds a lambda expression directly to an identifier.\n- Derive exceptions from `Exception` rather than `BaseException`. Design exception hierarchies based on the distinctions that code catching the exceptions is likely to need.\n- Use exception chaining appropriately (`raise X from Y`).\n- When catching exceptions, mention specific exceptions whenever possible instead of using a bare `except:` clause.\n- Limit the `try` clause to the absolute minimum amount of code necessary.\n- When a resource is local to a particular section of code, use a `with` statement to ensure it is cleaned up promptly and reliably after use.\n- Be consistent in return statements. Either all `return` statements in a function should return an expression, or none of them should.\n- Use `''.startswith()` and `''.endswith()` instead of string slicing to check for prefixes or suffixes.\n- Object type comparisons should always use `isinstance()` instead of comparing types directly.\n- For sequences (strings, lists, tuples), use the fact that empty sequences are false.\n- Don’t write string literals that rely on significant trailing whitespace.\n- Don’t compare boolean values to `True` or `False` using `==`.\n- Function annotations should use PEP 484 syntax.\n- Annotations for module-level variables, class and instance variables, and local variables should have a single space after the colon.\n\n## Code Organization and Structure\n\n- **Directory Structure:**\n    - A typical project structure might look like this:\n        \n        my_project/\n        ├── src/\n        │   ├── __init__.py\n        │   ├── main.py  # Entry point\n        │   ├── utils.py # Utility functions\n        │   ├── services/\n        │   │   ├── __init__.py\n        │   │   ├── http_service.py\n        │   │   └── db_service.py\n        │   └── models/\n        │       ├── __init__.py\n        │       └── user.py\n        ├── tests/\n        │   ├── __init__.py\n        │   ├── test_main.py\n        │   ├── test_utils.py\n        │   ├── services/\n        │   │   ├── test_http_service.py\n        │   │   └── test_db_service.py\n        │   └── models/\n        │       └── test_user.py\n        ├── README.md\n        ├── pyproject.toml  # Project configuration (poetry, pipenv)\n        └── .gitignore\n        \n    - Use a `src` directory to hold the main application code.  This helps separate application code from configuration and documentation.\n    - Keep tests in a separate `tests` directory, mirroring the structure of `src`.\n\n- **File Naming Conventions:**\n    - Use lowercase names for files and modules (e.g., `http_service.py`, `utils.py`).\n    - Test files should be prefixed with `test_` (e.g., `test_http_service.py`).\n\n- **Module Organization:**\n    - Organize code into logical modules based on functionality (e.g., `services`, `models`, `utils`).\n    - Use `__init__.py` files to make directories importable as packages.\n    - Avoid circular dependencies between modules.\n\n- **Component Architecture:**\n    - Consider using a layered architecture (e.g., presentation, business logic, data access) to separate concerns.\n    - Dependency Injection: Use dependency injection to make components more testable and reusable.\n\n- **Code Splitting:**\n    - Break down large modules into smaller, more manageable files.\n    - Consider splitting modules based on functionality or responsibilities.\n\n## Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Asynchronous Factory:**  Use factories to create asynchronous resources (e.g., connections) to manage initialization efficiently.\n        python\n        async def create_db_connection():\n            conn = await connect_to_db()\n            return conn\n        \n        async def main():\n            conn = await create_db_connection()\n            # Use the connection\n        \n    - **Resource Pooling:** Implement resource pooling for database connections or network connections to reduce overhead.\n\n- **Recommended Approaches:**\n    - Use nurseries for structured concurrency.\n    - Use streams (`trio.Stream`) for communication between tasks.\n    - Use channels (`trio.QueueChannel`) for passing data between tasks.\n\n- **Anti-patterns:**\n    - **Sleeping without Cancellation:** Avoid using `time.sleep()` directly, as it blocks the event loop and ignores cancellation. Use `await trio.sleep()` instead.\n    - **Long-Running Synchronous Operations:**  Don't perform CPU-bound operations directly in async functions. Offload them to separate threads or processes.\n    - **Ignoring Cancellation:** Ensure that your async functions handle cancellation requests (`trio.Cancelled`).\n    - **Unstructured Concurrency:**  Avoid spawning tasks without proper management (e.g., without using nurseries). This can lead to orphaned tasks and difficult debugging.\n\n- **State Management:**\n    - Immutable Data: Prefer immutable data structures to avoid race conditions and simplify reasoning about state.\n    - Task-Local Storage: Use `trio.TaskLocal` to store task-specific data.\n    - Thread-Safe Data Structures: If shared mutable state is necessary, use thread-safe data structures (e.g., `trio.Lock`, `trio.Semaphore`).\n\n- **Error Handling:**\n    - Use `try...except` blocks to handle exceptions within async functions.\n    - Propagate exceptions appropriately to the nursery for proper error handling.\n    - Consider using exception groups to handle multiple exceptions that occur concurrently.\n\n## Performance Considerations\n\n- **Optimization Techniques:**\n    - Minimize context switching:  Reduce unnecessary `await` calls.\n    - Use efficient data structures: Choose appropriate data structures for your specific use case.\n    - Avoid excessive copying:  Use views or iterators when possible to avoid copying large data structures.\n\n- **Memory Management:**\n    - Release resources promptly: Use `with` statements or `try...finally` blocks to ensure that resources are released even if exceptions occur.\n    - Avoid circular references: Be mindful of potential circular references, which can prevent garbage collection.\n\n## Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Race Conditions:**  Be aware of potential race conditions when accessing shared mutable state.\n    - **Cancellation Errors:** Improper cancellation handling can lead to resource leaks or incorrect program behavior.\n\n- **Input Validation:**\n    - Validate all external inputs to prevent injection attacks and other security vulnerabilities.\n    - Sanitize user inputs before using them in database queries or other sensitive operations.\n\n- **Authentication and Authorization:**\n    - Use established authentication and authorization libraries.\n    - Implement proper access controls to protect sensitive data.\n\n- **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure communication protocols (e.g., HTTPS).\n\n- **Secure API Communication:**\n    - Validate all API requests and responses.\n    - Implement rate limiting to prevent abuse.\n\n## Testing Approaches\n\n- **Unit Testing:**\n    - Use `trio.testing` to write unit tests for async functions.\n    - Use `trio.testing.MockClock` to control time in tests.\n    - Mock external dependencies to isolate the code being tested.\n\n- **Integration Testing:**\n    - Test the interaction between different components of your application.\n    - Use real or simulated external services to test the integration with external systems.\n\n- **End-to-End Testing:**\n    - Test the entire application flow from the user interface to the database.\n\n- **Test Organization:**\n    - Organize tests in a directory structure that mirrors the structure of your application code.\n    - Write clear and concise test names that describe the behavior being tested.\n\n- **Mocking and Stubbing:**\n    - Use mocking libraries like `unittest.mock` to replace external dependencies with mock objects.\n    - Use stubbing to provide predefined responses for external dependencies.\n\n## Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Blocking the event loop with synchronous operations.\n    - Ignoring cancellation requests.\n    - Using `time.sleep()` instead of `trio.sleep()`.\n    - Not handling exceptions properly.\n\n- **Edge Cases:**\n    - Handling timeouts and deadlines.\n    - Dealing with cancellation in complex workflows.\n    - Managing resources in the presence of exceptions and cancellations.\n\n- **Version-Specific Issues:**\n    - Be aware of any known bugs or limitations in specific versions of Trio.\n\n- **Compatibility Concerns:**\n    - Ensure compatibility between Trio and other libraries you are using.\n\n- **Debugging Strategies:**\n    - Use debuggers like `pdb` or `ipdb` to step through your code and inspect variables.\n    - Use logging to track the execution flow of your application.\n    - Use Trio's built-in debugging tools to identify performance bottlenecks and other issues.\n\n## Tooling and Environment\n\n- **Recommended Development Tools:**\n    - VS Code with the Python extension.\n    - PyCharm.\n    - IPython or Jupyter Notebook for interactive development.\n\n- **Build Configuration:**\n    - Use a build system like `poetry` or `pipenv` to manage dependencies.\n\n- **Linting and Formatting:**\n    - Use `flake8` and `black` to ensure consistent code style.\n    - Configure your editor to automatically format code on save.\n\n- **Deployment:**\n    - Use a process manager like `systemd` or `supervisor` to manage your application.\n\n- **CI/CD Integration:**\n    - Use CI/CD tools like GitHub Actions or GitLab CI to automate testing and deployment.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "trio.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "trio",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "asynchronous",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "trio",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-trpc",
    "description": "This rule provides comprehensive guidance on tRPC best practices, covering code organization, performance, security, testing, and common pitfalls to ensure robust and maintainable tRPC applications.",
    "author": "sanjeed5",
    "tags": [
      "trpc",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/trpc.mdc",
    "content": "# tRPC Best Practices: A Comprehensive Guide\n\nThis document outlines best practices for developing robust, maintainable, and efficient applications using tRPC (TypeScript Remote Procedure Call). It covers various aspects, from code organization to security considerations, providing actionable guidance for developers.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\n*   **Feature-Based Organization:** Organize your code around features or modules, rather than technical layers (e.g., `components`, `utils`, `services`).  This promotes modularity and maintainability. For example:\n\n    \n    src/\n    ├── features/\n    │   ├── user/\n    │   │   ├── components/\n    │   │   │   ├── UserProfile.tsx\n    │   │   │   └── UserSettings.tsx\n    │   │   ├── api/\n    │   │   │   ├── userRouter.ts  // tRPC router for user-related procedures\n    │   │   │   └── userSchema.ts // Zod schemas for input validation\n    │   │   ├── hooks/\n    │   │   │   └── useUser.ts    // Custom hooks for data fetching and state management\n    │   │   └── types/\n    │   │   │   └── user.ts        // TypeScript types related to users\n    │   ├── product/\n    │   │   └── ...\n    ├── utils/\n    │   ├── api.ts      // tRPC client initialization\n    │   └── db.ts       // Database connection/abstraction\n    ├── app/\n    │   ├── api/\n    │   │   └── root.ts   // Root tRPC router combining all feature routers\n    │   └── context.ts // tRPC context creation\n    └── index.ts      // Server entry point\n    \n\n*   **Separation of Concerns:**  Separate concerns into different directories and modules.  For instance, keep your tRPC router definitions separate from your business logic and data access layers.\n*   **Grouping Similar Functionality:**  Keep related files together within a feature directory.  This makes it easier to understand and maintain the code.\n\n### 1.2 File Naming Conventions\n\n*   **Descriptive Names:** Use descriptive names for files and directories that clearly indicate their purpose.\n*   **Consistent Case:**  Maintain a consistent casing convention (e.g., camelCase for variables, PascalCase for components). Use `kebab-case` for file names e.g. `user-profile.tsx` or `user.router.ts`\n*   **Suffixes:** Use suffixes to indicate the type of file (e.g., `.router.ts` for tRPC routers, `.schema.ts` for Zod schemas, `.component.tsx` for React components).\n\n### 1.3 Module Organization\n\n*   **Small Modules:**  Keep modules small and focused. A module should have a single responsibility. Aim for modules that are easy to understand and test.\n*   **Explicit Exports:** Use explicit exports to control what is exposed from a module. This helps to prevent accidental exposure of internal implementation details.\n*   **Circular Dependencies:** Avoid circular dependencies between modules. Circular dependencies can lead to unexpected behavior and make it difficult to reason about the code.\n\n### 1.4 Component Architecture\n\n*   **Presentational and Container Components:** Separate presentational (dumb) components from container (smart) components. Presentational components focus on rendering UI, while container components handle data fetching and state management. Use the term `view` instead of `component` in the file suffix can make a separation between React components and presentational components, e.g. `user-profile.view.tsx`\n*   **Reusable Components:** Design components to be reusable across different parts of the application. This reduces code duplication and improves maintainability.\n*   **Component Composition:** Favor component composition over inheritance. Composition allows you to create more flexible and reusable components.\n\n### 1.5 Code Splitting Strategies\n\n*   **Route-Based Splitting:** Split your code based on routes. This allows you to load only the code that is needed for a specific route. This can be easily achieved with React's `lazy` and `Suspense` APIs.\n*   **Component-Based Splitting:** Split your code based on components. This allows you to load only the code that is needed for a specific component.\n*   **Dynamic Imports:** Use dynamic imports to load code on demand. This can be useful for loading large libraries or components that are not needed immediately. \n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to tRPC\n\n*   **Router Composition:** Compose tRPC routers to create a hierarchical API structure. This allows you to organize your API into logical groups.\n\n    typescript\n    // src/app/api/routers/userRouter.ts\n    import { publicProcedure, router } from \"../trpc\";\n    import { z } from \"zod\";\n\n    export const userRouter = router({\n      getById: publicProcedure\n        .input(z.string())\n        .query(async ({ input }) => {\n          // ... fetch user by ID\n        }),\n      create: publicProcedure\n        .input(z.object({ name: z.string() }))\n        .mutation(async ({ input }) => {\n          // ... create a new user\n        }),\n    });\n\n    // src/app/api/root.ts\n    import { userRouter } from \"./routers/userRouter\";\n    import { productRouter } from \"./routers/productRouter\";\n\n    export const appRouter = router({\n      user: userRouter,\n      product: productRouter,\n    });\n\n    export type AppRouter = typeof appRouter;\n    \n\n*   **Middleware Chaining:** Use middleware to handle cross-cutting concerns such as authentication, authorization, and logging. Middleware can be chained to create a pipeline of operations.\n\n    typescript\n    // src/app/api/trpc.ts\n    import { initTRPC, TRPCError } from \"@trpc/server\";\n    import { Context } from \"./context\";\n\n    const t = initTRPC.context<Context>().create();\n    const isAuthed = t.middleware(({ ctx, next }) => {\n      if (!ctx.user) {\n        throw new TRPCError({ code: \"UNAUTHORIZED\" });\n      }\n      return next({\n        ctx: {\n          user: ctx.user,\n        },\n      });\n    });\n\n    export const router = t.router;\n    export const publicProcedure = t.procedure;\n    export const protectedProcedure = t.procedure.use(isAuthed);\n    \n\n*   **Input Validation with Zod:** Use Zod for input validation to ensure that data received from the client is valid. This helps to prevent errors and security vulnerabilities.\n\n    typescript\n    import { z } from \"zod\";\n    import { publicProcedure } from \"../trpc\";\n\n    export const createUserProcedure = publicProcedure\n      .input(z.object({ name: z.string().min(3), email: z.string().email() }))\n      .mutation(async ({ input }) => {\n        // ... create a new user\n      });\n    \n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Authentication:** Use tRPC middleware to authenticate users. Verify user credentials and set the user object in the context.\n*   **Authorization:** Use tRPC middleware to authorize users. Check if the user has the required permissions to access a resource.\n*   **Error Handling:** Use tRPC's built-in error handling mechanisms to handle errors gracefully. Throw `TRPCError` exceptions with appropriate error codes and messages.\n*   **Data Fetching:**  Use a data fetching library (e.g., Prisma, Drizzle ORM, Supabase) to interact with your database. Abstract data access logic into separate modules or services.\n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Over-fetching:** Avoid fetching more data than you need.  Use projections or GraphQL-style queries to fetch only the required fields.\n*   **Under-fetching:** Avoid making multiple API calls to fetch related data. Batch requests or use a data loader pattern to fetch related data in a single call.\n*   **Tight Coupling:** Avoid tight coupling between tRPC routers and your business logic.  Abstract business logic into separate modules or services.\n*   **Ignoring Errors:** Never ignore errors. Always handle errors gracefully and provide meaningful feedback to the client.\n*   **Direct Database Access in Routers:** Avoid accessing the database directly within tRPC router procedures. Instead, abstract data access into separate services or repositories.\n*   **Complex Business Logic in Routers:** Keep tRPC router procedures focused on routing and input validation. Move complex business logic to separate functions or modules.\n\n### 2.4 State Management Best Practices\n\n*   **Centralized State Management:** Use a centralized state management library (e.g., Zustand, Redux, Jotai) to manage application state. This makes it easier to share state between components and to reason about the application's state.\n*   **Immutable State:** Use immutable state to prevent unexpected side effects. This makes it easier to reason about the application's state and to debug issues.\n*   **Controlled Components:** Use controlled components to manage form state. This gives you more control over the form and makes it easier to validate input.\n*   **Server State Management:** Use a library like TanStack Query or SWR to manage server state (data fetched from the API). These libraries provide caching, optimistic updates, and other features that make it easier to manage server state.\n\n### 2.5 Error Handling Patterns\n\n*   **Centralized Error Handling:** Use a centralized error handling mechanism to handle errors consistently across the application.\n*   **Error Boundaries:** Use error boundaries to prevent errors from crashing the application. Error boundaries can catch errors that occur during rendering and display a fallback UI.\n*   **Logging:** Log errors to a central logging service. This makes it easier to track down and fix issues.\n*   **User-Friendly Error Messages:** Display user-friendly error messages to the user. Avoid displaying technical details or stack traces.\n*   **Retry Mechanism:** Implement a retry mechanism for transient errors. This can improve the resilience of the application.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Caching:** Implement caching to reduce the number of API calls. Cache data on the server and the client.\n*   **Compression:** Use compression to reduce the size of API responses. This can improve the performance of the application, especially on slow networks.\n*   **Code Splitting:** Split your code into smaller chunks to reduce the initial load time. Load code on demand as needed.\n*   **Debouncing and Throttling:** Use debouncing and throttling to reduce the number of API calls triggered by user input.\n*   **Efficient Data Structures:** Use efficient data structures to store and process data. Choose the right data structure for the task at hand.\n\n### 3.2 Memory Management\n\n*   **Avoid Memory Leaks:** Be careful to avoid memory leaks. Memory leaks can cause the application to slow down and eventually crash.\n*   **Garbage Collection:** Understand how garbage collection works in JavaScript. This can help you to avoid memory leaks and to optimize memory usage.\n*   **Use Weak References:** Use weak references to avoid keeping objects in memory longer than necessary.\n\n### 3.3 Rendering Optimization\n\n*   **Memoization:** Use memoization to avoid re-rendering components unnecessarily. Memoize components that receive the same props multiple times.\n*   **Virtualization:** Use virtualization to render large lists efficiently. Virtualization only renders the items that are visible on the screen.\n*   **Batch Updates:** Batch updates to reduce the number of re-renders. React's `useState` hook batches updates automatically.\n\n### 3.4 Bundle Size Optimization\n\n*   **Tree Shaking:** Use tree shaking to remove unused code from the bundle. This can significantly reduce the bundle size.\n*   **Code Minification:** Minify your code to reduce the bundle size. Minification removes whitespace and comments from the code.\n*   **Image Optimization:** Optimize images to reduce the bundle size. Use appropriate image formats and compress images.\n*   **Dependency Analysis:** Analyze your dependencies to identify large or unnecessary dependencies. Consider replacing large dependencies with smaller alternatives.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Lazy Load Images:** Lazy load images to improve the initial load time. Only load images when they are visible on the screen.\n*   **Lazy Load Components:** Lazy load components to improve the initial load time. Only load components when they are needed.\n*   **Lazy Load Modules:** Lazy load modules to improve the initial load time. Only load modules when they are needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by escaping user input and using a content security policy (CSP).\n*   **Cross-Site Request Forgery (CSRF):** Prevent CSRF attacks by using CSRF tokens. Most frameworks have built-in support for CSRF protection.\n*   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or an ORM.\n*   **Authentication and Authorization:** Implement strong authentication and authorization mechanisms to protect sensitive data.\n*   **Rate Limiting:** Implement rate limiting to prevent brute-force attacks.\n*   **Denial-of-Service (DoS):** Implement measures to prevent DoS attacks, such as rate limiting and input validation.\n\n### 4.2 Input Validation\n\n*   **Validate All Input:** Validate all input from the client, including query parameters, request bodies, and headers.\n*   **Use Strong Types:** Use strong types to define the expected format of input data. This can help to prevent type-related errors and security vulnerabilities. Tools like Zod are invaluable here.\n*   **Sanitize Input:** Sanitize input to remove potentially harmful characters or code. This can help to prevent XSS attacks.\n*   **Whitelist Input:** Whitelist allowed input values. This is more secure than blacklisting disallowed values.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **JWT (JSON Web Tokens):** Use JWTs for authentication. JWTs are a standard way to securely transmit information between parties as a JSON object.\n*   **OAuth 2.0:** Use OAuth 2.0 for authorization. OAuth 2.0 is a standard protocol for delegating access to resources.\n*   **Role-Based Access Control (RBAC):** Use RBAC to control access to resources based on user roles. This makes it easier to manage permissions and to enforce security policies.\n*   **Attribute-Based Access Control (ABAC):** Use ABAC to control access to resources based on user attributes. This provides more fine-grained control over access to resources.\n\n### 4.4 Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data at rest and in transit. Use strong encryption algorithms.\n*   **Hashing:** Hash passwords and other sensitive data. Use a strong hashing algorithm with a salt.\n*   **Data Masking:** Mask sensitive data in logs and other outputs. This prevents sensitive data from being exposed accidentally.\n*   **Data Redaction:** Redact sensitive data from API responses. This prevents sensitive data from being exposed to unauthorized users.\n\n### 4.5 Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication. HTTPS encrypts the communication between the client and the server, protecting it from eavesdropping and tampering.\n*   **CORS (Cross-Origin Resource Sharing):** Configure CORS to restrict access to your API from unauthorized domains. This helps to prevent cross-site scripting attacks.\n*   **Rate Limiting:** Implement rate limiting to prevent brute-force attacks and DoS attacks.\n*   **API Keys:** Use API keys to authenticate API clients. This helps to prevent unauthorized access to your API.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test Individual Functions and Modules:** Unit tests should focus on testing individual functions and modules in isolation.\n*   **Mock Dependencies:** Mock dependencies to isolate the code under test. This prevents external dependencies from interfering with the test.\n*   **Test Edge Cases:** Test edge cases to ensure that the code handles unexpected input correctly.\n*   **Test Error Handling:** Test error handling to ensure that the code handles errors gracefully.\n*   **Use Test-Driven Development (TDD):** Consider using TDD to write tests before writing code. This can help to improve the design of the code and to ensure that it is testable.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Modules:** Integration tests should focus on testing the interactions between modules. This ensures that the modules work together correctly.\n*   **Use Real Dependencies:** Use real dependencies in integration tests. This provides more realistic testing conditions.\n*   **Test Data Flow:** Test the data flow between modules to ensure that data is passed correctly.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Application:** End-to-end tests should focus on testing the entire application, from the user interface to the backend API.\n*   **Use a Test Automation Framework:** Use a test automation framework (e.g., Cypress, Playwright) to automate end-to-end tests. This makes it easier to run the tests and to verify that the application is working correctly.\n*   **Test User Flows:** Test common user flows to ensure that users can complete important tasks.\n\n### 5.4 Test Organization\n\n*   **Organize Tests by Feature:** Organize tests by feature. This makes it easier to find and run tests for a specific feature.\n*   **Keep Tests Separate from Code:** Keep tests separate from the code. This prevents tests from being included in the production bundle.\n*   **Use a Consistent Naming Convention:** Use a consistent naming convention for tests. This makes it easier to identify and understand the tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mocking Frameworks:** Use mocking frameworks (e.g., Jest, Sinon) to create mocks and stubs. This makes it easier to isolate the code under test.\n*   **Mock External Dependencies:** Mock external dependencies to prevent them from interfering with the test.\n*   **Stub API Responses:** Stub API responses to control the data that is returned by the API.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Not Validating Input:** Failing to validate input is a common mistake that can lead to errors and security vulnerabilities.\n*   **Ignoring Errors:** Ignoring errors can make it difficult to debug issues and can lead to unexpected behavior.\n*   **Over-Complicating Code:** Over-complicating code can make it difficult to understand and maintain.\n*   **Not Writing Tests:** Not writing tests can lead to bugs and can make it difficult to refactor the code.\n*   **Incorrect Context Usage:** Misunderstanding how the tRPC context works, especially when dealing with middleware and authentication.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **Empty Input:** Handle empty input gracefully. Provide default values or display an error message.\n*   **Invalid Input:** Handle invalid input gracefully. Display an error message to the user.\n*   **Network Errors:** Handle network errors gracefully. Display an error message to the user and provide a way to retry the request.\n*   **Server Errors:** Handle server errors gracefully. Display an error message to the user and log the error on the server.\n*   **Concurrency Issues:** Be aware of concurrency issues when dealing with shared resources. Use locks or other synchronization mechanisms to prevent data corruption.\n\n### 6.3 Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes when upgrading tRPC. Review the release notes carefully and update your code accordingly.\n*   **Deprecated Features:** Be aware of deprecated features. Replace deprecated features with the recommended alternatives.\n*   **Compatibility Issues:** Be aware of compatibility issues with other libraries. Test your code thoroughly after upgrading tRPC or other libraries.\n\n### 6.4 Compatibility Concerns\n\n*   **Browser Compatibility:** Ensure that your code is compatible with the browsers that you support.\n*   **Node.js Version Compatibility:** Ensure that your code is compatible with the Node.js versions that you support.\n*   **TypeScript Version Compatibility:** Ensure that your code is compatible with the TypeScript version that you are using.\n\n### 6.5 Debugging Strategies\n\n*   **Use Debugging Tools:** Use debugging tools (e.g., Chrome DevTools, VS Code debugger) to step through your code and inspect variables.\n*   **Add Logging Statements:** Add logging statements to your code to track the flow of execution and to identify errors.\n*   **Use a Debugger:** Use a debugger to pause the execution of your code and to inspect the state of the application.\n*   **Reproduce the Issue:** Try to reproduce the issue in a controlled environment. This makes it easier to identify the cause of the issue.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code:** Use VS Code as your IDE. VS Code provides excellent support for TypeScript and JavaScript development.\n*   **ESLint:** Use ESLint to enforce code style and to prevent errors.\n*   **Prettier:** Use Prettier to format your code automatically.\n*   **TypeScript Compiler:** Use the TypeScript compiler to compile your code.\n*   **npm or Yarn:** Use npm or Yarn to manage your dependencies.\n*   **Testing Framework:** Jest is a great testing framework\n\n### 7.2 Build Configuration\n\n*   **Use a Build Tool:** Use a build tool (e.g., Webpack, Parcel, Rollup) to bundle your code for production.\n*   **Configure the Build Tool:** Configure the build tool to optimize the bundle size, to minify the code, and to perform tree shaking.\n*   **Use Environment Variables:** Use environment variables to configure the build process.\n\n### 7.3 Linting and Formatting\n\n*   **Configure ESLint:** Configure ESLint to enforce code style and to prevent errors. Use a consistent code style across the entire project.\n*   **Configure Prettier:** Configure Prettier to format your code automatically. This ensures that the code is consistently formatted.\n*   **Use a Pre-Commit Hook:** Use a pre-commit hook to run ESLint and Prettier before committing code. This prevents code with style violations or errors from being committed.\n\n### 7.4 Deployment Best Practices\n\n*   **Use a Deployment Platform:** Use a deployment platform (e.g., Vercel, Netlify, AWS) to deploy your application.\n*   **Configure the Deployment Platform:** Configure the deployment platform to automatically deploy your application when changes are pushed to the repository.\n*   **Use Environment Variables:** Use environment variables to configure the deployment environment.\n*   **Monitor the Application:** Monitor the application to identify and resolve issues.\n\n### 7.5 CI/CD Integration\n\n*   **Use a CI/CD Tool:** Use a CI/CD tool (e.g., GitHub Actions, GitLab CI, CircleCI) to automate the build, test, and deployment process.\n*   **Configure the CI/CD Tool:** Configure the CI/CD tool to run tests, build the application, and deploy the application automatically.\n*   **Use Environment Variables:** Use environment variables to configure the CI/CD environment.\n\nBy adhering to these best practices, you can build robust, maintainable, and efficient applications using tRPC.",
    "metadata": {
      "globs": "*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "trpc.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "trpc",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidance",
      "best",
      "practices",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "trpc",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-turbopack",
    "description": "This rule provides comprehensive best practices for developing with Turbopack, covering code organization, performance, security, testing, and tooling to ensure efficient and maintainable applications.",
    "author": "sanjeed5",
    "tags": [
      "turbopack",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/turbopack.mdc",
    "content": "# Turbopack Best Practices\n\nThis document outlines best practices for developing with Turbopack, focusing on code organization, performance, security, testing, and tooling.\n\n## 1. Core Principles\n\n- **Leverage the Turbo Engine:** Turbopack's core strength lies in its Turbo engine for function-level caching. Understand and utilize this for incremental builds.\n- **Embrace Incremental Computation:** Be mindful of how changes affect the build process. Design your application to maximize incremental computation benefits.\n- **Use TypeScript:** Turbopack has built-in support for TypeScript and JSX, so use them to improve code quality and developer experience.  Make full use of TypeScript's features like generics, interfaces and types.\n- **Follow Next.js Conventions:** When using Turbopack within Next.js, adhere to Next.js's recommended patterns and practices.\n- **Avoid direct webpack configurations:** Turbopack aims to abstract away webpack configurations, prefer using Next.js configurations to customize Turbopack.\n\n## 2. Code Organization and Structure\n\n- **Directory Structure:**\n    - **`src/`:**  All application source code should reside within the `src/` directory.\n    - **`components/`:** Reusable UI components.\n    - **`pages/`:**  (Next.js) Pages for routing.\n    - **`api/`:** (Next.js) API routes.\n    - **`lib/` or `utils/`:** Utility functions and shared logic.\n    - **`types/` or `interfaces/`:** TypeScript type definitions and interfaces.\n    - **`styles/` or `css/`:** Global styles and CSS modules.\n    - **`public/`:** Static assets (images, fonts, etc.).\n- **File Naming Conventions:**\n    - Use descriptive names for files and directories.\n    - Component files: `ComponentName.jsx` or `ComponentName.tsx`.\n    - Style files: `ComponentName.module.css` or `ComponentName.module.scss`.\n    - Utility files: `utilityName.js` or `utilityName.ts`.\n- **Module Organization:**\n    - Group related code into modules with clear responsibilities.\n    - Export only what is necessary from each module.\n    - Use ES modules (import/export) for modularity.\n- **Component Architecture:**\n    - **Atomic Design:** Consider using Atomic Design principles to create a scalable and maintainable component architecture.\n    - **Composition:** Favor composition over inheritance for component reusability.\n    - **Separation of Concerns:**  Separate UI logic, data fetching, and state management within components.\n    - **Keep components small:** Focus on single responsability principle.\n- **Code Splitting Strategies:**\n    - **Dynamic Imports:** Use dynamic imports (`import()`) to split code into smaller chunks that are loaded on demand.\n    - **Route-Based Splitting:** (Next.js) Each page in the `pages/` directory is automatically code-split.\n    - **Component-Based Splitting:** Split large components into smaller, lazily loaded sub-components.\n    - **Vendor Splitting:** Turbopack automatically splits vendor code (third-party libraries) into separate chunks. \n\n## 3. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Higher-Order Components (HOCs):** Reusable logic for components (use with caution, consider hooks).\n    - **Render Props:** Sharing code between React components using a prop whose value is a function.\n    - **Hooks:**  Reusable stateful logic for functional components.\n    - **Context API:**  Share data that is considered \"global\" for a tree of React components.\n- **Recommended Approaches:**\n    - **Data Fetching:** Use `getServerSideProps`, `getStaticProps`, or `getInitialProps` (Next.js) for data fetching depending on your requirements.\n    - **API Routes:** Use Next.js API routes to create serverless functions for handling API requests.\n    - **State Management:** Choose a state management library (Redux, Zustand, Jotai, Recoil) based on the complexity of your application.\n- **Anti-patterns:**\n    - **Global State Mutation:** Avoid directly mutating global state, use reducers or state management libraries.\n    - **Over-Fetching:** Fetch only the data that is needed by a component.\n    - **Tight Coupling:**  Reduce dependencies between modules to improve maintainability.\n    - **Long Component Files:** Avoid having components larger than 200-300 lines, break down them into smaller components.\n- **State Management Best Practices:**\n    - **Centralized State:** Manage application state in a central store.\n    - **Immutability:** Treat state as immutable to prevent unexpected side effects.\n    - **Reducers:** Use reducers to update state based on actions.\n    - **Selectors:** Use selectors to derive data from the state.\n- **Error Handling Patterns:**\n    - **Error Boundaries:**  Use error boundaries to catch JavaScript errors anywhere in a component tree.\n    - **Centralized Error Logging:**  Log errors to a central service for monitoring and debugging.\n    - **Graceful Degradation:**  Handle errors gracefully and provide informative messages to the user.\n    - **Retry mechanisms:** Implement retry mechanisms for failed requests.\n\n## 4. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Caching:** Leverage Turbopack's caching capabilities to avoid unnecessary re-builds.\n    - **Memoization:** Use `React.memo` or `useMemo` to memoize components and values.\n    - **Debouncing and Throttling:** Use debouncing and throttling to reduce the frequency of function calls.\n- **Memory Management:**\n    - **Avoid Memory Leaks:**  Be careful to clean up event listeners and timers when components unmount.\n    - **Garbage Collection:**  Understand how JavaScript garbage collection works and avoid creating unnecessary objects.\n- **Rendering Optimization:**\n    - **Virtualization:** Use virtualization libraries for rendering large lists.\n    - **Code Splitting:** Split the codebase into smaller chunks using dynamic imports for faster initial load times.\n    - **Image Optimization:** Optimize images using tools like `next/image` or `cloudinary`.\n- **Bundle Size Optimization:**\n    - **Tree Shaking:**  Remove unused code from the bundle by using ES modules and configuring your bundler correctly.\n    - **Minification:** Minify JavaScript and CSS code to reduce bundle size.\n    - **Compression:** Compress assets using gzip or Brotli.\n- **Lazy Loading Strategies:**\n    - **Component-Level Lazy Loading:**  Lazy load components that are not initially visible.\n    - **Image Lazy Loading:**  Lazy load images that are not initially visible.\n    - **Route-Based Lazy Loading:**  Lazy load routes that are not frequently visited.\n\n## 5. Security Best Practices\n\n- **Common Vulnerabilities:**\n    - **Cross-Site Scripting (XSS):**  Prevent XSS attacks by sanitizing user input and using appropriate escaping techniques.\n    - **Cross-Site Request Forgery (CSRF):**  Prevent CSRF attacks by using CSRF tokens.\n    - **SQL Injection:**  Prevent SQL injection attacks by using parameterized queries or ORMs.\n    - **Authentication and Authorization Issues:**  Secure your API endpoints with proper authentication and authorization mechanisms.\n- **Input Validation:**\n    - **Validate all user input:** Sanitize and validate all user input on both the client and server.\n    - **Use appropriate data types:** Enforce data types to prevent unexpected values.\n- **Authentication and Authorization Patterns:**\n    - **JSON Web Tokens (JWT):**  Use JWTs for authentication and authorization.\n    - **Role-Based Access Control (RBAC):**  Implement RBAC to control access to resources based on user roles.\n    - **OAuth:**  Use OAuth for third-party authentication.\n- **Data Protection Strategies:**\n    - **Encryption:** Encrypt sensitive data at rest and in transit.\n    - **Data Masking:** Mask sensitive data in logs and reports.\n    - **Data Retention Policies:**  Implement data retention policies to ensure compliance with regulations.\n- **Secure API Communication:**\n    - **HTTPS:**  Use HTTPS to encrypt communication between the client and server.\n    - **Rate Limiting:**  Implement rate limiting to prevent abuse and denial-of-service attacks.\n    - **API Keys:**  Use API keys for authentication.\n\n## 6. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - **Test individual components and functions:**  Write unit tests to verify the behavior of individual components and functions.\n    - **Use mocking and stubbing:**  Use mocking and stubbing to isolate components from their dependencies.\n    - **Test edge cases:**  Test edge cases and error conditions.\n- **Integration Testing:**\n    - **Test the interaction between components:**  Write integration tests to verify the interaction between components.\n    - **Test data flow:**  Test the flow of data between components and services.\n- **End-to-End Testing:**\n    - **Test the entire application flow:**  Write end-to-end tests to verify the entire application flow.\n    - **Use browser automation tools:**  Use browser automation tools like Cypress or Puppeteer.\n- **Test Organization:**\n    - **Keep tests close to the code:**  Organize tests in the same directory as the code they test.\n    - **Use descriptive test names:**  Use descriptive test names that clearly describe what the test is verifying.\n- **Mocking and Stubbing:**\n    - **Use mocking libraries:**  Use mocking libraries like Jest or Sinon to create mocks and stubs.\n    - **Avoid over-mocking:**  Mock only the dependencies that are necessary.\n\n## 7. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - **Incorrectly configured `tsconfig.json`:** Ensure paths and baseUrl are correctly configured for absolute imports.\n    - **Misunderstanding caching:** Not utilizing Turbopack's caching efficiently, leading to slower builds.\n    - **Not using TypeScript features**: Not leveraging the benefits of Typescript and writing javascript code that misses out on typesafety.\n- **Edge Cases:**\n    - **Complex dependencies:**  Be aware of how complex dependencies can affect build times.\n    - **Large file sizes:**  Optimize large file sizes to improve performance.\n- **Version-Specific Issues:**\n    - **Breaking changes:**  Be aware of breaking changes in Turbopack and Next.js releases.\n    - **Compatibility issues:**  Ensure that your dependencies are compatible with the versions of Turbopack and Next.js that you are using.\n- **Compatibility Concerns:**\n    - **Browser compatibility:**  Test your application in different browsers to ensure compatibility.\n    - **Device compatibility:**  Test your application on different devices to ensure compatibility.\n- **Debugging Strategies:**\n    - **Use debugging tools:**  Use browser developer tools and debugging tools to identify and fix issues.\n    - **Log statements:**  Use log statements to track the flow of execution and identify errors.\n    - **Reproducible steps:**  Create reproducible steps to help isolate and fix issues.\n\n## 8. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **VS Code:**  A popular code editor with excellent support for JavaScript, TypeScript, and React.\n    - **ESLint:**  A linter that helps you identify and fix code style issues.\n    - **Prettier:**  A code formatter that automatically formats your code.\n    - **Chrome Developer Tools:** Powerful tools for debugging and profiling web applications.\n- **Build Configuration:**\n    - **Configure `tsconfig.json`:** Configure `tsconfig.json` to enable TypeScript features and specify compiler options.\n    - **Configure ESLint:** Configure ESLint to enforce code style guidelines.\n    - **Configure Prettier:** Configure Prettier to automatically format code.\n- **Linting and Formatting:**\n    - **Use ESLint and Prettier:**  Use ESLint and Prettier to automatically lint and format your code.\n    - **Integrate with your editor:**  Integrate ESLint and Prettier with your code editor to automatically lint and format code on save.\n- **Deployment Best Practices:**\n    - **Use a CI/CD pipeline:**  Use a CI/CD pipeline to automate the build, test, and deployment process.\n    - **Deploy to a CDN:**  Deploy static assets to a CDN for faster delivery.\n    - **Monitor your application:**  Monitor your application for errors and performance issues.\n- **CI/CD Integration:**\n    - **Use GitHub Actions, GitLab CI, or CircleCI:**  Use a CI/CD platform to automate the build, test, and deployment process.\n    - **Run tests in CI/CD:**  Run tests in your CI/CD pipeline to ensure that code changes do not introduce new bugs.\n    - **Automate deployments:**  Automate deployments to production and staging environments.\n\n## 9. Additional Considerations\n\n- **Experimentation:** Turbopack is rapidly evolving. Experiment with new features and configurations to optimize your build process.\n- **Community Engagement:** Participate in the Turbopack community to share your experiences and learn from others.\n- **Documentation:**  Refer to the official Turbopack documentation for the latest information and guidance.\n\nBy following these best practices, you can leverage the full potential of Turbopack to build high-performance, maintainable, and secure applications.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "turbopack.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "turbopack",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "turbopack",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-typer",
    "description": "This rule provides best practices and coding standards for developing command-line interfaces (CLIs) using the Typer library in Python. It includes guidelines for code organization, performance, security, and testing, aiming to enhance usability and maintainability.",
    "author": "sanjeed5",
    "tags": [
      "typer",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/typer.mdc",
    "content": "- Always use UV when installing depdendencies\n- Always use python 3.12\n- Always use classes instead of function\n\n# Typer CLI Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing command-line interfaces (CLIs) using the Typer library in Python. Following these guidelines will help you create robust, user-friendly, and maintainable CLIs.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure Best Practices\n\nAdopt a structured directory layout to improve code discoverability and maintainability. A typical project structure might look like this:\n\n\nmy_cli_project/\n├── my_cli/\n│   ├── __init__.py\n│   ├── main.py          # Main application logic\n│   ├── commands/        # Subcommands (if applicable)\n│   │   ├── __init__.py\n│   │   ├── command1.py\n│   │   └── command2.py\n│   ├── utils/           # Utility functions\n│   │   ├── __init__.py\n│   │   └── helpers.py\n│   └── models/          # Data models (if applicable)\n│   │   ├── __init__.py\n│   │   └── data_models.py\n├── tests/             # Unit and integration tests\n│   ├── __init__.py\n│   ├── test_main.py\n│   ├── test_commands.py\n│   └── conftest.py     # pytest configuration\n├── README.md\n├── pyproject.toml    # Project metadata and dependencies\n└── .gitignore\n\n\n*   **`my_cli/`**: Main package directory.\n*   **`my_cli/main.py`**: Entry point of the CLI application, where Typer app is initialized.\n*   **`my_cli/commands/`**: Directory for organizing subcommands into separate modules.\n*   **`my_cli/utils/`**: Helper functions and utilities used throughout the application.\n*   **`my_cli/models/`**: Data models and schemas used by the CLI.\n*   **`tests/`**: Contains all tests for the application.\n*   **`README.md`**: Project documentation.\n*   **`pyproject.toml`**: Project metadata and dependencies (using Poetry or similar).\n*   **.gitignore**: Specifies intentionally untracked files that Git should ignore.\n\n### 1.2. File Naming Conventions\n\n*   Use descriptive and consistent file names.\n*   Main application file: `main.py`\n*   Subcommand modules: `command_name.py`\n*   Utility modules: `helpers.py`, `utils.py`\n*   Model definitions: `models.py`, `data_models.py`\n*   Test files: `test_module_name.py`\n\n### 1.3. Module Organization Best Practices\n\n*   **Single Responsibility Principle**: Each module should have a single, well-defined purpose.\n*   **Clear Interfaces**: Define clear interfaces between modules to minimize dependencies.\n*   **Avoid Circular Dependencies**: Be mindful of circular dependencies between modules, which can lead to import errors and code that is difficult to reason about.\n*   **Use Packages**: Organize modules into packages using `__init__.py` files to create a hierarchical structure.\n\n### 1.4. Component Architecture Recommendations\n\n*   **Typer App Initialization**: Create a Typer app instance in `main.py`.\n*   **Subcommand Grouping**: Group related commands using Typer's `@app.command()` decorator.\n*   **Dependency Injection**: Use dependency injection to provide dependencies to command functions.\n*   **Configuration Management**: Load configuration from environment variables or configuration files.\n\n### 1.5. Code Splitting Strategies\n\n*   **Subcommands as Modules**: Split subcommands into separate modules within the `commands/` directory.\n*   **Utility Functions**: Extract reusable utility functions into the `utils/` directory.\n*   **Data Models**: Define data models in the `models/` directory.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns\n\n*   **Command Pattern**: Typer inherently implements the command pattern, where each CLI command is a separate executable action.\n*   **Dependency Injection**: Inject dependencies into command functions using Typer's type hinting system.\n*   **Configuration Pattern**: Load configuration from environment variables or configuration files using a dedicated configuration module.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Argument Parsing**: Utilize Typer's built-in argument parsing capabilities using type hints and decorators.\n*   **Subcommands**: Organize commands into subcommands for complex CLIs using `@app.command()` decorator.\n*   **Help Messages**: Customize help messages using docstrings for commands and parameters.\n*   **Error Handling**: Implement robust error handling using `try...except` blocks and custom exception classes.\n\n### 2.3. Anti-patterns and Code Smells\n\n*   **God Object**: Avoid creating a single, monolithic command function that handles too many responsibilities.\n*   **Magic Numbers**: Avoid hardcoding values directly in the code. Use constants or configuration variables instead.\n*   **Duplicated Code**: Extract reusable code into utility functions or classes.\n*   **Ignoring Errors**: Always handle errors gracefully and provide informative error messages to the user.\n\n### 2.4. State Management Best Practices\n\n*   **Stateless Commands**: Design commands to be stateless whenever possible. Pass all necessary data as arguments.\n*   **Context Objects**: Use Typer's context object to share state between commands.\n*   **External Storage**: Store persistent state in a database or configuration file.\n\n### 2.5. Error Handling Patterns\n\n*   **Try...Except Blocks**: Use `try...except` blocks to catch exceptions and handle errors gracefully.\n*   **Custom Exceptions**: Define custom exception classes for specific error conditions.\n*   **Logging**: Log errors and warnings to a file or console for debugging purposes.\n*   **Informative Error Messages**: Provide clear and informative error messages to the user.\n*   **Exit Codes**: Return appropriate exit codes to indicate success or failure.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Lazy Loading**: Use lazy loading to defer the loading of modules and resources until they are actually needed.\n*   **Caching**: Cache frequently accessed data to reduce the number of database queries or API calls.\n*   **Profiling**: Profile the code to identify performance bottlenecks and optimize them.\n*   **Asynchronous Operations**: Use asynchronous operations for I/O-bound tasks to improve responsiveness.\n\n### 3.2. Memory Management Considerations\n\n*   **Resource Cleanup**: Ensure that resources are properly released after use to prevent memory leaks.\n*   **Data Structures**: Use efficient data structures to minimize memory usage.\n*   **Generators**: Use generators to process large datasets in a memory-efficient manner.\n\n### 3.3. Bundle Size Optimization\n\n*   **Dependency Management**: Minimize the number of dependencies to reduce the bundle size.\n*   **Code Minification**: Minify the code to reduce its size.\n\n### 3.4. Lazy Loading Strategies\n\n*   **Conditional Imports**: Use conditional imports to load modules only when they are needed.\n*   **Dynamic Loading**: Use dynamic loading to load modules at runtime.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and Prevention\n\n*   **Command Injection**: Prevent command injection by validating user input and avoiding the use of `os.system` or `subprocess.call` with untrusted input.\n*   **Path Traversal**: Prevent path traversal by validating file paths and ensuring that users cannot access files outside of authorized directories.\n*   **Denial of Service (DoS)**: Prevent DoS attacks by limiting resource consumption and implementing rate limiting.\n\n### 4.2. Input Validation Best Practices\n\n*   **Type Checking**: Use Typer's type hinting system to enforce type checking of user input.\n*   **Regular Expressions**: Use regular expressions to validate user input against specific patterns.\n*   **Range Validation**: Validate that numerical input falls within acceptable ranges.\n*   **Whitelisting**: Whitelist allowed values for user input.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **API Keys**: Use API keys to authenticate users and authorize access to resources.\n*   **OAuth 2.0**: Implement OAuth 2.0 for more complex authentication and authorization scenarios.\n*   **Role-Based Access Control (RBAC)**: Implement RBAC to control access to resources based on user roles.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption**: Encrypt sensitive data at rest and in transit.\n*   **Hashing**: Hash passwords and other sensitive data before storing them.\n*   **Secure Storage**: Store sensitive data in a secure storage location, such as a password manager or a hardware security module (HSM).\n\n### 4.5. Secure API Communication\n\n*   **HTTPS**: Use HTTPS to encrypt communication between the CLI and the API.\n*   **TLS/SSL**: Use TLS/SSL certificates to verify the identity of the API server.\n*   **Input Sanitization**: Sanitize data received from APIs to prevent cross-site scripting (XSS) attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Test-Driven Development (TDD)**: Write unit tests before writing the code.\n*   **Mocking and Stubbing**: Use mocking and stubbing to isolate units of code and test them in isolation.\n*   **Assertion Libraries**: Use assertion libraries like `pytest` or `unittest` to write clear and concise assertions.\n\n### 5.2. Integration Testing Approaches\n\n*   **Test Command Interactions**: Verify that commands interact correctly with each other.\n*   **Test Database Interactions**: Verify that the CLI interacts correctly with the database.\n*   **Test API Interactions**: Verify that the CLI interacts correctly with the API.\n\n### 5.3. End-to-End Testing Recommendations\n\n*   **Automated Testing**: Automate end-to-end tests using tools like `Selenium` or `Playwright`.\n*   **Real-World Scenarios**: Test the CLI in real-world scenarios to ensure that it meets the needs of users.\n\n### 5.4. Test Organization Best Practices\n\n*   **Separate Test Files**: Create separate test files for each module or component.\n*   **Descriptive Test Names**: Use descriptive test names to make it easy to understand what each test is testing.\n*   **Test Fixtures**: Use test fixtures to set up and tear down test environments.\n\n### 5.5. Mocking and Stubbing Techniques\n\n*   **Mock External Dependencies**: Mock external dependencies like databases, APIs, and file systems.\n*   **Stub Function Calls**: Stub function calls to control the behavior of dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes\n\n*   **Ignoring Exit Codes**: Not checking exit codes of subprocesses can lead to undetected errors.\n*   **Incorrect Argument Parsing**: Mishandling of arguments leads to unexpected behavior.\n*   **Lack of Input Validation**: Failing to validate user input can lead to security vulnerabilities.\n\n### 6.2. Edge Cases\n\n*   **Handling Large Files**: Properly handle large files to avoid memory issues.\n*   **Internationalization (i18n)**: Be aware of character encoding issues.\n*   **Timezone Handling**: Ensure correct timezone handling when displaying or processing time-related data.\n\n### 6.3. Version-Specific Issues\n\n*   **Check Typer Versions**: Be aware of compatibility issues between different Typer versions.\n*   **Dependency Conflicts**:  Resolve conflicts between Typer and other dependencies.\n\n### 6.4. Compatibility Concerns\n\n*   **Operating System Compatibility**: Ensure that the CLI is compatible with different operating systems (Linux, macOS, Windows).\n*   **Python Version Compatibility**: Ensure that the CLI is compatible with different Python versions (3.7, 3.8, 3.9, etc.).\n\n### 6.5. Debugging Strategies\n\n*   **Logging**: Use logging to track the flow of execution and identify errors.\n*   **Debugging Tools**: Use debugging tools like `pdb` to step through the code and inspect variables.\n*   **Error Messages**: Pay attention to error messages and stack traces to identify the source of errors.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **Text Editor**: Use a text editor like VS Code, Sublime Text, or Atom.\n*   **IDE**: Use an IDE like PyCharm for advanced features like debugging and code completion.\n*   **Virtual Environment**: Use a virtual environment to isolate project dependencies.\n*   **Poetry or pip**: Use Poetry or pip for dependency management.\n\n### 7.2. Build Configuration Best Practices\n\n*   **pyproject.toml**: Use `pyproject.toml` to specify project metadata and dependencies.\n*   **setup.py**: Use `setup.py` to package the CLI for distribution.\n\n### 7.3. Linting and Formatting\n\n*   **Flake8**: Use Flake8 to lint the code and enforce coding style guidelines.\n*   **Black**: Use Black to automatically format the code.\n*   **mypy**: Use mypy for static type checking.\n\n### 7.4. Deployment Best Practices\n\n*   **Packaging**: Package the CLI using `setuptools` or `Poetry`.\n*   **Distribution**: Distribute the CLI using PyPI or other package repositories.\n\n### 7.5. CI/CD Integration\n\n*   **GitHub Actions**: Use GitHub Actions for CI/CD pipelines.\n*   **Testing**: Run unit and integration tests in the CI/CD pipeline.\n*   **Deployment**: Deploy the CLI automatically to PyPI or other package repositories.\n\n## 8. Additional Tips\n\n*   **Naming Conventions**:  Command names should be intuitive, starting with a lowercase letter and avoiding single-letter commands. Aim for meaningful names that are easy to remember while keeping them short and avoiding conflicts with existing commands.\n*   **Exit Codes**: Adhere to standard exit codes where `0` indicates success and non-zero values indicate errors. This is crucial for interoperability with other command-line tools and CI/CD systems.\n*   **Argument Parsing**: Utilize Typer for argument parsing instead of the built-in `argparse`, as it provides a more user-friendly experience and better support for features like subcommands and automatic help generation.\n*   **Help and Documentation**: Implement comprehensive help messages and support for both `-h` and `--help` options. Clear documentation improves user experience and reduces confusion.\n*   **Standard Input/Output**: Design your CLI to read from standard input (stdin) and write to standard output (stdout) and standard error (stderr) appropriately. This allows your tool to be easily integrated into pipelines.\n\nBy following these guidelines, you can create robust, user-friendly, and maintainable CLIs using the Typer library in Python.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "typer.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "typer",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "command",
      "line",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "typer",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-typescript",
    "description": "Enforces best practices for TypeScript development, including coding standards, performance considerations, and common pitfalls. This rule provides actionable guidance for developers to write clean, maintainable, and scalable TypeScript code.",
    "author": "sanjeed5",
    "tags": [
      "typescript",
      "javascript",
      "types",
      "cursor",
      "cursor-rule",
      "mdc",
      "type-safety",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/typescript.mdc",
    "content": "# TypeScript Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for developing TypeScript applications. Following these guidelines will help ensure code quality, maintainability, and scalability.\n\n## 1. Code Organization and Structure\n\n- **Directory Structure:**\n    - **Feature-based:** Group files related to a specific feature within a dedicated directory.\n    \n    src/\n    ├── feature1/\n    │   ├── components/\n    │   │   ├── ComponentA.tsx\n    │   │   └── ComponentB.tsx\n    │   ├── services/\n    │   │   └── feature1.service.ts\n    │   ├── types.ts\n    │   └── feature1.module.ts\n    ├── feature2/ \n    │   └── ...\n    └── shared/\n        ├── components/\n        │   └── ReusableComponent.tsx\n        ├── services/\n        │   └── api.service.ts\n        └── types/\n            └── global.d.ts\n    \n    - **Type-based:**  Separate files based on their role (components, services, types, etc.).\n    \n    src/\n    ├── components/\n    │   ├── Feature1Component.tsx\n    │   └── Feature2Component.tsx\n    ├── services/\n    │   ├── feature1.service.ts\n    │   └── feature2.service.ts\n    ├── types/\n    │   ├── feature1.types.ts\n    │   └── feature2.types.ts\n    └── modules/\n        ├── feature1.module.ts\n        └── feature2.module.ts\n    \n    - Choose the structure that best fits your project's complexity and team's preferences.  Consistency is key.\n\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names.\n    - Components: `ComponentName.tsx`\n    - Services: `serviceName.service.ts`\n    - Types: `typeName.types.ts` or `types.ts` (if grouping related types)\n    - Modules: `moduleName.module.ts`\n    - Interfaces: `IInterfaceName.ts` (or `interfaceName.interface.ts` if preferred and consistent throughout the codebase)\n\n- **Module Organization:**\n    - Use ES Modules (`import`/`export`) for modularity and reusability.\n    - Favor named exports over default exports for better discoverability and refactoring.\n    - Group related functionality into modules.\n    - Avoid circular dependencies.\n\n- **Component Architecture:**\n    - Consider using component-based architectures like React, Angular, or Vue.js.\n    - Follow component design principles: Single Responsibility Principle, separation of concerns.\n    - Use composition over inheritance.\n    - Keep components small and focused.\n\n- **Code Splitting Strategies:**\n    - Split your application into smaller chunks to improve initial load time.\n    - Implement lazy loading for modules and components that are not immediately needed.\n    - Use dynamic imports (`import()`).\n    - Webpack, Parcel, and other bundlers offer built-in support for code splitting.\n\n## 2. Common Patterns and Anti-patterns\n\n- **Design Patterns:**\n    - **Factory Pattern:**  Use factories to create objects with complex initialization logic.\n    - **Singleton Pattern:**  Use sparingly, and only when a single instance is truly required.\n    - **Observer Pattern:**  Implement reactive patterns for handling events and data changes.\n    - **Strategy Pattern:**  Define a family of algorithms and encapsulate each one into a separate class.\n    - **Dependency Injection:** Reduce coupling by injecting dependencies into components and services.\n\n- **Recommended Approaches:**\n    - **Data Fetching:** Use libraries like `axios` or `fetch` for making API requests.\n    - **State Management:** Choose a state management solution appropriate for your application's complexity (e.g., React Context, Redux, Zustand, MobX).\n    - **Form Handling:** Use libraries like `react-hook-form` or `formik` for managing form state and validation.\n\n- **Anti-patterns and Code Smells:**\n    - **`any` type overuse:** Avoid using `any` as much as possible. Use more specific types or generics.\n    - **Long methods/functions:** Break down large functions into smaller, more manageable units.\n    - **Deeply nested code:** Refactor deeply nested code to improve readability.\n    - **Magic numbers/strings:** Use constants for values that have a specific meaning.\n    - **Duplicated code:** Extract common logic into reusable functions or components.\n    - **Ignoring errors:** Always handle errors gracefully.  Don't just catch and ignore them.\n    - **Over-commenting:** Write self-documenting code and use comments only when necessary to explain complex logic.\n\n- **State Management Best Practices:**\n    - Choose a state management library based on project needs: React Context API, Redux, Zustand, MobX.\n    - Keep state minimal and derive values where possible.\n    - Follow immutable update patterns (especially with Redux).\n    - Use selectors to access state.\n    - Centralize state logic.\n\n- **Error Handling Patterns:**\n    - Use `try...catch` blocks to handle potential errors.\n    - Implement a global error handler to catch unhandled exceptions.\n    - Use error logging to track errors in production.\n    - Use discriminated unions for representing different error states.\n    - Implement retry mechanisms for transient errors.\n\n## 3. Performance Considerations\n\n- **Optimization Techniques:**\n    - **Memoization:** Use memoization techniques (e.g., `React.memo`, `useMemo`) to avoid unnecessary re-renders.\n    - **Debouncing and Throttling:** Limit the rate at which functions are executed in response to user input.\n    - **Virtualization:** Use virtualization for rendering large lists or tables.\n    - **Code Splitting:** Split your code into smaller chunks to reduce initial load time.\n\n- **Memory Management:**\n    - Avoid memory leaks by properly cleaning up resources (e.g., event listeners, timers).\n    - Use weak references to avoid circular dependencies that can prevent garbage collection.\n    - Profile your application to identify memory leaks.\n\n- **Rendering Optimization:**\n    - Minimize DOM manipulations.\n    - Use CSS transforms and animations instead of JavaScript animations.\n    - Optimize images and other assets.\n    - Use the `shouldComponentUpdate` lifecycle method or `React.memo` to prevent unnecessary re-renders.\n\n- **Bundle Size Optimization:**\n    - Use tree shaking to remove unused code from your bundle.\n    - Minify your code to reduce bundle size.\n    - Compress your code using gzip or Brotli.\n    - Use code splitting to load only the code that is needed for a particular page or component.\n\n- **Lazy Loading Strategies:**\n    - Lazy load modules and components that are not immediately needed.\n    - Use dynamic imports (`import()`) to load modules on demand.\n    - Implement a loading indicator to provide feedback to the user while the module is loading.\n\n## 4. Security Best Practices\n\n- **Common Vulnerabilities and Prevention:**\n    - **Cross-Site Scripting (XSS):** Sanitize user input and escape output to prevent XSS attacks.\n    - **Cross-Site Request Forgery (CSRF):** Use anti-CSRF tokens to protect against CSRF attacks.\n    - **SQL Injection:** Use parameterized queries or ORMs to prevent SQL injection attacks (relevant for backend TypeScript).\n    - **Denial of Service (DoS):** Implement rate limiting and other measures to prevent DoS attacks.\n    - **Man-in-the-Middle (MitM):** Use HTTPS to encrypt communication between the client and server.\n\n- **Input Validation:**\n    - Validate all user input on both the client and server sides.\n    - Use strong validation rules to prevent malicious input.\n    - Sanitize user input to remove potentially harmful characters.\n\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication mechanism to verify user identities.\n    - Implement authorization checks to control access to resources.\n    - Use role-based access control (RBAC) to manage user permissions.\n    - Use JSON Web Tokens (JWT) for stateless authentication.\n\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use strong encryption algorithms.\n    - Store passwords securely using a hashing algorithm and salt.\n    - Protect API keys and other secrets.\n\n- **Secure API Communication:**\n    - Use HTTPS for all API communication.\n    - Implement proper authentication and authorization for API endpoints.\n    - Use rate limiting to prevent abuse.\n    - Validate API requests and responses.\n\n## 5. Testing Approaches\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual functions and components.\n    - Use mocking and stubbing to isolate units of code.\n    - Test edge cases and error conditions.\n    - Aim for high code coverage.\n\n- **Integration Testing:**\n    - Test the interaction between different modules and components.\n    - Verify that different parts of the application work together correctly.\n\n- **End-to-End Testing:**\n    - Test the entire application from the user's perspective.\n    - Use tools like Cypress or Playwright to automate end-to-end tests.\n\n- **Test Organization:**\n    - Organize tests in a way that makes it easy to find and run them.\n    - Group tests by feature or module.\n    - Use descriptive test names.\n\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate units of code and simulate dependencies.\n    - Use mocking libraries like Jest or Sinon.js.\n\n## 6. Common Pitfalls and Gotchas\n\n- **Frequent Mistakes:**\n    - Incorrectly handling asynchronous operations (Promises, async/await).\n    - Not handling errors properly.\n    - Overusing the `any` type.\n    - Ignoring compiler warnings.\n    - Not keeping dependencies up to date.\n\n- **Edge Cases:**\n    - Handling different browser versions and devices.\n    - Dealing with network latency and failures.\n    - Handling different time zones and locales.\n    - Handling large datasets and complex calculations.\n\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in new versions of TypeScript and related libraries.\n    - Consult the release notes for each new version to identify potential issues.\n    - Use TypeScript's compiler options to target specific ECMAScript versions and maintain backwards compatibility if needed.\n\n- **Compatibility Concerns:**\n    - Ensure that your code is compatible with the target browsers and devices.\n    - Use polyfills to provide support for older browsers.\n    - Test your code on different platforms to identify compatibility issues.\n\n- **Debugging Strategies:**\n    - Use a debugger to step through your code and inspect variables.\n    - Use console logging to track the flow of execution and identify errors.\n    - Use TypeScript's type checking to catch errors early.\n    - Use source maps to debug code that has been transpiled or minified.\n    - Learn to read and understand stack traces.\n\n## 7. Tooling and Environment\n\n- **Recommended Development Tools:**\n    - **IDE:** Visual Studio Code with the TypeScript extension.\n    - **Package Manager:** npm or Yarn.\n    - **Bundler:** Webpack, Parcel, or Rollup.\n    - **Linter:** ESLint with TypeScript-specific rules.\n    - **Formatter:** Prettier.\n    - **Testing Framework:** Jest, Mocha, or Jasmine.\n\n- **Build Configuration:**\n    - Use a `tsconfig.json` file to configure the TypeScript compiler.\n    - Configure compiler options like `target`, `module`, `jsx`, and `strict`.\n    - Use TypeScript's project references to organize large projects.\n\n- **Linting and Formatting:**\n    - Use ESLint with TypeScript-specific rules to enforce coding standards.\n    - Use Prettier to automatically format your code.\n    - Integrate linting and formatting into your development workflow using Git hooks or CI/CD pipelines.\n\n- **Deployment Best Practices:**\n    - Use a build process to transpile and bundle your code.\n    - Minify and compress your code to reduce bundle size.\n    - Use a CDN to serve static assets.\n    - Implement caching strategies to improve performance.\n\n- **CI/CD Integration:**\n    - Integrate your tests and linters into your CI/CD pipeline.\n    - Automate the build and deployment process.\n    - Use environment variables to configure your application for different environments.",
    "metadata": {
      "globs": "*.ts?(x)",
      "format": "mdc",
      "originalFile": "typescript.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "typescript",
      "enforces",
      "best",
      "practices",
      "development",
      "including",
      "coding",
      "standards",
      "performance",
      "considerations",
      "javascript",
      "types",
      "cursor-rule",
      "mdc",
      "type-safety",
      "languages",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "typescript",
        "javascript",
        "types",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-unittest",
    "description": "This rule provides comprehensive best practices for writing effective, maintainable, and performant unit tests using Python's unittest library. It covers code organization, testing strategies, performance, security, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "unittest",
      "python",
      "backend",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "backend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/unittest.mdc",
    "content": "# unittest Best Practices: A Comprehensive Guide\n\nThis document provides a comprehensive set of guidelines and best practices for writing effective, maintainable, and performant unit tests using Python's `unittest` library. It covers various aspects of unit testing, from code organization to security considerations.\n\n## 1. Code Organization and Structure\n\nProper code organization is crucial for maintainability and scalability of your test suite.\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a consistent and logical directory structure for your tests. Here are two common approaches:\n\n*   **Separate Test Directory:** Create a dedicated `tests` directory at the root of your project.\n    \n    my_project/\n    ├── my_package/\n    │   ├── __init__.py\n    │   ├── module1.py\n    │   └── module2.py\n    ├── tests/\n    │   ├── __init__.py\n    │   ├── test_module1.py\n    │   └── test_module2.py\n    └── ...\n    \n*   **In-Source Tests:** Place test modules alongside the corresponding source code.\n    \n    my_project/\n    ├── my_package/\n    │   ├── __init__.py\n    │   ├── module1.py\n    │   ├── test_module1.py\n    │   └── module2.py\n    └── ...\n    \n\nThe first approach is generally preferred for larger projects as it clearly separates the test code from the main application code.  Ensure an `__init__.py` file exists within the `tests` directory to allow for easy module imports.\n\n### 1.2 File Naming Conventions\n\nFollow a consistent naming convention for your test files. Common patterns include:\n\n*   `test_module.py`: Tests for `module.py`\n*   `module_test.py`: Tests for `module.py`\n\nChoose one and stick to it consistently throughout your project. The `test_*` convention is generally recommended, as it's the default recognized by tools like `unittest` itself and `pytest`.  Regardless, the name should clearly indicate which module or component is being tested.\n\n### 1.3 Module Organization\n\nOrganize your test modules to mirror the structure of your application code. If your application has a module named `my_package.utils`, create a corresponding test module named `test_utils.py` (or `utils_test.py` depending on your chosen convention). Inside the test module, group related tests into test classes.\n\n### 1.4 Component Architecture\n\nDesign your components with testability in mind. Decouple components and use dependency injection to make it easier to mock dependencies in your tests. Avoid tightly coupled code, as it makes unit testing difficult.\n\n### 1.5 Code Splitting Strategies\n\nBreak down large modules into smaller, more manageable units. Each unit should have a clearly defined responsibility and be easy to test in isolation. Use functions or classes to encapsulate functionality.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Arrange-Act-Assert (AAA):** Structure your test methods using the AAA pattern. This pattern promotes readability and maintainability.\n*   **Test Fixtures:** Use test fixtures (e.g., `setUp` and `tearDown` methods in `unittest`) to set up and tear down resources required for your tests. This ensures a consistent testing environment.\n*   **Mock Objects:** Employ mock objects to isolate the code under test from external dependencies.\n\n### 2.2 Recommended Approaches\n\n*   **Test-Driven Development (TDD):** Write your tests *before* writing the code. This helps you define the expected behavior of your code and ensures that it is testable.\n*   **Behavior-Driven Development (BDD):** Describe the expected behavior of your code in a human-readable format (e.g., using Gherkin syntax) and use testing frameworks like `behave` or `pytest-bdd` to execute these descriptions as tests.\n*   **Focus on a single aspect per test:**  Each test should verify a single, well-defined aspect of the code's behavior. This makes it easier to identify the cause of failures and keeps tests simple.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **Testing implementation details:** Tests should focus on the *behavior* of the code, not its implementation. Avoid writing tests that rely on internal data structures or algorithms, as these tests will break when the implementation changes.\n*   **Large, complex tests:** Break down large tests into smaller, more focused tests. This improves readability and makes it easier to debug failures.\n*   **Ignoring test failures:** Never ignore failing tests. Investigate and fix them promptly.\n*   **Over-mocking:** Mock only the dependencies that are necessary to isolate the code under test. Over-mocking can lead to tests that pass even when the code is broken.\n*   **Non-deterministic tests:** Avoid tests that rely on external factors or random data, as these tests can produce inconsistent results.\n\n### 2.4 State Management\n\n*   **Isolate tests:** Ensure that each test runs in isolation and does not affect the state of other tests. Use test fixtures to reset the state before and after each test.\n*   **Avoid global state:** Minimize the use of global variables, as they can make it difficult to reason about the state of your application.\n*   **Use dependency injection:** Inject dependencies into your classes and functions to make it easier to control the state during testing.\n\n### 2.5 Error Handling\n\n*   **Test error conditions:** Write tests to verify that your code handles errors correctly. Use `assertRaises` or context managers like `pytest.raises` to assert that exceptions are raised when expected.\n*   **Provide informative error messages:** When an assertion fails, provide a clear and informative error message that helps you understand the cause of the failure.\n*   **Avoid catching generic exceptions:** Catch only the specific exceptions that you expect to handle. Catching generic exceptions can mask underlying problems.\n\n## 3. Performance Considerations\n\nWhile unit tests primarily focus on functionality, performance is also a consideration, especially for large test suites.\n\n### 3.1 Optimization Techniques\n\n*   **Reduce test execution time:** Identify and optimize slow-running tests. Use profiling tools to pinpoint performance bottlenecks.\n*   **Parallel test execution:** Use tools like `pytest-xdist` to run your tests in parallel, reducing the overall test execution time.\n*   **Selective test execution:** Run only the tests that are relevant to the code changes you've made. This can be achieved using test selection features provided by your testing framework.\n\n### 3.2 Memory Management\n\n*   **Avoid memory leaks:** Be mindful of memory leaks in your tests. Ensure that you release resources properly after each test.\n*   **Use efficient data structures:** Choose appropriate data structures for your tests to minimize memory consumption.\n\n### 3.3 (Not Applicable) Rendering Optimization\n\nThis is not typically applicable to `unittest`, as it does not directly handle rendering or UI elements.  If you are testing components with UI aspects, consider specialized UI testing frameworks.\n\n### 3.4 Bundle Size Optimization\n\nThis is not typically applicable to `unittest` tests themselves but is relevant for the overall project being tested. Tests should be designed to load and exercise components in isolation, not to be part of a deliverable bundle.\n\n### 3.5 Lazy Loading\n\nThis is not typically applicable directly to `unittest` tests, but rather in the code that you're testing. Ensure that your code uses lazy loading where appropriate to minimize startup time and memory consumption.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **SQL injection:** Prevent SQL injection by using parameterized queries or ORM tools.\n*   **Cross-site scripting (XSS):** Prevent XSS by properly escaping user input.\n*   **Command injection:** Prevent command injection by validating user input and avoiding the use of `os.system` or `subprocess.call` with untrusted data.\n*   **Denial-of-service (DoS):** Protect against DoS attacks by limiting resource consumption and implementing rate limiting.\n\n### 4.2 Input Validation\n\n*   **Validate all user input:** Validate user input to prevent malicious data from entering your system.\n*   **Use whitelists:** Define a whitelist of allowed characters and values, and reject any input that does not conform to the whitelist.\n*   **Sanitize user input:** Sanitize user input to remove any potentially harmful characters or code.\n\n### 4.3 Authentication and Authorization\n\n*   **Use strong authentication:** Use strong authentication mechanisms, such as multi-factor authentication, to protect user accounts.\n*   **Implement role-based access control (RBAC):** Implement RBAC to control access to sensitive resources.\n*   **Securely store passwords:** Store passwords securely using hashing and salting techniques.\n\n### 4.4 Data Protection\n\n*   **Encrypt sensitive data:** Encrypt sensitive data at rest and in transit.\n*   **Use secure communication protocols:** Use secure communication protocols, such as HTTPS, to protect data in transit.\n*   **Regularly back up your data:** Regularly back up your data to prevent data loss.\n\n### 4.5 Secure API Communication\n\n*   **Use API keys:** Use API keys to authenticate API requests.\n*   **Implement rate limiting:** Implement rate limiting to prevent abuse of your API.\n*   **Validate API input and output:** Validate API input and output to prevent malicious data from entering or leaving your system.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Test-Driven Development (TDD):**  Write tests before writing the code itself. This allows you to drive the design by thinking about the expected behavior and edge cases first.\n*   **Black-box testing:**  Test the code based only on its inputs and outputs, without knowledge of its internal workings.\n*   **White-box testing:**  Test the code based on its internal structure and logic. This requires knowledge of the code's implementation.\n*   **Boundary value analysis:** Test the code at the boundaries of its input ranges to identify potential errors.\n*   **Equivalence partitioning:** Divide the input domain into equivalence partitions and test one value from each partition.\n\n### 5.2 Integration Testing\n\n*   **Test interactions between components:** Integration tests verify that different components of your application work together correctly.\n*   **Use mock objects:** Use mock objects to simulate the behavior of external dependencies during integration tests.\n*   **Test data persistence:** Ensure that data is correctly persisted to and retrieved from the database.\n\n### 5.3 End-to-End Testing\n\n*   **Test the entire application workflow:** End-to-end tests verify that the entire application workflow works correctly, from the user interface to the backend systems.\n*   **Use automated testing tools:** Use automated testing tools, such as Selenium or Cypress, to automate end-to-end tests.\n*   **Focus on critical paths:** Focus on testing the critical paths through your application to ensure that the most important functionality is working correctly.\n\n### 5.4 Test Organization\n\n*   **Group related tests:** Group related tests into test classes or test suites.\n*   **Use descriptive names:** Use descriptive names for your tests to make it easy to understand their purpose.\n*   **Keep tests short and focused:** Keep tests short and focused on a single aspect of the code's behavior.\n*   **Automate test execution:** Automate test execution using continuous integration tools.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use mock objects:** Mock objects are used to replace real dependencies with simulated objects that can be controlled and inspected during testing.\n*   **Use stubs:** Stubs are simplified versions of real dependencies that provide predefined responses to specific calls.\n*   **Choose the right tool:** Choose the right mocking or stubbing tool for your needs. Popular tools include `unittest.mock` (part of the standard library) and `pytest-mock`.\n*   **Avoid over-mocking:** Mock only the dependencies that are necessary to isolate the code under test.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Testing implementation details:** As mentioned earlier, testing implementation instead of behavior.\n*   **Ignoring test failures:** Treat failing tests as critical errors, not warnings.\n*   **Writing tests that are too complex:** Overly complex tests can be difficult to understand and maintain.\n*   **Not using test fixtures:** Failing to use test fixtures can lead to inconsistent testing environments and unreliable results.\n*   **Ignoring code coverage:** While not a perfect measure, low code coverage indicates areas of code that are not being tested.\n\n### 6.2 Edge Cases\n\n*   **Empty inputs:** Test what happens when you pass empty lists, strings, or dictionaries to your code.\n*   **Null or None values:** Test how your code handles null or None values.\n*   **Invalid data types:** Test how your code handles invalid data types.\n*   **Boundary conditions:** Test the behavior of your code at the boundaries of its input ranges.\n*   **Unexpected exceptions:** Ensure that your code handles unexpected exceptions gracefully.\n\n### 6.3 Version-Specific Issues\n\n*   **Compatibility with older Python versions:** Be aware of potential compatibility issues when running tests on older Python versions. Use conditional imports or version checks to handle these issues.\n*   **Changes in unittest features:** Be aware of changes in unittest features and deprecations across different Python versions. Refer to the official documentation for details.\n\n### 6.4 Compatibility Concerns\n\n*   **Dependencies with C extensions:** Testing code that depends on libraries with C extensions can be tricky. Consider using mock objects or specialized testing tools.\n*   **Integration with external systems:** Testing code that integrates with external systems, such as databases or APIs, can require setting up test environments or using mock objects.\n\n### 6.5 Debugging Strategies\n\n*   **Use a debugger:** Use a debugger to step through your code and inspect variables during test execution.\n*   **Print statements:** Use print statements to output debugging information to the console.\n*   **Logging:** Use logging to record debugging information to a file.\n*   **Isolate the problem:** Try to isolate the problem by running only the failing test or a small subset of tests.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Tools\n\n*   **unittest:** Python's built-in unit testing framework.\n*   **pytest:** A popular third-party testing framework with a simpler syntax and more features.\n*   **coverage.py:** A tool for measuring code coverage.\n*   **mock:** A library for creating mock objects.\n*   **flake8:** A tool for linting and formatting Python code.\n*   **tox:** A tool for running tests in multiple Python environments.\n*   **virtualenv or venv:** Tools for creating isolated Python environments.\n\n### 7.2 Build Configuration\n\n*   **Use a build system:** Use a build system, such as `setuptools` or `poetry`, to manage your project's dependencies and build process.\n*   **Define test dependencies:** Specify your test dependencies in your build configuration file.\n*   **Automate test execution:** Integrate test execution into your build process so that tests are run automatically whenever the code is built.\n\n### 7.3 Linting and Formatting\n\n*   **Use a linter:** Use a linter, such as `flake8` or `pylint`, to enforce coding style guidelines and identify potential errors.\n*   **Use a formatter:** Use a formatter, such as `black` or `autopep8`, to automatically format your code.\n*   **Configure your editor:** Configure your editor to automatically run the linter and formatter whenever you save a file.\n\n### 7.4 Deployment\n\n*   **Run tests before deployment:** Always run your tests before deploying your code to production.\n*   **Use a continuous integration/continuous deployment (CI/CD) pipeline:** Use a CI/CD pipeline to automate the build, test, and deployment process.\n*   **Monitor your application:** Monitor your application in production to identify and fix any issues that may arise.\n\n### 7.5 CI/CD Integration\n\n*   **Choose a CI/CD provider:** Choose a CI/CD provider, such as Jenkins, GitLab CI, GitHub Actions, or CircleCI.\n*   **Configure your CI/CD pipeline:** Configure your CI/CD pipeline to automatically build, test, and deploy your code whenever changes are pushed to your repository.\n*   **Integrate with testing tools:** Integrate your CI/CD pipeline with your testing tools so that test results are automatically reported.\n*   **Use code coverage reports:** Use code coverage reports to track the effectiveness of your tests.\n\nBy following these best practices, you can write effective, maintainable, and performant unit tests that will help you ensure the quality and reliability of your Python code.",
    "metadata": {
      "globs": "*_test.py, **/test_*.py",
      "format": "mdc",
      "originalFile": "unittest.mdc"
    },
    "subcategory": "python",
    "keywords": [
      "cursor",
      "unittest",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "writing",
      "effective",
      "maintainable",
      "performant",
      "python",
      "backend",
      "cursor-rule",
      "mdc",
      "languages"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "unittest",
        "python",
        "backend",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "languages"
    }
  },
  {
    "name": "cursor-unity",
    "description": "This rule provides best practices for Unity C# development, covering code style, organization, performance, and security to ensure maintainable and efficient projects.",
    "author": "sanjeed5",
    "tags": [
      "unity",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/unity.mdc",
    "content": "# Unity C# Best Practices and Coding Standards\n\nThis document provides a comprehensive guide to best practices for Unity C# development, covering code style, organization, performance, and security, to ensure maintainable and efficient projects.\n\n## I. Code Organization and Structure\n\n### A. Directory Structure Best Practices\n\nA well-organized directory structure is crucial for maintainability and collaboration. Consider the following structure:\n\n\nAssets/\n├── Animations/\n│   ├── AnimationClips/\n│   └── Animators/\n├── Audio/\n│   ├── Music/\n│   └── SFX/\n├── Editor/\n│   └── EditorScripts/\n├── Fonts/\n├── Materials/\n├── Models/\n├── Plugins/\n├── Prefabs/\n├── Resources/\n├── Scenes/\n├── Scripts/\n│   ├── Core/\n│   ├── Gameplay/\n│   ├── UI/\n│   ├── Data/\n│   ├── Editor/\n│   └── Utilities/\n├── Textures/\n│   ├── UI/\n│   └── Environment/\n\n\n*   **Animations:** Contains all animation-related assets.\n*   **Audio:** Contains music and sound effects.\n*   **Editor:** Contains custom editor scripts.\n*   **Fonts:** Contains font assets.\n*   **Materials:** Contains material assets.\n*   **Models:** Contains 3D models.\n*   **Plugins:** Contains third-party plugins.\n*   **Prefabs:** Contains prefab assets.\n*   **Resources:** Contains assets loaded at runtime (use sparingly due to performance implications).\n*   **Scenes:** Contains scene files.\n*   **Scripts:** Contains all C# scripts, further organized by functionality.\n    *   **Core:** Fundamental scripts and systems.\n    *   **Gameplay:** Scripts related to gameplay mechanics.\n    *   **UI:** User interface scripts.\n    *   **Data:** Scripts related to data management (e.g., ScriptableObjects).\n    *   **Editor:** Custom editor tools and scripts.\n    *   **Utilities:** General-purpose utility scripts.\n*   **Textures:** Contains texture assets.\n\n### B. File Naming Conventions\n\nConsistent file naming improves project readability and searchability.\n\n*   **Scripts:** `PascalCase.cs` (e.g., `PlayerController.cs`)\n*   **Prefabs:** `PascalCase.prefab` (e.g., `EnemyPrefab.prefab`)\n*   **Scenes:** `PascalCase.unity` (e.g., `MainMenu.unity`)\n*   **Materials:** `PascalCase.mat` (e.g., `WaterMaterial.mat`)\n*   **Textures:** `PascalCase.png` or `PascalCase.jpg` (e.g., `GroundTexture.png`)\n*   **Animations:** `PascalCase.anim` (e.g., `PlayerIdle.anim`)\n\nFollow these conventions:\n\n*   Use PascalCase for class names, methods, and properties.\n*   Use camelCase for variables and parameters.\n*   Use UPPER_SNAKE_CASE for constants.\n\n### C. Module Organization Best Practices\n\nFor larger projects, consider organizing code into modules or namespaces.\n\n*   **Namespaces:** Group related classes within a namespace.  This avoids naming collisions and improves code organization. Use namespaces that reflect the folder structure.\n\n    csharp\n    namespace MyGame.Gameplay\n    {\n        public class PlayerController : MonoBehaviour\n        {\n            // ...\n        }\n    }\n    \n\n*   **Assembly Definitions:** Use Assembly Definition files (`.asmdef`) to define modules.  This enables faster compilation times and better code isolation.  Place each module in its own folder with an assembly definition file.\n\n### D. Component Architecture Recommendations\n\nUnity uses a component-based architecture. Design your game objects with small, reusable components that handle specific responsibilities.\n\n*   **Single Responsibility Principle:** Each component should have one specific responsibility.\n*   **Composition over Inheritance:** Favor composition over inheritance to create complex behavior.\n\nExample:\n\nInstead of a monolithic `Player` script, use separate components like `PlayerMovement`, `PlayerHealth`, and `PlayerAttack`.\n\n### E. Code Splitting Strategies\n\n*   **Partial Classes:** Split large classes into multiple files using the `partial` keyword.\n\n    csharp\n    // PlayerController.cs\n    public partial class PlayerController : MonoBehaviour\n    {\n        // Movement logic\n    }\n\n    // PlayerController.Combat.cs\n    public partial class PlayerController : MonoBehaviour\n    {\n        // Combat logic\n    }\n    \n\n*   **Extension Methods:** Add functionality to existing classes without modifying their source code.\n\n    csharp\n    public static class StringExtensions\n    {\n        public static string Capitalize(this string str)\n        {\n            return char.ToUpper(str[0]) + str.Substring(1);\n        }\n    }\n\n    // Usage\n    string name = \"john\";\n    string capitalizedName = name.Capitalize(); // John\n    \n\n## II. Common Patterns and Anti-patterns\n\n### A. Design Patterns\n\n*   **Singleton:** Ensure a class has only one instance and provides a global point of access to it (use carefully, as overuse can lead to tight coupling).\n\n    csharp\n    public class GameManager : MonoBehaviour\n    {\n        private static GameManager _instance;\n        public static GameManager Instance\n        {\n            get { return _instance; }\n        }\n\n        private void Awake()\n        {\n            if (_instance != null && _instance != this)\n            {\n                Destroy(this.gameObject);\n            } else {\n                _instance = this;\n                DontDestroyOnLoad(this.gameObject);\n            }\n        }\n    }\n    \n\n*   **Object Pooling:** Reuse objects instead of creating and destroying them frequently to reduce garbage collection overhead.\n\n    csharp\n    public class ObjectPool : MonoBehaviour\n    {\n        public GameObject pooledObject;\n        public int poolSize = 10;\n        private List<GameObject> pool;\n\n        void Start()\n        {\n            pool = new List<GameObject>();\n            for (int i = 0; i < poolSize; i++)\n            {\n                GameObject obj = (GameObject)Instantiate(pooledObject);\n                obj.SetActive(false);\n                pool.Add(obj);\n            }\n        }\n\n        public GameObject GetPooledObject()\n        {\n            for (int i = 0; i < pool.Count; i++)\n            {\n                if (!pool[i].activeInHierarchy)\n                {\n                    return pool[i];\n                }\n            }\n            return null; // Or Instantiate more if needed\n        }\n    }\n    \n*   **Factory:** Create objects without specifying the exact class of object that will be created.\n*   **Observer:** Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically.\n*   **Command:** Encapsulate a request as an object, thereby allowing for parameterizing clients with queues, requests, and operations.\n\n### B. Recommended Approaches for Common Tasks\n\n*   **Input Handling:** Use the new Input System for more flexible and customizable input handling.\n*   **UI Development:** Utilize Unity's UI system (Canvas, RectTransform, UI components) for creating user interfaces.\n*   **Data Persistence:** Use `PlayerPrefs` for simple data storage, and consider using serialization for more complex data structures.  Alternatively, consider using a database like SQLite for more complex data storage needs.\n*   **Networking:** Use Unity's `Netcode for GameObjects` for multiplayer games.  Also consider third-party networking solutions like Photon.\n*   **Asynchronous Operations:** Employ `async/await` to avoid blocking the main thread when performing long-running operations (e.g., loading assets, networking).\n\n### C. Anti-patterns and Code Smells\n\n*   **God Classes:** Avoid creating classes that do too much.  Split functionality into smaller, more manageable classes.\n*   **Spaghetti Code:** Avoid complex, unstructured code that is difficult to understand and maintain.  Use modular design and clear coding conventions.\n*   **Magic Numbers:** Avoid hardcoded numerical values in your code. Use named constants instead.\n*   **Overuse of `FindGameObjectWithTag` or `GetComponentInChildren`:** These methods can be slow. Cache references to frequently used objects and components.\n*   **Using `Resources.Load` excessively:**  `Resources.Load`  can lead to performance issues. Use AssetBundles or Addressables for better asset management.\n*   **Relying heavily on `Update()` for everything:**  Minimize the code in the  `Update()`  loop to avoid performance bottlenecks. Use events, coroutines, and other techniques to handle tasks outside of the main loop.\n\n### D. State Management Best Practices\n\n*   **State Machines:** Use state machines to manage complex object behavior.\n\n    csharp\n    public enum PlayerState\n    {\n        Idle,\n        Walking,\n        Jumping,\n        Attacking\n    }\n\n    public class PlayerController : MonoBehaviour\n    {\n        public PlayerState currentState = PlayerState.Idle;\n\n        void Update()\n        {\n            switch (currentState)\n            {\n                case PlayerState.Idle:\n                    // Handle idle state logic\n                    break;\n                case PlayerState.Walking:\n                    // Handle walking state logic\n                    break;\n                // ...\n            }\n        }\n    }\n    \n\n*   **ScriptableObjects:** Use ScriptableObjects to store game data and configuration parameters.\n\n    csharp\n    [CreateAssetMenu(fileName = \"WeaponData\", menuName = \"Game Data/Weapon Data\", order = 1)]\n    public class WeaponData : ScriptableObject\n    {\n        public string weaponName;\n        public int damage;\n        public float fireRate;\n    }\n    \n\n### E. Error Handling Patterns\n\n*   **Try-Catch Blocks:** Use try-catch blocks to handle exceptions gracefully.  Log exceptions and provide informative error messages.\n*   **Assertions:** Use assertions to validate assumptions in your code.\n*   **Null Checks:** Check for null references before accessing objects to prevent NullReferenceExceptions.\n*   **Custom Exceptions:** Create custom exception classes to handle specific error conditions in your game.\n\n## III. Performance Considerations\n\n### A. Optimization Techniques\n\n*   **Object Pooling:** Reuse objects to reduce garbage collection.\n*   **Caching:** Cache frequently accessed data to avoid repeated calculations or lookups.\n*   **String Concatenation:** Use `StringBuilder` for efficient string concatenation.\n*   **Minimize Garbage Collection:** Avoid creating temporary objects in frequently executed code.\n*   **Disable Unused Components:** Disable components that are not currently needed.\n*   **Reduce Draw Calls:** Batch static objects, use texture atlases, and optimize materials to reduce draw calls.\n*   **LOD (Level of Detail):** Use LOD groups to reduce the polygon count of objects at a distance.\n*   **Occlusion Culling:** Occlude objects that are not visible to the camera.\n*   **Use Profiler:** Regularly use the Unity Profiler to identify performance bottlenecks.\n\n### B. Memory Management\n\n*   **Asset Bundles:** Use Asset Bundles to load and unload assets dynamically, reducing the memory footprint of your game.\n*   **Addressable Asset System:**  Use Addressables for an even more flexible asset management system.\n*   **Unload Unused Assets:** Call `Resources.UnloadUnusedAssets()` to release unused assets from memory.\n*   **Weak References:** Use weak references to avoid memory leaks when referencing objects that may be destroyed.\n\n### C. Rendering Optimization\n\n*   **Optimize Shaders:** Use simple shaders and avoid complex calculations in shaders.\n*   **Texture Compression:** Compress textures to reduce memory usage and improve rendering performance.\n*   **Mipmapping:** Use mipmaps to reduce aliasing and improve performance.\n*   **Lightmapping:** Bake static lighting to reduce real-time lighting calculations.\n*   **Shadows:** Optimize shadow settings and reduce the number of real-time shadows.\n*   **Post-Processing:** Use post-processing effects sparingly, as they can be performance intensive.\n\n### D. Bundle Size Optimization\n\n*   **Texture Compression:** Compress textures to reduce their size.\n*   **Audio Compression:** Compress audio files to reduce their size.\n*   **Remove Unused Assets:** Delete unused assets from your project.\n*   **Use Asset Bundles:**  Split your game into multiple Asset Bundles to allow users to download only the content they need.\n*   **Stripping Level:**  Configure stripping level in project settings to remove unused code.\n\n### E. Lazy Loading\n\n*   **Load Assets Asynchronously:** Load assets in the background using `async/await` or coroutines.\n*   **Load Scenes Additively:** Load scenes additively to avoid interrupting gameplay.\n*   **Stream Assets:** Stream large assets from disk or the network instead of loading them into memory all at once.\n\n## IV. Security Best Practices\n\n### A. Common Vulnerabilities\n\n*   **Code Injection:** Prevent code injection by validating user input and avoiding the use of `eval` or similar functions.\n*   **Data Tampering:** Protect game data from tampering by using encryption and checksums.\n*   **Man-in-the-Middle Attacks:** Use HTTPS for all network communication to prevent man-in-the-middle attacks.\n*   **Denial of Service (DoS):** Protect your server from DoS attacks by implementing rate limiting and input validation.\n\n### B. Input Validation\n\n*   **Validate All User Input:** Validate all user input to prevent code injection, data tampering, and other attacks.\n*   **Use Whitelisting:** Use whitelisting to allow only specific characters or values in user input.\n*   **Limit Input Length:** Limit the length of user input to prevent buffer overflows.\n*   **Sanitize Input:** Sanitize user input to remove potentially harmful characters or code.\n\n### C. Authentication and Authorization\n\n*   **Use Secure Authentication:** Use a secure authentication method such as OAuth 2.0 or JWT (JSON Web Tokens).\n*   **Implement Authorization:** Implement authorization to control access to resources based on user roles and permissions.\n*   **Store Passwords Securely:** Hash passwords using a strong hashing algorithm such as bcrypt or Argon2.\n*   **Use Multi-Factor Authentication:** Use multi-factor authentication to add an extra layer of security.\n\n### D. Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data such as passwords, API keys, and payment information.\n*   **Use Secure Storage:** Store sensitive data in a secure storage location such as the keychain or a hardware security module (HSM).\n*   **Obfuscate Code:** Obfuscate your code to make it more difficult for attackers to reverse engineer.\n\n### E. Secure API Communication\n\n*   **Use HTTPS:** Use HTTPS for all API communication.\n*   **Validate API Responses:** Validate API responses to prevent data injection and other attacks.\n*   **Use API Keys:** Use API keys to authenticate requests to your API.\n*   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of your API.\n\n## V. Testing Approaches\n\n### A. Unit Testing\n\n*   **Isolate Components:** Write unit tests for individual components in isolation.\n*   **Use a Testing Framework:** Use a unit testing framework such as NUnit or Unity Test Runner.\n*   **Test Edge Cases:** Test edge cases and boundary conditions.\n*   **Write Mock Objects:** Use mock objects to simulate dependencies.\n*   **Follow AAA Pattern:** Arrange, Act, Assert.\n\n### B. Integration Testing\n\n*   **Test Interactions:** Test the interactions between multiple components.\n*   **Use Test Scenes:** Create test scenes to isolate integration tests.\n*   **Simulate Real-World Scenarios:** Simulate real-world scenarios to test the behavior of your game under different conditions.\n*   **Use Data-Driven Tests:** Use data-driven tests to test multiple scenarios with different input data.\n\n### C. End-to-End Testing\n\n*   **Test the Entire Game Flow:** Test the entire game flow from start to finish.\n*   **Use Automated Testing Tools:** Use automated testing tools such as Selenium or Appium.\n*   **Test on Multiple Platforms:** Test your game on multiple platforms to ensure compatibility.\n*   **Involve Testers:** Involve human testers to identify usability issues and other problems.\n\n### D. Test Organization\n\n*   **Create a Test Directory:** Create a separate directory for your tests.\n*   **Mirror the Source Directory:** Mirror the structure of your source directory in your test directory.\n*   **Name Test Classes Consistently:** Name your test classes consistently (e.g., `PlayerControllerTests`).\n*   **Group Tests by Functionality:** Group your tests by functionality.\n\n### E. Mocking and Stubbing\n\n*   **Use Mocking Frameworks:** Use mocking frameworks such as Moq or NSubstitute.\n*   **Create Interfaces:** Create interfaces for your dependencies to make them easier to mock.\n*   **Avoid Hardcoded Dependencies:** Avoid hardcoded dependencies in your code.\n*   **Use Dependency Injection:** Use dependency injection to inject mock objects into your code.\n\n## VI. Common Pitfalls and Gotchas\n\n### A. Frequent Mistakes\n\n*   **Ignoring Performance:** Neglecting performance optimization from the beginning of the project.\n*   **Overcomplicating Code:** Writing complex code when simpler solutions exist.\n*   **Not Using Version Control:** Failing to use version control (e.g., Git) to manage code changes.\n*   **Poor Asset Management:** Poorly organizing and managing assets, leading to project bloat.\n*   **Neglecting Testing:** Not writing unit tests, integration tests, or end-to-end tests.\n*   **Misunderstanding Coroutines:**  Improper use or overuse of coroutines leading to unexpected behavior or memory leaks.\n*   **Incorrect Use of `Time.deltaTime`:** Using `Time.deltaTime` incorrectly, leading to frame-rate dependent behavior.\n\n### B. Edge Cases\n\n*   **Floating Point Precision:** Be aware of floating-point precision issues when comparing floating-point numbers.\n*   **Garbage Collection Spikes:** Be aware of garbage collection spikes and try to minimize garbage generation.\n*   **Platform Differences:** Test your game on different platforms to ensure compatibility.\n*   **Screen Size and Resolution:**  Handle different screen sizes and resolutions gracefully.\n\n### C. Version-Specific Issues\n\n*   **API Changes:** Be aware of API changes between different versions of Unity.\n*   **Bug Fixes:** Be aware of bug fixes in different versions of Unity.\n*   **Feature Deprecations:** Be aware of feature deprecations in different versions of Unity.\n\n### D. Compatibility Concerns\n\n*   **.NET Framework:** Be aware of the .NET Framework version used by your project.\n*   **Third-Party Plugins:** Ensure that third-party plugins are compatible with your version of Unity.\n*   **Platform SDKs:** Ensure that the platform SDKs you are using are compatible with your version of Unity.\n\n### E. Debugging Strategies\n\n*   **Use the Unity Debugger:** Use the Unity debugger to step through your code and inspect variables.\n*   **Use Debug.Log:** Use `Debug.Log` to print messages to the console.\n*   **Use Assertions:** Use assertions to validate assumptions in your code.\n*   **Use the Unity Profiler:** Use the Unity Profiler to identify performance bottlenecks.\n*   **Remote Debugging:**  Use remote debugging to debug your game on a device.\n\n## VII. Tooling and Environment\n\n### A. Recommended Development Tools\n\n*   **Visual Studio or Visual Studio Code:** Use a powerful IDE for C# development.\n*   **Unity Asset Store:** Explore the Unity Asset Store for useful tools and assets.\n*   **Version Control System (Git):** Use a version control system to manage code changes.\n*   **Project Management Tool (Jira, Trello):** Use a project management tool to track tasks and bugs.\n*   **Code Editor Extensions:** Use code editor extensions for linting, formatting, and code completion.\n\n### B. Build Configuration\n\n*   **Use Development Builds:** Use development builds for testing and debugging.\n*   **Use Release Builds:** Use release builds for production deployments.\n*   **Configure Build Settings:** Configure build settings such as scripting backend, target architecture, and optimization level.\n*   **Use Scripting Define Symbols:** Use scripting define symbols to enable or disable code based on the build configuration.\n\n### C. Linting and Formatting\n\n*   **Use StyleCop Analyzers:** Use StyleCop Analyzers to enforce coding style rules.\n*   **Use EditorConfig:** Use EditorConfig to define coding style settings for your project.\n*   **Use a Code Formatter:** Use a code formatter to automatically format your code.\n\n### D. Deployment Best Practices\n\n*   **Test on Target Platforms:** Test your game on the target platforms before deployment.\n*   **Submit to App Stores:** Submit your game to the appropriate app stores.\n*   **Monitor Performance:** Monitor the performance of your game after deployment.\n*   **Gather User Feedback:** Gather user feedback to improve your game.\n\n### E. CI/CD Integration\n\n*   **Use a CI/CD Platform:** Use a CI/CD platform such as Jenkins, Travis CI, or GitHub Actions.\n*   **Automate Builds and Tests:** Automate builds and tests to ensure code quality.\n*   **Automate Deployments:** Automate deployments to streamline the release process.\n*   **Integrate with Version Control:** Integrate your CI/CD pipeline with your version control system.\n\nBy following these best practices, you can create maintainable, efficient, and secure Unity C# projects.",
    "metadata": {
      "globs": "*.cs",
      "format": "mdc",
      "originalFile": "unity.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "unity",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "development",
      "covering",
      "code",
      "style",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "unity",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-unreal-engine",
    "description": "Comprehensive best practices and coding standards for Unreal Engine projects. Covers code organization, performance, security, testing, and common pitfalls to ensure maintainable, efficient, and robust game development.",
    "author": "sanjeed5",
    "tags": [
      "unreal-engine",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/unreal-engine.mdc",
    "content": "# Unreal Engine Best Practices and Coding Standards\n\nThis document outlines best practices and coding standards for Unreal Engine projects. Following these guidelines will help ensure maintainability, efficiency, and robustness.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n*   **`Source/`:** Contains all C++ source code.\n    *   **`[GameName]/`:** Root directory for your game's code.\n        *   **`Public/`:** Header files (.h) for classes and components.\n        *   **`Private/`:** Implementation files (.cpp).\n        *   **`[Feature]/`:** Subdirectories for specific game features (e.g., `Inventory`, `AI`, `UI`).\n        *   **`Core/`:** Classes and functions shared across the project.\n        *   **`UMG/`**:  Code related to Unreal Motion Graphics (UI)\n*   **`Content/`:** Contains all assets (meshes, textures, materials, blueprints, etc.).\n    *   **`[GameName]/`:** Root directory for your game's content.\n        *   **`Characters/`:** Character assets.\n        *   **`Environments/`:** Environment assets (meshes, textures, materials).\n        *   **`UI/`:** User interface assets.\n        *   **`Blueprints/`:** Blueprint classes and scripts.\n        *   **`Materials/`:**  Material assets.\n        *   **`Textures/`:**  Texture assets.\n        *   **`Audio/`:** Audio assets.\n        *   **`Animations/`:**  Animation assets.\n*   **`Config/`:** Configuration files (e.g., `DefaultGame.ini`, `DefaultEngine.ini`).\n*   **`Plugins/`:** Plugin code and assets.\n\n### 1.2 File Naming Conventions\n\n*   **C++ Classes:** Use descriptive names with prefixes indicating the class type.\n    *   `A[ClassName]` for Actors (e.g., `ACharacter`, `APlayerController`).\n    *   `U[ClassName]` for UObjects (e.g., `UInventoryComponent`, `UGameInstance`).\n    *   `F[StructName]` for Structs (e.g., `FHitResult`, `FVector`).\n    *   `E[EnumName]` for Enums (e.g., `EMovementMode`, `EInventoryItemType`).\n    *   `I[InterfaceName]` for Interfaces (e.g., `IInteractable`, `IUsable`).\n*   **Blueprints:**\n    *   `BP_[AssetName]` (e.g., `BP_Character`, `BP_Door`).\n*   **Assets:** Use descriptive names with prefixes indicating asset type.\n    *   `SM_[AssetName]` for Static Meshes (e.g., `SM_Table`, `SM_Chair`).\n    *   `T_[AssetName]` for Textures (e.g., `T_Ground_Albedo`, `T_Wall_Normal`).\n    *   `M_[AssetName]` for Materials (e.g., `M_Rock`, `M_Water`).\n    *   `MI_[AssetName]` for Material Instances (e.g., `MI_Rock_Dark`, `MI_Water_Shallow`).\n    *   `S_[AssetName]` for Sounds (e.g., `S_Explosion`, `S_Footstep`).\n    *   `Anim_[AssetName]` for Animations (e.g., `Anim_Run`, `Anim_Jump`).\n    *   `Mat_[AssetName]` for Matinee Sequences (Legacy Animation).\n*   **Levels:**\n    *   `[LevelName]_Level` or `[LevelName]` (e.g., `MainMenu_Level`, `Gameplay`).\n\n### 1.3 Module Organization\n\n*   **Game Module:** The main module containing the game's core logic.\n*   **Feature Modules:** Modules dedicated to specific game features (e.g., `InventoryModule`, `AIModule`).\n*   **Plugin Modules:** Modules packaged as plugins, offering reusable functionality.\n\n### 1.4 Component Architecture\n\n*   **Favor Composition over Inheritance:** Use components to add functionality to actors.\n*   **Create Reusable Components:** Design components to be generic and adaptable.\n*   **Use Interfaces for Communication:** Define interfaces for components to interact with each other.\n*   **Avoid God Components:** Break down complex functionality into smaller, more manageable components.\n*   **Encapsulate Logic:** Keep component logic self-contained and avoid tight coupling.\n\n### 1.5 Code Splitting Strategies\n\n*   **Feature-Based Splitting:** Organize code by game features.\n*   **Module-Based Splitting:** Create separate modules for distinct functionalities.\n*   **Async Loading:** Load assets and levels asynchronously to avoid hitches.\n*   **Level Streaming:** Divide large levels into smaller, streamed sub-levels.\n*   **Object Pooling:** Reuse frequently created and destroyed objects to reduce garbage collection.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n*   **Singleton:** For classes with only one instance (e.g., `GameInstance`).\n*   **Observer:** For event-driven communication between actors and components.\n*   **Factory:** For creating objects without specifying their concrete classes.\n*   **Command:** For encapsulating actions as objects, enabling undo/redo functionality.\n*   **Strategy:** For defining a family of algorithms and making them interchangeable.\n*   **Decorator:** For dynamically adding responsibilities to an object.\n*   **Adapter:** For adapting the interface of a class to another interface clients expect.\n*   **Object Pool:** Reuse objects to avoid frequent allocation and deallocation, especially useful for projectiles or particle effects.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Actor Spawning:** Use `GetWorld()->SpawnActor<>()` to spawn actors dynamically.\n*   **Input Handling:** Use Enhanced Input System for flexible and configurable input mappings.\n*   **Timers:** Use `GetWorldTimerManager()` for timed events and actions.\n*   **Collision Handling:** Use collision components and event delegates for collision detection.\n*   **Networking:** Use Unreal Engine's built-in networking system for multiplayer games.\n*   **Animation:** Leverage Animation Blueprints and State Machines for complex character animations.\n*   **UI Design:**  Utilize UMG (Unreal Motion Graphics) for creating dynamic user interfaces.\n\n### 2.3 Anti-patterns and Code Smells\n\n*   **God Classes/Actors:** Avoid overly large classes with too many responsibilities.\n*   **Spaghetti Code:** Avoid complex and unstructured code that is difficult to understand and maintain.\n*   **Magic Numbers:** Avoid hardcoded values without clear explanations.\n*   **Copy-Pasted Code:** Refactor duplicated code into reusable functions or classes.\n*   **Tight Coupling:** Minimize dependencies between classes and components.\n*   **Memory Leaks:** Ensure proper memory management to avoid memory leaks.\n*   **Excessive Casting:** Minimize the use of `Cast<>` as it can impact performance.  Consider using interfaces or dynamic dispatch instead.\n*   **Polling:** Avoid constantly checking for conditions; use events or delegates instead.\n*   **Tick Abuse:** Avoid performing expensive operations in the `Tick()` function; use timers or asynchronous tasks.\n*   **Not using the Actor Component System:** Neglecting to leverage components leads to monolithic, inflexible Actor classes.\n\n### 2.4 State Management\n\n*   **Game Instance:** For storing global game state that persists across levels.\n*   **Game Mode:** For managing game rules and player interactions within a level.\n*   **Player State:** For storing player-specific information (e.g., score, inventory).\n*   **Actor State:** For storing the state of individual actors (e.g., health, position).\n*   **Use Data Assets:**  For storing configurable game data (e.g., weapon stats, enemy parameters).\n*   **State Tree:** For handling complex AI behavior.\n*   **Gameplay Abilities:** For managing player abilities and interactions using the Gameplay Ability System (GAS).\n\n### 2.5 Error Handling\n\n*   **Use `ensure()` for Debug Assertions:** Use `ensure()` to check for conditions that should always be true during development.\n*   **Use `check()` for Critical Assertions:** Use `check()` for conditions that must be true in all builds.\n*   **Use `try-catch` for Exception Handling:** Use `try-catch` blocks to handle exceptions in critical code sections.\n*   **Log Errors and Warnings:** Use `UE_LOG()` to log errors and warnings for debugging and monitoring.\n*   **Handle Potential Null Pointers:** Always check for null pointers before accessing object members.\n*   **Implement Recovery Mechanisms:** Provide mechanisms to recover from errors gracefully (e.g., retry logic, fallback behavior).\n*   **Validate Data:**  Implement robust input and data validation to prevent unexpected errors.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Profiling:** Use Unreal Engine's profiling tools (e.g., Unreal Insights, Stat commands) to identify performance bottlenecks.\n*   **LODs (Level of Detail):** Use LODs to reduce the complexity of meshes at a distance.\n*   **Occlusion Culling:** Use occlusion culling to hide objects that are not visible.\n*   **Distance Culling:** Use distance culling to remove objects that are too far away.\n*   **HLODs (Hierarchical Level of Detail):** Use HLODs to combine multiple static meshes into a single mesh.\n*   **Instanced Static Meshes:** Use instanced static meshes to render multiple copies of the same mesh efficiently.\n*   **Material Optimization:** Optimize material complexity to reduce pixel cost.\n*   **Texture Optimization:** Use appropriate texture resolutions and compression formats.\n*   **Blueprint Nativization:** Convert Blueprint logic to C++ for improved performance.\n*   **Asynchronous Loading:** Load assets and levels asynchronously to avoid hitches.\n*   **Object Pooling:** Reuse frequently created and destroyed objects to reduce garbage collection.\n*   **Avoid Dynamic Allocation:** Minimize dynamic memory allocation during runtime.\n*   **Optimize Collision:** Simplify collision geometry and disable unnecessary collision checks.\n*   **Use Niagara:** Use the Niagara particle system for efficient particle effects.\n*   **Implement Adaptive Resolution:** Dynamically adjust the resolution based on performance.\n*   **Use GPU Profiling tools:** Tools like RenderDoc can help you debug what is happening on the GPU and pin point bottlenecks.\n\n### 3.2 Memory Management\n\n*   **Use Smart Pointers:** Use `TSharedPtr` and `TWeakPtr` for automatic memory management.\n*   **Avoid Circular Dependencies:** Prevent circular dependencies between smart pointers.\n*   **Unload Unused Assets:** Unload assets that are no longer needed to free up memory.\n*   **Garbage Collection:** Understand and optimize garbage collection behavior.\n*   **Asset References:** Use asset references carefully to avoid unnecessary asset loading.\n*   **Texture Streaming:** Use texture streaming to load only the necessary texture mipmaps.\n*   **Minimize Asset Duplication:**  Avoid creating duplicate assets; reuse existing ones whenever possible.\n*   **Monitor Memory Usage:**  Regularly monitor memory usage to identify potential leaks or excessive consumption.\n\n### 3.3 Rendering Optimization\n\n*   **Minimize Draw Calls:** Reduce the number of unique meshes and materials.\n*   **Optimize Shaders:** Simplify shader complexity to reduce rendering time.\n*   **Use Post-Processing Effects Sparingly:** Post-processing effects can be expensive; use them judiciously.\n*   **Optimize Lighting:** Use baked lighting whenever possible to reduce runtime lighting calculations.\n*   **Shadow Optimization:** Optimize shadow settings to reduce shadow rendering cost.\n*   **Use Mobile Rendering Features:** Utilize mobile rendering features for improved performance on mobile devices.\n*   **Consider Nanite Carefully:** For next-gen fidelity, use Nanite, but be aware of its overhead on lower-end platforms.\n*   **Virtual Shadow Maps:** Use virtual shadow maps to improve shadow quality and performance in large open worlds.\n\n### 3.4 Package Size Optimization\n\n*   **Compress Assets:** Use asset compression to reduce package size.\n*   **Remove Unused Assets:** Delete unused assets from the project.\n*   **Texture Compression:** Use appropriate texture compression formats.\n*   **Audio Compression:** Use appropriate audio compression formats.\n*   **Blueprint Stripping:** Strip debug information from Blueprints in release builds.\n*   **Cook Only Necessary Assets:** Ensure that only necessary assets are cooked for the target platform.\n*   **Use Pak File Compression:** Employ compression when creating .pak files for deployment.\n\n### 3.5 Lazy Loading\n\n*   **Stream Levels:** Load and unload levels dynamically based on player location.\n*   **Load Assets On-Demand:** Load assets only when they are needed.\n*   **Use Async Load Asset:** Use the `Async Load Asset` node in Blueprints or `LoadObjectAsync` in C++ to load assets asynchronously.\n*   **Lazy Loading Proxies:**  Create proxy objects that load the full asset only when accessed.\n*   **Subobject loading:** Defer loading of certain UObject subobjects until needed.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities\n\n*   **Code Injection:** Prevent code injection by validating all input data.\n*   **Denial of Service (DoS):** Protect against DoS attacks by limiting resource usage.\n*   **Man-in-the-Middle (MitM):** Use encryption to protect data in transit.\n*   **Data Tampering:** Prevent data tampering by using checksums and digital signatures.\n*   **Save Game Manipulation:**  Protect save game data from modification to prevent cheating.\n\n### 4.2 Input Validation\n\n*   **Validate All Input Data:** Validate all input data from players and external sources.\n*   **Sanitize Input Data:** Sanitize input data to remove potentially malicious characters or code.\n*   **Limit Input Length:** Limit the length of input strings to prevent buffer overflows.\n*   **Use Regular Expressions:** Use regular expressions to validate input patterns.\n*   **Implement Whitelists:**  Use whitelists to define allowed characters and patterns.\n\n### 4.3 Authentication and Authorization\n\n*   **Use Secure Authentication Methods:** Use secure authentication methods such as OAuth 2.0 or JWT.\n*   **Implement Role-Based Access Control (RBAC):** Use RBAC to control access to different features and resources.\n*   **Use Strong Passwords:** Enforce the use of strong passwords.\n*   **Implement Multi-Factor Authentication (MFA):** Use MFA for added security.\n*   **Store Credentials Securely:**  Store user credentials securely using encryption and salting.\n*   **Avoid Storing Secrets in Code:** Use configuration files or environment variables to store sensitive information.\n\n### 4.4 Data Protection\n\n*   **Encrypt Sensitive Data:** Encrypt sensitive data at rest and in transit.\n*   **Use Secure Communication Protocols:** Use HTTPS for secure communication over the network.\n*   **Protect Save Game Data:** Encrypt save game data to prevent cheating.\n*   **Implement Data Backups:** Regularly back up data to prevent data loss.\n*   **Comply with Data Privacy Regulations:**  Comply with data privacy regulations such as GDPR and CCPA.\n*   **Avoid Exposing Debug Information in Release Builds:** Disable or remove debug information in release builds.\n\n### 4.5 Secure API Communication\n\n*   **Use API Keys:** Use API keys to authenticate API requests.\n*   **Implement Rate Limiting:** Implement rate limiting to prevent abuse of API endpoints.\n*   **Use Input Validation:** Utilize robust input validation on APIs\n*   **Use Secure Communication Protocols:** Use HTTPS for secure communication over the network.\n*   **Validate API Responses:** Validate API responses to ensure data integrity.\n*   **Log API Requests and Responses:** Log API requests and responses for auditing and monitoring.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n*   **Test Individual Components:** Write unit tests for individual components and classes.\n*   **Use a Testing Framework:** Use a testing framework such as Unreal Engine's built-in Automation System or third-party frameworks.\n*   **Write Clear and Concise Tests:** Write tests that are easy to understand and maintain.\n*   **Test Edge Cases:** Test edge cases and boundary conditions.\n*   **Use Mock Objects:** Use mock objects to isolate components during testing.\n*   **Test Driven Development:** Consider using Test Driven Development (TDD) principles.\n*   **Focus on Core Logic:** Prioritize testing core logic and critical functionalities.\n\n### 5.2 Integration Testing\n\n*   **Test Interactions Between Components:** Write integration tests to test the interactions between different components and classes.\n*   **Test Game Logic:** Test the overall game logic and flow.\n*   **Test Data Flow:** Test the flow of data between different systems.\n*   **Simulate Realistic Scenarios:**  Simulate realistic game scenarios during integration testing.\n\n### 5.3 End-to-End Testing\n\n*   **Test the Entire Game:** Test the entire game from start to finish.\n*   **Use Automated Testing Tools:** Use automated testing tools to simulate player interactions.\n*   **Test on Different Platforms:** Test on different platforms to ensure compatibility.\n*   **Test with Real Players:**  Test with real players to get feedback on gameplay and usability.\n\n### 5.4 Test Organization\n\n*   **Organize Tests by Feature:** Organize tests by game features or modules.\n*   **Create a Test Suite:** Create a test suite that can be run automatically.\n*   **Use a Consistent Naming Convention:** Use a consistent naming convention for tests.\n*   **Document Tests:** Document tests to explain their purpose and functionality.\n*   **Keep Tests Up-to-Date:** Keep tests up-to-date with code changes.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use Mock Objects:** Use mock objects to simulate dependencies during testing.\n*   **Use Stub Functions:** Use stub functions to replace complex or external functions.\n*   **Isolate Components:** Isolate components during testing to avoid unintended interactions.\n*   **Use a Mocking Framework:** Use a mocking framework such as Google Mock or EasyMock.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n*   **Incorrect Asset Management:** Failing to properly manage and reference assets.\n*   **Over-Reliance on Blueprints:** Overusing Blueprints for complex logic, leading to performance issues.\n*   **Ignoring Performance Considerations:** Neglecting to optimize code and assets for performance.\n*   **Poor Memory Management:** Creating memory leaks and excessive garbage collection.\n*   **Inadequate Error Handling:** Failing to handle errors and exceptions gracefully.\n*   **Lack of Testing:** Not writing adequate unit and integration tests.\n*   **Incorrect use of transform:** Using world transform directly, instead of relative transform for attached components.\n*   **Not using the Garbage Collector Properly:** Not understanding when and how the Unreal Engine garbage collector reclaims memory.\n\n### 6.2 Edge Cases\n\n*   **Platform-Specific Issues:** Encountering platform-specific bugs or limitations.\n*   **Device-Specific Issues:** Encountering device-specific performance issues.\n*   **Localization Issues:** Encountering issues with text localization and internationalization.\n*   **Save Game Corruption:** Dealing with corrupted save game data.\n*   **Network Latency:** Handling network latency and packet loss in multiplayer games.\n\n### 6.3 Version-Specific Issues\n\n*   **API Changes:** Dealing with API changes between Unreal Engine versions.\n*   **Deprecated Features:** Using deprecated features that may be removed in future versions.\n*   **Compatibility Issues:** Encountering compatibility issues between different Unreal Engine versions.\n*   **Shader Model Differences:**  Accounting for differences in shader models across different UE versions.\n\n### 6.4 Compatibility Concerns\n\n*   **Plugin Compatibility:** Ensuring compatibility between different plugins.\n*   **Hardware Compatibility:** Ensuring compatibility with different hardware configurations.\n*   **Operating System Compatibility:** Ensuring compatibility with different operating systems.\n*   **Third-Party Library Compatibility:** Ensuring compatibility with third-party libraries and SDKs.\n\n### 6.5 Debugging Strategies\n\n*   **Use the Unreal Engine Debugger:** Use the Unreal Engine debugger to step through code and inspect variables.\n*   **Use Logging Statements:** Use logging statements to track the flow of execution and identify errors.\n*   **Use Breakpoints:** Set breakpoints in the code to pause execution at specific points.\n*   **Use the Visual Logger:** Use the Visual Logger to visualize game data and events.\n*   **Use Unreal Insights:** Use Unreal Insights to profile performance and identify bottlenecks.\n*   **Crash Reporting:**  Implement crash reporting to collect crash logs and diagnose issues.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **Visual Studio:**  For C++ development on Windows.\n*   **XCode:** For C++ development on macOS.\n*   **Rider for Unreal Engine:** Cross-platform IDE for Unreal Engine development with C++ and Blueprints.\n*   **Substance Painter:** For creating and texturing materials.\n*   **Blender/Maya/3ds Max:** For creating 3D models and animations.\n*   **Perforce/Git:** For version control.\n*   **RenderDoc/PIX:** For GPU debugging and profiling.\n\n### 7.2 Build Configuration\n\n*   **Use Development Builds:** Use development builds for debugging and testing.\n*   **Use Shipping Builds:** Use shipping builds for release.\n*   **Configure Build Settings:** Configure build settings such as optimization level and debug information.\n*   **Use Build Automation:** Use build automation tools to automate the build process.\n*   **Set up Build Targets:** Properly configure build targets based on desired device platform (desktop, mobile, console, etc.)\n\n### 7.3 Linting and Formatting\n\n*   **Use a Code Linter:** Use a code linter to enforce code style and identify potential errors.\n*   **Use a Code Formatter:** Use a code formatter to automatically format code.\n*   **Follow the Unreal Engine Coding Standard:** Follow the Unreal Engine coding standard for consistency.\n*   **Configure Editor Settings:** Configure editor settings to automatically format code on save.\n\n### 7.4 Deployment\n\n*   **Package the Game:** Package the game for the target platform.\n*   **Test the Packaged Game:** Test the packaged game thoroughly before release.\n*   **Use a Deployment Platform:** Use a deployment platform such as Steam or the Epic Games Store.\n*   **Follow Platform-Specific Requirements:**  Follow platform-specific requirements for deployment.\n\n### 7.5 CI/CD Integration\n\n*   **Use a CI/CD System:** Use a CI/CD system such as Jenkins, Travis CI, or GitLab CI.\n*   **Automate Builds and Tests:** Automate builds and tests as part of the CI/CD pipeline.\n*   **Integrate with Version Control:** Integrate the CI/CD system with the version control system.\n*   **Automate Deployment:** Automate deployment to the target platform as part of the CI/CD pipeline.\n*   **Trigger Builds on Code Changes:**  Configure the CI/CD system to trigger builds automatically on code changes.",
    "metadata": {
      "globs": "*.h,*.cpp,*.uasset,*.umap,*.ini",
      "format": "mdc",
      "originalFile": "unreal-engine.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "unreal",
      "engine",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "covers",
      "code",
      "unreal-engine",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "unreal-engine",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-vercel",
    "description": "Enforces Vercel's recommended coding style, optimization strategies, and security best practices. This guide helps developers build performant, secure, and maintainable applications on the Vercel platform.",
    "author": "sanjeed5",
    "tags": [
      "vercel",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vercel.mdc",
    "content": "- Adhere to Vercel's Style Guide: Utilize linting and styling tools configured according to the Vercel Style Guide for consistent code formatting and style.  Use `@file vercel_style_guide.mdc` to include style guide details.\n- Enforce Consistent Coding Style:  Integrate ESLint, Prettier, and TypeScript to automatically enforce coding style and prevent stylistic inconsistencies.  Refer to [Vercel's documentation](https://vercel.com/docs) for setup instructions.\n- Optimize Codebase Performance: Focus on optimizing the codebase for faster loading times and improved user experience. Includes optimizing cache, assets, and serverless functions.\n- Implement Conformance Checks: Utilize Vercel's Conformance tools to automatically check for performance, security, and code health issues.\n\n## 1. Code Organization and Structure:\n\n- **Directory Structure:**\n    - Adopt a clear and consistent directory structure (e.g., `components`, `pages`, `lib`, `api`, `styles`, `public`).  Group related files logically to improve maintainability.\n    - Use a `src` directory to encapsulate all source code, separating it from configuration files and other project assets.\n- **File Naming Conventions:**\n    - Use descriptive and consistent file names (e.g., `Button.tsx`, `useUser.ts`, `api/products.js`).\n    - Prefer camelCase for JavaScript/TypeScript files and kebab-case for CSS/SCSS files.\n- **Module Organization:**\n    - Organize code into reusable modules or components. Favor small, focused modules with well-defined interfaces.\n    - Use ES modules (`import`/`export`) for modularity and dependency management.\n- **Component Architecture:**\n    - Employ a component-based architecture (e.g., using React, Vue, or Svelte) to build reusable UI elements.\n    - Follow the principles of separation of concerns and single responsibility.\n    - Consider using a design system or component library to maintain consistency across the application.\n- **Code Splitting Strategies:**\n    - Implement code splitting to reduce the initial bundle size and improve loading times.  Use dynamic imports for route-based or component-based splitting.\n    - Analyze bundle size using tools like `webpack-bundle-analyzer` to identify large dependencies.\n\n## 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns Specific to Vercel:**\n    - Serverless Functions: Use serverless functions for API endpoints and background tasks. Optimize function size and execution time to minimize cold starts.\n    - Edge Functions: Use edge functions to perform operations closer to the user, reducing latency for geographically distributed users.\n    - Incremental Static Regeneration (ISR): Use ISR to combine the benefits of static generation and server-side rendering.\n- **Recommended Approaches for Common Tasks:**\n    - Data Fetching: Use `getStaticProps` or `getServerSideProps` in Next.js for data fetching in pages.\n    - API Routes: Create API routes in the `pages/api` directory of a Next.js project for handling API requests.\n    - Environment Variables: Use environment variables to store sensitive information and configuration settings.\n- **Anti-patterns and Code Smells to Avoid:**\n    - Large components: Break down large components into smaller, more manageable pieces.\n    - Deeply nested components: Avoid excessive nesting of components, which can make code harder to read and maintain.\n    - Over-fetching data: Fetch only the data that is needed by a component.\n    - Mutating state directly: Avoid mutating state directly, which can lead to unexpected behavior.\n- **State Management Best Practices:**\n    - Choose a state management solution (e.g., Redux, Zustand, Recoil, React Context) that is appropriate for the application's complexity.\n    - Follow recommended patterns for managing state (e.g., reducers, actions, selectors).\n    - Avoid storing too much data in the global state.\n- **Error Handling Patterns:**\n    - Implement comprehensive error handling throughout the application.\n    - Use try-catch blocks to catch exceptions.\n    - Log errors to a monitoring service.\n    - Display user-friendly error messages.\n\n## 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - Minimize bundle size by removing unused code and dependencies (tree shaking).\n    - Compress images and other assets.\n    - Use a content delivery network (CDN) to serve static assets.\n    - Optimize database queries.\n    - Cache frequently accessed data.\n- **Memory Management:**\n    - Avoid memory leaks by properly releasing resources.\n    - Use garbage collection to reclaim unused memory.\n    - Profile application memory usage to identify potential issues.\n- **Rendering Optimization:**\n    - Use memoization techniques (e.g., `React.memo`, `useMemo`) to prevent unnecessary re-renders.\n    - Virtualize long lists to improve rendering performance.\n    - Use code splitting to reduce the initial bundle size.\n- **Bundle Size Optimization:**\n    - Analyze bundle size with tools like `webpack-bundle-analyzer` or `source-map-explorer`.\n    - Remove unused dependencies.\n    - Minify code.\n    - Compress code with gzip or Brotli.\n- **Lazy Loading Strategies:**\n    - Implement lazy loading for images, components, and routes.\n    - Use the `IntersectionObserver` API to detect when an element is visible in the viewport.\n\n## 4. Security Best Practices:\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - Cross-site scripting (XSS): Sanitize user input to prevent XSS attacks.  Use a library like DOMPurify.\n    - Cross-site request forgery (CSRF): Use CSRF tokens to protect against CSRF attacks.\n    - SQL injection: Use parameterized queries or an ORM to prevent SQL injection attacks.\n    - Authentication and authorization vulnerabilities: Implement strong authentication and authorization mechanisms.\n- **Input Validation:**\n    - Validate all user input on both the client and server sides.\n    - Use a validation library to simplify the validation process.\n- **Authentication and Authorization Patterns:**\n    - Use a secure authentication protocol (e.g., OAuth 2.0, JWT).\n    - Implement role-based access control (RBAC) to restrict access to sensitive resources.\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS to secure communication between the client and server.\n    - Protect against data breaches by implementing appropriate security measures.\n- **Secure API Communication:**\n    - Use HTTPS to encrypt API traffic.\n    - Authenticate and authorize API requests.\n    - Limit API rate to prevent abuse.\n\n## 5. Testing Approaches:\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual components, functions, and modules.\n    - Use a unit testing framework (e.g., Jest, Mocha, Jasmine).\n    - Mock external dependencies.\n- **Integration Testing:**\n    - Write integration tests to verify that different parts of the application work together correctly.\n    - Test interactions between components, modules, and APIs.\n- **End-to-End Testing:**\n    - Write end-to-end tests to simulate user interactions and verify that the application works as expected.\n    - Use an end-to-end testing framework (e.g., Cypress, Playwright).\n- **Test Organization:**\n    - Organize tests into separate directories based on the type of test (e.g., unit, integration, e2e).\n    - Use descriptive test names.\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate components and functions during testing.\n    - Mock external dependencies to avoid making real API calls.\n\n## 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes Developers Make:**\n    - Over-reliance on client-side rendering.\n    - Neglecting performance optimization.\n    - Ignoring security vulnerabilities.\n    - Not writing enough tests.\n- **Edge Cases to Be Aware Of:**\n    - Handling errors gracefully.\n    - Supporting different browsers and devices.\n    - Dealing with slow network connections.\n- **Version-Specific Issues:**\n    - Be aware of breaking changes in Vercel and its dependencies.\n    - Test application thoroughly after upgrading Vercel or any dependencies.\n- **Compatibility Concerns:**\n    - Ensure that the application is compatible with different browsers, devices, and operating systems.\n- **Debugging Strategies:**\n    - Use browser developer tools to debug client-side code.\n    - Use server-side logging to debug server-side code.\n    - Use a debugger to step through code and inspect variables.\n\n## 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - VS Code with extensions for ESLint, Prettier, and TypeScript.\n    - Chrome DevTools for debugging.\n    - Vercel CLI for deploying and managing applications.\n- **Build Configuration:**\n    - Configure build scripts to optimize code and assets.\n    - Use environment variables to configure the build process.\n- **Linting and Formatting:**\n    - Use ESLint and Prettier to enforce consistent code style.\n    - Configure linting and formatting rules to match the Vercel Style Guide.\n- **Deployment Best Practices:**\n    - Deploy application to Vercel using the Vercel CLI or Git integration.\n    - Configure environment variables for production.\n    - Monitor application performance and logs.\n- **CI/CD Integration:**\n    - Integrate with a CI/CD pipeline (e.g., GitHub Actions, CircleCI) to automate the build, test, and deployment process.\n    - Run tests and linters as part of the CI/CD pipeline.\n\n@file vercel_style_guide.mdc",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.md,*.mdx,*.json,*.yml,*.yaml,*.html,*.css,*.scss,*.sass",
      "format": "mdc",
      "originalFile": "vercel.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "vercel",
      "enforces",
      "recommended",
      "coding",
      "style",
      "optimization",
      "strategies",
      "security",
      "best",
      "practices",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vercel",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-vite",
    "description": "This rule provides comprehensive best practices, coding standards, and guidelines for developing applications using Vite, covering aspects from code organization and performance to security and testing.",
    "author": "sanjeed5",
    "tags": [
      "vite",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vite.mdc",
    "content": "- **Introduction:**\n  - This document outlines best practices for developing applications using Vite, a fast and opinionated build tool that aims to provide a better development experience.\n\n- **Prerequisites:**\n  - Ensure Node.js and npm/yarn/pnpm are installed.\n  - Familiarity with JavaScript/TypeScript, HTML, and CSS.\n\n- **Code Organization and Structure:**\n  - **Directory Structure:**\n    - Adopt a modular structure based on features or components.\n    \n    src/\n    ├── components/\n    │   ├── Button/\n    │   │   ├── Button.tsx\n    │   │   ├── Button.module.css\n    │   │   └── Button.test.tsx\n    │   ├── Input/\n    │   │   └── ...\n    ├── pages/\n    │   ├── Home.tsx\n    │   ├── About.tsx\n    │   └── ...\n    ├── services/\n    │   ├── api.ts\n    │   └── ...\n    ├── utils/\n    │   ├── helpers.ts\n    │   └── ...\n    ├── App.tsx\n    ├── main.tsx\n    └── vite-env.d.ts\n    \n  - **File Naming Conventions:**\n    - Use descriptive and consistent names.\n    - Component files: `ComponentName.tsx` or `component-name.tsx`.\n    - Style files: `ComponentName.module.css` or `component-name.module.css`.\n    - Test files: `ComponentName.test.tsx` or `component-name.test.tsx`.\n  - **Module Organization:**\n    - Group related files into modules or folders.\n    - Use `index.ts` (barrel files) to simplify imports.\n    typescript\n    // src/components/Button/index.ts\n    export { default as Button } from './Button';\n    \n  - **Component Architecture:**\n    - Favor small, reusable components.\n    - Utilize functional components and hooks in React (or equivalent in Vue/Svelte).\n    - Separate concerns: presentational vs. container components.\n  - **Code Splitting Strategies:**\n    - Use dynamic imports (`import()`) for lazy loading.\n    - Split routes using `React.lazy` or Vue's dynamic component feature.\n    - Configure Vite's `rollupOptions.output.manualChunks` for fine-grained control.\n\n- **Common Patterns and Anti-patterns:**\n  - **Design Patterns:**\n    - **Higher-Order Components (HOCs):**  Carefully consider alternatives like render props or hooks for better composability.\n    - **Render Props:**  Useful for sharing logic between components, but can lead to deeply nested structures.\n    - **Hooks:**  Promote code reuse and simplify component logic.\n  - **Recommended Approaches:**\n    - Use environment variables for configuration.\n    - Implement a consistent API client for data fetching.\n    - Centralize state management using libraries like Redux, Zustand, or Vuex.\n  - **Anti-patterns:**\n    - Avoid deeply nested component trees without proper optimization.\n    - Don't mutate state directly; use setState or Vue's reactivity system.\n    - Overusing global styles; prefer CSS modules or styled components.\n  - **State Management:**\n    - Choose a state management solution based on application complexity.\n    - Use Redux for complex state management with predictable state transitions and time travel debugging.\n    - Consider Zustand or Jotai for simpler state management with a smaller bundle size.\n    - For Vue, Vuex or Pinia are popular choices.\n  - **Error Handling:**\n    - Implement global error boundaries to catch unhandled exceptions.\n    - Use try-catch blocks for local error handling.\n    - Log errors to a central error tracking service (e.g., Sentry, Rollbar).\n\n- **Performance Considerations:**\n  - **Optimization Techniques:**\n    - Use production-ready code minification and bundling.\n    - Optimize images and other assets using tools like `imagemin` or Vite plugins.\n  - **Memory Management:**\n    - Avoid memory leaks by properly cleaning up event listeners and subscriptions.\n    - Use `useEffect` with a cleanup function in React (or `onUnmounted` in Vue).\n  - **Rendering Optimization:**\n    - Use memoization techniques (`React.memo`, `useMemo`, `shouldComponentUpdate`) to prevent unnecessary re-renders.\n    - Virtualize large lists using libraries like `react-window` or `react-virtualized`.\n  - **Bundle Size Optimization:**\n    - Analyze bundle size using `rollup-plugin-visualizer` or similar tools.\n    - Remove unused code using tree shaking.\n    - Use code splitting to load only necessary code.\n  - **Lazy Loading:**\n    - Lazy load components and images that are not immediately visible.\n    - Use `IntersectionObserver` to trigger loading when elements enter the viewport.\n\n- **Security Best Practices:**\n  - **Common Vulnerabilities:**\n    - Cross-Site Scripting (XSS): Sanitize user input to prevent XSS attacks.\n    - Cross-Site Request Forgery (CSRF): Use CSRF tokens to protect against CSRF attacks.\n    - Injection Attacks: Validate and sanitize input to prevent SQL injection and other injection attacks.\n  - **Input Validation:**\n    - Validate all user input on both the client and server side.\n    - Use a library like `yup` or `joi` for schema validation.\n  - **Authentication and Authorization:**\n    - Use a secure authentication and authorization mechanism (e.g., OAuth 2.0, JWT).\n    - Store passwords securely using bcrypt or Argon2.\n  - **Data Protection:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use HTTPS for all communication.\n  - **Secure API Communication:**\n    - Implement proper CORS configuration to prevent unauthorized access to your API.\n    - Rate limit API requests to prevent abuse.\n\n- **Testing Approaches:**\n  - **Unit Testing:**\n    - Write unit tests for individual components and functions.\n    - Use testing libraries like Jest, Mocha, or Vitest.\n    - Mock dependencies to isolate units under test.\n  - **Integration Testing:**\n    - Test the interaction between different parts of your application.\n    - Use testing libraries like React Testing Library or Vue Test Utils.\n  - **End-to-End Testing:**\n    - Test the entire application from the user's perspective.\n    - Use tools like Cypress or Playwright.\n  - **Test Organization:**\n    - Organize tests into folders based on features or components.\n    - Use descriptive test names.\n  - **Mocking and Stubbing:**\n    - Use mocks and stubs to isolate units under test.\n    - Avoid over-mocking; test the actual implementation whenever possible.\n\n- **Common Pitfalls and Gotchas:**\n  - **Frequent Mistakes:**\n    - Improperly handling asynchronous operations.\n    - Neglecting accessibility considerations.\n    - Using outdated dependencies.\n  - **Edge Cases:**\n    - Handling different screen sizes and devices.\n    - Supporting internationalization and localization.\n    - Dealing with slow network connections.\n  - **Version-Specific Issues:**\n    - Be aware of breaking changes in Vite and its plugins.\n    - Pin dependencies to specific versions to avoid unexpected issues.\n  - **Compatibility Concerns:**\n    - Test your application in different browsers and devices.\n    - Use polyfills to support older browsers.\n  - **Debugging Strategies:**\n    - Use browser developer tools to inspect the DOM, network requests, and console output.\n    - Use debugging tools like `debugger` or `console.log`.\n\n- **Tooling and Environment:**\n  - **Recommended Tools:**\n    - VS Code with extensions like ESLint, Prettier, and TypeScript.\n    - Chrome DevTools or Firefox Developer Tools.\n    - npm/yarn/pnpm for package management.\n  - **Build Configuration:**\n    - Configure Vite using `vite.config.ts` or `vite.config.js`.\n    - Customize build options like `outDir`, `assetsDir`, and `rollupOptions`.\n  - **Linting and Formatting:**\n    - Use ESLint with recommended rulesets (e.g., `eslint:recommended`, `plugin:react/recommended`).\n    - Use Prettier for code formatting.\n    - Configure ESLint and Prettier to work together.\n  - **Deployment Best Practices:**\n    - Deploy to a CDN for optimal performance.\n    - Use environment variables for configuration.\n    - Set up proper caching headers.\n  - **CI/CD Integration:**\n    - Integrate with a CI/CD pipeline for automated testing and deployment.\n    - Use tools like GitHub Actions, GitLab CI, or CircleCI.\n\n- **TypeScript Best Practices (when using TypeScript):**\n  - **Strict Type-Checking:**\n    - Enable strict type-checking options in `tsconfig.json` (e.g., `strict: true`, `noImplicitAny: true`, `strictNullChecks: true`).\n  - **Typing Props and State:**\n    - Use interfaces or types to define the shape of props and state.\n    typescript\n    interface ButtonProps {\n      label: string;\n      onClick: () => void;\n    }\n\n    const Button: React.FC<ButtonProps> = ({ label, onClick }) => {\n      return <button onClick={onClick}>{label}</button>;\n    };\n    \n\n- **ESLint Configuration (Example):**\n  javascript\n  module.exports = {\n    env: {\n      browser: true,\n      es2021: true,\n      node: true,\n    },\n    extends: [\n      'eslint:recommended',\n      'plugin:react/recommended',\n      'plugin:@typescript-eslint/recommended',\n      'prettier',\n    ],\n    parser: '@typescript-eslint/parser',\n    parserOptions: {\n      ecmaFeatures: {\n        jsx: true,\n      },\n      ecmaVersion: 12,\n      sourceType: 'module',\n    },\n    plugins: ['react', '@typescript-eslint', 'prettier'],\n    rules: {\n      'prettier/prettier': 'error',\n      'react/react-in-jsx-scope': 'off',\n      '@typescript-eslint/explicit-function-return-type': 'off',\n      '@typescript-eslint/no-explicit-any': 'warn',\n    },\n  };\n  \n\n- **Conclusion:**\n  - Following these best practices will help you build efficient, maintainable, and secure applications with Vite.  Continuously review and update your practices as the library and ecosystem evolve.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.vue,*.svelte",
      "format": "mdc",
      "originalFile": "vite.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "vite",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "coding",
      "standards",
      "guidelines",
      "developing",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vite",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-vitest",
    "description": "This rule file provides comprehensive best practices for using Vitest, covering code organization, testing strategies, performance, and security within Vitest projects. These guidelines ensure clean, maintainable, and reliable test suites.",
    "author": "sanjeed5",
    "tags": [
      "vitest",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "quality-testing",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vitest.mdc",
    "content": "# Vitest Best Practices and Coding Standards\n\nThis document outlines best practices for using Vitest to create reliable, maintainable, and performant test suites. It covers various aspects of testing, from code organization to performance considerations and security measures.\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure\n\n*   **Keep tests close to the source code:** Place test files in the same directory as the components or modules they test. This improves discoverability and maintainability.\n\n    \n    src/\n      components/\n        MyComponent.vue\n        MyComponent.spec.ts\n        MyComponent.test.ts  # Alternative naming\n      utils/\n        math.ts\n        math.test.ts\n      App.vue\n      App.spec.ts\n    \n\n*   **Use a dedicated `tests` directory for end-to-end tests or shared utilities:**  For larger projects, a `tests` directory at the root level can house end-to-end tests, integration tests that require a specific environment, or shared testing utilities.\n\n    \n    tests/\n      e2e/\n        specs/\n          home.spec.ts\n        support/\n          commands.ts\n      unit/\n        utils.test.ts # Tests for general utilities\n      integration/\n        db.setup.ts # Setup for integration tests \n    src/ \n      ...\n    \n\n### 1.2 File Naming Conventions\n\n*   **Use consistent naming:** Adopt a consistent naming scheme for test files. Common conventions include:\n    *   `[component/module].spec.ts`\n    *   `[component/module].test.ts`\n    *   `[component/module].e2e.ts` (for end-to-end tests)\n\n*   **Be descriptive:** Name test files to clearly indicate what they are testing. For example, `MyComponent.props.spec.ts` might test specific props of `MyComponent`.\n\n### 1.3 Module Organization\n\n*   **Group related tests:** Organize tests into modules using `describe` blocks. This improves readability and helps structure test output.\n\n    typescript\n    import { describe, it, expect } from 'vitest';\n    import { add } from './math';\n\n    describe('Math functions', () => {\n      describe('add', () => {\n        it('should add two numbers correctly', () => {\n          expect(add(2, 3)).toBe(5);\n        });\n\n        it('should handle negative numbers', () => {\n          expect(add(-1, 1)).toBe(0);\n        });\n      });\n    });\n    \n\n### 1.4 Component Architecture\n\n*   **Test component logic separately:** Extract complex logic from components into separate, testable functions or modules. This promotes reusability and simplifies component testing.\n\n*   **Focus on component interactions:**  When testing components, concentrate on verifying that the component renders correctly given certain props or state and that it emits the correct events in response to user interactions.\n\n### 1.5 Code Splitting Strategies\n\n*   **Test code splitting:**  If your application uses code splitting, ensure your tests cover different code chunks and lazy-loaded modules.\n\n*   **Mock dynamic imports:**  Use Vitest's mocking capabilities to simulate dynamic imports during testing.\n\n    typescript\n    import { describe, it, expect, vi } from 'vitest';\n\n    describe('Dynamic import', () => {\n      it('should mock dynamic import', async () => {\n        const mockModule = { value: 'mocked' };\n        vi.mock('./dynamic-module', () => ({\n          default: mockModule,\n        }));\n\n        const dynamicModule = await import('./dynamic-module');\n        expect(dynamicModule.default).toBe(mockModule);\n      });\n    });\n    \n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns Specific to Vitest\n\n*   **AAA (Arrange, Act, Assert):** Structure each test case following the AAA pattern for clarity and maintainability.\n\n    typescript\n    it('should add two numbers correctly', () => {\n      // Arrange\n      const a = 2;\n      const b = 3;\n\n      // Act\n      const result = add(a, b);\n\n      // Assert\n      expect(result).toBe(5);\n    });\n    \n\n*   **Page Object Model (POM):** For end-to-end tests, use the Page Object Model to abstract away the details of the user interface and make tests more resilient to UI changes. Define dedicated classes representing different pages or components.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n*   **Mocking external dependencies:**  Use Vitest's mocking capabilities to isolate units of code during testing. Use `vi.mock()` to mock modules and `vi.spyOn()` to spy on specific methods or properties.\n\n*   **Testing asynchronous code:** Utilize `async/await` and Vitest's `expect.resolves` and `expect.rejects` matchers for testing asynchronous functions.\n\n    typescript\n    it('should resolve with the correct value', async () => {\n      await expect(Promise.resolve(42)).resolves.toBe(42);\n    });\n\n    it('should reject with an error', async () => {\n      await expect(Promise.reject(new Error('Something went wrong'))).rejects.toThrow('Something went wrong');\n    });\n    \n\n### 2.3 Anti-patterns and Code Smells to Avoid\n\n*   **Over-mocking:** Avoid mocking everything.  Mock only external dependencies or components that are not under test.  Testing against mocks rather than real implementations reduces test confidence.\n\n*   **Flaky tests:**  Tests that pass or fail intermittently are a sign of underlying issues.  Investigate flaky tests to identify and fix the root cause, such as race conditions or reliance on external resources.\n\n*   **Ignoring edge cases:** Ensure your tests cover all possible scenarios, including edge cases, error conditions, and boundary values. Don't only test the \"happy path\".\n\n*   **Long test functions:** Break down overly complex test functions into smaller, more focused tests. This improves readability and makes it easier to identify the cause of failures.\n\n### 2.4 State Management Best Practices\n\n*   **Isolate state:**  When testing code that relies on state management libraries (e.g., Vuex, Pinia, Redux), isolate the state and actions being tested.\n\n*   **Mock store actions/getters:** Mock actions and getters to control the state during testing and verify that they are called correctly.\n\n    typescript\n    import { describe, it, expect, vi } from 'vitest';\n    import { useStore } from './store';\n\n    describe('Store actions', () => {\n      it('should dispatch the correct action', () => {\n        const store = useStore();\n        const mockAction = vi.fn();\n        store.dispatch = mockAction;\n\n        store.commit('increment');\n        expect(mockAction).toHaveBeenCalledWith('increment');\n      });\n    });\n    \n\n### 2.5 Error Handling Patterns\n\n*   **Test error handling:** Ensure your tests cover error handling scenarios.  Use `try...catch` blocks or `expect.rejects` to verify that errors are thrown and handled correctly.\n\n*   **Mock error responses:** Mock API responses to simulate error conditions and test how your code handles them.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n*   **Run tests in parallel:** Vitest supports running tests in parallel. Enable this feature to speed up test execution.\n\n    json\n    // vitest.config.ts\n    import { defineConfig } from 'vitest/config'\n\n    export default defineConfig({\n      test: {\n        threads: true,  // Enable parallel execution\n      },\n    })\n    \n\n*   **Use `--changed` and `--related` flags:**  When running tests, use the `--changed` flag to only run tests that have changed since the last commit or the `--related` flag to run tests related to specific files.\n\n    bash\n    vitest --changed\n    vitest --related src/components/MyComponent.vue\n    \n\n*   **Optimize test setup:**  Minimize the amount of setup required for each test.  Use `beforeAll` and `afterAll` hooks to perform setup and teardown operations once for each test suite, rather than for each test case.\n\n### 3.2 Memory Management\n\n*   **Clean up after tests:**  Ensure that your tests do not leak memory.  Use `afterEach` hooks to clean up any resources created during the test, such as mocks or temporary files.\n\n*   **Avoid creating large objects in tests:**  Minimize the size of objects created in tests to reduce memory consumption.\n\n### 3.3 Rendering Optimization\n\n*   **Use shallow rendering:**  When testing components, use shallow rendering to avoid rendering the entire component tree. This can significantly improve test performance.\n\n    typescript\n    import { shallowMount } from '@vue/test-utils';\n    import MyComponent from './MyComponent.vue';\n\n    it('should render correctly', () => {\n      const wrapper = shallowMount(MyComponent);\n      expect(wrapper.exists()).toBe(true);\n    });\n    \n\n### 3.4 Bundle Size Optimization\n\n*   **Keep tests small:**  Avoid including unnecessary dependencies in your test files.  This can help reduce the bundle size of your tests and improve startup time.\n\n### 3.5 Lazy Loading Strategies\n\n*   **Mock lazy-loaded modules:**  When testing code that uses lazy loading, mock the lazy-loaded modules to avoid loading them during testing.  This can improve test performance and reduce dependencies.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS vulnerabilities by sanitizing user input and encoding output. Ensure the testing framework is not vulnerable either. Check versions of plugins.\n\n*   **Injection Attacks:**  Prevent injection attacks by validating user input and using parameterized queries.\n\n*   **Sensitive Data Exposure:** Avoid storing sensitive data in test files. Use environment variables or secure configuration files to manage sensitive data.\n\n### 4.2 Input Validation\n\n*   **Test input validation:**  Ensure your tests cover input validation scenarios.  Verify that your code correctly validates user input and handles invalid input gracefully.\n\n### 4.3 Authentication and Authorization Patterns\n\n*   **Mock authentication:**  When testing code that requires authentication, mock the authentication service to avoid making actual API calls.  Verify that your code correctly handles authenticated and unauthenticated states.\n\n*   **Test authorization:**  Ensure your tests cover authorization scenarios.  Verify that your code correctly enforces access control and prevents unauthorized access to resources.\n\n### 4.4 Data Protection Strategies\n\n*   **Protect sensitive data in tests:**  Avoid including sensitive data in your test files.  Use mock data or anonymized data for testing.\n\n### 4.5 Secure API Communication\n\n*   **Mock API responses:**  Mock API responses to avoid making actual API calls during testing.  Use HTTPS for secure communication.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing Strategies\n\n*   **Focus on individual units:**  Unit tests should focus on testing individual functions, classes, or modules in isolation. Avoid testing multiple units of code in a single test.\n\n*   **Test all code paths:** Ensure your unit tests cover all possible code paths, including normal execution paths, error conditions, and edge cases.\n\n*   **Use mocks and stubs:** Use mocks and stubs to isolate units of code and control their behavior during testing. \n\n### 5.2 Integration Testing\n\n*   **Test interactions between units:**  Integration tests should focus on testing the interactions between different units of code. Verify that units of code work together correctly.\n\n*   **Use real dependencies:**  Use real dependencies in integration tests whenever possible.  This can help ensure that your code works correctly in a real-world environment.\n\n### 5.3 End-to-End Testing\n\n*   **Test the entire application:** End-to-end tests should focus on testing the entire application, from the user interface to the backend services. Verify that the application works correctly from the user's perspective.\n\n*   **Use a real browser:**  Use a real browser for end-to-end testing. This can help ensure that your application works correctly in different browsers and environments.\n\n### 5.4 Test Organization\n\n*   **Group related tests:**  Organize tests into modules using `describe` blocks. This improves readability and helps structure test output. (See 1.3 Module Organization)\n\n*   **Use meaningful test names:** Use descriptive test names that clearly indicate what the test is verifying. This makes it easier to understand the purpose of the test and to identify the cause of failures.\n\n*   **Keep tests short and focused:** Keep tests short and focused on a single aspect of the code. This improves readability and makes it easier to maintain the tests.\n\n### 5.5 Mocking and Stubbing\n\n*   **Use mocks to verify interactions:**  Use mocks to verify that functions are called with the correct arguments and that they return the correct values.\n\n*   **Use stubs to control behavior:** Use stubs to control the behavior of functions during testing. This allows you to simulate different scenarios and test how your code handles them.\n\n*   **Avoid over-mocking:** Only mock dependencies that are not under test.  Over-mocking can lead to tests that are brittle and do not accurately reflect the behavior of the code.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes Developers Make\n\n*   **Not writing enough tests:** Ensure that you have sufficient test coverage to catch bugs and prevent regressions.\n\n*   **Writing brittle tests:** Avoid writing tests that are too tightly coupled to the implementation details of the code. This makes the tests brittle and difficult to maintain.\n\n*   **Ignoring test failures:** Address test failures promptly.  Ignoring test failures can lead to regressions and make it more difficult to maintain the code.\n\n### 6.2 Edge Cases to Be Aware Of\n\n*   **Null and undefined values:** Ensure your tests cover scenarios where values are null or undefined.\n\n*   **Empty strings and arrays:** Ensure your tests cover scenarios where strings or arrays are empty.\n\n*   **Boundary values:** Ensure your tests cover boundary values, such as the minimum and maximum values of numeric types.\n\n### 6.3 Version-Specific Issues\n\n*   **Keep Vitest up to date:** Stay up-to-date with the latest version of Vitest to benefit from bug fixes, performance improvements, and new features.\n\n### 6.4 Compatibility Concerns\n\n*   **Test on different browsers and environments:** Ensure your tests cover different browsers and environments to catch compatibility issues.\n\n### 6.5 Debugging Strategies\n\n*   **Use debugging tools:** Utilize debugging tools to step through your tests and identify the cause of failures.  Vitest integrates with popular debuggers.\n\n*   **Write clear and concise tests:** Write clear and concise tests to make it easier to understand the purpose of the test and to identify the cause of failures.\n\n*   **Use logging:**  Add logging statements to your tests to help track the flow of execution and identify the source of problems.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n*   **VS Code with the Vitest extension:** VS Code with the Vitest extension provides a rich development experience, including test discovery, execution, and debugging.\n\n*   **Other IDEs with Vitest support:** Many other IDEs, such as WebStorm and IntelliJ IDEA, also offer support for Vitest.\n\n### 7.2 Build Configuration\n\n*   **Use a build tool:** Use a build tool, such as Vite or esbuild, to bundle your code and optimize it for testing.\n\n*   **Configure Vitest:** Configure Vitest to suit your project's needs.  Use the `vitest.config.ts` file to customize Vitest's behavior.\n\n### 7.3 Linting and Formatting\n\n*   **Use ESLint and Prettier:**  Use ESLint and Prettier to enforce consistent coding styles and catch potential errors. Integrate these tools into your development workflow.\n\n### 7.4 Deployment Best Practices\n\n*   **Run tests before deployment:** Always run your tests before deploying your code to ensure that it is working correctly.  Automate this process as part of your CI/CD pipeline.\n\n### 7.5 CI/CD Integration\n\n*   **Integrate Vitest with your CI/CD pipeline:**  Integrate Vitest with your CI/CD pipeline to automatically run tests on every commit. This helps catch bugs early and prevent regressions.\n\n*   **Use a CI/CD service:** Use a CI/CD service, such as GitHub Actions or GitLab CI, to automate your build, test, and deployment processes.\n\n## Conclusion\n\nBy following these best practices, you can create robust and maintainable test suites with Vitest that ensure the quality and reliability of your code.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx,*.vue,*.svelte,*.spec,*.test.*",
      "format": "mdc",
      "originalFile": "vitest.mdc"
    },
    "subcategory": "testing",
    "keywords": [
      "cursor",
      "vitest",
      "this",
      "rule",
      "file",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "using",
      "covering",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "testing"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vitest",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-vllm",
    "description": "This rule outlines the best practices and coding standards for developing with the vllm library, ensuring code quality, performance, and maintainability. It covers code organization, performance considerations, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "vllm",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vllm.mdc",
    "content": "- ## General\n  - Adhere to the Google Python Style Guide: vllm projects should strictly follow the Google Python Style Guide for consistency and readability.\n  - Adhere to the Google C++ Style Guide (where applicable, especially for backend components).\n  - Pass all linter checks: Ensure code passes all configured linter checks (e.g., pylint, flake8) before committing.\n  - Always use UV when installing dependencies.\n  - Always use Python 3.12 or higher.\n  - Prefer classes over bare functions for better code organization and state management (where appropriate).\n\n- ## Code Organization and Structure:\n  - **Directory Structure Best Practices:**\n    - `vllm/` (Root directory):\n      - `api/`: Contains API endpoints and related logic.\n      - `core/`: Core functionalities and algorithms.\n      - `layers/`: Custom layers for the models.\n      - `models/`: Model definitions and configurations.\n      - `sampling/`: Sampling algorithms.\n      - `sequence/`: Sequence management and data structures.\n      - `utils/`: Utility functions and helper modules.\n      - `tests/`: Unit and integration tests.\n      - `examples/`: Example usage and demonstrations.\n      - `docs/`: Documentation.\n    - Maintain clear separation of concerns.\n  - **File Naming Conventions:**\n    - Use descriptive and meaningful names for files and modules (e.g., `attention_layer.py`, `model_loader.py`).\n    - Follow snake_case for Python files and variables.\n  - **Module Organization:**\n    - Group related functionalities into modules.\n    - Use `__init__.py` files to define packages and control module imports.\n  - **Component Architecture:**\n    - Design components with clear interfaces and responsibilities.\n    - Favor composition over inheritance to promote flexibility and reusability.\n  - **Code Splitting Strategies:**\n    - Break down large modules into smaller, more manageable files.\n    - Utilize lazy loading or dynamic imports to reduce startup time.\n\n- ## Common Patterns and Anti-patterns:\n  - **Design Patterns Specific to vllm:**\n    - **Model Abstraction:** Decouple the model implementation from the core engine.\n    - **Sequence Manager:** Centralized management of sequences and their states.\n    - **Asynchronous Execution:** Use asyncio to handle concurrent requests and I/O operations.\n  - **Recommended Approaches for Common Tasks:**\n    - **Model Loading:** Implement a robust model loading mechanism with caching and error handling.\n    - **Tokenization:** Use a dedicated tokenizer class to handle tokenization and detokenization.\n    - **Inference:** Design an efficient inference pipeline with batching and optimized tensor operations.\n  - **Anti-patterns and Code Smells to Avoid:**\n    - **God Classes:** Avoid creating large classes with too many responsibilities.\n    - **Code Duplication:** Refactor duplicated code into reusable functions or classes.\n    - **Magic Numbers:** Use named constants for configuration values.\n  - **State Management Best Practices:**\n    - Use immutable data structures to avoid unintended side effects.\n    - Manage state within dedicated classes or modules.\n    - Avoid global state where possible.\n  - **Error Handling Patterns:**\n    - Use exceptions to handle errors and unexpected conditions.\n    - Provide informative error messages.\n    - Implement retry mechanisms for transient errors.\n\n- ## Performance Considerations:\n  - **Optimization Techniques:**\n    - **Tensor Optimization:** Use optimized tensor operations and data layouts (e.g., `torch.compile`).\n    - **Kernel Fusion:** Fuse multiple operations into a single kernel to reduce overhead.\n    - **Quantization:** Use quantization techniques to reduce model size and memory footprint.\n  - **Memory Management:**\n    - Minimize memory allocations and deallocations.\n    - Use memory pooling to reuse memory buffers.\n    - Profile memory usage to identify bottlenecks.\n  - **Bundle Size Optimization:**\n    - Remove unused dependencies.\n  - **Lazy Loading Strategies:**\n    - Use lazy loading for large modules or resources.\n    - Implement asynchronous loading for non-critical components.\n\n- ## Security Best Practices:\n  - **Common Vulnerabilities and How to Prevent Them:**\n    - **Injection Attacks:** Sanitize user inputs to prevent injection attacks.\n    - **Denial of Service (DoS):** Implement rate limiting and resource management to protect against DoS attacks.\n    - **Data Breaches:** Protect sensitive data with encryption and access controls.\n  - **Input Validation:**\n    - Validate all user inputs before processing.\n    - Use regular expressions or schema validation to enforce input constraints.\n  - **Authentication and Authorization Patterns:**\n    - Implement authentication to verify user identities.\n    - Use authorization to control access to resources.\n  - **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms.\n  - **Secure API Communication:**\n    - Use HTTPS for API communication.\n    - Implement API authentication and authorization.\n\n- ## Testing Approaches:\n  - **Unit Testing Strategies:**\n    - Write unit tests for individual functions and classes.\n    - Use mocking and stubbing to isolate units of code.\n  - **Integration Testing:**\n    - Test the interaction between different modules and components.\n  - **End-to-End Testing:**\n    - Test the entire system from end to end.\n  - **Test Organization:**\n    - Organize tests into separate directories.\n    - Use descriptive names for test files and functions.\n  - **Mocking and Stubbing:**\n    - Use mocking to replace external dependencies with controlled substitutes.\n    - Use stubbing to provide predefined responses for function calls.\n\n- ## Common Pitfalls and Gotchas:\n  - **Frequent Mistakes Developers Make:**\n    - **Incorrect Tensor Shapes:** Ensure tensor shapes are compatible for operations.\n    - **Memory Leaks:** Properly release allocated memory to prevent memory leaks.\n    - **Synchronization Issues:** Avoid race conditions and deadlocks in concurrent code.\n  - **Edge Cases to be Aware Of:**\n    - **Handling Empty Sequences:** Handle empty sequences gracefully.\n    - **Dealing with Unknown Tokens:** Implement a mechanism to handle unknown tokens.\n  - **Version-Specific Issues:**\n      - Keep dependencies up-to-date and be aware of breaking changes when upgrading.\n  - **Compatibility Concerns:**\n    - Ensure compatibility with different hardware platforms (CPU, GPU).\n    - Consider different versions of Python and PyTorch.\n  - **Debugging Strategies:**\n    - Use logging to track program execution.\n    - Use a debugger to step through code and inspect variables.\n    - Profile performance to identify bottlenecks.\n\n- ## Tooling and Environment:\n  - **Recommended Development Tools:**\n    - **VS Code:** A popular code editor with Python and C++ support.\n    - **PyCharm:** An IDE specifically designed for Python development.\n  - **Build Configuration:**\n    - Use `setup.py` or `pyproject.toml` to define project dependencies and build configurations.\n  - **Linting and Formatting:**\n    - Use pylint, flake8, and black to enforce code style.\n  - **Deployment Best Practices:**\n    - Use Docker to containerize the application.\n    - Deploy to a cloud platform such as AWS, Google Cloud, or Azure.\n  - **CI/CD Integration:**\n    - Use a CI/CD pipeline to automate testing and deployment.",
    "metadata": {
      "globs": "*.py",
      "format": "mdc",
      "originalFile": "vllm.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "vllm",
      "this",
      "rule",
      "outlines",
      "best",
      "practices",
      "coding",
      "standards",
      "developing",
      "with",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vllm",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-vue",
    "description": "Comprehensive guidelines for Vue.js development, covering code structure, performance, security, testing, and tooling best practices. This rule provides actionable guidance to enhance code quality, maintainability, and developer productivity in Vue.js projects.",
    "author": "sanjeed5",
    "tags": [
      "vue",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vue.mdc",
    "content": "# Vue.js Best Practices and Coding Standards\n\nThis document outlines best practices for Vue.js development, covering various aspects to ensure high-quality, maintainable, and performant code.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\n*   **Component-Based Structure:** Organize components into logical folders based on their functionality or feature. This improves code readability and maintainability.\n    \n    src/\n    ├── components/\n    │   ├── Button/\n    │   │   ├── Button.vue\n    │   │   └── Button.spec.js\n    │   ├── Input/\n    │   │   ├── Input.vue\n    │   │   └── Input.spec.js\n    │   └── ...\n    ├── views/\n    │   ├── Home.vue\n    │   ├── About.vue\n    │   └── ...\n    ├── services/\n    │   ├── api.js\n    │   └── auth.js\n    ├── store/\n    │   ├── index.js  # Vuex store\n    │   ├── modules/\n    │   │   ├── user.js\n    │   │   └── ...\n    ├── App.vue\n    └── main.js\n    \n*   **Feature-Based Structure:** Alternatively, organize files by feature, grouping components, routes, and store modules related to a specific feature.\n    \n    src/\n    ├── features/\n    │   ├── user-profile/\n    │   │   ├── components/\n    │   │   │   ├── UserProfile.vue\n    │   │   │   └── ...\n    │   │   ├── routes.js\n    │   │   ├── store.js\n    │   │   └── ...\n    │   ├── shopping-cart/\n    │   │   ├── ...\n    │   └── ...\n    ├── App.vue\n    └── main.js\n    \n\n### 1.2. File Naming Conventions\n\n*   **Component Files:** Use PascalCase for component file names (e.g., `MyComponent.vue`).\n*   **Other Files:** Use camelCase or kebab-case for other JavaScript/TypeScript files (e.g., `apiService.js`, `my-helper.js`).\n*   **Consistency:** Maintain a consistent naming convention throughout the project.\n\n### 1.3. Module Organization\n\n*   **ES Modules:** Utilize ES modules (`import`/`export`) for modular code organization.\n*   **Single Responsibility Principle:** Each module should have a single, well-defined responsibility.\n*   **Avoid Circular Dependencies:** Prevent circular dependencies between modules to avoid unexpected behavior and improve maintainability.\n\n### 1.4. Component Architecture\n\n*   **Component Composition:** Favor component composition over inheritance for increased flexibility and reusability.\n*   **Presentational and Container Components:** Separate presentational (dumb) components from container (smart) components. Presentational components focus on rendering UI, while container components handle data fetching and logic.\n*   **Single File Components (SFCs):** Leverage Vue's SFCs for encapsulating component logic, template, and styling.\n\n### 1.5. Code Splitting Strategies\n\n*   **Route-Based Splitting:** Use dynamic imports and Vue's `async` component feature to split the application into chunks based on routes.\n*   **Component-Based Splitting:** Split large components into smaller, lazy-loaded components to improve initial load time.\n*   **Vendor Splitting:** Separate vendor dependencies into a separate chunk to allow for browser caching and prevent unnecessary reloads.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Vue\n\n*   **Provide/Inject:** Use `provide` and `inject` for dependency injection between components, especially when dealing with deeply nested components.\n*   **Renderless Components:** Create renderless components that encapsulate logic and provide data to be rendered by slot-using components.\n*   **Higher-Order Components (HOCs):** Use HOCs to reuse component logic or add functionality to existing components.\n\n### 2.2. Recommended Approaches for Common Tasks\n\n*   **Form Handling:** Use `v-model` for two-way data binding in forms. Consider using a form validation library like Vuelidate or VeeValidate for robust form validation.\n*   **API Requests:** Use a dedicated service module for handling API requests. Use `async/await` for cleaner asynchronous code.\n*   **State Management:** Utilize Vuex for centralized state management in larger applications. For simpler applications, consider using Vue's reactivity system directly or a lightweight state management solution like Pinia.\n*   **Event Handling:** Use component events (`$emit`) for communication between parent and child components. For communication between unrelated components, use a global event bus (with caution) or a state management solution.\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n*   **Mutating Props Directly:** Avoid mutating props directly within a component. Instead, emit an event to the parent component to update the prop value.\n*   **Overusing Global State:** Avoid storing too much data in global state. Use local component state whenever possible.\n*   **Direct DOM Manipulation:** Avoid directly manipulating the DOM using `document` APIs. Use Vue's template directives and component APIs to update the DOM reactively.\n*   **Magic Numbers and Strings:** Avoid using magic numbers and strings directly in the code. Use constants to improve readability and maintainability.\n*   **Complex Computed Properties:** Keep computed properties simple and focused. Complex computations should be moved to methods or utility functions.\n\n### 2.4. State Management Best Practices\n\n*   **Single Source of Truth:** Maintain a single source of truth for application state using Vuex or Pinia.\n*   **Mutations for State Updates:** Only use mutations to update the state in Vuex. Mutations should be synchronous and atomic.\n*   **Actions for Asynchronous Operations:** Use actions to handle asynchronous operations like API requests. Actions can commit mutations to update the state.\n*   **Getters for Derived State:** Use getters to derive state from the store. Getters should be pure functions and should not modify the state.\n*   **Modularity:** Organize the store into modules to improve maintainability and scalability.\n\n### 2.5. Error Handling Patterns\n\n*   **Centralized Error Handling:** Implement a centralized error handling mechanism to catch and log errors consistently.\n*   **Error Boundary Components:** Use error boundary components to catch errors within specific parts of the application and prevent crashes.\n*   **User-Friendly Error Messages:** Provide user-friendly error messages to guide users when errors occur.\n*   **Logging:** Log errors to a server or error tracking service for monitoring and debugging.\n*   **Try-Catch Blocks:** Use `try-catch` blocks to handle potential errors in asynchronous operations or complex computations.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n*   **Virtual DOM Optimization:** Vue's virtual DOM implementation is already highly optimized, but avoid unnecessary re-renders by using `v-if` instead of `v-show` when elements are rarely displayed.\n*   **Computed Properties and Watchers:** Use computed properties and watchers judiciously. Avoid performing expensive computations in computed properties that are frequently re-evaluated. Debounce or throttle watchers to limit the number of updates.\n*   **List Rendering Optimization:** Use the `:key` attribute when rendering lists with `v-for` to help Vue track changes efficiently.  Ensure the keys are unique and stable.\n*   **Functional Components:** Use functional components for simple, stateless components to improve rendering performance.\n*   **Avoid Inline Templates:**  Use pre-compiled templates in single-file components instead of inline templates (using `<script type=\"text/x-template\">`) for better performance.\n\n### 3.2. Memory Management\n\n*   **Remove Event Listeners:**  When a component is destroyed, remove any event listeners that were added manually (e.g., using `addEventListener`).\n*   **Unsubscribe from Observables:**  If using RxJS or other observable libraries, unsubscribe from observables when the component is destroyed to prevent memory leaks.\n*   **Release References:**  Release references to large objects or data structures when they are no longer needed to allow the garbage collector to reclaim memory.\n\n### 3.3. Rendering Optimization\n\n*   **Asynchronous Updates:**  Use `Vue.nextTick()` or `setTimeout()` to defer updates that are not immediately needed, allowing the browser to complete rendering tasks.\n*   **Debouncing and Throttling:**  Debounce or throttle event handlers that trigger frequent updates to prevent excessive re-renders.\n*   **`v-once` Directive:**  Use the `v-once` directive for elements that will never change to improve rendering performance.\n*   **Avoid Deeply Nested Components:**  Deeply nested component hierarchies can impact rendering performance. Consider flattening the hierarchy or using techniques like scoped slots to optimize rendering.\n\n### 3.4. Bundle Size Optimization\n\n*   **Code Splitting:** Implement code splitting to reduce the initial bundle size and improve loading time.\n*   **Tree Shaking:**  Use a modern build tool like Webpack or Rollup to perform tree shaking and remove unused code from the final bundle.\n*   **Minification and Compression:**  Minify and compress the code to reduce the bundle size.\n*   **Image Optimization:**  Optimize images by compressing them and using appropriate formats (e.g., WebP) to reduce file sizes.\n*   **Lazy Loading:**  Lazy load images, components, and other resources to improve initial load time.\n\n### 3.5. Lazy Loading Strategies\n\n*   **Lazy Loading Components:** Use dynamic imports to lazy load components only when they are needed.\n*   **Lazy Loading Images:** Use a lazy loading library to load images only when they are visible in the viewport.\n*   **Lazy Loading Routes:** Lazy load routes using Vue Router's `component: () => import('./MyComponent.vue')` syntax.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n*   **Cross-Site Scripting (XSS):** Prevent XSS attacks by sanitizing user input and using Vue's built-in template directives, which automatically escape HTML entities.\n*   **Cross-Site Request Forgery (CSRF):** Protect against CSRF attacks by implementing CSRF tokens in forms and API requests.\n*   **SQL Injection:** Prevent SQL injection attacks by using parameterized queries or an ORM with built-in protection.\n*   **Man-in-the-Middle (MitM) Attacks:** Use HTTPS to encrypt communication between the client and server and protect against MitM attacks.\n*   **Clickjacking:** Prevent clickjacking attacks by setting the `X-Frame-Options` header to `DENY` or `SAMEORIGIN`.\n\n### 4.2. Input Validation\n\n*   **Server-Side Validation:** Always perform server-side validation to ensure data integrity and prevent malicious input.\n*   **Client-Side Validation:** Implement client-side validation to provide immediate feedback to users and reduce server load. Use libraries like Vuelidate or VeeValidate.\n*   **Sanitization:** Sanitize user input to remove potentially harmful characters or code.\n\n### 4.3. Authentication and Authorization Patterns\n\n*   **JSON Web Tokens (JWT):** Use JWTs for authentication and authorization. Store JWTs securely in the client-side (e.g., using HTTP-only cookies or local storage with encryption).\n*   **Role-Based Access Control (RBAC):** Implement RBAC to control access to different parts of the application based on user roles.\n*   **OAuth 2.0:** Use OAuth 2.0 for third-party authentication and authorization.\n*   **Secure Password Storage:** Store passwords securely using a strong hashing algorithm like bcrypt or Argon2.\n\n### 4.4. Data Protection Strategies\n\n*   **Encryption:** Encrypt sensitive data both in transit and at rest.\n*   **Data Masking:** Mask sensitive data in the UI to prevent unauthorized access.\n*   **Data Minimization:** Collect only the necessary data and avoid storing sensitive data unnecessarily.\n*   **Regular Security Audits:** Conduct regular security audits to identify and address potential vulnerabilities.\n\n### 4.5. Secure API Communication\n\n*   **HTTPS:** Use HTTPS for all API communication.\n*   **API Authentication:** Implement authentication for all API endpoints using JWTs or other authentication mechanisms.\n*   **Rate Limiting:** Implement rate limiting to prevent abuse and denial-of-service attacks.\n*   **Input Validation:** Validate all API input to prevent injection attacks.\n*   **Output Encoding:** Encode API output to prevent XSS attacks.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n*   **Component Testing:** Write unit tests for individual Vue components to verify their behavior in isolation. Use a testing library like Jest or Mocha with Vue Test Utils.\n*   **Function Testing:** Write unit tests for utility functions and other non-component code.\n*   **Test-Driven Development (TDD):** Consider using TDD to write tests before writing the code.\n\n### 5.2. Integration Testing\n\n*   **Component Integration:** Write integration tests to verify the interaction between multiple components.\n*   **Module Integration:** Write integration tests to verify the interaction between different modules of the application.\n*   **End-to-End Integration:** Write end-to-end integration tests to verify the entire application flow from the user's perspective. Tools like Cypress, Playwright, or Selenium can be used for E2E testing.\n\n### 5.3. End-to-End Testing\n\n*   **User Flow Testing:** Simulate user flows to test the application's functionality from end to end.\n*   **Visual Regression Testing:** Use visual regression testing to detect unintended visual changes in the UI.\n*   **Accessibility Testing:** Test the application's accessibility to ensure it is usable by people with disabilities.\n\n### 5.4. Test Organization\n\n*   **Test Suites:** Organize tests into suites based on the component or module being tested.\n*   **Test Cases:** Write clear and concise test cases with descriptive names.\n*   **Arrange-Act-Assert:** Follow the Arrange-Act-Assert pattern in each test case.\n\n### 5.5. Mocking and Stubbing\n\n*   **Mock Dependencies:** Mock external dependencies like API services or third-party libraries to isolate the code being tested.\n*   **Stub Component Behavior:** Stub the behavior of child components to focus on testing the parent component's logic.\n*   **Use Mocking Libraries:** Use a mocking library like Jest's `jest.fn()` to create mock functions and objects.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n*   **Forgetting to Use `:key` in `v-for`:** Always use the `:key` attribute when rendering lists with `v-for` to ensure efficient DOM updates.\n*   **Incorrectly Using `v-if` and `v-show`:** Understand the difference between `v-if` and `v-show` and use them appropriately.  `v-if` conditionally renders the element, while `v-show` toggles the element's visibility.\n*   **Mutating Props Directly:** Avoid mutating props directly. Emit an event to the parent component to update the prop value.\n*   **Not Handling Edge Cases:**  Consider edge cases and write tests to cover them.\n\n### 6.2. Edge Cases to Be Aware Of\n\n*   **Empty Arrays or Objects:**  Handle cases where data is empty or null.\n*   **Unexpected API Responses:**  Handle cases where the API returns an error or unexpected data.\n*   **User Input Errors:**  Handle cases where the user enters invalid or malicious input.\n\n### 6.3. Version-Specific Issues\n\n*   **Breaking Changes:** Be aware of breaking changes in new Vue.js versions and update the code accordingly.\n*   **Deprecated APIs:** Avoid using deprecated APIs and migrate to the recommended alternatives.\n*   **Compatibility Issues:** Ensure compatibility with the target browsers and devices.\n\n### 6.4. Compatibility Concerns\n\n*   **Browser Compatibility:** Test the application in different browsers and devices to ensure compatibility.\n*   **Accessibility:** Ensure the application is accessible to users with disabilities.\n*   **Responsive Design:** Implement responsive design to ensure the application looks good on different screen sizes.\n\n### 6.5. Debugging Strategies\n\n*   **Vue Devtools:** Use the Vue Devtools browser extension to inspect components, state, and events.\n*   **Console Logging:** Use `console.log()` to debug code and track variables.\n*   **Debugger Statements:** Use `debugger` statements to pause the execution of code and inspect variables.\n*   **Error Logging:** Log errors to a server or error tracking service for monitoring and debugging.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n*   **VS Code with Vetur or Volar:** Use VS Code with the Vetur (Vue tooling) or Volar extension for syntax highlighting, code completion, and other features.\n*   **Vue CLI:** Use Vue CLI for scaffolding projects, building, and serving the application.\n*   **Vue Devtools:** Use the Vue Devtools browser extension for debugging Vue applications.\n*   **ESLint:** Use ESLint with the `eslint-plugin-vue` plugin for linting Vue code.\n*   **Prettier:** Use Prettier for formatting Vue code.\n\n### 7.2. Build Configuration\n\n*   **Webpack or Rollup:** Use Webpack or Rollup for building the application.\n*   **Babel:** Use Babel for transpiling JavaScript code to ensure compatibility with older browsers.\n*   **PostCSS:** Use PostCSS for processing CSS code and adding vendor prefixes.\n\n### 7.3. Linting and Formatting\n\n*   **ESLint:** Configure ESLint with the `eslint-plugin-vue` plugin to enforce coding standards and prevent errors.\n*   **Prettier:** Configure Prettier to automatically format code according to a consistent style.\n*   **Husky and lint-staged:** Use Husky and lint-staged to run linters and formatters before committing code.\n\n### 7.4. Deployment Best Practices\n\n*   **Build for Production:** Build the application for production with the `--mode production` flag.\n*   **Optimize Assets:** Optimize assets like images and fonts to reduce file sizes.\n*   **Use a CDN:** Use a content delivery network (CDN) to serve static assets.\n*   **Configure Caching:** Configure caching headers to improve performance.\n*   **Use HTTPS:** Use HTTPS for all communication.\n\n### 7.5. CI/CD Integration\n\n*   **Automated Builds:** Configure a CI/CD pipeline to automatically build and deploy the application whenever changes are pushed to the repository.\n*   **Automated Testing:** Run automated tests in the CI/CD pipeline to ensure code quality.\n*   **Automated Deployment:** Automate the deployment process to reduce manual effort and prevent errors.\n\n\nBy following these best practices, you can create high-quality, maintainable, and performant Vue.js applications.",
    "metadata": {
      "globs": "*.vue, *.js, *.ts",
      "format": "mdc",
      "originalFile": "vue.mdc"
    },
    "subcategory": "vue-ecosystem",
    "keywords": [
      "cursor",
      "vue",
      "comprehensive",
      "guidelines",
      "development",
      "covering",
      "code",
      "structure",
      "performance",
      "security",
      "testing",
      "tooling",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "vue-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vue",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-vue3",
    "description": "This rule provides best practices and coding standards for Vue 3 projects, covering code organization, performance, security, testing, tooling, and common pitfalls to ensure maintainable and efficient applications. It aims to guide developers in writing high-quality Vue 3 code.",
    "author": "sanjeed5",
    "tags": [
      "vue3",
      "vue",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/vue3.mdc",
    "content": "- **Code Organization and Structure**:\n  - **Directory Structure**: Adopt a feature-based directory structure. Group related files (components, stores, utilities) within feature-specific directories rather than separating by file type. This enhances maintainability and discoverability.\n    - Example:\n      \n      src/\n        components/\n          MyComponent.vue\n          ...\n        views/\n          MyView.vue\n          ...\n        features/\n          user-profile/\n            components/\n              UserProfileCard.vue\n            composables/\n              useUserProfileData.js\n            store/\n              userProfile.js\n          ...\n      \n  - **File Naming Conventions**: Use PascalCase for component file names (e.g., `MyComponent.vue`). Use camelCase for variable and function names (e.g., `myVariable`, `myFunction`). Use kebab-case for component selectors in templates (e.g., `<my-component>`).\n  - **Module Organization**: Utilize ES modules (`import`/`export`) for modularity and code reusability. Group related functions and components into modules.\n  - **Component Architecture**: Favor a component-based architecture. Design components to be small, reusable, and composable. Use props for data input and events for data output. Consider using a component library (e.g., Vuetify, Element Plus) for pre-built components.\n  - **Code Splitting Strategies**: Implement lazy loading for components and routes to reduce initial bundle size. Use dynamic imports for on-demand loading of modules.\n    - Example:\n      javascript\n      // Route-based code splitting\n      const routes = [\n        {\n          path: '/about',\n          component: () => import('./views/About.vue')\n        }\n      ]\n      \n\n- **Common Patterns and Anti-patterns**:\n  - **Design Patterns**: Apply common design patterns such as composition API, provider/inject, and observer pattern where applicable.\n    - **Composition API**: Organize component logic into composable functions for reusability and maintainability.\n    - **Provider/Inject**: Use `provide` and `inject` to share data between components without prop drilling.\n  - **Recommended Approaches**: Utilize `v-model` for two-way data binding, computed properties for derived state, and watchers for side effects. Use the Composition API for enhanced code organization and reusability.\n  - **Anti-patterns and Code Smells**: Avoid directly mutating props. Avoid excessive use of global variables. Avoid complex logic within templates. Avoid tight coupling between components. Avoid over-engineering solutions.\n  - **State Management**: Choose a state management solution (e.g., Vuex, Pinia) for complex applications.  Favor Pinia for Vue 3 due to its simpler API and improved TypeScript support. Decouple components from state management logic using actions and mutations.\n  - **Error Handling**: Implement global error handling using `app.config.errorHandler`. Use `try...catch` blocks for handling synchronous errors. Utilize `Promise.catch` for handling asynchronous errors. Provide user-friendly error messages.\n    - Example:\n      javascript\n      // Global error handler\n      app.config.errorHandler = (err, vm, info) => {\n        console.error('Global error:', err, info);\n        // Report error to server or display user-friendly message\n      }\n      \n\n- **Performance Considerations**:\n  - **Optimization Techniques**: Use `v-once` for static content. Use `v-memo` to memoize parts of the template. Use `key` attribute for `v-for` loops to improve rendering performance.\n  - **Memory Management**: Avoid creating memory leaks by properly cleaning up event listeners and timers. Use `onBeforeUnmount` lifecycle hook to release resources.\n  - **Rendering Optimization**: Use virtual DOM efficiently. Minimize unnecessary re-renders by using `ref` and `reactive` appropriately. Use `shouldUpdate` hook in functional components to control updates.\n  - **Bundle Size Optimization**: Use code splitting, tree shaking, and minification to reduce bundle size. Remove unused dependencies. Use smaller alternative libraries where possible.\n  - **Lazy Loading**: Implement lazy loading for images, components, and routes. Use `IntersectionObserver` API for lazy loading images.\n\n- **Security Best Practices**:\n  - **Common Vulnerabilities**: Prevent Cross-Site Scripting (XSS) attacks by sanitizing user input. Prevent Cross-Site Request Forgery (CSRF) attacks by using CSRF tokens. Prevent SQL injection attacks by using parameterized queries.\n  - **Input Validation**: Validate user input on both client-side and server-side. Use appropriate data types and formats. Escape special characters.\n  - **Authentication and Authorization**: Implement secure authentication and authorization mechanisms. Use HTTPS to encrypt communication. Store passwords securely using hashing and salting.\n  - **Data Protection**: Protect sensitive data using encryption. Avoid storing sensitive data in client-side storage. Follow privacy best practices.\n  - **Secure API Communication**: Use HTTPS for API communication. Validate API responses. Implement rate limiting to prevent abuse.\n\n- **Testing Approaches**:\n  - **Unit Testing**: Write unit tests for individual components, functions, and modules. Use Jest or Vitest as a test runner. Mock dependencies to isolate units of code.\n  - **Integration Testing**: Write integration tests to verify the interaction between components and modules. Use Vue Test Utils for component testing.\n  - **End-to-End Testing**: Write end-to-end tests to simulate user interactions and verify the application's overall functionality. Use Cypress or Playwright for end-to-end testing.\n  - **Test Organization**: Organize tests into separate directories based on the component or module being tested. Use descriptive test names.\n  - **Mocking and Stubbing**: Use mocks and stubs to isolate units of code and simulate dependencies. Use `jest.mock` or `vi.mock` for mocking modules.\n\n- **Common Pitfalls and Gotchas**:\n  - **Frequent Mistakes**: Forgetting to register components. Incorrectly using `v-if` and `v-show`. Mutating props directly. Not handling asynchronous operations correctly. Ignoring error messages.\n  - **Edge Cases**: Handling empty arrays or objects. Dealing with browser compatibility issues. Managing state in complex components.\n  - **Version-Specific Issues**: Being aware of breaking changes between Vue 2 and Vue 3. Using deprecated APIs.\n  - **Compatibility Concerns**: Ensuring compatibility with different browsers and devices. Testing on different screen sizes and resolutions.\n  - **Debugging Strategies**: Using Vue Devtools for debugging. Using `console.log` statements for inspecting variables. Using a debugger for stepping through code.\n\n- **Tooling and Environment**:\n  - **Recommended Development Tools**: Use VS Code with the Volar extension for Vue 3 development. Use Vue CLI or Vite for project scaffolding. Use Vue Devtools for debugging.\n  - **Build Configuration**: Configure Webpack or Rollup for building the application. Optimize build settings for production. Use environment variables for configuration.\n  - **Linting and Formatting**: Use ESLint with the `eslint-plugin-vue` plugin for linting Vue code. Use Prettier for code formatting. Configure linting and formatting rules to enforce code style.\n  - **Deployment Best Practices**: Use a CDN for serving static assets. Use server-side rendering (SSR) or pre-rendering for improved SEO and performance. Deploy to a reliable hosting platform.\n  - **CI/CD Integration**: Integrate linting, testing, and building into the CI/CD pipeline. Use automated deployment tools. Monitor application performance and errors.\n\n- **Additional Best Practices**: \n  - **Accessibility (A11y)**: Ensure components are accessible by using semantic HTML, providing ARIA attributes where necessary, and testing with screen readers. \n  - **Internationalization (i18n)**: Implement i18n from the start if multilingual support is required. Use a library like `vue-i18n` to manage translations. \n  - **Documentation**: Document components and composables using JSDoc or similar tools. Generate documentation automatically using tools like Storybook. \n\n- **Vue 3 Specific Recommendations**:\n    - **TypeScript**: Use TypeScript for improved type safety and code maintainability. Define component props and emits with type annotations.\n    - **Teleport**: Use the `Teleport` component to render content outside the component's DOM hierarchy, useful for modals and tooltips.\n    - **Suspense**: Use the `Suspense` component to handle asynchronous dependencies gracefully, providing fallback content while waiting for data to load.\n\n- **Naming Conventions**:\n    - Components: PascalCase (e.g., `MyComponent.vue`)\n    - Variables/Functions: camelCase (e.g., `myVariable`, `myFunction`)\n    - Props/Events: camelCase (e.g., `myProp`, `myEvent`)\n    - Directives: kebab-case (e.g., `v-my-directive`)\n\n- **Composition API Best Practices**:\n  - **Reactive Refs**: Use `ref` for primitive values and `reactive` for objects. \n  - **Readonly Refs**: Use `readonly` to prevent accidental mutations of reactive data.\n  - **Computed Properties**: Use `computed` for derived state and avoid complex logic within templates.\n  - **Lifecycle Hooks**: Use `onMounted`, `onUpdated`, `onUnmounted`, etc., to manage component lifecycle events.\n  - **Watchers**: Use `watch` for reacting to reactive data changes and performing side effects.",
    "metadata": {
      "globs": "*.vue",
      "format": "mdc",
      "originalFile": "vue3.mdc"
    },
    "subcategory": "vue-ecosystem",
    "keywords": [
      "cursor",
      "vue3",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "coding",
      "standards",
      "projects",
      "covering",
      "code",
      "vue",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "vue-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "vue3",
        "vue",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  },
  {
    "name": "cursor-webpack",
    "description": "This rule provides comprehensive best practices for Webpack configuration, optimization, and usage within projects. It covers code organization, performance, security, testing, and common pitfalls to ensure robust and efficient builds.",
    "author": "sanjeed5",
    "tags": [
      "webpack",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/webpack.mdc",
    "content": "# Webpack Best Practices: A Comprehensive Guide\n\nThis guide provides a detailed set of best practices for using Webpack effectively, covering various aspects from project setup to production optimization.  Following these guidelines will help you create robust, performant, and maintainable webpack configurations.\n\n## 1. Code Organization and Structure\n\n### Directory Structure Best Practices\n\nA well-structured directory is crucial for maintainability and scalability. Here's a recommended directory structure:\n\n\nproject-name/\n├── src/                  # Source code directory\n│   ├── components/       # Reusable UI components\n│   ├── modules/          # Independent modules\n│   ├── assets/           # Static assets (images, fonts, etc.)\n│   │   ├── images/\n│   │   ├── fonts/\n│   │   └── styles/\n│   ├── index.js          # Entry point of the application\n│   └── ...\n├── dist/                 # Output directory (generated by Webpack)\n├── config/               # Webpack configuration files\n│   ├── webpack.common.js # Common configuration for all environments\n│   ├── webpack.dev.js  # Development-specific configuration\n│   └── webpack.prod.js # Production-specific configuration\n├── node_modules/          # Node modules (dependencies)\n├── package.json          # Project metadata and dependencies\n├── webpack.config.js   # Main webpack configuration entry point (can delegate to config/)\n├── .babelrc              # Babel configuration file (if using Babel)\n└── ...\n\n\n### File Naming Conventions\n\n*   **JavaScript/JSX:**  `ComponentName.js` or `ComponentName.jsx`\n*   **CSS/SCSS/LESS:**  `ComponentName.module.css`, `ComponentName.module.scss`, or `ComponentName.module.less` (for CSS Modules)\n*   **Images:**  `descriptive-name.jpg`, `descriptive-name.png`, `descriptive-name.svg`\n*   **Webpack Config:** `webpack.config.js`, `webpack.common.js`, `webpack.dev.js`, `webpack.prod.js`\n\n### Module Organization\n\nOrganize modules based on functionality or feature. Use clear and descriptive names. For example:\n\njavascript\n// src/modules/api.js\nexport function fetchData(url) \n  // ...\n\n\n// src/modules/utils.js\nexport function formatDate(date) {\n  // ...\n}\n\n\n### Component Architecture\n\nFor UI frameworks like React, Vue, or Angular, adopt a component-based architecture.  Separate concerns into reusable components. Use a clear folder structure within the `components` directory (e.g., `src/components/Button/Button.jsx`).\n\n### Code Splitting Strategies\n\n*   **Entry Points:** Define multiple entry points in `webpack.config.js` for different pages or sections of your application.  Useful for multi-page applications.\n*   **Dynamic Imports:** Use `import()` syntax for lazy-loading modules or components on demand. This can significantly reduce the initial bundle size.\n    javascript\n    // Example of dynamic import\n    async function loadComponent() {\n      const { default: Component } = await import('./MyComponent');\n      // ...\n    }\n    \n*   **SplitChunksPlugin:**  Use the `SplitChunksPlugin` to extract common dependencies into separate chunks, which can be cached by the browser.  Configure it in `webpack.config.js`:\n    javascript\n    // webpack.config.js\n    optimization: {\n      splitChunks: {\n        chunks: 'all',\n        cacheGroups: {\n          vendor: {\n            test: /[\\\\/]node_modules[\\\\/]/,\n            name: 'vendors',\n            chunks: 'all',\n          },\n        },\n      },\n    },\n    \n    Consider these `SplitChunksPlugin` options:\n    * `chunks`:  `'all'` (recommended), `'async'`, or `'initial'`\n    * `cacheGroups`: Define rules for creating chunks (e.g., `vendor` for node_modules)\n    * `minSize`:  Minimum size of a chunk to be created\n\n## 2. Common Patterns and Anti-patterns\n\n### Design Patterns Specific to Webpack\n\n*   **Environment-Specific Configurations:**  Use separate configuration files for development and production (e.g., `webpack.dev.js`, `webpack.prod.js`). Use `webpack-merge` to combine common configurations with environment-specific settings.\n*   **Loader Chains:**  Configure loaders to process files in a specific order (e.g., `sass-loader` -> `css-loader` -> `style-loader`).\n*   **Plugin Composition:** Use multiple plugins to achieve complex build processes.\n\n### Recommended Approaches for Common Tasks\n\n*   **Handling CSS:** Use CSS Modules for component-level styling.  Combine with `sass-loader` or `less-loader` for pre-processing.\n*   **Image Optimization:** Use `image-webpack-loader` to optimize images during the build process.\n*   **Environment Variables:** Use `DefinePlugin` to inject environment variables into your code.\n\n### Anti-patterns and Code Smells to Avoid\n\n*   **Overly Complex Configurations:** Keep configurations as simple as possible.  Break down complex logic into reusable modules.\n*   **Large Bundles:**  Avoid large bundles by using code splitting and tree shaking.\n*   **Ignoring Warnings/Errors:** Always address warnings and errors reported by Webpack.\n*   **Over-relying on Global Styles:**  Prefer CSS Modules to avoid naming conflicts.\n\n### State Management Best Practices\n\n*   If using a state management library like Redux or Vuex, ensure that it is correctly integrated with Webpack.\n*   Consider using lazy-loading for state modules to improve initial load time.\n\n### Error Handling Patterns\n\n*   Use try-catch blocks to handle errors in asynchronous operations.\n*   Implement error boundaries in UI components to prevent crashes.\n*   Configure Webpack to display meaningful error messages.\n\n## 3. Performance Considerations\n\n### Optimization Techniques\n\n*   **Tree Shaking:**  Remove unused code by using ES modules and setting `optimization.usedExports: true` in `webpack.config.js`.  Ensure that your code is written in ES module syntax (e.g., `import` and `export`).\n*   **Minification:**  Use TerserPlugin (included by default in production mode) or other minification plugins to reduce bundle size.\n*   **Code Splitting:**  Split your code into smaller chunks to improve initial load time (see Code Splitting Strategies above).\n*   **Compression:**  Use Gzip or Brotli compression on your server to reduce the size of transferred files.\n*   **Caching:**  Leverage browser caching by using content hashes in filenames (e.g., `[name].[contenthash].js`).\n\n### Memory Management\n\n*   Be mindful of memory usage during the build process, especially when using loaders that perform complex transformations.\n*   Consider using `thread-loader` to offload expensive loaders to a worker pool.\n\n### Rendering Optimization\n\n*   Optimize images and other assets to reduce their size.\n*   Use lazy-loading for images and components that are not immediately visible.\n\n### Bundle Size Optimization\n\n*   Analyze your bundle size using `webpack-bundle-analyzer` to identify large dependencies.\n*   Remove unnecessary dependencies.\n*   Use smaller alternatives to large libraries when possible.\n\n### Lazy Loading Strategies\n\n*   Implement lazy-loading for routes, components, and modules that are not critical for the initial load.\n*   Use the `React.lazy` or `Vue.component` with a dynamic `import()` to lazy load components.\n\n## 4. Security Best Practices\n\n### Common Vulnerabilities and How to Prevent Them\n\n*   **Dependency Vulnerabilities:**  Use `npm audit` or `yarn audit` to identify and fix vulnerabilities in your dependencies.  Consider using tools like Snyk or Dependabot for automated vulnerability scanning.\n*   **Cross-Site Scripting (XSS):**  Sanitize user inputs to prevent XSS attacks. Be especially careful when using `dangerouslySetInnerHTML` in React.\n*   **Security Misconfiguration:**  Ensure that your Webpack configuration does not expose sensitive information (e.g., API keys).\n\n### Input Validation\n\n*   Validate user inputs on both the client and server sides.\n*   Use appropriate validation libraries to prevent injection attacks.\n\n### Authentication and Authorization Patterns\n\n*   Implement secure authentication and authorization mechanisms.\n*   Use HTTPS to encrypt communication between the client and server.\n*   Store sensitive data securely using environment variables and secret management tools.\n\n### Data Protection Strategies\n\n*   Encrypt sensitive data at rest and in transit.\n*   Use secure storage mechanisms to protect user data.\n*   Follow data privacy regulations (e.g., GDPR, CCPA).\n\n### Secure API Communication\n\n*   Use HTTPS for all API communication.\n*   Implement proper authentication and authorization for API endpoints.\n*   Validate API responses to prevent data injection.\n\n## 5. Testing Approaches\n\n### Unit Testing Strategies\n\n*   Write unit tests for individual modules and components.\n*   Use testing frameworks like Jest, Mocha, or Jasmine.\n*   Mock external dependencies to isolate units under test.\n\n### Integration Testing\n\n*   Write integration tests to verify the interaction between different modules and components.\n*   Use tools like Cypress or Puppeteer for end-to-end testing.\n\n### End-to-end Testing\n\n*   Write end-to-end tests to simulate user interactions and verify the overall functionality of the application.\n*   Use testing frameworks like Selenium or Playwright.\n\n### Test Organization\n\n*   Organize tests in a clear and consistent manner (e.g., `src/components/Button/Button.test.js`).\n*   Use descriptive test names.\n\n### Mocking and Stubbing\n\n*   Use mocking and stubbing to isolate units under test and simulate external dependencies.\n*   Use mocking libraries like Jest's `jest.mock()` or Sinon.js.\n\n## 6. Common Pitfalls and Gotchas\n\n### Frequent Mistakes Developers Make\n\n*   **Incorrect Loader Configuration:**  Double-check the order and configuration of loaders.\n*   **Missing Dependencies:**  Ensure that all required dependencies are installed.\n*   **Ignoring Cache:**  Leverage caching to speed up build times.\n*   **Not Understanding Context:** Ensure loaders and plugins are applied to the correct files by using `include` and `exclude` options.\n\n### Edge Cases to Be Aware Of\n\n*   **Circular Dependencies:**  Avoid circular dependencies, which can lead to unexpected behavior.\n*   **Large Files:**  Optimize large files (e.g., images, videos) to reduce bundle size.\n*   **Conflicting Plugins:** Ensure that plugins do not conflict with each other.\n\n### Version-Specific Issues\n\n*   Be aware of breaking changes in Webpack versions.\n*   Consult the Webpack documentation for version-specific information.\n\n### Compatibility Concerns\n\n*   Test your application in different browsers and devices to ensure compatibility.\n*   Use Babel to transpile your code to older JavaScript versions.\n\n### Debugging Strategies\n\n*   Use source maps to debug your code in the browser.\n*   Use the `console.log` statement to inspect variables and data structures.\n*   Use the Webpack Dev Server's hot module replacement (HMR) feature for faster development cycles.\n\n## 7. Tooling and Environment\n\n### Recommended Development Tools\n\n*   **Code Editor:**  VS Code, Sublime Text, Atom\n*   **Browser:** Chrome, Firefox, Safari\n*   **Node.js:**  Latest LTS version\n*   **NPM/Yarn:** Package managers\n\n### Build Configuration\n\n*   Use separate configuration files for development and production (e.g., `webpack.dev.js`, `webpack.prod.js`).\n*   Use `webpack-merge` to combine common configurations with environment-specific settings.\n\n### Linting and Formatting\n\n*   Use ESLint and Prettier to enforce code style and catch errors early.\n*   Integrate linting and formatting into your build process.\n\n### Deployment Best Practices\n\n*   Use a CI/CD pipeline to automate the deployment process.\n*   Deploy your application to a production-ready environment (e.g., AWS, Azure, Google Cloud).\n*   Use a CDN to serve static assets.\n\n### CI/CD Integration\n\n*   Integrate Webpack into your CI/CD pipeline to automate the build, test, and deployment processes.\n*   Use tools like Jenkins, Travis CI, or CircleCI.\n*   Automate dependency updates using tools like Dependabot.\n\nBy following these best practices, you can ensure that your Webpack configurations are robust, performant, and maintainable.",
    "metadata": {
      "globs": "webpack.config.js",
      "format": "mdc",
      "originalFile": "webpack.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "webpack",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "best",
      "practices",
      "configuration",
      "optimization",
      "usage",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "webpack",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-xgboost",
    "description": "This rule provides best practices for developing with XGBoost, covering code organization, performance, security, testing, and common pitfalls.",
    "author": "sanjeed5",
    "tags": [
      "xgboost",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/xgboost.mdc",
    "content": "# XGBoost Best Practices\n\nThis document outlines best practices for developing with XGBoost, focusing on code organization, common patterns, performance, security, testing, common pitfalls, and tooling.\n\n## Library Information:\n\n- Name: xgboost\n- Tags: ai, ml, machine-learning, python, gradient-boosting\n\n## 1. Code Organization and Structure\n\n### 1.1 Directory Structure Best Practices\n\nAdopt a clear and maintainable directory structure. Here's a recommended structure:\n\n\nproject_root/\n├── data/\n│   ├── raw/\n│   ├── processed/\n│   └── external/\n├── models/\n│   ├── trained_models/\n│   └── evaluation_metrics/\n├── src/\n│   ├── features/\n│   │   └── build_features.py  # Data transformation and feature engineering\n│   ├── models/\n│   │   ├── train_model.py     # Model training script\n│   │   ├── predict_model.py   # Model prediction script\n│   │   └── xgboost_model.py # Definition of XGBoost model and related functions\n│   ├── visualization/\n│   │   └── visualize.py     # Visualization tools\n│   ├── utils/\n│   │   └── helpers.py         # Helper functions\n│   └── __init__.py\n├── notebooks/\n│   └── exploratory_data_analysis.ipynb # EDA notebooks\n├── tests/\n│   ├── features/\n│   ├── models/\n│   └── utils/\n├── .gitignore\n├── README.md\n├── requirements.txt\n└── config.yaml # Configuration file\n\n\n### 1.2 File Naming Conventions\n\n- Use descriptive and consistent file names.\n- Python scripts: `snake_case.py` (e.g., `train_model.py`, `build_features.py`).\n- Configuration files: `config.yaml` or `config.json`.\n- Data files: `descriptive_name.csv` or `descriptive_name.parquet`.\n- Model files: `model_name.pkl` or `model_name.joblib`.\n\n### 1.3 Module Organization\n\n- Group related functions and classes into modules.\n- Use `__init__.py` files to make directories importable as packages.\n- Example `src/models/xgboost_model.py`:\n\npython\nimport xgboost as xgb\n\nclass XGBoostModel:\n    def __init__(self, params=None):\n        self.params = params or {}\n        self.model = None\n\n    def train(self, X, y):\n        self.model = xgb.XGBRegressor(**self.params)\n        self.model.fit(X, y)\n\n    def predict(self, X):\n        return self.model.predict(X)\n\n    def evaluate(self, X, y):\n        # Evaluation metrics\n        pass\n\n\n### 1.4 Component Architecture\n\n- **Data Ingestion Layer**: Responsible for reading and validating input data.\n- **Feature Engineering Layer**: Transforms raw data into features suitable for XGBoost.\n- **Model Training Layer**: Trains the XGBoost model using the prepared features.\n- **Prediction Layer**: Loads the trained model and makes predictions on new data.\n- **Evaluation Layer**: Evaluates the model's performance using appropriate metrics.\n\n### 1.5 Code Splitting\n\n- Break down large scripts into smaller, reusable functions and classes.\n- Use separate modules for data loading, preprocessing, model training, and evaluation.\n- Leverage configuration files for managing parameters and settings.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1 Design Patterns\n\n- **Factory Pattern**: To create different types of XGBoost models based on configuration.\n- **Strategy Pattern**: To implement different feature engineering techniques or evaluation metrics.\n- **Observer Pattern**: To log training progress or monitor performance during training.\n\n### 2.2 Recommended Approaches for Common Tasks\n\n- **Hyperparameter Tuning**: Use `GridSearchCV`, `RandomizedSearchCV`, or Bayesian optimization techniques like `Hyperopt` or `Optuna` to find optimal hyperparameters.\n- **Cross-Validation**: Use `KFold` or `StratifiedKFold` to evaluate model performance robustly.\n- **Feature Importance**: Use `model.feature_importances_` or `xgb.plot_importance` to understand feature importance and perform feature selection.\n- **Early Stopping**: Monitor validation performance during training and stop when performance plateaus to prevent overfitting. Use `early_stopping_rounds` parameter in `xgb.train` or `model.fit`.\n\n### 2.3 Anti-patterns and Code Smells\n\n- **Hardcoding parameters**: Avoid hardcoding hyperparameters or file paths directly in the code. Use configuration files or command-line arguments instead.\n- **Ignoring feature scaling**: XGBoost is sensitive to feature scaling, so always normalize or standardize your features.\n- **Overfitting**: Be cautious of overfitting, especially with complex models. Use regularization, early stopping, and cross-validation to mitigate this.\n- **Ignoring data leakage**: Ensure that your training data is not contaminated with information from the test data.\n- **Not tracking experiments**:  Use experiment tracking tools like Neptune.ai, MLflow, or Weights & Biases to manage model versions, hyperparameters, and results effectively.\n\n### 2.4 State Management\n\n- Use classes to encapsulate model state and provide methods for training, prediction, and evaluation.\n- Store trained models in a serialized format (e.g., `pickle`, `joblib`) for later use.\n- Manage configuration parameters using a dedicated configuration file or object.\n\n### 2.5 Error Handling\n\n- Use `try-except` blocks to handle potential exceptions, such as file not found or invalid data.\n- Log errors and warnings using the `logging` module.\n- Provide informative error messages to help with debugging.\n\n## 3. Performance Considerations\n\n### 3.1 Optimization Techniques\n\n- **GPU Acceleration**: Use GPU training to significantly speed up model training.\n- **Parallel Processing**: XGBoost supports parallel processing, so utilize multiple CPU cores to speed up training.\n- **Column Subsampling**: Reduce the number of features used in each tree to improve performance.\n- **Row Subsampling**: Reduce the number of samples used in each boosting round to improve performance.\n- **Data Types**: Use appropriate data types for your data (e.g., `float32` instead of `float64`) to reduce memory usage and improve performance.\n\n### 3.2 Memory Management\n\n- **Large Datasets**: For large datasets, consider using out-of-core training or distributed computing frameworks like Dask or Spark.\n- **Feature Reduction**: Reduce the number of features used in the model to reduce memory usage.\n- **Data Sampling**: Use sampling techniques to reduce the size of the training dataset.\n\n### 3.3 Lazy Loading\n\n- Implement lazy loading for large datasets or models to avoid loading them into memory until they are needed.\n- Use generators or iterators to process data in chunks.\n\n## 4. Security Best Practices\n\n### 4.1 Common Vulnerabilities and Prevention\n\n- **Model Poisoning**: Ensure your training data is from trusted sources to prevent malicious data from influencing the model.\n- **Input Injection**: Sanitize user inputs before feeding them to the model to prevent injection attacks.\n- **Model Extraction**: Protect your trained models from unauthorized access to prevent model extraction attacks.\n\n### 4.2 Input Validation\n\n- Validate input data to ensure it conforms to expected formats and ranges.\n- Use schema validation libraries to enforce data quality.\n- Sanitize user inputs to prevent injection attacks.\n\n### 4.3 Authentication and Authorization\n\n- Implement authentication and authorization mechanisms to restrict access to sensitive data and models.\n- Use role-based access control (RBAC) to manage user permissions.\n\n### 4.4 Data Protection\n\n- Encrypt sensitive data at rest and in transit.\n- Use data masking or anonymization techniques to protect personally identifiable information (PII).\n- Comply with relevant data privacy regulations (e.g., GDPR, CCPA).\n\n### 4.5 Secure API Communication\n\n- Use HTTPS for secure communication between clients and servers.\n- Implement API rate limiting to prevent denial-of-service attacks.\n- Use API keys or tokens for authentication.\n\n## 5. Testing Approaches\n\n### 5.1 Unit Testing\n\n- Test individual functions and classes in isolation.\n- Use mocking and stubbing to isolate components and simulate dependencies.\n- Write test cases for various scenarios, including edge cases and error conditions.\n\n### 5.2 Integration Testing\n\n- Test the interaction between different components or modules.\n- Verify that data flows correctly between modules.\n- Test the integration of XGBoost with other libraries or frameworks.\n\n### 5.3 End-to-End Testing\n\n- Test the entire application from end to end.\n- Simulate user interactions and verify that the application behaves as expected.\n- Test the deployment pipeline to ensure that the application can be deployed successfully.\n\n### 5.4 Test Organization\n\n- Organize tests into separate directories based on the module or component being tested.\n- Use a consistent naming convention for test files and test functions.\n- Keep tests concise and easy to understand.\n\n### 5.5 Mocking and Stubbing\n\n- Use mocking and stubbing to isolate components and simulate dependencies.\n- Use mocking libraries like `unittest.mock` or `pytest-mock`.\n- Create mock objects that mimic the behavior of real dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1 Frequent Mistakes\n\n- **Incorrect data types**: Ensure data types are appropriate (e.g. numerical features are not strings).\n- **Not handling missing data**: XGBoost can handle missing values, but ensure you understand the implications and consider imputation.\n- **Ignoring class imbalance**: Use `scale_pos_weight` or other techniques to address class imbalance in classification problems.\n- **Not setting `eval_metric`**:  Always define an evaluation metric to monitor training progress, especially when using early stopping.\n\n### 6.2 Edge Cases\n\n- **Rare categories**:  Handle rare categories in categorical features appropriately, possibly by grouping them into a single category.\n- **Outliers**: Consider the impact of outliers on the model and apply appropriate outlier detection and removal techniques.\n- **Data drift**: Monitor the model's performance over time and retrain the model if data drift occurs.\n\n### 6.3 Version-Specific Issues\n\n- **API changes**: Be aware of API changes between XGBoost versions and update your code accordingly.\n- **Compatibility issues**: Check for compatibility issues with other libraries or frameworks when upgrading XGBoost.\n\n### 6.4 Compatibility Concerns\n\n- Ensure compatibility between XGBoost and other libraries, such as scikit-learn, pandas, and NumPy.\n- Use compatible versions of these libraries to avoid conflicts.\n\n### 6.5 Debugging Strategies\n\n- Use logging to track the flow of execution and identify errors.\n- Use a debugger to step through the code and inspect variables.\n- Use profiling tools to identify performance bottlenecks.\n\n## 7. Tooling and Environment\n\n### 7.1 Recommended Development Tools\n\n- **IDE**: VS Code, PyCharm, Jupyter Notebooks.\n- **Experiment Tracking**: MLflow, Neptune.ai, Weights & Biases.\n- **Data Visualization**: Matplotlib, Seaborn, Plotly.\n- **Profiling**: cProfile, memory_profiler.\n- **Debugging**: pdb (Python Debugger).\n\n### 7.2 Build Configuration\n\n- Use a `requirements.txt` file to manage dependencies.\n- Use a virtual environment to isolate project dependencies.\n- Use a `setup.py` or `pyproject.toml` file for packaging and distribution.\n- Specify versions for all dependencies to ensure reproducibility\n\n### 7.3 Linting and Formatting\n\n- Use a linter like `flake8` or `pylint` to enforce code style and detect errors.\n- Use a formatter like `black` or `autopep8` to automatically format your code.\n\n### 7.4 Deployment\n\n- **Model Serialization**: Serialize the model using `pickle` or `joblib` for deployment.\n- **Containerization**: Containerize the application using Docker for easy deployment and scalability.\n- **Serving**: Serve the model using a web framework like Flask or FastAPI.\n- **Cloud Platforms**: Deploy the application to a cloud platform like AWS, Azure, or Google Cloud.\n\n### 7.5 CI/CD Integration\n\n- Use a CI/CD pipeline to automate the build, test, and deployment process.\n- Integrate with version control systems like Git.\n- Use testing frameworks like pytest or unittest to run tests automatically.\n- Automate deployment to staging and production environments.\n\nBy following these best practices, you can develop robust, maintainable, and high-performing XGBoost applications.",
    "metadata": {
      "globs": "*.py,*.ipynb",
      "format": "mdc",
      "originalFile": "xgboost.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "xgboost",
      "this",
      "rule",
      "provides",
      "best",
      "practices",
      "developing",
      "with",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "xgboost",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-zod",
    "description": "This rule provides comprehensive guidelines for using the Zod library effectively, covering code organization, performance, security, and testing to ensure robust and maintainable type validation.",
    "author": "sanjeed5",
    "tags": [
      "zod",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/zod.mdc",
    "content": "- **Organize Zod schemas logically for readability and maintainability.** Group related schemas together and structure your Zod code for improved clarity, especially in larger projects.\n- **Compose and reuse related schemas to avoid repetition.** Use Zod's composition features (e.g., `z.intersection`, `z.union`, `z.extend`) to create reusable schema components and reduce redundancy.\n- **Implement schema versioning for better management.** As your application evolves, version your schemas to handle data migrations and maintain compatibility with older data formats.\n- **Use Zod for type-safe data validation and transformation.** Leverage Zod's capabilities for both validating and transforming data to ensure data integrity throughout your application.\n\n### 1. Code Organization and Structure:\n\n- **Directory Structure Best Practices:**\n    - Consider grouping Zod schemas within dedicated directories (e.g., `schemas/`, `models/schemas/`).\n    - Organize schemas by domain, feature, or data model.\n    - Use subdirectories for complex schemas or schema families.\n- **File Naming Conventions:**\n    - Name schema files descriptively (e.g., `user.schema.ts`, `product.schema.ts`).\n    - Use a consistent naming pattern throughout the project.\n    - Consider including the data model name or the schema's purpose in the filename.\n- **Module Organization:**\n    - Export schemas as named exports from each module.\n    - Create index files (e.g., `index.ts`) to re-export schemas from subdirectories for easier access.\n    - Use clear and concise module names.\n- **Component Architecture:**\n    - If you are building React components, consider creating a `components/schemas/` directory where you house your schema related to specific components.\n    - Use Zod to validate the props passed to React components using `z.infer` and `z.ZodType<Props>`\n    - You can create a custom hook that handles validation with Zod and stores the parsed result in React state.\n- **Code Splitting Strategies:**\n    - For large schema definitions, split them into smaller, more manageable files.\n    - Use Zod's composition features to combine these smaller schemas into larger, more complex schemas as needed.\n\n### 2. Common Patterns and Anti-patterns:\n\n- **Design Patterns Specific to Zod:**\n    - **Schema Composition:** Use `z.intersection`, `z.union`, `z.extend`, and `z.optional` to combine and modify existing schemas.\n    - **Schema Transformation:** Use `.transform` to modify data during validation.\n    - **Custom Validation:** Use `.refine` and `.superRefine` for custom validation logic.\n    - **Default Values:** Use `.default` to assign default values to schema properties.\n- **Recommended Approaches for Common Tasks:**\n    - **Form Validation:** Use Zod to validate form input data and display errors.\n    - **API Request Validation:** Use Zod to validate incoming API request bodies.\n    - **Data Serialization/Deserialization:** Use Zod to validate and transform data when serializing or deserializing.\n- **Anti-patterns and Code Smells to Avoid:**\n    - **Overly Complex Schemas:** Avoid creating schemas that are too complex or difficult to understand. Break them down into smaller, more manageable schemas.\n    - **Ignoring Validation Errors:** Always handle validation errors and provide informative feedback to the user.\n    - **Duplicated Schema Definitions:** Avoid duplicating schema definitions. Use schema composition to reuse existing schemas.\n- **State Management Best Practices:**\n    - When using Zod with state management libraries (e.g., Redux, Zustand), validate the state data using Zod schemas.\n    - Use Zod to validate state updates before applying them to the state.\n- **Error Handling Patterns:**\n    - Use Zod's `.safeParse` method to handle validation errors gracefully.\n    - Provide informative error messages to the user.\n    - Log validation errors for debugging purposes.\n\n### 3. Performance Considerations:\n\n- **Optimization Techniques:**\n    - **Schema Caching:** Cache frequently used schemas to avoid re-parsing them.\n    - **Pre-compilation:** If possible, pre-compile schemas during build time to improve performance.\n    - **Minimize Schema Complexity:** Keep schemas as simple as possible to reduce validation overhead.\n- **Memory Management:**\n    - Be mindful of the memory usage of large schemas, especially when dealing with large datasets.\n    - Release unused schemas when they are no longer needed.\n- **Bundle Size Optimization:**\n    - Remove unused schemas and code from the bundle.\n    - Use tree shaking to eliminate dead code.\n- **Lazy Loading Strategies:**\n    - Lazily load schemas that are not immediately needed.\n    - Use code splitting to load schemas on demand.\n\n### 4. Security Best Practices:\n\n- **Common Vulnerabilities and How to Prevent Them:**\n    - **Injection Attacks:** Prevent injection attacks by validating and sanitizing user input data.\n    - **Cross-Site Scripting (XSS):** Prevent XSS attacks by encoding user input data before displaying it in the UI.\n    - **Denial of Service (DoS):** Prevent DoS attacks by limiting the size and complexity of input data.\n- **Input Validation:**\n    - Validate all user input data using Zod schemas.\n    - Enforce strict validation rules to prevent invalid or malicious data from entering the system.\n- **Authentication and Authorization Patterns:**\n    - Use Zod to validate user credentials during authentication.\n    - Use Zod to validate authorization tokens and permissions.\n- **Data Protection Strategies:**\n    - Encrypt sensitive data at rest and in transit.\n    - Use secure storage mechanisms to protect data from unauthorized access.\n- **Secure API Communication:**\n    - Use HTTPS to encrypt API communication.\n    - Validate API request and response data using Zod schemas.\n\n### 5. Testing Approaches:\n\n- **Unit Testing Strategies:**\n    - Write unit tests for individual schemas to ensure they validate data correctly.\n    - Test different input scenarios, including valid and invalid data.\n    - Use mocking and stubbing to isolate schemas from external dependencies.\n- **Integration Testing:**\n    - Write integration tests to ensure that schemas work correctly with other parts of the application.\n    - Test the interaction between schemas and data sources (e.g., databases, APIs).\n- **End-to-End Testing:**\n    - Write end-to-end tests to ensure that the entire application works correctly with Zod schemas.\n    - Test the user interface and the data flow through the application.\n- **Test Organization:**\n    - Organize tests into separate directories based on the type of test (e.g., unit, integration, end-to-end).\n    - Use descriptive test names to indicate the purpose of each test.\n- **Mocking and Stubbing:**\n    - Use mocking and stubbing to isolate schemas from external dependencies during testing.\n    - Mock data sources and APIs to control the test environment.\n\n### 6. Common Pitfalls and Gotchas:\n\n- **Frequent Mistakes Developers Make:**\n    - **Incorrect Schema Definitions:** Ensure that schema definitions accurately reflect the expected data format.\n    - **Ignoring Validation Errors:** Always handle validation errors and provide informative feedback to the user.\n    - **Overly Complex Schemas:** Avoid creating schemas that are too complex or difficult to understand.\n- **Edge Cases to Be Aware Of:**\n    - **Null and Undefined Values:** Handle null and undefined values correctly in schemas.\n    - **Empty Strings and Arrays:** Handle empty strings and arrays appropriately.\n    - **Date and Time Formats:** Use consistent date and time formats throughout the application.\n- **Version-Specific Issues:**\n    - Be aware of any version-specific issues or breaking changes in Zod.\n    - Refer to the Zod documentation and release notes for information on compatibility and migration.\n- **Compatibility Concerns:**\n    - Ensure that Zod schemas are compatible with the data formats used by other systems or libraries.\n    - Consider using a data serialization format (e.g., JSON, YAML) that is widely supported.\n- **Debugging Strategies:**\n    - Use Zod's `.safeParse` method to log validation errors for debugging purposes.\n    - Use a debugger to step through the validation process and identify issues.\n\n### 7. Tooling and Environment:\n\n- **Recommended Development Tools:**\n    - **TypeScript:** Use TypeScript to provide static typing for Zod schemas and data.\n    - **VS Code:** Use VS Code with the Zod extension for improved code completion and validation.\n- **Build Configuration:**\n    - Configure the build process to transpile TypeScript code and bundle JavaScript code.\n    - Use a module bundler (e.g., Webpack, Parcel, Rollup) to optimize the bundle size.\n- **Linting and Formatting:**\n    - Use a linter (e.g., ESLint) to enforce code style and best practices.\n    - Use a code formatter (e.g., Prettier) to automatically format code.\n- **Deployment Best Practices:**\n    - Deploy the application to a production environment with appropriate security measures in place.\n    - Monitor the application for errors and performance issues.\n- **CI/CD Integration:**\n    - Integrate Zod schemas into the CI/CD pipeline to automate validation and testing.\n    - Run unit tests, integration tests, and end-to-end tests as part of the CI/CD process.",
    "metadata": {
      "globs": "*.ts?(x)",
      "format": "mdc",
      "originalFile": "zod.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "zod",
      "this",
      "rule",
      "provides",
      "comprehensive",
      "guidelines",
      "using",
      "library",
      "effectively",
      "covering",
      "code",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "zod",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-zsh",
    "description": "This rule enforces best practices and coding standards for Zsh scripting to enhance readability, maintainability, security, and performance. It covers code structure, common patterns, performance, security, testing, common pitfalls, and tooling.",
    "author": "sanjeed5",
    "tags": [
      "zsh",
      "cursor",
      "cursor-rule",
      "mdc",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "windsurf-rules",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/zsh.mdc",
    "content": "# Zsh Best Practices and Coding Standards\n\nThis document outlines the best practices and coding standards for Zsh scripting, aiming to enhance readability, maintainability, security, and performance of your scripts.\n\n## 1. Code Organization and Structure\n\n*   **Directory Structure Best Practices:**\n    *   `bin/`: Executable scripts intended for general use.\n    *   `lib/`: Library functions and modules.\n    *   `conf/`: Configuration files.\n    *   `test/`: Test scripts.\n    *   `modules/`: Dynamically loaded modules.\n    *   `data/`: Data files used by scripts.\n    *   `tmp/`: Temporary files (ensure proper cleanup).\n*   **File Naming Conventions:**\n    *   Use `.zsh` extension for Zsh scripts.\n    *   Descriptive names using lowercase and underscores (e.g., `process_data.zsh`, `utility_functions.zsh`).\n    *   Avoid spaces in file names.\n*   **Module Organization:**\n    *   Split code into logical modules (e.g., `network_utils.zsh`, `string_manipulation.zsh`).\n    *   Use `source` or `.` to include modules in your scripts.\n        zsh\n        source lib/network_utils.zsh\n        \n    *   Consider using Zsh's module loading capabilities for larger projects.\n        zsh\n        zmodload zsh/datetime\n        \n*   **Component Architecture:**\n    *   Design scripts with modular, reusable components.\n    *   Encapsulate functionality within functions.\n    *   Use meaningful function names that describe their purpose.\n*   **Code Splitting Strategies:**\n    *   Split large scripts into smaller, manageable files.\n    *   Group related functions into modules.\n    *   Use functions to abstract complex logic.\n\n## 2. Common Patterns and Anti-patterns\n\n*   **Design Patterns:**\n    *   **Command Pattern:** Encapsulate commands as objects.\n    *   **Strategy Pattern:** Define a family of algorithms, encapsulate each one, and make them interchangeable.\n    *   **Template Method Pattern:** Define the skeleton of an algorithm in a function, deferring some steps to sub-functions.\n*   **Recommended Approaches for Common Tasks:**\n    *   **Parsing Command-Line Arguments:** Use `getopts` or `zparseopts` for parsing command-line arguments.\n        zsh\n        while getopts 'a:b:c' opt;\n        do\n          case \"$opt\" in\n            a) arg_a=\"$OPTARG\" ;;\n            b) arg_b=\"$OPTARG\" ;;\n            c) flag_c=true ;;\n            \\?) echo \"Invalid option: -$OPTARG\" >&2 ;;\n          esac\n        done\n        shift \"$((OPTIND - 1))\"\n        \n    *   **String Manipulation:** Use Zsh's built-in string manipulation features (e.g., parameter expansion, pattern matching).\n    *   **File I/O:** Use redirection (`>`, `<`, `>>`) and pipes (`|`) for file input/output.\n*   **Anti-patterns and Code Smells:**\n    *   **Global Variables:** Avoid global variables; use local variables within functions.\n    *   **Magic Numbers:** Avoid hardcoding values directly; use named constants.\n    *   **Code Duplication:** Refactor duplicated code into reusable functions or modules.\n    *   **Long Functions:** Break down long functions into smaller, more manageable units.\n    *   **Unclear Error Messages:** Provide informative error messages to the user.\n*   **State Management:**\n    *   Minimize the use of global state.\n    *   Pass state as arguments to functions.\n    *   Use temporary files for persistent state (with proper cleanup).\n*   **Error Handling:**\n    *   Use `set -e` to exit immediately if a command exits with a non-zero status.\n    *   Use `set -u` to treat unset variables as an error.\n    *   Check the exit status of commands using `$?`.\n    *   Use `trap` to handle signals (e.g., `EXIT`, `INT`, `TERM`).\n        zsh\n        trap 'echo \"Script interrupted.\"; exit 1' INT TERM\n        \n    *   Redirect stderr to a file for debugging.\n\n## 3. Performance Considerations\n\n*   **Optimization Techniques:**\n    *   **Avoid Spawning External Processes:** Use Zsh's built-in commands whenever possible.\n    *   **Minimize Disk I/O:** Use caching to reduce disk access.\n    *   **Optimize Loops:** Use efficient looping constructs (e.g., `for` loops over arrays).\n    *   **Use Arrays:** Arrays are generally faster than string manipulation for certain tasks.\n    *   **Use `zcompile`:** Pre-compile your zsh scripts to improve startup time\n        zsh\n        zcompile script.zsh\n        \n*   **Memory Management:**\n    *   Be mindful of memory usage when working with large files or data sets.\n    *   Use `unset` to free memory occupied by variables that are no longer needed.\n*   **Rendering Optimization (if applicable):**\n    *   Optimize terminal output for speed and clarity.\n    *   Avoid excessive use of colors and formatting.\n*   **Bundle Size Optimization:**\n    *   Not applicable to Zsh scripts in the same way as web applications, but keep scripts concise and avoid unnecessary dependencies.\n*   **Lazy Loading:**\n    *   Load modules and functions only when they are needed.\n\n## 4. Security Best Practices\n\n*   **Common Vulnerabilities:**\n    *   **Command Injection:** Prevent command injection by properly quoting variables and avoiding the use of `eval`.\n    *   **Path Traversal:** Sanitize user input to prevent path traversal attacks.\n    *   **Denial of Service (DoS):** Limit resource consumption to prevent DoS attacks.\n*   **Input Validation:**\n    *   Validate all user input before using it in commands.\n    *   Use regular expressions to validate data formats.\n    *   Use `typeset -i` to ensure variables are integers when expected.\n*   **Authentication and Authorization:**\n    *   For scripts requiring authentication, consider using existing authentication mechanisms (e.g., SSH keys).\n    *   Implement authorization checks to restrict access to sensitive resources.\n*   **Data Protection:**\n    *   Store sensitive data securely (e.g., using encrypted files).\n    *   Avoid storing passwords directly in scripts.\n    *   Use environment variables for sensitive configuration information.\n*   **Secure API Communication:**\n    *   Use HTTPS for all API communication.\n    *   Validate API responses.\n    *   Handle API errors gracefully.\n\n## 5. Testing Approaches\n\n*   **Unit Testing:**\n    *   Test individual functions in isolation.\n    *   Use a testing framework like `zunit` or `zrtest`.\n    *   Write tests for both positive and negative scenarios.\n*   **Integration Testing:**\n    *   Test the interaction between different modules and components.\n    *   Simulate real-world scenarios.\n*   **End-to-End Testing:**\n    *   Test the entire script from start to finish.\n    *   Verify that the script produces the expected output.\n*   **Test Organization:**\n    *   Create a separate directory for test scripts.\n    *   Organize tests by module or component.\n*   **Mocking and Stubbing:**\n    *   Use mocking and stubbing to isolate units of code during testing.\n    *   Create mock objects for external dependencies.\n\n## 6. Common Pitfalls and Gotchas\n\n*   **Frequent Mistakes:**\n    *   **Forgetting to Quote Variables:** Always quote variables to prevent word splitting and globbing.\n    *   **Ignoring Exit Status:** Always check the exit status of commands.\n    *   **Using `eval` Unnecessarily:** Avoid `eval` if possible, as it can lead to security vulnerabilities.\n    *   **Not Handling Signals:** Handle signals like `INT` and `TERM` to ensure proper cleanup.\n*   **Edge Cases:**\n    *   Handling empty or missing input.\n    *   Dealing with special characters in filenames.\n    *   Handling different locales and character encodings.\n*   **Version-Specific Issues:**\n    *   Be aware of differences between Zsh versions.\n    *   Use feature detection to ensure compatibility.\n*   **Compatibility Concerns:**\n    *   Ensure that your scripts are compatible with different operating systems.\n    *   Test your scripts on different environments.\n*   **Debugging Strategies:**\n    *   Use `set -x` to trace the execution of your script.\n    *   Use `echo` statements to print debugging information.\n    *   Use a debugger like `gdb` or `lldb` (if available).\n\n## 7. Tooling and Environment\n\n*   **Recommended Development Tools:**\n    *   **Text Editor:** Use a text editor with Zsh syntax highlighting and linting (e.g., VS Code with Zsh extensions).\n    *   **Shellcheck:** Use Shellcheck to identify potential problems in your scripts.\n    *   **Zsh Debugger:** If available, use a debugger to step through your code.\n*   **Build Configuration:**\n    *   Use Makefiles or other build tools to automate the build process.\n    *   Define dependencies and build targets.\n*   **Linting and Formatting:**\n    *   Use Shellcheck for linting.\n    *   Use a code formatter like `shfmt` to ensure consistent formatting.\n*   **Deployment Best Practices:**\n    *   Package your scripts with any necessary dependencies.\n    *   Use a version control system like Git to track changes.\n    *   Automate the deployment process using tools like Ansible or Puppet.\n*   **CI/CD Integration:**\n    *   Integrate your scripts with a CI/CD pipeline.\n    *   Run tests and linters automatically.\n    *   Deploy your scripts to production automatically.\n\n## Additional Considerations\n\n*   **Shebang:** Always start your scripts with a shebang line specifying the Zsh interpreter:\n    zsh\n    #!/usr/bin/env zsh\n    \n*   **Coding Style:** Follow a consistent coding style to improve readability.\n*   **Documentation:** Document your scripts and functions using comments.\n*   **Keep it Simple:** Aim for simplicity and clarity in your code.\n\nBy following these best practices, you can write Zsh scripts that are more reliable, maintainable, and secure.",
    "metadata": {
      "globs": "*.zsh",
      "format": "mdc",
      "originalFile": "zsh.mdc"
    },
    "subcategory": "general",
    "keywords": [
      "cursor",
      "zsh",
      "this",
      "rule",
      "enforces",
      "best",
      "practices",
      "coding",
      "standards",
      "scripting",
      "enhance",
      "readability",
      "cursor-rule",
      "mdc",
      "cursor-rules",
      "general"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "zsh",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "cursor-rules"
    }
  },
  {
    "name": "cursor-zustand",
    "description": "This rule provides guidelines for using Zustand, a simple and unopinionated state management library, in React applications. It covers best practices for code organization, performance optimization, testing, and common pitfalls to avoid.",
    "author": "sanjeed5",
    "tags": [
      "zustand",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor",
      "cursor-rule",
      "mdc",
      "web",
      "windsurf",
      "windsurf-rule"
    ],
    "type": "rule",
    "category": "frontend-frameworks",
    "sourceUrl": "https://github.com/sanjeed5/awesome-cursor-rules-mdc/blob/main/rules-mdc/zustand.mdc",
    "content": "# Zustand Best Practices\n\nThis document outlines best practices for using Zustand in your React applications. Zustand is a simple and unopinionated state management library. Following these guidelines will help you write maintainable, performant, and scalable applications.\n\n## 1. Code Organization and Structure\n\n### 1.1. Directory Structure\n\nOrganize your store files in a dedicated directory, such as `store` or `state`, at the root of your project or within a specific feature directory. This enhances discoverability and maintainability.\n\n\nsrc/\n├── components/\n│   ├── ...\n├── store/\n│   ├── index.ts          # Main store file (optional)\n│   ├── bearStore.ts      # Example store\n│   ├── fishStore.ts      # Example store\n│   └── utils.ts         # Utility functions for stores\n├── App.tsx\n└── ...\n\n\n### 1.2. File Naming Conventions\n\nUse descriptive names for your store files, typically reflecting the domain or feature the store manages. For example, `userStore.ts`, `cartStore.js`, or `settingsStore.tsx`.  Use PascalCase for the store name itself (e.g., `UserStore`).\n\n### 1.3. Module Organization\n\n- **Single Store per File:**  Prefer defining one Zustand store per file.  This improves readability and maintainability.\n- **Slices Pattern:** For complex stores, consider using the slices pattern to divide the store into smaller, more manageable pieces.  Each slice manages a specific part of the state and its related actions.\n\ntypescript\n// store/bearStore.ts\nimport { StateCreator, create } from 'zustand';\n\ninterface BearSlice {\n  bears: number;\n  addBear: () => void;\n}\n\nconst createBearSlice: StateCreator<BearSlice> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })),\n});\n\nexport const useBearStore = create<BearSlice>()((...a) => ({\n  ...createBearSlice(...a),\n}));\n\n// Another slice could be in fishStore.ts, etc.\n\n\n### 1.4. Component Architecture\n\n- **Presentational and Container Components:**  Separate presentational (UI) components from container components that interact with the Zustand store. Container components fetch data from the store and pass it down to presentational components.\n- **Hooks for Data Fetching:** Utilize Zustand's `useStore` hook within container components to subscribe to specific parts of the state.\n\n### 1.5. Code Splitting Strategies\n\n- **Lazy Loading Stores:**  Load stores on demand using dynamic imports.  This can reduce the initial bundle size, especially for larger applications.\n- **Feature-Based Splitting:** Split your application into feature modules and create separate stores for each feature.  This allows for independent loading and reduces dependencies between different parts of the application.\n\n## 2. Common Patterns and Anti-patterns\n\n### 2.1. Design Patterns Specific to Zustand\n\n- **Colocated Actions and State:**  Keep actions and the state they modify within the same store. This promotes encapsulation and makes it easier to understand how the store's state is updated.\n- **Selectors:** Use selectors to derive computed values from the store's state. Selectors should be memoized to prevent unnecessary re-renders.\n\ntypescript\n// store/userStore.ts\nimport { create } from 'zustand';\n\ninterface UserState {\n  name: string;\n  age: number;\n}\n\ninterface UserActions {\n  setName: (name: string) => void;\n  isAdult: () => boolean; // Selector\n}\n\nexport const useUserStore = create<UserState & UserActions>((set, get) => ({\n  name: 'John Doe',\n  age: 20,\n  setName: (name) => set({ name }),\n  isAdult: () => get().age >= 18, // Selector\n}));\n\n\n### 2.2. Recommended Approaches for Common Tasks\n\n- **Asynchronous Actions:** Use `async/await` within actions to handle asynchronous operations such as fetching data from an API.\n\ntypescript\ninterface DataState {\n  data: any | null;\n  isLoading: boolean;\n  fetchData: () => Promise<void>;\n}\n\nexport const useDataStore = create<DataState>((set) => ({\n  data: null,\n  isLoading: false,\n  fetchData: async () => {\n    set({ isLoading: true });\n    try {\n      const response = await fetch('https://api.example.com/data');\n      const data = await response.json();\n      set({ data, isLoading: false });\n    } catch (error) {\n      console.error('Error fetching data:', error);\n      set({ isLoading: false, data: null });\n    }\n  },\n}));\n\n\n- **Persisting State:** Use the `zustand/middleware`'s `persist` middleware to persist the store's state to local storage or another storage mechanism.  Configure a `partialize` function to select the state you want to persist.\n\ntypescript\nimport { create } from 'zustand'\nimport { persist } from 'zustand/middleware'\n\ninterface AuthState {\n  token: string | null;\n  setToken: (token: string | null) => void;\n}\n\nexport const useAuthStore = create<AuthState>()(\n  persist(\n    (set) => ({\n      token: null,\n      setToken: (token) => set({ token }),\n    }),\n    {\n      name: 'auth-storage', // unique name\n      partialize: (state) => ({ token: state.token }), // Only persist the token\n    }\n  )\n)\n\n\n### 2.3. Anti-patterns and Code Smells to Avoid\n\n- **Over-reliance on Global State:** Avoid storing everything in a single global store.  Instead, break down your application's state into smaller, more manageable stores based on feature or domain.\n- **Mutating State Directly:** Never mutate the state directly. Always use the `set` function provided by Zustand to ensure proper state updates and re-renders.  Consider using Immer middleware (`zustand/middleware`) for immutable updates with mutable syntax.\n- **Complex Selectors without Memoization:**  Avoid complex selectors that perform expensive computations without memoization.  This can lead to performance issues, especially with frequent state updates.\n- **Creating Stores Inside Components:**  Do not define Zustand stores inside React components.  This will cause the store to be re-created on every render, leading to data loss and unexpected behavior.\n\n### 2.4. State Management Best Practices\n\n- **Single Source of Truth:**  Treat the Zustand store as the single source of truth for your application's state.\n- **Minimize State:** Store only the essential data in the store.  Derive computed values using selectors.\n- **Clear State Transitions:**  Ensure that state transitions are predictable and well-defined.  Avoid complex and convoluted update logic.\n\n### 2.5. Error Handling Patterns\n\n- **Try/Catch Blocks in Actions:**  Wrap asynchronous actions in `try/catch` blocks to handle potential errors.  Update the state to reflect the error status.\n- **Error Boundary Components:**  Use React error boundary components to catch errors that occur during rendering.\n- **Centralized Error Logging:** Implement a centralized error logging mechanism to track errors that occur in your application.  Send error reports to a monitoring service.\n\n## 3. Performance Considerations\n\n### 3.1. Optimization Techniques\n\n- **Selective Updates:**  Use selectors to subscribe to only the specific parts of the state that your component needs. This prevents unnecessary re-renders when other parts of the state change.\n- **Shallow Equality Checks:** By default, Zustand uses strict equality (`===`) for state comparisons. If you're using complex objects, use `shallow` from `zustand/shallow` as an equality function in `useStore` to avoid unnecessary re-renders.\n- **Memoization:** Memoize selectors using libraries like `reselect` or `lodash.memoize` to prevent unnecessary re-computations.\n- **Batch Updates:** Use `unstable_batchedUpdates` from `react-dom` to batch multiple state updates into a single render cycle.\n\n### 3.2. Memory Management\n\n- **Avoid Leaks:** Ensure that you are not creating memory leaks by properly cleaning up any subscriptions or event listeners that you create.\n- **Limit Store Size:** Keep your stores as small as possible by only storing the data that you need.\n\n### 3.3. Rendering Optimization\n\n- **Virtualization:** If you are rendering large lists of data, use virtualization techniques (e.g., `react-window`, `react-virtualized`) to only render the visible items.\n- **Code Splitting:**  Split your application into smaller bundles to reduce the initial load time.\n\n### 3.4. Bundle Size Optimization\n\n- **Tree Shaking:** Ensure that your build process is configured to perform tree shaking, which removes unused code from your bundles.\n- **Minimize Dependencies:**  Use only the dependencies that you need.  Avoid importing entire libraries when you only need a few functions.\n- **Compression:**  Compress your bundles using tools like Gzip or Brotli.\n\n### 3.5. Lazy Loading Strategies\n\n- **Component-Level Lazy Loading:**  Lazy load components using `React.lazy` and `Suspense`.\n- **Route-Based Lazy Loading:**  Lazy load routes using `react-router-dom`'s `lazy` function.\n\n## 4. Security Best Practices\n\n### 4.1. Common Vulnerabilities and How to Prevent Them\n\n- **Cross-Site Scripting (XSS):** Sanitize user inputs to prevent XSS attacks.\n- **Cross-Site Request Forgery (CSRF):** Protect your API endpoints from CSRF attacks by implementing CSRF tokens.\n- **Sensitive Data Exposure:** Avoid storing sensitive data in the store unless absolutely necessary. Encrypt sensitive data if it must be stored.\n\n### 4.2. Input Validation\n\n- **Server-Side Validation:** Always validate user inputs on the server-side.\n- **Client-Side Validation:** Perform client-side validation to provide immediate feedback to the user.\n\n### 4.3. Authentication and Authorization Patterns\n\n- **JSON Web Tokens (JWT):** Use JWTs for authentication and authorization.\n- **Role-Based Access Control (RBAC):** Implement RBAC to control access to different parts of your application based on user roles.\n\n### 4.4. Data Protection Strategies\n\n- **Encryption:** Encrypt sensitive data at rest and in transit.\n- **Data Masking:** Mask sensitive data in logs and other outputs.\n\n### 4.5. Secure API Communication\n\n- **HTTPS:** Use HTTPS to encrypt communication between the client and server.\n- **API Rate Limiting:** Implement API rate limiting to prevent abuse.\n\n## 5. Testing Approaches\n\n### 5.1. Unit Testing Strategies\n\n- **Test Store Logic:** Write unit tests to verify the logic of your Zustand stores.\n- **Mock Dependencies:** Mock any external dependencies (e.g., API calls) to isolate the store logic.\n- **Test State Transitions:** Ensure that state transitions are correct by asserting the expected state after each action.\n\n### 5.2. Integration Testing\n\n- **Test Component Interactions:** Write integration tests to verify that your components interact correctly with the Zustand store.\n- **Render Components:** Render your components and simulate user interactions to test the integration between the UI and the store.\n\n### 5.3. End-to-End Testing\n\n- **Simulate User Flows:** Write end-to-end tests to simulate complete user flows through your application.\n- **Test Real-World Scenarios:** Test real-world scenarios to ensure that your application is working correctly in a production-like environment.\n\n### 5.4. Test Organization\n\n- **Colocate Tests:** Colocate your tests with the code that they are testing.\n- **Use Descriptive Names:** Use descriptive names for your test files and test cases.\n\n### 5.5. Mocking and Stubbing\n\n- **Jest Mocks:** Use Jest's mocking capabilities to mock external dependencies.\n- **Sinon Stubs:** Use Sinon to create stubs for functions and methods.\n\n## 6. Common Pitfalls and Gotchas\n\n### 6.1. Frequent Mistakes Developers Make\n\n- **Incorrectly Using `set`:** Forgetting to use the functional form of `set` when updating state based on the previous state.\n- **Not Handling Asynchronous Errors:** Failing to handle errors in asynchronous actions.\n- **Over-relying on `shallow`:**  Using `shallow` equality when a deep comparison is actually required.\n\n### 6.2. Edge Cases to Be Aware Of\n\n- **Race Conditions:** Be aware of potential race conditions when handling asynchronous actions.\n- **Context Loss:** Ensure that the Zustand provider is properly configured to avoid context loss issues.\n\n### 6.3. Version-Specific Issues\n\n- **Check Release Notes:**  Always check the release notes for new versions of Zustand to be aware of any breaking changes or new features.\n\n### 6.4. Compatibility Concerns\n\n- **React Version:**  Ensure that your version of React is compatible with the version of Zustand that you are using.\n\n### 6.5. Debugging Strategies\n\n- **Zustand Devtools:** Use the Zustand Devtools extension to inspect the store's state and track state changes.\n- **Console Logging:**  Use console logging to debug your store logic and component interactions.\n- **Breakpoints:** Set breakpoints in your code to step through the execution and inspect the state.\n\n## 7. Tooling and Environment\n\n### 7.1. Recommended Development Tools\n\n- **VS Code:** Use VS Code as your code editor.\n- **ESLint:**  Use ESLint to enforce code style and prevent errors.\n- **Prettier:** Use Prettier to automatically format your code.\n- **Zustand Devtools:**  Use the Zustand Devtools extension to inspect the store's state.\n\n### 7.2. Build Configuration\n\n- **Webpack:** Use Webpack to bundle your code.\n- **Parcel:** Use Parcel for zero-configuration bundling.\n- **Rollup:** Use Rollup for building libraries.\n\n### 7.3. Linting and Formatting\n\n- **ESLint:** Configure ESLint to enforce code style and best practices.\n- **Prettier:** Configure Prettier to automatically format your code.\n- **Husky:** Use Husky to run linters and formatters before committing code.\n\n### 7.4. Deployment Best Practices\n\n- **Environment Variables:** Use environment variables to configure your application for different environments.\n- **CDN:** Use a CDN to serve your static assets.\n- **Caching:** Implement caching to improve performance.\n\n### 7.5. CI/CD Integration\n\n- **GitHub Actions:** Use GitHub Actions to automate your build, test, and deployment processes.\n- **CircleCI:** Use CircleCI to automate your build, test, and deployment processes.\n- **Jenkins:** Use Jenkins to automate your build, test, and deployment processes.\n\n## 8. Zustand-X (zustandx.udecode.dev)\n\nZustand-X builds on top of Zustand to reduce boilerplate and enhance features, providing a store factory with derived selectors and actions.\n\n### 8.1. Key Features\n\n- **Less Boilerplate:** Simplified store creation.\n- **Modular State Management:** Derived selectors and actions.\n- **Middleware Support:** Integrates with `immer`, `devtools`, and `persist`.\n- **TypeScript Support:** Full TypeScript support.\n- **React-Tracked Support:** Integration with `react-tracked`.\n\n### 8.2. Usage\n\njavascript\nimport { createStore } from 'zustand-x';\n\nconst repoStore = createStore('repo')({\n  name: 'zustandX',\n  stars: 0,\n  owner: {\n    name: 'someone',\n    email: 'someone@xxx.com',\n  },\n});\n\n// Hook store\nrepoStore.useStore;\n\n// Vanilla store\nrepoStore.store;\n\n// Selectors\nrepoStore.use.name();\nrepoStore.get.name();\n\n// Actions\nrepoStore.set.name('new name');\n\n// Extend selectors\nrepoStore.extendSelectors((state, get, api) => ({\n  validName: () => get.name().trim(),\n  title: (prefix) => `${prefix + get.validName()} with ${get.stars()} stars`,\n}));\n\n// Extend actions\nrepoStore.extendActions((set, get, api) => ({\n  validName: (name) => {\n    set.name(name.trim());\n  },\n  reset: (name) => {\n    set.validName(name);\n    set.stars(0);\n  },\n}));\n\n\n### 8.3. Global Store\n\nCombine multiple stores into a global store for easier access.\n\njavascript\nimport { mapValuesKey } from 'zustand-x';\n\nexport const rootStore = {\n  repo: repoStore,\n  // other stores\n};\n\nexport const useStore = () => mapValuesKey('use', rootStore);\nexport const useTrackedStore = () => mapValuesKey('useTracked', rootStore);\nexport const store = mapValuesKey('get', rootStore);\nexport const actions = mapValuesKey('set', rootStore);\n\n// Usage\nuseStore().repo.name();\nactions.repo.stars(store.repo.stars + 1);\n\n\n## 9. zustand-ards\n\nA library of simple, opinionated utilities for Zustand to improve the developer experience.\n\n### 9.1 Installation\n\nbash\npnpm i zustand-ards\n# or\nnpm i zustand-ards\n\n\n### 9.2 Basic Usage\n\njavascript\nimport { withZustandards } from 'zustand-ards';\n\nconst useWithZustandards = withZustandards(useStore);\nconst { bears, increaseBears } = useWithZustandards(['bears', 'increaseBears']);\n\n\n### 9.3 Store Hook Enhancements\n\n- **`withZustandards`:** Combines `withArraySelector` and `withDefaultShallow`.\n- **`withArraySelector`:** Adds an array selector to the store hook, eliminating the need for multiple hooks or complex selector functions.\n- **`withDefaultShallow`:** Makes the store hook shallow by default, equivalent to passing `shallow` from `zustand/shallow` to the original hook.\n\njavascript\nimport { withArraySelector } from 'zustand-ards';\n\nconst useStoreWithArray = withArraySelector(useExampleStore);\nconst { bears, increaseBears } = useStoreWithArray(['bears', 'increaseBears']);\n\nimport { withDefaultShallow } from 'zustand-ards';\n\nconst useShallowStore = withDefaultShallow(useExampleStore);\nconst { wizards } = useShallowStore((state) => ({ wizards: state.wizards }));\n\n\n## 10. TypeScript Guide\n\n### 10.1. Basic Usage\n\nAnnotate the store's state type using `create<T>()(...)`.\n\ntypescript\nimport { create } from 'zustand';\n\ninterface BearState {\n  bears: number;\n  increase: (by: number) => void;\n}\n\nconst useBearStore = create<BearState>()((set) => ({\n  bears: 0,\n  increase: (by) => set((state) => ({ bears: state.bears + by }))\n}));\n\n\n### 10.2. Using `combine`\n\n`combine` infers the state, so no need to type it.\n\ntypescript\nimport { create } from 'zustand';\nimport { combine } from 'zustand/middleware';\n\nconst useBearStore = create(\n  combine({ bears: 0 }, (set) => ({\n    increase: (by: number) => set((state) => ({ bears: state.bears + by }))\n  }))\n);\n\n\n### 10.3. Using Middlewares\n\nUse middlewares immediately inside `create` to ensure contextual inference works correctly. Devtools should be used last to prevent other middlewares from mutating the `setState` before it.\n\ntypescript\nimport { create } from 'zustand';\nimport { devtools, persist } from 'zustand/middleware';\n\ninterface BearState {\n  bears: number;\n  increase: (by: number) => void;\n}\n\nconst useBearStore = create<BearState>()(\n  devtools(\n    persist(\n      (set) => ({\n        bears: 0,\n        increase: (by) => set((state) => ({ bears: state.bears + by }))\n      }),\n      { name: 'bearStore' }\n    )\n  )\n);\n\n\n### 10.4. Authoring Middlewares and Advanced Usage\n\nZustand middlewares can mutate the store.  Higher-kinded mutators are available for complex type problems.\n\n### 10.5. Middleware Examples\n\n**Middleware that doesn't change the store type:**\n\ntypescript\nimport { create, State, StateCreator, StoreMutatorIdentifier } from 'zustand';\n\ntype Logger = <\n  T extends State,\n  Mps extends [StoreMutatorIdentifier, unknown][] = [],\n  Mcs extends [StoreMutatorIdentifier, unknown][] = [],\n>(f: StateCreator<T, Mps, Mcs>, name?: string) => StateCreator<T, Mps, Mcs>;\n\nconst loggerImpl = (f, name) => (set, get, store) => {\n  const loggedSet = (...a) => {\n    set(...a);\n    console.log(...(name ? [`${name}:`] : []), get());\n  };\n  const setState = store.setState;\n  store.setState = (...a) => {\n    setState(...a);\n    console.log(...(name ? [`${name}:`] : []), store.getState());\n  };\n  return f(loggedSet, get, store);\n};\n\nexport const logger = loggerImpl;\n\n\n**Middleware that changes the store type:** Requires advanced TypeScript features.\n\n### 10.6. Slices Pattern\n\nThe slices pattern is a way to split a store into smaller, more manageable parts.\n\ntypescript\nimport { create, StateCreator } from 'zustand';\n\ninterface BearSlice {\n  bears: number;\n  addBear: () => void;\n  eatFish: () => void;\n}\n\ninterface FishSlice {\n  fishes: number;\n  addFish: () => void;\n}\n\nconst createBearSlice: StateCreator<BearSlice> = (set) => ({\n  bears: 0,\n  addBear: () => set((state) => ({ bears: state.bears + 1 })), \n  eatFish: () => set((state) => ({fishes: state.fishes -1}))\n});\n\nconst createFishSlice: StateCreator<FishSlice> = (set) => ({\n  fishes: 0,\n  addFish: () => set((state) => ({ fishes: state.fishes + 1 }))\n});\n\n\nexport const useBoundStore = create<BearSlice & FishSlice>()((...a) => ({\n  ...createBearSlice(...a),\n  ...createFishSlice(...a),\n}));\n\n\n### 10.7. Bounded useStore Hook for Vanilla Stores\n\nProvides type safety when using `useStore` with vanilla stores.\n\n## 11. Zustand Tools (zustand-tools)\n\nTools for simpler Zustand usage with React.\n\n### 11.1. `createSimple(initStore, middlewares)`\n\nCreates a simple store with correct typings and hooks for easier usage.\n\njavascript\nimport { createSimple } from 'zustand-tools';\n\nconst demoStore = createSimple({ foo: 'bar' });\n\n/*\n * will provide:\n * demoStore.useStore.getState().foo\n * demoStore.useStore.getState().setFoo(value)\n * demoStore.hooks.useFoo() => [value, setter] // like useState\n */\n\nconst useFoo = demoStore.hooks.useFoo;\n\nfunction App() {\n  const [foo, setFoo] = useFoo();\n\n  useEffect(() => {\n    setFoo('newBar');\n  }, [setFoo]);\n\n  return <div>{foo}</div>;\n}\n\n\n### 11.2. `createSimpleContext(initStore, middlewares)`\n\nBasically the same as `createSimple` but returns a provider to use the store only for a specific context.\n\n### 11.3. `useAllData()`\n\nReturns all data from the store using a shallow compare.\n\n### 11.4. Adding Additional Actions\n\nAdd additional actions to the generated store.\n\njavascript\nimport { createSimple } from 'zustand-tools';\n\nconst { useStore } = createSimple(\n  { foo: 1 },\n  {\n    actions: (set) => ({\n      increaseFoo: (amount) => set((state) => ({ foo: state.foo + amount }))\n    })\n  }\n);\n\nuseStore.getState().increaseFoo(5);\n\n\n### 11.5. Adding Middlewares\n\nMiddlewares can be added by passing an array as middlewares in the second parameter.\n\njavascript\nimport { createSimple } from 'zustand-tools';\nimport { devtools } from 'zustand/middleware';\n\nconst demoStore = createSimple({ foo: 'bar' }, { middlewares: [(initializer) => devtools(initializer, { enabled: true })] });\n\n\n## 12. Practice with no Store Actions\n\n### 12.1. Colocated Actions and State\n\nThe recommended usage is to colocate actions and states within the store.\n\njavascript\nexport const useBoundStore = create((set) => ({\n  count: 0,\n  text: 'hello',\n  inc: () => set((state) => ({ count: state.count + 1 })),\n  setText: (text) => set({ text }),\n}));\n\n\n### 12.2. External Actions\n\nAn alternative approach is to define actions at the module level, external to the store.\n\njavascript\nexport const useBoundStore = create(() => ({\n  count: 0,\n  text: 'hello',\n}));\n\nexport const inc = () =>\n  useBoundStore.setState((state) => ({ count: state.count + 1 }));\nexport const setText = (text) => useBoundStore.setState({ text });\n\n\n## Conclusion\n\nBy following these best practices, you can build robust and scalable applications using Zustand. Remember to adapt these guidelines to your specific project needs and coding style.",
    "metadata": {
      "globs": "*.js,*.jsx,*.ts,*.tsx",
      "format": "mdc",
      "originalFile": "zustand.mdc"
    },
    "subcategory": "react-ecosystem",
    "keywords": [
      "cursor",
      "zustand",
      "this",
      "rule",
      "provides",
      "guidelines",
      "using",
      "simple",
      "unopinionated",
      "state",
      "management",
      "react",
      "frontend",
      "javascript",
      "ui",
      "cursor-rule",
      "mdc",
      "web",
      "frontend-frameworks",
      "react-ecosystem"
    ],
    "verified": false,
    "karenScore": null,
    "downloads": 0,
    "stars": 0,
    "_original": {
      "tags": [
        "zustand",
        "react",
        "frontend",
        "javascript",
        "ui",
        "cursor",
        "cursor-rule",
        "mdc"
      ],
      "category": "frontend-frameworks"
    }
  }
]